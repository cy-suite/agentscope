{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.554243083618278,
  "eval_steps": 500,
  "global_step": 20000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 7.771215418091389e-05,
      "grad_norm": 0.2214256227016449,
      "learning_rate": 9.999611439229096e-06,
      "loss": 0.7006,
      "step": 1
    },
    {
      "epoch": 0.00015542430836182778,
      "grad_norm": 0.11325420439243317,
      "learning_rate": 9.99922287845819e-06,
      "loss": 0.2056,
      "step": 2
    },
    {
      "epoch": 0.00023313646254274168,
      "grad_norm": 0.21504034101963043,
      "learning_rate": 9.998834317687287e-06,
      "loss": 0.6356,
      "step": 3
    },
    {
      "epoch": 0.00031084861672365556,
      "grad_norm": 0.12968073785305023,
      "learning_rate": 9.998445756916382e-06,
      "loss": 0.504,
      "step": 4
    },
    {
      "epoch": 0.0003885607709045695,
      "grad_norm": 0.13861270248889923,
      "learning_rate": 9.998057196145477e-06,
      "loss": 0.1138,
      "step": 5
    },
    {
      "epoch": 0.00046627292508548337,
      "grad_norm": 0.25079450011253357,
      "learning_rate": 9.997668635374574e-06,
      "loss": 0.4052,
      "step": 6
    },
    {
      "epoch": 0.0005439850792663972,
      "grad_norm": 0.21725472807884216,
      "learning_rate": 9.997280074603669e-06,
      "loss": 0.4082,
      "step": 7
    },
    {
      "epoch": 0.0006216972334473111,
      "grad_norm": 0.17378583550453186,
      "learning_rate": 9.996891513832764e-06,
      "loss": 0.3,
      "step": 8
    },
    {
      "epoch": 0.0006994093876282251,
      "grad_norm": 0.07391942292451859,
      "learning_rate": 9.996502953061859e-06,
      "loss": 0.1763,
      "step": 9
    },
    {
      "epoch": 0.000777121541809139,
      "grad_norm": 0.14442017674446106,
      "learning_rate": 9.996114392290955e-06,
      "loss": 0.284,
      "step": 10
    },
    {
      "epoch": 0.0008548336959900529,
      "grad_norm": 0.16426338255405426,
      "learning_rate": 9.99572583152005e-06,
      "loss": 0.3743,
      "step": 11
    },
    {
      "epoch": 0.0009325458501709667,
      "grad_norm": 0.1151408851146698,
      "learning_rate": 9.995337270749145e-06,
      "loss": 0.1495,
      "step": 12
    },
    {
      "epoch": 0.0010102580043518806,
      "grad_norm": 0.20022174715995789,
      "learning_rate": 9.994948709978242e-06,
      "loss": 0.3362,
      "step": 13
    },
    {
      "epoch": 0.0010879701585327945,
      "grad_norm": 0.26036882400512695,
      "learning_rate": 9.994560149207337e-06,
      "loss": 1.0529,
      "step": 14
    },
    {
      "epoch": 0.0011656823127137084,
      "grad_norm": 0.09306538850069046,
      "learning_rate": 9.994171588436432e-06,
      "loss": 0.2439,
      "step": 15
    },
    {
      "epoch": 0.0012433944668946222,
      "grad_norm": 0.3211129605770111,
      "learning_rate": 9.993783027665528e-06,
      "loss": 0.7112,
      "step": 16
    },
    {
      "epoch": 0.0013211066210755361,
      "grad_norm": 0.1085270568728447,
      "learning_rate": 9.993394466894623e-06,
      "loss": 0.2536,
      "step": 17
    },
    {
      "epoch": 0.0013988187752564502,
      "grad_norm": 0.643956184387207,
      "learning_rate": 9.993005906123718e-06,
      "loss": 0.4426,
      "step": 18
    },
    {
      "epoch": 0.001476530929437364,
      "grad_norm": 0.23626023530960083,
      "learning_rate": 9.992617345352813e-06,
      "loss": 0.9266,
      "step": 19
    },
    {
      "epoch": 0.001554243083618278,
      "grad_norm": 0.05641040951013565,
      "learning_rate": 9.99222878458191e-06,
      "loss": 0.1305,
      "step": 20
    },
    {
      "epoch": 0.0016319552377991918,
      "grad_norm": 0.27753177285194397,
      "learning_rate": 9.991840223811005e-06,
      "loss": 0.5951,
      "step": 21
    },
    {
      "epoch": 0.0017096673919801057,
      "grad_norm": 0.36399710178375244,
      "learning_rate": 9.9914516630401e-06,
      "loss": 0.3665,
      "step": 22
    },
    {
      "epoch": 0.0017873795461610196,
      "grad_norm": 0.107342429459095,
      "learning_rate": 9.991063102269197e-06,
      "loss": 0.1727,
      "step": 23
    },
    {
      "epoch": 0.0018650917003419335,
      "grad_norm": 0.4323076903820038,
      "learning_rate": 9.990674541498291e-06,
      "loss": 0.574,
      "step": 24
    },
    {
      "epoch": 0.0019428038545228473,
      "grad_norm": 0.09699997305870056,
      "learning_rate": 9.990285980727386e-06,
      "loss": 0.2031,
      "step": 25
    },
    {
      "epoch": 0.002020516008703761,
      "grad_norm": 0.3450029194355011,
      "learning_rate": 9.989897419956483e-06,
      "loss": 0.3577,
      "step": 26
    },
    {
      "epoch": 0.002098228162884675,
      "grad_norm": 0.20984363555908203,
      "learning_rate": 9.989508859185576e-06,
      "loss": 0.2667,
      "step": 27
    },
    {
      "epoch": 0.002175940317065589,
      "grad_norm": 0.275882363319397,
      "learning_rate": 9.989120298414673e-06,
      "loss": 0.2671,
      "step": 28
    },
    {
      "epoch": 0.002253652471246503,
      "grad_norm": 0.25029125809669495,
      "learning_rate": 9.988731737643768e-06,
      "loss": 0.1548,
      "step": 29
    },
    {
      "epoch": 0.0023313646254274167,
      "grad_norm": 0.2938680052757263,
      "learning_rate": 9.988343176872863e-06,
      "loss": 1.2653,
      "step": 30
    },
    {
      "epoch": 0.0024090767796083306,
      "grad_norm": 0.28842124342918396,
      "learning_rate": 9.98795461610196e-06,
      "loss": 0.173,
      "step": 31
    },
    {
      "epoch": 0.0024867889337892445,
      "grad_norm": 0.12260326743125916,
      "learning_rate": 9.987566055331054e-06,
      "loss": 0.0474,
      "step": 32
    },
    {
      "epoch": 0.0025645010879701583,
      "grad_norm": 0.23569174110889435,
      "learning_rate": 9.98717749456015e-06,
      "loss": 0.3335,
      "step": 33
    },
    {
      "epoch": 0.0026422132421510722,
      "grad_norm": 0.44659674167633057,
      "learning_rate": 9.986788933789246e-06,
      "loss": 0.3344,
      "step": 34
    },
    {
      "epoch": 0.0027199253963319865,
      "grad_norm": 0.19444088637828827,
      "learning_rate": 9.986400373018341e-06,
      "loss": 0.6433,
      "step": 35
    },
    {
      "epoch": 0.0027976375505129004,
      "grad_norm": 0.1707882434129715,
      "learning_rate": 9.986011812247436e-06,
      "loss": 0.241,
      "step": 36
    },
    {
      "epoch": 0.0028753497046938143,
      "grad_norm": 0.16395463049411774,
      "learning_rate": 9.985623251476531e-06,
      "loss": 0.524,
      "step": 37
    },
    {
      "epoch": 0.002953061858874728,
      "grad_norm": 0.3149009644985199,
      "learning_rate": 9.985234690705628e-06,
      "loss": 0.2911,
      "step": 38
    },
    {
      "epoch": 0.003030774013055642,
      "grad_norm": 0.07931841909885406,
      "learning_rate": 9.984846129934722e-06,
      "loss": 0.0709,
      "step": 39
    },
    {
      "epoch": 0.003108486167236556,
      "grad_norm": 0.14047203958034515,
      "learning_rate": 9.984457569163817e-06,
      "loss": 0.1794,
      "step": 40
    },
    {
      "epoch": 0.00318619832141747,
      "grad_norm": 0.25653982162475586,
      "learning_rate": 9.984069008392914e-06,
      "loss": 0.1226,
      "step": 41
    },
    {
      "epoch": 0.0032639104755983837,
      "grad_norm": 1.023783564567566,
      "learning_rate": 9.983680447622009e-06,
      "loss": 0.7093,
      "step": 42
    },
    {
      "epoch": 0.0033416226297792975,
      "grad_norm": 0.25671514868736267,
      "learning_rate": 9.983291886851104e-06,
      "loss": 0.3008,
      "step": 43
    },
    {
      "epoch": 0.0034193347839602114,
      "grad_norm": 0.12696926295757294,
      "learning_rate": 9.9829033260802e-06,
      "loss": 0.1424,
      "step": 44
    },
    {
      "epoch": 0.0034970469381411253,
      "grad_norm": 0.2907988727092743,
      "learning_rate": 9.982514765309294e-06,
      "loss": 0.2406,
      "step": 45
    },
    {
      "epoch": 0.003574759092322039,
      "grad_norm": 0.20096401870250702,
      "learning_rate": 9.98212620453839e-06,
      "loss": 0.2074,
      "step": 46
    },
    {
      "epoch": 0.003652471246502953,
      "grad_norm": 0.10423679649829865,
      "learning_rate": 9.981737643767485e-06,
      "loss": 0.2222,
      "step": 47
    },
    {
      "epoch": 0.003730183400683867,
      "grad_norm": 0.23132027685642242,
      "learning_rate": 9.981349082996582e-06,
      "loss": 0.2007,
      "step": 48
    },
    {
      "epoch": 0.003807895554864781,
      "grad_norm": 0.14190995693206787,
      "learning_rate": 9.980960522225677e-06,
      "loss": 0.1281,
      "step": 49
    },
    {
      "epoch": 0.0038856077090456947,
      "grad_norm": 0.5333910584449768,
      "learning_rate": 9.980571961454772e-06,
      "loss": 0.2236,
      "step": 50
    },
    {
      "epoch": 0.003963319863226609,
      "grad_norm": 0.2027159184217453,
      "learning_rate": 9.980183400683869e-06,
      "loss": 0.4816,
      "step": 51
    },
    {
      "epoch": 0.004041032017407522,
      "grad_norm": 0.6409115791320801,
      "learning_rate": 9.979794839912964e-06,
      "loss": 0.2003,
      "step": 52
    },
    {
      "epoch": 0.004118744171588437,
      "grad_norm": 0.20566663146018982,
      "learning_rate": 9.979406279142059e-06,
      "loss": 0.1617,
      "step": 53
    },
    {
      "epoch": 0.00419645632576935,
      "grad_norm": 0.3986101746559143,
      "learning_rate": 9.979017718371155e-06,
      "loss": 0.3199,
      "step": 54
    },
    {
      "epoch": 0.0042741684799502645,
      "grad_norm": 0.1163100004196167,
      "learning_rate": 9.978629157600248e-06,
      "loss": 0.0952,
      "step": 55
    },
    {
      "epoch": 0.004351880634131178,
      "grad_norm": 0.2420162409543991,
      "learning_rate": 9.978240596829345e-06,
      "loss": 0.3276,
      "step": 56
    },
    {
      "epoch": 0.004429592788312092,
      "grad_norm": 0.2128966748714447,
      "learning_rate": 9.97785203605844e-06,
      "loss": 0.2183,
      "step": 57
    },
    {
      "epoch": 0.004507304942493006,
      "grad_norm": 0.24627093970775604,
      "learning_rate": 9.977463475287535e-06,
      "loss": 0.1414,
      "step": 58
    },
    {
      "epoch": 0.00458501709667392,
      "grad_norm": 0.3853744566440582,
      "learning_rate": 9.977074914516632e-06,
      "loss": 0.1361,
      "step": 59
    },
    {
      "epoch": 0.0046627292508548334,
      "grad_norm": 0.23129308223724365,
      "learning_rate": 9.976686353745727e-06,
      "loss": 0.0708,
      "step": 60
    },
    {
      "epoch": 0.004740441405035748,
      "grad_norm": 0.1495751440525055,
      "learning_rate": 9.976297792974822e-06,
      "loss": 0.1417,
      "step": 61
    },
    {
      "epoch": 0.004818153559216661,
      "grad_norm": 0.3315111994743347,
      "learning_rate": 9.975909232203918e-06,
      "loss": 0.9985,
      "step": 62
    },
    {
      "epoch": 0.0048958657133975755,
      "grad_norm": 0.13987670838832855,
      "learning_rate": 9.975520671433013e-06,
      "loss": 0.1298,
      "step": 63
    },
    {
      "epoch": 0.004973577867578489,
      "grad_norm": 0.35686370730400085,
      "learning_rate": 9.975132110662108e-06,
      "loss": 0.2298,
      "step": 64
    },
    {
      "epoch": 0.005051290021759403,
      "grad_norm": 0.2735859751701355,
      "learning_rate": 9.974743549891203e-06,
      "loss": 0.5272,
      "step": 65
    },
    {
      "epoch": 0.005129002175940317,
      "grad_norm": 0.11351852118968964,
      "learning_rate": 9.9743549891203e-06,
      "loss": 0.6039,
      "step": 66
    },
    {
      "epoch": 0.005206714330121231,
      "grad_norm": 0.4113835394382477,
      "learning_rate": 9.973966428349395e-06,
      "loss": 0.1962,
      "step": 67
    },
    {
      "epoch": 0.0052844264843021444,
      "grad_norm": 0.16180764138698578,
      "learning_rate": 9.97357786757849e-06,
      "loss": 0.1375,
      "step": 68
    },
    {
      "epoch": 0.005362138638483059,
      "grad_norm": 0.19228442013263702,
      "learning_rate": 9.973189306807586e-06,
      "loss": 0.1749,
      "step": 69
    },
    {
      "epoch": 0.005439850792663973,
      "grad_norm": 0.796389102935791,
      "learning_rate": 9.972800746036681e-06,
      "loss": 0.2795,
      "step": 70
    },
    {
      "epoch": 0.0055175629468448865,
      "grad_norm": 0.36275550723075867,
      "learning_rate": 9.972412185265776e-06,
      "loss": 0.576,
      "step": 71
    },
    {
      "epoch": 0.005595275101025801,
      "grad_norm": 0.7070936560630798,
      "learning_rate": 9.972023624494873e-06,
      "loss": 0.3298,
      "step": 72
    },
    {
      "epoch": 0.005672987255206714,
      "grad_norm": 0.24289831519126892,
      "learning_rate": 9.971635063723966e-06,
      "loss": 0.2693,
      "step": 73
    },
    {
      "epoch": 0.005750699409387629,
      "grad_norm": 0.1891765594482422,
      "learning_rate": 9.971246502953063e-06,
      "loss": 0.1638,
      "step": 74
    },
    {
      "epoch": 0.005828411563568542,
      "grad_norm": 0.5269400477409363,
      "learning_rate": 9.970857942182158e-06,
      "loss": 0.3671,
      "step": 75
    },
    {
      "epoch": 0.005906123717749456,
      "grad_norm": 0.1401059776544571,
      "learning_rate": 9.970469381411254e-06,
      "loss": 0.1112,
      "step": 76
    },
    {
      "epoch": 0.00598383587193037,
      "grad_norm": 0.15754334628582,
      "learning_rate": 9.97008082064035e-06,
      "loss": 0.2379,
      "step": 77
    },
    {
      "epoch": 0.006061548026111284,
      "grad_norm": 0.1553478091955185,
      "learning_rate": 9.969692259869444e-06,
      "loss": 0.2096,
      "step": 78
    },
    {
      "epoch": 0.0061392601802921975,
      "grad_norm": 0.06258516013622284,
      "learning_rate": 9.96930369909854e-06,
      "loss": 0.0886,
      "step": 79
    },
    {
      "epoch": 0.006216972334473112,
      "grad_norm": 0.27510392665863037,
      "learning_rate": 9.968915138327636e-06,
      "loss": 0.28,
      "step": 80
    },
    {
      "epoch": 0.006294684488654025,
      "grad_norm": 0.06469372659921646,
      "learning_rate": 9.96852657755673e-06,
      "loss": 0.0744,
      "step": 81
    },
    {
      "epoch": 0.00637239664283494,
      "grad_norm": 0.2643513083457947,
      "learning_rate": 9.968138016785827e-06,
      "loss": 0.191,
      "step": 82
    },
    {
      "epoch": 0.006450108797015853,
      "grad_norm": 0.18779246509075165,
      "learning_rate": 9.96774945601492e-06,
      "loss": 0.0843,
      "step": 83
    },
    {
      "epoch": 0.006527820951196767,
      "grad_norm": 0.14481042325496674,
      "learning_rate": 9.967360895244017e-06,
      "loss": 0.2754,
      "step": 84
    },
    {
      "epoch": 0.006605533105377681,
      "grad_norm": 0.1665925532579422,
      "learning_rate": 9.966972334473112e-06,
      "loss": 0.1849,
      "step": 85
    },
    {
      "epoch": 0.006683245259558595,
      "grad_norm": 0.3156093657016754,
      "learning_rate": 9.966583773702207e-06,
      "loss": 0.1523,
      "step": 86
    },
    {
      "epoch": 0.0067609574137395085,
      "grad_norm": 0.22181257605552673,
      "learning_rate": 9.966195212931304e-06,
      "loss": 0.1741,
      "step": 87
    },
    {
      "epoch": 0.006838669567920423,
      "grad_norm": 0.21658410131931305,
      "learning_rate": 9.965806652160399e-06,
      "loss": 0.2654,
      "step": 88
    },
    {
      "epoch": 0.006916381722101336,
      "grad_norm": 0.2346242368221283,
      "learning_rate": 9.965418091389494e-06,
      "loss": 0.0973,
      "step": 89
    },
    {
      "epoch": 0.006994093876282251,
      "grad_norm": 0.1793724149465561,
      "learning_rate": 9.96502953061859e-06,
      "loss": 0.0803,
      "step": 90
    },
    {
      "epoch": 0.007071806030463164,
      "grad_norm": 0.33894068002700806,
      "learning_rate": 9.964640969847685e-06,
      "loss": 0.8159,
      "step": 91
    },
    {
      "epoch": 0.007149518184644078,
      "grad_norm": 0.1899886429309845,
      "learning_rate": 9.96425240907678e-06,
      "loss": 0.167,
      "step": 92
    },
    {
      "epoch": 0.007227230338824993,
      "grad_norm": 0.31844180822372437,
      "learning_rate": 9.963863848305875e-06,
      "loss": 0.5923,
      "step": 93
    },
    {
      "epoch": 0.007304942493005906,
      "grad_norm": 0.13174575567245483,
      "learning_rate": 9.963475287534972e-06,
      "loss": 0.1046,
      "step": 94
    },
    {
      "epoch": 0.00738265464718682,
      "grad_norm": 0.10706369578838348,
      "learning_rate": 9.963086726764067e-06,
      "loss": 0.4925,
      "step": 95
    },
    {
      "epoch": 0.007460366801367734,
      "grad_norm": 0.49256831407546997,
      "learning_rate": 9.962698165993162e-06,
      "loss": 0.6524,
      "step": 96
    },
    {
      "epoch": 0.007538078955548648,
      "grad_norm": 0.2382735162973404,
      "learning_rate": 9.962309605222258e-06,
      "loss": 0.0704,
      "step": 97
    },
    {
      "epoch": 0.007615791109729562,
      "grad_norm": 0.2922145426273346,
      "learning_rate": 9.961921044451353e-06,
      "loss": 0.0827,
      "step": 98
    },
    {
      "epoch": 0.007693503263910476,
      "grad_norm": 0.061951130628585815,
      "learning_rate": 9.961532483680448e-06,
      "loss": 0.0562,
      "step": 99
    },
    {
      "epoch": 0.007771215418091389,
      "grad_norm": 0.0987272560596466,
      "learning_rate": 9.961143922909545e-06,
      "loss": 0.1628,
      "step": 100
    },
    {
      "epoch": 0.007848927572272303,
      "grad_norm": 0.2316354364156723,
      "learning_rate": 9.960755362138638e-06,
      "loss": 0.1692,
      "step": 101
    },
    {
      "epoch": 0.007926639726453218,
      "grad_norm": 0.3707481622695923,
      "learning_rate": 9.960366801367735e-06,
      "loss": 0.4203,
      "step": 102
    },
    {
      "epoch": 0.008004351880634131,
      "grad_norm": 0.3134300410747528,
      "learning_rate": 9.95997824059683e-06,
      "loss": 0.1154,
      "step": 103
    },
    {
      "epoch": 0.008082064034815045,
      "grad_norm": 0.1780293732881546,
      "learning_rate": 9.959589679825925e-06,
      "loss": 0.1118,
      "step": 104
    },
    {
      "epoch": 0.008159776188995958,
      "grad_norm": 0.037882354110479355,
      "learning_rate": 9.959201119055021e-06,
      "loss": 0.0227,
      "step": 105
    },
    {
      "epoch": 0.008237488343176873,
      "grad_norm": 0.2163611799478531,
      "learning_rate": 9.958812558284116e-06,
      "loss": 0.2982,
      "step": 106
    },
    {
      "epoch": 0.008315200497357787,
      "grad_norm": 0.07366267591714859,
      "learning_rate": 9.958423997513213e-06,
      "loss": 0.0248,
      "step": 107
    },
    {
      "epoch": 0.0083929126515387,
      "grad_norm": 0.07087940722703934,
      "learning_rate": 9.958035436742308e-06,
      "loss": 0.0857,
      "step": 108
    },
    {
      "epoch": 0.008470624805719614,
      "grad_norm": 0.539107620716095,
      "learning_rate": 9.957646875971403e-06,
      "loss": 0.2839,
      "step": 109
    },
    {
      "epoch": 0.008548336959900529,
      "grad_norm": 0.4316738545894623,
      "learning_rate": 9.9572583152005e-06,
      "loss": 0.3485,
      "step": 110
    },
    {
      "epoch": 0.008626049114081442,
      "grad_norm": 0.24422091245651245,
      "learning_rate": 9.956869754429593e-06,
      "loss": 0.1046,
      "step": 111
    },
    {
      "epoch": 0.008703761268262356,
      "grad_norm": 0.10206308960914612,
      "learning_rate": 9.95648119365869e-06,
      "loss": 0.1584,
      "step": 112
    },
    {
      "epoch": 0.00878147342244327,
      "grad_norm": 0.15456874668598175,
      "learning_rate": 9.956092632887784e-06,
      "loss": 0.0378,
      "step": 113
    },
    {
      "epoch": 0.008859185576624184,
      "grad_norm": 0.31253865361213684,
      "learning_rate": 9.95570407211688e-06,
      "loss": 0.5667,
      "step": 114
    },
    {
      "epoch": 0.008936897730805098,
      "grad_norm": 0.36124733090400696,
      "learning_rate": 9.955315511345976e-06,
      "loss": 0.1328,
      "step": 115
    },
    {
      "epoch": 0.009014609884986011,
      "grad_norm": 0.1404377669095993,
      "learning_rate": 9.954926950575071e-06,
      "loss": 0.1252,
      "step": 116
    },
    {
      "epoch": 0.009092322039166927,
      "grad_norm": 0.38761967420578003,
      "learning_rate": 9.954538389804166e-06,
      "loss": 0.2475,
      "step": 117
    },
    {
      "epoch": 0.00917003419334784,
      "grad_norm": 0.2814584970474243,
      "learning_rate": 9.954149829033262e-06,
      "loss": 0.6613,
      "step": 118
    },
    {
      "epoch": 0.009247746347528753,
      "grad_norm": 0.2122446447610855,
      "learning_rate": 9.953761268262357e-06,
      "loss": 0.1906,
      "step": 119
    },
    {
      "epoch": 0.009325458501709667,
      "grad_norm": 0.2147643268108368,
      "learning_rate": 9.953372707491452e-06,
      "loss": 0.2917,
      "step": 120
    },
    {
      "epoch": 0.009403170655890582,
      "grad_norm": 0.18167322874069214,
      "learning_rate": 9.952984146720547e-06,
      "loss": 0.5371,
      "step": 121
    },
    {
      "epoch": 0.009480882810071495,
      "grad_norm": 0.23760230839252472,
      "learning_rate": 9.952595585949644e-06,
      "loss": 0.0634,
      "step": 122
    },
    {
      "epoch": 0.009558594964252409,
      "grad_norm": 0.3763054609298706,
      "learning_rate": 9.952207025178739e-06,
      "loss": 0.1625,
      "step": 123
    },
    {
      "epoch": 0.009636307118433322,
      "grad_norm": 0.1712132692337036,
      "learning_rate": 9.951818464407834e-06,
      "loss": 0.1834,
      "step": 124
    },
    {
      "epoch": 0.009714019272614238,
      "grad_norm": 0.12803247570991516,
      "learning_rate": 9.95142990363693e-06,
      "loss": 0.0621,
      "step": 125
    },
    {
      "epoch": 0.009791731426795151,
      "grad_norm": 0.2119101732969284,
      "learning_rate": 9.951041342866025e-06,
      "loss": 0.1277,
      "step": 126
    },
    {
      "epoch": 0.009869443580976064,
      "grad_norm": 0.3349386751651764,
      "learning_rate": 9.95065278209512e-06,
      "loss": 0.0537,
      "step": 127
    },
    {
      "epoch": 0.009947155735156978,
      "grad_norm": 0.1582932025194168,
      "learning_rate": 9.950264221324215e-06,
      "loss": 0.0688,
      "step": 128
    },
    {
      "epoch": 0.010024867889337893,
      "grad_norm": 0.3608787953853607,
      "learning_rate": 9.94987566055331e-06,
      "loss": 0.1729,
      "step": 129
    },
    {
      "epoch": 0.010102580043518807,
      "grad_norm": 0.1300254911184311,
      "learning_rate": 9.949487099782407e-06,
      "loss": 0.1276,
      "step": 130
    },
    {
      "epoch": 0.01018029219769972,
      "grad_norm": 0.1649625599384308,
      "learning_rate": 9.949098539011502e-06,
      "loss": 0.2018,
      "step": 131
    },
    {
      "epoch": 0.010258004351880633,
      "grad_norm": 0.20219741761684418,
      "learning_rate": 9.948709978240597e-06,
      "loss": 0.0758,
      "step": 132
    },
    {
      "epoch": 0.010335716506061549,
      "grad_norm": 0.14809131622314453,
      "learning_rate": 9.948321417469694e-06,
      "loss": 0.2576,
      "step": 133
    },
    {
      "epoch": 0.010413428660242462,
      "grad_norm": 0.4219307601451874,
      "learning_rate": 9.947932856698788e-06,
      "loss": 0.2127,
      "step": 134
    },
    {
      "epoch": 0.010491140814423375,
      "grad_norm": 0.04863402247428894,
      "learning_rate": 9.947544295927883e-06,
      "loss": 0.0127,
      "step": 135
    },
    {
      "epoch": 0.010568852968604289,
      "grad_norm": 0.34839653968811035,
      "learning_rate": 9.947155735156978e-06,
      "loss": 0.7482,
      "step": 136
    },
    {
      "epoch": 0.010646565122785204,
      "grad_norm": 0.16495570540428162,
      "learning_rate": 9.946767174386075e-06,
      "loss": 0.1247,
      "step": 137
    },
    {
      "epoch": 0.010724277276966118,
      "grad_norm": 0.09726385027170181,
      "learning_rate": 9.94637861361517e-06,
      "loss": 0.0678,
      "step": 138
    },
    {
      "epoch": 0.010801989431147031,
      "grad_norm": 0.1494305580854416,
      "learning_rate": 9.945990052844265e-06,
      "loss": 0.0817,
      "step": 139
    },
    {
      "epoch": 0.010879701585327946,
      "grad_norm": 0.17016181349754333,
      "learning_rate": 9.945601492073362e-06,
      "loss": 0.4076,
      "step": 140
    },
    {
      "epoch": 0.01095741373950886,
      "grad_norm": 0.14625443518161774,
      "learning_rate": 9.945212931302456e-06,
      "loss": 0.0425,
      "step": 141
    },
    {
      "epoch": 0.011035125893689773,
      "grad_norm": 0.26823872327804565,
      "learning_rate": 9.944824370531551e-06,
      "loss": 0.1993,
      "step": 142
    },
    {
      "epoch": 0.011112838047870686,
      "grad_norm": 0.20134001970291138,
      "learning_rate": 9.944435809760648e-06,
      "loss": 0.1391,
      "step": 143
    },
    {
      "epoch": 0.011190550202051602,
      "grad_norm": 0.3892163634300232,
      "learning_rate": 9.944047248989743e-06,
      "loss": 0.2199,
      "step": 144
    },
    {
      "epoch": 0.011268262356232515,
      "grad_norm": 0.15642133355140686,
      "learning_rate": 9.943658688218838e-06,
      "loss": 0.2609,
      "step": 145
    },
    {
      "epoch": 0.011345974510413429,
      "grad_norm": 0.2898559868335724,
      "learning_rate": 9.943270127447933e-06,
      "loss": 0.2996,
      "step": 146
    },
    {
      "epoch": 0.011423686664594342,
      "grad_norm": 0.2734662592411041,
      "learning_rate": 9.94288156667703e-06,
      "loss": 0.0969,
      "step": 147
    },
    {
      "epoch": 0.011501398818775257,
      "grad_norm": 0.717184841632843,
      "learning_rate": 9.942493005906125e-06,
      "loss": 0.3103,
      "step": 148
    },
    {
      "epoch": 0.01157911097295617,
      "grad_norm": 0.04764099791646004,
      "learning_rate": 9.94210444513522e-06,
      "loss": 0.0165,
      "step": 149
    },
    {
      "epoch": 0.011656823127137084,
      "grad_norm": 0.3482997417449951,
      "learning_rate": 9.941715884364316e-06,
      "loss": 0.3999,
      "step": 150
    },
    {
      "epoch": 0.011734535281317997,
      "grad_norm": 0.2953164577484131,
      "learning_rate": 9.941327323593411e-06,
      "loss": 0.3796,
      "step": 151
    },
    {
      "epoch": 0.011812247435498913,
      "grad_norm": 0.30155038833618164,
      "learning_rate": 9.940938762822506e-06,
      "loss": 0.1199,
      "step": 152
    },
    {
      "epoch": 0.011889959589679826,
      "grad_norm": 0.292898565530777,
      "learning_rate": 9.940550202051603e-06,
      "loss": 0.5234,
      "step": 153
    },
    {
      "epoch": 0.01196767174386074,
      "grad_norm": 0.4905354678630829,
      "learning_rate": 9.940161641280696e-06,
      "loss": 0.1186,
      "step": 154
    },
    {
      "epoch": 0.012045383898041653,
      "grad_norm": 0.24770495295524597,
      "learning_rate": 9.939773080509793e-06,
      "loss": 0.2274,
      "step": 155
    },
    {
      "epoch": 0.012123096052222568,
      "grad_norm": 0.41571885347366333,
      "learning_rate": 9.939384519738888e-06,
      "loss": 2.2966,
      "step": 156
    },
    {
      "epoch": 0.012200808206403482,
      "grad_norm": 0.35041454434394836,
      "learning_rate": 9.938995958967982e-06,
      "loss": 0.655,
      "step": 157
    },
    {
      "epoch": 0.012278520360584395,
      "grad_norm": 0.24149006605148315,
      "learning_rate": 9.938607398197079e-06,
      "loss": 0.1374,
      "step": 158
    },
    {
      "epoch": 0.012356232514765308,
      "grad_norm": 0.12241432070732117,
      "learning_rate": 9.938218837426174e-06,
      "loss": 0.058,
      "step": 159
    },
    {
      "epoch": 0.012433944668946224,
      "grad_norm": 0.18433375656604767,
      "learning_rate": 9.937830276655269e-06,
      "loss": 0.2775,
      "step": 160
    },
    {
      "epoch": 0.012511656823127137,
      "grad_norm": 0.4147595465183258,
      "learning_rate": 9.937441715884366e-06,
      "loss": 0.156,
      "step": 161
    },
    {
      "epoch": 0.01258936897730805,
      "grad_norm": 0.31887778639793396,
      "learning_rate": 9.93705315511346e-06,
      "loss": 0.4364,
      "step": 162
    },
    {
      "epoch": 0.012667081131488966,
      "grad_norm": 0.1671028882265091,
      "learning_rate": 9.936664594342556e-06,
      "loss": 0.2509,
      "step": 163
    },
    {
      "epoch": 0.01274479328566988,
      "grad_norm": 0.4201398491859436,
      "learning_rate": 9.93627603357165e-06,
      "loss": 1.1257,
      "step": 164
    },
    {
      "epoch": 0.012822505439850793,
      "grad_norm": 0.2978348135948181,
      "learning_rate": 9.935887472800747e-06,
      "loss": 0.3494,
      "step": 165
    },
    {
      "epoch": 0.012900217594031706,
      "grad_norm": 0.5021065473556519,
      "learning_rate": 9.935498912029842e-06,
      "loss": 1.0938,
      "step": 166
    },
    {
      "epoch": 0.012977929748212621,
      "grad_norm": 0.08740897476673126,
      "learning_rate": 9.935110351258937e-06,
      "loss": 0.1234,
      "step": 167
    },
    {
      "epoch": 0.013055641902393535,
      "grad_norm": 0.1649065613746643,
      "learning_rate": 9.934721790488034e-06,
      "loss": 0.218,
      "step": 168
    },
    {
      "epoch": 0.013133354056574448,
      "grad_norm": 0.08079051226377487,
      "learning_rate": 9.934333229717129e-06,
      "loss": 0.152,
      "step": 169
    },
    {
      "epoch": 0.013211066210755362,
      "grad_norm": 0.1733066588640213,
      "learning_rate": 9.933944668946224e-06,
      "loss": 0.2592,
      "step": 170
    },
    {
      "epoch": 0.013288778364936277,
      "grad_norm": 0.15295599400997162,
      "learning_rate": 9.93355610817532e-06,
      "loss": 0.1978,
      "step": 171
    },
    {
      "epoch": 0.01336649051911719,
      "grad_norm": 0.18794061243534088,
      "learning_rate": 9.933167547404415e-06,
      "loss": 0.3049,
      "step": 172
    },
    {
      "epoch": 0.013444202673298104,
      "grad_norm": 0.13916601240634918,
      "learning_rate": 9.93277898663351e-06,
      "loss": 0.1264,
      "step": 173
    },
    {
      "epoch": 0.013521914827479017,
      "grad_norm": 0.036224424839019775,
      "learning_rate": 9.932390425862605e-06,
      "loss": 0.0364,
      "step": 174
    },
    {
      "epoch": 0.013599626981659932,
      "grad_norm": 0.27834779024124146,
      "learning_rate": 9.932001865091702e-06,
      "loss": 0.6162,
      "step": 175
    },
    {
      "epoch": 0.013677339135840846,
      "grad_norm": 0.3532849848270416,
      "learning_rate": 9.931613304320797e-06,
      "loss": 0.0828,
      "step": 176
    },
    {
      "epoch": 0.013755051290021759,
      "grad_norm": 0.2945534288883209,
      "learning_rate": 9.931224743549892e-06,
      "loss": 0.205,
      "step": 177
    },
    {
      "epoch": 0.013832763444202673,
      "grad_norm": 1.7843886613845825,
      "learning_rate": 9.930836182778988e-06,
      "loss": 2.8671,
      "step": 178
    },
    {
      "epoch": 0.013910475598383588,
      "grad_norm": 0.15604525804519653,
      "learning_rate": 9.930447622008083e-06,
      "loss": 0.044,
      "step": 179
    },
    {
      "epoch": 0.013988187752564501,
      "grad_norm": 0.15461041033267975,
      "learning_rate": 9.930059061237178e-06,
      "loss": 0.1479,
      "step": 180
    },
    {
      "epoch": 0.014065899906745415,
      "grad_norm": 0.08829308301210403,
      "learning_rate": 9.929670500466275e-06,
      "loss": 0.1029,
      "step": 181
    },
    {
      "epoch": 0.014143612060926328,
      "grad_norm": 0.13407251238822937,
      "learning_rate": 9.929281939695368e-06,
      "loss": 0.3879,
      "step": 182
    },
    {
      "epoch": 0.014221324215107243,
      "grad_norm": 0.11907169222831726,
      "learning_rate": 9.928893378924465e-06,
      "loss": 0.1138,
      "step": 183
    },
    {
      "epoch": 0.014299036369288157,
      "grad_norm": 0.13159556686878204,
      "learning_rate": 9.92850481815356e-06,
      "loss": 0.1013,
      "step": 184
    },
    {
      "epoch": 0.01437674852346907,
      "grad_norm": 0.2359185516834259,
      "learning_rate": 9.928116257382655e-06,
      "loss": 0.1416,
      "step": 185
    },
    {
      "epoch": 0.014454460677649985,
      "grad_norm": 0.3312108516693115,
      "learning_rate": 9.927727696611751e-06,
      "loss": 0.3908,
      "step": 186
    },
    {
      "epoch": 0.014532172831830899,
      "grad_norm": 0.26972436904907227,
      "learning_rate": 9.927339135840846e-06,
      "loss": 0.443,
      "step": 187
    },
    {
      "epoch": 0.014609884986011812,
      "grad_norm": 0.9766281843185425,
      "learning_rate": 9.926950575069941e-06,
      "loss": 0.4782,
      "step": 188
    },
    {
      "epoch": 0.014687597140192726,
      "grad_norm": 0.1432487964630127,
      "learning_rate": 9.926562014299038e-06,
      "loss": 0.1231,
      "step": 189
    },
    {
      "epoch": 0.01476530929437364,
      "grad_norm": 0.08772391080856323,
      "learning_rate": 9.926173453528133e-06,
      "loss": 0.0271,
      "step": 190
    },
    {
      "epoch": 0.014843021448554554,
      "grad_norm": 0.49169987440109253,
      "learning_rate": 9.925784892757228e-06,
      "loss": 0.3053,
      "step": 191
    },
    {
      "epoch": 0.014920733602735468,
      "grad_norm": 0.12663911283016205,
      "learning_rate": 9.925396331986323e-06,
      "loss": 0.1892,
      "step": 192
    },
    {
      "epoch": 0.014998445756916381,
      "grad_norm": 0.3877165913581848,
      "learning_rate": 9.92500777121542e-06,
      "loss": 0.3326,
      "step": 193
    },
    {
      "epoch": 0.015076157911097296,
      "grad_norm": 0.2465025931596756,
      "learning_rate": 9.924619210444514e-06,
      "loss": 0.2536,
      "step": 194
    },
    {
      "epoch": 0.01515387006527821,
      "grad_norm": 0.5437003374099731,
      "learning_rate": 9.92423064967361e-06,
      "loss": 0.3599,
      "step": 195
    },
    {
      "epoch": 0.015231582219459123,
      "grad_norm": 0.06047160178422928,
      "learning_rate": 9.923842088902706e-06,
      "loss": 0.0167,
      "step": 196
    },
    {
      "epoch": 0.015309294373640037,
      "grad_norm": 0.16327881813049316,
      "learning_rate": 9.9234535281318e-06,
      "loss": 0.3093,
      "step": 197
    },
    {
      "epoch": 0.015387006527820952,
      "grad_norm": 0.3733786642551422,
      "learning_rate": 9.923064967360896e-06,
      "loss": 0.1743,
      "step": 198
    },
    {
      "epoch": 0.015464718682001865,
      "grad_norm": 0.08405598253011703,
      "learning_rate": 9.922676406589992e-06,
      "loss": 0.0535,
      "step": 199
    },
    {
      "epoch": 0.015542430836182779,
      "grad_norm": 0.09016449004411697,
      "learning_rate": 9.922287845819087e-06,
      "loss": 0.0321,
      "step": 200
    },
    {
      "epoch": 0.015620142990363692,
      "grad_norm": 0.2709532380104065,
      "learning_rate": 9.921899285048182e-06,
      "loss": 1.0543,
      "step": 201
    },
    {
      "epoch": 0.015697855144544606,
      "grad_norm": 0.5631552934646606,
      "learning_rate": 9.921510724277277e-06,
      "loss": 0.3926,
      "step": 202
    },
    {
      "epoch": 0.01577556729872552,
      "grad_norm": 0.1598658263683319,
      "learning_rate": 9.921122163506374e-06,
      "loss": 0.1687,
      "step": 203
    },
    {
      "epoch": 0.015853279452906436,
      "grad_norm": 0.10474331676959991,
      "learning_rate": 9.920733602735469e-06,
      "loss": 0.1154,
      "step": 204
    },
    {
      "epoch": 0.015930991607087348,
      "grad_norm": 0.26824814081192017,
      "learning_rate": 9.920345041964564e-06,
      "loss": 0.0533,
      "step": 205
    },
    {
      "epoch": 0.016008703761268263,
      "grad_norm": 0.26556167006492615,
      "learning_rate": 9.91995648119366e-06,
      "loss": 0.3633,
      "step": 206
    },
    {
      "epoch": 0.016086415915449175,
      "grad_norm": 0.09285826981067657,
      "learning_rate": 9.919567920422755e-06,
      "loss": 0.199,
      "step": 207
    },
    {
      "epoch": 0.01616412806963009,
      "grad_norm": 0.14042501151561737,
      "learning_rate": 9.91917935965185e-06,
      "loss": 0.0617,
      "step": 208
    },
    {
      "epoch": 0.016241840223811005,
      "grad_norm": 0.30923888087272644,
      "learning_rate": 9.918790798880947e-06,
      "loss": 0.1069,
      "step": 209
    },
    {
      "epoch": 0.016319552377991917,
      "grad_norm": 0.16674838960170746,
      "learning_rate": 9.91840223811004e-06,
      "loss": 0.0464,
      "step": 210
    },
    {
      "epoch": 0.016397264532172832,
      "grad_norm": 0.06155933439731598,
      "learning_rate": 9.918013677339137e-06,
      "loss": 0.0312,
      "step": 211
    },
    {
      "epoch": 0.016474976686353747,
      "grad_norm": 0.3148004114627838,
      "learning_rate": 9.917625116568232e-06,
      "loss": 0.328,
      "step": 212
    },
    {
      "epoch": 0.01655268884053466,
      "grad_norm": 0.35077130794525146,
      "learning_rate": 9.917236555797327e-06,
      "loss": 0.2605,
      "step": 213
    },
    {
      "epoch": 0.016630400994715574,
      "grad_norm": 0.29849156737327576,
      "learning_rate": 9.916847995026423e-06,
      "loss": 0.2272,
      "step": 214
    },
    {
      "epoch": 0.01670811314889649,
      "grad_norm": 0.06077186390757561,
      "learning_rate": 9.916459434255518e-06,
      "loss": 0.0537,
      "step": 215
    },
    {
      "epoch": 0.0167858253030774,
      "grad_norm": 0.15024901926517487,
      "learning_rate": 9.916070873484613e-06,
      "loss": 0.0689,
      "step": 216
    },
    {
      "epoch": 0.016863537457258316,
      "grad_norm": 0.3326651155948639,
      "learning_rate": 9.91568231271371e-06,
      "loss": 0.3974,
      "step": 217
    },
    {
      "epoch": 0.016941249611439228,
      "grad_norm": 0.1285664141178131,
      "learning_rate": 9.915293751942805e-06,
      "loss": 0.1315,
      "step": 218
    },
    {
      "epoch": 0.017018961765620143,
      "grad_norm": 0.1416897177696228,
      "learning_rate": 9.9149051911719e-06,
      "loss": 0.1084,
      "step": 219
    },
    {
      "epoch": 0.017096673919801058,
      "grad_norm": 0.10914652794599533,
      "learning_rate": 9.914516630400995e-06,
      "loss": 0.0384,
      "step": 220
    },
    {
      "epoch": 0.01717438607398197,
      "grad_norm": 0.27947115898132324,
      "learning_rate": 9.914128069630091e-06,
      "loss": 0.2093,
      "step": 221
    },
    {
      "epoch": 0.017252098228162885,
      "grad_norm": 0.12340757250785828,
      "learning_rate": 9.913739508859186e-06,
      "loss": 0.1319,
      "step": 222
    },
    {
      "epoch": 0.0173298103823438,
      "grad_norm": 0.5091403126716614,
      "learning_rate": 9.913350948088281e-06,
      "loss": 0.1565,
      "step": 223
    },
    {
      "epoch": 0.017407522536524712,
      "grad_norm": 0.3925435543060303,
      "learning_rate": 9.912962387317378e-06,
      "loss": 0.1428,
      "step": 224
    },
    {
      "epoch": 0.017485234690705627,
      "grad_norm": 0.12126293033361435,
      "learning_rate": 9.912573826546473e-06,
      "loss": 0.0566,
      "step": 225
    },
    {
      "epoch": 0.01756294684488654,
      "grad_norm": 0.6660026907920837,
      "learning_rate": 9.912185265775568e-06,
      "loss": 0.6491,
      "step": 226
    },
    {
      "epoch": 0.017640658999067454,
      "grad_norm": 0.43673527240753174,
      "learning_rate": 9.911796705004665e-06,
      "loss": 0.2641,
      "step": 227
    },
    {
      "epoch": 0.01771837115324837,
      "grad_norm": 0.1108812466263771,
      "learning_rate": 9.91140814423376e-06,
      "loss": 0.1154,
      "step": 228
    },
    {
      "epoch": 0.01779608330742928,
      "grad_norm": 0.35961204767227173,
      "learning_rate": 9.911019583462854e-06,
      "loss": 0.2976,
      "step": 229
    },
    {
      "epoch": 0.017873795461610196,
      "grad_norm": 0.4029097855091095,
      "learning_rate": 9.91063102269195e-06,
      "loss": 0.4064,
      "step": 230
    },
    {
      "epoch": 0.01795150761579111,
      "grad_norm": 1.2528407573699951,
      "learning_rate": 9.910242461921046e-06,
      "loss": 0.9929,
      "step": 231
    },
    {
      "epoch": 0.018029219769972023,
      "grad_norm": 0.32425349950790405,
      "learning_rate": 9.909853901150141e-06,
      "loss": 0.2683,
      "step": 232
    },
    {
      "epoch": 0.018106931924152938,
      "grad_norm": 0.2692769467830658,
      "learning_rate": 9.909465340379236e-06,
      "loss": 0.1689,
      "step": 233
    },
    {
      "epoch": 0.018184644078333853,
      "grad_norm": 0.4518708884716034,
      "learning_rate": 9.909076779608333e-06,
      "loss": 0.5729,
      "step": 234
    },
    {
      "epoch": 0.018262356232514765,
      "grad_norm": 0.38452449440956116,
      "learning_rate": 9.908688218837428e-06,
      "loss": 0.4439,
      "step": 235
    },
    {
      "epoch": 0.01834006838669568,
      "grad_norm": 0.26162105798721313,
      "learning_rate": 9.908299658066522e-06,
      "loss": 0.2706,
      "step": 236
    },
    {
      "epoch": 0.01841778054087659,
      "grad_norm": 0.37246260046958923,
      "learning_rate": 9.907911097295619e-06,
      "loss": 0.695,
      "step": 237
    },
    {
      "epoch": 0.018495492695057507,
      "grad_norm": 0.24531146883964539,
      "learning_rate": 9.907522536524712e-06,
      "loss": 0.298,
      "step": 238
    },
    {
      "epoch": 0.018573204849238422,
      "grad_norm": 0.11610741168260574,
      "learning_rate": 9.907133975753809e-06,
      "loss": 0.2179,
      "step": 239
    },
    {
      "epoch": 0.018650917003419334,
      "grad_norm": 0.1055741235613823,
      "learning_rate": 9.906745414982904e-06,
      "loss": 0.1609,
      "step": 240
    },
    {
      "epoch": 0.01872862915760025,
      "grad_norm": 0.42476382851600647,
      "learning_rate": 9.906356854211999e-06,
      "loss": 0.1262,
      "step": 241
    },
    {
      "epoch": 0.018806341311781164,
      "grad_norm": 0.1913059800863266,
      "learning_rate": 9.905968293441096e-06,
      "loss": 0.2121,
      "step": 242
    },
    {
      "epoch": 0.018884053465962076,
      "grad_norm": 0.3748663365840912,
      "learning_rate": 9.90557973267019e-06,
      "loss": 0.8987,
      "step": 243
    },
    {
      "epoch": 0.01896176562014299,
      "grad_norm": 0.1757555603981018,
      "learning_rate": 9.905191171899285e-06,
      "loss": 0.0934,
      "step": 244
    },
    {
      "epoch": 0.019039477774323903,
      "grad_norm": 0.178755983710289,
      "learning_rate": 9.904802611128382e-06,
      "loss": 0.3238,
      "step": 245
    },
    {
      "epoch": 0.019117189928504818,
      "grad_norm": 0.11681023985147476,
      "learning_rate": 9.904414050357477e-06,
      "loss": 0.0388,
      "step": 246
    },
    {
      "epoch": 0.019194902082685733,
      "grad_norm": 0.058958180248737335,
      "learning_rate": 9.904025489586572e-06,
      "loss": 0.0963,
      "step": 247
    },
    {
      "epoch": 0.019272614236866645,
      "grad_norm": 0.10382818430662155,
      "learning_rate": 9.903636928815667e-06,
      "loss": 0.1159,
      "step": 248
    },
    {
      "epoch": 0.01935032639104756,
      "grad_norm": 0.21755842864513397,
      "learning_rate": 9.903248368044764e-06,
      "loss": 0.1868,
      "step": 249
    },
    {
      "epoch": 0.019428038545228475,
      "grad_norm": 0.346849262714386,
      "learning_rate": 9.902859807273859e-06,
      "loss": 0.3923,
      "step": 250
    },
    {
      "epoch": 0.019505750699409387,
      "grad_norm": 0.1078554019331932,
      "learning_rate": 9.902471246502953e-06,
      "loss": 0.0427,
      "step": 251
    },
    {
      "epoch": 0.019583462853590302,
      "grad_norm": 0.1334024965763092,
      "learning_rate": 9.90208268573205e-06,
      "loss": 0.0492,
      "step": 252
    },
    {
      "epoch": 0.019661175007771214,
      "grad_norm": 0.14518806338310242,
      "learning_rate": 9.901694124961145e-06,
      "loss": 0.0801,
      "step": 253
    },
    {
      "epoch": 0.01973888716195213,
      "grad_norm": 0.14130237698554993,
      "learning_rate": 9.90130556419024e-06,
      "loss": 0.1827,
      "step": 254
    },
    {
      "epoch": 0.019816599316133044,
      "grad_norm": 0.38231950998306274,
      "learning_rate": 9.900917003419335e-06,
      "loss": 0.0383,
      "step": 255
    },
    {
      "epoch": 0.019894311470313956,
      "grad_norm": 0.46643340587615967,
      "learning_rate": 9.90052844264843e-06,
      "loss": 0.5865,
      "step": 256
    },
    {
      "epoch": 0.01997202362449487,
      "grad_norm": 0.2914884090423584,
      "learning_rate": 9.900139881877527e-06,
      "loss": 0.3414,
      "step": 257
    },
    {
      "epoch": 0.020049735778675786,
      "grad_norm": 0.04671332985162735,
      "learning_rate": 9.899751321106622e-06,
      "loss": 0.0245,
      "step": 258
    },
    {
      "epoch": 0.020127447932856698,
      "grad_norm": 0.1251996010541916,
      "learning_rate": 9.899362760335718e-06,
      "loss": 0.1089,
      "step": 259
    },
    {
      "epoch": 0.020205160087037613,
      "grad_norm": 0.17455002665519714,
      "learning_rate": 9.898974199564813e-06,
      "loss": 0.0779,
      "step": 260
    },
    {
      "epoch": 0.020282872241218528,
      "grad_norm": 0.11576198041439056,
      "learning_rate": 9.898585638793908e-06,
      "loss": 0.0888,
      "step": 261
    },
    {
      "epoch": 0.02036058439539944,
      "grad_norm": 0.23304277658462524,
      "learning_rate": 9.898197078023005e-06,
      "loss": 0.2523,
      "step": 262
    },
    {
      "epoch": 0.020438296549580355,
      "grad_norm": 0.22530598938465118,
      "learning_rate": 9.897808517252098e-06,
      "loss": 0.1036,
      "step": 263
    },
    {
      "epoch": 0.020516008703761267,
      "grad_norm": 0.19606967270374298,
      "learning_rate": 9.897419956481195e-06,
      "loss": 0.3216,
      "step": 264
    },
    {
      "epoch": 0.020593720857942182,
      "grad_norm": 0.18931609392166138,
      "learning_rate": 9.89703139571029e-06,
      "loss": 0.2259,
      "step": 265
    },
    {
      "epoch": 0.020671433012123097,
      "grad_norm": 0.2104988694190979,
      "learning_rate": 9.896642834939385e-06,
      "loss": 0.0555,
      "step": 266
    },
    {
      "epoch": 0.02074914516630401,
      "grad_norm": 0.20686067640781403,
      "learning_rate": 9.896254274168481e-06,
      "loss": 0.2217,
      "step": 267
    },
    {
      "epoch": 0.020826857320484924,
      "grad_norm": 0.2468045949935913,
      "learning_rate": 9.895865713397576e-06,
      "loss": 0.239,
      "step": 268
    },
    {
      "epoch": 0.02090456947466584,
      "grad_norm": 0.17213159799575806,
      "learning_rate": 9.895477152626671e-06,
      "loss": 0.098,
      "step": 269
    },
    {
      "epoch": 0.02098228162884675,
      "grad_norm": 0.11861305683851242,
      "learning_rate": 9.895088591855768e-06,
      "loss": 0.1494,
      "step": 270
    },
    {
      "epoch": 0.021059993783027666,
      "grad_norm": 0.2006492167711258,
      "learning_rate": 9.894700031084863e-06,
      "loss": 0.2817,
      "step": 271
    },
    {
      "epoch": 0.021137705937208578,
      "grad_norm": 0.2657236158847809,
      "learning_rate": 9.894311470313958e-06,
      "loss": 0.6725,
      "step": 272
    },
    {
      "epoch": 0.021215418091389493,
      "grad_norm": 0.3923812806606293,
      "learning_rate": 9.893922909543053e-06,
      "loss": 0.3473,
      "step": 273
    },
    {
      "epoch": 0.021293130245570408,
      "grad_norm": 0.09700055420398712,
      "learning_rate": 9.89353434877215e-06,
      "loss": 0.1027,
      "step": 274
    },
    {
      "epoch": 0.02137084239975132,
      "grad_norm": 0.3101847469806671,
      "learning_rate": 9.893145788001244e-06,
      "loss": 0.4045,
      "step": 275
    },
    {
      "epoch": 0.021448554553932235,
      "grad_norm": 0.18236204981803894,
      "learning_rate": 9.892757227230339e-06,
      "loss": 0.154,
      "step": 276
    },
    {
      "epoch": 0.02152626670811315,
      "grad_norm": 0.06538596749305725,
      "learning_rate": 9.892368666459436e-06,
      "loss": 0.0763,
      "step": 277
    },
    {
      "epoch": 0.021603978862294062,
      "grad_norm": 0.1582062691450119,
      "learning_rate": 9.89198010568853e-06,
      "loss": 0.0902,
      "step": 278
    },
    {
      "epoch": 0.021681691016474977,
      "grad_norm": 0.38574185967445374,
      "learning_rate": 9.891591544917626e-06,
      "loss": 0.3874,
      "step": 279
    },
    {
      "epoch": 0.021759403170655892,
      "grad_norm": 0.3028804063796997,
      "learning_rate": 9.891202984146722e-06,
      "loss": 0.5979,
      "step": 280
    },
    {
      "epoch": 0.021837115324836804,
      "grad_norm": 0.09570923447608948,
      "learning_rate": 9.890814423375816e-06,
      "loss": 0.053,
      "step": 281
    },
    {
      "epoch": 0.02191482747901772,
      "grad_norm": 0.2106248289346695,
      "learning_rate": 9.890425862604912e-06,
      "loss": 0.1547,
      "step": 282
    },
    {
      "epoch": 0.02199253963319863,
      "grad_norm": 0.05703400820493698,
      "learning_rate": 9.890037301834007e-06,
      "loss": 0.0639,
      "step": 283
    },
    {
      "epoch": 0.022070251787379546,
      "grad_norm": 0.4601021111011505,
      "learning_rate": 9.889648741063102e-06,
      "loss": 0.3616,
      "step": 284
    },
    {
      "epoch": 0.02214796394156046,
      "grad_norm": 0.14631181955337524,
      "learning_rate": 9.889260180292199e-06,
      "loss": 0.4077,
      "step": 285
    },
    {
      "epoch": 0.022225676095741373,
      "grad_norm": 0.11446675658226013,
      "learning_rate": 9.888871619521294e-06,
      "loss": 0.1727,
      "step": 286
    },
    {
      "epoch": 0.022303388249922288,
      "grad_norm": 0.31378695368766785,
      "learning_rate": 9.888483058750389e-06,
      "loss": 0.1917,
      "step": 287
    },
    {
      "epoch": 0.022381100404103203,
      "grad_norm": 1.2212713956832886,
      "learning_rate": 9.888094497979485e-06,
      "loss": 0.2654,
      "step": 288
    },
    {
      "epoch": 0.022458812558284115,
      "grad_norm": 0.2708561420440674,
      "learning_rate": 9.88770593720858e-06,
      "loss": 0.2224,
      "step": 289
    },
    {
      "epoch": 0.02253652471246503,
      "grad_norm": 0.09674029797315598,
      "learning_rate": 9.887317376437677e-06,
      "loss": 0.077,
      "step": 290
    },
    {
      "epoch": 0.022614236866645942,
      "grad_norm": 0.10427173972129822,
      "learning_rate": 9.88692881566677e-06,
      "loss": 0.0867,
      "step": 291
    },
    {
      "epoch": 0.022691949020826857,
      "grad_norm": 0.18154621124267578,
      "learning_rate": 9.886540254895867e-06,
      "loss": 0.1414,
      "step": 292
    },
    {
      "epoch": 0.022769661175007772,
      "grad_norm": 0.27708160877227783,
      "learning_rate": 9.886151694124962e-06,
      "loss": 0.268,
      "step": 293
    },
    {
      "epoch": 0.022847373329188684,
      "grad_norm": 0.11340215057134628,
      "learning_rate": 9.885763133354057e-06,
      "loss": 0.0346,
      "step": 294
    },
    {
      "epoch": 0.0229250854833696,
      "grad_norm": 0.26766741275787354,
      "learning_rate": 9.885374572583153e-06,
      "loss": 0.2461,
      "step": 295
    },
    {
      "epoch": 0.023002797637550514,
      "grad_norm": 1.321624994277954,
      "learning_rate": 9.884986011812248e-06,
      "loss": 0.4817,
      "step": 296
    },
    {
      "epoch": 0.023080509791731426,
      "grad_norm": 0.28620976209640503,
      "learning_rate": 9.884597451041343e-06,
      "loss": 0.34,
      "step": 297
    },
    {
      "epoch": 0.02315822194591234,
      "grad_norm": 0.09210661053657532,
      "learning_rate": 9.88420889027044e-06,
      "loss": 0.0917,
      "step": 298
    },
    {
      "epoch": 0.023235934100093253,
      "grad_norm": 0.6687570810317993,
      "learning_rate": 9.883820329499535e-06,
      "loss": 0.4219,
      "step": 299
    },
    {
      "epoch": 0.023313646254274168,
      "grad_norm": 0.6302201151847839,
      "learning_rate": 9.88343176872863e-06,
      "loss": 0.4921,
      "step": 300
    },
    {
      "epoch": 0.023391358408455083,
      "grad_norm": 0.3335745930671692,
      "learning_rate": 9.883043207957725e-06,
      "loss": 0.2999,
      "step": 301
    },
    {
      "epoch": 0.023469070562635995,
      "grad_norm": 0.05613398179411888,
      "learning_rate": 9.882654647186821e-06,
      "loss": 0.0196,
      "step": 302
    },
    {
      "epoch": 0.02354678271681691,
      "grad_norm": 0.3024153709411621,
      "learning_rate": 9.882266086415916e-06,
      "loss": 0.3114,
      "step": 303
    },
    {
      "epoch": 0.023624494870997825,
      "grad_norm": 0.1597585380077362,
      "learning_rate": 9.881877525645011e-06,
      "loss": 0.0393,
      "step": 304
    },
    {
      "epoch": 0.023702207025178737,
      "grad_norm": 0.32496240735054016,
      "learning_rate": 9.881488964874108e-06,
      "loss": 0.4504,
      "step": 305
    },
    {
      "epoch": 0.023779919179359652,
      "grad_norm": 0.13402262330055237,
      "learning_rate": 9.881100404103203e-06,
      "loss": 0.1925,
      "step": 306
    },
    {
      "epoch": 0.023857631333540567,
      "grad_norm": 0.38143861293792725,
      "learning_rate": 9.880711843332298e-06,
      "loss": 0.4078,
      "step": 307
    },
    {
      "epoch": 0.02393534348772148,
      "grad_norm": 0.21965962648391724,
      "learning_rate": 9.880323282561394e-06,
      "loss": 0.614,
      "step": 308
    },
    {
      "epoch": 0.024013055641902394,
      "grad_norm": 0.1450093388557434,
      "learning_rate": 9.879934721790488e-06,
      "loss": 0.3002,
      "step": 309
    },
    {
      "epoch": 0.024090767796083306,
      "grad_norm": 0.4589548110961914,
      "learning_rate": 9.879546161019584e-06,
      "loss": 0.3566,
      "step": 310
    },
    {
      "epoch": 0.02416847995026422,
      "grad_norm": 0.2563250958919525,
      "learning_rate": 9.87915760024868e-06,
      "loss": 0.1085,
      "step": 311
    },
    {
      "epoch": 0.024246192104445136,
      "grad_norm": 0.20039935410022736,
      "learning_rate": 9.878769039477774e-06,
      "loss": 0.2952,
      "step": 312
    },
    {
      "epoch": 0.024323904258626048,
      "grad_norm": 0.4704281985759735,
      "learning_rate": 9.878380478706871e-06,
      "loss": 0.6909,
      "step": 313
    },
    {
      "epoch": 0.024401616412806963,
      "grad_norm": 0.034847281873226166,
      "learning_rate": 9.877991917935966e-06,
      "loss": 0.015,
      "step": 314
    },
    {
      "epoch": 0.02447932856698788,
      "grad_norm": 0.23161110281944275,
      "learning_rate": 9.87760335716506e-06,
      "loss": 0.2337,
      "step": 315
    },
    {
      "epoch": 0.02455704072116879,
      "grad_norm": 0.41252487897872925,
      "learning_rate": 9.877214796394157e-06,
      "loss": 0.3744,
      "step": 316
    },
    {
      "epoch": 0.024634752875349705,
      "grad_norm": 0.23575426638126373,
      "learning_rate": 9.876826235623252e-06,
      "loss": 0.4248,
      "step": 317
    },
    {
      "epoch": 0.024712465029530617,
      "grad_norm": 0.22740723192691803,
      "learning_rate": 9.876437674852347e-06,
      "loss": 0.3102,
      "step": 318
    },
    {
      "epoch": 0.024790177183711532,
      "grad_norm": 0.12838660180568695,
      "learning_rate": 9.876049114081442e-06,
      "loss": 0.0756,
      "step": 319
    },
    {
      "epoch": 0.024867889337892447,
      "grad_norm": 0.3632642924785614,
      "learning_rate": 9.875660553310539e-06,
      "loss": 0.7883,
      "step": 320
    },
    {
      "epoch": 0.02494560149207336,
      "grad_norm": 0.07409429550170898,
      "learning_rate": 9.875271992539634e-06,
      "loss": 0.0938,
      "step": 321
    },
    {
      "epoch": 0.025023313646254274,
      "grad_norm": 0.39895856380462646,
      "learning_rate": 9.874883431768729e-06,
      "loss": 0.1073,
      "step": 322
    },
    {
      "epoch": 0.02510102580043519,
      "grad_norm": 0.48617300391197205,
      "learning_rate": 9.874494870997825e-06,
      "loss": 0.3342,
      "step": 323
    },
    {
      "epoch": 0.0251787379546161,
      "grad_norm": 0.46871834993362427,
      "learning_rate": 9.87410631022692e-06,
      "loss": 0.2357,
      "step": 324
    },
    {
      "epoch": 0.025256450108797016,
      "grad_norm": 0.20418967306613922,
      "learning_rate": 9.873717749456015e-06,
      "loss": 0.1476,
      "step": 325
    },
    {
      "epoch": 0.02533416226297793,
      "grad_norm": 0.16786986589431763,
      "learning_rate": 9.873329188685112e-06,
      "loss": 0.3493,
      "step": 326
    },
    {
      "epoch": 0.025411874417158843,
      "grad_norm": 0.1651882827281952,
      "learning_rate": 9.872940627914207e-06,
      "loss": 0.0954,
      "step": 327
    },
    {
      "epoch": 0.02548958657133976,
      "grad_norm": 0.21775996685028076,
      "learning_rate": 9.872552067143302e-06,
      "loss": 0.569,
      "step": 328
    },
    {
      "epoch": 0.02556729872552067,
      "grad_norm": 0.12362334877252579,
      "learning_rate": 9.872163506372397e-06,
      "loss": 0.0989,
      "step": 329
    },
    {
      "epoch": 0.025645010879701585,
      "grad_norm": 0.0658334493637085,
      "learning_rate": 9.871774945601493e-06,
      "loss": 0.0263,
      "step": 330
    },
    {
      "epoch": 0.0257227230338825,
      "grad_norm": 0.05637213587760925,
      "learning_rate": 9.871386384830588e-06,
      "loss": 0.0657,
      "step": 331
    },
    {
      "epoch": 0.025800435188063412,
      "grad_norm": 0.2526310086250305,
      "learning_rate": 9.870997824059683e-06,
      "loss": 0.5363,
      "step": 332
    },
    {
      "epoch": 0.025878147342244327,
      "grad_norm": 0.1992296278476715,
      "learning_rate": 9.87060926328878e-06,
      "loss": 0.2397,
      "step": 333
    },
    {
      "epoch": 0.025955859496425242,
      "grad_norm": 0.14279887080192566,
      "learning_rate": 9.870220702517875e-06,
      "loss": 0.0527,
      "step": 334
    },
    {
      "epoch": 0.026033571650606154,
      "grad_norm": 0.05648783594369888,
      "learning_rate": 9.86983214174697e-06,
      "loss": 0.0305,
      "step": 335
    },
    {
      "epoch": 0.02611128380478707,
      "grad_norm": 0.3955810070037842,
      "learning_rate": 9.869443580976067e-06,
      "loss": 0.394,
      "step": 336
    },
    {
      "epoch": 0.02618899595896798,
      "grad_norm": 0.6387127637863159,
      "learning_rate": 9.86905502020516e-06,
      "loss": 0.6386,
      "step": 337
    },
    {
      "epoch": 0.026266708113148896,
      "grad_norm": 0.21107739210128784,
      "learning_rate": 9.868666459434256e-06,
      "loss": 0.226,
      "step": 338
    },
    {
      "epoch": 0.02634442026732981,
      "grad_norm": 0.19884677231311798,
      "learning_rate": 9.868277898663351e-06,
      "loss": 0.156,
      "step": 339
    },
    {
      "epoch": 0.026422132421510723,
      "grad_norm": 0.17536379396915436,
      "learning_rate": 9.867889337892446e-06,
      "loss": 0.129,
      "step": 340
    },
    {
      "epoch": 0.02649984457569164,
      "grad_norm": 0.0964314267039299,
      "learning_rate": 9.867500777121543e-06,
      "loss": 0.0459,
      "step": 341
    },
    {
      "epoch": 0.026577556729872553,
      "grad_norm": 0.24546243250370026,
      "learning_rate": 9.867112216350638e-06,
      "loss": 0.1117,
      "step": 342
    },
    {
      "epoch": 0.026655268884053465,
      "grad_norm": 1.0294803380966187,
      "learning_rate": 9.866723655579733e-06,
      "loss": 0.7121,
      "step": 343
    },
    {
      "epoch": 0.02673298103823438,
      "grad_norm": 0.05092126131057739,
      "learning_rate": 9.86633509480883e-06,
      "loss": 0.0181,
      "step": 344
    },
    {
      "epoch": 0.026810693192415292,
      "grad_norm": 0.14364111423492432,
      "learning_rate": 9.865946534037925e-06,
      "loss": 0.1242,
      "step": 345
    },
    {
      "epoch": 0.026888405346596207,
      "grad_norm": 0.06502986699342728,
      "learning_rate": 9.86555797326702e-06,
      "loss": 0.0357,
      "step": 346
    },
    {
      "epoch": 0.026966117500777122,
      "grad_norm": 0.18938688933849335,
      "learning_rate": 9.865169412496114e-06,
      "loss": 0.3568,
      "step": 347
    },
    {
      "epoch": 0.027043829654958034,
      "grad_norm": 0.1288590431213379,
      "learning_rate": 9.864780851725211e-06,
      "loss": 0.0464,
      "step": 348
    },
    {
      "epoch": 0.02712154180913895,
      "grad_norm": 0.44261860847473145,
      "learning_rate": 9.864392290954306e-06,
      "loss": 0.193,
      "step": 349
    },
    {
      "epoch": 0.027199253963319864,
      "grad_norm": 0.17483019828796387,
      "learning_rate": 9.864003730183401e-06,
      "loss": 0.7706,
      "step": 350
    },
    {
      "epoch": 0.027276966117500776,
      "grad_norm": 0.2274535745382309,
      "learning_rate": 9.863615169412498e-06,
      "loss": 0.2592,
      "step": 351
    },
    {
      "epoch": 0.02735467827168169,
      "grad_norm": 0.009881840087473392,
      "learning_rate": 9.863226608641593e-06,
      "loss": 0.0021,
      "step": 352
    },
    {
      "epoch": 0.027432390425862607,
      "grad_norm": 0.2672121226787567,
      "learning_rate": 9.862838047870687e-06,
      "loss": 0.2935,
      "step": 353
    },
    {
      "epoch": 0.027510102580043518,
      "grad_norm": 0.14527662098407745,
      "learning_rate": 9.862449487099784e-06,
      "loss": 0.0771,
      "step": 354
    },
    {
      "epoch": 0.027587814734224433,
      "grad_norm": 0.09194346517324448,
      "learning_rate": 9.862060926328879e-06,
      "loss": 0.1145,
      "step": 355
    },
    {
      "epoch": 0.027665526888405345,
      "grad_norm": 0.296878844499588,
      "learning_rate": 9.861672365557974e-06,
      "loss": 0.318,
      "step": 356
    },
    {
      "epoch": 0.02774323904258626,
      "grad_norm": 0.16171248257160187,
      "learning_rate": 9.861283804787069e-06,
      "loss": 0.1429,
      "step": 357
    },
    {
      "epoch": 0.027820951196767175,
      "grad_norm": 0.11260483413934708,
      "learning_rate": 9.860895244016166e-06,
      "loss": 0.1477,
      "step": 358
    },
    {
      "epoch": 0.027898663350948087,
      "grad_norm": 0.08253724873065948,
      "learning_rate": 9.86050668324526e-06,
      "loss": 0.1263,
      "step": 359
    },
    {
      "epoch": 0.027976375505129002,
      "grad_norm": 0.15323549509048462,
      "learning_rate": 9.860118122474356e-06,
      "loss": 0.0663,
      "step": 360
    },
    {
      "epoch": 0.028054087659309918,
      "grad_norm": 0.1373187154531479,
      "learning_rate": 9.859729561703452e-06,
      "loss": 0.0673,
      "step": 361
    },
    {
      "epoch": 0.02813179981349083,
      "grad_norm": 0.3224591314792633,
      "learning_rate": 9.859341000932547e-06,
      "loss": 0.5089,
      "step": 362
    },
    {
      "epoch": 0.028209511967671744,
      "grad_norm": 0.6655696034431458,
      "learning_rate": 9.858952440161642e-06,
      "loss": 2.2745,
      "step": 363
    },
    {
      "epoch": 0.028287224121852656,
      "grad_norm": 0.08349884301424026,
      "learning_rate": 9.858563879390739e-06,
      "loss": 0.0262,
      "step": 364
    },
    {
      "epoch": 0.02836493627603357,
      "grad_norm": 0.1990043967962265,
      "learning_rate": 9.858175318619832e-06,
      "loss": 0.1552,
      "step": 365
    },
    {
      "epoch": 0.028442648430214486,
      "grad_norm": 0.4982219636440277,
      "learning_rate": 9.857786757848929e-06,
      "loss": 0.2233,
      "step": 366
    },
    {
      "epoch": 0.028520360584395398,
      "grad_norm": 0.14749297499656677,
      "learning_rate": 9.857398197078024e-06,
      "loss": 0.1882,
      "step": 367
    },
    {
      "epoch": 0.028598072738576313,
      "grad_norm": 0.0739552453160286,
      "learning_rate": 9.857009636307119e-06,
      "loss": 0.0272,
      "step": 368
    },
    {
      "epoch": 0.02867578489275723,
      "grad_norm": 0.20688313245773315,
      "learning_rate": 9.856621075536215e-06,
      "loss": 0.111,
      "step": 369
    },
    {
      "epoch": 0.02875349704693814,
      "grad_norm": 0.1375185251235962,
      "learning_rate": 9.85623251476531e-06,
      "loss": 0.0711,
      "step": 370
    },
    {
      "epoch": 0.028831209201119055,
      "grad_norm": 0.7717638611793518,
      "learning_rate": 9.855843953994405e-06,
      "loss": 0.5994,
      "step": 371
    },
    {
      "epoch": 0.02890892135529997,
      "grad_norm": 0.20425748825073242,
      "learning_rate": 9.855455393223502e-06,
      "loss": 0.1989,
      "step": 372
    },
    {
      "epoch": 0.028986633509480882,
      "grad_norm": 0.03297382965683937,
      "learning_rate": 9.855066832452597e-06,
      "loss": 0.0121,
      "step": 373
    },
    {
      "epoch": 0.029064345663661798,
      "grad_norm": 0.2631717026233673,
      "learning_rate": 9.854678271681692e-06,
      "loss": 0.227,
      "step": 374
    },
    {
      "epoch": 0.02914205781784271,
      "grad_norm": 0.2342657446861267,
      "learning_rate": 9.854289710910787e-06,
      "loss": 0.1316,
      "step": 375
    },
    {
      "epoch": 0.029219769972023624,
      "grad_norm": 0.20466402173042297,
      "learning_rate": 9.853901150139883e-06,
      "loss": 0.1831,
      "step": 376
    },
    {
      "epoch": 0.02929748212620454,
      "grad_norm": 0.06415842473506927,
      "learning_rate": 9.853512589368978e-06,
      "loss": 0.0425,
      "step": 377
    },
    {
      "epoch": 0.02937519428038545,
      "grad_norm": 0.37743330001831055,
      "learning_rate": 9.853124028598073e-06,
      "loss": 0.5999,
      "step": 378
    },
    {
      "epoch": 0.029452906434566366,
      "grad_norm": 0.2122478038072586,
      "learning_rate": 9.85273546782717e-06,
      "loss": 0.146,
      "step": 379
    },
    {
      "epoch": 0.02953061858874728,
      "grad_norm": 0.808914840221405,
      "learning_rate": 9.852346907056265e-06,
      "loss": 0.6882,
      "step": 380
    },
    {
      "epoch": 0.029608330742928193,
      "grad_norm": 0.5018517374992371,
      "learning_rate": 9.85195834628536e-06,
      "loss": 0.2307,
      "step": 381
    },
    {
      "epoch": 0.02968604289710911,
      "grad_norm": 0.1309652030467987,
      "learning_rate": 9.851569785514455e-06,
      "loss": 0.2352,
      "step": 382
    },
    {
      "epoch": 0.02976375505129002,
      "grad_norm": 0.28828492760658264,
      "learning_rate": 9.851181224743551e-06,
      "loss": 0.1447,
      "step": 383
    },
    {
      "epoch": 0.029841467205470935,
      "grad_norm": 0.5994514226913452,
      "learning_rate": 9.850792663972646e-06,
      "loss": 0.3917,
      "step": 384
    },
    {
      "epoch": 0.02991917935965185,
      "grad_norm": 0.015497772954404354,
      "learning_rate": 9.850404103201741e-06,
      "loss": 0.0077,
      "step": 385
    },
    {
      "epoch": 0.029996891513832762,
      "grad_norm": 0.47288405895233154,
      "learning_rate": 9.850015542430838e-06,
      "loss": 0.4468,
      "step": 386
    },
    {
      "epoch": 0.030074603668013677,
      "grad_norm": 0.347165584564209,
      "learning_rate": 9.849626981659933e-06,
      "loss": 0.5486,
      "step": 387
    },
    {
      "epoch": 0.030152315822194593,
      "grad_norm": 0.18266835808753967,
      "learning_rate": 9.849238420889028e-06,
      "loss": 0.0928,
      "step": 388
    },
    {
      "epoch": 0.030230027976375504,
      "grad_norm": 0.3159070611000061,
      "learning_rate": 9.848849860118124e-06,
      "loss": 0.085,
      "step": 389
    },
    {
      "epoch": 0.03030774013055642,
      "grad_norm": 0.10723557323217392,
      "learning_rate": 9.848461299347218e-06,
      "loss": 0.0637,
      "step": 390
    },
    {
      "epoch": 0.03038545228473733,
      "grad_norm": 0.03535984829068184,
      "learning_rate": 9.848072738576314e-06,
      "loss": 0.0177,
      "step": 391
    },
    {
      "epoch": 0.030463164438918246,
      "grad_norm": 0.26017895340919495,
      "learning_rate": 9.84768417780541e-06,
      "loss": 0.1126,
      "step": 392
    },
    {
      "epoch": 0.03054087659309916,
      "grad_norm": 0.8900088667869568,
      "learning_rate": 9.847295617034504e-06,
      "loss": 0.1948,
      "step": 393
    },
    {
      "epoch": 0.030618588747280073,
      "grad_norm": 0.08345896005630493,
      "learning_rate": 9.8469070562636e-06,
      "loss": 0.0308,
      "step": 394
    },
    {
      "epoch": 0.03069630090146099,
      "grad_norm": 0.6536670327186584,
      "learning_rate": 9.846518495492696e-06,
      "loss": 0.594,
      "step": 395
    },
    {
      "epoch": 0.030774013055641904,
      "grad_norm": 0.3174552619457245,
      "learning_rate": 9.84612993472179e-06,
      "loss": 0.2493,
      "step": 396
    },
    {
      "epoch": 0.030851725209822815,
      "grad_norm": 0.3552177846431732,
      "learning_rate": 9.845741373950887e-06,
      "loss": 0.1446,
      "step": 397
    },
    {
      "epoch": 0.03092943736400373,
      "grad_norm": 0.1704886108636856,
      "learning_rate": 9.845352813179982e-06,
      "loss": 0.429,
      "step": 398
    },
    {
      "epoch": 0.031007149518184646,
      "grad_norm": 0.1922927349805832,
      "learning_rate": 9.844964252409077e-06,
      "loss": 0.2718,
      "step": 399
    },
    {
      "epoch": 0.031084861672365557,
      "grad_norm": 0.21687300503253937,
      "learning_rate": 9.844575691638172e-06,
      "loss": 0.0457,
      "step": 400
    },
    {
      "epoch": 0.031162573826546473,
      "grad_norm": 0.24008093774318695,
      "learning_rate": 9.844187130867269e-06,
      "loss": 0.1936,
      "step": 401
    },
    {
      "epoch": 0.031240285980727384,
      "grad_norm": 0.09960883110761642,
      "learning_rate": 9.843798570096364e-06,
      "loss": 0.094,
      "step": 402
    },
    {
      "epoch": 0.0313179981349083,
      "grad_norm": 0.08284728229045868,
      "learning_rate": 9.843410009325459e-06,
      "loss": 0.0167,
      "step": 403
    },
    {
      "epoch": 0.03139571028908921,
      "grad_norm": 0.09004189819097519,
      "learning_rate": 9.843021448554555e-06,
      "loss": 0.0607,
      "step": 404
    },
    {
      "epoch": 0.03147342244327013,
      "grad_norm": 0.2743859887123108,
      "learning_rate": 9.84263288778365e-06,
      "loss": 0.1623,
      "step": 405
    },
    {
      "epoch": 0.03155113459745104,
      "grad_norm": 0.25708484649658203,
      "learning_rate": 9.842244327012745e-06,
      "loss": 0.4988,
      "step": 406
    },
    {
      "epoch": 0.03162884675163195,
      "grad_norm": 0.15106865763664246,
      "learning_rate": 9.841855766241842e-06,
      "loss": 0.1078,
      "step": 407
    },
    {
      "epoch": 0.03170655890581287,
      "grad_norm": 0.20681127905845642,
      "learning_rate": 9.841467205470935e-06,
      "loss": 0.0636,
      "step": 408
    },
    {
      "epoch": 0.031784271059993784,
      "grad_norm": 0.34193524718284607,
      "learning_rate": 9.841078644700032e-06,
      "loss": 0.4019,
      "step": 409
    },
    {
      "epoch": 0.031861983214174695,
      "grad_norm": 0.27498459815979004,
      "learning_rate": 9.840690083929127e-06,
      "loss": 0.1723,
      "step": 410
    },
    {
      "epoch": 0.031939695368355614,
      "grad_norm": 0.08317834883928299,
      "learning_rate": 9.840301523158223e-06,
      "loss": 0.0786,
      "step": 411
    },
    {
      "epoch": 0.032017407522536526,
      "grad_norm": 0.18037836253643036,
      "learning_rate": 9.839912962387318e-06,
      "loss": 0.2136,
      "step": 412
    },
    {
      "epoch": 0.03209511967671744,
      "grad_norm": 0.14045466482639313,
      "learning_rate": 9.839524401616413e-06,
      "loss": 0.124,
      "step": 413
    },
    {
      "epoch": 0.03217283183089835,
      "grad_norm": 0.21945694088935852,
      "learning_rate": 9.83913584084551e-06,
      "loss": 0.4853,
      "step": 414
    },
    {
      "epoch": 0.03225054398507927,
      "grad_norm": 0.2613902986049652,
      "learning_rate": 9.838747280074605e-06,
      "loss": 0.2059,
      "step": 415
    },
    {
      "epoch": 0.03232825613926018,
      "grad_norm": 0.16161657869815826,
      "learning_rate": 9.8383587193037e-06,
      "loss": 0.2682,
      "step": 416
    },
    {
      "epoch": 0.03240596829344109,
      "grad_norm": 0.1580953449010849,
      "learning_rate": 9.837970158532796e-06,
      "loss": 0.0764,
      "step": 417
    },
    {
      "epoch": 0.03248368044762201,
      "grad_norm": 0.1667596846818924,
      "learning_rate": 9.83758159776189e-06,
      "loss": 0.1898,
      "step": 418
    },
    {
      "epoch": 0.03256139260180292,
      "grad_norm": 0.35117289423942566,
      "learning_rate": 9.837193036990986e-06,
      "loss": 0.3779,
      "step": 419
    },
    {
      "epoch": 0.03263910475598383,
      "grad_norm": 0.08418571949005127,
      "learning_rate": 9.836804476220081e-06,
      "loss": 0.1212,
      "step": 420
    },
    {
      "epoch": 0.03271681691016475,
      "grad_norm": 0.1685718148946762,
      "learning_rate": 9.836415915449176e-06,
      "loss": 0.1901,
      "step": 421
    },
    {
      "epoch": 0.032794529064345664,
      "grad_norm": 0.12777158617973328,
      "learning_rate": 9.836027354678273e-06,
      "loss": 0.0804,
      "step": 422
    },
    {
      "epoch": 0.032872241218526575,
      "grad_norm": 0.1535557508468628,
      "learning_rate": 9.835638793907368e-06,
      "loss": 0.0651,
      "step": 423
    },
    {
      "epoch": 0.032949953372707494,
      "grad_norm": 0.16288118064403534,
      "learning_rate": 9.835250233136463e-06,
      "loss": 0.0817,
      "step": 424
    },
    {
      "epoch": 0.033027665526888406,
      "grad_norm": 0.17720454931259155,
      "learning_rate": 9.83486167236556e-06,
      "loss": 0.1527,
      "step": 425
    },
    {
      "epoch": 0.03310537768106932,
      "grad_norm": 0.2867257297039032,
      "learning_rate": 9.834473111594654e-06,
      "loss": 0.1933,
      "step": 426
    },
    {
      "epoch": 0.033183089835250236,
      "grad_norm": 0.2369541972875595,
      "learning_rate": 9.83408455082375e-06,
      "loss": 0.2692,
      "step": 427
    },
    {
      "epoch": 0.03326080198943115,
      "grad_norm": 0.47261878848075867,
      "learning_rate": 9.833695990052844e-06,
      "loss": 0.1165,
      "step": 428
    },
    {
      "epoch": 0.03333851414361206,
      "grad_norm": 0.277336448431015,
      "learning_rate": 9.833307429281941e-06,
      "loss": 0.2369,
      "step": 429
    },
    {
      "epoch": 0.03341622629779298,
      "grad_norm": 0.12475185841321945,
      "learning_rate": 9.832918868511036e-06,
      "loss": 0.0487,
      "step": 430
    },
    {
      "epoch": 0.03349393845197389,
      "grad_norm": 0.15530189871788025,
      "learning_rate": 9.832530307740131e-06,
      "loss": 0.1574,
      "step": 431
    },
    {
      "epoch": 0.0335716506061548,
      "grad_norm": 0.07632549107074738,
      "learning_rate": 9.832141746969227e-06,
      "loss": 0.1,
      "step": 432
    },
    {
      "epoch": 0.03364936276033571,
      "grad_norm": 0.1526554524898529,
      "learning_rate": 9.831753186198322e-06,
      "loss": 0.2605,
      "step": 433
    },
    {
      "epoch": 0.03372707491451663,
      "grad_norm": 0.048579905182123184,
      "learning_rate": 9.831364625427417e-06,
      "loss": 0.0172,
      "step": 434
    },
    {
      "epoch": 0.033804787068697544,
      "grad_norm": 0.21594761312007904,
      "learning_rate": 9.830976064656514e-06,
      "loss": 0.1402,
      "step": 435
    },
    {
      "epoch": 0.033882499222878455,
      "grad_norm": 0.3223609924316406,
      "learning_rate": 9.830587503885607e-06,
      "loss": 0.371,
      "step": 436
    },
    {
      "epoch": 0.033960211377059374,
      "grad_norm": 0.27666497230529785,
      "learning_rate": 9.830198943114704e-06,
      "loss": 0.2245,
      "step": 437
    },
    {
      "epoch": 0.034037923531240286,
      "grad_norm": 0.112143374979496,
      "learning_rate": 9.829810382343799e-06,
      "loss": 0.0502,
      "step": 438
    },
    {
      "epoch": 0.0341156356854212,
      "grad_norm": 0.13922032713890076,
      "learning_rate": 9.829421821572894e-06,
      "loss": 0.2211,
      "step": 439
    },
    {
      "epoch": 0.034193347839602116,
      "grad_norm": 0.10826369374990463,
      "learning_rate": 9.82903326080199e-06,
      "loss": 0.0549,
      "step": 440
    },
    {
      "epoch": 0.03427105999378303,
      "grad_norm": 0.18336868286132812,
      "learning_rate": 9.828644700031085e-06,
      "loss": 0.1527,
      "step": 441
    },
    {
      "epoch": 0.03434877214796394,
      "grad_norm": 0.1309441477060318,
      "learning_rate": 9.828256139260182e-06,
      "loss": 0.12,
      "step": 442
    },
    {
      "epoch": 0.03442648430214486,
      "grad_norm": 0.4381161034107208,
      "learning_rate": 9.827867578489277e-06,
      "loss": 0.348,
      "step": 443
    },
    {
      "epoch": 0.03450419645632577,
      "grad_norm": 0.21476565301418304,
      "learning_rate": 9.827479017718372e-06,
      "loss": 0.3665,
      "step": 444
    },
    {
      "epoch": 0.03458190861050668,
      "grad_norm": 0.26736053824424744,
      "learning_rate": 9.827090456947469e-06,
      "loss": 0.3098,
      "step": 445
    },
    {
      "epoch": 0.0346596207646876,
      "grad_norm": 0.10147804766893387,
      "learning_rate": 9.826701896176562e-06,
      "loss": 0.0446,
      "step": 446
    },
    {
      "epoch": 0.03473733291886851,
      "grad_norm": 0.31998589634895325,
      "learning_rate": 9.826313335405659e-06,
      "loss": 0.3406,
      "step": 447
    },
    {
      "epoch": 0.034815045073049423,
      "grad_norm": 0.239583820104599,
      "learning_rate": 9.825924774634753e-06,
      "loss": 0.1347,
      "step": 448
    },
    {
      "epoch": 0.03489275722723034,
      "grad_norm": 0.058679886162281036,
      "learning_rate": 9.825536213863848e-06,
      "loss": 0.051,
      "step": 449
    },
    {
      "epoch": 0.034970469381411254,
      "grad_norm": 0.0876389741897583,
      "learning_rate": 9.825147653092945e-06,
      "loss": 0.0215,
      "step": 450
    },
    {
      "epoch": 0.035048181535592166,
      "grad_norm": 0.09790652990341187,
      "learning_rate": 9.82475909232204e-06,
      "loss": 0.1175,
      "step": 451
    },
    {
      "epoch": 0.03512589368977308,
      "grad_norm": 0.28513872623443604,
      "learning_rate": 9.824370531551135e-06,
      "loss": 0.2047,
      "step": 452
    },
    {
      "epoch": 0.035203605843953996,
      "grad_norm": 0.06832098960876465,
      "learning_rate": 9.823981970780232e-06,
      "loss": 0.063,
      "step": 453
    },
    {
      "epoch": 0.03528131799813491,
      "grad_norm": 0.11448107659816742,
      "learning_rate": 9.823593410009327e-06,
      "loss": 0.0966,
      "step": 454
    },
    {
      "epoch": 0.03535903015231582,
      "grad_norm": 0.08753572404384613,
      "learning_rate": 9.823204849238422e-06,
      "loss": 0.0727,
      "step": 455
    },
    {
      "epoch": 0.03543674230649674,
      "grad_norm": 0.21053361892700195,
      "learning_rate": 9.822816288467516e-06,
      "loss": 0.2219,
      "step": 456
    },
    {
      "epoch": 0.03551445446067765,
      "grad_norm": 0.12037412822246552,
      "learning_rate": 9.822427727696613e-06,
      "loss": 0.1029,
      "step": 457
    },
    {
      "epoch": 0.03559216661485856,
      "grad_norm": 0.2363804578781128,
      "learning_rate": 9.822039166925708e-06,
      "loss": 0.1125,
      "step": 458
    },
    {
      "epoch": 0.03566987876903948,
      "grad_norm": 0.5840532183647156,
      "learning_rate": 9.821650606154803e-06,
      "loss": 0.4005,
      "step": 459
    },
    {
      "epoch": 0.03574759092322039,
      "grad_norm": 0.15867005288600922,
      "learning_rate": 9.8212620453839e-06,
      "loss": 0.1832,
      "step": 460
    },
    {
      "epoch": 0.0358253030774013,
      "grad_norm": 0.44134873151779175,
      "learning_rate": 9.820873484612995e-06,
      "loss": 0.2609,
      "step": 461
    },
    {
      "epoch": 0.03590301523158222,
      "grad_norm": 0.18685407936573029,
      "learning_rate": 9.82048492384209e-06,
      "loss": 0.0825,
      "step": 462
    },
    {
      "epoch": 0.035980727385763134,
      "grad_norm": 0.10727149993181229,
      "learning_rate": 9.820096363071186e-06,
      "loss": 0.0504,
      "step": 463
    },
    {
      "epoch": 0.036058439539944045,
      "grad_norm": 0.21573948860168457,
      "learning_rate": 9.81970780230028e-06,
      "loss": 0.1827,
      "step": 464
    },
    {
      "epoch": 0.036136151694124964,
      "grad_norm": 0.1756429821252823,
      "learning_rate": 9.819319241529376e-06,
      "loss": 0.5453,
      "step": 465
    },
    {
      "epoch": 0.036213863848305876,
      "grad_norm": 0.1867145448923111,
      "learning_rate": 9.818930680758471e-06,
      "loss": 0.198,
      "step": 466
    },
    {
      "epoch": 0.03629157600248679,
      "grad_norm": 0.25101980566978455,
      "learning_rate": 9.818542119987566e-06,
      "loss": 0.4444,
      "step": 467
    },
    {
      "epoch": 0.036369288156667706,
      "grad_norm": 0.05181529000401497,
      "learning_rate": 9.818153559216663e-06,
      "loss": 0.0657,
      "step": 468
    },
    {
      "epoch": 0.03644700031084862,
      "grad_norm": 0.20654426515102386,
      "learning_rate": 9.817764998445758e-06,
      "loss": 0.3092,
      "step": 469
    },
    {
      "epoch": 0.03652471246502953,
      "grad_norm": 0.5875721573829651,
      "learning_rate": 9.817376437674853e-06,
      "loss": 0.4111,
      "step": 470
    },
    {
      "epoch": 0.03660242461921044,
      "grad_norm": 0.3224957287311554,
      "learning_rate": 9.81698787690395e-06,
      "loss": 0.5024,
      "step": 471
    },
    {
      "epoch": 0.03668013677339136,
      "grad_norm": 0.1444677859544754,
      "learning_rate": 9.816599316133044e-06,
      "loss": 0.1535,
      "step": 472
    },
    {
      "epoch": 0.03675784892757227,
      "grad_norm": 0.18210282921791077,
      "learning_rate": 9.81621075536214e-06,
      "loss": 0.3771,
      "step": 473
    },
    {
      "epoch": 0.03683556108175318,
      "grad_norm": 0.23166242241859436,
      "learning_rate": 9.815822194591234e-06,
      "loss": 0.1174,
      "step": 474
    },
    {
      "epoch": 0.0369132732359341,
      "grad_norm": 0.23113298416137695,
      "learning_rate": 9.81543363382033e-06,
      "loss": 0.2018,
      "step": 475
    },
    {
      "epoch": 0.036990985390115014,
      "grad_norm": 0.08723851293325424,
      "learning_rate": 9.815045073049426e-06,
      "loss": 0.0398,
      "step": 476
    },
    {
      "epoch": 0.037068697544295925,
      "grad_norm": 0.21943287551403046,
      "learning_rate": 9.81465651227852e-06,
      "loss": 0.1511,
      "step": 477
    },
    {
      "epoch": 0.037146409698476844,
      "grad_norm": 0.55238938331604,
      "learning_rate": 9.814267951507617e-06,
      "loss": 1.0795,
      "step": 478
    },
    {
      "epoch": 0.037224121852657756,
      "grad_norm": 0.28657346963882446,
      "learning_rate": 9.813879390736712e-06,
      "loss": 0.168,
      "step": 479
    },
    {
      "epoch": 0.03730183400683867,
      "grad_norm": 0.1352669596672058,
      "learning_rate": 9.813490829965807e-06,
      "loss": 0.111,
      "step": 480
    },
    {
      "epoch": 0.037379546161019586,
      "grad_norm": 0.11002194881439209,
      "learning_rate": 9.813102269194904e-06,
      "loss": 0.096,
      "step": 481
    },
    {
      "epoch": 0.0374572583152005,
      "grad_norm": 0.3114229142665863,
      "learning_rate": 9.812713708423999e-06,
      "loss": 0.1282,
      "step": 482
    },
    {
      "epoch": 0.03753497046938141,
      "grad_norm": 0.17815154790878296,
      "learning_rate": 9.812325147653094e-06,
      "loss": 0.1657,
      "step": 483
    },
    {
      "epoch": 0.03761268262356233,
      "grad_norm": 0.2257682979106903,
      "learning_rate": 9.811936586882189e-06,
      "loss": 0.1499,
      "step": 484
    },
    {
      "epoch": 0.03769039477774324,
      "grad_norm": 0.2870447337627411,
      "learning_rate": 9.811548026111285e-06,
      "loss": 0.1018,
      "step": 485
    },
    {
      "epoch": 0.03776810693192415,
      "grad_norm": 0.04284437745809555,
      "learning_rate": 9.81115946534038e-06,
      "loss": 0.07,
      "step": 486
    },
    {
      "epoch": 0.03784581908610507,
      "grad_norm": 0.590064287185669,
      "learning_rate": 9.810770904569475e-06,
      "loss": 0.2853,
      "step": 487
    },
    {
      "epoch": 0.03792353124028598,
      "grad_norm": 0.23994873464107513,
      "learning_rate": 9.810382343798572e-06,
      "loss": 0.1877,
      "step": 488
    },
    {
      "epoch": 0.038001243394466894,
      "grad_norm": 0.08288003504276276,
      "learning_rate": 9.809993783027667e-06,
      "loss": 0.0302,
      "step": 489
    },
    {
      "epoch": 0.038078955548647805,
      "grad_norm": 0.28577086329460144,
      "learning_rate": 9.809605222256762e-06,
      "loss": 0.4512,
      "step": 490
    },
    {
      "epoch": 0.038156667702828724,
      "grad_norm": 0.21308384835720062,
      "learning_rate": 9.809216661485858e-06,
      "loss": 0.1348,
      "step": 491
    },
    {
      "epoch": 0.038234379857009636,
      "grad_norm": 0.3216307461261749,
      "learning_rate": 9.808828100714952e-06,
      "loss": 0.4501,
      "step": 492
    },
    {
      "epoch": 0.03831209201119055,
      "grad_norm": 0.09349066764116287,
      "learning_rate": 9.808439539944048e-06,
      "loss": 0.0747,
      "step": 493
    },
    {
      "epoch": 0.038389804165371466,
      "grad_norm": 0.12034210562705994,
      "learning_rate": 9.808050979173143e-06,
      "loss": 0.1335,
      "step": 494
    },
    {
      "epoch": 0.03846751631955238,
      "grad_norm": 0.47796499729156494,
      "learning_rate": 9.807662418402238e-06,
      "loss": 0.2779,
      "step": 495
    },
    {
      "epoch": 0.03854522847373329,
      "grad_norm": 0.20199549198150635,
      "learning_rate": 9.807273857631335e-06,
      "loss": 0.3662,
      "step": 496
    },
    {
      "epoch": 0.03862294062791421,
      "grad_norm": 0.15851151943206787,
      "learning_rate": 9.80688529686043e-06,
      "loss": 0.1234,
      "step": 497
    },
    {
      "epoch": 0.03870065278209512,
      "grad_norm": 0.17559075355529785,
      "learning_rate": 9.806496736089525e-06,
      "loss": 0.6748,
      "step": 498
    },
    {
      "epoch": 0.03877836493627603,
      "grad_norm": 0.4056936502456665,
      "learning_rate": 9.806108175318621e-06,
      "loss": 0.1555,
      "step": 499
    },
    {
      "epoch": 0.03885607709045695,
      "grad_norm": 0.08995974063873291,
      "learning_rate": 9.805719614547716e-06,
      "loss": 0.0187,
      "step": 500
    },
    {
      "epoch": 0.03893378924463786,
      "grad_norm": 0.28856363892555237,
      "learning_rate": 9.805331053776811e-06,
      "loss": 0.2615,
      "step": 501
    },
    {
      "epoch": 0.039011501398818774,
      "grad_norm": 0.09182102233171463,
      "learning_rate": 9.804942493005906e-06,
      "loss": 0.0312,
      "step": 502
    },
    {
      "epoch": 0.03908921355299969,
      "grad_norm": 0.6343715190887451,
      "learning_rate": 9.804553932235003e-06,
      "loss": 0.356,
      "step": 503
    },
    {
      "epoch": 0.039166925707180604,
      "grad_norm": 0.12550872564315796,
      "learning_rate": 9.804165371464098e-06,
      "loss": 0.0817,
      "step": 504
    },
    {
      "epoch": 0.039244637861361516,
      "grad_norm": 0.4069913327693939,
      "learning_rate": 9.803776810693193e-06,
      "loss": 0.7045,
      "step": 505
    },
    {
      "epoch": 0.03932235001554243,
      "grad_norm": 0.12325815111398697,
      "learning_rate": 9.80338824992229e-06,
      "loss": 0.1244,
      "step": 506
    },
    {
      "epoch": 0.039400062169723346,
      "grad_norm": 0.7826159000396729,
      "learning_rate": 9.802999689151384e-06,
      "loss": 0.4775,
      "step": 507
    },
    {
      "epoch": 0.03947777432390426,
      "grad_norm": 0.11947937309741974,
      "learning_rate": 9.80261112838048e-06,
      "loss": 0.0455,
      "step": 508
    },
    {
      "epoch": 0.03955548647808517,
      "grad_norm": 0.19303067028522491,
      "learning_rate": 9.802222567609574e-06,
      "loss": 0.1241,
      "step": 509
    },
    {
      "epoch": 0.03963319863226609,
      "grad_norm": 0.5998091697692871,
      "learning_rate": 9.80183400683867e-06,
      "loss": 1.0749,
      "step": 510
    },
    {
      "epoch": 0.039710910786447,
      "grad_norm": 0.3398677408695221,
      "learning_rate": 9.801445446067766e-06,
      "loss": 0.1588,
      "step": 511
    },
    {
      "epoch": 0.03978862294062791,
      "grad_norm": 0.11673702299594879,
      "learning_rate": 9.80105688529686e-06,
      "loss": 0.0942,
      "step": 512
    },
    {
      "epoch": 0.03986633509480883,
      "grad_norm": 0.739901065826416,
      "learning_rate": 9.800668324525957e-06,
      "loss": 0.4486,
      "step": 513
    },
    {
      "epoch": 0.03994404724898974,
      "grad_norm": 0.3269282877445221,
      "learning_rate": 9.800279763755052e-06,
      "loss": 0.1973,
      "step": 514
    },
    {
      "epoch": 0.040021759403170654,
      "grad_norm": 0.5204206109046936,
      "learning_rate": 9.799891202984147e-06,
      "loss": 0.246,
      "step": 515
    },
    {
      "epoch": 0.04009947155735157,
      "grad_norm": 0.11900775134563446,
      "learning_rate": 9.799502642213244e-06,
      "loss": 0.0411,
      "step": 516
    },
    {
      "epoch": 0.040177183711532484,
      "grad_norm": 0.11792762577533722,
      "learning_rate": 9.799114081442337e-06,
      "loss": 0.0846,
      "step": 517
    },
    {
      "epoch": 0.040254895865713396,
      "grad_norm": 0.21229338645935059,
      "learning_rate": 9.798725520671434e-06,
      "loss": 0.3306,
      "step": 518
    },
    {
      "epoch": 0.040332608019894314,
      "grad_norm": 0.20147158205509186,
      "learning_rate": 9.798336959900529e-06,
      "loss": 0.1199,
      "step": 519
    },
    {
      "epoch": 0.040410320174075226,
      "grad_norm": 0.042689450085163116,
      "learning_rate": 9.797948399129624e-06,
      "loss": 0.0116,
      "step": 520
    },
    {
      "epoch": 0.04048803232825614,
      "grad_norm": 0.19771625101566315,
      "learning_rate": 9.79755983835872e-06,
      "loss": 0.2217,
      "step": 521
    },
    {
      "epoch": 0.040565744482437056,
      "grad_norm": 0.10383053869009018,
      "learning_rate": 9.797171277587815e-06,
      "loss": 0.3095,
      "step": 522
    },
    {
      "epoch": 0.04064345663661797,
      "grad_norm": 0.12561319768428802,
      "learning_rate": 9.79678271681691e-06,
      "loss": 0.04,
      "step": 523
    },
    {
      "epoch": 0.04072116879079888,
      "grad_norm": 0.14028798043727875,
      "learning_rate": 9.796394156046007e-06,
      "loss": 0.1106,
      "step": 524
    },
    {
      "epoch": 0.04079888094497979,
      "grad_norm": 0.12612226605415344,
      "learning_rate": 9.796005595275102e-06,
      "loss": 0.0735,
      "step": 525
    },
    {
      "epoch": 0.04087659309916071,
      "grad_norm": 0.5364346504211426,
      "learning_rate": 9.795617034504197e-06,
      "loss": 0.4307,
      "step": 526
    },
    {
      "epoch": 0.04095430525334162,
      "grad_norm": 0.315669983625412,
      "learning_rate": 9.795228473733292e-06,
      "loss": 0.5836,
      "step": 527
    },
    {
      "epoch": 0.041032017407522534,
      "grad_norm": 0.24701529741287231,
      "learning_rate": 9.794839912962388e-06,
      "loss": 0.2448,
      "step": 528
    },
    {
      "epoch": 0.04110972956170345,
      "grad_norm": 0.16056232154369354,
      "learning_rate": 9.794451352191483e-06,
      "loss": 0.5256,
      "step": 529
    },
    {
      "epoch": 0.041187441715884364,
      "grad_norm": 0.10094534605741501,
      "learning_rate": 9.794062791420578e-06,
      "loss": 0.0413,
      "step": 530
    },
    {
      "epoch": 0.041265153870065276,
      "grad_norm": 0.4455731213092804,
      "learning_rate": 9.793674230649675e-06,
      "loss": 0.7056,
      "step": 531
    },
    {
      "epoch": 0.041342866024246194,
      "grad_norm": 0.20368751883506775,
      "learning_rate": 9.79328566987877e-06,
      "loss": 0.2246,
      "step": 532
    },
    {
      "epoch": 0.041420578178427106,
      "grad_norm": 0.25451377034187317,
      "learning_rate": 9.792897109107865e-06,
      "loss": 0.3256,
      "step": 533
    },
    {
      "epoch": 0.04149829033260802,
      "grad_norm": 0.31752845644950867,
      "learning_rate": 9.792508548336961e-06,
      "loss": 0.1704,
      "step": 534
    },
    {
      "epoch": 0.041576002486788936,
      "grad_norm": 0.08900267630815506,
      "learning_rate": 9.792119987566056e-06,
      "loss": 0.1156,
      "step": 535
    },
    {
      "epoch": 0.04165371464096985,
      "grad_norm": 0.10375488549470901,
      "learning_rate": 9.791731426795151e-06,
      "loss": 0.204,
      "step": 536
    },
    {
      "epoch": 0.04173142679515076,
      "grad_norm": 0.19303132593631744,
      "learning_rate": 9.791342866024246e-06,
      "loss": 0.1238,
      "step": 537
    },
    {
      "epoch": 0.04180913894933168,
      "grad_norm": 0.39419668912887573,
      "learning_rate": 9.790954305253343e-06,
      "loss": 0.2775,
      "step": 538
    },
    {
      "epoch": 0.04188685110351259,
      "grad_norm": 0.06173829734325409,
      "learning_rate": 9.790565744482438e-06,
      "loss": 0.1268,
      "step": 539
    },
    {
      "epoch": 0.0419645632576935,
      "grad_norm": 0.16990308463573456,
      "learning_rate": 9.790177183711533e-06,
      "loss": 0.0564,
      "step": 540
    },
    {
      "epoch": 0.04204227541187442,
      "grad_norm": 0.20254863798618317,
      "learning_rate": 9.78978862294063e-06,
      "loss": 0.3092,
      "step": 541
    },
    {
      "epoch": 0.04211998756605533,
      "grad_norm": 0.2281845360994339,
      "learning_rate": 9.789400062169724e-06,
      "loss": 0.1492,
      "step": 542
    },
    {
      "epoch": 0.042197699720236244,
      "grad_norm": 0.2579488754272461,
      "learning_rate": 9.78901150139882e-06,
      "loss": 0.4727,
      "step": 543
    },
    {
      "epoch": 0.042275411874417156,
      "grad_norm": 0.20418858528137207,
      "learning_rate": 9.788622940627916e-06,
      "loss": 0.1975,
      "step": 544
    },
    {
      "epoch": 0.042353124028598074,
      "grad_norm": 0.18290072679519653,
      "learning_rate": 9.78823437985701e-06,
      "loss": 0.219,
      "step": 545
    },
    {
      "epoch": 0.042430836182778986,
      "grad_norm": 0.10548646748065948,
      "learning_rate": 9.787845819086106e-06,
      "loss": 0.0835,
      "step": 546
    },
    {
      "epoch": 0.0425085483369599,
      "grad_norm": 0.27761581540107727,
      "learning_rate": 9.787457258315201e-06,
      "loss": 0.2808,
      "step": 547
    },
    {
      "epoch": 0.042586260491140816,
      "grad_norm": 0.49712327122688293,
      "learning_rate": 9.787068697544296e-06,
      "loss": 0.8639,
      "step": 548
    },
    {
      "epoch": 0.04266397264532173,
      "grad_norm": 0.22206978499889374,
      "learning_rate": 9.786680136773393e-06,
      "loss": 0.2568,
      "step": 549
    },
    {
      "epoch": 0.04274168479950264,
      "grad_norm": 0.34361112117767334,
      "learning_rate": 9.786291576002487e-06,
      "loss": 0.1355,
      "step": 550
    },
    {
      "epoch": 0.04281939695368356,
      "grad_norm": 0.2273918241262436,
      "learning_rate": 9.785903015231582e-06,
      "loss": 0.4509,
      "step": 551
    },
    {
      "epoch": 0.04289710910786447,
      "grad_norm": 0.20828987658023834,
      "learning_rate": 9.785514454460679e-06,
      "loss": 0.2226,
      "step": 552
    },
    {
      "epoch": 0.04297482126204538,
      "grad_norm": 0.08664388954639435,
      "learning_rate": 9.785125893689774e-06,
      "loss": 0.1124,
      "step": 553
    },
    {
      "epoch": 0.0430525334162263,
      "grad_norm": 0.1823466718196869,
      "learning_rate": 9.784737332918869e-06,
      "loss": 0.1759,
      "step": 554
    },
    {
      "epoch": 0.04313024557040721,
      "grad_norm": 0.1331000179052353,
      "learning_rate": 9.784348772147964e-06,
      "loss": 0.0857,
      "step": 555
    },
    {
      "epoch": 0.043207957724588124,
      "grad_norm": 0.07938078790903091,
      "learning_rate": 9.78396021137706e-06,
      "loss": 0.1657,
      "step": 556
    },
    {
      "epoch": 0.04328566987876904,
      "grad_norm": 0.2351883202791214,
      "learning_rate": 9.783571650606156e-06,
      "loss": 0.0879,
      "step": 557
    },
    {
      "epoch": 0.043363382032949954,
      "grad_norm": 0.16099777817726135,
      "learning_rate": 9.78318308983525e-06,
      "loss": 0.0895,
      "step": 558
    },
    {
      "epoch": 0.043441094187130866,
      "grad_norm": 0.2716922461986542,
      "learning_rate": 9.782794529064347e-06,
      "loss": 0.4229,
      "step": 559
    },
    {
      "epoch": 0.043518806341311785,
      "grad_norm": 0.17350247502326965,
      "learning_rate": 9.782405968293442e-06,
      "loss": 0.2151,
      "step": 560
    },
    {
      "epoch": 0.043596518495492696,
      "grad_norm": 0.16330043971538544,
      "learning_rate": 9.782017407522537e-06,
      "loss": 0.1535,
      "step": 561
    },
    {
      "epoch": 0.04367423064967361,
      "grad_norm": 0.49594712257385254,
      "learning_rate": 9.781628846751634e-06,
      "loss": 0.4993,
      "step": 562
    },
    {
      "epoch": 0.04375194280385452,
      "grad_norm": 0.11257417500019073,
      "learning_rate": 9.781240285980729e-06,
      "loss": 0.1045,
      "step": 563
    },
    {
      "epoch": 0.04382965495803544,
      "grad_norm": 0.14176663756370544,
      "learning_rate": 9.780851725209824e-06,
      "loss": 0.0765,
      "step": 564
    },
    {
      "epoch": 0.04390736711221635,
      "grad_norm": 0.4372263252735138,
      "learning_rate": 9.780463164438918e-06,
      "loss": 0.3383,
      "step": 565
    },
    {
      "epoch": 0.04398507926639726,
      "grad_norm": 0.30640679597854614,
      "learning_rate": 9.780074603668015e-06,
      "loss": 0.5429,
      "step": 566
    },
    {
      "epoch": 0.04406279142057818,
      "grad_norm": 0.12338866293430328,
      "learning_rate": 9.77968604289711e-06,
      "loss": 0.1498,
      "step": 567
    },
    {
      "epoch": 0.04414050357475909,
      "grad_norm": 0.18342922627925873,
      "learning_rate": 9.779297482126205e-06,
      "loss": 0.1262,
      "step": 568
    },
    {
      "epoch": 0.044218215728940004,
      "grad_norm": 0.30646243691444397,
      "learning_rate": 9.778908921355302e-06,
      "loss": 0.0774,
      "step": 569
    },
    {
      "epoch": 0.04429592788312092,
      "grad_norm": 0.4514845311641693,
      "learning_rate": 9.778520360584397e-06,
      "loss": 0.6078,
      "step": 570
    },
    {
      "epoch": 0.044373640037301834,
      "grad_norm": 0.5410376191139221,
      "learning_rate": 9.778131799813492e-06,
      "loss": 0.3586,
      "step": 571
    },
    {
      "epoch": 0.044451352191482746,
      "grad_norm": 0.5123199820518494,
      "learning_rate": 9.777743239042588e-06,
      "loss": 0.4342,
      "step": 572
    },
    {
      "epoch": 0.044529064345663665,
      "grad_norm": 0.45562952756881714,
      "learning_rate": 9.777354678271681e-06,
      "loss": 0.5622,
      "step": 573
    },
    {
      "epoch": 0.044606776499844576,
      "grad_norm": 0.7252792716026306,
      "learning_rate": 9.776966117500778e-06,
      "loss": 0.8746,
      "step": 574
    },
    {
      "epoch": 0.04468448865402549,
      "grad_norm": 0.6745438575744629,
      "learning_rate": 9.776577556729873e-06,
      "loss": 0.606,
      "step": 575
    },
    {
      "epoch": 0.04476220080820641,
      "grad_norm": 0.12045750766992569,
      "learning_rate": 9.776188995958968e-06,
      "loss": 0.06,
      "step": 576
    },
    {
      "epoch": 0.04483991296238732,
      "grad_norm": 0.28240805864334106,
      "learning_rate": 9.775800435188065e-06,
      "loss": 0.2367,
      "step": 577
    },
    {
      "epoch": 0.04491762511656823,
      "grad_norm": 0.1608758419752121,
      "learning_rate": 9.77541187441716e-06,
      "loss": 0.1397,
      "step": 578
    },
    {
      "epoch": 0.04499533727074915,
      "grad_norm": 0.2471625953912735,
      "learning_rate": 9.775023313646255e-06,
      "loss": 0.24,
      "step": 579
    },
    {
      "epoch": 0.04507304942493006,
      "grad_norm": 0.1184525340795517,
      "learning_rate": 9.774634752875351e-06,
      "loss": 0.0914,
      "step": 580
    },
    {
      "epoch": 0.04515076157911097,
      "grad_norm": 0.25708574056625366,
      "learning_rate": 9.774246192104446e-06,
      "loss": 0.2047,
      "step": 581
    },
    {
      "epoch": 0.045228473733291884,
      "grad_norm": 0.037319477647542953,
      "learning_rate": 9.773857631333541e-06,
      "loss": 0.0281,
      "step": 582
    },
    {
      "epoch": 0.0453061858874728,
      "grad_norm": 0.21524518728256226,
      "learning_rate": 9.773469070562636e-06,
      "loss": 0.2604,
      "step": 583
    },
    {
      "epoch": 0.045383898041653714,
      "grad_norm": 0.3626478612422943,
      "learning_rate": 9.773080509791733e-06,
      "loss": 0.7208,
      "step": 584
    },
    {
      "epoch": 0.045461610195834626,
      "grad_norm": 0.438870906829834,
      "learning_rate": 9.772691949020828e-06,
      "loss": 0.5436,
      "step": 585
    },
    {
      "epoch": 0.045539322350015544,
      "grad_norm": 0.3217775225639343,
      "learning_rate": 9.772303388249923e-06,
      "loss": 0.2492,
      "step": 586
    },
    {
      "epoch": 0.045617034504196456,
      "grad_norm": 0.20439912378787994,
      "learning_rate": 9.77191482747902e-06,
      "loss": 0.2723,
      "step": 587
    },
    {
      "epoch": 0.04569474665837737,
      "grad_norm": 0.28372645378112793,
      "learning_rate": 9.771526266708114e-06,
      "loss": 0.0988,
      "step": 588
    },
    {
      "epoch": 0.045772458812558287,
      "grad_norm": 0.3053094148635864,
      "learning_rate": 9.771137705937209e-06,
      "loss": 0.7358,
      "step": 589
    },
    {
      "epoch": 0.0458501709667392,
      "grad_norm": 0.2938595712184906,
      "learning_rate": 9.770749145166306e-06,
      "loss": 0.408,
      "step": 590
    },
    {
      "epoch": 0.04592788312092011,
      "grad_norm": 0.14603376388549805,
      "learning_rate": 9.770360584395399e-06,
      "loss": 0.0307,
      "step": 591
    },
    {
      "epoch": 0.04600559527510103,
      "grad_norm": 0.13711968064308167,
      "learning_rate": 9.769972023624496e-06,
      "loss": 0.1113,
      "step": 592
    },
    {
      "epoch": 0.04608330742928194,
      "grad_norm": 0.10637202113866806,
      "learning_rate": 9.76958346285359e-06,
      "loss": 0.0394,
      "step": 593
    },
    {
      "epoch": 0.04616101958346285,
      "grad_norm": 0.1460973024368286,
      "learning_rate": 9.769194902082687e-06,
      "loss": 0.0327,
      "step": 594
    },
    {
      "epoch": 0.04623873173764377,
      "grad_norm": 0.07875348627567291,
      "learning_rate": 9.768806341311782e-06,
      "loss": 0.0477,
      "step": 595
    },
    {
      "epoch": 0.04631644389182468,
      "grad_norm": 0.34724506735801697,
      "learning_rate": 9.768417780540877e-06,
      "loss": 0.2377,
      "step": 596
    },
    {
      "epoch": 0.046394156046005594,
      "grad_norm": 0.39336955547332764,
      "learning_rate": 9.768029219769974e-06,
      "loss": 0.2307,
      "step": 597
    },
    {
      "epoch": 0.046471868200186506,
      "grad_norm": 0.05030813440680504,
      "learning_rate": 9.767640658999069e-06,
      "loss": 0.0289,
      "step": 598
    },
    {
      "epoch": 0.046549580354367424,
      "grad_norm": 0.12850059568881989,
      "learning_rate": 9.767252098228164e-06,
      "loss": 0.115,
      "step": 599
    },
    {
      "epoch": 0.046627292508548336,
      "grad_norm": 0.3612850606441498,
      "learning_rate": 9.76686353745726e-06,
      "loss": 0.2811,
      "step": 600
    },
    {
      "epoch": 0.04670500466272925,
      "grad_norm": 0.27597883343696594,
      "learning_rate": 9.766474976686354e-06,
      "loss": 0.346,
      "step": 601
    },
    {
      "epoch": 0.046782716816910166,
      "grad_norm": 0.18902036547660828,
      "learning_rate": 9.76608641591545e-06,
      "loss": 0.0493,
      "step": 602
    },
    {
      "epoch": 0.04686042897109108,
      "grad_norm": 0.46650809049606323,
      "learning_rate": 9.765697855144545e-06,
      "loss": 0.8991,
      "step": 603
    },
    {
      "epoch": 0.04693814112527199,
      "grad_norm": 0.04732467606663704,
      "learning_rate": 9.76530929437364e-06,
      "loss": 0.0091,
      "step": 604
    },
    {
      "epoch": 0.04701585327945291,
      "grad_norm": 0.1603790521621704,
      "learning_rate": 9.764920733602737e-06,
      "loss": 0.1733,
      "step": 605
    },
    {
      "epoch": 0.04709356543363382,
      "grad_norm": 0.21674248576164246,
      "learning_rate": 9.764532172831832e-06,
      "loss": 0.0894,
      "step": 606
    },
    {
      "epoch": 0.04717127758781473,
      "grad_norm": 0.1830194890499115,
      "learning_rate": 9.764143612060927e-06,
      "loss": 0.1096,
      "step": 607
    },
    {
      "epoch": 0.04724898974199565,
      "grad_norm": 0.09647779166698456,
      "learning_rate": 9.763755051290023e-06,
      "loss": 0.1061,
      "step": 608
    },
    {
      "epoch": 0.04732670189617656,
      "grad_norm": 0.18298232555389404,
      "learning_rate": 9.763366490519118e-06,
      "loss": 0.5754,
      "step": 609
    },
    {
      "epoch": 0.047404414050357474,
      "grad_norm": 0.2447732388973236,
      "learning_rate": 9.762977929748213e-06,
      "loss": 0.2605,
      "step": 610
    },
    {
      "epoch": 0.04748212620453839,
      "grad_norm": 0.05983632057905197,
      "learning_rate": 9.762589368977308e-06,
      "loss": 0.0405,
      "step": 611
    },
    {
      "epoch": 0.047559838358719304,
      "grad_norm": 0.16617351770401,
      "learning_rate": 9.762200808206405e-06,
      "loss": 0.0864,
      "step": 612
    },
    {
      "epoch": 0.047637550512900216,
      "grad_norm": 0.17172393202781677,
      "learning_rate": 9.7618122474355e-06,
      "loss": 0.5505,
      "step": 613
    },
    {
      "epoch": 0.047715262667081135,
      "grad_norm": 0.17949265241622925,
      "learning_rate": 9.761423686664595e-06,
      "loss": 0.2469,
      "step": 614
    },
    {
      "epoch": 0.047792974821262046,
      "grad_norm": 0.15233293175697327,
      "learning_rate": 9.761035125893691e-06,
      "loss": 0.0669,
      "step": 615
    },
    {
      "epoch": 0.04787068697544296,
      "grad_norm": 0.24251344799995422,
      "learning_rate": 9.760646565122786e-06,
      "loss": 0.124,
      "step": 616
    },
    {
      "epoch": 0.04794839912962387,
      "grad_norm": 0.14448101818561554,
      "learning_rate": 9.760258004351881e-06,
      "loss": 0.2203,
      "step": 617
    },
    {
      "epoch": 0.04802611128380479,
      "grad_norm": 0.2625563442707062,
      "learning_rate": 9.759869443580978e-06,
      "loss": 0.2868,
      "step": 618
    },
    {
      "epoch": 0.0481038234379857,
      "grad_norm": 0.24827048182487488,
      "learning_rate": 9.759480882810071e-06,
      "loss": 0.1819,
      "step": 619
    },
    {
      "epoch": 0.04818153559216661,
      "grad_norm": 0.26164710521698,
      "learning_rate": 9.759092322039168e-06,
      "loss": 0.3114,
      "step": 620
    },
    {
      "epoch": 0.04825924774634753,
      "grad_norm": 0.06356875598430634,
      "learning_rate": 9.758703761268263e-06,
      "loss": 0.0428,
      "step": 621
    },
    {
      "epoch": 0.04833695990052844,
      "grad_norm": 0.2351755052804947,
      "learning_rate": 9.758315200497358e-06,
      "loss": 0.2998,
      "step": 622
    },
    {
      "epoch": 0.048414672054709354,
      "grad_norm": 0.17217987775802612,
      "learning_rate": 9.757926639726454e-06,
      "loss": 0.184,
      "step": 623
    },
    {
      "epoch": 0.04849238420889027,
      "grad_norm": 0.2321896255016327,
      "learning_rate": 9.75753807895555e-06,
      "loss": 0.7012,
      "step": 624
    },
    {
      "epoch": 0.048570096363071184,
      "grad_norm": 0.46624502539634705,
      "learning_rate": 9.757149518184646e-06,
      "loss": 0.3021,
      "step": 625
    },
    {
      "epoch": 0.048647808517252096,
      "grad_norm": 0.231881245970726,
      "learning_rate": 9.756760957413741e-06,
      "loss": 0.5966,
      "step": 626
    },
    {
      "epoch": 0.048725520671433015,
      "grad_norm": 0.4488949775695801,
      "learning_rate": 9.756372396642836e-06,
      "loss": 0.0909,
      "step": 627
    },
    {
      "epoch": 0.048803232825613926,
      "grad_norm": 0.4985879957675934,
      "learning_rate": 9.75598383587193e-06,
      "loss": 0.3305,
      "step": 628
    },
    {
      "epoch": 0.04888094497979484,
      "grad_norm": 0.4302189350128174,
      "learning_rate": 9.755595275101026e-06,
      "loss": 0.8859,
      "step": 629
    },
    {
      "epoch": 0.04895865713397576,
      "grad_norm": 0.316815584897995,
      "learning_rate": 9.755206714330122e-06,
      "loss": 0.3788,
      "step": 630
    },
    {
      "epoch": 0.04903636928815667,
      "grad_norm": 0.18424950540065765,
      "learning_rate": 9.754818153559217e-06,
      "loss": 0.1102,
      "step": 631
    },
    {
      "epoch": 0.04911408144233758,
      "grad_norm": 0.22059088945388794,
      "learning_rate": 9.754429592788312e-06,
      "loss": 0.173,
      "step": 632
    },
    {
      "epoch": 0.0491917935965185,
      "grad_norm": 0.1832035332918167,
      "learning_rate": 9.754041032017409e-06,
      "loss": 0.2599,
      "step": 633
    },
    {
      "epoch": 0.04926950575069941,
      "grad_norm": 0.24220235645771027,
      "learning_rate": 9.753652471246504e-06,
      "loss": 0.2514,
      "step": 634
    },
    {
      "epoch": 0.04934721790488032,
      "grad_norm": 0.4040122628211975,
      "learning_rate": 9.753263910475599e-06,
      "loss": 0.3633,
      "step": 635
    },
    {
      "epoch": 0.049424930059061234,
      "grad_norm": 0.14486469328403473,
      "learning_rate": 9.752875349704694e-06,
      "loss": 0.0972,
      "step": 636
    },
    {
      "epoch": 0.04950264221324215,
      "grad_norm": 0.2156839817762375,
      "learning_rate": 9.75248678893379e-06,
      "loss": 0.2293,
      "step": 637
    },
    {
      "epoch": 0.049580354367423064,
      "grad_norm": 0.6476929783821106,
      "learning_rate": 9.752098228162885e-06,
      "loss": 0.3999,
      "step": 638
    },
    {
      "epoch": 0.049658066521603976,
      "grad_norm": 0.20043334364891052,
      "learning_rate": 9.75170966739198e-06,
      "loss": 0.2047,
      "step": 639
    },
    {
      "epoch": 0.049735778675784895,
      "grad_norm": 0.2342623472213745,
      "learning_rate": 9.751321106621077e-06,
      "loss": 0.1562,
      "step": 640
    },
    {
      "epoch": 0.049813490829965806,
      "grad_norm": 0.12905125319957733,
      "learning_rate": 9.750932545850172e-06,
      "loss": 0.1292,
      "step": 641
    },
    {
      "epoch": 0.04989120298414672,
      "grad_norm": 0.250386506319046,
      "learning_rate": 9.750543985079267e-06,
      "loss": 0.0806,
      "step": 642
    },
    {
      "epoch": 0.04996891513832764,
      "grad_norm": 0.19981107115745544,
      "learning_rate": 9.750155424308364e-06,
      "loss": 0.2589,
      "step": 643
    },
    {
      "epoch": 0.05004662729250855,
      "grad_norm": 0.23548109829425812,
      "learning_rate": 9.749766863537457e-06,
      "loss": 0.2205,
      "step": 644
    },
    {
      "epoch": 0.05012433944668946,
      "grad_norm": 0.13757237792015076,
      "learning_rate": 9.749378302766553e-06,
      "loss": 0.1058,
      "step": 645
    },
    {
      "epoch": 0.05020205160087038,
      "grad_norm": 0.47566208243370056,
      "learning_rate": 9.748989741995648e-06,
      "loss": 0.3233,
      "step": 646
    },
    {
      "epoch": 0.05027976375505129,
      "grad_norm": 0.6545426845550537,
      "learning_rate": 9.748601181224743e-06,
      "loss": 0.5256,
      "step": 647
    },
    {
      "epoch": 0.0503574759092322,
      "grad_norm": 0.09671635925769806,
      "learning_rate": 9.74821262045384e-06,
      "loss": 0.136,
      "step": 648
    },
    {
      "epoch": 0.05043518806341312,
      "grad_norm": 0.13413359224796295,
      "learning_rate": 9.747824059682935e-06,
      "loss": 0.1676,
      "step": 649
    },
    {
      "epoch": 0.05051290021759403,
      "grad_norm": 0.11096440255641937,
      "learning_rate": 9.74743549891203e-06,
      "loss": 0.2194,
      "step": 650
    },
    {
      "epoch": 0.050590612371774944,
      "grad_norm": 0.09579383581876755,
      "learning_rate": 9.747046938141127e-06,
      "loss": 0.0731,
      "step": 651
    },
    {
      "epoch": 0.05066832452595586,
      "grad_norm": 0.08996078372001648,
      "learning_rate": 9.746658377370221e-06,
      "loss": 0.1131,
      "step": 652
    },
    {
      "epoch": 0.050746036680136775,
      "grad_norm": 0.22420698404312134,
      "learning_rate": 9.746269816599318e-06,
      "loss": 0.0938,
      "step": 653
    },
    {
      "epoch": 0.050823748834317686,
      "grad_norm": 0.16584201157093048,
      "learning_rate": 9.745881255828411e-06,
      "loss": 0.1134,
      "step": 654
    },
    {
      "epoch": 0.0509014609884986,
      "grad_norm": 0.18706797063350677,
      "learning_rate": 9.745492695057508e-06,
      "loss": 0.0942,
      "step": 655
    },
    {
      "epoch": 0.05097917314267952,
      "grad_norm": 0.3253229260444641,
      "learning_rate": 9.745104134286603e-06,
      "loss": 0.1661,
      "step": 656
    },
    {
      "epoch": 0.05105688529686043,
      "grad_norm": 0.0868016928434372,
      "learning_rate": 9.744715573515698e-06,
      "loss": 0.0266,
      "step": 657
    },
    {
      "epoch": 0.05113459745104134,
      "grad_norm": 0.1479688435792923,
      "learning_rate": 9.744327012744795e-06,
      "loss": 0.1168,
      "step": 658
    },
    {
      "epoch": 0.05121230960522226,
      "grad_norm": 0.024646008387207985,
      "learning_rate": 9.74393845197389e-06,
      "loss": 0.0054,
      "step": 659
    },
    {
      "epoch": 0.05129002175940317,
      "grad_norm": 0.02080746740102768,
      "learning_rate": 9.743549891202984e-06,
      "loss": 0.0298,
      "step": 660
    },
    {
      "epoch": 0.05136773391358408,
      "grad_norm": 0.07984118908643723,
      "learning_rate": 9.743161330432081e-06,
      "loss": 0.0549,
      "step": 661
    },
    {
      "epoch": 0.051445446067765,
      "grad_norm": 0.18445013463497162,
      "learning_rate": 9.742772769661176e-06,
      "loss": 0.3429,
      "step": 662
    },
    {
      "epoch": 0.05152315822194591,
      "grad_norm": 0.40875113010406494,
      "learning_rate": 9.742384208890271e-06,
      "loss": 0.243,
      "step": 663
    },
    {
      "epoch": 0.051600870376126824,
      "grad_norm": 0.17095892131328583,
      "learning_rate": 9.741995648119366e-06,
      "loss": 0.2026,
      "step": 664
    },
    {
      "epoch": 0.05167858253030774,
      "grad_norm": 0.030390290543437004,
      "learning_rate": 9.741607087348463e-06,
      "loss": 0.0133,
      "step": 665
    },
    {
      "epoch": 0.051756294684488655,
      "grad_norm": 0.25176888704299927,
      "learning_rate": 9.741218526577558e-06,
      "loss": 0.3172,
      "step": 666
    },
    {
      "epoch": 0.051834006838669566,
      "grad_norm": 0.10401799529790878,
      "learning_rate": 9.740829965806652e-06,
      "loss": 0.1107,
      "step": 667
    },
    {
      "epoch": 0.051911718992850485,
      "grad_norm": 0.0782061442732811,
      "learning_rate": 9.740441405035749e-06,
      "loss": 0.0512,
      "step": 668
    },
    {
      "epoch": 0.0519894311470314,
      "grad_norm": 0.3134668171405792,
      "learning_rate": 9.740052844264844e-06,
      "loss": 0.4221,
      "step": 669
    },
    {
      "epoch": 0.05206714330121231,
      "grad_norm": 5.912886142730713,
      "learning_rate": 9.739664283493939e-06,
      "loss": 2.3295,
      "step": 670
    },
    {
      "epoch": 0.05214485545539322,
      "grad_norm": 0.058823924511671066,
      "learning_rate": 9.739275722723036e-06,
      "loss": 0.0544,
      "step": 671
    },
    {
      "epoch": 0.05222256760957414,
      "grad_norm": 0.3237478733062744,
      "learning_rate": 9.738887161952129e-06,
      "loss": 0.2145,
      "step": 672
    },
    {
      "epoch": 0.05230027976375505,
      "grad_norm": 0.33346325159072876,
      "learning_rate": 9.738498601181226e-06,
      "loss": 0.2625,
      "step": 673
    },
    {
      "epoch": 0.05237799191793596,
      "grad_norm": 0.10073620826005936,
      "learning_rate": 9.73811004041032e-06,
      "loss": 0.0986,
      "step": 674
    },
    {
      "epoch": 0.05245570407211688,
      "grad_norm": 0.046059876680374146,
      "learning_rate": 9.737721479639415e-06,
      "loss": 0.0165,
      "step": 675
    },
    {
      "epoch": 0.05253341622629779,
      "grad_norm": 0.3427366614341736,
      "learning_rate": 9.737332918868512e-06,
      "loss": 0.3532,
      "step": 676
    },
    {
      "epoch": 0.052611128380478704,
      "grad_norm": 0.25709760189056396,
      "learning_rate": 9.736944358097607e-06,
      "loss": 0.2174,
      "step": 677
    },
    {
      "epoch": 0.05268884053465962,
      "grad_norm": 0.09149991720914841,
      "learning_rate": 9.736555797326702e-06,
      "loss": 0.033,
      "step": 678
    },
    {
      "epoch": 0.052766552688840535,
      "grad_norm": 0.05035584792494774,
      "learning_rate": 9.736167236555799e-06,
      "loss": 0.0271,
      "step": 679
    },
    {
      "epoch": 0.052844264843021446,
      "grad_norm": 0.23060166835784912,
      "learning_rate": 9.735778675784894e-06,
      "loss": 0.2198,
      "step": 680
    },
    {
      "epoch": 0.052921976997202365,
      "grad_norm": 0.6634255647659302,
      "learning_rate": 9.735390115013989e-06,
      "loss": 0.6041,
      "step": 681
    },
    {
      "epoch": 0.05299968915138328,
      "grad_norm": 0.22082555294036865,
      "learning_rate": 9.735001554243084e-06,
      "loss": 0.1664,
      "step": 682
    },
    {
      "epoch": 0.05307740130556419,
      "grad_norm": 0.5724040865898132,
      "learning_rate": 9.73461299347218e-06,
      "loss": 0.4796,
      "step": 683
    },
    {
      "epoch": 0.05315511345974511,
      "grad_norm": 0.34621232748031616,
      "learning_rate": 9.734224432701275e-06,
      "loss": 0.118,
      "step": 684
    },
    {
      "epoch": 0.05323282561392602,
      "grad_norm": 0.36064252257347107,
      "learning_rate": 9.73383587193037e-06,
      "loss": 0.6953,
      "step": 685
    },
    {
      "epoch": 0.05331053776810693,
      "grad_norm": 0.1362021267414093,
      "learning_rate": 9.733447311159467e-06,
      "loss": 0.0729,
      "step": 686
    },
    {
      "epoch": 0.05338824992228785,
      "grad_norm": 0.16904309391975403,
      "learning_rate": 9.733058750388562e-06,
      "loss": 0.1284,
      "step": 687
    },
    {
      "epoch": 0.05346596207646876,
      "grad_norm": 0.37848034501075745,
      "learning_rate": 9.732670189617657e-06,
      "loss": 0.4127,
      "step": 688
    },
    {
      "epoch": 0.05354367423064967,
      "grad_norm": 0.17119529843330383,
      "learning_rate": 9.732281628846753e-06,
      "loss": 0.2027,
      "step": 689
    },
    {
      "epoch": 0.053621386384830584,
      "grad_norm": 0.1462721824645996,
      "learning_rate": 9.731893068075848e-06,
      "loss": 0.1203,
      "step": 690
    },
    {
      "epoch": 0.0536990985390115,
      "grad_norm": 0.21244952082633972,
      "learning_rate": 9.731504507304943e-06,
      "loss": 0.0633,
      "step": 691
    },
    {
      "epoch": 0.053776810693192414,
      "grad_norm": 0.0933450311422348,
      "learning_rate": 9.731115946534038e-06,
      "loss": 0.0262,
      "step": 692
    },
    {
      "epoch": 0.053854522847373326,
      "grad_norm": 0.15061168372631073,
      "learning_rate": 9.730727385763135e-06,
      "loss": 0.0876,
      "step": 693
    },
    {
      "epoch": 0.053932235001554245,
      "grad_norm": 0.17494291067123413,
      "learning_rate": 9.73033882499223e-06,
      "loss": 0.1673,
      "step": 694
    },
    {
      "epoch": 0.05400994715573516,
      "grad_norm": 0.1853131651878357,
      "learning_rate": 9.729950264221325e-06,
      "loss": 0.2032,
      "step": 695
    },
    {
      "epoch": 0.05408765930991607,
      "grad_norm": 0.22492478787899017,
      "learning_rate": 9.729561703450421e-06,
      "loss": 0.206,
      "step": 696
    },
    {
      "epoch": 0.05416537146409699,
      "grad_norm": 0.17014673352241516,
      "learning_rate": 9.729173142679516e-06,
      "loss": 0.1292,
      "step": 697
    },
    {
      "epoch": 0.0542430836182779,
      "grad_norm": 0.18620893359184265,
      "learning_rate": 9.728784581908611e-06,
      "loss": 0.2303,
      "step": 698
    },
    {
      "epoch": 0.05432079577245881,
      "grad_norm": 0.3399886190891266,
      "learning_rate": 9.728396021137708e-06,
      "loss": 0.1447,
      "step": 699
    },
    {
      "epoch": 0.05439850792663973,
      "grad_norm": 0.10832321643829346,
      "learning_rate": 9.728007460366801e-06,
      "loss": 0.0253,
      "step": 700
    },
    {
      "epoch": 0.05447622008082064,
      "grad_norm": 0.3518913984298706,
      "learning_rate": 9.727618899595898e-06,
      "loss": 0.4261,
      "step": 701
    },
    {
      "epoch": 0.05455393223500155,
      "grad_norm": 0.5662758946418762,
      "learning_rate": 9.727230338824993e-06,
      "loss": 0.387,
      "step": 702
    },
    {
      "epoch": 0.05463164438918247,
      "grad_norm": 0.2917744219303131,
      "learning_rate": 9.726841778054088e-06,
      "loss": 0.3355,
      "step": 703
    },
    {
      "epoch": 0.05470935654336338,
      "grad_norm": 0.34324678778648376,
      "learning_rate": 9.726453217283184e-06,
      "loss": 0.1384,
      "step": 704
    },
    {
      "epoch": 0.054787068697544294,
      "grad_norm": 0.09645521640777588,
      "learning_rate": 9.72606465651228e-06,
      "loss": 0.0579,
      "step": 705
    },
    {
      "epoch": 0.05486478085172521,
      "grad_norm": 1.0062060356140137,
      "learning_rate": 9.725676095741374e-06,
      "loss": 0.5063,
      "step": 706
    },
    {
      "epoch": 0.054942493005906125,
      "grad_norm": 0.13791801035404205,
      "learning_rate": 9.72528753497047e-06,
      "loss": 0.1365,
      "step": 707
    },
    {
      "epoch": 0.055020205160087036,
      "grad_norm": 0.3223525285720825,
      "learning_rate": 9.724898974199566e-06,
      "loss": 0.1179,
      "step": 708
    },
    {
      "epoch": 0.05509791731426795,
      "grad_norm": 0.4072260558605194,
      "learning_rate": 9.72451041342866e-06,
      "loss": 0.1245,
      "step": 709
    },
    {
      "epoch": 0.05517562946844887,
      "grad_norm": 0.31921902298927307,
      "learning_rate": 9.724121852657756e-06,
      "loss": 0.6801,
      "step": 710
    },
    {
      "epoch": 0.05525334162262978,
      "grad_norm": 0.21960212290287018,
      "learning_rate": 9.723733291886852e-06,
      "loss": 0.2603,
      "step": 711
    },
    {
      "epoch": 0.05533105377681069,
      "grad_norm": 0.3589567244052887,
      "learning_rate": 9.723344731115947e-06,
      "loss": 0.2281,
      "step": 712
    },
    {
      "epoch": 0.05540876593099161,
      "grad_norm": 0.47034403681755066,
      "learning_rate": 9.722956170345042e-06,
      "loss": 1.1152,
      "step": 713
    },
    {
      "epoch": 0.05548647808517252,
      "grad_norm": 0.16534391045570374,
      "learning_rate": 9.722567609574139e-06,
      "loss": 0.128,
      "step": 714
    },
    {
      "epoch": 0.05556419023935343,
      "grad_norm": 0.15874023735523224,
      "learning_rate": 9.722179048803234e-06,
      "loss": 0.131,
      "step": 715
    },
    {
      "epoch": 0.05564190239353435,
      "grad_norm": 0.05948704108595848,
      "learning_rate": 9.721790488032329e-06,
      "loss": 0.07,
      "step": 716
    },
    {
      "epoch": 0.05571961454771526,
      "grad_norm": 0.1601334661245346,
      "learning_rate": 9.721401927261425e-06,
      "loss": 0.4781,
      "step": 717
    },
    {
      "epoch": 0.055797326701896174,
      "grad_norm": 0.25851982831954956,
      "learning_rate": 9.72101336649052e-06,
      "loss": 0.3248,
      "step": 718
    },
    {
      "epoch": 0.05587503885607709,
      "grad_norm": 0.4738540053367615,
      "learning_rate": 9.720624805719615e-06,
      "loss": 0.2881,
      "step": 719
    },
    {
      "epoch": 0.055952751010258005,
      "grad_norm": 0.3921099603176117,
      "learning_rate": 9.72023624494871e-06,
      "loss": 0.3602,
      "step": 720
    },
    {
      "epoch": 0.056030463164438916,
      "grad_norm": 0.5166429281234741,
      "learning_rate": 9.719847684177807e-06,
      "loss": 0.4709,
      "step": 721
    },
    {
      "epoch": 0.056108175318619835,
      "grad_norm": 0.29328492283821106,
      "learning_rate": 9.719459123406902e-06,
      "loss": 0.4962,
      "step": 722
    },
    {
      "epoch": 0.05618588747280075,
      "grad_norm": 0.2681804597377777,
      "learning_rate": 9.719070562635997e-06,
      "loss": 0.2976,
      "step": 723
    },
    {
      "epoch": 0.05626359962698166,
      "grad_norm": 0.11901400983333588,
      "learning_rate": 9.718682001865093e-06,
      "loss": 0.0785,
      "step": 724
    },
    {
      "epoch": 0.05634131178116258,
      "grad_norm": 0.17642267048358917,
      "learning_rate": 9.718293441094188e-06,
      "loss": 0.1026,
      "step": 725
    },
    {
      "epoch": 0.05641902393534349,
      "grad_norm": 0.4541599452495575,
      "learning_rate": 9.717904880323283e-06,
      "loss": 0.43,
      "step": 726
    },
    {
      "epoch": 0.0564967360895244,
      "grad_norm": 0.24278812110424042,
      "learning_rate": 9.71751631955238e-06,
      "loss": 0.0474,
      "step": 727
    },
    {
      "epoch": 0.05657444824370531,
      "grad_norm": 0.07102510333061218,
      "learning_rate": 9.717127758781473e-06,
      "loss": 0.0797,
      "step": 728
    },
    {
      "epoch": 0.05665216039788623,
      "grad_norm": 0.36917755007743835,
      "learning_rate": 9.71673919801057e-06,
      "loss": 0.087,
      "step": 729
    },
    {
      "epoch": 0.05672987255206714,
      "grad_norm": 0.1441621482372284,
      "learning_rate": 9.716350637239665e-06,
      "loss": 0.1152,
      "step": 730
    },
    {
      "epoch": 0.056807584706248054,
      "grad_norm": 0.4008530378341675,
      "learning_rate": 9.71596207646876e-06,
      "loss": 0.3537,
      "step": 731
    },
    {
      "epoch": 0.05688529686042897,
      "grad_norm": 0.4664740264415741,
      "learning_rate": 9.715573515697856e-06,
      "loss": 0.4558,
      "step": 732
    },
    {
      "epoch": 0.056963009014609885,
      "grad_norm": 0.07907368242740631,
      "learning_rate": 9.715184954926951e-06,
      "loss": 0.0338,
      "step": 733
    },
    {
      "epoch": 0.057040721168790796,
      "grad_norm": 0.020959408953785896,
      "learning_rate": 9.714796394156046e-06,
      "loss": 0.0045,
      "step": 734
    },
    {
      "epoch": 0.057118433322971715,
      "grad_norm": 0.6945550441741943,
      "learning_rate": 9.714407833385143e-06,
      "loss": 0.175,
      "step": 735
    },
    {
      "epoch": 0.05719614547715263,
      "grad_norm": 0.17344102263450623,
      "learning_rate": 9.714019272614238e-06,
      "loss": 0.1157,
      "step": 736
    },
    {
      "epoch": 0.05727385763133354,
      "grad_norm": 0.37116914987564087,
      "learning_rate": 9.713630711843333e-06,
      "loss": 0.3363,
      "step": 737
    },
    {
      "epoch": 0.05735156978551446,
      "grad_norm": 0.17413778603076935,
      "learning_rate": 9.713242151072428e-06,
      "loss": 0.2614,
      "step": 738
    },
    {
      "epoch": 0.05742928193969537,
      "grad_norm": 0.0512884221971035,
      "learning_rate": 9.712853590301524e-06,
      "loss": 0.0241,
      "step": 739
    },
    {
      "epoch": 0.05750699409387628,
      "grad_norm": 0.14384698867797852,
      "learning_rate": 9.71246502953062e-06,
      "loss": 0.1546,
      "step": 740
    },
    {
      "epoch": 0.0575847062480572,
      "grad_norm": 0.1958511918783188,
      "learning_rate": 9.712076468759714e-06,
      "loss": 0.1368,
      "step": 741
    },
    {
      "epoch": 0.05766241840223811,
      "grad_norm": 0.41255664825439453,
      "learning_rate": 9.711687907988811e-06,
      "loss": 0.9106,
      "step": 742
    },
    {
      "epoch": 0.05774013055641902,
      "grad_norm": 0.17298762500286102,
      "learning_rate": 9.711299347217906e-06,
      "loss": 0.4122,
      "step": 743
    },
    {
      "epoch": 0.05781784271059994,
      "grad_norm": 0.1208023652434349,
      "learning_rate": 9.710910786447001e-06,
      "loss": 0.042,
      "step": 744
    },
    {
      "epoch": 0.05789555486478085,
      "grad_norm": 0.13268281519412994,
      "learning_rate": 9.710522225676098e-06,
      "loss": 0.3319,
      "step": 745
    },
    {
      "epoch": 0.057973267018961765,
      "grad_norm": 0.3515789210796356,
      "learning_rate": 9.710133664905192e-06,
      "loss": 0.1664,
      "step": 746
    },
    {
      "epoch": 0.058050979173142676,
      "grad_norm": 0.20810115337371826,
      "learning_rate": 9.709745104134287e-06,
      "loss": 0.1677,
      "step": 747
    },
    {
      "epoch": 0.058128691327323595,
      "grad_norm": 0.10699226707220078,
      "learning_rate": 9.709356543363382e-06,
      "loss": 0.1077,
      "step": 748
    },
    {
      "epoch": 0.05820640348150451,
      "grad_norm": 0.10843868553638458,
      "learning_rate": 9.708967982592479e-06,
      "loss": 0.0964,
      "step": 749
    },
    {
      "epoch": 0.05828411563568542,
      "grad_norm": 0.1649048626422882,
      "learning_rate": 9.708579421821574e-06,
      "loss": 0.1061,
      "step": 750
    },
    {
      "epoch": 0.05836182778986634,
      "grad_norm": 0.1247345432639122,
      "learning_rate": 9.708190861050669e-06,
      "loss": 0.0768,
      "step": 751
    },
    {
      "epoch": 0.05843953994404725,
      "grad_norm": 0.252832293510437,
      "learning_rate": 9.707802300279766e-06,
      "loss": 0.2669,
      "step": 752
    },
    {
      "epoch": 0.05851725209822816,
      "grad_norm": 0.5457659959793091,
      "learning_rate": 9.707413739508859e-06,
      "loss": 0.353,
      "step": 753
    },
    {
      "epoch": 0.05859496425240908,
      "grad_norm": 0.025004062801599503,
      "learning_rate": 9.707025178737955e-06,
      "loss": 0.0239,
      "step": 754
    },
    {
      "epoch": 0.05867267640658999,
      "grad_norm": 0.12658658623695374,
      "learning_rate": 9.70663661796705e-06,
      "loss": 0.0813,
      "step": 755
    },
    {
      "epoch": 0.0587503885607709,
      "grad_norm": 0.21593987941741943,
      "learning_rate": 9.706248057196145e-06,
      "loss": 0.1764,
      "step": 756
    },
    {
      "epoch": 0.05882810071495182,
      "grad_norm": 0.373857706785202,
      "learning_rate": 9.705859496425242e-06,
      "loss": 0.2761,
      "step": 757
    },
    {
      "epoch": 0.05890581286913273,
      "grad_norm": 0.1493130624294281,
      "learning_rate": 9.705470935654337e-06,
      "loss": 0.1005,
      "step": 758
    },
    {
      "epoch": 0.058983525023313645,
      "grad_norm": 0.23566056787967682,
      "learning_rate": 9.705082374883432e-06,
      "loss": 0.2875,
      "step": 759
    },
    {
      "epoch": 0.05906123717749456,
      "grad_norm": 0.2607017159461975,
      "learning_rate": 9.704693814112529e-06,
      "loss": 0.246,
      "step": 760
    },
    {
      "epoch": 0.059138949331675475,
      "grad_norm": 0.17639338970184326,
      "learning_rate": 9.704305253341624e-06,
      "loss": 0.4987,
      "step": 761
    },
    {
      "epoch": 0.05921666148585639,
      "grad_norm": 0.6803033351898193,
      "learning_rate": 9.703916692570718e-06,
      "loss": 0.291,
      "step": 762
    },
    {
      "epoch": 0.0592943736400373,
      "grad_norm": 0.5162284970283508,
      "learning_rate": 9.703528131799813e-06,
      "loss": 0.4385,
      "step": 763
    },
    {
      "epoch": 0.05937208579421822,
      "grad_norm": 0.3867737948894501,
      "learning_rate": 9.70313957102891e-06,
      "loss": 0.3959,
      "step": 764
    },
    {
      "epoch": 0.05944979794839913,
      "grad_norm": 0.1403467357158661,
      "learning_rate": 9.702751010258005e-06,
      "loss": 0.0419,
      "step": 765
    },
    {
      "epoch": 0.05952751010258004,
      "grad_norm": 0.10313908755779266,
      "learning_rate": 9.7023624494871e-06,
      "loss": 0.0982,
      "step": 766
    },
    {
      "epoch": 0.05960522225676096,
      "grad_norm": 0.30175262689590454,
      "learning_rate": 9.701973888716197e-06,
      "loss": 0.1419,
      "step": 767
    },
    {
      "epoch": 0.05968293441094187,
      "grad_norm": 0.2921190857887268,
      "learning_rate": 9.701585327945292e-06,
      "loss": 0.3049,
      "step": 768
    },
    {
      "epoch": 0.05976064656512278,
      "grad_norm": 0.29393643140792847,
      "learning_rate": 9.701196767174387e-06,
      "loss": 0.257,
      "step": 769
    },
    {
      "epoch": 0.0598383587193037,
      "grad_norm": 0.6531646847724915,
      "learning_rate": 9.700808206403483e-06,
      "loss": 0.4261,
      "step": 770
    },
    {
      "epoch": 0.05991607087348461,
      "grad_norm": 0.26455172896385193,
      "learning_rate": 9.700419645632576e-06,
      "loss": 0.6328,
      "step": 771
    },
    {
      "epoch": 0.059993783027665525,
      "grad_norm": 0.16753050684928894,
      "learning_rate": 9.700031084861673e-06,
      "loss": 0.3197,
      "step": 772
    },
    {
      "epoch": 0.06007149518184644,
      "grad_norm": 0.34527403116226196,
      "learning_rate": 9.699642524090768e-06,
      "loss": 0.1359,
      "step": 773
    },
    {
      "epoch": 0.060149207336027355,
      "grad_norm": 0.1817442625761032,
      "learning_rate": 9.699253963319865e-06,
      "loss": 0.1462,
      "step": 774
    },
    {
      "epoch": 0.06022691949020827,
      "grad_norm": 0.3954804539680481,
      "learning_rate": 9.69886540254896e-06,
      "loss": 0.6265,
      "step": 775
    },
    {
      "epoch": 0.060304631644389185,
      "grad_norm": 0.056120697408914566,
      "learning_rate": 9.698476841778055e-06,
      "loss": 0.0136,
      "step": 776
    },
    {
      "epoch": 0.0603823437985701,
      "grad_norm": 0.223948672413826,
      "learning_rate": 9.698088281007151e-06,
      "loss": 0.1082,
      "step": 777
    },
    {
      "epoch": 0.06046005595275101,
      "grad_norm": 0.30250605940818787,
      "learning_rate": 9.697699720236246e-06,
      "loss": 0.6542,
      "step": 778
    },
    {
      "epoch": 0.06053776810693193,
      "grad_norm": 0.2513701319694519,
      "learning_rate": 9.697311159465341e-06,
      "loss": 0.5942,
      "step": 779
    },
    {
      "epoch": 0.06061548026111284,
      "grad_norm": 0.20978626608848572,
      "learning_rate": 9.696922598694438e-06,
      "loss": 0.1958,
      "step": 780
    },
    {
      "epoch": 0.06069319241529375,
      "grad_norm": 0.5239572525024414,
      "learning_rate": 9.696534037923531e-06,
      "loss": 0.1181,
      "step": 781
    },
    {
      "epoch": 0.06077090456947466,
      "grad_norm": 0.09445088356733322,
      "learning_rate": 9.696145477152628e-06,
      "loss": 0.0598,
      "step": 782
    },
    {
      "epoch": 0.06084861672365558,
      "grad_norm": 0.04895385727286339,
      "learning_rate": 9.695756916381723e-06,
      "loss": 0.0143,
      "step": 783
    },
    {
      "epoch": 0.06092632887783649,
      "grad_norm": 0.29656121134757996,
      "learning_rate": 9.695368355610818e-06,
      "loss": 0.2594,
      "step": 784
    },
    {
      "epoch": 0.061004041032017405,
      "grad_norm": 0.04209425672888756,
      "learning_rate": 9.694979794839914e-06,
      "loss": 0.0087,
      "step": 785
    },
    {
      "epoch": 0.06108175318619832,
      "grad_norm": 0.15154404938220978,
      "learning_rate": 9.694591234069009e-06,
      "loss": 0.1215,
      "step": 786
    },
    {
      "epoch": 0.061159465340379235,
      "grad_norm": 0.14733587205410004,
      "learning_rate": 9.694202673298104e-06,
      "loss": 0.0786,
      "step": 787
    },
    {
      "epoch": 0.06123717749456015,
      "grad_norm": 0.09093182533979416,
      "learning_rate": 9.6938141125272e-06,
      "loss": 0.0646,
      "step": 788
    },
    {
      "epoch": 0.061314889648741065,
      "grad_norm": 0.20029675960540771,
      "learning_rate": 9.693425551756296e-06,
      "loss": 0.628,
      "step": 789
    },
    {
      "epoch": 0.06139260180292198,
      "grad_norm": 0.2585026025772095,
      "learning_rate": 9.69303699098539e-06,
      "loss": 0.3166,
      "step": 790
    },
    {
      "epoch": 0.06147031395710289,
      "grad_norm": 0.1683853715658188,
      "learning_rate": 9.692648430214486e-06,
      "loss": 0.4307,
      "step": 791
    },
    {
      "epoch": 0.06154802611128381,
      "grad_norm": 0.22373993694782257,
      "learning_rate": 9.692259869443582e-06,
      "loss": 0.479,
      "step": 792
    },
    {
      "epoch": 0.06162573826546472,
      "grad_norm": 0.08714637905359268,
      "learning_rate": 9.691871308672677e-06,
      "loss": 0.0278,
      "step": 793
    },
    {
      "epoch": 0.06170345041964563,
      "grad_norm": 0.3079690635204315,
      "learning_rate": 9.691482747901772e-06,
      "loss": 0.4652,
      "step": 794
    },
    {
      "epoch": 0.06178116257382655,
      "grad_norm": 0.1573437750339508,
      "learning_rate": 9.691094187130869e-06,
      "loss": 0.0577,
      "step": 795
    },
    {
      "epoch": 0.06185887472800746,
      "grad_norm": 0.22050899267196655,
      "learning_rate": 9.690705626359964e-06,
      "loss": 0.2831,
      "step": 796
    },
    {
      "epoch": 0.06193658688218837,
      "grad_norm": 0.08014920353889465,
      "learning_rate": 9.690317065589059e-06,
      "loss": 0.0375,
      "step": 797
    },
    {
      "epoch": 0.06201429903636929,
      "grad_norm": 0.22494199872016907,
      "learning_rate": 9.689928504818155e-06,
      "loss": 0.4366,
      "step": 798
    },
    {
      "epoch": 0.0620920111905502,
      "grad_norm": 0.15459971129894257,
      "learning_rate": 9.689539944047249e-06,
      "loss": 0.0705,
      "step": 799
    },
    {
      "epoch": 0.062169723344731115,
      "grad_norm": 0.11787553876638412,
      "learning_rate": 9.689151383276345e-06,
      "loss": 0.0336,
      "step": 800
    },
    {
      "epoch": 0.06224743549891203,
      "grad_norm": 0.4048426151275635,
      "learning_rate": 9.68876282250544e-06,
      "loss": 0.1785,
      "step": 801
    },
    {
      "epoch": 0.062325147653092945,
      "grad_norm": 0.448106586933136,
      "learning_rate": 9.688374261734535e-06,
      "loss": 0.1467,
      "step": 802
    },
    {
      "epoch": 0.06240285980727386,
      "grad_norm": 0.18037858605384827,
      "learning_rate": 9.687985700963632e-06,
      "loss": 0.1851,
      "step": 803
    },
    {
      "epoch": 0.06248057196145477,
      "grad_norm": 0.3123800754547119,
      "learning_rate": 9.687597140192727e-06,
      "loss": 0.0927,
      "step": 804
    },
    {
      "epoch": 0.06255828411563569,
      "grad_norm": 0.28268253803253174,
      "learning_rate": 9.687208579421823e-06,
      "loss": 0.2601,
      "step": 805
    },
    {
      "epoch": 0.0626359962698166,
      "grad_norm": 0.6660346984863281,
      "learning_rate": 9.686820018650918e-06,
      "loss": 0.1884,
      "step": 806
    },
    {
      "epoch": 0.06271370842399751,
      "grad_norm": 0.27632009983062744,
      "learning_rate": 9.686431457880013e-06,
      "loss": 0.3241,
      "step": 807
    },
    {
      "epoch": 0.06279142057817842,
      "grad_norm": 0.24207594990730286,
      "learning_rate": 9.68604289710911e-06,
      "loss": 0.1423,
      "step": 808
    },
    {
      "epoch": 0.06286913273235933,
      "grad_norm": 0.24196089804172516,
      "learning_rate": 9.685654336338203e-06,
      "loss": 0.1962,
      "step": 809
    },
    {
      "epoch": 0.06294684488654026,
      "grad_norm": 0.022112403064966202,
      "learning_rate": 9.6852657755673e-06,
      "loss": 0.011,
      "step": 810
    },
    {
      "epoch": 0.06302455704072117,
      "grad_norm": 0.21697577834129333,
      "learning_rate": 9.684877214796395e-06,
      "loss": 0.1568,
      "step": 811
    },
    {
      "epoch": 0.06310226919490208,
      "grad_norm": 0.18856695294380188,
      "learning_rate": 9.68448865402549e-06,
      "loss": 0.1106,
      "step": 812
    },
    {
      "epoch": 0.063179981349083,
      "grad_norm": 0.18151713907718658,
      "learning_rate": 9.684100093254586e-06,
      "loss": 0.1735,
      "step": 813
    },
    {
      "epoch": 0.0632576935032639,
      "grad_norm": 0.22007523477077484,
      "learning_rate": 9.683711532483681e-06,
      "loss": 0.1624,
      "step": 814
    },
    {
      "epoch": 0.06333540565744482,
      "grad_norm": 0.2196701169013977,
      "learning_rate": 9.683322971712776e-06,
      "loss": 0.182,
      "step": 815
    },
    {
      "epoch": 0.06341311781162574,
      "grad_norm": 0.2262018322944641,
      "learning_rate": 9.682934410941873e-06,
      "loss": 0.2446,
      "step": 816
    },
    {
      "epoch": 0.06349082996580666,
      "grad_norm": 0.24048259854316711,
      "learning_rate": 9.682545850170968e-06,
      "loss": 0.2245,
      "step": 817
    },
    {
      "epoch": 0.06356854211998757,
      "grad_norm": 0.24821507930755615,
      "learning_rate": 9.682157289400063e-06,
      "loss": 0.1611,
      "step": 818
    },
    {
      "epoch": 0.06364625427416848,
      "grad_norm": 0.11347034573554993,
      "learning_rate": 9.681768728629158e-06,
      "loss": 0.0912,
      "step": 819
    },
    {
      "epoch": 0.06372396642834939,
      "grad_norm": 0.08766134828329086,
      "learning_rate": 9.681380167858254e-06,
      "loss": 0.0614,
      "step": 820
    },
    {
      "epoch": 0.0638016785825303,
      "grad_norm": 0.25602230429649353,
      "learning_rate": 9.68099160708735e-06,
      "loss": 0.4693,
      "step": 821
    },
    {
      "epoch": 0.06387939073671123,
      "grad_norm": 0.15037643909454346,
      "learning_rate": 9.680603046316444e-06,
      "loss": 0.0546,
      "step": 822
    },
    {
      "epoch": 0.06395710289089214,
      "grad_norm": 0.11140633374452591,
      "learning_rate": 9.680214485545541e-06,
      "loss": 0.1078,
      "step": 823
    },
    {
      "epoch": 0.06403481504507305,
      "grad_norm": 0.6375483870506287,
      "learning_rate": 9.679825924774636e-06,
      "loss": 0.9998,
      "step": 824
    },
    {
      "epoch": 0.06411252719925396,
      "grad_norm": 0.16907231509685516,
      "learning_rate": 9.67943736400373e-06,
      "loss": 0.0959,
      "step": 825
    },
    {
      "epoch": 0.06419023935343487,
      "grad_norm": 0.17194652557373047,
      "learning_rate": 9.679048803232827e-06,
      "loss": 0.2104,
      "step": 826
    },
    {
      "epoch": 0.06426795150761579,
      "grad_norm": 0.08479548245668411,
      "learning_rate": 9.67866024246192e-06,
      "loss": 0.0488,
      "step": 827
    },
    {
      "epoch": 0.0643456636617967,
      "grad_norm": 0.10481109470129013,
      "learning_rate": 9.678271681691017e-06,
      "loss": 0.0874,
      "step": 828
    },
    {
      "epoch": 0.06442337581597762,
      "grad_norm": 0.1437443494796753,
      "learning_rate": 9.677883120920112e-06,
      "loss": 0.1509,
      "step": 829
    },
    {
      "epoch": 0.06450108797015854,
      "grad_norm": 0.24172206223011017,
      "learning_rate": 9.677494560149207e-06,
      "loss": 0.2859,
      "step": 830
    },
    {
      "epoch": 0.06457880012433945,
      "grad_norm": 0.2887585163116455,
      "learning_rate": 9.677105999378304e-06,
      "loss": 0.2586,
      "step": 831
    },
    {
      "epoch": 0.06465651227852036,
      "grad_norm": 0.20759496092796326,
      "learning_rate": 9.676717438607399e-06,
      "loss": 0.116,
      "step": 832
    },
    {
      "epoch": 0.06473422443270127,
      "grad_norm": 0.5069974064826965,
      "learning_rate": 9.676328877836494e-06,
      "loss": 0.3027,
      "step": 833
    },
    {
      "epoch": 0.06481193658688218,
      "grad_norm": 0.09778571873903275,
      "learning_rate": 9.67594031706559e-06,
      "loss": 0.0263,
      "step": 834
    },
    {
      "epoch": 0.06488964874106311,
      "grad_norm": 0.5002213716506958,
      "learning_rate": 9.675551756294685e-06,
      "loss": 0.2152,
      "step": 835
    },
    {
      "epoch": 0.06496736089524402,
      "grad_norm": 0.44680482149124146,
      "learning_rate": 9.675163195523782e-06,
      "loss": 0.3509,
      "step": 836
    },
    {
      "epoch": 0.06504507304942493,
      "grad_norm": 0.23141096532344818,
      "learning_rate": 9.674774634752875e-06,
      "loss": 0.0709,
      "step": 837
    },
    {
      "epoch": 0.06512278520360584,
      "grad_norm": 0.1762724667787552,
      "learning_rate": 9.674386073981972e-06,
      "loss": 0.0411,
      "step": 838
    },
    {
      "epoch": 0.06520049735778675,
      "grad_norm": 0.10293439030647278,
      "learning_rate": 9.673997513211067e-06,
      "loss": 0.2524,
      "step": 839
    },
    {
      "epoch": 0.06527820951196767,
      "grad_norm": 0.09204874187707901,
      "learning_rate": 9.673608952440162e-06,
      "loss": 0.0947,
      "step": 840
    },
    {
      "epoch": 0.06535592166614859,
      "grad_norm": 0.16407112777233124,
      "learning_rate": 9.673220391669258e-06,
      "loss": 0.1185,
      "step": 841
    },
    {
      "epoch": 0.0654336338203295,
      "grad_norm": 0.21506385505199432,
      "learning_rate": 9.672831830898353e-06,
      "loss": 0.1112,
      "step": 842
    },
    {
      "epoch": 0.06551134597451042,
      "grad_norm": 0.1534477174282074,
      "learning_rate": 9.672443270127448e-06,
      "loss": 0.1295,
      "step": 843
    },
    {
      "epoch": 0.06558905812869133,
      "grad_norm": 0.07669033855199814,
      "learning_rate": 9.672054709356545e-06,
      "loss": 0.0454,
      "step": 844
    },
    {
      "epoch": 0.06566677028287224,
      "grad_norm": 0.06559894233942032,
      "learning_rate": 9.67166614858564e-06,
      "loss": 0.0598,
      "step": 845
    },
    {
      "epoch": 0.06574448243705315,
      "grad_norm": 0.21183592081069946,
      "learning_rate": 9.671277587814735e-06,
      "loss": 0.0567,
      "step": 846
    },
    {
      "epoch": 0.06582219459123406,
      "grad_norm": 0.5263762474060059,
      "learning_rate": 9.67088902704383e-06,
      "loss": 0.3211,
      "step": 847
    },
    {
      "epoch": 0.06589990674541499,
      "grad_norm": 0.08776791393756866,
      "learning_rate": 9.670500466272926e-06,
      "loss": 0.0425,
      "step": 848
    },
    {
      "epoch": 0.0659776188995959,
      "grad_norm": 0.2363562136888504,
      "learning_rate": 9.670111905502021e-06,
      "loss": 0.176,
      "step": 849
    },
    {
      "epoch": 0.06605533105377681,
      "grad_norm": 0.1285141259431839,
      "learning_rate": 9.669723344731116e-06,
      "loss": 0.0983,
      "step": 850
    },
    {
      "epoch": 0.06613304320795772,
      "grad_norm": 0.11794309318065643,
      "learning_rate": 9.669334783960213e-06,
      "loss": 0.0457,
      "step": 851
    },
    {
      "epoch": 0.06621075536213863,
      "grad_norm": 0.1933090090751648,
      "learning_rate": 9.668946223189308e-06,
      "loss": 0.1312,
      "step": 852
    },
    {
      "epoch": 0.06628846751631955,
      "grad_norm": 0.13946616649627686,
      "learning_rate": 9.668557662418403e-06,
      "loss": 0.0683,
      "step": 853
    },
    {
      "epoch": 0.06636617967050047,
      "grad_norm": 0.06808517128229141,
      "learning_rate": 9.6681691016475e-06,
      "loss": 0.0422,
      "step": 854
    },
    {
      "epoch": 0.06644389182468138,
      "grad_norm": 0.39577537775039673,
      "learning_rate": 9.667780540876593e-06,
      "loss": 0.6947,
      "step": 855
    },
    {
      "epoch": 0.0665216039788623,
      "grad_norm": 0.1436191350221634,
      "learning_rate": 9.66739198010569e-06,
      "loss": 0.0671,
      "step": 856
    },
    {
      "epoch": 0.06659931613304321,
      "grad_norm": 0.15388061106204987,
      "learning_rate": 9.667003419334784e-06,
      "loss": 0.1025,
      "step": 857
    },
    {
      "epoch": 0.06667702828722412,
      "grad_norm": 0.7212492823600769,
      "learning_rate": 9.66661485856388e-06,
      "loss": 0.5156,
      "step": 858
    },
    {
      "epoch": 0.06675474044140503,
      "grad_norm": 0.3276079297065735,
      "learning_rate": 9.666226297792976e-06,
      "loss": 0.736,
      "step": 859
    },
    {
      "epoch": 0.06683245259558596,
      "grad_norm": 0.2845042049884796,
      "learning_rate": 9.665837737022071e-06,
      "loss": 0.2242,
      "step": 860
    },
    {
      "epoch": 0.06691016474976687,
      "grad_norm": 0.1920301467180252,
      "learning_rate": 9.665449176251166e-06,
      "loss": 0.0432,
      "step": 861
    },
    {
      "epoch": 0.06698787690394778,
      "grad_norm": 0.36761078238487244,
      "learning_rate": 9.665060615480263e-06,
      "loss": 0.2502,
      "step": 862
    },
    {
      "epoch": 0.06706558905812869,
      "grad_norm": 0.2959997057914734,
      "learning_rate": 9.664672054709358e-06,
      "loss": 0.1259,
      "step": 863
    },
    {
      "epoch": 0.0671433012123096,
      "grad_norm": 0.16738583147525787,
      "learning_rate": 9.664283493938452e-06,
      "loss": 0.102,
      "step": 864
    },
    {
      "epoch": 0.06722101336649051,
      "grad_norm": 0.2144533395767212,
      "learning_rate": 9.663894933167547e-06,
      "loss": 0.0529,
      "step": 865
    },
    {
      "epoch": 0.06729872552067143,
      "grad_norm": 0.12738850712776184,
      "learning_rate": 9.663506372396644e-06,
      "loss": 0.0832,
      "step": 866
    },
    {
      "epoch": 0.06737643767485235,
      "grad_norm": 0.7446984648704529,
      "learning_rate": 9.663117811625739e-06,
      "loss": 0.5715,
      "step": 867
    },
    {
      "epoch": 0.06745414982903326,
      "grad_norm": 0.2555656135082245,
      "learning_rate": 9.662729250854834e-06,
      "loss": 0.1032,
      "step": 868
    },
    {
      "epoch": 0.06753186198321418,
      "grad_norm": 0.09472089260816574,
      "learning_rate": 9.66234069008393e-06,
      "loss": 0.0652,
      "step": 869
    },
    {
      "epoch": 0.06760957413739509,
      "grad_norm": 0.2506923973560333,
      "learning_rate": 9.661952129313026e-06,
      "loss": 0.1231,
      "step": 870
    },
    {
      "epoch": 0.067687286291576,
      "grad_norm": 0.15559154748916626,
      "learning_rate": 9.66156356854212e-06,
      "loss": 0.0883,
      "step": 871
    },
    {
      "epoch": 0.06776499844575691,
      "grad_norm": 0.11094421148300171,
      "learning_rate": 9.661175007771217e-06,
      "loss": 0.0488,
      "step": 872
    },
    {
      "epoch": 0.06784271059993784,
      "grad_norm": 0.18922919034957886,
      "learning_rate": 9.660786447000312e-06,
      "loss": 0.3323,
      "step": 873
    },
    {
      "epoch": 0.06792042275411875,
      "grad_norm": 0.12403567880392075,
      "learning_rate": 9.660397886229407e-06,
      "loss": 0.144,
      "step": 874
    },
    {
      "epoch": 0.06799813490829966,
      "grad_norm": 0.15413311123847961,
      "learning_rate": 9.660009325458502e-06,
      "loss": 0.1631,
      "step": 875
    },
    {
      "epoch": 0.06807584706248057,
      "grad_norm": 0.10784520208835602,
      "learning_rate": 9.659620764687599e-06,
      "loss": 0.0927,
      "step": 876
    },
    {
      "epoch": 0.06815355921666148,
      "grad_norm": 0.3939865231513977,
      "learning_rate": 9.659232203916694e-06,
      "loss": 0.5446,
      "step": 877
    },
    {
      "epoch": 0.0682312713708424,
      "grad_norm": 0.24246855080127716,
      "learning_rate": 9.658843643145789e-06,
      "loss": 0.105,
      "step": 878
    },
    {
      "epoch": 0.06830898352502332,
      "grad_norm": 0.1560070961713791,
      "learning_rate": 9.658455082374885e-06,
      "loss": 0.0556,
      "step": 879
    },
    {
      "epoch": 0.06838669567920423,
      "grad_norm": 0.24783246219158173,
      "learning_rate": 9.658066521603978e-06,
      "loss": 0.1846,
      "step": 880
    },
    {
      "epoch": 0.06846440783338514,
      "grad_norm": 0.10783649235963821,
      "learning_rate": 9.657677960833075e-06,
      "loss": 0.1021,
      "step": 881
    },
    {
      "epoch": 0.06854211998756606,
      "grad_norm": 0.23466819524765015,
      "learning_rate": 9.65728940006217e-06,
      "loss": 0.4373,
      "step": 882
    },
    {
      "epoch": 0.06861983214174697,
      "grad_norm": 0.5151912569999695,
      "learning_rate": 9.656900839291265e-06,
      "loss": 0.3508,
      "step": 883
    },
    {
      "epoch": 0.06869754429592788,
      "grad_norm": 0.07631208002567291,
      "learning_rate": 9.656512278520362e-06,
      "loss": 0.0371,
      "step": 884
    },
    {
      "epoch": 0.06877525645010879,
      "grad_norm": 0.13184796273708344,
      "learning_rate": 9.656123717749457e-06,
      "loss": 0.0992,
      "step": 885
    },
    {
      "epoch": 0.06885296860428972,
      "grad_norm": 0.4244503676891327,
      "learning_rate": 9.655735156978552e-06,
      "loss": 0.3192,
      "step": 886
    },
    {
      "epoch": 0.06893068075847063,
      "grad_norm": 0.12891387939453125,
      "learning_rate": 9.655346596207648e-06,
      "loss": 0.0455,
      "step": 887
    },
    {
      "epoch": 0.06900839291265154,
      "grad_norm": 0.1545172780752182,
      "learning_rate": 9.654958035436743e-06,
      "loss": 0.0691,
      "step": 888
    },
    {
      "epoch": 0.06908610506683245,
      "grad_norm": 0.4912440776824951,
      "learning_rate": 9.654569474665838e-06,
      "loss": 0.195,
      "step": 889
    },
    {
      "epoch": 0.06916381722101336,
      "grad_norm": 0.2106555551290512,
      "learning_rate": 9.654180913894933e-06,
      "loss": 0.1603,
      "step": 890
    },
    {
      "epoch": 0.06924152937519427,
      "grad_norm": 0.09465458989143372,
      "learning_rate": 9.65379235312403e-06,
      "loss": 0.0582,
      "step": 891
    },
    {
      "epoch": 0.0693192415293752,
      "grad_norm": 0.3601393401622772,
      "learning_rate": 9.653403792353125e-06,
      "loss": 0.2428,
      "step": 892
    },
    {
      "epoch": 0.06939695368355611,
      "grad_norm": 0.05772323161363602,
      "learning_rate": 9.65301523158222e-06,
      "loss": 0.0372,
      "step": 893
    },
    {
      "epoch": 0.06947466583773702,
      "grad_norm": 0.1405719667673111,
      "learning_rate": 9.652626670811316e-06,
      "loss": 0.1511,
      "step": 894
    },
    {
      "epoch": 0.06955237799191794,
      "grad_norm": 0.20662930607795715,
      "learning_rate": 9.652238110040411e-06,
      "loss": 0.1091,
      "step": 895
    },
    {
      "epoch": 0.06963009014609885,
      "grad_norm": 0.4048295021057129,
      "learning_rate": 9.651849549269506e-06,
      "loss": 0.521,
      "step": 896
    },
    {
      "epoch": 0.06970780230027976,
      "grad_norm": 0.12726162374019623,
      "learning_rate": 9.651460988498603e-06,
      "loss": 0.1627,
      "step": 897
    },
    {
      "epoch": 0.06978551445446068,
      "grad_norm": 0.16569368541240692,
      "learning_rate": 9.651072427727698e-06,
      "loss": 0.1406,
      "step": 898
    },
    {
      "epoch": 0.0698632266086416,
      "grad_norm": 0.18189363181591034,
      "learning_rate": 9.650683866956793e-06,
      "loss": 0.2347,
      "step": 899
    },
    {
      "epoch": 0.06994093876282251,
      "grad_norm": 0.0919327661395073,
      "learning_rate": 9.650295306185888e-06,
      "loss": 0.0819,
      "step": 900
    },
    {
      "epoch": 0.07001865091700342,
      "grad_norm": 0.10062248259782791,
      "learning_rate": 9.649906745414984e-06,
      "loss": 0.0995,
      "step": 901
    },
    {
      "epoch": 0.07009636307118433,
      "grad_norm": 0.3170776665210724,
      "learning_rate": 9.64951818464408e-06,
      "loss": 0.4981,
      "step": 902
    },
    {
      "epoch": 0.07017407522536524,
      "grad_norm": 0.22490157186985016,
      "learning_rate": 9.649129623873174e-06,
      "loss": 0.1078,
      "step": 903
    },
    {
      "epoch": 0.07025178737954615,
      "grad_norm": 0.3981180489063263,
      "learning_rate": 9.64874106310227e-06,
      "loss": 0.2472,
      "step": 904
    },
    {
      "epoch": 0.07032949953372708,
      "grad_norm": 0.20134605467319489,
      "learning_rate": 9.648352502331366e-06,
      "loss": 0.1398,
      "step": 905
    },
    {
      "epoch": 0.07040721168790799,
      "grad_norm": 0.14646293222904205,
      "learning_rate": 9.64796394156046e-06,
      "loss": 0.4673,
      "step": 906
    },
    {
      "epoch": 0.0704849238420889,
      "grad_norm": 0.07276634126901627,
      "learning_rate": 9.647575380789557e-06,
      "loss": 0.0423,
      "step": 907
    },
    {
      "epoch": 0.07056263599626982,
      "grad_norm": 0.19577954709529877,
      "learning_rate": 9.64718682001865e-06,
      "loss": 0.1204,
      "step": 908
    },
    {
      "epoch": 0.07064034815045073,
      "grad_norm": 0.23439303040504456,
      "learning_rate": 9.646798259247747e-06,
      "loss": 0.3109,
      "step": 909
    },
    {
      "epoch": 0.07071806030463164,
      "grad_norm": 0.2951670289039612,
      "learning_rate": 9.646409698476842e-06,
      "loss": 0.3101,
      "step": 910
    },
    {
      "epoch": 0.07079577245881256,
      "grad_norm": 0.28481829166412354,
      "learning_rate": 9.646021137705937e-06,
      "loss": 0.3124,
      "step": 911
    },
    {
      "epoch": 0.07087348461299348,
      "grad_norm": 0.09439921379089355,
      "learning_rate": 9.645632576935034e-06,
      "loss": 0.0157,
      "step": 912
    },
    {
      "epoch": 0.07095119676717439,
      "grad_norm": 0.10379578918218613,
      "learning_rate": 9.645244016164129e-06,
      "loss": 0.0292,
      "step": 913
    },
    {
      "epoch": 0.0710289089213553,
      "grad_norm": 0.16688565909862518,
      "learning_rate": 9.644855455393224e-06,
      "loss": 0.2028,
      "step": 914
    },
    {
      "epoch": 0.07110662107553621,
      "grad_norm": 0.13001300394535065,
      "learning_rate": 9.64446689462232e-06,
      "loss": 0.0361,
      "step": 915
    },
    {
      "epoch": 0.07118433322971712,
      "grad_norm": 0.27491360902786255,
      "learning_rate": 9.644078333851415e-06,
      "loss": 0.3692,
      "step": 916
    },
    {
      "epoch": 0.07126204538389805,
      "grad_norm": 0.6503445506095886,
      "learning_rate": 9.64368977308051e-06,
      "loss": 0.8593,
      "step": 917
    },
    {
      "epoch": 0.07133975753807896,
      "grad_norm": 0.1969061642885208,
      "learning_rate": 9.643301212309605e-06,
      "loss": 0.1145,
      "step": 918
    },
    {
      "epoch": 0.07141746969225987,
      "grad_norm": 0.26644018292427063,
      "learning_rate": 9.642912651538702e-06,
      "loss": 0.2462,
      "step": 919
    },
    {
      "epoch": 0.07149518184644078,
      "grad_norm": 0.12944114208221436,
      "learning_rate": 9.642524090767797e-06,
      "loss": 0.1022,
      "step": 920
    },
    {
      "epoch": 0.0715728940006217,
      "grad_norm": 0.10017705708742142,
      "learning_rate": 9.642135529996892e-06,
      "loss": 0.131,
      "step": 921
    },
    {
      "epoch": 0.0716506061548026,
      "grad_norm": 0.15094968676567078,
      "learning_rate": 9.641746969225988e-06,
      "loss": 0.1533,
      "step": 922
    },
    {
      "epoch": 0.07172831830898352,
      "grad_norm": 0.22271177172660828,
      "learning_rate": 9.641358408455083e-06,
      "loss": 0.2056,
      "step": 923
    },
    {
      "epoch": 0.07180603046316444,
      "grad_norm": 0.2787137031555176,
      "learning_rate": 9.640969847684178e-06,
      "loss": 0.1365,
      "step": 924
    },
    {
      "epoch": 0.07188374261734536,
      "grad_norm": 0.16385409235954285,
      "learning_rate": 9.640581286913275e-06,
      "loss": 0.0643,
      "step": 925
    },
    {
      "epoch": 0.07196145477152627,
      "grad_norm": 0.33154773712158203,
      "learning_rate": 9.64019272614237e-06,
      "loss": 0.1733,
      "step": 926
    },
    {
      "epoch": 0.07203916692570718,
      "grad_norm": 0.14085157215595245,
      "learning_rate": 9.639804165371465e-06,
      "loss": 0.0203,
      "step": 927
    },
    {
      "epoch": 0.07211687907988809,
      "grad_norm": 0.12194482982158661,
      "learning_rate": 9.63941560460056e-06,
      "loss": 0.1162,
      "step": 928
    },
    {
      "epoch": 0.072194591234069,
      "grad_norm": 0.460287481546402,
      "learning_rate": 9.639027043829656e-06,
      "loss": 1.0532,
      "step": 929
    },
    {
      "epoch": 0.07227230338824993,
      "grad_norm": 0.12317561358213425,
      "learning_rate": 9.638638483058751e-06,
      "loss": 0.135,
      "step": 930
    },
    {
      "epoch": 0.07235001554243084,
      "grad_norm": 0.35457393527030945,
      "learning_rate": 9.638249922287846e-06,
      "loss": 0.1004,
      "step": 931
    },
    {
      "epoch": 0.07242772769661175,
      "grad_norm": 0.18562786281108856,
      "learning_rate": 9.637861361516943e-06,
      "loss": 0.0679,
      "step": 932
    },
    {
      "epoch": 0.07250543985079266,
      "grad_norm": 0.19964781403541565,
      "learning_rate": 9.637472800746038e-06,
      "loss": 0.3063,
      "step": 933
    },
    {
      "epoch": 0.07258315200497358,
      "grad_norm": 0.24095207452774048,
      "learning_rate": 9.637084239975133e-06,
      "loss": 0.146,
      "step": 934
    },
    {
      "epoch": 0.07266086415915449,
      "grad_norm": 0.23283852636814117,
      "learning_rate": 9.63669567920423e-06,
      "loss": 0.1388,
      "step": 935
    },
    {
      "epoch": 0.07273857631333541,
      "grad_norm": 0.09960499405860901,
      "learning_rate": 9.636307118433323e-06,
      "loss": 0.04,
      "step": 936
    },
    {
      "epoch": 0.07281628846751632,
      "grad_norm": 0.08648935705423355,
      "learning_rate": 9.63591855766242e-06,
      "loss": 0.0477,
      "step": 937
    },
    {
      "epoch": 0.07289400062169724,
      "grad_norm": 0.17834268510341644,
      "learning_rate": 9.635529996891514e-06,
      "loss": 0.1685,
      "step": 938
    },
    {
      "epoch": 0.07297171277587815,
      "grad_norm": 0.21241608262062073,
      "learning_rate": 9.63514143612061e-06,
      "loss": 0.2366,
      "step": 939
    },
    {
      "epoch": 0.07304942493005906,
      "grad_norm": 0.24528434872627258,
      "learning_rate": 9.634752875349706e-06,
      "loss": 0.0653,
      "step": 940
    },
    {
      "epoch": 0.07312713708423997,
      "grad_norm": 0.22929002344608307,
      "learning_rate": 9.634364314578801e-06,
      "loss": 0.1874,
      "step": 941
    },
    {
      "epoch": 0.07320484923842088,
      "grad_norm": 0.1384369283914566,
      "learning_rate": 9.633975753807896e-06,
      "loss": 0.1004,
      "step": 942
    },
    {
      "epoch": 0.07328256139260181,
      "grad_norm": 0.13419358432292938,
      "learning_rate": 9.633587193036992e-06,
      "loss": 0.07,
      "step": 943
    },
    {
      "epoch": 0.07336027354678272,
      "grad_norm": 0.1157076358795166,
      "learning_rate": 9.633198632266087e-06,
      "loss": 0.1455,
      "step": 944
    },
    {
      "epoch": 0.07343798570096363,
      "grad_norm": 0.10999865084886551,
      "learning_rate": 9.632810071495182e-06,
      "loss": 0.1969,
      "step": 945
    },
    {
      "epoch": 0.07351569785514454,
      "grad_norm": 0.23788288235664368,
      "learning_rate": 9.632421510724277e-06,
      "loss": 0.2339,
      "step": 946
    },
    {
      "epoch": 0.07359341000932546,
      "grad_norm": 0.026291651651263237,
      "learning_rate": 9.632032949953374e-06,
      "loss": 0.0142,
      "step": 947
    },
    {
      "epoch": 0.07367112216350637,
      "grad_norm": 0.07017719745635986,
      "learning_rate": 9.631644389182469e-06,
      "loss": 0.0476,
      "step": 948
    },
    {
      "epoch": 0.07374883431768729,
      "grad_norm": 0.17315563559532166,
      "learning_rate": 9.631255828411564e-06,
      "loss": 0.1137,
      "step": 949
    },
    {
      "epoch": 0.0738265464718682,
      "grad_norm": 0.22763735055923462,
      "learning_rate": 9.63086726764066e-06,
      "loss": 0.231,
      "step": 950
    },
    {
      "epoch": 0.07390425862604912,
      "grad_norm": 0.15381476283073425,
      "learning_rate": 9.630478706869755e-06,
      "loss": 0.1794,
      "step": 951
    },
    {
      "epoch": 0.07398197078023003,
      "grad_norm": 0.31797680258750916,
      "learning_rate": 9.63009014609885e-06,
      "loss": 0.3469,
      "step": 952
    },
    {
      "epoch": 0.07405968293441094,
      "grad_norm": 0.44480252265930176,
      "learning_rate": 9.629701585327947e-06,
      "loss": 0.2564,
      "step": 953
    },
    {
      "epoch": 0.07413739508859185,
      "grad_norm": 0.12031237781047821,
      "learning_rate": 9.62931302455704e-06,
      "loss": 0.0631,
      "step": 954
    },
    {
      "epoch": 0.07421510724277278,
      "grad_norm": 0.2013784497976303,
      "learning_rate": 9.628924463786137e-06,
      "loss": 0.2009,
      "step": 955
    },
    {
      "epoch": 0.07429281939695369,
      "grad_norm": 0.10579852014780045,
      "learning_rate": 9.628535903015232e-06,
      "loss": 0.0912,
      "step": 956
    },
    {
      "epoch": 0.0743705315511346,
      "grad_norm": 0.09832296520471573,
      "learning_rate": 9.628147342244329e-06,
      "loss": 0.0609,
      "step": 957
    },
    {
      "epoch": 0.07444824370531551,
      "grad_norm": 0.06882362067699432,
      "learning_rate": 9.627758781473423e-06,
      "loss": 0.0398,
      "step": 958
    },
    {
      "epoch": 0.07452595585949642,
      "grad_norm": 0.9056088924407959,
      "learning_rate": 9.627370220702518e-06,
      "loss": 0.1328,
      "step": 959
    },
    {
      "epoch": 0.07460366801367734,
      "grad_norm": 0.42334017157554626,
      "learning_rate": 9.626981659931615e-06,
      "loss": 0.5089,
      "step": 960
    },
    {
      "epoch": 0.07468138016785825,
      "grad_norm": 0.14970454573631287,
      "learning_rate": 9.62659309916071e-06,
      "loss": 0.034,
      "step": 961
    },
    {
      "epoch": 0.07475909232203917,
      "grad_norm": 0.15082493424415588,
      "learning_rate": 9.626204538389805e-06,
      "loss": 0.0847,
      "step": 962
    },
    {
      "epoch": 0.07483680447622008,
      "grad_norm": 0.1306019127368927,
      "learning_rate": 9.625815977618902e-06,
      "loss": 0.1301,
      "step": 963
    },
    {
      "epoch": 0.074914516630401,
      "grad_norm": 0.15592321753501892,
      "learning_rate": 9.625427416847995e-06,
      "loss": 0.0482,
      "step": 964
    },
    {
      "epoch": 0.07499222878458191,
      "grad_norm": 0.3618165850639343,
      "learning_rate": 9.625038856077092e-06,
      "loss": 0.2083,
      "step": 965
    },
    {
      "epoch": 0.07506994093876282,
      "grad_norm": 0.09153414517641068,
      "learning_rate": 9.624650295306186e-06,
      "loss": 0.0901,
      "step": 966
    },
    {
      "epoch": 0.07514765309294373,
      "grad_norm": 0.0869189202785492,
      "learning_rate": 9.624261734535281e-06,
      "loss": 0.0137,
      "step": 967
    },
    {
      "epoch": 0.07522536524712466,
      "grad_norm": 0.2653222978115082,
      "learning_rate": 9.623873173764378e-06,
      "loss": 0.1287,
      "step": 968
    },
    {
      "epoch": 0.07530307740130557,
      "grad_norm": 0.1886783093214035,
      "learning_rate": 9.623484612993473e-06,
      "loss": 0.2114,
      "step": 969
    },
    {
      "epoch": 0.07538078955548648,
      "grad_norm": 0.2694031298160553,
      "learning_rate": 9.623096052222568e-06,
      "loss": 0.2546,
      "step": 970
    },
    {
      "epoch": 0.07545850170966739,
      "grad_norm": 0.21026453375816345,
      "learning_rate": 9.622707491451665e-06,
      "loss": 0.1656,
      "step": 971
    },
    {
      "epoch": 0.0755362138638483,
      "grad_norm": 0.26217368245124817,
      "learning_rate": 9.62231893068076e-06,
      "loss": 0.2574,
      "step": 972
    },
    {
      "epoch": 0.07561392601802921,
      "grad_norm": 0.059534769505262375,
      "learning_rate": 9.621930369909855e-06,
      "loss": 0.028,
      "step": 973
    },
    {
      "epoch": 0.07569163817221014,
      "grad_norm": 0.19590865075588226,
      "learning_rate": 9.62154180913895e-06,
      "loss": 0.165,
      "step": 974
    },
    {
      "epoch": 0.07576935032639105,
      "grad_norm": 0.2830063998699188,
      "learning_rate": 9.621153248368046e-06,
      "loss": 0.1208,
      "step": 975
    },
    {
      "epoch": 0.07584706248057196,
      "grad_norm": 0.2637622356414795,
      "learning_rate": 9.620764687597141e-06,
      "loss": 0.0726,
      "step": 976
    },
    {
      "epoch": 0.07592477463475288,
      "grad_norm": 0.43537217378616333,
      "learning_rate": 9.620376126826236e-06,
      "loss": 0.3728,
      "step": 977
    },
    {
      "epoch": 0.07600248678893379,
      "grad_norm": 0.1912890076637268,
      "learning_rate": 9.619987566055333e-06,
      "loss": 0.0729,
      "step": 978
    },
    {
      "epoch": 0.0760801989431147,
      "grad_norm": 0.08234476298093796,
      "learning_rate": 9.619599005284428e-06,
      "loss": 0.1044,
      "step": 979
    },
    {
      "epoch": 0.07615791109729561,
      "grad_norm": 0.28106367588043213,
      "learning_rate": 9.619210444513523e-06,
      "loss": 0.3042,
      "step": 980
    },
    {
      "epoch": 0.07623562325147654,
      "grad_norm": 0.5018036961555481,
      "learning_rate": 9.61882188374262e-06,
      "loss": 0.4356,
      "step": 981
    },
    {
      "epoch": 0.07631333540565745,
      "grad_norm": 0.1776895970106125,
      "learning_rate": 9.618433322971712e-06,
      "loss": 0.197,
      "step": 982
    },
    {
      "epoch": 0.07639104755983836,
      "grad_norm": 0.08370494097471237,
      "learning_rate": 9.618044762200809e-06,
      "loss": 0.046,
      "step": 983
    },
    {
      "epoch": 0.07646875971401927,
      "grad_norm": 0.5490767955780029,
      "learning_rate": 9.617656201429904e-06,
      "loss": 0.2835,
      "step": 984
    },
    {
      "epoch": 0.07654647186820018,
      "grad_norm": 0.08477316796779633,
      "learning_rate": 9.617267640658999e-06,
      "loss": 0.0344,
      "step": 985
    },
    {
      "epoch": 0.0766241840223811,
      "grad_norm": 0.1496051400899887,
      "learning_rate": 9.616879079888096e-06,
      "loss": 0.0936,
      "step": 986
    },
    {
      "epoch": 0.07670189617656202,
      "grad_norm": 0.33635425567626953,
      "learning_rate": 9.61649051911719e-06,
      "loss": 0.5901,
      "step": 987
    },
    {
      "epoch": 0.07677960833074293,
      "grad_norm": 0.041585516184568405,
      "learning_rate": 9.616101958346287e-06,
      "loss": 0.0623,
      "step": 988
    },
    {
      "epoch": 0.07685732048492384,
      "grad_norm": 0.2199118286371231,
      "learning_rate": 9.615713397575382e-06,
      "loss": 0.201,
      "step": 989
    },
    {
      "epoch": 0.07693503263910476,
      "grad_norm": 0.1962323635816574,
      "learning_rate": 9.615324836804477e-06,
      "loss": 0.1262,
      "step": 990
    },
    {
      "epoch": 0.07701274479328567,
      "grad_norm": 0.20734316110610962,
      "learning_rate": 9.614936276033574e-06,
      "loss": 0.2555,
      "step": 991
    },
    {
      "epoch": 0.07709045694746658,
      "grad_norm": 0.19665060937404633,
      "learning_rate": 9.614547715262667e-06,
      "loss": 0.1622,
      "step": 992
    },
    {
      "epoch": 0.07716816910164749,
      "grad_norm": 0.10367929190397263,
      "learning_rate": 9.614159154491764e-06,
      "loss": 0.1459,
      "step": 993
    },
    {
      "epoch": 0.07724588125582842,
      "grad_norm": 0.08088721334934235,
      "learning_rate": 9.613770593720859e-06,
      "loss": 0.0618,
      "step": 994
    },
    {
      "epoch": 0.07732359341000933,
      "grad_norm": 0.1834881752729416,
      "learning_rate": 9.613382032949954e-06,
      "loss": 0.22,
      "step": 995
    },
    {
      "epoch": 0.07740130556419024,
      "grad_norm": 0.2261345386505127,
      "learning_rate": 9.61299347217905e-06,
      "loss": 0.1459,
      "step": 996
    },
    {
      "epoch": 0.07747901771837115,
      "grad_norm": 0.19801972806453705,
      "learning_rate": 9.612604911408145e-06,
      "loss": 0.1129,
      "step": 997
    },
    {
      "epoch": 0.07755672987255206,
      "grad_norm": 0.032211583107709885,
      "learning_rate": 9.61221635063724e-06,
      "loss": 0.0124,
      "step": 998
    },
    {
      "epoch": 0.07763444202673297,
      "grad_norm": 0.20539286732673645,
      "learning_rate": 9.611827789866337e-06,
      "loss": 0.0825,
      "step": 999
    },
    {
      "epoch": 0.0777121541809139,
      "grad_norm": 0.20237456262111664,
      "learning_rate": 9.611439229095432e-06,
      "loss": 0.1142,
      "step": 1000
    },
    {
      "epoch": 0.07778986633509481,
      "grad_norm": 0.1803024560213089,
      "learning_rate": 9.611050668324527e-06,
      "loss": 0.1416,
      "step": 1001
    },
    {
      "epoch": 0.07786757848927572,
      "grad_norm": 0.2117224633693695,
      "learning_rate": 9.610662107553622e-06,
      "loss": 0.1493,
      "step": 1002
    },
    {
      "epoch": 0.07794529064345664,
      "grad_norm": 0.533492922782898,
      "learning_rate": 9.610273546782718e-06,
      "loss": 0.5786,
      "step": 1003
    },
    {
      "epoch": 0.07802300279763755,
      "grad_norm": 0.1323065310716629,
      "learning_rate": 9.609884986011813e-06,
      "loss": 0.0876,
      "step": 1004
    },
    {
      "epoch": 0.07810071495181846,
      "grad_norm": 0.07348300516605377,
      "learning_rate": 9.609496425240908e-06,
      "loss": 0.0445,
      "step": 1005
    },
    {
      "epoch": 0.07817842710599938,
      "grad_norm": 0.16433921456336975,
      "learning_rate": 9.609107864470005e-06,
      "loss": 0.1749,
      "step": 1006
    },
    {
      "epoch": 0.0782561392601803,
      "grad_norm": 0.10730816423892975,
      "learning_rate": 9.608719303699098e-06,
      "loss": 0.0411,
      "step": 1007
    },
    {
      "epoch": 0.07833385141436121,
      "grad_norm": 0.2955557703971863,
      "learning_rate": 9.608330742928195e-06,
      "loss": 0.106,
      "step": 1008
    },
    {
      "epoch": 0.07841156356854212,
      "grad_norm": 0.18071813881397247,
      "learning_rate": 9.60794218215729e-06,
      "loss": 0.153,
      "step": 1009
    },
    {
      "epoch": 0.07848927572272303,
      "grad_norm": 0.14910568296909332,
      "learning_rate": 9.607553621386385e-06,
      "loss": 0.0371,
      "step": 1010
    },
    {
      "epoch": 0.07856698787690394,
      "grad_norm": 0.2466442883014679,
      "learning_rate": 9.607165060615481e-06,
      "loss": 0.2141,
      "step": 1011
    },
    {
      "epoch": 0.07864470003108485,
      "grad_norm": 0.361972451210022,
      "learning_rate": 9.606776499844576e-06,
      "loss": 0.4211,
      "step": 1012
    },
    {
      "epoch": 0.07872241218526578,
      "grad_norm": 0.17193461954593658,
      "learning_rate": 9.606387939073671e-06,
      "loss": 0.1104,
      "step": 1013
    },
    {
      "epoch": 0.07880012433944669,
      "grad_norm": 0.17228905856609344,
      "learning_rate": 9.605999378302768e-06,
      "loss": 0.1889,
      "step": 1014
    },
    {
      "epoch": 0.0788778364936276,
      "grad_norm": 0.20157115161418915,
      "learning_rate": 9.605610817531863e-06,
      "loss": 0.1425,
      "step": 1015
    },
    {
      "epoch": 0.07895554864780852,
      "grad_norm": 0.2378450483083725,
      "learning_rate": 9.605222256760958e-06,
      "loss": 0.1511,
      "step": 1016
    },
    {
      "epoch": 0.07903326080198943,
      "grad_norm": 0.07124452292919159,
      "learning_rate": 9.604833695990053e-06,
      "loss": 0.0503,
      "step": 1017
    },
    {
      "epoch": 0.07911097295617034,
      "grad_norm": 0.4234614670276642,
      "learning_rate": 9.60444513521915e-06,
      "loss": 0.3892,
      "step": 1018
    },
    {
      "epoch": 0.07918868511035126,
      "grad_norm": 0.4306228458881378,
      "learning_rate": 9.604056574448244e-06,
      "loss": 0.0508,
      "step": 1019
    },
    {
      "epoch": 0.07926639726453218,
      "grad_norm": 0.16916784644126892,
      "learning_rate": 9.60366801367734e-06,
      "loss": 0.1931,
      "step": 1020
    },
    {
      "epoch": 0.07934410941871309,
      "grad_norm": 0.15957416594028473,
      "learning_rate": 9.603279452906436e-06,
      "loss": 0.0758,
      "step": 1021
    },
    {
      "epoch": 0.079421821572894,
      "grad_norm": 1.4484388828277588,
      "learning_rate": 9.60289089213553e-06,
      "loss": 0.4963,
      "step": 1022
    },
    {
      "epoch": 0.07949953372707491,
      "grad_norm": 0.09964759647846222,
      "learning_rate": 9.602502331364626e-06,
      "loss": 0.0929,
      "step": 1023
    },
    {
      "epoch": 0.07957724588125582,
      "grad_norm": 0.35357335209846497,
      "learning_rate": 9.602113770593722e-06,
      "loss": 0.4453,
      "step": 1024
    },
    {
      "epoch": 0.07965495803543675,
      "grad_norm": 0.17724162340164185,
      "learning_rate": 9.601725209822817e-06,
      "loss": 0.1144,
      "step": 1025
    },
    {
      "epoch": 0.07973267018961766,
      "grad_norm": 0.20493607223033905,
      "learning_rate": 9.601336649051912e-06,
      "loss": 0.2384,
      "step": 1026
    },
    {
      "epoch": 0.07981038234379857,
      "grad_norm": 0.30057308077812195,
      "learning_rate": 9.600948088281007e-06,
      "loss": 0.4281,
      "step": 1027
    },
    {
      "epoch": 0.07988809449797948,
      "grad_norm": 0.17183129489421844,
      "learning_rate": 9.600559527510104e-06,
      "loss": 0.0468,
      "step": 1028
    },
    {
      "epoch": 0.0799658066521604,
      "grad_norm": 0.07103853672742844,
      "learning_rate": 9.600170966739199e-06,
      "loss": 0.0658,
      "step": 1029
    },
    {
      "epoch": 0.08004351880634131,
      "grad_norm": 0.16742853820323944,
      "learning_rate": 9.599782405968294e-06,
      "loss": 0.0989,
      "step": 1030
    },
    {
      "epoch": 0.08012123096052222,
      "grad_norm": 0.274494469165802,
      "learning_rate": 9.59939384519739e-06,
      "loss": 0.2818,
      "step": 1031
    },
    {
      "epoch": 0.08019894311470314,
      "grad_norm": 0.18364264070987701,
      "learning_rate": 9.599005284426485e-06,
      "loss": 0.2429,
      "step": 1032
    },
    {
      "epoch": 0.08027665526888406,
      "grad_norm": 0.25698885321617126,
      "learning_rate": 9.59861672365558e-06,
      "loss": 0.1761,
      "step": 1033
    },
    {
      "epoch": 0.08035436742306497,
      "grad_norm": 0.15792004764080048,
      "learning_rate": 9.598228162884677e-06,
      "loss": 0.1188,
      "step": 1034
    },
    {
      "epoch": 0.08043207957724588,
      "grad_norm": 0.1939055174589157,
      "learning_rate": 9.59783960211377e-06,
      "loss": 0.1278,
      "step": 1035
    },
    {
      "epoch": 0.08050979173142679,
      "grad_norm": 0.09857974946498871,
      "learning_rate": 9.597451041342867e-06,
      "loss": 0.1133,
      "step": 1036
    },
    {
      "epoch": 0.0805875038856077,
      "grad_norm": 0.18944142758846283,
      "learning_rate": 9.597062480571962e-06,
      "loss": 0.111,
      "step": 1037
    },
    {
      "epoch": 0.08066521603978863,
      "grad_norm": 0.41412273049354553,
      "learning_rate": 9.596673919801057e-06,
      "loss": 0.5568,
      "step": 1038
    },
    {
      "epoch": 0.08074292819396954,
      "grad_norm": 0.8084129691123962,
      "learning_rate": 9.596285359030153e-06,
      "loss": 0.48,
      "step": 1039
    },
    {
      "epoch": 0.08082064034815045,
      "grad_norm": 0.28537386655807495,
      "learning_rate": 9.595896798259248e-06,
      "loss": 0.2455,
      "step": 1040
    },
    {
      "epoch": 0.08089835250233136,
      "grad_norm": 0.13179977238178253,
      "learning_rate": 9.595508237488343e-06,
      "loss": 0.071,
      "step": 1041
    },
    {
      "epoch": 0.08097606465651228,
      "grad_norm": 0.16170229017734528,
      "learning_rate": 9.59511967671744e-06,
      "loss": 0.0415,
      "step": 1042
    },
    {
      "epoch": 0.08105377681069319,
      "grad_norm": 0.3708786964416504,
      "learning_rate": 9.594731115946535e-06,
      "loss": 0.2492,
      "step": 1043
    },
    {
      "epoch": 0.08113148896487411,
      "grad_norm": 0.19171293079853058,
      "learning_rate": 9.59434255517563e-06,
      "loss": 0.254,
      "step": 1044
    },
    {
      "epoch": 0.08120920111905502,
      "grad_norm": 0.0562136210501194,
      "learning_rate": 9.593953994404725e-06,
      "loss": 0.0149,
      "step": 1045
    },
    {
      "epoch": 0.08128691327323594,
      "grad_norm": 0.2319832146167755,
      "learning_rate": 9.593565433633821e-06,
      "loss": 0.17,
      "step": 1046
    },
    {
      "epoch": 0.08136462542741685,
      "grad_norm": 0.06901875883340836,
      "learning_rate": 9.593176872862916e-06,
      "loss": 0.0173,
      "step": 1047
    },
    {
      "epoch": 0.08144233758159776,
      "grad_norm": 0.4518153667449951,
      "learning_rate": 9.592788312092011e-06,
      "loss": 0.895,
      "step": 1048
    },
    {
      "epoch": 0.08152004973577867,
      "grad_norm": 0.037640515714883804,
      "learning_rate": 9.592399751321108e-06,
      "loss": 0.0531,
      "step": 1049
    },
    {
      "epoch": 0.08159776188995958,
      "grad_norm": 0.32491180300712585,
      "learning_rate": 9.592011190550203e-06,
      "loss": 0.1067,
      "step": 1050
    },
    {
      "epoch": 0.08167547404414051,
      "grad_norm": 0.1001572385430336,
      "learning_rate": 9.591622629779298e-06,
      "loss": 0.0739,
      "step": 1051
    },
    {
      "epoch": 0.08175318619832142,
      "grad_norm": 0.4152728021144867,
      "learning_rate": 9.591234069008395e-06,
      "loss": 0.2534,
      "step": 1052
    },
    {
      "epoch": 0.08183089835250233,
      "grad_norm": 0.19484777748584747,
      "learning_rate": 9.59084550823749e-06,
      "loss": 0.3076,
      "step": 1053
    },
    {
      "epoch": 0.08190861050668324,
      "grad_norm": 0.5744126439094543,
      "learning_rate": 9.590456947466584e-06,
      "loss": 0.2996,
      "step": 1054
    },
    {
      "epoch": 0.08198632266086416,
      "grad_norm": 0.05560539290308952,
      "learning_rate": 9.59006838669568e-06,
      "loss": 0.0363,
      "step": 1055
    },
    {
      "epoch": 0.08206403481504507,
      "grad_norm": 0.14691361784934998,
      "learning_rate": 9.589679825924776e-06,
      "loss": 0.1158,
      "step": 1056
    },
    {
      "epoch": 0.08214174696922599,
      "grad_norm": 0.06560193747282028,
      "learning_rate": 9.589291265153871e-06,
      "loss": 0.0461,
      "step": 1057
    },
    {
      "epoch": 0.0822194591234069,
      "grad_norm": 0.0936795175075531,
      "learning_rate": 9.588902704382966e-06,
      "loss": 0.0632,
      "step": 1058
    },
    {
      "epoch": 0.08229717127758782,
      "grad_norm": 0.17983557283878326,
      "learning_rate": 9.588514143612063e-06,
      "loss": 0.0399,
      "step": 1059
    },
    {
      "epoch": 0.08237488343176873,
      "grad_norm": 0.11061001569032669,
      "learning_rate": 9.588125582841157e-06,
      "loss": 0.0808,
      "step": 1060
    },
    {
      "epoch": 0.08245259558594964,
      "grad_norm": 0.073145292699337,
      "learning_rate": 9.587737022070252e-06,
      "loss": 0.0786,
      "step": 1061
    },
    {
      "epoch": 0.08253030774013055,
      "grad_norm": 0.3661814033985138,
      "learning_rate": 9.587348461299349e-06,
      "loss": 0.0795,
      "step": 1062
    },
    {
      "epoch": 0.08260801989431148,
      "grad_norm": 0.41648977994918823,
      "learning_rate": 9.586959900528442e-06,
      "loss": 0.4534,
      "step": 1063
    },
    {
      "epoch": 0.08268573204849239,
      "grad_norm": 0.1198042780160904,
      "learning_rate": 9.586571339757539e-06,
      "loss": 0.0954,
      "step": 1064
    },
    {
      "epoch": 0.0827634442026733,
      "grad_norm": 0.10771747678518295,
      "learning_rate": 9.586182778986634e-06,
      "loss": 0.042,
      "step": 1065
    },
    {
      "epoch": 0.08284115635685421,
      "grad_norm": 0.112497478723526,
      "learning_rate": 9.585794218215729e-06,
      "loss": 0.0577,
      "step": 1066
    },
    {
      "epoch": 0.08291886851103512,
      "grad_norm": 0.5533702969551086,
      "learning_rate": 9.585405657444826e-06,
      "loss": 0.4094,
      "step": 1067
    },
    {
      "epoch": 0.08299658066521604,
      "grad_norm": 0.17759914696216583,
      "learning_rate": 9.58501709667392e-06,
      "loss": 0.1281,
      "step": 1068
    },
    {
      "epoch": 0.08307429281939695,
      "grad_norm": 0.11251849681138992,
      "learning_rate": 9.584628535903015e-06,
      "loss": 0.2079,
      "step": 1069
    },
    {
      "epoch": 0.08315200497357787,
      "grad_norm": 0.35233932733535767,
      "learning_rate": 9.584239975132112e-06,
      "loss": 0.322,
      "step": 1070
    },
    {
      "epoch": 0.08322971712775878,
      "grad_norm": 0.3491470515727997,
      "learning_rate": 9.583851414361207e-06,
      "loss": 0.4425,
      "step": 1071
    },
    {
      "epoch": 0.0833074292819397,
      "grad_norm": 0.12149152159690857,
      "learning_rate": 9.583462853590302e-06,
      "loss": 0.0925,
      "step": 1072
    },
    {
      "epoch": 0.08338514143612061,
      "grad_norm": 0.289120078086853,
      "learning_rate": 9.583074292819397e-06,
      "loss": 0.2068,
      "step": 1073
    },
    {
      "epoch": 0.08346285359030152,
      "grad_norm": 0.12904833257198334,
      "learning_rate": 9.582685732048494e-06,
      "loss": 0.0545,
      "step": 1074
    },
    {
      "epoch": 0.08354056574448243,
      "grad_norm": 0.21513740718364716,
      "learning_rate": 9.582297171277589e-06,
      "loss": 0.452,
      "step": 1075
    },
    {
      "epoch": 0.08361827789866336,
      "grad_norm": 0.10676407814025879,
      "learning_rate": 9.581908610506683e-06,
      "loss": 0.0878,
      "step": 1076
    },
    {
      "epoch": 0.08369599005284427,
      "grad_norm": 0.19318822026252747,
      "learning_rate": 9.58152004973578e-06,
      "loss": 0.2378,
      "step": 1077
    },
    {
      "epoch": 0.08377370220702518,
      "grad_norm": 0.31059563159942627,
      "learning_rate": 9.581131488964875e-06,
      "loss": 0.1621,
      "step": 1078
    },
    {
      "epoch": 0.08385141436120609,
      "grad_norm": 0.059523068368434906,
      "learning_rate": 9.58074292819397e-06,
      "loss": 0.0191,
      "step": 1079
    },
    {
      "epoch": 0.083929126515387,
      "grad_norm": 0.26239317655563354,
      "learning_rate": 9.580354367423067e-06,
      "loss": 0.0925,
      "step": 1080
    },
    {
      "epoch": 0.08400683866956792,
      "grad_norm": 0.08543412387371063,
      "learning_rate": 9.579965806652162e-06,
      "loss": 0.0599,
      "step": 1081
    },
    {
      "epoch": 0.08408455082374884,
      "grad_norm": 0.1074119359254837,
      "learning_rate": 9.579577245881257e-06,
      "loss": 0.0682,
      "step": 1082
    },
    {
      "epoch": 0.08416226297792975,
      "grad_norm": 0.10446351021528244,
      "learning_rate": 9.579188685110352e-06,
      "loss": 0.0329,
      "step": 1083
    },
    {
      "epoch": 0.08423997513211066,
      "grad_norm": 0.20542466640472412,
      "learning_rate": 9.578800124339448e-06,
      "loss": 0.3508,
      "step": 1084
    },
    {
      "epoch": 0.08431768728629158,
      "grad_norm": 0.4007205665111542,
      "learning_rate": 9.578411563568543e-06,
      "loss": 0.3595,
      "step": 1085
    },
    {
      "epoch": 0.08439539944047249,
      "grad_norm": 0.20887082815170288,
      "learning_rate": 9.578023002797638e-06,
      "loss": 0.1227,
      "step": 1086
    },
    {
      "epoch": 0.0844731115946534,
      "grad_norm": 0.08766256272792816,
      "learning_rate": 9.577634442026735e-06,
      "loss": 0.0665,
      "step": 1087
    },
    {
      "epoch": 0.08455082374883431,
      "grad_norm": 0.2779410481452942,
      "learning_rate": 9.57724588125583e-06,
      "loss": 0.4777,
      "step": 1088
    },
    {
      "epoch": 0.08462853590301524,
      "grad_norm": 0.19125887751579285,
      "learning_rate": 9.576857320484925e-06,
      "loss": 0.218,
      "step": 1089
    },
    {
      "epoch": 0.08470624805719615,
      "grad_norm": 0.15063689649105072,
      "learning_rate": 9.576468759714021e-06,
      "loss": 0.1425,
      "step": 1090
    },
    {
      "epoch": 0.08478396021137706,
      "grad_norm": 0.08249035477638245,
      "learning_rate": 9.576080198943114e-06,
      "loss": 0.0437,
      "step": 1091
    },
    {
      "epoch": 0.08486167236555797,
      "grad_norm": 0.20261195302009583,
      "learning_rate": 9.575691638172211e-06,
      "loss": 0.2298,
      "step": 1092
    },
    {
      "epoch": 0.08493938451973888,
      "grad_norm": 0.24682651460170746,
      "learning_rate": 9.575303077401306e-06,
      "loss": 0.0684,
      "step": 1093
    },
    {
      "epoch": 0.0850170966739198,
      "grad_norm": 0.2667628824710846,
      "learning_rate": 9.574914516630401e-06,
      "loss": 0.2535,
      "step": 1094
    },
    {
      "epoch": 0.08509480882810072,
      "grad_norm": 0.8438614010810852,
      "learning_rate": 9.574525955859498e-06,
      "loss": 0.293,
      "step": 1095
    },
    {
      "epoch": 0.08517252098228163,
      "grad_norm": 0.12444233149290085,
      "learning_rate": 9.574137395088593e-06,
      "loss": 0.0709,
      "step": 1096
    },
    {
      "epoch": 0.08525023313646254,
      "grad_norm": 0.08692079782485962,
      "learning_rate": 9.573748834317688e-06,
      "loss": 0.027,
      "step": 1097
    },
    {
      "epoch": 0.08532794529064346,
      "grad_norm": 0.38211798667907715,
      "learning_rate": 9.573360273546784e-06,
      "loss": 0.1187,
      "step": 1098
    },
    {
      "epoch": 0.08540565744482437,
      "grad_norm": 0.7667893171310425,
      "learning_rate": 9.57297171277588e-06,
      "loss": 0.547,
      "step": 1099
    },
    {
      "epoch": 0.08548336959900528,
      "grad_norm": 0.15319164097309113,
      "learning_rate": 9.572583152004974e-06,
      "loss": 0.1336,
      "step": 1100
    },
    {
      "epoch": 0.0855610817531862,
      "grad_norm": 0.01390855759382248,
      "learning_rate": 9.572194591234069e-06,
      "loss": 0.0074,
      "step": 1101
    },
    {
      "epoch": 0.08563879390736712,
      "grad_norm": 0.26056674122810364,
      "learning_rate": 9.571806030463166e-06,
      "loss": 0.183,
      "step": 1102
    },
    {
      "epoch": 0.08571650606154803,
      "grad_norm": 0.1400570273399353,
      "learning_rate": 9.57141746969226e-06,
      "loss": 0.1353,
      "step": 1103
    },
    {
      "epoch": 0.08579421821572894,
      "grad_norm": 0.49299368262290955,
      "learning_rate": 9.571028908921356e-06,
      "loss": 0.3016,
      "step": 1104
    },
    {
      "epoch": 0.08587193036990985,
      "grad_norm": 0.25902751088142395,
      "learning_rate": 9.570640348150452e-06,
      "loss": 0.2044,
      "step": 1105
    },
    {
      "epoch": 0.08594964252409076,
      "grad_norm": 0.21511372923851013,
      "learning_rate": 9.570251787379547e-06,
      "loss": 0.2242,
      "step": 1106
    },
    {
      "epoch": 0.08602735467827168,
      "grad_norm": 0.268996000289917,
      "learning_rate": 9.569863226608642e-06,
      "loss": 0.3573,
      "step": 1107
    },
    {
      "epoch": 0.0861050668324526,
      "grad_norm": 0.19139650464057922,
      "learning_rate": 9.569474665837739e-06,
      "loss": 0.1231,
      "step": 1108
    },
    {
      "epoch": 0.08618277898663351,
      "grad_norm": 0.3105904161930084,
      "learning_rate": 9.569086105066834e-06,
      "loss": 0.1271,
      "step": 1109
    },
    {
      "epoch": 0.08626049114081442,
      "grad_norm": 0.2153506726026535,
      "learning_rate": 9.568697544295929e-06,
      "loss": 0.1953,
      "step": 1110
    },
    {
      "epoch": 0.08633820329499534,
      "grad_norm": 0.14628449082374573,
      "learning_rate": 9.568308983525024e-06,
      "loss": 0.0834,
      "step": 1111
    },
    {
      "epoch": 0.08641591544917625,
      "grad_norm": 0.4792179465293884,
      "learning_rate": 9.56792042275412e-06,
      "loss": 0.4907,
      "step": 1112
    },
    {
      "epoch": 0.08649362760335716,
      "grad_norm": 0.2806759476661682,
      "learning_rate": 9.567531861983215e-06,
      "loss": 0.2769,
      "step": 1113
    },
    {
      "epoch": 0.08657133975753808,
      "grad_norm": 0.07686710357666016,
      "learning_rate": 9.56714330121231e-06,
      "loss": 0.0948,
      "step": 1114
    },
    {
      "epoch": 0.086649051911719,
      "grad_norm": 0.17159368097782135,
      "learning_rate": 9.566754740441407e-06,
      "loss": 0.0566,
      "step": 1115
    },
    {
      "epoch": 0.08672676406589991,
      "grad_norm": 0.07166284322738647,
      "learning_rate": 9.566366179670502e-06,
      "loss": 0.0567,
      "step": 1116
    },
    {
      "epoch": 0.08680447622008082,
      "grad_norm": 0.45749977231025696,
      "learning_rate": 9.565977618899597e-06,
      "loss": 0.32,
      "step": 1117
    },
    {
      "epoch": 0.08688218837426173,
      "grad_norm": 0.07607363164424896,
      "learning_rate": 9.565589058128693e-06,
      "loss": 0.0359,
      "step": 1118
    },
    {
      "epoch": 0.08695990052844264,
      "grad_norm": 0.2687840759754181,
      "learning_rate": 9.565200497357787e-06,
      "loss": 0.1461,
      "step": 1119
    },
    {
      "epoch": 0.08703761268262357,
      "grad_norm": 1.2665308713912964,
      "learning_rate": 9.564811936586883e-06,
      "loss": 0.6221,
      "step": 1120
    },
    {
      "epoch": 0.08711532483680448,
      "grad_norm": 0.09042786061763763,
      "learning_rate": 9.564423375815978e-06,
      "loss": 0.0763,
      "step": 1121
    },
    {
      "epoch": 0.08719303699098539,
      "grad_norm": 0.3697170913219452,
      "learning_rate": 9.564034815045073e-06,
      "loss": 0.1552,
      "step": 1122
    },
    {
      "epoch": 0.0872707491451663,
      "grad_norm": 0.2229427844285965,
      "learning_rate": 9.56364625427417e-06,
      "loss": 0.396,
      "step": 1123
    },
    {
      "epoch": 0.08734846129934722,
      "grad_norm": 0.3272509276866913,
      "learning_rate": 9.563257693503265e-06,
      "loss": 0.1425,
      "step": 1124
    },
    {
      "epoch": 0.08742617345352813,
      "grad_norm": 0.5377213954925537,
      "learning_rate": 9.56286913273236e-06,
      "loss": 0.1381,
      "step": 1125
    },
    {
      "epoch": 0.08750388560770904,
      "grad_norm": 0.4056166410446167,
      "learning_rate": 9.562480571961455e-06,
      "loss": 0.4991,
      "step": 1126
    },
    {
      "epoch": 0.08758159776188996,
      "grad_norm": 0.21877221763134003,
      "learning_rate": 9.562092011190551e-06,
      "loss": 0.2285,
      "step": 1127
    },
    {
      "epoch": 0.08765930991607088,
      "grad_norm": 0.47091615200042725,
      "learning_rate": 9.561703450419646e-06,
      "loss": 0.6196,
      "step": 1128
    },
    {
      "epoch": 0.08773702207025179,
      "grad_norm": 0.2203252762556076,
      "learning_rate": 9.561314889648741e-06,
      "loss": 0.0812,
      "step": 1129
    },
    {
      "epoch": 0.0878147342244327,
      "grad_norm": 0.1649419367313385,
      "learning_rate": 9.560926328877838e-06,
      "loss": 0.1009,
      "step": 1130
    },
    {
      "epoch": 0.08789244637861361,
      "grad_norm": 0.3909427523612976,
      "learning_rate": 9.560537768106933e-06,
      "loss": 0.4299,
      "step": 1131
    },
    {
      "epoch": 0.08797015853279452,
      "grad_norm": 0.32315489649772644,
      "learning_rate": 9.560149207336028e-06,
      "loss": 0.3069,
      "step": 1132
    },
    {
      "epoch": 0.08804787068697545,
      "grad_norm": 0.13539013266563416,
      "learning_rate": 9.559760646565124e-06,
      "loss": 0.098,
      "step": 1133
    },
    {
      "epoch": 0.08812558284115636,
      "grad_norm": 0.07851865142583847,
      "learning_rate": 9.559372085794218e-06,
      "loss": 0.0705,
      "step": 1134
    },
    {
      "epoch": 0.08820329499533727,
      "grad_norm": 0.39601510763168335,
      "learning_rate": 9.558983525023314e-06,
      "loss": 0.2835,
      "step": 1135
    },
    {
      "epoch": 0.08828100714951818,
      "grad_norm": 0.4034166634082794,
      "learning_rate": 9.55859496425241e-06,
      "loss": 0.1898,
      "step": 1136
    },
    {
      "epoch": 0.0883587193036991,
      "grad_norm": 0.2752765417098999,
      "learning_rate": 9.558206403481504e-06,
      "loss": 0.7419,
      "step": 1137
    },
    {
      "epoch": 0.08843643145788001,
      "grad_norm": 0.16850876808166504,
      "learning_rate": 9.5578178427106e-06,
      "loss": 0.174,
      "step": 1138
    },
    {
      "epoch": 0.08851414361206093,
      "grad_norm": 0.39201653003692627,
      "learning_rate": 9.557429281939696e-06,
      "loss": 0.3335,
      "step": 1139
    },
    {
      "epoch": 0.08859185576624184,
      "grad_norm": 0.31337934732437134,
      "learning_rate": 9.557040721168792e-06,
      "loss": 0.3297,
      "step": 1140
    },
    {
      "epoch": 0.08866956792042276,
      "grad_norm": 0.2265615165233612,
      "learning_rate": 9.556652160397887e-06,
      "loss": 0.1565,
      "step": 1141
    },
    {
      "epoch": 0.08874728007460367,
      "grad_norm": 0.10699092596769333,
      "learning_rate": 9.556263599626982e-06,
      "loss": 0.033,
      "step": 1142
    },
    {
      "epoch": 0.08882499222878458,
      "grad_norm": 0.15584544837474823,
      "learning_rate": 9.555875038856079e-06,
      "loss": 0.1708,
      "step": 1143
    },
    {
      "epoch": 0.08890270438296549,
      "grad_norm": 0.37571731209754944,
      "learning_rate": 9.555486478085172e-06,
      "loss": 0.746,
      "step": 1144
    },
    {
      "epoch": 0.0889804165371464,
      "grad_norm": 0.4687831401824951,
      "learning_rate": 9.555097917314269e-06,
      "loss": 0.3938,
      "step": 1145
    },
    {
      "epoch": 0.08905812869132733,
      "grad_norm": 0.18174104392528534,
      "learning_rate": 9.554709356543364e-06,
      "loss": 0.148,
      "step": 1146
    },
    {
      "epoch": 0.08913584084550824,
      "grad_norm": 0.523868203163147,
      "learning_rate": 9.554320795772459e-06,
      "loss": 0.5559,
      "step": 1147
    },
    {
      "epoch": 0.08921355299968915,
      "grad_norm": 0.14628374576568604,
      "learning_rate": 9.553932235001555e-06,
      "loss": 0.1138,
      "step": 1148
    },
    {
      "epoch": 0.08929126515387006,
      "grad_norm": 0.19835777580738068,
      "learning_rate": 9.55354367423065e-06,
      "loss": 0.0851,
      "step": 1149
    },
    {
      "epoch": 0.08936897730805098,
      "grad_norm": 0.14179079234600067,
      "learning_rate": 9.553155113459745e-06,
      "loss": 0.1836,
      "step": 1150
    },
    {
      "epoch": 0.08944668946223189,
      "grad_norm": 0.32194796204566956,
      "learning_rate": 9.552766552688842e-06,
      "loss": 0.1006,
      "step": 1151
    },
    {
      "epoch": 0.08952440161641281,
      "grad_norm": 0.13140107691287994,
      "learning_rate": 9.552377991917937e-06,
      "loss": 0.0463,
      "step": 1152
    },
    {
      "epoch": 0.08960211377059372,
      "grad_norm": 0.2816099524497986,
      "learning_rate": 9.551989431147032e-06,
      "loss": 0.1312,
      "step": 1153
    },
    {
      "epoch": 0.08967982592477464,
      "grad_norm": 0.08229105174541473,
      "learning_rate": 9.551600870376127e-06,
      "loss": 0.0196,
      "step": 1154
    },
    {
      "epoch": 0.08975753807895555,
      "grad_norm": 0.1009383350610733,
      "learning_rate": 9.551212309605223e-06,
      "loss": 0.053,
      "step": 1155
    },
    {
      "epoch": 0.08983525023313646,
      "grad_norm": 0.804273247718811,
      "learning_rate": 9.550823748834318e-06,
      "loss": 0.225,
      "step": 1156
    },
    {
      "epoch": 0.08991296238731737,
      "grad_norm": 0.12631282210350037,
      "learning_rate": 9.550435188063413e-06,
      "loss": 0.1182,
      "step": 1157
    },
    {
      "epoch": 0.0899906745414983,
      "grad_norm": 0.2249397188425064,
      "learning_rate": 9.55004662729251e-06,
      "loss": 0.1913,
      "step": 1158
    },
    {
      "epoch": 0.09006838669567921,
      "grad_norm": 0.16635988652706146,
      "learning_rate": 9.549658066521605e-06,
      "loss": 0.096,
      "step": 1159
    },
    {
      "epoch": 0.09014609884986012,
      "grad_norm": 0.0724811851978302,
      "learning_rate": 9.5492695057507e-06,
      "loss": 0.0892,
      "step": 1160
    },
    {
      "epoch": 0.09022381100404103,
      "grad_norm": 0.24578996002674103,
      "learning_rate": 9.548880944979797e-06,
      "loss": 0.1449,
      "step": 1161
    },
    {
      "epoch": 0.09030152315822194,
      "grad_norm": 0.06792175769805908,
      "learning_rate": 9.54849238420889e-06,
      "loss": 0.025,
      "step": 1162
    },
    {
      "epoch": 0.09037923531240286,
      "grad_norm": 0.10782980918884277,
      "learning_rate": 9.548103823437986e-06,
      "loss": 0.0407,
      "step": 1163
    },
    {
      "epoch": 0.09045694746658377,
      "grad_norm": 0.20528732240200043,
      "learning_rate": 9.547715262667081e-06,
      "loss": 0.1871,
      "step": 1164
    },
    {
      "epoch": 0.0905346596207647,
      "grad_norm": 0.32014989852905273,
      "learning_rate": 9.547326701896176e-06,
      "loss": 0.1757,
      "step": 1165
    },
    {
      "epoch": 0.0906123717749456,
      "grad_norm": 0.14142386615276337,
      "learning_rate": 9.546938141125273e-06,
      "loss": 0.137,
      "step": 1166
    },
    {
      "epoch": 0.09069008392912652,
      "grad_norm": 0.24548588693141937,
      "learning_rate": 9.546549580354368e-06,
      "loss": 0.4216,
      "step": 1167
    },
    {
      "epoch": 0.09076779608330743,
      "grad_norm": 0.2688838541507721,
      "learning_rate": 9.546161019583463e-06,
      "loss": 0.2393,
      "step": 1168
    },
    {
      "epoch": 0.09084550823748834,
      "grad_norm": 0.12269497662782669,
      "learning_rate": 9.54577245881256e-06,
      "loss": 0.0727,
      "step": 1169
    },
    {
      "epoch": 0.09092322039166925,
      "grad_norm": 0.12796470522880554,
      "learning_rate": 9.545383898041654e-06,
      "loss": 0.0722,
      "step": 1170
    },
    {
      "epoch": 0.09100093254585018,
      "grad_norm": 0.6796514391899109,
      "learning_rate": 9.544995337270751e-06,
      "loss": 0.4445,
      "step": 1171
    },
    {
      "epoch": 0.09107864470003109,
      "grad_norm": 0.15444202721118927,
      "learning_rate": 9.544606776499844e-06,
      "loss": 0.052,
      "step": 1172
    },
    {
      "epoch": 0.091156356854212,
      "grad_norm": 0.17331762611865997,
      "learning_rate": 9.544218215728941e-06,
      "loss": 0.077,
      "step": 1173
    },
    {
      "epoch": 0.09123406900839291,
      "grad_norm": 0.11910835653543472,
      "learning_rate": 9.543829654958036e-06,
      "loss": 0.0484,
      "step": 1174
    },
    {
      "epoch": 0.09131178116257382,
      "grad_norm": 0.29059717059135437,
      "learning_rate": 9.543441094187131e-06,
      "loss": 0.1678,
      "step": 1175
    },
    {
      "epoch": 0.09138949331675474,
      "grad_norm": 0.2175552248954773,
      "learning_rate": 9.543052533416228e-06,
      "loss": 0.2295,
      "step": 1176
    },
    {
      "epoch": 0.09146720547093565,
      "grad_norm": 0.13878710567951202,
      "learning_rate": 9.542663972645323e-06,
      "loss": 0.1058,
      "step": 1177
    },
    {
      "epoch": 0.09154491762511657,
      "grad_norm": 0.9394898414611816,
      "learning_rate": 9.542275411874417e-06,
      "loss": 0.4351,
      "step": 1178
    },
    {
      "epoch": 0.09162262977929748,
      "grad_norm": 0.12110123783349991,
      "learning_rate": 9.541886851103514e-06,
      "loss": 0.077,
      "step": 1179
    },
    {
      "epoch": 0.0917003419334784,
      "grad_norm": 0.28348901867866516,
      "learning_rate": 9.541498290332609e-06,
      "loss": 0.1041,
      "step": 1180
    },
    {
      "epoch": 0.09177805408765931,
      "grad_norm": 0.14614221453666687,
      "learning_rate": 9.541109729561704e-06,
      "loss": 0.1649,
      "step": 1181
    },
    {
      "epoch": 0.09185576624184022,
      "grad_norm": 0.04662619158625603,
      "learning_rate": 9.540721168790799e-06,
      "loss": 0.0122,
      "step": 1182
    },
    {
      "epoch": 0.09193347839602113,
      "grad_norm": 0.22685571014881134,
      "learning_rate": 9.540332608019896e-06,
      "loss": 0.1306,
      "step": 1183
    },
    {
      "epoch": 0.09201119055020206,
      "grad_norm": 2.3578999042510986,
      "learning_rate": 9.53994404724899e-06,
      "loss": 0.6616,
      "step": 1184
    },
    {
      "epoch": 0.09208890270438297,
      "grad_norm": 0.24970602989196777,
      "learning_rate": 9.539555486478086e-06,
      "loss": 0.3138,
      "step": 1185
    },
    {
      "epoch": 0.09216661485856388,
      "grad_norm": 0.3199756145477295,
      "learning_rate": 9.539166925707182e-06,
      "loss": 0.1965,
      "step": 1186
    },
    {
      "epoch": 0.09224432701274479,
      "grad_norm": 0.18061721324920654,
      "learning_rate": 9.538778364936277e-06,
      "loss": 0.021,
      "step": 1187
    },
    {
      "epoch": 0.0923220391669257,
      "grad_norm": 0.13359223306179047,
      "learning_rate": 9.538389804165372e-06,
      "loss": 0.0945,
      "step": 1188
    },
    {
      "epoch": 0.09239975132110662,
      "grad_norm": 0.1761380434036255,
      "learning_rate": 9.538001243394469e-06,
      "loss": 0.1544,
      "step": 1189
    },
    {
      "epoch": 0.09247746347528754,
      "grad_norm": 0.40098273754119873,
      "learning_rate": 9.537612682623562e-06,
      "loss": 0.3937,
      "step": 1190
    },
    {
      "epoch": 0.09255517562946845,
      "grad_norm": 0.2567724287509918,
      "learning_rate": 9.537224121852659e-06,
      "loss": 0.2202,
      "step": 1191
    },
    {
      "epoch": 0.09263288778364936,
      "grad_norm": 0.2378484159708023,
      "learning_rate": 9.536835561081754e-06,
      "loss": 0.1156,
      "step": 1192
    },
    {
      "epoch": 0.09271059993783028,
      "grad_norm": 0.23052972555160522,
      "learning_rate": 9.536447000310848e-06,
      "loss": 0.1873,
      "step": 1193
    },
    {
      "epoch": 0.09278831209201119,
      "grad_norm": 0.06660136580467224,
      "learning_rate": 9.536058439539945e-06,
      "loss": 0.1946,
      "step": 1194
    },
    {
      "epoch": 0.0928660242461921,
      "grad_norm": 0.2180863618850708,
      "learning_rate": 9.53566987876904e-06,
      "loss": 0.1953,
      "step": 1195
    },
    {
      "epoch": 0.09294373640037301,
      "grad_norm": 0.24593250453472137,
      "learning_rate": 9.535281317998135e-06,
      "loss": 0.1918,
      "step": 1196
    },
    {
      "epoch": 0.09302144855455394,
      "grad_norm": 0.27036359906196594,
      "learning_rate": 9.534892757227232e-06,
      "loss": 0.0795,
      "step": 1197
    },
    {
      "epoch": 0.09309916070873485,
      "grad_norm": 0.3318239748477936,
      "learning_rate": 9.534504196456327e-06,
      "loss": 0.1416,
      "step": 1198
    },
    {
      "epoch": 0.09317687286291576,
      "grad_norm": 0.16444623470306396,
      "learning_rate": 9.534115635685423e-06,
      "loss": 0.2874,
      "step": 1199
    },
    {
      "epoch": 0.09325458501709667,
      "grad_norm": 0.17871610820293427,
      "learning_rate": 9.533727074914517e-06,
      "loss": 0.1301,
      "step": 1200
    },
    {
      "epoch": 0.09333229717127758,
      "grad_norm": 0.2997511327266693,
      "learning_rate": 9.533338514143613e-06,
      "loss": 0.3112,
      "step": 1201
    },
    {
      "epoch": 0.0934100093254585,
      "grad_norm": 0.2618049681186676,
      "learning_rate": 9.532949953372708e-06,
      "loss": 0.0549,
      "step": 1202
    },
    {
      "epoch": 0.09348772147963942,
      "grad_norm": 0.09671881049871445,
      "learning_rate": 9.532561392601803e-06,
      "loss": 0.0424,
      "step": 1203
    },
    {
      "epoch": 0.09356543363382033,
      "grad_norm": 0.30923229455947876,
      "learning_rate": 9.5321728318309e-06,
      "loss": 0.2903,
      "step": 1204
    },
    {
      "epoch": 0.09364314578800124,
      "grad_norm": 0.20377656817436218,
      "learning_rate": 9.531784271059995e-06,
      "loss": 0.101,
      "step": 1205
    },
    {
      "epoch": 0.09372085794218216,
      "grad_norm": 0.33426928520202637,
      "learning_rate": 9.53139571028909e-06,
      "loss": 0.0357,
      "step": 1206
    },
    {
      "epoch": 0.09379857009636307,
      "grad_norm": 0.3390169143676758,
      "learning_rate": 9.531007149518186e-06,
      "loss": 0.3968,
      "step": 1207
    },
    {
      "epoch": 0.09387628225054398,
      "grad_norm": 0.27092504501342773,
      "learning_rate": 9.530618588747281e-06,
      "loss": 0.2903,
      "step": 1208
    },
    {
      "epoch": 0.0939539944047249,
      "grad_norm": 0.20301492512226105,
      "learning_rate": 9.530230027976376e-06,
      "loss": 0.1827,
      "step": 1209
    },
    {
      "epoch": 0.09403170655890582,
      "grad_norm": 0.49619606137275696,
      "learning_rate": 9.529841467205471e-06,
      "loss": 0.1536,
      "step": 1210
    },
    {
      "epoch": 0.09410941871308673,
      "grad_norm": 0.27916356921195984,
      "learning_rate": 9.529452906434568e-06,
      "loss": 0.2418,
      "step": 1211
    },
    {
      "epoch": 0.09418713086726764,
      "grad_norm": 0.6209473609924316,
      "learning_rate": 9.529064345663663e-06,
      "loss": 0.3731,
      "step": 1212
    },
    {
      "epoch": 0.09426484302144855,
      "grad_norm": 0.5201990008354187,
      "learning_rate": 9.528675784892758e-06,
      "loss": 0.4097,
      "step": 1213
    },
    {
      "epoch": 0.09434255517562946,
      "grad_norm": 0.13871535658836365,
      "learning_rate": 9.528287224121854e-06,
      "loss": 0.1018,
      "step": 1214
    },
    {
      "epoch": 0.09442026732981038,
      "grad_norm": 0.22993755340576172,
      "learning_rate": 9.52789866335095e-06,
      "loss": 0.1824,
      "step": 1215
    },
    {
      "epoch": 0.0944979794839913,
      "grad_norm": 0.5211188197135925,
      "learning_rate": 9.527510102580044e-06,
      "loss": 0.898,
      "step": 1216
    },
    {
      "epoch": 0.09457569163817221,
      "grad_norm": 0.15023018419742584,
      "learning_rate": 9.52712154180914e-06,
      "loss": 0.129,
      "step": 1217
    },
    {
      "epoch": 0.09465340379235312,
      "grad_norm": 0.272235631942749,
      "learning_rate": 9.526732981038234e-06,
      "loss": 0.1156,
      "step": 1218
    },
    {
      "epoch": 0.09473111594653404,
      "grad_norm": 0.32755517959594727,
      "learning_rate": 9.52634442026733e-06,
      "loss": 0.3449,
      "step": 1219
    },
    {
      "epoch": 0.09480882810071495,
      "grad_norm": 0.4212915897369385,
      "learning_rate": 9.525955859496426e-06,
      "loss": 0.2836,
      "step": 1220
    },
    {
      "epoch": 0.09488654025489586,
      "grad_norm": 0.08478236943483353,
      "learning_rate": 9.52556729872552e-06,
      "loss": 0.027,
      "step": 1221
    },
    {
      "epoch": 0.09496425240907679,
      "grad_norm": 0.3505233824253082,
      "learning_rate": 9.525178737954617e-06,
      "loss": 0.136,
      "step": 1222
    },
    {
      "epoch": 0.0950419645632577,
      "grad_norm": 0.22913557291030884,
      "learning_rate": 9.524790177183712e-06,
      "loss": 0.1431,
      "step": 1223
    },
    {
      "epoch": 0.09511967671743861,
      "grad_norm": 0.1467556208372116,
      "learning_rate": 9.524401616412807e-06,
      "loss": 0.0892,
      "step": 1224
    },
    {
      "epoch": 0.09519738887161952,
      "grad_norm": 0.20646893978118896,
      "learning_rate": 9.524013055641904e-06,
      "loss": 0.1341,
      "step": 1225
    },
    {
      "epoch": 0.09527510102580043,
      "grad_norm": 0.29751133918762207,
      "learning_rate": 9.523624494870999e-06,
      "loss": 0.4445,
      "step": 1226
    },
    {
      "epoch": 0.09535281317998134,
      "grad_norm": 0.14688269793987274,
      "learning_rate": 9.523235934100094e-06,
      "loss": 0.0819,
      "step": 1227
    },
    {
      "epoch": 0.09543052533416227,
      "grad_norm": 0.15519610047340393,
      "learning_rate": 9.522847373329189e-06,
      "loss": 0.1707,
      "step": 1228
    },
    {
      "epoch": 0.09550823748834318,
      "grad_norm": 0.08439460396766663,
      "learning_rate": 9.522458812558285e-06,
      "loss": 0.0544,
      "step": 1229
    },
    {
      "epoch": 0.09558594964252409,
      "grad_norm": 0.34721073508262634,
      "learning_rate": 9.52207025178738e-06,
      "loss": 0.1442,
      "step": 1230
    },
    {
      "epoch": 0.095663661796705,
      "grad_norm": 0.20684243738651276,
      "learning_rate": 9.521681691016475e-06,
      "loss": 0.2268,
      "step": 1231
    },
    {
      "epoch": 0.09574137395088592,
      "grad_norm": 0.40441954135894775,
      "learning_rate": 9.521293130245572e-06,
      "loss": 0.4125,
      "step": 1232
    },
    {
      "epoch": 0.09581908610506683,
      "grad_norm": 0.21894827485084534,
      "learning_rate": 9.520904569474667e-06,
      "loss": 0.2769,
      "step": 1233
    },
    {
      "epoch": 0.09589679825924774,
      "grad_norm": 0.4143129289150238,
      "learning_rate": 9.520516008703762e-06,
      "loss": 0.2455,
      "step": 1234
    },
    {
      "epoch": 0.09597451041342867,
      "grad_norm": 0.04064133018255234,
      "learning_rate": 9.520127447932858e-06,
      "loss": 0.0066,
      "step": 1235
    },
    {
      "epoch": 0.09605222256760958,
      "grad_norm": 0.31500497460365295,
      "learning_rate": 9.519738887161953e-06,
      "loss": 0.1814,
      "step": 1236
    },
    {
      "epoch": 0.09612993472179049,
      "grad_norm": 0.11231385916471481,
      "learning_rate": 9.519350326391048e-06,
      "loss": 0.0623,
      "step": 1237
    },
    {
      "epoch": 0.0962076468759714,
      "grad_norm": 0.06151483952999115,
      "learning_rate": 9.518961765620143e-06,
      "loss": 0.0092,
      "step": 1238
    },
    {
      "epoch": 0.09628535903015231,
      "grad_norm": 0.23738546669483185,
      "learning_rate": 9.51857320484924e-06,
      "loss": 0.2211,
      "step": 1239
    },
    {
      "epoch": 0.09636307118433322,
      "grad_norm": 0.0745132640004158,
      "learning_rate": 9.518184644078335e-06,
      "loss": 0.0195,
      "step": 1240
    },
    {
      "epoch": 0.09644078333851415,
      "grad_norm": 0.3842211067676544,
      "learning_rate": 9.51779608330743e-06,
      "loss": 0.3402,
      "step": 1241
    },
    {
      "epoch": 0.09651849549269506,
      "grad_norm": 0.6459692120552063,
      "learning_rate": 9.517407522536526e-06,
      "loss": 0.5666,
      "step": 1242
    },
    {
      "epoch": 0.09659620764687597,
      "grad_norm": 0.06187533214688301,
      "learning_rate": 9.517018961765621e-06,
      "loss": 0.029,
      "step": 1243
    },
    {
      "epoch": 0.09667391980105688,
      "grad_norm": 0.2090577483177185,
      "learning_rate": 9.516630400994716e-06,
      "loss": 0.1033,
      "step": 1244
    },
    {
      "epoch": 0.0967516319552378,
      "grad_norm": 0.2983941435813904,
      "learning_rate": 9.516241840223813e-06,
      "loss": 0.2916,
      "step": 1245
    },
    {
      "epoch": 0.09682934410941871,
      "grad_norm": 0.25965172052383423,
      "learning_rate": 9.515853279452906e-06,
      "loss": 0.1722,
      "step": 1246
    },
    {
      "epoch": 0.09690705626359963,
      "grad_norm": 0.12790429592132568,
      "learning_rate": 9.515464718682003e-06,
      "loss": 0.0373,
      "step": 1247
    },
    {
      "epoch": 0.09698476841778055,
      "grad_norm": 0.45587778091430664,
      "learning_rate": 9.515076157911098e-06,
      "loss": 0.5074,
      "step": 1248
    },
    {
      "epoch": 0.09706248057196146,
      "grad_norm": 0.3534446656703949,
      "learning_rate": 9.514687597140193e-06,
      "loss": 0.2862,
      "step": 1249
    },
    {
      "epoch": 0.09714019272614237,
      "grad_norm": 0.40604934096336365,
      "learning_rate": 9.51429903636929e-06,
      "loss": 0.3872,
      "step": 1250
    },
    {
      "epoch": 0.09721790488032328,
      "grad_norm": 0.24946165084838867,
      "learning_rate": 9.513910475598384e-06,
      "loss": 0.0609,
      "step": 1251
    },
    {
      "epoch": 0.09729561703450419,
      "grad_norm": 0.298307865858078,
      "learning_rate": 9.51352191482748e-06,
      "loss": 0.0806,
      "step": 1252
    },
    {
      "epoch": 0.0973733291886851,
      "grad_norm": 0.18534353375434875,
      "learning_rate": 9.513133354056574e-06,
      "loss": 0.0759,
      "step": 1253
    },
    {
      "epoch": 0.09745104134286603,
      "grad_norm": 0.48862624168395996,
      "learning_rate": 9.512744793285671e-06,
      "loss": 0.2515,
      "step": 1254
    },
    {
      "epoch": 0.09752875349704694,
      "grad_norm": 0.0841854140162468,
      "learning_rate": 9.512356232514766e-06,
      "loss": 0.0641,
      "step": 1255
    },
    {
      "epoch": 0.09760646565122785,
      "grad_norm": 0.37169161438941956,
      "learning_rate": 9.51196767174386e-06,
      "loss": 0.2372,
      "step": 1256
    },
    {
      "epoch": 0.09768417780540876,
      "grad_norm": 0.1278810203075409,
      "learning_rate": 9.511579110972957e-06,
      "loss": 0.0942,
      "step": 1257
    },
    {
      "epoch": 0.09776188995958968,
      "grad_norm": 0.36402201652526855,
      "learning_rate": 9.511190550202052e-06,
      "loss": 0.1644,
      "step": 1258
    },
    {
      "epoch": 0.09783960211377059,
      "grad_norm": 0.60848069190979,
      "learning_rate": 9.510801989431147e-06,
      "loss": 0.2516,
      "step": 1259
    },
    {
      "epoch": 0.09791731426795151,
      "grad_norm": 0.356897234916687,
      "learning_rate": 9.510413428660244e-06,
      "loss": 0.7067,
      "step": 1260
    },
    {
      "epoch": 0.09799502642213243,
      "grad_norm": 0.0967707633972168,
      "learning_rate": 9.510024867889339e-06,
      "loss": 0.0426,
      "step": 1261
    },
    {
      "epoch": 0.09807273857631334,
      "grad_norm": 0.022421641275286674,
      "learning_rate": 9.509636307118434e-06,
      "loss": 0.0031,
      "step": 1262
    },
    {
      "epoch": 0.09815045073049425,
      "grad_norm": 0.23635445535182953,
      "learning_rate": 9.509247746347529e-06,
      "loss": 0.2295,
      "step": 1263
    },
    {
      "epoch": 0.09822816288467516,
      "grad_norm": 0.07130087912082672,
      "learning_rate": 9.508859185576626e-06,
      "loss": 0.0218,
      "step": 1264
    },
    {
      "epoch": 0.09830587503885607,
      "grad_norm": 0.31433889269828796,
      "learning_rate": 9.50847062480572e-06,
      "loss": 0.2185,
      "step": 1265
    },
    {
      "epoch": 0.098383587193037,
      "grad_norm": 0.6033232808113098,
      "learning_rate": 9.508082064034815e-06,
      "loss": 0.7605,
      "step": 1266
    },
    {
      "epoch": 0.09846129934721791,
      "grad_norm": 0.539399266242981,
      "learning_rate": 9.507693503263912e-06,
      "loss": 0.1098,
      "step": 1267
    },
    {
      "epoch": 0.09853901150139882,
      "grad_norm": 0.19594255089759827,
      "learning_rate": 9.507304942493007e-06,
      "loss": 0.2351,
      "step": 1268
    },
    {
      "epoch": 0.09861672365557973,
      "grad_norm": 0.2470581978559494,
      "learning_rate": 9.506916381722102e-06,
      "loss": 0.3112,
      "step": 1269
    },
    {
      "epoch": 0.09869443580976064,
      "grad_norm": 0.18199552595615387,
      "learning_rate": 9.506527820951199e-06,
      "loss": 0.0574,
      "step": 1270
    },
    {
      "epoch": 0.09877214796394156,
      "grad_norm": 0.2686227858066559,
      "learning_rate": 9.506139260180292e-06,
      "loss": 0.1649,
      "step": 1271
    },
    {
      "epoch": 0.09884986011812247,
      "grad_norm": 0.20977388322353363,
      "learning_rate": 9.505750699409388e-06,
      "loss": 0.1396,
      "step": 1272
    },
    {
      "epoch": 0.0989275722723034,
      "grad_norm": 0.2844950258731842,
      "learning_rate": 9.505362138638483e-06,
      "loss": 0.2862,
      "step": 1273
    },
    {
      "epoch": 0.0990052844264843,
      "grad_norm": 0.38594821095466614,
      "learning_rate": 9.504973577867578e-06,
      "loss": 0.2221,
      "step": 1274
    },
    {
      "epoch": 0.09908299658066522,
      "grad_norm": 0.14914558827877045,
      "learning_rate": 9.504585017096675e-06,
      "loss": 0.0527,
      "step": 1275
    },
    {
      "epoch": 0.09916070873484613,
      "grad_norm": 0.13642637431621552,
      "learning_rate": 9.50419645632577e-06,
      "loss": 0.0793,
      "step": 1276
    },
    {
      "epoch": 0.09923842088902704,
      "grad_norm": 0.31896838545799255,
      "learning_rate": 9.503807895554865e-06,
      "loss": 0.1526,
      "step": 1277
    },
    {
      "epoch": 0.09931613304320795,
      "grad_norm": 0.3855724036693573,
      "learning_rate": 9.503419334783962e-06,
      "loss": 0.2855,
      "step": 1278
    },
    {
      "epoch": 0.09939384519738888,
      "grad_norm": 1.2355021238327026,
      "learning_rate": 9.503030774013057e-06,
      "loss": 0.5871,
      "step": 1279
    },
    {
      "epoch": 0.09947155735156979,
      "grad_norm": 0.4266521632671356,
      "learning_rate": 9.502642213242151e-06,
      "loss": 0.2774,
      "step": 1280
    },
    {
      "epoch": 0.0995492695057507,
      "grad_norm": 0.1451820582151413,
      "learning_rate": 9.502253652471246e-06,
      "loss": 0.1743,
      "step": 1281
    },
    {
      "epoch": 0.09962698165993161,
      "grad_norm": 0.12434141337871552,
      "learning_rate": 9.501865091700343e-06,
      "loss": 0.0648,
      "step": 1282
    },
    {
      "epoch": 0.09970469381411252,
      "grad_norm": 0.2640962600708008,
      "learning_rate": 9.501476530929438e-06,
      "loss": 0.2959,
      "step": 1283
    },
    {
      "epoch": 0.09978240596829344,
      "grad_norm": 0.6328630447387695,
      "learning_rate": 9.501087970158533e-06,
      "loss": 0.4649,
      "step": 1284
    },
    {
      "epoch": 0.09986011812247436,
      "grad_norm": 0.3098548650741577,
      "learning_rate": 9.50069940938763e-06,
      "loss": 0.3606,
      "step": 1285
    },
    {
      "epoch": 0.09993783027665527,
      "grad_norm": 0.14304521679878235,
      "learning_rate": 9.500310848616725e-06,
      "loss": 0.1043,
      "step": 1286
    },
    {
      "epoch": 0.10001554243083619,
      "grad_norm": 0.10523908585309982,
      "learning_rate": 9.49992228784582e-06,
      "loss": 0.1712,
      "step": 1287
    },
    {
      "epoch": 0.1000932545850171,
      "grad_norm": 0.6225690841674805,
      "learning_rate": 9.499533727074916e-06,
      "loss": 0.6306,
      "step": 1288
    },
    {
      "epoch": 0.10017096673919801,
      "grad_norm": 0.03439825028181076,
      "learning_rate": 9.49914516630401e-06,
      "loss": 0.008,
      "step": 1289
    },
    {
      "epoch": 0.10024867889337892,
      "grad_norm": 0.07413963228464127,
      "learning_rate": 9.498756605533106e-06,
      "loss": 0.0317,
      "step": 1290
    },
    {
      "epoch": 0.10032639104755983,
      "grad_norm": 0.2289637178182602,
      "learning_rate": 9.498368044762201e-06,
      "loss": 0.2557,
      "step": 1291
    },
    {
      "epoch": 0.10040410320174076,
      "grad_norm": 0.4575936794281006,
      "learning_rate": 9.497979483991298e-06,
      "loss": 0.4255,
      "step": 1292
    },
    {
      "epoch": 0.10048181535592167,
      "grad_norm": 0.9397498965263367,
      "learning_rate": 9.497590923220393e-06,
      "loss": 0.6008,
      "step": 1293
    },
    {
      "epoch": 0.10055952751010258,
      "grad_norm": 0.16109046339988708,
      "learning_rate": 9.497202362449488e-06,
      "loss": 0.0612,
      "step": 1294
    },
    {
      "epoch": 0.10063723966428349,
      "grad_norm": 0.5199317336082458,
      "learning_rate": 9.496813801678584e-06,
      "loss": 0.5626,
      "step": 1295
    },
    {
      "epoch": 0.1007149518184644,
      "grad_norm": 0.39185261726379395,
      "learning_rate": 9.496425240907679e-06,
      "loss": 0.5925,
      "step": 1296
    },
    {
      "epoch": 0.10079266397264532,
      "grad_norm": 0.0755629763007164,
      "learning_rate": 9.496036680136774e-06,
      "loss": 0.0505,
      "step": 1297
    },
    {
      "epoch": 0.10087037612682624,
      "grad_norm": 0.1476200968027115,
      "learning_rate": 9.49564811936587e-06,
      "loss": 0.0724,
      "step": 1298
    },
    {
      "epoch": 0.10094808828100715,
      "grad_norm": 0.13997036218643188,
      "learning_rate": 9.495259558594964e-06,
      "loss": 0.1581,
      "step": 1299
    },
    {
      "epoch": 0.10102580043518807,
      "grad_norm": 0.2964170575141907,
      "learning_rate": 9.49487099782406e-06,
      "loss": 0.1855,
      "step": 1300
    },
    {
      "epoch": 0.10110351258936898,
      "grad_norm": 0.13418081402778625,
      "learning_rate": 9.494482437053156e-06,
      "loss": 0.0608,
      "step": 1301
    },
    {
      "epoch": 0.10118122474354989,
      "grad_norm": 0.2061980813741684,
      "learning_rate": 9.49409387628225e-06,
      "loss": 0.1526,
      "step": 1302
    },
    {
      "epoch": 0.1012589368977308,
      "grad_norm": 0.099245086312294,
      "learning_rate": 9.493705315511347e-06,
      "loss": 0.056,
      "step": 1303
    },
    {
      "epoch": 0.10133664905191173,
      "grad_norm": 0.13465942442417145,
      "learning_rate": 9.493316754740442e-06,
      "loss": 0.0686,
      "step": 1304
    },
    {
      "epoch": 0.10141436120609264,
      "grad_norm": 0.1980075240135193,
      "learning_rate": 9.492928193969537e-06,
      "loss": 0.1914,
      "step": 1305
    },
    {
      "epoch": 0.10149207336027355,
      "grad_norm": 0.17787101864814758,
      "learning_rate": 9.492539633198634e-06,
      "loss": 0.2138,
      "step": 1306
    },
    {
      "epoch": 0.10156978551445446,
      "grad_norm": 0.21950891613960266,
      "learning_rate": 9.492151072427729e-06,
      "loss": 0.1358,
      "step": 1307
    },
    {
      "epoch": 0.10164749766863537,
      "grad_norm": 0.07845785468816757,
      "learning_rate": 9.491762511656824e-06,
      "loss": 0.1054,
      "step": 1308
    },
    {
      "epoch": 0.10172520982281628,
      "grad_norm": 0.09582370519638062,
      "learning_rate": 9.491373950885919e-06,
      "loss": 0.0545,
      "step": 1309
    },
    {
      "epoch": 0.1018029219769972,
      "grad_norm": 0.6342707872390747,
      "learning_rate": 9.490985390115015e-06,
      "loss": 0.4334,
      "step": 1310
    },
    {
      "epoch": 0.10188063413117812,
      "grad_norm": 0.20995928347110748,
      "learning_rate": 9.49059682934411e-06,
      "loss": 0.1968,
      "step": 1311
    },
    {
      "epoch": 0.10195834628535903,
      "grad_norm": 0.4858623147010803,
      "learning_rate": 9.490208268573205e-06,
      "loss": 0.1235,
      "step": 1312
    },
    {
      "epoch": 0.10203605843953995,
      "grad_norm": 0.3290741741657257,
      "learning_rate": 9.489819707802302e-06,
      "loss": 0.1316,
      "step": 1313
    },
    {
      "epoch": 0.10211377059372086,
      "grad_norm": 0.1750931292772293,
      "learning_rate": 9.489431147031397e-06,
      "loss": 0.0771,
      "step": 1314
    },
    {
      "epoch": 0.10219148274790177,
      "grad_norm": 0.03925305977463722,
      "learning_rate": 9.489042586260492e-06,
      "loss": 0.0358,
      "step": 1315
    },
    {
      "epoch": 0.10226919490208268,
      "grad_norm": 0.18167158961296082,
      "learning_rate": 9.488654025489588e-06,
      "loss": 0.1589,
      "step": 1316
    },
    {
      "epoch": 0.1023469070562636,
      "grad_norm": 0.14018966257572174,
      "learning_rate": 9.488265464718682e-06,
      "loss": 0.1228,
      "step": 1317
    },
    {
      "epoch": 0.10242461921044452,
      "grad_norm": 0.15528927743434906,
      "learning_rate": 9.487876903947778e-06,
      "loss": 0.0851,
      "step": 1318
    },
    {
      "epoch": 0.10250233136462543,
      "grad_norm": 0.3150981664657593,
      "learning_rate": 9.487488343176873e-06,
      "loss": 0.3022,
      "step": 1319
    },
    {
      "epoch": 0.10258004351880634,
      "grad_norm": 0.1915651112794876,
      "learning_rate": 9.487099782405968e-06,
      "loss": 0.2616,
      "step": 1320
    },
    {
      "epoch": 0.10265775567298725,
      "grad_norm": 0.4346388876438141,
      "learning_rate": 9.486711221635065e-06,
      "loss": 0.6078,
      "step": 1321
    },
    {
      "epoch": 0.10273546782716816,
      "grad_norm": 0.1952485740184784,
      "learning_rate": 9.48632266086416e-06,
      "loss": 0.0311,
      "step": 1322
    },
    {
      "epoch": 0.10281317998134909,
      "grad_norm": 0.034554075449705124,
      "learning_rate": 9.485934100093256e-06,
      "loss": 0.0088,
      "step": 1323
    },
    {
      "epoch": 0.10289089213553,
      "grad_norm": 0.3246555030345917,
      "learning_rate": 9.485545539322351e-06,
      "loss": 0.2171,
      "step": 1324
    },
    {
      "epoch": 0.10296860428971091,
      "grad_norm": 0.31879734992980957,
      "learning_rate": 9.485156978551446e-06,
      "loss": 0.3707,
      "step": 1325
    },
    {
      "epoch": 0.10304631644389182,
      "grad_norm": 0.6439780592918396,
      "learning_rate": 9.484768417780543e-06,
      "loss": 0.9667,
      "step": 1326
    },
    {
      "epoch": 0.10312402859807274,
      "grad_norm": 0.4039216637611389,
      "learning_rate": 9.484379857009636e-06,
      "loss": 0.3581,
      "step": 1327
    },
    {
      "epoch": 0.10320174075225365,
      "grad_norm": 0.5299399495124817,
      "learning_rate": 9.483991296238733e-06,
      "loss": 0.4607,
      "step": 1328
    },
    {
      "epoch": 0.10327945290643456,
      "grad_norm": 0.15864886343479156,
      "learning_rate": 9.483602735467828e-06,
      "loss": 0.6119,
      "step": 1329
    },
    {
      "epoch": 0.10335716506061549,
      "grad_norm": 1.1104248762130737,
      "learning_rate": 9.483214174696923e-06,
      "loss": 0.6032,
      "step": 1330
    },
    {
      "epoch": 0.1034348772147964,
      "grad_norm": 0.08206180483102798,
      "learning_rate": 9.48282561392602e-06,
      "loss": 0.0574,
      "step": 1331
    },
    {
      "epoch": 0.10351258936897731,
      "grad_norm": 0.08879118412733078,
      "learning_rate": 9.482437053155114e-06,
      "loss": 0.0832,
      "step": 1332
    },
    {
      "epoch": 0.10359030152315822,
      "grad_norm": 0.21450544893741608,
      "learning_rate": 9.48204849238421e-06,
      "loss": 0.0455,
      "step": 1333
    },
    {
      "epoch": 0.10366801367733913,
      "grad_norm": 0.37717166543006897,
      "learning_rate": 9.481659931613306e-06,
      "loss": 0.2162,
      "step": 1334
    },
    {
      "epoch": 0.10374572583152004,
      "grad_norm": 0.2208140641450882,
      "learning_rate": 9.4812713708424e-06,
      "loss": 0.2719,
      "step": 1335
    },
    {
      "epoch": 0.10382343798570097,
      "grad_norm": 0.5031662583351135,
      "learning_rate": 9.480882810071496e-06,
      "loss": 0.1026,
      "step": 1336
    },
    {
      "epoch": 0.10390115013988188,
      "grad_norm": 0.4306027591228485,
      "learning_rate": 9.48049424930059e-06,
      "loss": 0.1928,
      "step": 1337
    },
    {
      "epoch": 0.1039788622940628,
      "grad_norm": 0.2877669632434845,
      "learning_rate": 9.480105688529687e-06,
      "loss": 0.1188,
      "step": 1338
    },
    {
      "epoch": 0.1040565744482437,
      "grad_norm": 0.2699955105781555,
      "learning_rate": 9.479717127758782e-06,
      "loss": 0.1355,
      "step": 1339
    },
    {
      "epoch": 0.10413428660242462,
      "grad_norm": 0.8192707300186157,
      "learning_rate": 9.479328566987877e-06,
      "loss": 0.1866,
      "step": 1340
    },
    {
      "epoch": 0.10421199875660553,
      "grad_norm": 0.13359101116657257,
      "learning_rate": 9.478940006216974e-06,
      "loss": 0.0854,
      "step": 1341
    },
    {
      "epoch": 0.10428971091078644,
      "grad_norm": 0.18317465484142303,
      "learning_rate": 9.478551445446069e-06,
      "loss": 0.0805,
      "step": 1342
    },
    {
      "epoch": 0.10436742306496737,
      "grad_norm": 0.3818958103656769,
      "learning_rate": 9.478162884675164e-06,
      "loss": 0.4658,
      "step": 1343
    },
    {
      "epoch": 0.10444513521914828,
      "grad_norm": 0.652660608291626,
      "learning_rate": 9.47777432390426e-06,
      "loss": 0.8418,
      "step": 1344
    },
    {
      "epoch": 0.10452284737332919,
      "grad_norm": 0.33304521441459656,
      "learning_rate": 9.477385763133354e-06,
      "loss": 0.2082,
      "step": 1345
    },
    {
      "epoch": 0.1046005595275101,
      "grad_norm": 0.13599269092082977,
      "learning_rate": 9.47699720236245e-06,
      "loss": 0.1507,
      "step": 1346
    },
    {
      "epoch": 0.10467827168169101,
      "grad_norm": 0.33479809761047363,
      "learning_rate": 9.476608641591545e-06,
      "loss": 0.4866,
      "step": 1347
    },
    {
      "epoch": 0.10475598383587192,
      "grad_norm": 0.3586798310279846,
      "learning_rate": 9.47622008082064e-06,
      "loss": 0.2391,
      "step": 1348
    },
    {
      "epoch": 0.10483369599005285,
      "grad_norm": 0.22105777263641357,
      "learning_rate": 9.475831520049737e-06,
      "loss": 0.1425,
      "step": 1349
    },
    {
      "epoch": 0.10491140814423376,
      "grad_norm": 0.4546751081943512,
      "learning_rate": 9.475442959278832e-06,
      "loss": 0.4116,
      "step": 1350
    },
    {
      "epoch": 0.10498912029841467,
      "grad_norm": 0.33210238814353943,
      "learning_rate": 9.475054398507928e-06,
      "loss": 0.3605,
      "step": 1351
    },
    {
      "epoch": 0.10506683245259558,
      "grad_norm": 0.12702244520187378,
      "learning_rate": 9.474665837737023e-06,
      "loss": 0.1357,
      "step": 1352
    },
    {
      "epoch": 0.1051445446067765,
      "grad_norm": 0.06448041647672653,
      "learning_rate": 9.474277276966118e-06,
      "loss": 0.013,
      "step": 1353
    },
    {
      "epoch": 0.10522225676095741,
      "grad_norm": 0.21221794188022614,
      "learning_rate": 9.473888716195215e-06,
      "loss": 0.0544,
      "step": 1354
    },
    {
      "epoch": 0.10529996891513833,
      "grad_norm": 0.2218274176120758,
      "learning_rate": 9.473500155424308e-06,
      "loss": 0.1801,
      "step": 1355
    },
    {
      "epoch": 0.10537768106931925,
      "grad_norm": 0.3316996991634369,
      "learning_rate": 9.473111594653405e-06,
      "loss": 0.5172,
      "step": 1356
    },
    {
      "epoch": 0.10545539322350016,
      "grad_norm": 0.09508152306079865,
      "learning_rate": 9.4727230338825e-06,
      "loss": 0.0666,
      "step": 1357
    },
    {
      "epoch": 0.10553310537768107,
      "grad_norm": 0.40643855929374695,
      "learning_rate": 9.472334473111595e-06,
      "loss": 0.4222,
      "step": 1358
    },
    {
      "epoch": 0.10561081753186198,
      "grad_norm": 0.36258190870285034,
      "learning_rate": 9.471945912340691e-06,
      "loss": 0.2068,
      "step": 1359
    },
    {
      "epoch": 0.10568852968604289,
      "grad_norm": 0.14151960611343384,
      "learning_rate": 9.471557351569786e-06,
      "loss": 0.2092,
      "step": 1360
    },
    {
      "epoch": 0.1057662418402238,
      "grad_norm": 0.5513757467269897,
      "learning_rate": 9.471168790798881e-06,
      "loss": 0.3311,
      "step": 1361
    },
    {
      "epoch": 0.10584395399440473,
      "grad_norm": 0.16719070076942444,
      "learning_rate": 9.470780230027978e-06,
      "loss": 0.1065,
      "step": 1362
    },
    {
      "epoch": 0.10592166614858564,
      "grad_norm": 0.33064448833465576,
      "learning_rate": 9.470391669257073e-06,
      "loss": 0.19,
      "step": 1363
    },
    {
      "epoch": 0.10599937830276655,
      "grad_norm": 0.16800056397914886,
      "learning_rate": 9.470003108486168e-06,
      "loss": 0.1628,
      "step": 1364
    },
    {
      "epoch": 0.10607709045694746,
      "grad_norm": 0.18138815462589264,
      "learning_rate": 9.469614547715263e-06,
      "loss": 0.103,
      "step": 1365
    },
    {
      "epoch": 0.10615480261112838,
      "grad_norm": 0.4863468408584595,
      "learning_rate": 9.46922598694436e-06,
      "loss": 0.126,
      "step": 1366
    },
    {
      "epoch": 0.10623251476530929,
      "grad_norm": 0.22473615407943726,
      "learning_rate": 9.468837426173454e-06,
      "loss": 0.2015,
      "step": 1367
    },
    {
      "epoch": 0.10631022691949021,
      "grad_norm": 0.5194770693778992,
      "learning_rate": 9.46844886540255e-06,
      "loss": 0.4643,
      "step": 1368
    },
    {
      "epoch": 0.10638793907367113,
      "grad_norm": 0.24523304402828217,
      "learning_rate": 9.468060304631646e-06,
      "loss": 0.1285,
      "step": 1369
    },
    {
      "epoch": 0.10646565122785204,
      "grad_norm": 0.06603182107210159,
      "learning_rate": 9.467671743860741e-06,
      "loss": 0.0834,
      "step": 1370
    },
    {
      "epoch": 0.10654336338203295,
      "grad_norm": 0.4391177296638489,
      "learning_rate": 9.467283183089836e-06,
      "loss": 0.1961,
      "step": 1371
    },
    {
      "epoch": 0.10662107553621386,
      "grad_norm": 0.09607619792222977,
      "learning_rate": 9.466894622318933e-06,
      "loss": 0.0459,
      "step": 1372
    },
    {
      "epoch": 0.10669878769039477,
      "grad_norm": 0.25513410568237305,
      "learning_rate": 9.466506061548026e-06,
      "loss": 0.2346,
      "step": 1373
    },
    {
      "epoch": 0.1067764998445757,
      "grad_norm": 0.17337347567081451,
      "learning_rate": 9.466117500777122e-06,
      "loss": 0.0349,
      "step": 1374
    },
    {
      "epoch": 0.10685421199875661,
      "grad_norm": 0.1814844161272049,
      "learning_rate": 9.465728940006217e-06,
      "loss": 0.1214,
      "step": 1375
    },
    {
      "epoch": 0.10693192415293752,
      "grad_norm": 0.19114050269126892,
      "learning_rate": 9.465340379235312e-06,
      "loss": 0.0966,
      "step": 1376
    },
    {
      "epoch": 0.10700963630711843,
      "grad_norm": 0.12625671923160553,
      "learning_rate": 9.464951818464409e-06,
      "loss": 0.0916,
      "step": 1377
    },
    {
      "epoch": 0.10708734846129934,
      "grad_norm": 0.07513228803873062,
      "learning_rate": 9.464563257693504e-06,
      "loss": 0.0337,
      "step": 1378
    },
    {
      "epoch": 0.10716506061548026,
      "grad_norm": 0.04511823505163193,
      "learning_rate": 9.464174696922599e-06,
      "loss": 0.0099,
      "step": 1379
    },
    {
      "epoch": 0.10724277276966117,
      "grad_norm": 0.21513795852661133,
      "learning_rate": 9.463786136151694e-06,
      "loss": 0.3258,
      "step": 1380
    },
    {
      "epoch": 0.1073204849238421,
      "grad_norm": 0.5928670167922974,
      "learning_rate": 9.46339757538079e-06,
      "loss": 0.2214,
      "step": 1381
    },
    {
      "epoch": 0.107398197078023,
      "grad_norm": 0.6780276298522949,
      "learning_rate": 9.463009014609885e-06,
      "loss": 0.7082,
      "step": 1382
    },
    {
      "epoch": 0.10747590923220392,
      "grad_norm": 0.04254372790455818,
      "learning_rate": 9.46262045383898e-06,
      "loss": 0.011,
      "step": 1383
    },
    {
      "epoch": 0.10755362138638483,
      "grad_norm": 0.11330091953277588,
      "learning_rate": 9.462231893068077e-06,
      "loss": 0.0762,
      "step": 1384
    },
    {
      "epoch": 0.10763133354056574,
      "grad_norm": 0.13815757632255554,
      "learning_rate": 9.461843332297172e-06,
      "loss": 0.0442,
      "step": 1385
    },
    {
      "epoch": 0.10770904569474665,
      "grad_norm": 0.2537587881088257,
      "learning_rate": 9.461454771526267e-06,
      "loss": 0.2179,
      "step": 1386
    },
    {
      "epoch": 0.10778675784892758,
      "grad_norm": 0.18621701002120972,
      "learning_rate": 9.461066210755364e-06,
      "loss": 0.0587,
      "step": 1387
    },
    {
      "epoch": 0.10786447000310849,
      "grad_norm": 0.12840060889720917,
      "learning_rate": 9.460677649984459e-06,
      "loss": 0.0657,
      "step": 1388
    },
    {
      "epoch": 0.1079421821572894,
      "grad_norm": 0.49792197346687317,
      "learning_rate": 9.460289089213554e-06,
      "loss": 0.3583,
      "step": 1389
    },
    {
      "epoch": 0.10801989431147031,
      "grad_norm": 0.47177642583847046,
      "learning_rate": 9.459900528442648e-06,
      "loss": 0.8673,
      "step": 1390
    },
    {
      "epoch": 0.10809760646565122,
      "grad_norm": 0.1284925639629364,
      "learning_rate": 9.459511967671745e-06,
      "loss": 0.0765,
      "step": 1391
    },
    {
      "epoch": 0.10817531861983214,
      "grad_norm": 0.4405793845653534,
      "learning_rate": 9.45912340690084e-06,
      "loss": 0.9251,
      "step": 1392
    },
    {
      "epoch": 0.10825303077401306,
      "grad_norm": 0.17116640508174896,
      "learning_rate": 9.458734846129935e-06,
      "loss": 0.0695,
      "step": 1393
    },
    {
      "epoch": 0.10833074292819397,
      "grad_norm": 0.08325526118278503,
      "learning_rate": 9.458346285359032e-06,
      "loss": 0.0153,
      "step": 1394
    },
    {
      "epoch": 0.10840845508237489,
      "grad_norm": 0.2653290629386902,
      "learning_rate": 9.457957724588127e-06,
      "loss": 0.0895,
      "step": 1395
    },
    {
      "epoch": 0.1084861672365558,
      "grad_norm": 0.3107433617115021,
      "learning_rate": 9.457569163817222e-06,
      "loss": 0.2979,
      "step": 1396
    },
    {
      "epoch": 0.10856387939073671,
      "grad_norm": 0.16402457654476166,
      "learning_rate": 9.457180603046318e-06,
      "loss": 0.0712,
      "step": 1397
    },
    {
      "epoch": 0.10864159154491762,
      "grad_norm": 0.26912879943847656,
      "learning_rate": 9.456792042275411e-06,
      "loss": 0.1116,
      "step": 1398
    },
    {
      "epoch": 0.10871930369909853,
      "grad_norm": 0.19822324812412262,
      "learning_rate": 9.456403481504508e-06,
      "loss": 0.1675,
      "step": 1399
    },
    {
      "epoch": 0.10879701585327946,
      "grad_norm": 0.4001806676387787,
      "learning_rate": 9.456014920733603e-06,
      "loss": 0.0866,
      "step": 1400
    },
    {
      "epoch": 0.10887472800746037,
      "grad_norm": 0.2776477336883545,
      "learning_rate": 9.455626359962698e-06,
      "loss": 0.0734,
      "step": 1401
    },
    {
      "epoch": 0.10895244016164128,
      "grad_norm": 0.3142811357975006,
      "learning_rate": 9.455237799191795e-06,
      "loss": 0.1029,
      "step": 1402
    },
    {
      "epoch": 0.10903015231582219,
      "grad_norm": 0.10197298228740692,
      "learning_rate": 9.45484923842089e-06,
      "loss": 0.0445,
      "step": 1403
    },
    {
      "epoch": 0.1091078644700031,
      "grad_norm": 0.8883069157600403,
      "learning_rate": 9.454460677649985e-06,
      "loss": 0.6636,
      "step": 1404
    },
    {
      "epoch": 0.10918557662418402,
      "grad_norm": 0.6678569316864014,
      "learning_rate": 9.454072116879081e-06,
      "loss": 0.576,
      "step": 1405
    },
    {
      "epoch": 0.10926328877836494,
      "grad_norm": 0.40571674704551697,
      "learning_rate": 9.453683556108176e-06,
      "loss": 0.7315,
      "step": 1406
    },
    {
      "epoch": 0.10934100093254585,
      "grad_norm": 0.18561023473739624,
      "learning_rate": 9.453294995337271e-06,
      "loss": 0.1338,
      "step": 1407
    },
    {
      "epoch": 0.10941871308672677,
      "grad_norm": 1.4474810361862183,
      "learning_rate": 9.452906434566366e-06,
      "loss": 0.1276,
      "step": 1408
    },
    {
      "epoch": 0.10949642524090768,
      "grad_norm": 0.2066507637500763,
      "learning_rate": 9.452517873795463e-06,
      "loss": 0.1167,
      "step": 1409
    },
    {
      "epoch": 0.10957413739508859,
      "grad_norm": 0.20066729187965393,
      "learning_rate": 9.452129313024558e-06,
      "loss": 0.2379,
      "step": 1410
    },
    {
      "epoch": 0.1096518495492695,
      "grad_norm": 0.23108389973640442,
      "learning_rate": 9.451740752253653e-06,
      "loss": 0.0357,
      "step": 1411
    },
    {
      "epoch": 0.10972956170345043,
      "grad_norm": 0.5578399300575256,
      "learning_rate": 9.45135219148275e-06,
      "loss": 0.5485,
      "step": 1412
    },
    {
      "epoch": 0.10980727385763134,
      "grad_norm": 0.5183880925178528,
      "learning_rate": 9.450963630711844e-06,
      "loss": 0.3119,
      "step": 1413
    },
    {
      "epoch": 0.10988498601181225,
      "grad_norm": 0.44037535786628723,
      "learning_rate": 9.450575069940939e-06,
      "loss": 0.3096,
      "step": 1414
    },
    {
      "epoch": 0.10996269816599316,
      "grad_norm": 0.25390294194221497,
      "learning_rate": 9.450186509170036e-06,
      "loss": 0.2394,
      "step": 1415
    },
    {
      "epoch": 0.11004041032017407,
      "grad_norm": 0.16119375824928284,
      "learning_rate": 9.44979794839913e-06,
      "loss": 0.1755,
      "step": 1416
    },
    {
      "epoch": 0.11011812247435498,
      "grad_norm": 0.15592415630817413,
      "learning_rate": 9.449409387628226e-06,
      "loss": 0.0786,
      "step": 1417
    },
    {
      "epoch": 0.1101958346285359,
      "grad_norm": 0.1169472485780716,
      "learning_rate": 9.44902082685732e-06,
      "loss": 0.1355,
      "step": 1418
    },
    {
      "epoch": 0.11027354678271682,
      "grad_norm": 0.3650616407394409,
      "learning_rate": 9.448632266086417e-06,
      "loss": 0.5151,
      "step": 1419
    },
    {
      "epoch": 0.11035125893689773,
      "grad_norm": 0.2661021649837494,
      "learning_rate": 9.448243705315512e-06,
      "loss": 0.1261,
      "step": 1420
    },
    {
      "epoch": 0.11042897109107865,
      "grad_norm": 0.4128190875053406,
      "learning_rate": 9.447855144544607e-06,
      "loss": 0.3777,
      "step": 1421
    },
    {
      "epoch": 0.11050668324525956,
      "grad_norm": 0.3369224965572357,
      "learning_rate": 9.447466583773704e-06,
      "loss": 0.3238,
      "step": 1422
    },
    {
      "epoch": 0.11058439539944047,
      "grad_norm": 0.12908092141151428,
      "learning_rate": 9.447078023002799e-06,
      "loss": 0.0885,
      "step": 1423
    },
    {
      "epoch": 0.11066210755362138,
      "grad_norm": 0.1349225491285324,
      "learning_rate": 9.446689462231894e-06,
      "loss": 0.0232,
      "step": 1424
    },
    {
      "epoch": 0.1107398197078023,
      "grad_norm": 0.1500805914402008,
      "learning_rate": 9.44630090146099e-06,
      "loss": 0.0778,
      "step": 1425
    },
    {
      "epoch": 0.11081753186198322,
      "grad_norm": 0.027194621041417122,
      "learning_rate": 9.445912340690084e-06,
      "loss": 0.011,
      "step": 1426
    },
    {
      "epoch": 0.11089524401616413,
      "grad_norm": 0.10853296518325806,
      "learning_rate": 9.44552377991918e-06,
      "loss": 0.0653,
      "step": 1427
    },
    {
      "epoch": 0.11097295617034504,
      "grad_norm": 0.16107769310474396,
      "learning_rate": 9.445135219148275e-06,
      "loss": 0.0647,
      "step": 1428
    },
    {
      "epoch": 0.11105066832452595,
      "grad_norm": 0.36365222930908203,
      "learning_rate": 9.44474665837737e-06,
      "loss": 0.174,
      "step": 1429
    },
    {
      "epoch": 0.11112838047870686,
      "grad_norm": 0.6345091462135315,
      "learning_rate": 9.444358097606467e-06,
      "loss": 0.4276,
      "step": 1430
    },
    {
      "epoch": 0.11120609263288779,
      "grad_norm": 0.4161801338195801,
      "learning_rate": 9.443969536835562e-06,
      "loss": 0.4582,
      "step": 1431
    },
    {
      "epoch": 0.1112838047870687,
      "grad_norm": 0.16088874638080597,
      "learning_rate": 9.443580976064657e-06,
      "loss": 0.0895,
      "step": 1432
    },
    {
      "epoch": 0.11136151694124961,
      "grad_norm": 0.2425779402256012,
      "learning_rate": 9.443192415293753e-06,
      "loss": 0.1585,
      "step": 1433
    },
    {
      "epoch": 0.11143922909543053,
      "grad_norm": 0.9960986971855164,
      "learning_rate": 9.442803854522848e-06,
      "loss": 0.3161,
      "step": 1434
    },
    {
      "epoch": 0.11151694124961144,
      "grad_norm": 0.09774947166442871,
      "learning_rate": 9.442415293751943e-06,
      "loss": 0.095,
      "step": 1435
    },
    {
      "epoch": 0.11159465340379235,
      "grad_norm": 0.3265124261379242,
      "learning_rate": 9.442026732981038e-06,
      "loss": 0.1729,
      "step": 1436
    },
    {
      "epoch": 0.11167236555797326,
      "grad_norm": 0.1825471818447113,
      "learning_rate": 9.441638172210135e-06,
      "loss": 0.0842,
      "step": 1437
    },
    {
      "epoch": 0.11175007771215419,
      "grad_norm": 0.14559078216552734,
      "learning_rate": 9.44124961143923e-06,
      "loss": 0.0562,
      "step": 1438
    },
    {
      "epoch": 0.1118277898663351,
      "grad_norm": 0.34515663981437683,
      "learning_rate": 9.440861050668325e-06,
      "loss": 0.3405,
      "step": 1439
    },
    {
      "epoch": 0.11190550202051601,
      "grad_norm": 0.09473621100187302,
      "learning_rate": 9.440472489897421e-06,
      "loss": 0.0269,
      "step": 1440
    },
    {
      "epoch": 0.11198321417469692,
      "grad_norm": 0.2687675356864929,
      "learning_rate": 9.440083929126516e-06,
      "loss": 0.2184,
      "step": 1441
    },
    {
      "epoch": 0.11206092632887783,
      "grad_norm": 1.2257734537124634,
      "learning_rate": 9.439695368355611e-06,
      "loss": 0.1432,
      "step": 1442
    },
    {
      "epoch": 0.11213863848305874,
      "grad_norm": 0.537552535533905,
      "learning_rate": 9.439306807584708e-06,
      "loss": 0.2639,
      "step": 1443
    },
    {
      "epoch": 0.11221635063723967,
      "grad_norm": 0.08260947465896606,
      "learning_rate": 9.438918246813803e-06,
      "loss": 0.0541,
      "step": 1444
    },
    {
      "epoch": 0.11229406279142058,
      "grad_norm": 0.14810632169246674,
      "learning_rate": 9.438529686042898e-06,
      "loss": 0.1702,
      "step": 1445
    },
    {
      "epoch": 0.1123717749456015,
      "grad_norm": 0.2544087767601013,
      "learning_rate": 9.438141125271993e-06,
      "loss": 0.1167,
      "step": 1446
    },
    {
      "epoch": 0.1124494870997824,
      "grad_norm": 0.2471875101327896,
      "learning_rate": 9.43775256450109e-06,
      "loss": 0.2597,
      "step": 1447
    },
    {
      "epoch": 0.11252719925396332,
      "grad_norm": 0.5584617257118225,
      "learning_rate": 9.437364003730184e-06,
      "loss": 0.4226,
      "step": 1448
    },
    {
      "epoch": 0.11260491140814423,
      "grad_norm": 0.27591606974601746,
      "learning_rate": 9.43697544295928e-06,
      "loss": 0.1928,
      "step": 1449
    },
    {
      "epoch": 0.11268262356232515,
      "grad_norm": 0.887904942035675,
      "learning_rate": 9.436586882188376e-06,
      "loss": 0.4864,
      "step": 1450
    },
    {
      "epoch": 0.11276033571650607,
      "grad_norm": 0.2567277252674103,
      "learning_rate": 9.436198321417471e-06,
      "loss": 0.1417,
      "step": 1451
    },
    {
      "epoch": 0.11283804787068698,
      "grad_norm": 0.1465383768081665,
      "learning_rate": 9.435809760646566e-06,
      "loss": 0.103,
      "step": 1452
    },
    {
      "epoch": 0.11291576002486789,
      "grad_norm": 0.16130073368549347,
      "learning_rate": 9.435421199875662e-06,
      "loss": 0.2007,
      "step": 1453
    },
    {
      "epoch": 0.1129934721790488,
      "grad_norm": 0.10135313868522644,
      "learning_rate": 9.435032639104756e-06,
      "loss": 0.0388,
      "step": 1454
    },
    {
      "epoch": 0.11307118433322971,
      "grad_norm": 0.20943105220794678,
      "learning_rate": 9.434644078333852e-06,
      "loss": 0.0951,
      "step": 1455
    },
    {
      "epoch": 0.11314889648741062,
      "grad_norm": 0.24725966155529022,
      "learning_rate": 9.434255517562947e-06,
      "loss": 0.1613,
      "step": 1456
    },
    {
      "epoch": 0.11322660864159155,
      "grad_norm": 0.3816598951816559,
      "learning_rate": 9.433866956792042e-06,
      "loss": 0.1697,
      "step": 1457
    },
    {
      "epoch": 0.11330432079577246,
      "grad_norm": 0.262589693069458,
      "learning_rate": 9.433478396021139e-06,
      "loss": 0.1005,
      "step": 1458
    },
    {
      "epoch": 0.11338203294995337,
      "grad_norm": 0.22225865721702576,
      "learning_rate": 9.433089835250234e-06,
      "loss": 0.3128,
      "step": 1459
    },
    {
      "epoch": 0.11345974510413429,
      "grad_norm": 0.027081552892923355,
      "learning_rate": 9.432701274479329e-06,
      "loss": 0.012,
      "step": 1460
    },
    {
      "epoch": 0.1135374572583152,
      "grad_norm": 1.43553626537323,
      "learning_rate": 9.432312713708425e-06,
      "loss": 0.7317,
      "step": 1461
    },
    {
      "epoch": 0.11361516941249611,
      "grad_norm": 0.3029078543186188,
      "learning_rate": 9.43192415293752e-06,
      "loss": 0.1147,
      "step": 1462
    },
    {
      "epoch": 0.11369288156667703,
      "grad_norm": 0.43681448698043823,
      "learning_rate": 9.431535592166615e-06,
      "loss": 0.5922,
      "step": 1463
    },
    {
      "epoch": 0.11377059372085795,
      "grad_norm": 0.11072330921888351,
      "learning_rate": 9.43114703139571e-06,
      "loss": 0.0673,
      "step": 1464
    },
    {
      "epoch": 0.11384830587503886,
      "grad_norm": 0.2617608904838562,
      "learning_rate": 9.430758470624807e-06,
      "loss": 0.2862,
      "step": 1465
    },
    {
      "epoch": 0.11392601802921977,
      "grad_norm": 0.2825285792350769,
      "learning_rate": 9.430369909853902e-06,
      "loss": 0.1481,
      "step": 1466
    },
    {
      "epoch": 0.11400373018340068,
      "grad_norm": 0.3945681154727936,
      "learning_rate": 9.429981349082997e-06,
      "loss": 0.2674,
      "step": 1467
    },
    {
      "epoch": 0.11408144233758159,
      "grad_norm": 0.17653246223926544,
      "learning_rate": 9.429592788312094e-06,
      "loss": 0.0594,
      "step": 1468
    },
    {
      "epoch": 0.11415915449176252,
      "grad_norm": 0.07784075289964676,
      "learning_rate": 9.429204227541188e-06,
      "loss": 0.0633,
      "step": 1469
    },
    {
      "epoch": 0.11423686664594343,
      "grad_norm": 0.5009628534317017,
      "learning_rate": 9.428815666770283e-06,
      "loss": 0.2804,
      "step": 1470
    },
    {
      "epoch": 0.11431457880012434,
      "grad_norm": 0.05209348350763321,
      "learning_rate": 9.42842710599938e-06,
      "loss": 0.0158,
      "step": 1471
    },
    {
      "epoch": 0.11439229095430525,
      "grad_norm": 0.15665900707244873,
      "learning_rate": 9.428038545228475e-06,
      "loss": 0.0566,
      "step": 1472
    },
    {
      "epoch": 0.11447000310848617,
      "grad_norm": 1.521529197692871,
      "learning_rate": 9.42764998445757e-06,
      "loss": 0.8656,
      "step": 1473
    },
    {
      "epoch": 0.11454771526266708,
      "grad_norm": 0.169975146651268,
      "learning_rate": 9.427261423686665e-06,
      "loss": 0.1419,
      "step": 1474
    },
    {
      "epoch": 0.11462542741684799,
      "grad_norm": 0.3733493387699127,
      "learning_rate": 9.426872862915762e-06,
      "loss": 0.1017,
      "step": 1475
    },
    {
      "epoch": 0.11470313957102891,
      "grad_norm": 0.563779890537262,
      "learning_rate": 9.426484302144857e-06,
      "loss": 0.3277,
      "step": 1476
    },
    {
      "epoch": 0.11478085172520983,
      "grad_norm": 0.34868013858795166,
      "learning_rate": 9.426095741373951e-06,
      "loss": 0.7692,
      "step": 1477
    },
    {
      "epoch": 0.11485856387939074,
      "grad_norm": 0.12371034175157547,
      "learning_rate": 9.425707180603048e-06,
      "loss": 0.0706,
      "step": 1478
    },
    {
      "epoch": 0.11493627603357165,
      "grad_norm": 0.16629190742969513,
      "learning_rate": 9.425318619832143e-06,
      "loss": 0.1086,
      "step": 1479
    },
    {
      "epoch": 0.11501398818775256,
      "grad_norm": 0.6302667856216431,
      "learning_rate": 9.424930059061238e-06,
      "loss": 0.5212,
      "step": 1480
    },
    {
      "epoch": 0.11509170034193347,
      "grad_norm": 0.3159295916557312,
      "learning_rate": 9.424541498290335e-06,
      "loss": 0.235,
      "step": 1481
    },
    {
      "epoch": 0.1151694124961144,
      "grad_norm": 0.5272226333618164,
      "learning_rate": 9.424152937519428e-06,
      "loss": 0.6216,
      "step": 1482
    },
    {
      "epoch": 0.11524712465029531,
      "grad_norm": 0.06927769631147385,
      "learning_rate": 9.423764376748525e-06,
      "loss": 0.0281,
      "step": 1483
    },
    {
      "epoch": 0.11532483680447622,
      "grad_norm": 0.3300118148326874,
      "learning_rate": 9.42337581597762e-06,
      "loss": 0.2186,
      "step": 1484
    },
    {
      "epoch": 0.11540254895865713,
      "grad_norm": 0.22898368537425995,
      "learning_rate": 9.422987255206714e-06,
      "loss": 0.2593,
      "step": 1485
    },
    {
      "epoch": 0.11548026111283805,
      "grad_norm": 0.20713818073272705,
      "learning_rate": 9.422598694435811e-06,
      "loss": 0.0958,
      "step": 1486
    },
    {
      "epoch": 0.11555797326701896,
      "grad_norm": 0.31382256746292114,
      "learning_rate": 9.422210133664906e-06,
      "loss": 0.1614,
      "step": 1487
    },
    {
      "epoch": 0.11563568542119988,
      "grad_norm": 0.3958500921726227,
      "learning_rate": 9.421821572894001e-06,
      "loss": 0.445,
      "step": 1488
    },
    {
      "epoch": 0.1157133975753808,
      "grad_norm": 0.42242804169654846,
      "learning_rate": 9.421433012123098e-06,
      "loss": 0.422,
      "step": 1489
    },
    {
      "epoch": 0.1157911097295617,
      "grad_norm": 0.45914798974990845,
      "learning_rate": 9.421044451352193e-06,
      "loss": 0.2679,
      "step": 1490
    },
    {
      "epoch": 0.11586882188374262,
      "grad_norm": 0.22841298580169678,
      "learning_rate": 9.420655890581288e-06,
      "loss": 0.2413,
      "step": 1491
    },
    {
      "epoch": 0.11594653403792353,
      "grad_norm": 0.44690483808517456,
      "learning_rate": 9.420267329810382e-06,
      "loss": 0.4321,
      "step": 1492
    },
    {
      "epoch": 0.11602424619210444,
      "grad_norm": 0.3820491433143616,
      "learning_rate": 9.419878769039479e-06,
      "loss": 0.2549,
      "step": 1493
    },
    {
      "epoch": 0.11610195834628535,
      "grad_norm": 0.16771200299263,
      "learning_rate": 9.419490208268574e-06,
      "loss": 0.0833,
      "step": 1494
    },
    {
      "epoch": 0.11617967050046628,
      "grad_norm": 0.5938539505004883,
      "learning_rate": 9.419101647497669e-06,
      "loss": 0.3822,
      "step": 1495
    },
    {
      "epoch": 0.11625738265464719,
      "grad_norm": 0.10977505147457123,
      "learning_rate": 9.418713086726766e-06,
      "loss": 0.0479,
      "step": 1496
    },
    {
      "epoch": 0.1163350948088281,
      "grad_norm": 0.12644259631633759,
      "learning_rate": 9.41832452595586e-06,
      "loss": 0.097,
      "step": 1497
    },
    {
      "epoch": 0.11641280696300901,
      "grad_norm": 0.26894164085388184,
      "learning_rate": 9.417935965184956e-06,
      "loss": 0.6865,
      "step": 1498
    },
    {
      "epoch": 0.11649051911718993,
      "grad_norm": 0.31634482741355896,
      "learning_rate": 9.41754740441405e-06,
      "loss": 0.3022,
      "step": 1499
    },
    {
      "epoch": 0.11656823127137084,
      "grad_norm": 0.10628661513328552,
      "learning_rate": 9.417158843643145e-06,
      "loss": 0.0329,
      "step": 1500
    },
    {
      "epoch": 0.11664594342555176,
      "grad_norm": 0.14291127026081085,
      "learning_rate": 9.416770282872242e-06,
      "loss": 0.0349,
      "step": 1501
    },
    {
      "epoch": 0.11672365557973267,
      "grad_norm": 0.19540710747241974,
      "learning_rate": 9.416381722101337e-06,
      "loss": 0.1042,
      "step": 1502
    },
    {
      "epoch": 0.11680136773391359,
      "grad_norm": 0.3166726529598236,
      "learning_rate": 9.415993161330434e-06,
      "loss": 0.2626,
      "step": 1503
    },
    {
      "epoch": 0.1168790798880945,
      "grad_norm": 0.18015383183956146,
      "learning_rate": 9.415604600559529e-06,
      "loss": 0.062,
      "step": 1504
    },
    {
      "epoch": 0.11695679204227541,
      "grad_norm": 0.11483360081911087,
      "learning_rate": 9.415216039788624e-06,
      "loss": 0.0876,
      "step": 1505
    },
    {
      "epoch": 0.11703450419645632,
      "grad_norm": 0.341531902551651,
      "learning_rate": 9.41482747901772e-06,
      "loss": 0.3427,
      "step": 1506
    },
    {
      "epoch": 0.11711221635063725,
      "grad_norm": 2.462860584259033,
      "learning_rate": 9.414438918246813e-06,
      "loss": 1.0093,
      "step": 1507
    },
    {
      "epoch": 0.11718992850481816,
      "grad_norm": 0.07030370086431503,
      "learning_rate": 9.41405035747591e-06,
      "loss": 0.0414,
      "step": 1508
    },
    {
      "epoch": 0.11726764065899907,
      "grad_norm": 0.16463056206703186,
      "learning_rate": 9.413661796705005e-06,
      "loss": 0.0902,
      "step": 1509
    },
    {
      "epoch": 0.11734535281317998,
      "grad_norm": 0.43511176109313965,
      "learning_rate": 9.4132732359341e-06,
      "loss": 0.1879,
      "step": 1510
    },
    {
      "epoch": 0.1174230649673609,
      "grad_norm": 0.1331603229045868,
      "learning_rate": 9.412884675163197e-06,
      "loss": 0.0638,
      "step": 1511
    },
    {
      "epoch": 0.1175007771215418,
      "grad_norm": 0.04950648546218872,
      "learning_rate": 9.412496114392292e-06,
      "loss": 0.0199,
      "step": 1512
    },
    {
      "epoch": 0.11757848927572272,
      "grad_norm": 0.3571629226207733,
      "learning_rate": 9.412107553621387e-06,
      "loss": 0.2997,
      "step": 1513
    },
    {
      "epoch": 0.11765620142990364,
      "grad_norm": 0.5292398929595947,
      "learning_rate": 9.411718992850483e-06,
      "loss": 0.1878,
      "step": 1514
    },
    {
      "epoch": 0.11773391358408455,
      "grad_norm": 0.3311581015586853,
      "learning_rate": 9.411330432079578e-06,
      "loss": 0.1974,
      "step": 1515
    },
    {
      "epoch": 0.11781162573826547,
      "grad_norm": 0.2612418234348297,
      "learning_rate": 9.410941871308673e-06,
      "loss": 0.0993,
      "step": 1516
    },
    {
      "epoch": 0.11788933789244638,
      "grad_norm": 0.31940987706184387,
      "learning_rate": 9.410553310537768e-06,
      "loss": 0.2287,
      "step": 1517
    },
    {
      "epoch": 0.11796705004662729,
      "grad_norm": 0.08244486898183823,
      "learning_rate": 9.410164749766865e-06,
      "loss": 0.0159,
      "step": 1518
    },
    {
      "epoch": 0.1180447622008082,
      "grad_norm": 0.6145244836807251,
      "learning_rate": 9.40977618899596e-06,
      "loss": 0.5457,
      "step": 1519
    },
    {
      "epoch": 0.11812247435498913,
      "grad_norm": 0.24950392544269562,
      "learning_rate": 9.409387628225055e-06,
      "loss": 0.1003,
      "step": 1520
    },
    {
      "epoch": 0.11820018650917004,
      "grad_norm": 0.49046429991722107,
      "learning_rate": 9.408999067454151e-06,
      "loss": 0.2194,
      "step": 1521
    },
    {
      "epoch": 0.11827789866335095,
      "grad_norm": 0.3232838809490204,
      "learning_rate": 9.408610506683246e-06,
      "loss": 0.4362,
      "step": 1522
    },
    {
      "epoch": 0.11835561081753186,
      "grad_norm": 0.4530041217803955,
      "learning_rate": 9.408221945912341e-06,
      "loss": 0.1972,
      "step": 1523
    },
    {
      "epoch": 0.11843332297171277,
      "grad_norm": 0.11315484344959259,
      "learning_rate": 9.407833385141438e-06,
      "loss": 0.0309,
      "step": 1524
    },
    {
      "epoch": 0.11851103512589369,
      "grad_norm": 0.1193995475769043,
      "learning_rate": 9.407444824370531e-06,
      "loss": 0.0455,
      "step": 1525
    },
    {
      "epoch": 0.1185887472800746,
      "grad_norm": 0.08341259509325027,
      "learning_rate": 9.407056263599628e-06,
      "loss": 0.0574,
      "step": 1526
    },
    {
      "epoch": 0.11866645943425552,
      "grad_norm": 0.2091815024614334,
      "learning_rate": 9.406667702828723e-06,
      "loss": 0.1433,
      "step": 1527
    },
    {
      "epoch": 0.11874417158843643,
      "grad_norm": 0.1772383451461792,
      "learning_rate": 9.406279142057818e-06,
      "loss": 0.1782,
      "step": 1528
    },
    {
      "epoch": 0.11882188374261735,
      "grad_norm": 0.1099373996257782,
      "learning_rate": 9.405890581286914e-06,
      "loss": 0.0579,
      "step": 1529
    },
    {
      "epoch": 0.11889959589679826,
      "grad_norm": 0.2793610990047455,
      "learning_rate": 9.40550202051601e-06,
      "loss": 0.2786,
      "step": 1530
    },
    {
      "epoch": 0.11897730805097917,
      "grad_norm": 0.609150767326355,
      "learning_rate": 9.405113459745104e-06,
      "loss": 0.2233,
      "step": 1531
    },
    {
      "epoch": 0.11905502020516008,
      "grad_norm": 0.14922000467777252,
      "learning_rate": 9.4047248989742e-06,
      "loss": 0.1356,
      "step": 1532
    },
    {
      "epoch": 0.119132732359341,
      "grad_norm": 0.42877599596977234,
      "learning_rate": 9.404336338203296e-06,
      "loss": 0.2654,
      "step": 1533
    },
    {
      "epoch": 0.11921044451352192,
      "grad_norm": 0.12850260734558105,
      "learning_rate": 9.403947777432392e-06,
      "loss": 0.0793,
      "step": 1534
    },
    {
      "epoch": 0.11928815666770283,
      "grad_norm": 0.20082786679267883,
      "learning_rate": 9.403559216661486e-06,
      "loss": 0.0519,
      "step": 1535
    },
    {
      "epoch": 0.11936586882188374,
      "grad_norm": 0.3279445171356201,
      "learning_rate": 9.403170655890582e-06,
      "loss": 0.1386,
      "step": 1536
    },
    {
      "epoch": 0.11944358097606465,
      "grad_norm": 0.08447213470935822,
      "learning_rate": 9.402782095119677e-06,
      "loss": 0.0411,
      "step": 1537
    },
    {
      "epoch": 0.11952129313024557,
      "grad_norm": 0.34385842084884644,
      "learning_rate": 9.402393534348772e-06,
      "loss": 0.1819,
      "step": 1538
    },
    {
      "epoch": 0.11959900528442649,
      "grad_norm": 0.22434397041797638,
      "learning_rate": 9.402004973577869e-06,
      "loss": 0.2137,
      "step": 1539
    },
    {
      "epoch": 0.1196767174386074,
      "grad_norm": 0.7026426196098328,
      "learning_rate": 9.401616412806964e-06,
      "loss": 0.3741,
      "step": 1540
    },
    {
      "epoch": 0.11975442959278831,
      "grad_norm": 0.06836152821779251,
      "learning_rate": 9.401227852036059e-06,
      "loss": 0.0364,
      "step": 1541
    },
    {
      "epoch": 0.11983214174696923,
      "grad_norm": 0.15613143146038055,
      "learning_rate": 9.400839291265155e-06,
      "loss": 0.1267,
      "step": 1542
    },
    {
      "epoch": 0.11990985390115014,
      "grad_norm": 0.16348028182983398,
      "learning_rate": 9.40045073049425e-06,
      "loss": 0.0989,
      "step": 1543
    },
    {
      "epoch": 0.11998756605533105,
      "grad_norm": 0.1355857402086258,
      "learning_rate": 9.400062169723345e-06,
      "loss": 0.086,
      "step": 1544
    },
    {
      "epoch": 0.12006527820951196,
      "grad_norm": 0.28797513246536255,
      "learning_rate": 9.39967360895244e-06,
      "loss": 0.1566,
      "step": 1545
    },
    {
      "epoch": 0.12014299036369289,
      "grad_norm": 0.5580248832702637,
      "learning_rate": 9.399285048181537e-06,
      "loss": 0.459,
      "step": 1546
    },
    {
      "epoch": 0.1202207025178738,
      "grad_norm": 0.3115694522857666,
      "learning_rate": 9.398896487410632e-06,
      "loss": 0.1902,
      "step": 1547
    },
    {
      "epoch": 0.12029841467205471,
      "grad_norm": 0.08472073078155518,
      "learning_rate": 9.398507926639727e-06,
      "loss": 0.0854,
      "step": 1548
    },
    {
      "epoch": 0.12037612682623562,
      "grad_norm": 0.1357249617576599,
      "learning_rate": 9.398119365868823e-06,
      "loss": 0.1098,
      "step": 1549
    },
    {
      "epoch": 0.12045383898041653,
      "grad_norm": 0.5400413274765015,
      "learning_rate": 9.397730805097918e-06,
      "loss": 0.2923,
      "step": 1550
    },
    {
      "epoch": 0.12053155113459744,
      "grad_norm": 0.26230597496032715,
      "learning_rate": 9.397342244327013e-06,
      "loss": 0.2526,
      "step": 1551
    },
    {
      "epoch": 0.12060926328877837,
      "grad_norm": 0.19211634993553162,
      "learning_rate": 9.39695368355611e-06,
      "loss": 0.1106,
      "step": 1552
    },
    {
      "epoch": 0.12068697544295928,
      "grad_norm": 0.427055686712265,
      "learning_rate": 9.396565122785203e-06,
      "loss": 0.771,
      "step": 1553
    },
    {
      "epoch": 0.1207646875971402,
      "grad_norm": 0.6526730060577393,
      "learning_rate": 9.3961765620143e-06,
      "loss": 0.2495,
      "step": 1554
    },
    {
      "epoch": 0.1208423997513211,
      "grad_norm": 0.2938522696495056,
      "learning_rate": 9.395788001243395e-06,
      "loss": 0.2989,
      "step": 1555
    },
    {
      "epoch": 0.12092011190550202,
      "grad_norm": 0.19015026092529297,
      "learning_rate": 9.39539944047249e-06,
      "loss": 0.0752,
      "step": 1556
    },
    {
      "epoch": 0.12099782405968293,
      "grad_norm": 0.2045445740222931,
      "learning_rate": 9.395010879701586e-06,
      "loss": 0.1594,
      "step": 1557
    },
    {
      "epoch": 0.12107553621386385,
      "grad_norm": 0.16440723836421967,
      "learning_rate": 9.394622318930681e-06,
      "loss": 0.1997,
      "step": 1558
    },
    {
      "epoch": 0.12115324836804477,
      "grad_norm": 0.6927515268325806,
      "learning_rate": 9.394233758159776e-06,
      "loss": 0.5186,
      "step": 1559
    },
    {
      "epoch": 0.12123096052222568,
      "grad_norm": 0.31557193398475647,
      "learning_rate": 9.393845197388873e-06,
      "loss": 0.2997,
      "step": 1560
    },
    {
      "epoch": 0.12130867267640659,
      "grad_norm": 0.28826332092285156,
      "learning_rate": 9.393456636617968e-06,
      "loss": 0.2167,
      "step": 1561
    },
    {
      "epoch": 0.1213863848305875,
      "grad_norm": 0.2776035666465759,
      "learning_rate": 9.393068075847063e-06,
      "loss": 0.1049,
      "step": 1562
    },
    {
      "epoch": 0.12146409698476841,
      "grad_norm": 0.09718382358551025,
      "learning_rate": 9.392679515076158e-06,
      "loss": 0.0414,
      "step": 1563
    },
    {
      "epoch": 0.12154180913894932,
      "grad_norm": 0.2714114189147949,
      "learning_rate": 9.392290954305254e-06,
      "loss": 0.1518,
      "step": 1564
    },
    {
      "epoch": 0.12161952129313025,
      "grad_norm": 0.19824053347110748,
      "learning_rate": 9.39190239353435e-06,
      "loss": 0.1259,
      "step": 1565
    },
    {
      "epoch": 0.12169723344731116,
      "grad_norm": 0.35053354501724243,
      "learning_rate": 9.391513832763444e-06,
      "loss": 0.122,
      "step": 1566
    },
    {
      "epoch": 0.12177494560149207,
      "grad_norm": 0.2943721413612366,
      "learning_rate": 9.391125271992541e-06,
      "loss": 0.2615,
      "step": 1567
    },
    {
      "epoch": 0.12185265775567299,
      "grad_norm": 0.09714964032173157,
      "learning_rate": 9.390736711221636e-06,
      "loss": 0.0372,
      "step": 1568
    },
    {
      "epoch": 0.1219303699098539,
      "grad_norm": 0.4748348295688629,
      "learning_rate": 9.390348150450731e-06,
      "loss": 0.3557,
      "step": 1569
    },
    {
      "epoch": 0.12200808206403481,
      "grad_norm": 0.06981499493122101,
      "learning_rate": 9.389959589679828e-06,
      "loss": 0.0399,
      "step": 1570
    },
    {
      "epoch": 0.12208579421821573,
      "grad_norm": 0.0701863020658493,
      "learning_rate": 9.389571028908922e-06,
      "loss": 0.0336,
      "step": 1571
    },
    {
      "epoch": 0.12216350637239665,
      "grad_norm": 0.36391010880470276,
      "learning_rate": 9.389182468138017e-06,
      "loss": 0.0708,
      "step": 1572
    },
    {
      "epoch": 0.12224121852657756,
      "grad_norm": 0.1961391717195511,
      "learning_rate": 9.388793907367112e-06,
      "loss": 0.1775,
      "step": 1573
    },
    {
      "epoch": 0.12231893068075847,
      "grad_norm": 0.3674410581588745,
      "learning_rate": 9.388405346596209e-06,
      "loss": 0.5815,
      "step": 1574
    },
    {
      "epoch": 0.12239664283493938,
      "grad_norm": 0.4582792818546295,
      "learning_rate": 9.388016785825304e-06,
      "loss": 0.2227,
      "step": 1575
    },
    {
      "epoch": 0.1224743549891203,
      "grad_norm": 0.24597737193107605,
      "learning_rate": 9.387628225054399e-06,
      "loss": 0.1925,
      "step": 1576
    },
    {
      "epoch": 0.12255206714330122,
      "grad_norm": 0.25685977935791016,
      "learning_rate": 9.387239664283496e-06,
      "loss": 0.1131,
      "step": 1577
    },
    {
      "epoch": 0.12262977929748213,
      "grad_norm": 0.2432180941104889,
      "learning_rate": 9.38685110351259e-06,
      "loss": 0.2554,
      "step": 1578
    },
    {
      "epoch": 0.12270749145166304,
      "grad_norm": 0.25247037410736084,
      "learning_rate": 9.386462542741685e-06,
      "loss": 0.1987,
      "step": 1579
    },
    {
      "epoch": 0.12278520360584395,
      "grad_norm": 0.3712048828601837,
      "learning_rate": 9.386073981970782e-06,
      "loss": 0.5276,
      "step": 1580
    },
    {
      "epoch": 0.12286291576002487,
      "grad_norm": 0.06870180368423462,
      "learning_rate": 9.385685421199875e-06,
      "loss": 0.035,
      "step": 1581
    },
    {
      "epoch": 0.12294062791420578,
      "grad_norm": 0.2399546355009079,
      "learning_rate": 9.385296860428972e-06,
      "loss": 0.1136,
      "step": 1582
    },
    {
      "epoch": 0.12301834006838669,
      "grad_norm": 0.18977616727352142,
      "learning_rate": 9.384908299658067e-06,
      "loss": 0.066,
      "step": 1583
    },
    {
      "epoch": 0.12309605222256761,
      "grad_norm": 0.2879248261451721,
      "learning_rate": 9.384519738887162e-06,
      "loss": 0.2163,
      "step": 1584
    },
    {
      "epoch": 0.12317376437674853,
      "grad_norm": 0.2932817041873932,
      "learning_rate": 9.384131178116259e-06,
      "loss": 0.1431,
      "step": 1585
    },
    {
      "epoch": 0.12325147653092944,
      "grad_norm": 0.22645123302936554,
      "learning_rate": 9.383742617345353e-06,
      "loss": 0.1446,
      "step": 1586
    },
    {
      "epoch": 0.12332918868511035,
      "grad_norm": 0.5070374608039856,
      "learning_rate": 9.383354056574448e-06,
      "loss": 0.6338,
      "step": 1587
    },
    {
      "epoch": 0.12340690083929126,
      "grad_norm": 0.15266768634319305,
      "learning_rate": 9.382965495803545e-06,
      "loss": 0.0683,
      "step": 1588
    },
    {
      "epoch": 0.12348461299347217,
      "grad_norm": 0.2527906894683838,
      "learning_rate": 9.38257693503264e-06,
      "loss": 0.196,
      "step": 1589
    },
    {
      "epoch": 0.1235623251476531,
      "grad_norm": 0.09217587113380432,
      "learning_rate": 9.382188374261735e-06,
      "loss": 0.0246,
      "step": 1590
    },
    {
      "epoch": 0.12364003730183401,
      "grad_norm": 0.9919965863227844,
      "learning_rate": 9.38179981349083e-06,
      "loss": 0.3003,
      "step": 1591
    },
    {
      "epoch": 0.12371774945601492,
      "grad_norm": 0.38927754759788513,
      "learning_rate": 9.381411252719927e-06,
      "loss": 0.292,
      "step": 1592
    },
    {
      "epoch": 0.12379546161019583,
      "grad_norm": 0.4607742726802826,
      "learning_rate": 9.381022691949022e-06,
      "loss": 0.5264,
      "step": 1593
    },
    {
      "epoch": 0.12387317376437675,
      "grad_norm": 0.23596446216106415,
      "learning_rate": 9.380634131178116e-06,
      "loss": 0.2474,
      "step": 1594
    },
    {
      "epoch": 0.12395088591855766,
      "grad_norm": 0.22497780621051788,
      "learning_rate": 9.380245570407213e-06,
      "loss": 0.092,
      "step": 1595
    },
    {
      "epoch": 0.12402859807273858,
      "grad_norm": 0.30640512704849243,
      "learning_rate": 9.379857009636308e-06,
      "loss": 0.2416,
      "step": 1596
    },
    {
      "epoch": 0.1241063102269195,
      "grad_norm": 0.9760950207710266,
      "learning_rate": 9.379468448865403e-06,
      "loss": 0.1136,
      "step": 1597
    },
    {
      "epoch": 0.1241840223811004,
      "grad_norm": 0.2674091160297394,
      "learning_rate": 9.3790798880945e-06,
      "loss": 0.2155,
      "step": 1598
    },
    {
      "epoch": 0.12426173453528132,
      "grad_norm": 0.2913026213645935,
      "learning_rate": 9.378691327323595e-06,
      "loss": 0.0544,
      "step": 1599
    },
    {
      "epoch": 0.12433944668946223,
      "grad_norm": 0.0736997202038765,
      "learning_rate": 9.37830276655269e-06,
      "loss": 0.0438,
      "step": 1600
    },
    {
      "epoch": 0.12441715884364314,
      "grad_norm": 0.23800060153007507,
      "learning_rate": 9.377914205781785e-06,
      "loss": 0.1141,
      "step": 1601
    },
    {
      "epoch": 0.12449487099782405,
      "grad_norm": 0.2429092973470688,
      "learning_rate": 9.377525645010881e-06,
      "loss": 0.134,
      "step": 1602
    },
    {
      "epoch": 0.12457258315200498,
      "grad_norm": 0.5129991173744202,
      "learning_rate": 9.377137084239976e-06,
      "loss": 0.3553,
      "step": 1603
    },
    {
      "epoch": 0.12465029530618589,
      "grad_norm": 0.11921272426843643,
      "learning_rate": 9.376748523469071e-06,
      "loss": 0.0866,
      "step": 1604
    },
    {
      "epoch": 0.1247280074603668,
      "grad_norm": 0.38691774010658264,
      "learning_rate": 9.376359962698168e-06,
      "loss": 0.4176,
      "step": 1605
    },
    {
      "epoch": 0.12480571961454771,
      "grad_norm": 0.37283894419670105,
      "learning_rate": 9.375971401927263e-06,
      "loss": 0.5031,
      "step": 1606
    },
    {
      "epoch": 0.12488343176872863,
      "grad_norm": 0.3267390727996826,
      "learning_rate": 9.375582841156358e-06,
      "loss": 0.2641,
      "step": 1607
    },
    {
      "epoch": 0.12496114392290954,
      "grad_norm": 0.2737733721733093,
      "learning_rate": 9.375194280385454e-06,
      "loss": 0.1909,
      "step": 1608
    },
    {
      "epoch": 0.12503885607709045,
      "grad_norm": 0.11461140215396881,
      "learning_rate": 9.374805719614548e-06,
      "loss": 0.0413,
      "step": 1609
    },
    {
      "epoch": 0.12511656823127137,
      "grad_norm": 0.42512062191963196,
      "learning_rate": 9.374417158843644e-06,
      "loss": 0.2356,
      "step": 1610
    },
    {
      "epoch": 0.12519428038545227,
      "grad_norm": 0.3523106873035431,
      "learning_rate": 9.374028598072739e-06,
      "loss": 0.2874,
      "step": 1611
    },
    {
      "epoch": 0.1252719925396332,
      "grad_norm": 0.6346626877784729,
      "learning_rate": 9.373640037301834e-06,
      "loss": 0.2582,
      "step": 1612
    },
    {
      "epoch": 0.12534970469381412,
      "grad_norm": 0.4901833236217499,
      "learning_rate": 9.37325147653093e-06,
      "loss": 0.2749,
      "step": 1613
    },
    {
      "epoch": 0.12542741684799502,
      "grad_norm": 0.35652294754981995,
      "learning_rate": 9.372862915760026e-06,
      "loss": 0.2349,
      "step": 1614
    },
    {
      "epoch": 0.12550512900217595,
      "grad_norm": 0.49236470460891724,
      "learning_rate": 9.37247435498912e-06,
      "loss": 0.4851,
      "step": 1615
    },
    {
      "epoch": 0.12558284115635684,
      "grad_norm": 0.47737008333206177,
      "learning_rate": 9.372085794218217e-06,
      "loss": 0.0989,
      "step": 1616
    },
    {
      "epoch": 0.12566055331053777,
      "grad_norm": 0.26015886664390564,
      "learning_rate": 9.371697233447312e-06,
      "loss": 0.1626,
      "step": 1617
    },
    {
      "epoch": 0.12573826546471867,
      "grad_norm": 0.4171718657016754,
      "learning_rate": 9.371308672676407e-06,
      "loss": 0.4884,
      "step": 1618
    },
    {
      "epoch": 0.1258159776188996,
      "grad_norm": 0.18169376254081726,
      "learning_rate": 9.370920111905502e-06,
      "loss": 0.2167,
      "step": 1619
    },
    {
      "epoch": 0.12589368977308052,
      "grad_norm": 0.1484575867652893,
      "learning_rate": 9.370531551134599e-06,
      "loss": 0.0697,
      "step": 1620
    },
    {
      "epoch": 0.12597140192726142,
      "grad_norm": 0.2728215754032135,
      "learning_rate": 9.370142990363694e-06,
      "loss": 0.1573,
      "step": 1621
    },
    {
      "epoch": 0.12604911408144234,
      "grad_norm": 0.5840156078338623,
      "learning_rate": 9.369754429592789e-06,
      "loss": 0.4011,
      "step": 1622
    },
    {
      "epoch": 0.12612682623562324,
      "grad_norm": 0.14646640419960022,
      "learning_rate": 9.369365868821885e-06,
      "loss": 0.0605,
      "step": 1623
    },
    {
      "epoch": 0.12620453838980417,
      "grad_norm": 0.29752060770988464,
      "learning_rate": 9.36897730805098e-06,
      "loss": 0.2774,
      "step": 1624
    },
    {
      "epoch": 0.1262822505439851,
      "grad_norm": 0.2576594054698944,
      "learning_rate": 9.368588747280075e-06,
      "loss": 0.1605,
      "step": 1625
    },
    {
      "epoch": 0.126359962698166,
      "grad_norm": 0.08608041703701019,
      "learning_rate": 9.36820018650917e-06,
      "loss": 0.0594,
      "step": 1626
    },
    {
      "epoch": 0.12643767485234692,
      "grad_norm": 0.4943833649158478,
      "learning_rate": 9.367811625738267e-06,
      "loss": 0.1757,
      "step": 1627
    },
    {
      "epoch": 0.1265153870065278,
      "grad_norm": 0.2603176534175873,
      "learning_rate": 9.367423064967362e-06,
      "loss": 0.0401,
      "step": 1628
    },
    {
      "epoch": 0.12659309916070874,
      "grad_norm": 0.6813678741455078,
      "learning_rate": 9.367034504196457e-06,
      "loss": 0.3659,
      "step": 1629
    },
    {
      "epoch": 0.12667081131488964,
      "grad_norm": 0.27950453758239746,
      "learning_rate": 9.366645943425553e-06,
      "loss": 0.0501,
      "step": 1630
    },
    {
      "epoch": 0.12674852346907056,
      "grad_norm": 0.130384624004364,
      "learning_rate": 9.366257382654648e-06,
      "loss": 0.0345,
      "step": 1631
    },
    {
      "epoch": 0.1268262356232515,
      "grad_norm": 0.45734331011772156,
      "learning_rate": 9.365868821883743e-06,
      "loss": 0.1997,
      "step": 1632
    },
    {
      "epoch": 0.12690394777743239,
      "grad_norm": 0.08990037441253662,
      "learning_rate": 9.36548026111284e-06,
      "loss": 0.02,
      "step": 1633
    },
    {
      "epoch": 0.1269816599316133,
      "grad_norm": 0.16154545545578003,
      "learning_rate": 9.365091700341933e-06,
      "loss": 0.0812,
      "step": 1634
    },
    {
      "epoch": 0.1270593720857942,
      "grad_norm": 0.2610047459602356,
      "learning_rate": 9.36470313957103e-06,
      "loss": 0.1478,
      "step": 1635
    },
    {
      "epoch": 0.12713708423997513,
      "grad_norm": 0.71878582239151,
      "learning_rate": 9.364314578800125e-06,
      "loss": 0.5135,
      "step": 1636
    },
    {
      "epoch": 0.12721479639415603,
      "grad_norm": 0.696296751499176,
      "learning_rate": 9.36392601802922e-06,
      "loss": 0.4349,
      "step": 1637
    },
    {
      "epoch": 0.12729250854833696,
      "grad_norm": 0.48520612716674805,
      "learning_rate": 9.363537457258316e-06,
      "loss": 0.3638,
      "step": 1638
    },
    {
      "epoch": 0.12737022070251788,
      "grad_norm": 0.18026967346668243,
      "learning_rate": 9.363148896487411e-06,
      "loss": 0.1737,
      "step": 1639
    },
    {
      "epoch": 0.12744793285669878,
      "grad_norm": 0.6090734004974365,
      "learning_rate": 9.362760335716506e-06,
      "loss": 0.6029,
      "step": 1640
    },
    {
      "epoch": 0.1275256450108797,
      "grad_norm": 0.44693922996520996,
      "learning_rate": 9.362371774945603e-06,
      "loss": 0.2602,
      "step": 1641
    },
    {
      "epoch": 0.1276033571650606,
      "grad_norm": 0.16370175778865814,
      "learning_rate": 9.361983214174698e-06,
      "loss": 0.0829,
      "step": 1642
    },
    {
      "epoch": 0.12768106931924153,
      "grad_norm": 0.0896555483341217,
      "learning_rate": 9.361594653403793e-06,
      "loss": 0.0224,
      "step": 1643
    },
    {
      "epoch": 0.12775878147342246,
      "grad_norm": 0.2713298499584198,
      "learning_rate": 9.361206092632888e-06,
      "loss": 0.1877,
      "step": 1644
    },
    {
      "epoch": 0.12783649362760335,
      "grad_norm": 0.07330712676048279,
      "learning_rate": 9.360817531861984e-06,
      "loss": 0.016,
      "step": 1645
    },
    {
      "epoch": 0.12791420578178428,
      "grad_norm": 0.17754413187503815,
      "learning_rate": 9.36042897109108e-06,
      "loss": 0.1432,
      "step": 1646
    },
    {
      "epoch": 0.12799191793596518,
      "grad_norm": 0.2002880573272705,
      "learning_rate": 9.360040410320174e-06,
      "loss": 0.3496,
      "step": 1647
    },
    {
      "epoch": 0.1280696300901461,
      "grad_norm": 0.21397365629673004,
      "learning_rate": 9.359651849549271e-06,
      "loss": 0.1152,
      "step": 1648
    },
    {
      "epoch": 0.128147342244327,
      "grad_norm": 0.39989736676216125,
      "learning_rate": 9.359263288778366e-06,
      "loss": 0.2943,
      "step": 1649
    },
    {
      "epoch": 0.12822505439850793,
      "grad_norm": 0.18334710597991943,
      "learning_rate": 9.35887472800746e-06,
      "loss": 0.0938,
      "step": 1650
    },
    {
      "epoch": 0.12830276655268885,
      "grad_norm": 0.10242019593715668,
      "learning_rate": 9.358486167236557e-06,
      "loss": 0.079,
      "step": 1651
    },
    {
      "epoch": 0.12838047870686975,
      "grad_norm": 0.2817603647708893,
      "learning_rate": 9.35809760646565e-06,
      "loss": 0.2194,
      "step": 1652
    },
    {
      "epoch": 0.12845819086105068,
      "grad_norm": 0.11327309161424637,
      "learning_rate": 9.357709045694747e-06,
      "loss": 0.0915,
      "step": 1653
    },
    {
      "epoch": 0.12853590301523157,
      "grad_norm": 0.6409659385681152,
      "learning_rate": 9.357320484923842e-06,
      "loss": 0.1683,
      "step": 1654
    },
    {
      "epoch": 0.1286136151694125,
      "grad_norm": 0.1367684155702591,
      "learning_rate": 9.356931924152939e-06,
      "loss": 0.0861,
      "step": 1655
    },
    {
      "epoch": 0.1286913273235934,
      "grad_norm": 0.30524304509162903,
      "learning_rate": 9.356543363382034e-06,
      "loss": 0.7451,
      "step": 1656
    },
    {
      "epoch": 0.12876903947777432,
      "grad_norm": 1.1974899768829346,
      "learning_rate": 9.356154802611129e-06,
      "loss": 0.2648,
      "step": 1657
    },
    {
      "epoch": 0.12884675163195525,
      "grad_norm": 0.09621545672416687,
      "learning_rate": 9.355766241840225e-06,
      "loss": 0.0398,
      "step": 1658
    },
    {
      "epoch": 0.12892446378613615,
      "grad_norm": 0.3442577123641968,
      "learning_rate": 9.35537768106932e-06,
      "loss": 0.1996,
      "step": 1659
    },
    {
      "epoch": 0.12900217594031707,
      "grad_norm": 0.21111096441745758,
      "learning_rate": 9.354989120298415e-06,
      "loss": 0.1173,
      "step": 1660
    },
    {
      "epoch": 0.12907988809449797,
      "grad_norm": 0.09778859466314316,
      "learning_rate": 9.354600559527512e-06,
      "loss": 0.0322,
      "step": 1661
    },
    {
      "epoch": 0.1291576002486789,
      "grad_norm": 0.21240432560443878,
      "learning_rate": 9.354211998756605e-06,
      "loss": 0.1758,
      "step": 1662
    },
    {
      "epoch": 0.12923531240285982,
      "grad_norm": 0.19112183153629303,
      "learning_rate": 9.353823437985702e-06,
      "loss": 0.1792,
      "step": 1663
    },
    {
      "epoch": 0.12931302455704072,
      "grad_norm": 0.17739331722259521,
      "learning_rate": 9.353434877214797e-06,
      "loss": 0.0688,
      "step": 1664
    },
    {
      "epoch": 0.12939073671122164,
      "grad_norm": 0.2504313290119171,
      "learning_rate": 9.353046316443892e-06,
      "loss": 0.1923,
      "step": 1665
    },
    {
      "epoch": 0.12946844886540254,
      "grad_norm": 0.2919565439224243,
      "learning_rate": 9.352657755672988e-06,
      "loss": 0.3864,
      "step": 1666
    },
    {
      "epoch": 0.12954616101958347,
      "grad_norm": 0.011499261483550072,
      "learning_rate": 9.352269194902083e-06,
      "loss": 0.0018,
      "step": 1667
    },
    {
      "epoch": 0.12962387317376436,
      "grad_norm": 0.5377324223518372,
      "learning_rate": 9.351880634131178e-06,
      "loss": 0.8261,
      "step": 1668
    },
    {
      "epoch": 0.1297015853279453,
      "grad_norm": 0.23143164813518524,
      "learning_rate": 9.351492073360275e-06,
      "loss": 0.1992,
      "step": 1669
    },
    {
      "epoch": 0.12977929748212622,
      "grad_norm": 0.13850471377372742,
      "learning_rate": 9.35110351258937e-06,
      "loss": 0.057,
      "step": 1670
    },
    {
      "epoch": 0.1298570096363071,
      "grad_norm": 0.22081030905246735,
      "learning_rate": 9.350714951818465e-06,
      "loss": 0.0889,
      "step": 1671
    },
    {
      "epoch": 0.12993472179048804,
      "grad_norm": 0.12124975025653839,
      "learning_rate": 9.35032639104756e-06,
      "loss": 0.0673,
      "step": 1672
    },
    {
      "epoch": 0.13001243394466894,
      "grad_norm": 0.16748198866844177,
      "learning_rate": 9.349937830276656e-06,
      "loss": 0.1408,
      "step": 1673
    },
    {
      "epoch": 0.13009014609884986,
      "grad_norm": 0.5491378307342529,
      "learning_rate": 9.349549269505751e-06,
      "loss": 0.5869,
      "step": 1674
    },
    {
      "epoch": 0.13016785825303076,
      "grad_norm": 0.09215062856674194,
      "learning_rate": 9.349160708734846e-06,
      "loss": 0.1011,
      "step": 1675
    },
    {
      "epoch": 0.13024557040721169,
      "grad_norm": 0.483199805021286,
      "learning_rate": 9.348772147963943e-06,
      "loss": 0.4254,
      "step": 1676
    },
    {
      "epoch": 0.1303232825613926,
      "grad_norm": 0.13814233243465424,
      "learning_rate": 9.348383587193038e-06,
      "loss": 0.0467,
      "step": 1677
    },
    {
      "epoch": 0.1304009947155735,
      "grad_norm": 0.12819185853004456,
      "learning_rate": 9.347995026422133e-06,
      "loss": 0.0868,
      "step": 1678
    },
    {
      "epoch": 0.13047870686975443,
      "grad_norm": 0.33449527621269226,
      "learning_rate": 9.34760646565123e-06,
      "loss": 0.2509,
      "step": 1679
    },
    {
      "epoch": 0.13055641902393533,
      "grad_norm": 0.10896866023540497,
      "learning_rate": 9.347217904880323e-06,
      "loss": 0.0614,
      "step": 1680
    },
    {
      "epoch": 0.13063413117811626,
      "grad_norm": 0.20824046432971954,
      "learning_rate": 9.34682934410942e-06,
      "loss": 0.0944,
      "step": 1681
    },
    {
      "epoch": 0.13071184333229718,
      "grad_norm": 0.18089023232460022,
      "learning_rate": 9.346440783338514e-06,
      "loss": 0.0543,
      "step": 1682
    },
    {
      "epoch": 0.13078955548647808,
      "grad_norm": 0.2624190151691437,
      "learning_rate": 9.34605222256761e-06,
      "loss": 0.1948,
      "step": 1683
    },
    {
      "epoch": 0.130867267640659,
      "grad_norm": 0.3064875602722168,
      "learning_rate": 9.345663661796706e-06,
      "loss": 0.2077,
      "step": 1684
    },
    {
      "epoch": 0.1309449797948399,
      "grad_norm": 0.2834498882293701,
      "learning_rate": 9.345275101025801e-06,
      "loss": 0.1218,
      "step": 1685
    },
    {
      "epoch": 0.13102269194902083,
      "grad_norm": 0.23739825189113617,
      "learning_rate": 9.344886540254898e-06,
      "loss": 0.2685,
      "step": 1686
    },
    {
      "epoch": 0.13110040410320173,
      "grad_norm": 0.15436071157455444,
      "learning_rate": 9.344497979483993e-06,
      "loss": 0.0855,
      "step": 1687
    },
    {
      "epoch": 0.13117811625738265,
      "grad_norm": 0.12302982807159424,
      "learning_rate": 9.344109418713087e-06,
      "loss": 0.0628,
      "step": 1688
    },
    {
      "epoch": 0.13125582841156358,
      "grad_norm": 0.08696463704109192,
      "learning_rate": 9.343720857942184e-06,
      "loss": 0.0625,
      "step": 1689
    },
    {
      "epoch": 0.13133354056574448,
      "grad_norm": 0.21548545360565186,
      "learning_rate": 9.343332297171277e-06,
      "loss": 0.1376,
      "step": 1690
    },
    {
      "epoch": 0.1314112527199254,
      "grad_norm": 0.33304113149642944,
      "learning_rate": 9.342943736400374e-06,
      "loss": 0.1623,
      "step": 1691
    },
    {
      "epoch": 0.1314889648741063,
      "grad_norm": 0.08612014353275299,
      "learning_rate": 9.342555175629469e-06,
      "loss": 0.0347,
      "step": 1692
    },
    {
      "epoch": 0.13156667702828723,
      "grad_norm": 0.11575523763895035,
      "learning_rate": 9.342166614858564e-06,
      "loss": 0.0859,
      "step": 1693
    },
    {
      "epoch": 0.13164438918246812,
      "grad_norm": 0.31438079476356506,
      "learning_rate": 9.34177805408766e-06,
      "loss": 0.3174,
      "step": 1694
    },
    {
      "epoch": 0.13172210133664905,
      "grad_norm": 0.25891485810279846,
      "learning_rate": 9.341389493316756e-06,
      "loss": 0.0719,
      "step": 1695
    },
    {
      "epoch": 0.13179981349082998,
      "grad_norm": 0.15959922969341278,
      "learning_rate": 9.34100093254585e-06,
      "loss": 0.0858,
      "step": 1696
    },
    {
      "epoch": 0.13187752564501087,
      "grad_norm": 0.2208910584449768,
      "learning_rate": 9.340612371774947e-06,
      "loss": 0.2176,
      "step": 1697
    },
    {
      "epoch": 0.1319552377991918,
      "grad_norm": 0.2014714628458023,
      "learning_rate": 9.340223811004042e-06,
      "loss": 0.2152,
      "step": 1698
    },
    {
      "epoch": 0.1320329499533727,
      "grad_norm": 0.11190977692604065,
      "learning_rate": 9.339835250233137e-06,
      "loss": 0.0482,
      "step": 1699
    },
    {
      "epoch": 0.13211066210755362,
      "grad_norm": 0.0843263491988182,
      "learning_rate": 9.339446689462232e-06,
      "loss": 0.0656,
      "step": 1700
    },
    {
      "epoch": 0.13218837426173455,
      "grad_norm": 0.14930057525634766,
      "learning_rate": 9.339058128691329e-06,
      "loss": 0.0503,
      "step": 1701
    },
    {
      "epoch": 0.13226608641591545,
      "grad_norm": 0.2845979630947113,
      "learning_rate": 9.338669567920424e-06,
      "loss": 0.2409,
      "step": 1702
    },
    {
      "epoch": 0.13234379857009637,
      "grad_norm": 0.17211927473545074,
      "learning_rate": 9.338281007149519e-06,
      "loss": 0.1378,
      "step": 1703
    },
    {
      "epoch": 0.13242151072427727,
      "grad_norm": 0.3913266956806183,
      "learning_rate": 9.337892446378615e-06,
      "loss": 0.2797,
      "step": 1704
    },
    {
      "epoch": 0.1324992228784582,
      "grad_norm": 0.25459107756614685,
      "learning_rate": 9.33750388560771e-06,
      "loss": 0.1871,
      "step": 1705
    },
    {
      "epoch": 0.1325769350326391,
      "grad_norm": 0.050238169729709625,
      "learning_rate": 9.337115324836805e-06,
      "loss": 0.0438,
      "step": 1706
    },
    {
      "epoch": 0.13265464718682002,
      "grad_norm": 0.26948291063308716,
      "learning_rate": 9.336726764065902e-06,
      "loss": 0.1794,
      "step": 1707
    },
    {
      "epoch": 0.13273235934100094,
      "grad_norm": 0.05677285045385361,
      "learning_rate": 9.336338203294995e-06,
      "loss": 0.0409,
      "step": 1708
    },
    {
      "epoch": 0.13281007149518184,
      "grad_norm": 1.1089885234832764,
      "learning_rate": 9.335949642524092e-06,
      "loss": 0.2286,
      "step": 1709
    },
    {
      "epoch": 0.13288778364936277,
      "grad_norm": 0.3043385446071625,
      "learning_rate": 9.335561081753187e-06,
      "loss": 0.1348,
      "step": 1710
    },
    {
      "epoch": 0.13296549580354367,
      "grad_norm": 0.5903640985488892,
      "learning_rate": 9.335172520982282e-06,
      "loss": 0.393,
      "step": 1711
    },
    {
      "epoch": 0.1330432079577246,
      "grad_norm": 0.26901018619537354,
      "learning_rate": 9.334783960211378e-06,
      "loss": 0.1971,
      "step": 1712
    },
    {
      "epoch": 0.1331209201119055,
      "grad_norm": 0.15258821845054626,
      "learning_rate": 9.334395399440473e-06,
      "loss": 0.0535,
      "step": 1713
    },
    {
      "epoch": 0.13319863226608641,
      "grad_norm": 0.4158936142921448,
      "learning_rate": 9.334006838669568e-06,
      "loss": 0.1491,
      "step": 1714
    },
    {
      "epoch": 0.13327634442026734,
      "grad_norm": 0.28512153029441833,
      "learning_rate": 9.333618277898665e-06,
      "loss": 0.1662,
      "step": 1715
    },
    {
      "epoch": 0.13335405657444824,
      "grad_norm": 0.015195770189166069,
      "learning_rate": 9.33322971712776e-06,
      "loss": 0.0017,
      "step": 1716
    },
    {
      "epoch": 0.13343176872862916,
      "grad_norm": 0.3997407853603363,
      "learning_rate": 9.332841156356856e-06,
      "loss": 0.2402,
      "step": 1717
    },
    {
      "epoch": 0.13350948088281006,
      "grad_norm": 0.21205879747867584,
      "learning_rate": 9.33245259558595e-06,
      "loss": 0.0638,
      "step": 1718
    },
    {
      "epoch": 0.133587193036991,
      "grad_norm": 0.8133431077003479,
      "learning_rate": 9.332064034815046e-06,
      "loss": 0.4935,
      "step": 1719
    },
    {
      "epoch": 0.1336649051911719,
      "grad_norm": 0.038210995495319366,
      "learning_rate": 9.331675474044141e-06,
      "loss": 0.0081,
      "step": 1720
    },
    {
      "epoch": 0.1337426173453528,
      "grad_norm": 0.07332731783390045,
      "learning_rate": 9.331286913273236e-06,
      "loss": 0.026,
      "step": 1721
    },
    {
      "epoch": 0.13382032949953374,
      "grad_norm": 0.23736605048179626,
      "learning_rate": 9.330898352502333e-06,
      "loss": 0.3649,
      "step": 1722
    },
    {
      "epoch": 0.13389804165371463,
      "grad_norm": 0.36186614632606506,
      "learning_rate": 9.330509791731428e-06,
      "loss": 0.3332,
      "step": 1723
    },
    {
      "epoch": 0.13397575380789556,
      "grad_norm": 0.32039347290992737,
      "learning_rate": 9.330121230960523e-06,
      "loss": 0.0986,
      "step": 1724
    },
    {
      "epoch": 0.13405346596207646,
      "grad_norm": 0.392922043800354,
      "learning_rate": 9.32973267018962e-06,
      "loss": 0.5714,
      "step": 1725
    },
    {
      "epoch": 0.13413117811625738,
      "grad_norm": 0.21540528535842896,
      "learning_rate": 9.329344109418714e-06,
      "loss": 0.1585,
      "step": 1726
    },
    {
      "epoch": 0.1342088902704383,
      "grad_norm": 0.21814124286174774,
      "learning_rate": 9.32895554864781e-06,
      "loss": 0.1975,
      "step": 1727
    },
    {
      "epoch": 0.1342866024246192,
      "grad_norm": 0.3084782361984253,
      "learning_rate": 9.328566987876904e-06,
      "loss": 0.1605,
      "step": 1728
    },
    {
      "epoch": 0.13436431457880013,
      "grad_norm": 0.11428702622652054,
      "learning_rate": 9.328178427106e-06,
      "loss": 0.0485,
      "step": 1729
    },
    {
      "epoch": 0.13444202673298103,
      "grad_norm": 0.32870933413505554,
      "learning_rate": 9.327789866335096e-06,
      "loss": 0.3101,
      "step": 1730
    },
    {
      "epoch": 0.13451973888716195,
      "grad_norm": 0.11051604896783829,
      "learning_rate": 9.32740130556419e-06,
      "loss": 0.02,
      "step": 1731
    },
    {
      "epoch": 0.13459745104134285,
      "grad_norm": 0.13087257742881775,
      "learning_rate": 9.327012744793287e-06,
      "loss": 0.0378,
      "step": 1732
    },
    {
      "epoch": 0.13467516319552378,
      "grad_norm": 0.09406747668981552,
      "learning_rate": 9.326624184022382e-06,
      "loss": 0.0407,
      "step": 1733
    },
    {
      "epoch": 0.1347528753497047,
      "grad_norm": 7.402775764465332,
      "learning_rate": 9.326235623251477e-06,
      "loss": 2.0151,
      "step": 1734
    },
    {
      "epoch": 0.1348305875038856,
      "grad_norm": 0.6983204483985901,
      "learning_rate": 9.325847062480574e-06,
      "loss": 0.6418,
      "step": 1735
    },
    {
      "epoch": 0.13490829965806653,
      "grad_norm": 0.2321220338344574,
      "learning_rate": 9.325458501709667e-06,
      "loss": 0.1701,
      "step": 1736
    },
    {
      "epoch": 0.13498601181224743,
      "grad_norm": 0.4162604510784149,
      "learning_rate": 9.325069940938764e-06,
      "loss": 0.1196,
      "step": 1737
    },
    {
      "epoch": 0.13506372396642835,
      "grad_norm": 0.28729814291000366,
      "learning_rate": 9.324681380167859e-06,
      "loss": 0.1934,
      "step": 1738
    },
    {
      "epoch": 0.13514143612060928,
      "grad_norm": 0.3409171998500824,
      "learning_rate": 9.324292819396954e-06,
      "loss": 0.2852,
      "step": 1739
    },
    {
      "epoch": 0.13521914827479017,
      "grad_norm": 0.26934048533439636,
      "learning_rate": 9.32390425862605e-06,
      "loss": 0.144,
      "step": 1740
    },
    {
      "epoch": 0.1352968604289711,
      "grad_norm": 0.3741718828678131,
      "learning_rate": 9.323515697855145e-06,
      "loss": 0.2136,
      "step": 1741
    },
    {
      "epoch": 0.135374572583152,
      "grad_norm": 0.14647404849529266,
      "learning_rate": 9.32312713708424e-06,
      "loss": 0.1106,
      "step": 1742
    },
    {
      "epoch": 0.13545228473733292,
      "grad_norm": 0.48090988397598267,
      "learning_rate": 9.322738576313337e-06,
      "loss": 1.3377,
      "step": 1743
    },
    {
      "epoch": 0.13552999689151382,
      "grad_norm": 0.11022180318832397,
      "learning_rate": 9.322350015542432e-06,
      "loss": 0.0247,
      "step": 1744
    },
    {
      "epoch": 0.13560770904569475,
      "grad_norm": 0.07265742123126984,
      "learning_rate": 9.321961454771527e-06,
      "loss": 0.0229,
      "step": 1745
    },
    {
      "epoch": 0.13568542119987567,
      "grad_norm": 0.2013673633337021,
      "learning_rate": 9.321572894000622e-06,
      "loss": 0.0653,
      "step": 1746
    },
    {
      "epoch": 0.13576313335405657,
      "grad_norm": 0.27084705233573914,
      "learning_rate": 9.321184333229718e-06,
      "loss": 0.2399,
      "step": 1747
    },
    {
      "epoch": 0.1358408455082375,
      "grad_norm": 0.9649025797843933,
      "learning_rate": 9.320795772458813e-06,
      "loss": 0.1116,
      "step": 1748
    },
    {
      "epoch": 0.1359185576624184,
      "grad_norm": 0.17620694637298584,
      "learning_rate": 9.320407211687908e-06,
      "loss": 0.1292,
      "step": 1749
    },
    {
      "epoch": 0.13599626981659932,
      "grad_norm": 0.0747591108083725,
      "learning_rate": 9.320018650917005e-06,
      "loss": 0.0638,
      "step": 1750
    },
    {
      "epoch": 0.13607398197078022,
      "grad_norm": 0.12964239716529846,
      "learning_rate": 9.3196300901461e-06,
      "loss": 0.0561,
      "step": 1751
    },
    {
      "epoch": 0.13615169412496114,
      "grad_norm": 0.32422512769699097,
      "learning_rate": 9.319241529375195e-06,
      "loss": 0.1754,
      "step": 1752
    },
    {
      "epoch": 0.13622940627914207,
      "grad_norm": 0.3594624996185303,
      "learning_rate": 9.31885296860429e-06,
      "loss": 0.595,
      "step": 1753
    },
    {
      "epoch": 0.13630711843332297,
      "grad_norm": 0.280249685049057,
      "learning_rate": 9.318464407833386e-06,
      "loss": 0.2837,
      "step": 1754
    },
    {
      "epoch": 0.1363848305875039,
      "grad_norm": 0.34848836064338684,
      "learning_rate": 9.318075847062481e-06,
      "loss": 0.2265,
      "step": 1755
    },
    {
      "epoch": 0.1364625427416848,
      "grad_norm": 0.3492041826248169,
      "learning_rate": 9.317687286291576e-06,
      "loss": 0.2489,
      "step": 1756
    },
    {
      "epoch": 0.13654025489586571,
      "grad_norm": 0.04420488327741623,
      "learning_rate": 9.317298725520673e-06,
      "loss": 0.0198,
      "step": 1757
    },
    {
      "epoch": 0.13661796705004664,
      "grad_norm": 0.3000766336917877,
      "learning_rate": 9.316910164749768e-06,
      "loss": 0.1692,
      "step": 1758
    },
    {
      "epoch": 0.13669567920422754,
      "grad_norm": 0.13442586362361908,
      "learning_rate": 9.316521603978863e-06,
      "loss": 0.073,
      "step": 1759
    },
    {
      "epoch": 0.13677339135840846,
      "grad_norm": 0.4018850326538086,
      "learning_rate": 9.31613304320796e-06,
      "loss": 0.1781,
      "step": 1760
    },
    {
      "epoch": 0.13685110351258936,
      "grad_norm": 0.5089628100395203,
      "learning_rate": 9.315744482437053e-06,
      "loss": 0.2802,
      "step": 1761
    },
    {
      "epoch": 0.1369288156667703,
      "grad_norm": 0.173419788479805,
      "learning_rate": 9.31535592166615e-06,
      "loss": 0.0487,
      "step": 1762
    },
    {
      "epoch": 0.13700652782095118,
      "grad_norm": 0.26918280124664307,
      "learning_rate": 9.314967360895244e-06,
      "loss": 0.373,
      "step": 1763
    },
    {
      "epoch": 0.1370842399751321,
      "grad_norm": 0.9563800096511841,
      "learning_rate": 9.31457880012434e-06,
      "loss": 0.8092,
      "step": 1764
    },
    {
      "epoch": 0.13716195212931304,
      "grad_norm": 0.23561610281467438,
      "learning_rate": 9.314190239353436e-06,
      "loss": 0.3309,
      "step": 1765
    },
    {
      "epoch": 0.13723966428349393,
      "grad_norm": 0.573110044002533,
      "learning_rate": 9.313801678582531e-06,
      "loss": 0.2637,
      "step": 1766
    },
    {
      "epoch": 0.13731737643767486,
      "grad_norm": 0.2833329439163208,
      "learning_rate": 9.313413117811626e-06,
      "loss": 0.1833,
      "step": 1767
    },
    {
      "epoch": 0.13739508859185576,
      "grad_norm": 0.2056998461484909,
      "learning_rate": 9.313024557040722e-06,
      "loss": 0.2675,
      "step": 1768
    },
    {
      "epoch": 0.13747280074603668,
      "grad_norm": 0.6977062225341797,
      "learning_rate": 9.312635996269817e-06,
      "loss": 0.2819,
      "step": 1769
    },
    {
      "epoch": 0.13755051290021758,
      "grad_norm": 0.21348445117473602,
      "learning_rate": 9.312247435498912e-06,
      "loss": 0.0783,
      "step": 1770
    },
    {
      "epoch": 0.1376282250543985,
      "grad_norm": 0.2199297845363617,
      "learning_rate": 9.311858874728007e-06,
      "loss": 0.062,
      "step": 1771
    },
    {
      "epoch": 0.13770593720857943,
      "grad_norm": 0.30883851647377014,
      "learning_rate": 9.311470313957104e-06,
      "loss": 0.2099,
      "step": 1772
    },
    {
      "epoch": 0.13778364936276033,
      "grad_norm": 0.13826142251491547,
      "learning_rate": 9.311081753186199e-06,
      "loss": 0.0842,
      "step": 1773
    },
    {
      "epoch": 0.13786136151694126,
      "grad_norm": 0.181211918592453,
      "learning_rate": 9.310693192415294e-06,
      "loss": 0.0395,
      "step": 1774
    },
    {
      "epoch": 0.13793907367112215,
      "grad_norm": 0.07342853397130966,
      "learning_rate": 9.31030463164439e-06,
      "loss": 0.038,
      "step": 1775
    },
    {
      "epoch": 0.13801678582530308,
      "grad_norm": 0.15029646456241608,
      "learning_rate": 9.309916070873485e-06,
      "loss": 0.1316,
      "step": 1776
    },
    {
      "epoch": 0.138094497979484,
      "grad_norm": 0.09207320958375931,
      "learning_rate": 9.30952751010258e-06,
      "loss": 0.0898,
      "step": 1777
    },
    {
      "epoch": 0.1381722101336649,
      "grad_norm": 0.29725396633148193,
      "learning_rate": 9.309138949331677e-06,
      "loss": 0.1813,
      "step": 1778
    },
    {
      "epoch": 0.13824992228784583,
      "grad_norm": 0.19456416368484497,
      "learning_rate": 9.308750388560772e-06,
      "loss": 0.0591,
      "step": 1779
    },
    {
      "epoch": 0.13832763444202673,
      "grad_norm": 0.20363663136959076,
      "learning_rate": 9.308361827789867e-06,
      "loss": 0.1361,
      "step": 1780
    },
    {
      "epoch": 0.13840534659620765,
      "grad_norm": 0.29219892621040344,
      "learning_rate": 9.307973267018962e-06,
      "loss": 0.2192,
      "step": 1781
    },
    {
      "epoch": 0.13848305875038855,
      "grad_norm": 0.4344790577888489,
      "learning_rate": 9.307584706248059e-06,
      "loss": 0.2479,
      "step": 1782
    },
    {
      "epoch": 0.13856077090456947,
      "grad_norm": 0.44513559341430664,
      "learning_rate": 9.307196145477153e-06,
      "loss": 0.3285,
      "step": 1783
    },
    {
      "epoch": 0.1386384830587504,
      "grad_norm": 0.3045533299446106,
      "learning_rate": 9.306807584706248e-06,
      "loss": 0.0718,
      "step": 1784
    },
    {
      "epoch": 0.1387161952129313,
      "grad_norm": 0.2517232596874237,
      "learning_rate": 9.306419023935345e-06,
      "loss": 0.5038,
      "step": 1785
    },
    {
      "epoch": 0.13879390736711222,
      "grad_norm": 0.2933400273323059,
      "learning_rate": 9.30603046316444e-06,
      "loss": 0.1222,
      "step": 1786
    },
    {
      "epoch": 0.13887161952129312,
      "grad_norm": 0.05452727526426315,
      "learning_rate": 9.305641902393535e-06,
      "loss": 0.0232,
      "step": 1787
    },
    {
      "epoch": 0.13894933167547405,
      "grad_norm": 0.24944035708904266,
      "learning_rate": 9.305253341622632e-06,
      "loss": 0.0525,
      "step": 1788
    },
    {
      "epoch": 0.13902704382965494,
      "grad_norm": 0.24749600887298584,
      "learning_rate": 9.304864780851725e-06,
      "loss": 0.1222,
      "step": 1789
    },
    {
      "epoch": 0.13910475598383587,
      "grad_norm": 0.5715239644050598,
      "learning_rate": 9.304476220080822e-06,
      "loss": 0.0811,
      "step": 1790
    },
    {
      "epoch": 0.1391824681380168,
      "grad_norm": 0.11647968739271164,
      "learning_rate": 9.304087659309916e-06,
      "loss": 0.0195,
      "step": 1791
    },
    {
      "epoch": 0.1392601802921977,
      "grad_norm": 0.18738137185573578,
      "learning_rate": 9.303699098539011e-06,
      "loss": 0.0968,
      "step": 1792
    },
    {
      "epoch": 0.13933789244637862,
      "grad_norm": 0.39532095193862915,
      "learning_rate": 9.303310537768108e-06,
      "loss": 0.1496,
      "step": 1793
    },
    {
      "epoch": 0.13941560460055952,
      "grad_norm": 0.3916795551776886,
      "learning_rate": 9.302921976997203e-06,
      "loss": 0.6517,
      "step": 1794
    },
    {
      "epoch": 0.13949331675474044,
      "grad_norm": 3.450090169906616,
      "learning_rate": 9.302533416226298e-06,
      "loss": 0.2006,
      "step": 1795
    },
    {
      "epoch": 0.13957102890892137,
      "grad_norm": 0.34966036677360535,
      "learning_rate": 9.302144855455395e-06,
      "loss": 0.1322,
      "step": 1796
    },
    {
      "epoch": 0.13964874106310227,
      "grad_norm": 0.16570250689983368,
      "learning_rate": 9.30175629468449e-06,
      "loss": 0.0529,
      "step": 1797
    },
    {
      "epoch": 0.1397264532172832,
      "grad_norm": 0.21037767827510834,
      "learning_rate": 9.301367733913584e-06,
      "loss": 0.0761,
      "step": 1798
    },
    {
      "epoch": 0.1398041653714641,
      "grad_norm": 0.32042670249938965,
      "learning_rate": 9.30097917314268e-06,
      "loss": 0.2505,
      "step": 1799
    },
    {
      "epoch": 0.13988187752564502,
      "grad_norm": 0.6519608497619629,
      "learning_rate": 9.300590612371776e-06,
      "loss": 0.3396,
      "step": 1800
    },
    {
      "epoch": 0.1399595896798259,
      "grad_norm": 0.2939239740371704,
      "learning_rate": 9.300202051600871e-06,
      "loss": 0.0772,
      "step": 1801
    },
    {
      "epoch": 0.14003730183400684,
      "grad_norm": 0.7027768492698669,
      "learning_rate": 9.299813490829966e-06,
      "loss": 0.8293,
      "step": 1802
    },
    {
      "epoch": 0.14011501398818776,
      "grad_norm": 0.4586414396762848,
      "learning_rate": 9.299424930059063e-06,
      "loss": 0.2265,
      "step": 1803
    },
    {
      "epoch": 0.14019272614236866,
      "grad_norm": 0.1847490668296814,
      "learning_rate": 9.299036369288158e-06,
      "loss": 0.1271,
      "step": 1804
    },
    {
      "epoch": 0.1402704382965496,
      "grad_norm": 0.16968028247356415,
      "learning_rate": 9.298647808517253e-06,
      "loss": 0.1077,
      "step": 1805
    },
    {
      "epoch": 0.14034815045073049,
      "grad_norm": 0.21773536503314972,
      "learning_rate": 9.29825924774635e-06,
      "loss": 0.212,
      "step": 1806
    },
    {
      "epoch": 0.1404258626049114,
      "grad_norm": 0.13666661083698273,
      "learning_rate": 9.297870686975444e-06,
      "loss": 0.0381,
      "step": 1807
    },
    {
      "epoch": 0.1405035747590923,
      "grad_norm": 0.15770865976810455,
      "learning_rate": 9.297482126204539e-06,
      "loss": 0.0922,
      "step": 1808
    },
    {
      "epoch": 0.14058128691327323,
      "grad_norm": 0.4358583092689514,
      "learning_rate": 9.297093565433634e-06,
      "loss": 0.3992,
      "step": 1809
    },
    {
      "epoch": 0.14065899906745416,
      "grad_norm": 0.11462303251028061,
      "learning_rate": 9.29670500466273e-06,
      "loss": 0.0716,
      "step": 1810
    },
    {
      "epoch": 0.14073671122163506,
      "grad_norm": 0.5566308498382568,
      "learning_rate": 9.296316443891826e-06,
      "loss": 0.1874,
      "step": 1811
    },
    {
      "epoch": 0.14081442337581598,
      "grad_norm": 0.3205946385860443,
      "learning_rate": 9.29592788312092e-06,
      "loss": 0.054,
      "step": 1812
    },
    {
      "epoch": 0.14089213552999688,
      "grad_norm": 0.7025822401046753,
      "learning_rate": 9.295539322350017e-06,
      "loss": 0.4068,
      "step": 1813
    },
    {
      "epoch": 0.1409698476841778,
      "grad_norm": 0.2749392092227936,
      "learning_rate": 9.295150761579112e-06,
      "loss": 0.1811,
      "step": 1814
    },
    {
      "epoch": 0.14104755983835873,
      "grad_norm": 0.2257402092218399,
      "learning_rate": 9.294762200808207e-06,
      "loss": 0.2563,
      "step": 1815
    },
    {
      "epoch": 0.14112527199253963,
      "grad_norm": 0.16186752915382385,
      "learning_rate": 9.294373640037304e-06,
      "loss": 0.0982,
      "step": 1816
    },
    {
      "epoch": 0.14120298414672056,
      "grad_norm": 0.15751080214977264,
      "learning_rate": 9.293985079266397e-06,
      "loss": 0.0845,
      "step": 1817
    },
    {
      "epoch": 0.14128069630090145,
      "grad_norm": 0.24387773871421814,
      "learning_rate": 9.293596518495494e-06,
      "loss": 0.1239,
      "step": 1818
    },
    {
      "epoch": 0.14135840845508238,
      "grad_norm": 0.32368966937065125,
      "learning_rate": 9.293207957724589e-06,
      "loss": 0.1793,
      "step": 1819
    },
    {
      "epoch": 0.14143612060926328,
      "grad_norm": 0.37853214144706726,
      "learning_rate": 9.292819396953684e-06,
      "loss": 0.2141,
      "step": 1820
    },
    {
      "epoch": 0.1415138327634442,
      "grad_norm": 0.05676068738102913,
      "learning_rate": 9.29243083618278e-06,
      "loss": 0.0297,
      "step": 1821
    },
    {
      "epoch": 0.14159154491762513,
      "grad_norm": 0.05189617723226547,
      "learning_rate": 9.292042275411875e-06,
      "loss": 0.0146,
      "step": 1822
    },
    {
      "epoch": 0.14166925707180603,
      "grad_norm": 0.43067827820777893,
      "learning_rate": 9.29165371464097e-06,
      "loss": 0.1572,
      "step": 1823
    },
    {
      "epoch": 0.14174696922598695,
      "grad_norm": 0.41860970854759216,
      "learning_rate": 9.291265153870067e-06,
      "loss": 0.8572,
      "step": 1824
    },
    {
      "epoch": 0.14182468138016785,
      "grad_norm": 0.08203002065420151,
      "learning_rate": 9.290876593099162e-06,
      "loss": 0.0319,
      "step": 1825
    },
    {
      "epoch": 0.14190239353434878,
      "grad_norm": 0.08904717117547989,
      "learning_rate": 9.290488032328257e-06,
      "loss": 0.0502,
      "step": 1826
    },
    {
      "epoch": 0.14198010568852967,
      "grad_norm": 0.1507902294397354,
      "learning_rate": 9.290099471557352e-06,
      "loss": 0.0909,
      "step": 1827
    },
    {
      "epoch": 0.1420578178427106,
      "grad_norm": 0.5729782581329346,
      "learning_rate": 9.289710910786448e-06,
      "loss": 0.1385,
      "step": 1828
    },
    {
      "epoch": 0.14213552999689152,
      "grad_norm": 0.20940634608268738,
      "learning_rate": 9.289322350015543e-06,
      "loss": 0.0451,
      "step": 1829
    },
    {
      "epoch": 0.14221324215107242,
      "grad_norm": 0.09568165242671967,
      "learning_rate": 9.288933789244638e-06,
      "loss": 0.0475,
      "step": 1830
    },
    {
      "epoch": 0.14229095430525335,
      "grad_norm": 0.17660509049892426,
      "learning_rate": 9.288545228473735e-06,
      "loss": 0.1572,
      "step": 1831
    },
    {
      "epoch": 0.14236866645943425,
      "grad_norm": 0.11117737740278244,
      "learning_rate": 9.28815666770283e-06,
      "loss": 0.1603,
      "step": 1832
    },
    {
      "epoch": 0.14244637861361517,
      "grad_norm": 0.2681070864200592,
      "learning_rate": 9.287768106931925e-06,
      "loss": 0.2381,
      "step": 1833
    },
    {
      "epoch": 0.1425240907677961,
      "grad_norm": 0.17040349543094635,
      "learning_rate": 9.287379546161021e-06,
      "loss": 0.0873,
      "step": 1834
    },
    {
      "epoch": 0.142601802921977,
      "grad_norm": 0.39741864800453186,
      "learning_rate": 9.286990985390115e-06,
      "loss": 0.1149,
      "step": 1835
    },
    {
      "epoch": 0.14267951507615792,
      "grad_norm": 0.06424900889396667,
      "learning_rate": 9.286602424619211e-06,
      "loss": 0.014,
      "step": 1836
    },
    {
      "epoch": 0.14275722723033882,
      "grad_norm": 0.31345126032829285,
      "learning_rate": 9.286213863848306e-06,
      "loss": 0.0577,
      "step": 1837
    },
    {
      "epoch": 0.14283493938451974,
      "grad_norm": 0.2807725667953491,
      "learning_rate": 9.285825303077403e-06,
      "loss": 0.1412,
      "step": 1838
    },
    {
      "epoch": 0.14291265153870064,
      "grad_norm": 0.2548278570175171,
      "learning_rate": 9.285436742306498e-06,
      "loss": 0.044,
      "step": 1839
    },
    {
      "epoch": 0.14299036369288157,
      "grad_norm": 0.17096839845180511,
      "learning_rate": 9.285048181535593e-06,
      "loss": 0.111,
      "step": 1840
    },
    {
      "epoch": 0.1430680758470625,
      "grad_norm": 0.34889280796051025,
      "learning_rate": 9.28465962076469e-06,
      "loss": 0.2387,
      "step": 1841
    },
    {
      "epoch": 0.1431457880012434,
      "grad_norm": 0.19384820759296417,
      "learning_rate": 9.284271059993784e-06,
      "loss": 0.2399,
      "step": 1842
    },
    {
      "epoch": 0.14322350015542432,
      "grad_norm": 0.33752989768981934,
      "learning_rate": 9.28388249922288e-06,
      "loss": 0.1618,
      "step": 1843
    },
    {
      "epoch": 0.1433012123096052,
      "grad_norm": 0.18322642147541046,
      "learning_rate": 9.283493938451976e-06,
      "loss": 0.1402,
      "step": 1844
    },
    {
      "epoch": 0.14337892446378614,
      "grad_norm": 0.23098158836364746,
      "learning_rate": 9.283105377681069e-06,
      "loss": 0.1106,
      "step": 1845
    },
    {
      "epoch": 0.14345663661796704,
      "grad_norm": 0.3781362473964691,
      "learning_rate": 9.282716816910166e-06,
      "loss": 0.2164,
      "step": 1846
    },
    {
      "epoch": 0.14353434877214796,
      "grad_norm": 0.20167644321918488,
      "learning_rate": 9.28232825613926e-06,
      "loss": 0.0396,
      "step": 1847
    },
    {
      "epoch": 0.1436120609263289,
      "grad_norm": 0.425446093082428,
      "learning_rate": 9.281939695368356e-06,
      "loss": 0.057,
      "step": 1848
    },
    {
      "epoch": 0.1436897730805098,
      "grad_norm": 0.20608647167682648,
      "learning_rate": 9.281551134597452e-06,
      "loss": 0.1642,
      "step": 1849
    },
    {
      "epoch": 0.1437674852346907,
      "grad_norm": 0.06563102453947067,
      "learning_rate": 9.281162573826547e-06,
      "loss": 0.027,
      "step": 1850
    },
    {
      "epoch": 0.1438451973888716,
      "grad_norm": 0.10453783720731735,
      "learning_rate": 9.280774013055642e-06,
      "loss": 0.2299,
      "step": 1851
    },
    {
      "epoch": 0.14392290954305254,
      "grad_norm": 0.2963694632053375,
      "learning_rate": 9.280385452284739e-06,
      "loss": 0.2139,
      "step": 1852
    },
    {
      "epoch": 0.14400062169723346,
      "grad_norm": 0.02916860021650791,
      "learning_rate": 9.279996891513834e-06,
      "loss": 0.0079,
      "step": 1853
    },
    {
      "epoch": 0.14407833385141436,
      "grad_norm": 0.02497541531920433,
      "learning_rate": 9.279608330742929e-06,
      "loss": 0.0108,
      "step": 1854
    },
    {
      "epoch": 0.14415604600559528,
      "grad_norm": 0.12783364951610565,
      "learning_rate": 9.279219769972024e-06,
      "loss": 0.0635,
      "step": 1855
    },
    {
      "epoch": 0.14423375815977618,
      "grad_norm": 0.15397851169109344,
      "learning_rate": 9.27883120920112e-06,
      "loss": 0.1383,
      "step": 1856
    },
    {
      "epoch": 0.1443114703139571,
      "grad_norm": 0.10091544687747955,
      "learning_rate": 9.278442648430215e-06,
      "loss": 0.0562,
      "step": 1857
    },
    {
      "epoch": 0.144389182468138,
      "grad_norm": 0.4726480543613434,
      "learning_rate": 9.27805408765931e-06,
      "loss": 0.1222,
      "step": 1858
    },
    {
      "epoch": 0.14446689462231893,
      "grad_norm": 0.10345547646284103,
      "learning_rate": 9.277665526888407e-06,
      "loss": 0.046,
      "step": 1859
    },
    {
      "epoch": 0.14454460677649986,
      "grad_norm": 0.31129077076911926,
      "learning_rate": 9.277276966117502e-06,
      "loss": 0.164,
      "step": 1860
    },
    {
      "epoch": 0.14462231893068075,
      "grad_norm": 0.10769721120595932,
      "learning_rate": 9.276888405346597e-06,
      "loss": 0.0677,
      "step": 1861
    },
    {
      "epoch": 0.14470003108486168,
      "grad_norm": 0.15343032777309418,
      "learning_rate": 9.276499844575693e-06,
      "loss": 0.0908,
      "step": 1862
    },
    {
      "epoch": 0.14477774323904258,
      "grad_norm": 0.5070023536682129,
      "learning_rate": 9.276111283804787e-06,
      "loss": 0.3829,
      "step": 1863
    },
    {
      "epoch": 0.1448554553932235,
      "grad_norm": 0.3368132710456848,
      "learning_rate": 9.275722723033883e-06,
      "loss": 0.0853,
      "step": 1864
    },
    {
      "epoch": 0.1449331675474044,
      "grad_norm": 0.2702951729297638,
      "learning_rate": 9.275334162262978e-06,
      "loss": 0.2229,
      "step": 1865
    },
    {
      "epoch": 0.14501087970158533,
      "grad_norm": 0.29187294840812683,
      "learning_rate": 9.274945601492073e-06,
      "loss": 0.1062,
      "step": 1866
    },
    {
      "epoch": 0.14508859185576625,
      "grad_norm": 0.38709503412246704,
      "learning_rate": 9.27455704072117e-06,
      "loss": 0.1871,
      "step": 1867
    },
    {
      "epoch": 0.14516630400994715,
      "grad_norm": 0.2477586567401886,
      "learning_rate": 9.274168479950265e-06,
      "loss": 0.1452,
      "step": 1868
    },
    {
      "epoch": 0.14524401616412808,
      "grad_norm": 0.2050558477640152,
      "learning_rate": 9.273779919179361e-06,
      "loss": 0.0438,
      "step": 1869
    },
    {
      "epoch": 0.14532172831830897,
      "grad_norm": 0.6941171884536743,
      "learning_rate": 9.273391358408456e-06,
      "loss": 1.0312,
      "step": 1870
    },
    {
      "epoch": 0.1453994404724899,
      "grad_norm": 0.4315735101699829,
      "learning_rate": 9.273002797637551e-06,
      "loss": 0.1931,
      "step": 1871
    },
    {
      "epoch": 0.14547715262667082,
      "grad_norm": 0.05800815299153328,
      "learning_rate": 9.272614236866646e-06,
      "loss": 0.0107,
      "step": 1872
    },
    {
      "epoch": 0.14555486478085172,
      "grad_norm": 0.3533397614955902,
      "learning_rate": 9.272225676095741e-06,
      "loss": 0.1553,
      "step": 1873
    },
    {
      "epoch": 0.14563257693503265,
      "grad_norm": 0.2591944634914398,
      "learning_rate": 9.271837115324838e-06,
      "loss": 0.248,
      "step": 1874
    },
    {
      "epoch": 0.14571028908921355,
      "grad_norm": 0.3755616843700409,
      "learning_rate": 9.271448554553933e-06,
      "loss": 0.2876,
      "step": 1875
    },
    {
      "epoch": 0.14578800124339447,
      "grad_norm": 0.2694198191165924,
      "learning_rate": 9.271059993783028e-06,
      "loss": 0.261,
      "step": 1876
    },
    {
      "epoch": 0.14586571339757537,
      "grad_norm": 0.29616275429725647,
      "learning_rate": 9.270671433012124e-06,
      "loss": 0.0592,
      "step": 1877
    },
    {
      "epoch": 0.1459434255517563,
      "grad_norm": 0.4011640250682831,
      "learning_rate": 9.27028287224122e-06,
      "loss": 0.4558,
      "step": 1878
    },
    {
      "epoch": 0.14602113770593722,
      "grad_norm": 0.19439558684825897,
      "learning_rate": 9.269894311470314e-06,
      "loss": 0.1668,
      "step": 1879
    },
    {
      "epoch": 0.14609884986011812,
      "grad_norm": 0.16178442537784576,
      "learning_rate": 9.26950575069941e-06,
      "loss": 0.2301,
      "step": 1880
    },
    {
      "epoch": 0.14617656201429904,
      "grad_norm": 0.07766834646463394,
      "learning_rate": 9.269117189928506e-06,
      "loss": 0.0273,
      "step": 1881
    },
    {
      "epoch": 0.14625427416847994,
      "grad_norm": 0.30750924348831177,
      "learning_rate": 9.268728629157601e-06,
      "loss": 0.1504,
      "step": 1882
    },
    {
      "epoch": 0.14633198632266087,
      "grad_norm": 0.25639602541923523,
      "learning_rate": 9.268340068386696e-06,
      "loss": 0.3769,
      "step": 1883
    },
    {
      "epoch": 0.14640969847684177,
      "grad_norm": 0.3501793444156647,
      "learning_rate": 9.267951507615793e-06,
      "loss": 0.0869,
      "step": 1884
    },
    {
      "epoch": 0.1464874106310227,
      "grad_norm": 0.13106469810009003,
      "learning_rate": 9.267562946844887e-06,
      "loss": 0.0551,
      "step": 1885
    },
    {
      "epoch": 0.14656512278520362,
      "grad_norm": 0.37336206436157227,
      "learning_rate": 9.267174386073982e-06,
      "loss": 0.2373,
      "step": 1886
    },
    {
      "epoch": 0.14664283493938451,
      "grad_norm": 0.3529277443885803,
      "learning_rate": 9.266785825303079e-06,
      "loss": 0.3799,
      "step": 1887
    },
    {
      "epoch": 0.14672054709356544,
      "grad_norm": 0.30495119094848633,
      "learning_rate": 9.266397264532172e-06,
      "loss": 0.2313,
      "step": 1888
    },
    {
      "epoch": 0.14679825924774634,
      "grad_norm": 0.36623483896255493,
      "learning_rate": 9.266008703761269e-06,
      "loss": 0.5066,
      "step": 1889
    },
    {
      "epoch": 0.14687597140192726,
      "grad_norm": 0.16965454816818237,
      "learning_rate": 9.265620142990364e-06,
      "loss": 0.1551,
      "step": 1890
    },
    {
      "epoch": 0.1469536835561082,
      "grad_norm": 0.3860786557197571,
      "learning_rate": 9.265231582219459e-06,
      "loss": 0.8387,
      "step": 1891
    },
    {
      "epoch": 0.1470313957102891,
      "grad_norm": 0.8293201327323914,
      "learning_rate": 9.264843021448556e-06,
      "loss": 0.3043,
      "step": 1892
    },
    {
      "epoch": 0.14710910786447,
      "grad_norm": 0.39933404326438904,
      "learning_rate": 9.26445446067765e-06,
      "loss": 0.7781,
      "step": 1893
    },
    {
      "epoch": 0.1471868200186509,
      "grad_norm": 0.6157564520835876,
      "learning_rate": 9.264065899906745e-06,
      "loss": 0.3405,
      "step": 1894
    },
    {
      "epoch": 0.14726453217283184,
      "grad_norm": 0.1961022913455963,
      "learning_rate": 9.263677339135842e-06,
      "loss": 0.1863,
      "step": 1895
    },
    {
      "epoch": 0.14734224432701273,
      "grad_norm": 0.3598031997680664,
      "learning_rate": 9.263288778364937e-06,
      "loss": 0.2583,
      "step": 1896
    },
    {
      "epoch": 0.14741995648119366,
      "grad_norm": 0.802949070930481,
      "learning_rate": 9.262900217594034e-06,
      "loss": 0.4752,
      "step": 1897
    },
    {
      "epoch": 0.14749766863537458,
      "grad_norm": 0.13168038427829742,
      "learning_rate": 9.262511656823127e-06,
      "loss": 0.1057,
      "step": 1898
    },
    {
      "epoch": 0.14757538078955548,
      "grad_norm": 0.21654751896858215,
      "learning_rate": 9.262123096052224e-06,
      "loss": 0.2312,
      "step": 1899
    },
    {
      "epoch": 0.1476530929437364,
      "grad_norm": 0.14425091445446014,
      "learning_rate": 9.261734535281318e-06,
      "loss": 0.0461,
      "step": 1900
    },
    {
      "epoch": 0.1477308050979173,
      "grad_norm": 0.29949939250946045,
      "learning_rate": 9.261345974510413e-06,
      "loss": 0.1759,
      "step": 1901
    },
    {
      "epoch": 0.14780851725209823,
      "grad_norm": 0.13137997686862946,
      "learning_rate": 9.26095741373951e-06,
      "loss": 0.0456,
      "step": 1902
    },
    {
      "epoch": 0.14788622940627913,
      "grad_norm": 0.08603712916374207,
      "learning_rate": 9.260568852968605e-06,
      "loss": 0.0275,
      "step": 1903
    },
    {
      "epoch": 0.14796394156046005,
      "grad_norm": 0.3684476912021637,
      "learning_rate": 9.2601802921977e-06,
      "loss": 0.1396,
      "step": 1904
    },
    {
      "epoch": 0.14804165371464098,
      "grad_norm": 0.44195473194122314,
      "learning_rate": 9.259791731426797e-06,
      "loss": 0.0932,
      "step": 1905
    },
    {
      "epoch": 0.14811936586882188,
      "grad_norm": 0.13824830949306488,
      "learning_rate": 9.259403170655892e-06,
      "loss": 0.0505,
      "step": 1906
    },
    {
      "epoch": 0.1481970780230028,
      "grad_norm": 0.16664499044418335,
      "learning_rate": 9.259014609884987e-06,
      "loss": 0.1242,
      "step": 1907
    },
    {
      "epoch": 0.1482747901771837,
      "grad_norm": 0.545044481754303,
      "learning_rate": 9.258626049114081e-06,
      "loss": 1.1666,
      "step": 1908
    },
    {
      "epoch": 0.14835250233136463,
      "grad_norm": 0.5355232954025269,
      "learning_rate": 9.258237488343178e-06,
      "loss": 0.0991,
      "step": 1909
    },
    {
      "epoch": 0.14843021448554555,
      "grad_norm": 0.3998416066169739,
      "learning_rate": 9.257848927572273e-06,
      "loss": 0.3936,
      "step": 1910
    },
    {
      "epoch": 0.14850792663972645,
      "grad_norm": 0.3446660041809082,
      "learning_rate": 9.257460366801368e-06,
      "loss": 0.2637,
      "step": 1911
    },
    {
      "epoch": 0.14858563879390738,
      "grad_norm": 0.3390500247478485,
      "learning_rate": 9.257071806030465e-06,
      "loss": 0.3148,
      "step": 1912
    },
    {
      "epoch": 0.14866335094808827,
      "grad_norm": 0.43450456857681274,
      "learning_rate": 9.25668324525956e-06,
      "loss": 0.4027,
      "step": 1913
    },
    {
      "epoch": 0.1487410631022692,
      "grad_norm": 0.34974732995033264,
      "learning_rate": 9.256294684488655e-06,
      "loss": 0.2705,
      "step": 1914
    },
    {
      "epoch": 0.1488187752564501,
      "grad_norm": 0.0892847403883934,
      "learning_rate": 9.255906123717751e-06,
      "loss": 0.0445,
      "step": 1915
    },
    {
      "epoch": 0.14889648741063102,
      "grad_norm": 0.19156399369239807,
      "learning_rate": 9.255517562946844e-06,
      "loss": 0.1418,
      "step": 1916
    },
    {
      "epoch": 0.14897419956481195,
      "grad_norm": 0.19393454492092133,
      "learning_rate": 9.255129002175941e-06,
      "loss": 0.1203,
      "step": 1917
    },
    {
      "epoch": 0.14905191171899285,
      "grad_norm": 0.20346124470233917,
      "learning_rate": 9.254740441405036e-06,
      "loss": 0.1418,
      "step": 1918
    },
    {
      "epoch": 0.14912962387317377,
      "grad_norm": 0.05731126293540001,
      "learning_rate": 9.254351880634131e-06,
      "loss": 0.0196,
      "step": 1919
    },
    {
      "epoch": 0.14920733602735467,
      "grad_norm": 0.4806930124759674,
      "learning_rate": 9.253963319863228e-06,
      "loss": 0.8047,
      "step": 1920
    },
    {
      "epoch": 0.1492850481815356,
      "grad_norm": 0.5761611461639404,
      "learning_rate": 9.253574759092323e-06,
      "loss": 0.5267,
      "step": 1921
    },
    {
      "epoch": 0.1493627603357165,
      "grad_norm": 0.5157683491706848,
      "learning_rate": 9.253186198321418e-06,
      "loss": 0.1962,
      "step": 1922
    },
    {
      "epoch": 0.14944047248989742,
      "grad_norm": 0.3241215944290161,
      "learning_rate": 9.252797637550514e-06,
      "loss": 0.2218,
      "step": 1923
    },
    {
      "epoch": 0.14951818464407834,
      "grad_norm": 0.2598632872104645,
      "learning_rate": 9.252409076779609e-06,
      "loss": 0.0989,
      "step": 1924
    },
    {
      "epoch": 0.14959589679825924,
      "grad_norm": 0.21452704071998596,
      "learning_rate": 9.252020516008704e-06,
      "loss": 0.0948,
      "step": 1925
    },
    {
      "epoch": 0.14967360895244017,
      "grad_norm": 0.9965200424194336,
      "learning_rate": 9.251631955237799e-06,
      "loss": 0.2863,
      "step": 1926
    },
    {
      "epoch": 0.14975132110662107,
      "grad_norm": 0.3266140818595886,
      "learning_rate": 9.251243394466896e-06,
      "loss": 0.3566,
      "step": 1927
    },
    {
      "epoch": 0.149829033260802,
      "grad_norm": 0.527350127696991,
      "learning_rate": 9.25085483369599e-06,
      "loss": 0.171,
      "step": 1928
    },
    {
      "epoch": 0.14990674541498292,
      "grad_norm": 0.3713836669921875,
      "learning_rate": 9.250466272925086e-06,
      "loss": 0.2551,
      "step": 1929
    },
    {
      "epoch": 0.14998445756916381,
      "grad_norm": 0.10647927969694138,
      "learning_rate": 9.250077712154182e-06,
      "loss": 0.1221,
      "step": 1930
    },
    {
      "epoch": 0.15006216972334474,
      "grad_norm": 0.24863849580287933,
      "learning_rate": 9.249689151383277e-06,
      "loss": 0.1845,
      "step": 1931
    },
    {
      "epoch": 0.15013988187752564,
      "grad_norm": 0.6719349026679993,
      "learning_rate": 9.249300590612372e-06,
      "loss": 0.7605,
      "step": 1932
    },
    {
      "epoch": 0.15021759403170656,
      "grad_norm": 0.3245203495025635,
      "learning_rate": 9.248912029841469e-06,
      "loss": 0.2057,
      "step": 1933
    },
    {
      "epoch": 0.15029530618588746,
      "grad_norm": 0.25649482011795044,
      "learning_rate": 9.248523469070564e-06,
      "loss": 0.2082,
      "step": 1934
    },
    {
      "epoch": 0.1503730183400684,
      "grad_norm": 0.37001606822013855,
      "learning_rate": 9.248134908299659e-06,
      "loss": 0.2015,
      "step": 1935
    },
    {
      "epoch": 0.1504507304942493,
      "grad_norm": 0.5239736437797546,
      "learning_rate": 9.247746347528754e-06,
      "loss": 0.5342,
      "step": 1936
    },
    {
      "epoch": 0.1505284426484302,
      "grad_norm": 0.2952885925769806,
      "learning_rate": 9.24735778675785e-06,
      "loss": 0.2403,
      "step": 1937
    },
    {
      "epoch": 0.15060615480261114,
      "grad_norm": 0.6196228861808777,
      "learning_rate": 9.246969225986945e-06,
      "loss": 0.6437,
      "step": 1938
    },
    {
      "epoch": 0.15068386695679203,
      "grad_norm": 0.37366724014282227,
      "learning_rate": 9.24658066521604e-06,
      "loss": 0.2164,
      "step": 1939
    },
    {
      "epoch": 0.15076157911097296,
      "grad_norm": 0.7039561867713928,
      "learning_rate": 9.246192104445137e-06,
      "loss": 1.0001,
      "step": 1940
    },
    {
      "epoch": 0.15083929126515386,
      "grad_norm": 0.12631061673164368,
      "learning_rate": 9.245803543674232e-06,
      "loss": 0.1478,
      "step": 1941
    },
    {
      "epoch": 0.15091700341933478,
      "grad_norm": 0.10630081593990326,
      "learning_rate": 9.245414982903327e-06,
      "loss": 0.0233,
      "step": 1942
    },
    {
      "epoch": 0.1509947155735157,
      "grad_norm": 0.6990630030632019,
      "learning_rate": 9.245026422132423e-06,
      "loss": 0.4099,
      "step": 1943
    },
    {
      "epoch": 0.1510724277276966,
      "grad_norm": 0.08778059482574463,
      "learning_rate": 9.244637861361517e-06,
      "loss": 0.0443,
      "step": 1944
    },
    {
      "epoch": 0.15115013988187753,
      "grad_norm": 0.05839471146464348,
      "learning_rate": 9.244249300590613e-06,
      "loss": 0.0152,
      "step": 1945
    },
    {
      "epoch": 0.15122785203605843,
      "grad_norm": 0.20738165080547333,
      "learning_rate": 9.243860739819708e-06,
      "loss": 0.1809,
      "step": 1946
    },
    {
      "epoch": 0.15130556419023936,
      "grad_norm": 0.21624387800693512,
      "learning_rate": 9.243472179048803e-06,
      "loss": 0.1462,
      "step": 1947
    },
    {
      "epoch": 0.15138327634442028,
      "grad_norm": 0.26570791006088257,
      "learning_rate": 9.2430836182779e-06,
      "loss": 0.4379,
      "step": 1948
    },
    {
      "epoch": 0.15146098849860118,
      "grad_norm": 0.2594716548919678,
      "learning_rate": 9.242695057506995e-06,
      "loss": 0.1527,
      "step": 1949
    },
    {
      "epoch": 0.1515387006527821,
      "grad_norm": 0.20613862574100494,
      "learning_rate": 9.24230649673609e-06,
      "loss": 0.1908,
      "step": 1950
    },
    {
      "epoch": 0.151616412806963,
      "grad_norm": 0.30247852206230164,
      "learning_rate": 9.241917935965186e-06,
      "loss": 0.2336,
      "step": 1951
    },
    {
      "epoch": 0.15169412496114393,
      "grad_norm": 0.2743975520133972,
      "learning_rate": 9.241529375194281e-06,
      "loss": 0.2958,
      "step": 1952
    },
    {
      "epoch": 0.15177183711532483,
      "grad_norm": 0.17903465032577515,
      "learning_rate": 9.241140814423376e-06,
      "loss": 0.1818,
      "step": 1953
    },
    {
      "epoch": 0.15184954926950575,
      "grad_norm": 0.19391697645187378,
      "learning_rate": 9.240752253652471e-06,
      "loss": 0.0942,
      "step": 1954
    },
    {
      "epoch": 0.15192726142368668,
      "grad_norm": 0.6943462491035461,
      "learning_rate": 9.240363692881568e-06,
      "loss": 0.5774,
      "step": 1955
    },
    {
      "epoch": 0.15200497357786757,
      "grad_norm": 0.225960835814476,
      "learning_rate": 9.239975132110663e-06,
      "loss": 0.0894,
      "step": 1956
    },
    {
      "epoch": 0.1520826857320485,
      "grad_norm": 0.21708732843399048,
      "learning_rate": 9.239586571339758e-06,
      "loss": 0.1716,
      "step": 1957
    },
    {
      "epoch": 0.1521603978862294,
      "grad_norm": 0.2529194951057434,
      "learning_rate": 9.239198010568854e-06,
      "loss": 0.075,
      "step": 1958
    },
    {
      "epoch": 0.15223811004041032,
      "grad_norm": 0.28446903824806213,
      "learning_rate": 9.23880944979795e-06,
      "loss": 0.3616,
      "step": 1959
    },
    {
      "epoch": 0.15231582219459122,
      "grad_norm": 0.1263846606016159,
      "learning_rate": 9.238420889027044e-06,
      "loss": 0.0339,
      "step": 1960
    },
    {
      "epoch": 0.15239353434877215,
      "grad_norm": 0.07685798406600952,
      "learning_rate": 9.238032328256141e-06,
      "loss": 0.005,
      "step": 1961
    },
    {
      "epoch": 0.15247124650295307,
      "grad_norm": 0.10128019750118256,
      "learning_rate": 9.237643767485236e-06,
      "loss": 0.0199,
      "step": 1962
    },
    {
      "epoch": 0.15254895865713397,
      "grad_norm": 0.3527381420135498,
      "learning_rate": 9.23725520671433e-06,
      "loss": 0.2401,
      "step": 1963
    },
    {
      "epoch": 0.1526266708113149,
      "grad_norm": 0.14026929438114166,
      "learning_rate": 9.236866645943426e-06,
      "loss": 0.0996,
      "step": 1964
    },
    {
      "epoch": 0.1527043829654958,
      "grad_norm": 0.3877023160457611,
      "learning_rate": 9.236478085172522e-06,
      "loss": 0.1609,
      "step": 1965
    },
    {
      "epoch": 0.15278209511967672,
      "grad_norm": 0.7001241445541382,
      "learning_rate": 9.236089524401617e-06,
      "loss": 0.767,
      "step": 1966
    },
    {
      "epoch": 0.15285980727385762,
      "grad_norm": 0.15777195990085602,
      "learning_rate": 9.235700963630712e-06,
      "loss": 0.0564,
      "step": 1967
    },
    {
      "epoch": 0.15293751942803854,
      "grad_norm": 0.39588770270347595,
      "learning_rate": 9.235312402859809e-06,
      "loss": 0.2422,
      "step": 1968
    },
    {
      "epoch": 0.15301523158221947,
      "grad_norm": 0.1712643802165985,
      "learning_rate": 9.234923842088904e-06,
      "loss": 0.0523,
      "step": 1969
    },
    {
      "epoch": 0.15309294373640037,
      "grad_norm": 0.28310689330101013,
      "learning_rate": 9.234535281317999e-06,
      "loss": 0.1861,
      "step": 1970
    },
    {
      "epoch": 0.1531706558905813,
      "grad_norm": 0.1933714896440506,
      "learning_rate": 9.234146720547096e-06,
      "loss": 0.0799,
      "step": 1971
    },
    {
      "epoch": 0.1532483680447622,
      "grad_norm": 0.2632824778556824,
      "learning_rate": 9.233758159776189e-06,
      "loss": 0.0566,
      "step": 1972
    },
    {
      "epoch": 0.15332608019894312,
      "grad_norm": 0.32546958327293396,
      "learning_rate": 9.233369599005285e-06,
      "loss": 0.5344,
      "step": 1973
    },
    {
      "epoch": 0.15340379235312404,
      "grad_norm": 0.26643410325050354,
      "learning_rate": 9.23298103823438e-06,
      "loss": 0.1593,
      "step": 1974
    },
    {
      "epoch": 0.15348150450730494,
      "grad_norm": 0.3627137839794159,
      "learning_rate": 9.232592477463475e-06,
      "loss": 0.1765,
      "step": 1975
    },
    {
      "epoch": 0.15355921666148586,
      "grad_norm": 0.08382415771484375,
      "learning_rate": 9.232203916692572e-06,
      "loss": 0.0286,
      "step": 1976
    },
    {
      "epoch": 0.15363692881566676,
      "grad_norm": 0.4682539105415344,
      "learning_rate": 9.231815355921667e-06,
      "loss": 0.2166,
      "step": 1977
    },
    {
      "epoch": 0.1537146409698477,
      "grad_norm": 0.5866514444351196,
      "learning_rate": 9.231426795150762e-06,
      "loss": 0.2939,
      "step": 1978
    },
    {
      "epoch": 0.15379235312402859,
      "grad_norm": 0.2045735865831375,
      "learning_rate": 9.231038234379858e-06,
      "loss": 0.0424,
      "step": 1979
    },
    {
      "epoch": 0.1538700652782095,
      "grad_norm": 0.1458835005760193,
      "learning_rate": 9.230649673608953e-06,
      "loss": 0.0719,
      "step": 1980
    },
    {
      "epoch": 0.15394777743239044,
      "grad_norm": 0.42883461713790894,
      "learning_rate": 9.230261112838048e-06,
      "loss": 0.4383,
      "step": 1981
    },
    {
      "epoch": 0.15402548958657133,
      "grad_norm": 0.32868796586990356,
      "learning_rate": 9.229872552067143e-06,
      "loss": 0.2679,
      "step": 1982
    },
    {
      "epoch": 0.15410320174075226,
      "grad_norm": 0.6589144468307495,
      "learning_rate": 9.22948399129624e-06,
      "loss": 0.2518,
      "step": 1983
    },
    {
      "epoch": 0.15418091389493316,
      "grad_norm": 0.33245861530303955,
      "learning_rate": 9.229095430525335e-06,
      "loss": 0.4711,
      "step": 1984
    },
    {
      "epoch": 0.15425862604911408,
      "grad_norm": 0.15101425349712372,
      "learning_rate": 9.22870686975443e-06,
      "loss": 0.0848,
      "step": 1985
    },
    {
      "epoch": 0.15433633820329498,
      "grad_norm": 0.3168770968914032,
      "learning_rate": 9.228318308983527e-06,
      "loss": 0.3301,
      "step": 1986
    },
    {
      "epoch": 0.1544140503574759,
      "grad_norm": 0.057307928800582886,
      "learning_rate": 9.227929748212621e-06,
      "loss": 0.014,
      "step": 1987
    },
    {
      "epoch": 0.15449176251165683,
      "grad_norm": 0.2870592772960663,
      "learning_rate": 9.227541187441716e-06,
      "loss": 0.0814,
      "step": 1988
    },
    {
      "epoch": 0.15456947466583773,
      "grad_norm": 0.09026439487934113,
      "learning_rate": 9.227152626670813e-06,
      "loss": 0.0585,
      "step": 1989
    },
    {
      "epoch": 0.15464718682001866,
      "grad_norm": 0.36743229627609253,
      "learning_rate": 9.226764065899908e-06,
      "loss": 0.299,
      "step": 1990
    },
    {
      "epoch": 0.15472489897419955,
      "grad_norm": 0.17502357065677643,
      "learning_rate": 9.226375505129003e-06,
      "loss": 0.1218,
      "step": 1991
    },
    {
      "epoch": 0.15480261112838048,
      "grad_norm": 0.08358846604824066,
      "learning_rate": 9.225986944358098e-06,
      "loss": 0.0377,
      "step": 1992
    },
    {
      "epoch": 0.1548803232825614,
      "grad_norm": 0.33839625120162964,
      "learning_rate": 9.225598383587195e-06,
      "loss": 0.1936,
      "step": 1993
    },
    {
      "epoch": 0.1549580354367423,
      "grad_norm": 0.2251719832420349,
      "learning_rate": 9.22520982281629e-06,
      "loss": 0.6764,
      "step": 1994
    },
    {
      "epoch": 0.15503574759092323,
      "grad_norm": 0.5197272300720215,
      "learning_rate": 9.224821262045384e-06,
      "loss": 0.1506,
      "step": 1995
    },
    {
      "epoch": 0.15511345974510413,
      "grad_norm": 0.25584548711776733,
      "learning_rate": 9.224432701274481e-06,
      "loss": 0.1354,
      "step": 1996
    },
    {
      "epoch": 0.15519117189928505,
      "grad_norm": 0.3556699752807617,
      "learning_rate": 9.224044140503576e-06,
      "loss": 0.1484,
      "step": 1997
    },
    {
      "epoch": 0.15526888405346595,
      "grad_norm": 0.26634499430656433,
      "learning_rate": 9.223655579732671e-06,
      "loss": 0.1952,
      "step": 1998
    },
    {
      "epoch": 0.15534659620764688,
      "grad_norm": 0.26759660243988037,
      "learning_rate": 9.223267018961766e-06,
      "loss": 0.1738,
      "step": 1999
    },
    {
      "epoch": 0.1554243083618278,
      "grad_norm": 0.4923156797885895,
      "learning_rate": 9.222878458190861e-06,
      "loss": 0.2807,
      "step": 2000
    },
    {
      "epoch": 0.1555020205160087,
      "grad_norm": 0.07906440645456314,
      "learning_rate": 9.222489897419958e-06,
      "loss": 0.0392,
      "step": 2001
    },
    {
      "epoch": 0.15557973267018962,
      "grad_norm": 0.13405665755271912,
      "learning_rate": 9.222101336649052e-06,
      "loss": 0.0676,
      "step": 2002
    },
    {
      "epoch": 0.15565744482437052,
      "grad_norm": 0.15917524695396423,
      "learning_rate": 9.221712775878147e-06,
      "loss": 0.114,
      "step": 2003
    },
    {
      "epoch": 0.15573515697855145,
      "grad_norm": 0.4003926217556,
      "learning_rate": 9.221324215107244e-06,
      "loss": 0.4025,
      "step": 2004
    },
    {
      "epoch": 0.15581286913273235,
      "grad_norm": 0.13268497586250305,
      "learning_rate": 9.220935654336339e-06,
      "loss": 0.0751,
      "step": 2005
    },
    {
      "epoch": 0.15589058128691327,
      "grad_norm": 0.21329855918884277,
      "learning_rate": 9.220547093565434e-06,
      "loss": 0.1783,
      "step": 2006
    },
    {
      "epoch": 0.1559682934410942,
      "grad_norm": 0.24192549288272858,
      "learning_rate": 9.220158532794529e-06,
      "loss": 0.1332,
      "step": 2007
    },
    {
      "epoch": 0.1560460055952751,
      "grad_norm": 0.2421988844871521,
      "learning_rate": 9.219769972023626e-06,
      "loss": 0.2685,
      "step": 2008
    },
    {
      "epoch": 0.15612371774945602,
      "grad_norm": 0.6063023209571838,
      "learning_rate": 9.21938141125272e-06,
      "loss": 0.7808,
      "step": 2009
    },
    {
      "epoch": 0.15620142990363692,
      "grad_norm": 0.2538151741027832,
      "learning_rate": 9.218992850481815e-06,
      "loss": 0.1447,
      "step": 2010
    },
    {
      "epoch": 0.15627914205781784,
      "grad_norm": 0.3923315107822418,
      "learning_rate": 9.218604289710912e-06,
      "loss": 0.1728,
      "step": 2011
    },
    {
      "epoch": 0.15635685421199877,
      "grad_norm": 0.11264669895172119,
      "learning_rate": 9.218215728940007e-06,
      "loss": 0.0565,
      "step": 2012
    },
    {
      "epoch": 0.15643456636617967,
      "grad_norm": 0.3336503207683563,
      "learning_rate": 9.217827168169102e-06,
      "loss": 0.1741,
      "step": 2013
    },
    {
      "epoch": 0.1565122785203606,
      "grad_norm": 0.7896547317504883,
      "learning_rate": 9.217438607398199e-06,
      "loss": 0.4572,
      "step": 2014
    },
    {
      "epoch": 0.1565899906745415,
      "grad_norm": 0.1350819319486618,
      "learning_rate": 9.217050046627292e-06,
      "loss": 0.0475,
      "step": 2015
    },
    {
      "epoch": 0.15666770282872242,
      "grad_norm": 0.2955266237258911,
      "learning_rate": 9.216661485856389e-06,
      "loss": 0.1255,
      "step": 2016
    },
    {
      "epoch": 0.1567454149829033,
      "grad_norm": 0.07099664211273193,
      "learning_rate": 9.216272925085484e-06,
      "loss": 0.0439,
      "step": 2017
    },
    {
      "epoch": 0.15682312713708424,
      "grad_norm": 0.41018110513687134,
      "learning_rate": 9.215884364314578e-06,
      "loss": 0.2397,
      "step": 2018
    },
    {
      "epoch": 0.15690083929126517,
      "grad_norm": 0.3917129337787628,
      "learning_rate": 9.215495803543675e-06,
      "loss": 0.2755,
      "step": 2019
    },
    {
      "epoch": 0.15697855144544606,
      "grad_norm": 0.4143964350223541,
      "learning_rate": 9.21510724277277e-06,
      "loss": 0.2261,
      "step": 2020
    },
    {
      "epoch": 0.157056263599627,
      "grad_norm": 0.1386731117963791,
      "learning_rate": 9.214718682001867e-06,
      "loss": 0.1068,
      "step": 2021
    },
    {
      "epoch": 0.1571339757538079,
      "grad_norm": 0.6747106909751892,
      "learning_rate": 9.214330121230962e-06,
      "loss": 0.3314,
      "step": 2022
    },
    {
      "epoch": 0.1572116879079888,
      "grad_norm": 0.11966875195503235,
      "learning_rate": 9.213941560460057e-06,
      "loss": 0.1157,
      "step": 2023
    },
    {
      "epoch": 0.1572894000621697,
      "grad_norm": 0.22504638135433197,
      "learning_rate": 9.213552999689153e-06,
      "loss": 0.4074,
      "step": 2024
    },
    {
      "epoch": 0.15736711221635064,
      "grad_norm": 0.12120970338582993,
      "learning_rate": 9.213164438918247e-06,
      "loss": 0.0238,
      "step": 2025
    },
    {
      "epoch": 0.15744482437053156,
      "grad_norm": 0.06428063660860062,
      "learning_rate": 9.212775878147343e-06,
      "loss": 0.0245,
      "step": 2026
    },
    {
      "epoch": 0.15752253652471246,
      "grad_norm": 0.2643944323062897,
      "learning_rate": 9.212387317376438e-06,
      "loss": 0.0892,
      "step": 2027
    },
    {
      "epoch": 0.15760024867889338,
      "grad_norm": 0.1462552696466446,
      "learning_rate": 9.211998756605533e-06,
      "loss": 0.1513,
      "step": 2028
    },
    {
      "epoch": 0.15767796083307428,
      "grad_norm": 0.43322256207466125,
      "learning_rate": 9.21161019583463e-06,
      "loss": 0.4647,
      "step": 2029
    },
    {
      "epoch": 0.1577556729872552,
      "grad_norm": 0.4538256525993347,
      "learning_rate": 9.211221635063725e-06,
      "loss": 0.2202,
      "step": 2030
    },
    {
      "epoch": 0.15783338514143613,
      "grad_norm": 0.30998608469963074,
      "learning_rate": 9.21083307429282e-06,
      "loss": 0.1608,
      "step": 2031
    },
    {
      "epoch": 0.15791109729561703,
      "grad_norm": 0.3040706217288971,
      "learning_rate": 9.210444513521916e-06,
      "loss": 0.2357,
      "step": 2032
    },
    {
      "epoch": 0.15798880944979796,
      "grad_norm": 0.13226783275604248,
      "learning_rate": 9.210055952751011e-06,
      "loss": 0.0496,
      "step": 2033
    },
    {
      "epoch": 0.15806652160397885,
      "grad_norm": 0.33247387409210205,
      "learning_rate": 9.209667391980106e-06,
      "loss": 0.072,
      "step": 2034
    },
    {
      "epoch": 0.15814423375815978,
      "grad_norm": 0.328368216753006,
      "learning_rate": 9.209278831209201e-06,
      "loss": 0.1575,
      "step": 2035
    },
    {
      "epoch": 0.15822194591234068,
      "grad_norm": 0.08742867410182953,
      "learning_rate": 9.208890270438298e-06,
      "loss": 0.0367,
      "step": 2036
    },
    {
      "epoch": 0.1582996580665216,
      "grad_norm": 0.44257116317749023,
      "learning_rate": 9.208501709667393e-06,
      "loss": 0.2946,
      "step": 2037
    },
    {
      "epoch": 0.15837737022070253,
      "grad_norm": 0.10075780749320984,
      "learning_rate": 9.208113148896488e-06,
      "loss": 0.0265,
      "step": 2038
    },
    {
      "epoch": 0.15845508237488343,
      "grad_norm": 0.5274208188056946,
      "learning_rate": 9.207724588125584e-06,
      "loss": 0.1194,
      "step": 2039
    },
    {
      "epoch": 0.15853279452906435,
      "grad_norm": 0.44240379333496094,
      "learning_rate": 9.20733602735468e-06,
      "loss": 0.2108,
      "step": 2040
    },
    {
      "epoch": 0.15861050668324525,
      "grad_norm": 0.18733395636081696,
      "learning_rate": 9.206947466583774e-06,
      "loss": 0.1167,
      "step": 2041
    },
    {
      "epoch": 0.15868821883742618,
      "grad_norm": 0.5801123380661011,
      "learning_rate": 9.20655890581287e-06,
      "loss": 0.9687,
      "step": 2042
    },
    {
      "epoch": 0.15876593099160707,
      "grad_norm": 0.13070477545261383,
      "learning_rate": 9.206170345041964e-06,
      "loss": 0.0325,
      "step": 2043
    },
    {
      "epoch": 0.158843643145788,
      "grad_norm": 0.10882484167814255,
      "learning_rate": 9.20578178427106e-06,
      "loss": 0.035,
      "step": 2044
    },
    {
      "epoch": 0.15892135529996892,
      "grad_norm": 0.658626914024353,
      "learning_rate": 9.205393223500156e-06,
      "loss": 0.4214,
      "step": 2045
    },
    {
      "epoch": 0.15899906745414982,
      "grad_norm": 0.19230493903160095,
      "learning_rate": 9.20500466272925e-06,
      "loss": 0.1081,
      "step": 2046
    },
    {
      "epoch": 0.15907677960833075,
      "grad_norm": 0.13924294710159302,
      "learning_rate": 9.204616101958347e-06,
      "loss": 0.1421,
      "step": 2047
    },
    {
      "epoch": 0.15915449176251165,
      "grad_norm": 0.43919384479522705,
      "learning_rate": 9.204227541187442e-06,
      "loss": 0.1692,
      "step": 2048
    },
    {
      "epoch": 0.15923220391669257,
      "grad_norm": 0.1829465627670288,
      "learning_rate": 9.203838980416539e-06,
      "loss": 0.1884,
      "step": 2049
    },
    {
      "epoch": 0.1593099160708735,
      "grad_norm": 0.3891359269618988,
      "learning_rate": 9.203450419645634e-06,
      "loss": 0.2884,
      "step": 2050
    },
    {
      "epoch": 0.1593876282250544,
      "grad_norm": 0.14638668298721313,
      "learning_rate": 9.203061858874729e-06,
      "loss": 0.1732,
      "step": 2051
    },
    {
      "epoch": 0.15946534037923532,
      "grad_norm": 0.3325358033180237,
      "learning_rate": 9.202673298103825e-06,
      "loss": 0.0723,
      "step": 2052
    },
    {
      "epoch": 0.15954305253341622,
      "grad_norm": 0.04656749218702316,
      "learning_rate": 9.202284737332919e-06,
      "loss": 0.0082,
      "step": 2053
    },
    {
      "epoch": 0.15962076468759714,
      "grad_norm": 0.27090516686439514,
      "learning_rate": 9.201896176562015e-06,
      "loss": 0.1168,
      "step": 2054
    },
    {
      "epoch": 0.15969847684177804,
      "grad_norm": 0.34614914655685425,
      "learning_rate": 9.20150761579111e-06,
      "loss": 0.5334,
      "step": 2055
    },
    {
      "epoch": 0.15977618899595897,
      "grad_norm": 0.5164764523506165,
      "learning_rate": 9.201119055020205e-06,
      "loss": 0.0414,
      "step": 2056
    },
    {
      "epoch": 0.1598539011501399,
      "grad_norm": 0.19443681836128235,
      "learning_rate": 9.200730494249302e-06,
      "loss": 0.0813,
      "step": 2057
    },
    {
      "epoch": 0.1599316133043208,
      "grad_norm": 0.38757115602493286,
      "learning_rate": 9.200341933478397e-06,
      "loss": 0.3187,
      "step": 2058
    },
    {
      "epoch": 0.16000932545850172,
      "grad_norm": 0.6869766116142273,
      "learning_rate": 9.199953372707492e-06,
      "loss": 0.4411,
      "step": 2059
    },
    {
      "epoch": 0.16008703761268261,
      "grad_norm": 0.16411060094833374,
      "learning_rate": 9.199564811936588e-06,
      "loss": 0.0456,
      "step": 2060
    },
    {
      "epoch": 0.16016474976686354,
      "grad_norm": 0.39594027400016785,
      "learning_rate": 9.199176251165683e-06,
      "loss": 0.3579,
      "step": 2061
    },
    {
      "epoch": 0.16024246192104444,
      "grad_norm": 0.16575533151626587,
      "learning_rate": 9.198787690394778e-06,
      "loss": 0.0695,
      "step": 2062
    },
    {
      "epoch": 0.16032017407522536,
      "grad_norm": 0.2979429066181183,
      "learning_rate": 9.198399129623873e-06,
      "loss": 0.5042,
      "step": 2063
    },
    {
      "epoch": 0.1603978862294063,
      "grad_norm": 0.22579054534435272,
      "learning_rate": 9.19801056885297e-06,
      "loss": 0.2865,
      "step": 2064
    },
    {
      "epoch": 0.1604755983835872,
      "grad_norm": 0.174417182803154,
      "learning_rate": 9.197622008082065e-06,
      "loss": 0.0637,
      "step": 2065
    },
    {
      "epoch": 0.1605533105377681,
      "grad_norm": 0.06111652031540871,
      "learning_rate": 9.19723344731116e-06,
      "loss": 0.0155,
      "step": 2066
    },
    {
      "epoch": 0.160631022691949,
      "grad_norm": 0.15059739351272583,
      "learning_rate": 9.196844886540256e-06,
      "loss": 0.0441,
      "step": 2067
    },
    {
      "epoch": 0.16070873484612994,
      "grad_norm": 0.3670250475406647,
      "learning_rate": 9.196456325769351e-06,
      "loss": 0.253,
      "step": 2068
    },
    {
      "epoch": 0.16078644700031086,
      "grad_norm": 0.5407605767250061,
      "learning_rate": 9.196067764998446e-06,
      "loss": 0.4289,
      "step": 2069
    },
    {
      "epoch": 0.16086415915449176,
      "grad_norm": 0.12784071266651154,
      "learning_rate": 9.195679204227543e-06,
      "loss": 0.0568,
      "step": 2070
    },
    {
      "epoch": 0.16094187130867268,
      "grad_norm": 0.2623061239719391,
      "learning_rate": 9.195290643456636e-06,
      "loss": 0.2617,
      "step": 2071
    },
    {
      "epoch": 0.16101958346285358,
      "grad_norm": 0.34213200211524963,
      "learning_rate": 9.194902082685733e-06,
      "loss": 0.4555,
      "step": 2072
    },
    {
      "epoch": 0.1610972956170345,
      "grad_norm": 0.6530295610427856,
      "learning_rate": 9.194513521914828e-06,
      "loss": 0.3084,
      "step": 2073
    },
    {
      "epoch": 0.1611750077712154,
      "grad_norm": 0.11537936329841614,
      "learning_rate": 9.194124961143923e-06,
      "loss": 0.0206,
      "step": 2074
    },
    {
      "epoch": 0.16125271992539633,
      "grad_norm": 0.2802378237247467,
      "learning_rate": 9.19373640037302e-06,
      "loss": 0.2989,
      "step": 2075
    },
    {
      "epoch": 0.16133043207957726,
      "grad_norm": 0.1449621021747589,
      "learning_rate": 9.193347839602114e-06,
      "loss": 0.0667,
      "step": 2076
    },
    {
      "epoch": 0.16140814423375816,
      "grad_norm": 0.8733662366867065,
      "learning_rate": 9.19295927883121e-06,
      "loss": 0.5608,
      "step": 2077
    },
    {
      "epoch": 0.16148585638793908,
      "grad_norm": 0.0773952305316925,
      "learning_rate": 9.192570718060306e-06,
      "loss": 0.0365,
      "step": 2078
    },
    {
      "epoch": 0.16156356854211998,
      "grad_norm": 0.13500645756721497,
      "learning_rate": 9.192182157289401e-06,
      "loss": 0.0506,
      "step": 2079
    },
    {
      "epoch": 0.1616412806963009,
      "grad_norm": 0.10193324834108353,
      "learning_rate": 9.191793596518498e-06,
      "loss": 0.0877,
      "step": 2080
    },
    {
      "epoch": 0.1617189928504818,
      "grad_norm": 0.31231433153152466,
      "learning_rate": 9.19140503574759e-06,
      "loss": 0.3475,
      "step": 2081
    },
    {
      "epoch": 0.16179670500466273,
      "grad_norm": 0.4420921206474304,
      "learning_rate": 9.191016474976687e-06,
      "loss": 0.3884,
      "step": 2082
    },
    {
      "epoch": 0.16187441715884365,
      "grad_norm": 0.3010358214378357,
      "learning_rate": 9.190627914205782e-06,
      "loss": 0.1393,
      "step": 2083
    },
    {
      "epoch": 0.16195212931302455,
      "grad_norm": 0.2511402368545532,
      "learning_rate": 9.190239353434877e-06,
      "loss": 0.0997,
      "step": 2084
    },
    {
      "epoch": 0.16202984146720548,
      "grad_norm": 0.30329978466033936,
      "learning_rate": 9.189850792663974e-06,
      "loss": 0.2805,
      "step": 2085
    },
    {
      "epoch": 0.16210755362138637,
      "grad_norm": 0.2377777248620987,
      "learning_rate": 9.189462231893069e-06,
      "loss": 0.0646,
      "step": 2086
    },
    {
      "epoch": 0.1621852657755673,
      "grad_norm": 0.06893476843833923,
      "learning_rate": 9.189073671122164e-06,
      "loss": 0.0395,
      "step": 2087
    },
    {
      "epoch": 0.16226297792974823,
      "grad_norm": 0.2587464153766632,
      "learning_rate": 9.18868511035126e-06,
      "loss": 0.1993,
      "step": 2088
    },
    {
      "epoch": 0.16234069008392912,
      "grad_norm": 0.6099798083305359,
      "learning_rate": 9.188296549580355e-06,
      "loss": 0.4947,
      "step": 2089
    },
    {
      "epoch": 0.16241840223811005,
      "grad_norm": 0.18607103824615479,
      "learning_rate": 9.18790798880945e-06,
      "loss": 0.0741,
      "step": 2090
    },
    {
      "epoch": 0.16249611439229095,
      "grad_norm": 0.27001625299453735,
      "learning_rate": 9.187519428038545e-06,
      "loss": 0.1529,
      "step": 2091
    },
    {
      "epoch": 0.16257382654647187,
      "grad_norm": 0.40133264660835266,
      "learning_rate": 9.187130867267642e-06,
      "loss": 0.2783,
      "step": 2092
    },
    {
      "epoch": 0.16265153870065277,
      "grad_norm": 0.7683300375938416,
      "learning_rate": 9.186742306496737e-06,
      "loss": 0.154,
      "step": 2093
    },
    {
      "epoch": 0.1627292508548337,
      "grad_norm": 0.32137030363082886,
      "learning_rate": 9.186353745725832e-06,
      "loss": 0.0679,
      "step": 2094
    },
    {
      "epoch": 0.16280696300901462,
      "grad_norm": 0.18042363226413727,
      "learning_rate": 9.185965184954929e-06,
      "loss": 0.1954,
      "step": 2095
    },
    {
      "epoch": 0.16288467516319552,
      "grad_norm": 0.21101854741573334,
      "learning_rate": 9.185576624184024e-06,
      "loss": 0.2265,
      "step": 2096
    },
    {
      "epoch": 0.16296238731737644,
      "grad_norm": 0.3579043447971344,
      "learning_rate": 9.185188063413118e-06,
      "loss": 0.2282,
      "step": 2097
    },
    {
      "epoch": 0.16304009947155734,
      "grad_norm": 0.5978263020515442,
      "learning_rate": 9.184799502642215e-06,
      "loss": 0.2477,
      "step": 2098
    },
    {
      "epoch": 0.16311781162573827,
      "grad_norm": 0.33687469363212585,
      "learning_rate": 9.184410941871308e-06,
      "loss": 0.1697,
      "step": 2099
    },
    {
      "epoch": 0.16319552377991917,
      "grad_norm": 0.1429223120212555,
      "learning_rate": 9.184022381100405e-06,
      "loss": 0.0623,
      "step": 2100
    },
    {
      "epoch": 0.1632732359341001,
      "grad_norm": 0.10370903462171555,
      "learning_rate": 9.1836338203295e-06,
      "loss": 0.0548,
      "step": 2101
    },
    {
      "epoch": 0.16335094808828102,
      "grad_norm": 0.19992581009864807,
      "learning_rate": 9.183245259558595e-06,
      "loss": 0.1047,
      "step": 2102
    },
    {
      "epoch": 0.16342866024246192,
      "grad_norm": 0.3773916959762573,
      "learning_rate": 9.182856698787692e-06,
      "loss": 0.2712,
      "step": 2103
    },
    {
      "epoch": 0.16350637239664284,
      "grad_norm": 0.2984198033809662,
      "learning_rate": 9.182468138016787e-06,
      "loss": 0.1206,
      "step": 2104
    },
    {
      "epoch": 0.16358408455082374,
      "grad_norm": 0.31728747487068176,
      "learning_rate": 9.182079577245881e-06,
      "loss": 0.2188,
      "step": 2105
    },
    {
      "epoch": 0.16366179670500466,
      "grad_norm": 0.8310748338699341,
      "learning_rate": 9.181691016474978e-06,
      "loss": 0.357,
      "step": 2106
    },
    {
      "epoch": 0.1637395088591856,
      "grad_norm": 0.21675226092338562,
      "learning_rate": 9.181302455704073e-06,
      "loss": 0.1979,
      "step": 2107
    },
    {
      "epoch": 0.1638172210133665,
      "grad_norm": 0.36951136589050293,
      "learning_rate": 9.180913894933168e-06,
      "loss": 0.5496,
      "step": 2108
    },
    {
      "epoch": 0.1638949331675474,
      "grad_norm": 0.1572885513305664,
      "learning_rate": 9.180525334162263e-06,
      "loss": 0.0638,
      "step": 2109
    },
    {
      "epoch": 0.1639726453217283,
      "grad_norm": 0.1932622343301773,
      "learning_rate": 9.18013677339136e-06,
      "loss": 0.0944,
      "step": 2110
    },
    {
      "epoch": 0.16405035747590924,
      "grad_norm": 0.7690970301628113,
      "learning_rate": 9.179748212620455e-06,
      "loss": 1.0446,
      "step": 2111
    },
    {
      "epoch": 0.16412806963009013,
      "grad_norm": 0.33221518993377686,
      "learning_rate": 9.17935965184955e-06,
      "loss": 0.2652,
      "step": 2112
    },
    {
      "epoch": 0.16420578178427106,
      "grad_norm": 0.20247513055801392,
      "learning_rate": 9.178971091078646e-06,
      "loss": 0.0749,
      "step": 2113
    },
    {
      "epoch": 0.16428349393845199,
      "grad_norm": 0.4416322112083435,
      "learning_rate": 9.178582530307741e-06,
      "loss": 0.3872,
      "step": 2114
    },
    {
      "epoch": 0.16436120609263288,
      "grad_norm": 0.13945713639259338,
      "learning_rate": 9.178193969536836e-06,
      "loss": 0.0579,
      "step": 2115
    },
    {
      "epoch": 0.1644389182468138,
      "grad_norm": 0.715871274471283,
      "learning_rate": 9.177805408765933e-06,
      "loss": 0.2067,
      "step": 2116
    },
    {
      "epoch": 0.1645166304009947,
      "grad_norm": 0.10623239725828171,
      "learning_rate": 9.177416847995028e-06,
      "loss": 0.0225,
      "step": 2117
    },
    {
      "epoch": 0.16459434255517563,
      "grad_norm": 0.2098347246646881,
      "learning_rate": 9.177028287224123e-06,
      "loss": 0.0993,
      "step": 2118
    },
    {
      "epoch": 0.16467205470935653,
      "grad_norm": 0.2013297826051712,
      "learning_rate": 9.176639726453218e-06,
      "loss": 0.1292,
      "step": 2119
    },
    {
      "epoch": 0.16474976686353746,
      "grad_norm": 0.19972191751003265,
      "learning_rate": 9.176251165682314e-06,
      "loss": 0.1154,
      "step": 2120
    },
    {
      "epoch": 0.16482747901771838,
      "grad_norm": 0.32549336552619934,
      "learning_rate": 9.175862604911409e-06,
      "loss": 0.1792,
      "step": 2121
    },
    {
      "epoch": 0.16490519117189928,
      "grad_norm": 0.3189406991004944,
      "learning_rate": 9.175474044140504e-06,
      "loss": 0.0916,
      "step": 2122
    },
    {
      "epoch": 0.1649829033260802,
      "grad_norm": 0.266937792301178,
      "learning_rate": 9.1750854833696e-06,
      "loss": 0.0846,
      "step": 2123
    },
    {
      "epoch": 0.1650606154802611,
      "grad_norm": 0.03153420239686966,
      "learning_rate": 9.174696922598696e-06,
      "loss": 0.0168,
      "step": 2124
    },
    {
      "epoch": 0.16513832763444203,
      "grad_norm": 0.36575499176979065,
      "learning_rate": 9.17430836182779e-06,
      "loss": 0.1614,
      "step": 2125
    },
    {
      "epoch": 0.16521603978862295,
      "grad_norm": 1.1146869659423828,
      "learning_rate": 9.173919801056886e-06,
      "loss": 0.3209,
      "step": 2126
    },
    {
      "epoch": 0.16529375194280385,
      "grad_norm": 0.24948440492153168,
      "learning_rate": 9.17353124028598e-06,
      "loss": 0.2182,
      "step": 2127
    },
    {
      "epoch": 0.16537146409698478,
      "grad_norm": 0.6907370686531067,
      "learning_rate": 9.173142679515077e-06,
      "loss": 0.4619,
      "step": 2128
    },
    {
      "epoch": 0.16544917625116567,
      "grad_norm": 0.2341638207435608,
      "learning_rate": 9.172754118744172e-06,
      "loss": 0.1001,
      "step": 2129
    },
    {
      "epoch": 0.1655268884053466,
      "grad_norm": 0.2810957729816437,
      "learning_rate": 9.172365557973267e-06,
      "loss": 0.1993,
      "step": 2130
    },
    {
      "epoch": 0.1656046005595275,
      "grad_norm": 0.1412501484155655,
      "learning_rate": 9.171976997202364e-06,
      "loss": 0.0424,
      "step": 2131
    },
    {
      "epoch": 0.16568231271370842,
      "grad_norm": 0.2794663906097412,
      "learning_rate": 9.171588436431459e-06,
      "loss": 0.1643,
      "step": 2132
    },
    {
      "epoch": 0.16576002486788935,
      "grad_norm": 0.4411197900772095,
      "learning_rate": 9.171199875660554e-06,
      "loss": 0.4948,
      "step": 2133
    },
    {
      "epoch": 0.16583773702207025,
      "grad_norm": 0.07754889130592346,
      "learning_rate": 9.170811314889649e-06,
      "loss": 0.0316,
      "step": 2134
    },
    {
      "epoch": 0.16591544917625117,
      "grad_norm": 0.2899993360042572,
      "learning_rate": 9.170422754118745e-06,
      "loss": 0.1888,
      "step": 2135
    },
    {
      "epoch": 0.16599316133043207,
      "grad_norm": 0.35284507274627686,
      "learning_rate": 9.17003419334784e-06,
      "loss": 0.3859,
      "step": 2136
    },
    {
      "epoch": 0.166070873484613,
      "grad_norm": 0.07356894016265869,
      "learning_rate": 9.169645632576935e-06,
      "loss": 0.0179,
      "step": 2137
    },
    {
      "epoch": 0.1661485856387939,
      "grad_norm": 0.1761859506368637,
      "learning_rate": 9.169257071806032e-06,
      "loss": 0.1665,
      "step": 2138
    },
    {
      "epoch": 0.16622629779297482,
      "grad_norm": 0.14920973777770996,
      "learning_rate": 9.168868511035127e-06,
      "loss": 0.1028,
      "step": 2139
    },
    {
      "epoch": 0.16630400994715575,
      "grad_norm": 0.18959324061870575,
      "learning_rate": 9.168479950264222e-06,
      "loss": 0.0381,
      "step": 2140
    },
    {
      "epoch": 0.16638172210133664,
      "grad_norm": 0.19368794560432434,
      "learning_rate": 9.168091389493318e-06,
      "loss": 0.2002,
      "step": 2141
    },
    {
      "epoch": 0.16645943425551757,
      "grad_norm": 0.7749213576316833,
      "learning_rate": 9.167702828722413e-06,
      "loss": 0.401,
      "step": 2142
    },
    {
      "epoch": 0.16653714640969847,
      "grad_norm": 0.4260440170764923,
      "learning_rate": 9.167314267951508e-06,
      "loss": 0.3253,
      "step": 2143
    },
    {
      "epoch": 0.1666148585638794,
      "grad_norm": 0.33389467000961304,
      "learning_rate": 9.166925707180603e-06,
      "loss": 0.1068,
      "step": 2144
    },
    {
      "epoch": 0.16669257071806032,
      "grad_norm": 0.16249513626098633,
      "learning_rate": 9.1665371464097e-06,
      "loss": 0.0813,
      "step": 2145
    },
    {
      "epoch": 0.16677028287224122,
      "grad_norm": 0.5741744041442871,
      "learning_rate": 9.166148585638795e-06,
      "loss": 0.0927,
      "step": 2146
    },
    {
      "epoch": 0.16684799502642214,
      "grad_norm": 0.3858785629272461,
      "learning_rate": 9.16576002486789e-06,
      "loss": 0.4245,
      "step": 2147
    },
    {
      "epoch": 0.16692570718060304,
      "grad_norm": 0.15027858316898346,
      "learning_rate": 9.165371464096986e-06,
      "loss": 0.0822,
      "step": 2148
    },
    {
      "epoch": 0.16700341933478396,
      "grad_norm": 0.4408199191093445,
      "learning_rate": 9.164982903326081e-06,
      "loss": 0.4577,
      "step": 2149
    },
    {
      "epoch": 0.16708113148896486,
      "grad_norm": 0.12593233585357666,
      "learning_rate": 9.164594342555176e-06,
      "loss": 0.0749,
      "step": 2150
    },
    {
      "epoch": 0.1671588436431458,
      "grad_norm": 0.14380000531673431,
      "learning_rate": 9.164205781784273e-06,
      "loss": 0.0605,
      "step": 2151
    },
    {
      "epoch": 0.1672365557973267,
      "grad_norm": 1.0942763090133667,
      "learning_rate": 9.163817221013366e-06,
      "loss": 0.632,
      "step": 2152
    },
    {
      "epoch": 0.1673142679515076,
      "grad_norm": 0.45868587493896484,
      "learning_rate": 9.163428660242463e-06,
      "loss": 0.2157,
      "step": 2153
    },
    {
      "epoch": 0.16739198010568854,
      "grad_norm": 0.1344098597764969,
      "learning_rate": 9.163040099471558e-06,
      "loss": 0.1477,
      "step": 2154
    },
    {
      "epoch": 0.16746969225986943,
      "grad_norm": 0.19746792316436768,
      "learning_rate": 9.162651538700653e-06,
      "loss": 0.104,
      "step": 2155
    },
    {
      "epoch": 0.16754740441405036,
      "grad_norm": 0.18080230057239532,
      "learning_rate": 9.16226297792975e-06,
      "loss": 0.0554,
      "step": 2156
    },
    {
      "epoch": 0.16762511656823126,
      "grad_norm": 0.07273130118846893,
      "learning_rate": 9.161874417158844e-06,
      "loss": 0.0105,
      "step": 2157
    },
    {
      "epoch": 0.16770282872241218,
      "grad_norm": 0.3312833905220032,
      "learning_rate": 9.16148585638794e-06,
      "loss": 0.1285,
      "step": 2158
    },
    {
      "epoch": 0.1677805408765931,
      "grad_norm": 0.3753833770751953,
      "learning_rate": 9.161097295617036e-06,
      "loss": 0.3242,
      "step": 2159
    },
    {
      "epoch": 0.167858253030774,
      "grad_norm": 0.3076525926589966,
      "learning_rate": 9.16070873484613e-06,
      "loss": 0.2415,
      "step": 2160
    },
    {
      "epoch": 0.16793596518495493,
      "grad_norm": 0.12105236947536469,
      "learning_rate": 9.160320174075226e-06,
      "loss": 0.0878,
      "step": 2161
    },
    {
      "epoch": 0.16801367733913583,
      "grad_norm": 1.3026862144470215,
      "learning_rate": 9.15993161330432e-06,
      "loss": 0.445,
      "step": 2162
    },
    {
      "epoch": 0.16809138949331676,
      "grad_norm": 0.12101494520902634,
      "learning_rate": 9.159543052533417e-06,
      "loss": 0.0911,
      "step": 2163
    },
    {
      "epoch": 0.16816910164749768,
      "grad_norm": 0.1837424784898758,
      "learning_rate": 9.159154491762512e-06,
      "loss": 0.1232,
      "step": 2164
    },
    {
      "epoch": 0.16824681380167858,
      "grad_norm": 0.12191154807806015,
      "learning_rate": 9.158765930991607e-06,
      "loss": 0.1023,
      "step": 2165
    },
    {
      "epoch": 0.1683245259558595,
      "grad_norm": 0.034654028713703156,
      "learning_rate": 9.158377370220704e-06,
      "loss": 0.0055,
      "step": 2166
    },
    {
      "epoch": 0.1684022381100404,
      "grad_norm": 0.802234411239624,
      "learning_rate": 9.157988809449799e-06,
      "loss": 0.2059,
      "step": 2167
    },
    {
      "epoch": 0.16847995026422133,
      "grad_norm": 0.1749519407749176,
      "learning_rate": 9.157600248678894e-06,
      "loss": 0.1161,
      "step": 2168
    },
    {
      "epoch": 0.16855766241840223,
      "grad_norm": 0.44200584292411804,
      "learning_rate": 9.15721168790799e-06,
      "loss": 0.1548,
      "step": 2169
    },
    {
      "epoch": 0.16863537457258315,
      "grad_norm": 0.30651727318763733,
      "learning_rate": 9.156823127137085e-06,
      "loss": 0.4692,
      "step": 2170
    },
    {
      "epoch": 0.16871308672676408,
      "grad_norm": 0.43188950419425964,
      "learning_rate": 9.15643456636618e-06,
      "loss": 0.463,
      "step": 2171
    },
    {
      "epoch": 0.16879079888094498,
      "grad_norm": 0.2880997955799103,
      "learning_rate": 9.156046005595275e-06,
      "loss": 0.2037,
      "step": 2172
    },
    {
      "epoch": 0.1688685110351259,
      "grad_norm": 0.5091960430145264,
      "learning_rate": 9.155657444824372e-06,
      "loss": 0.3755,
      "step": 2173
    },
    {
      "epoch": 0.1689462231893068,
      "grad_norm": 0.09869707375764847,
      "learning_rate": 9.155268884053467e-06,
      "loss": 0.0908,
      "step": 2174
    },
    {
      "epoch": 0.16902393534348772,
      "grad_norm": 1.0465683937072754,
      "learning_rate": 9.154880323282562e-06,
      "loss": 0.2841,
      "step": 2175
    },
    {
      "epoch": 0.16910164749766862,
      "grad_norm": 0.18924346566200256,
      "learning_rate": 9.154491762511658e-06,
      "loss": 0.1843,
      "step": 2176
    },
    {
      "epoch": 0.16917935965184955,
      "grad_norm": 0.5329694747924805,
      "learning_rate": 9.154103201740753e-06,
      "loss": 0.2937,
      "step": 2177
    },
    {
      "epoch": 0.16925707180603047,
      "grad_norm": 0.0987357497215271,
      "learning_rate": 9.153714640969848e-06,
      "loss": 0.0118,
      "step": 2178
    },
    {
      "epoch": 0.16933478396021137,
      "grad_norm": 0.08467437326908112,
      "learning_rate": 9.153326080198945e-06,
      "loss": 0.044,
      "step": 2179
    },
    {
      "epoch": 0.1694124961143923,
      "grad_norm": 0.3308868110179901,
      "learning_rate": 9.152937519428038e-06,
      "loss": 0.1134,
      "step": 2180
    },
    {
      "epoch": 0.1694902082685732,
      "grad_norm": 0.028320252895355225,
      "learning_rate": 9.152548958657135e-06,
      "loss": 0.0085,
      "step": 2181
    },
    {
      "epoch": 0.16956792042275412,
      "grad_norm": 0.4949663579463959,
      "learning_rate": 9.15216039788623e-06,
      "loss": 0.2518,
      "step": 2182
    },
    {
      "epoch": 0.16964563257693505,
      "grad_norm": 0.05572154372930527,
      "learning_rate": 9.151771837115325e-06,
      "loss": 0.0194,
      "step": 2183
    },
    {
      "epoch": 0.16972334473111594,
      "grad_norm": 0.26260995864868164,
      "learning_rate": 9.151383276344421e-06,
      "loss": 0.2079,
      "step": 2184
    },
    {
      "epoch": 0.16980105688529687,
      "grad_norm": 0.10363183915615082,
      "learning_rate": 9.150994715573516e-06,
      "loss": 0.06,
      "step": 2185
    },
    {
      "epoch": 0.16987876903947777,
      "grad_norm": 0.06354954093694687,
      "learning_rate": 9.150606154802611e-06,
      "loss": 0.0225,
      "step": 2186
    },
    {
      "epoch": 0.1699564811936587,
      "grad_norm": 0.1969197392463684,
      "learning_rate": 9.150217594031708e-06,
      "loss": 0.067,
      "step": 2187
    },
    {
      "epoch": 0.1700341933478396,
      "grad_norm": 0.46757543087005615,
      "learning_rate": 9.149829033260803e-06,
      "loss": 0.1868,
      "step": 2188
    },
    {
      "epoch": 0.17011190550202052,
      "grad_norm": 0.0200987309217453,
      "learning_rate": 9.149440472489898e-06,
      "loss": 0.007,
      "step": 2189
    },
    {
      "epoch": 0.17018961765620144,
      "grad_norm": 0.25837442278862,
      "learning_rate": 9.149051911718993e-06,
      "loss": 0.16,
      "step": 2190
    },
    {
      "epoch": 0.17026732981038234,
      "grad_norm": 0.21052232384681702,
      "learning_rate": 9.14866335094809e-06,
      "loss": 0.0708,
      "step": 2191
    },
    {
      "epoch": 0.17034504196456327,
      "grad_norm": 0.26410624384880066,
      "learning_rate": 9.148274790177184e-06,
      "loss": 0.1417,
      "step": 2192
    },
    {
      "epoch": 0.17042275411874416,
      "grad_norm": 0.11522750556468964,
      "learning_rate": 9.14788622940628e-06,
      "loss": 0.0608,
      "step": 2193
    },
    {
      "epoch": 0.1705004662729251,
      "grad_norm": 0.5503128170967102,
      "learning_rate": 9.147497668635376e-06,
      "loss": 0.0274,
      "step": 2194
    },
    {
      "epoch": 0.170578178427106,
      "grad_norm": 0.5947709679603577,
      "learning_rate": 9.147109107864471e-06,
      "loss": 0.3303,
      "step": 2195
    },
    {
      "epoch": 0.1706558905812869,
      "grad_norm": 0.3494161069393158,
      "learning_rate": 9.146720547093566e-06,
      "loss": 0.4351,
      "step": 2196
    },
    {
      "epoch": 0.17073360273546784,
      "grad_norm": 0.3333740234375,
      "learning_rate": 9.146331986322663e-06,
      "loss": 0.2032,
      "step": 2197
    },
    {
      "epoch": 0.17081131488964874,
      "grad_norm": 0.11430224031209946,
      "learning_rate": 9.145943425551756e-06,
      "loss": 0.0681,
      "step": 2198
    },
    {
      "epoch": 0.17088902704382966,
      "grad_norm": 0.5528225898742676,
      "learning_rate": 9.145554864780852e-06,
      "loss": 0.3837,
      "step": 2199
    },
    {
      "epoch": 0.17096673919801056,
      "grad_norm": 0.3541259169578552,
      "learning_rate": 9.145166304009947e-06,
      "loss": 0.2393,
      "step": 2200
    },
    {
      "epoch": 0.17104445135219148,
      "grad_norm": 0.1698918491601944,
      "learning_rate": 9.144777743239044e-06,
      "loss": 0.1215,
      "step": 2201
    },
    {
      "epoch": 0.1711221635063724,
      "grad_norm": 0.2683921456336975,
      "learning_rate": 9.144389182468139e-06,
      "loss": 0.1755,
      "step": 2202
    },
    {
      "epoch": 0.1711998756605533,
      "grad_norm": 1.0132803916931152,
      "learning_rate": 9.144000621697234e-06,
      "loss": 0.5638,
      "step": 2203
    },
    {
      "epoch": 0.17127758781473423,
      "grad_norm": 0.3028094470500946,
      "learning_rate": 9.14361206092633e-06,
      "loss": 0.2469,
      "step": 2204
    },
    {
      "epoch": 0.17135529996891513,
      "grad_norm": 0.371734619140625,
      "learning_rate": 9.143223500155426e-06,
      "loss": 0.3554,
      "step": 2205
    },
    {
      "epoch": 0.17143301212309606,
      "grad_norm": 0.27744626998901367,
      "learning_rate": 9.14283493938452e-06,
      "loss": 0.1548,
      "step": 2206
    },
    {
      "epoch": 0.17151072427727695,
      "grad_norm": 0.09615319222211838,
      "learning_rate": 9.142446378613617e-06,
      "loss": 0.0222,
      "step": 2207
    },
    {
      "epoch": 0.17158843643145788,
      "grad_norm": 0.06330125778913498,
      "learning_rate": 9.14205781784271e-06,
      "loss": 0.0153,
      "step": 2208
    },
    {
      "epoch": 0.1716661485856388,
      "grad_norm": 0.1269942969083786,
      "learning_rate": 9.141669257071807e-06,
      "loss": 0.0737,
      "step": 2209
    },
    {
      "epoch": 0.1717438607398197,
      "grad_norm": 0.2441670149564743,
      "learning_rate": 9.141280696300902e-06,
      "loss": 0.2756,
      "step": 2210
    },
    {
      "epoch": 0.17182157289400063,
      "grad_norm": 0.49726349115371704,
      "learning_rate": 9.140892135529997e-06,
      "loss": 0.6073,
      "step": 2211
    },
    {
      "epoch": 0.17189928504818153,
      "grad_norm": 0.15295177698135376,
      "learning_rate": 9.140503574759094e-06,
      "loss": 0.1451,
      "step": 2212
    },
    {
      "epoch": 0.17197699720236245,
      "grad_norm": 0.27684685587882996,
      "learning_rate": 9.140115013988189e-06,
      "loss": 0.0945,
      "step": 2213
    },
    {
      "epoch": 0.17205470935654335,
      "grad_norm": 0.11646188795566559,
      "learning_rate": 9.139726453217283e-06,
      "loss": 0.0299,
      "step": 2214
    },
    {
      "epoch": 0.17213242151072428,
      "grad_norm": 0.046573713421821594,
      "learning_rate": 9.13933789244638e-06,
      "loss": 0.0073,
      "step": 2215
    },
    {
      "epoch": 0.1722101336649052,
      "grad_norm": 0.36955177783966064,
      "learning_rate": 9.138949331675475e-06,
      "loss": 0.395,
      "step": 2216
    },
    {
      "epoch": 0.1722878458190861,
      "grad_norm": 0.1554839015007019,
      "learning_rate": 9.13856077090457e-06,
      "loss": 0.0996,
      "step": 2217
    },
    {
      "epoch": 0.17236555797326703,
      "grad_norm": 0.2548341453075409,
      "learning_rate": 9.138172210133665e-06,
      "loss": 0.1247,
      "step": 2218
    },
    {
      "epoch": 0.17244327012744792,
      "grad_norm": 0.01109880581498146,
      "learning_rate": 9.137783649362762e-06,
      "loss": 0.0025,
      "step": 2219
    },
    {
      "epoch": 0.17252098228162885,
      "grad_norm": 0.3082600235939026,
      "learning_rate": 9.137395088591857e-06,
      "loss": 0.3313,
      "step": 2220
    },
    {
      "epoch": 0.17259869443580977,
      "grad_norm": 0.18253514170646667,
      "learning_rate": 9.137006527820952e-06,
      "loss": 0.1395,
      "step": 2221
    },
    {
      "epoch": 0.17267640658999067,
      "grad_norm": 0.5458884835243225,
      "learning_rate": 9.136617967050048e-06,
      "loss": 0.3895,
      "step": 2222
    },
    {
      "epoch": 0.1727541187441716,
      "grad_norm": 0.18139231204986572,
      "learning_rate": 9.136229406279143e-06,
      "loss": 0.1684,
      "step": 2223
    },
    {
      "epoch": 0.1728318308983525,
      "grad_norm": 0.4318847358226776,
      "learning_rate": 9.135840845508238e-06,
      "loss": 0.6081,
      "step": 2224
    },
    {
      "epoch": 0.17290954305253342,
      "grad_norm": 0.5069816708564758,
      "learning_rate": 9.135452284737335e-06,
      "loss": 0.1551,
      "step": 2225
    },
    {
      "epoch": 0.17298725520671432,
      "grad_norm": 0.5608392357826233,
      "learning_rate": 9.135063723966428e-06,
      "loss": 0.2242,
      "step": 2226
    },
    {
      "epoch": 0.17306496736089524,
      "grad_norm": 0.38174551725387573,
      "learning_rate": 9.134675163195525e-06,
      "loss": 0.2648,
      "step": 2227
    },
    {
      "epoch": 0.17314267951507617,
      "grad_norm": 0.5178457498550415,
      "learning_rate": 9.13428660242462e-06,
      "loss": 0.4468,
      "step": 2228
    },
    {
      "epoch": 0.17322039166925707,
      "grad_norm": 0.49089524149894714,
      "learning_rate": 9.133898041653715e-06,
      "loss": 0.1847,
      "step": 2229
    },
    {
      "epoch": 0.173298103823438,
      "grad_norm": 0.33127638697624207,
      "learning_rate": 9.133509480882811e-06,
      "loss": 0.1291,
      "step": 2230
    },
    {
      "epoch": 0.1733758159776189,
      "grad_norm": 0.28018322587013245,
      "learning_rate": 9.133120920111906e-06,
      "loss": 0.1926,
      "step": 2231
    },
    {
      "epoch": 0.17345352813179982,
      "grad_norm": 0.7920942306518555,
      "learning_rate": 9.132732359341003e-06,
      "loss": 0.6738,
      "step": 2232
    },
    {
      "epoch": 0.17353124028598071,
      "grad_norm": 0.13648061454296112,
      "learning_rate": 9.132343798570098e-06,
      "loss": 0.0655,
      "step": 2233
    },
    {
      "epoch": 0.17360895244016164,
      "grad_norm": 0.2793799340724945,
      "learning_rate": 9.131955237799193e-06,
      "loss": 0.1324,
      "step": 2234
    },
    {
      "epoch": 0.17368666459434257,
      "grad_norm": 0.22008070349693298,
      "learning_rate": 9.13156667702829e-06,
      "loss": 0.4743,
      "step": 2235
    },
    {
      "epoch": 0.17376437674852346,
      "grad_norm": 0.32096755504608154,
      "learning_rate": 9.131178116257383e-06,
      "loss": 0.2159,
      "step": 2236
    },
    {
      "epoch": 0.1738420889027044,
      "grad_norm": 0.4245055317878723,
      "learning_rate": 9.13078955548648e-06,
      "loss": 0.2508,
      "step": 2237
    },
    {
      "epoch": 0.1739198010568853,
      "grad_norm": 0.2089424580335617,
      "learning_rate": 9.130400994715574e-06,
      "loss": 0.1116,
      "step": 2238
    },
    {
      "epoch": 0.1739975132110662,
      "grad_norm": 0.5910006165504456,
      "learning_rate": 9.130012433944669e-06,
      "loss": 0.8481,
      "step": 2239
    },
    {
      "epoch": 0.17407522536524714,
      "grad_norm": 1.6712875366210938,
      "learning_rate": 9.129623873173766e-06,
      "loss": 0.5965,
      "step": 2240
    },
    {
      "epoch": 0.17415293751942804,
      "grad_norm": 0.42100265622138977,
      "learning_rate": 9.12923531240286e-06,
      "loss": 0.2117,
      "step": 2241
    },
    {
      "epoch": 0.17423064967360896,
      "grad_norm": 0.40080899000167847,
      "learning_rate": 9.128846751631956e-06,
      "loss": 0.3779,
      "step": 2242
    },
    {
      "epoch": 0.17430836182778986,
      "grad_norm": 0.14875173568725586,
      "learning_rate": 9.128458190861052e-06,
      "loss": 0.0768,
      "step": 2243
    },
    {
      "epoch": 0.17438607398197079,
      "grad_norm": 0.16437885165214539,
      "learning_rate": 9.128069630090147e-06,
      "loss": 0.1062,
      "step": 2244
    },
    {
      "epoch": 0.17446378613615168,
      "grad_norm": 0.2951497733592987,
      "learning_rate": 9.127681069319242e-06,
      "loss": 0.1396,
      "step": 2245
    },
    {
      "epoch": 0.1745414982903326,
      "grad_norm": 0.5031413435935974,
      "learning_rate": 9.127292508548337e-06,
      "loss": 0.4909,
      "step": 2246
    },
    {
      "epoch": 0.17461921044451353,
      "grad_norm": 0.5169416069984436,
      "learning_rate": 9.126903947777434e-06,
      "loss": 0.1646,
      "step": 2247
    },
    {
      "epoch": 0.17469692259869443,
      "grad_norm": 0.2885388731956482,
      "learning_rate": 9.126515387006529e-06,
      "loss": 0.2049,
      "step": 2248
    },
    {
      "epoch": 0.17477463475287536,
      "grad_norm": 0.15909335017204285,
      "learning_rate": 9.126126826235624e-06,
      "loss": 0.0889,
      "step": 2249
    },
    {
      "epoch": 0.17485234690705626,
      "grad_norm": 0.19102679193019867,
      "learning_rate": 9.12573826546472e-06,
      "loss": 0.0337,
      "step": 2250
    },
    {
      "epoch": 0.17493005906123718,
      "grad_norm": 0.25721949338912964,
      "learning_rate": 9.125349704693815e-06,
      "loss": 0.3864,
      "step": 2251
    },
    {
      "epoch": 0.17500777121541808,
      "grad_norm": 0.19343441724777222,
      "learning_rate": 9.12496114392291e-06,
      "loss": 0.0822,
      "step": 2252
    },
    {
      "epoch": 0.175085483369599,
      "grad_norm": 0.2605023682117462,
      "learning_rate": 9.124572583152005e-06,
      "loss": 0.2209,
      "step": 2253
    },
    {
      "epoch": 0.17516319552377993,
      "grad_norm": 0.18918417394161224,
      "learning_rate": 9.1241840223811e-06,
      "loss": 0.0399,
      "step": 2254
    },
    {
      "epoch": 0.17524090767796083,
      "grad_norm": 0.3977770209312439,
      "learning_rate": 9.123795461610197e-06,
      "loss": 0.3077,
      "step": 2255
    },
    {
      "epoch": 0.17531861983214175,
      "grad_norm": 0.2739497423171997,
      "learning_rate": 9.123406900839292e-06,
      "loss": 0.2903,
      "step": 2256
    },
    {
      "epoch": 0.17539633198632265,
      "grad_norm": 0.190940722823143,
      "learning_rate": 9.123018340068387e-06,
      "loss": 0.0948,
      "step": 2257
    },
    {
      "epoch": 0.17547404414050358,
      "grad_norm": 0.1434788703918457,
      "learning_rate": 9.122629779297483e-06,
      "loss": 0.0885,
      "step": 2258
    },
    {
      "epoch": 0.1755517562946845,
      "grad_norm": 0.3639478087425232,
      "learning_rate": 9.122241218526578e-06,
      "loss": 0.2892,
      "step": 2259
    },
    {
      "epoch": 0.1756294684488654,
      "grad_norm": 0.329010933637619,
      "learning_rate": 9.121852657755673e-06,
      "loss": 0.3022,
      "step": 2260
    },
    {
      "epoch": 0.17570718060304633,
      "grad_norm": 0.3108985126018524,
      "learning_rate": 9.121464096984768e-06,
      "loss": 0.0644,
      "step": 2261
    },
    {
      "epoch": 0.17578489275722722,
      "grad_norm": 0.47841233015060425,
      "learning_rate": 9.121075536213865e-06,
      "loss": 0.6586,
      "step": 2262
    },
    {
      "epoch": 0.17586260491140815,
      "grad_norm": 0.7790050506591797,
      "learning_rate": 9.12068697544296e-06,
      "loss": 0.7392,
      "step": 2263
    },
    {
      "epoch": 0.17594031706558905,
      "grad_norm": 0.49532899260520935,
      "learning_rate": 9.120298414672055e-06,
      "loss": 0.3015,
      "step": 2264
    },
    {
      "epoch": 0.17601802921976997,
      "grad_norm": 0.3611931800842285,
      "learning_rate": 9.119909853901151e-06,
      "loss": 0.2903,
      "step": 2265
    },
    {
      "epoch": 0.1760957413739509,
      "grad_norm": 0.3913131356239319,
      "learning_rate": 9.119521293130246e-06,
      "loss": 0.5012,
      "step": 2266
    },
    {
      "epoch": 0.1761734535281318,
      "grad_norm": 0.2527029812335968,
      "learning_rate": 9.119132732359341e-06,
      "loss": 0.0549,
      "step": 2267
    },
    {
      "epoch": 0.17625116568231272,
      "grad_norm": 0.6410201191902161,
      "learning_rate": 9.118744171588438e-06,
      "loss": 0.5965,
      "step": 2268
    },
    {
      "epoch": 0.17632887783649362,
      "grad_norm": 0.35669997334480286,
      "learning_rate": 9.118355610817533e-06,
      "loss": 0.2308,
      "step": 2269
    },
    {
      "epoch": 0.17640658999067454,
      "grad_norm": 0.5612279772758484,
      "learning_rate": 9.117967050046628e-06,
      "loss": 0.1712,
      "step": 2270
    },
    {
      "epoch": 0.17648430214485544,
      "grad_norm": 0.8884523510932922,
      "learning_rate": 9.117578489275723e-06,
      "loss": 0.5135,
      "step": 2271
    },
    {
      "epoch": 0.17656201429903637,
      "grad_norm": 0.34070420265197754,
      "learning_rate": 9.11718992850482e-06,
      "loss": 0.1123,
      "step": 2272
    },
    {
      "epoch": 0.1766397264532173,
      "grad_norm": 0.2476096898317337,
      "learning_rate": 9.116801367733914e-06,
      "loss": 0.0807,
      "step": 2273
    },
    {
      "epoch": 0.1767174386073982,
      "grad_norm": 0.43137678503990173,
      "learning_rate": 9.11641280696301e-06,
      "loss": 0.4828,
      "step": 2274
    },
    {
      "epoch": 0.17679515076157912,
      "grad_norm": 0.14925815165042877,
      "learning_rate": 9.116024246192106e-06,
      "loss": 0.07,
      "step": 2275
    },
    {
      "epoch": 0.17687286291576002,
      "grad_norm": 0.12735486030578613,
      "learning_rate": 9.115635685421201e-06,
      "loss": 0.1033,
      "step": 2276
    },
    {
      "epoch": 0.17695057506994094,
      "grad_norm": 0.5940515398979187,
      "learning_rate": 9.115247124650296e-06,
      "loss": 0.4564,
      "step": 2277
    },
    {
      "epoch": 0.17702828722412187,
      "grad_norm": 0.2894716262817383,
      "learning_rate": 9.114858563879392e-06,
      "loss": 0.2965,
      "step": 2278
    },
    {
      "epoch": 0.17710599937830276,
      "grad_norm": 0.24491827189922333,
      "learning_rate": 9.114470003108486e-06,
      "loss": 0.2309,
      "step": 2279
    },
    {
      "epoch": 0.1771837115324837,
      "grad_norm": 0.24643203616142273,
      "learning_rate": 9.114081442337582e-06,
      "loss": 0.136,
      "step": 2280
    },
    {
      "epoch": 0.1772614236866646,
      "grad_norm": 0.16031745076179504,
      "learning_rate": 9.113692881566677e-06,
      "loss": 0.0432,
      "step": 2281
    },
    {
      "epoch": 0.1773391358408455,
      "grad_norm": 0.25851377844810486,
      "learning_rate": 9.113304320795772e-06,
      "loss": 0.1386,
      "step": 2282
    },
    {
      "epoch": 0.1774168479950264,
      "grad_norm": 0.3859090209007263,
      "learning_rate": 9.112915760024869e-06,
      "loss": 0.2666,
      "step": 2283
    },
    {
      "epoch": 0.17749456014920734,
      "grad_norm": 0.17880885303020477,
      "learning_rate": 9.112527199253964e-06,
      "loss": 0.1372,
      "step": 2284
    },
    {
      "epoch": 0.17757227230338826,
      "grad_norm": 0.5028280019760132,
      "learning_rate": 9.112138638483059e-06,
      "loss": 0.0884,
      "step": 2285
    },
    {
      "epoch": 0.17764998445756916,
      "grad_norm": 0.17923565208911896,
      "learning_rate": 9.111750077712155e-06,
      "loss": 0.0375,
      "step": 2286
    },
    {
      "epoch": 0.17772769661175009,
      "grad_norm": 0.1648786962032318,
      "learning_rate": 9.11136151694125e-06,
      "loss": 0.1033,
      "step": 2287
    },
    {
      "epoch": 0.17780540876593098,
      "grad_norm": 0.19658160209655762,
      "learning_rate": 9.110972956170345e-06,
      "loss": 0.1963,
      "step": 2288
    },
    {
      "epoch": 0.1778831209201119,
      "grad_norm": 0.31374675035476685,
      "learning_rate": 9.11058439539944e-06,
      "loss": 0.1619,
      "step": 2289
    },
    {
      "epoch": 0.1779608330742928,
      "grad_norm": 0.7022225260734558,
      "learning_rate": 9.110195834628537e-06,
      "loss": 0.4314,
      "step": 2290
    },
    {
      "epoch": 0.17803854522847373,
      "grad_norm": 0.26653167605400085,
      "learning_rate": 9.109807273857632e-06,
      "loss": 0.1611,
      "step": 2291
    },
    {
      "epoch": 0.17811625738265466,
      "grad_norm": 0.2507268190383911,
      "learning_rate": 9.109418713086727e-06,
      "loss": 0.238,
      "step": 2292
    },
    {
      "epoch": 0.17819396953683556,
      "grad_norm": 0.16832716763019562,
      "learning_rate": 9.109030152315823e-06,
      "loss": 0.1481,
      "step": 2293
    },
    {
      "epoch": 0.17827168169101648,
      "grad_norm": 0.2620834410190582,
      "learning_rate": 9.108641591544918e-06,
      "loss": 0.1211,
      "step": 2294
    },
    {
      "epoch": 0.17834939384519738,
      "grad_norm": 0.2611194849014282,
      "learning_rate": 9.108253030774013e-06,
      "loss": 0.2359,
      "step": 2295
    },
    {
      "epoch": 0.1784271059993783,
      "grad_norm": 0.1570557802915573,
      "learning_rate": 9.10786447000311e-06,
      "loss": 0.0247,
      "step": 2296
    },
    {
      "epoch": 0.17850481815355923,
      "grad_norm": 0.21491780877113342,
      "learning_rate": 9.107475909232205e-06,
      "loss": 0.0913,
      "step": 2297
    },
    {
      "epoch": 0.17858253030774013,
      "grad_norm": 0.1133187860250473,
      "learning_rate": 9.1070873484613e-06,
      "loss": 0.0311,
      "step": 2298
    },
    {
      "epoch": 0.17866024246192105,
      "grad_norm": 0.19716453552246094,
      "learning_rate": 9.106698787690395e-06,
      "loss": 0.1467,
      "step": 2299
    },
    {
      "epoch": 0.17873795461610195,
      "grad_norm": 0.1905510276556015,
      "learning_rate": 9.106310226919492e-06,
      "loss": 0.0433,
      "step": 2300
    },
    {
      "epoch": 0.17881566677028288,
      "grad_norm": 0.11926055699586868,
      "learning_rate": 9.105921666148586e-06,
      "loss": 0.0593,
      "step": 2301
    },
    {
      "epoch": 0.17889337892446378,
      "grad_norm": 0.23415406048297882,
      "learning_rate": 9.105533105377681e-06,
      "loss": 0.137,
      "step": 2302
    },
    {
      "epoch": 0.1789710910786447,
      "grad_norm": 0.1112125813961029,
      "learning_rate": 9.105144544606778e-06,
      "loss": 0.0576,
      "step": 2303
    },
    {
      "epoch": 0.17904880323282563,
      "grad_norm": 0.3196139335632324,
      "learning_rate": 9.104755983835873e-06,
      "loss": 0.153,
      "step": 2304
    },
    {
      "epoch": 0.17912651538700652,
      "grad_norm": 0.15191340446472168,
      "learning_rate": 9.104367423064968e-06,
      "loss": 0.1648,
      "step": 2305
    },
    {
      "epoch": 0.17920422754118745,
      "grad_norm": 0.3659508526325226,
      "learning_rate": 9.103978862294065e-06,
      "loss": 0.2617,
      "step": 2306
    },
    {
      "epoch": 0.17928193969536835,
      "grad_norm": 0.664922297000885,
      "learning_rate": 9.103590301523158e-06,
      "loss": 0.4399,
      "step": 2307
    },
    {
      "epoch": 0.17935965184954927,
      "grad_norm": 0.17362773418426514,
      "learning_rate": 9.103201740752255e-06,
      "loss": 0.0838,
      "step": 2308
    },
    {
      "epoch": 0.17943736400373017,
      "grad_norm": 0.2559375762939453,
      "learning_rate": 9.10281317998135e-06,
      "loss": 0.1606,
      "step": 2309
    },
    {
      "epoch": 0.1795150761579111,
      "grad_norm": 0.36497363448143005,
      "learning_rate": 9.102424619210444e-06,
      "loss": 0.118,
      "step": 2310
    },
    {
      "epoch": 0.17959278831209202,
      "grad_norm": 0.2061082273721695,
      "learning_rate": 9.102036058439541e-06,
      "loss": 0.0614,
      "step": 2311
    },
    {
      "epoch": 0.17967050046627292,
      "grad_norm": 0.15268167853355408,
      "learning_rate": 9.101647497668636e-06,
      "loss": 0.0711,
      "step": 2312
    },
    {
      "epoch": 0.17974821262045385,
      "grad_norm": 0.43854400515556335,
      "learning_rate": 9.101258936897731e-06,
      "loss": 0.3485,
      "step": 2313
    },
    {
      "epoch": 0.17982592477463474,
      "grad_norm": 0.257088303565979,
      "learning_rate": 9.100870376126828e-06,
      "loss": 0.1019,
      "step": 2314
    },
    {
      "epoch": 0.17990363692881567,
      "grad_norm": 0.42953696846961975,
      "learning_rate": 9.100481815355923e-06,
      "loss": 0.1987,
      "step": 2315
    },
    {
      "epoch": 0.1799813490829966,
      "grad_norm": 0.2339387834072113,
      "learning_rate": 9.100093254585017e-06,
      "loss": 0.0831,
      "step": 2316
    },
    {
      "epoch": 0.1800590612371775,
      "grad_norm": 0.3517804741859436,
      "learning_rate": 9.099704693814112e-06,
      "loss": 0.2135,
      "step": 2317
    },
    {
      "epoch": 0.18013677339135842,
      "grad_norm": 0.0952114537358284,
      "learning_rate": 9.099316133043209e-06,
      "loss": 0.0381,
      "step": 2318
    },
    {
      "epoch": 0.18021448554553932,
      "grad_norm": 0.05613226816058159,
      "learning_rate": 9.098927572272304e-06,
      "loss": 0.0478,
      "step": 2319
    },
    {
      "epoch": 0.18029219769972024,
      "grad_norm": 0.4110759198665619,
      "learning_rate": 9.098539011501399e-06,
      "loss": 0.111,
      "step": 2320
    },
    {
      "epoch": 0.18036990985390114,
      "grad_norm": 0.31642019748687744,
      "learning_rate": 9.098150450730496e-06,
      "loss": 0.235,
      "step": 2321
    },
    {
      "epoch": 0.18044762200808206,
      "grad_norm": 0.08929003775119781,
      "learning_rate": 9.09776188995959e-06,
      "loss": 0.0228,
      "step": 2322
    },
    {
      "epoch": 0.180525334162263,
      "grad_norm": 0.3559039831161499,
      "learning_rate": 9.097373329188686e-06,
      "loss": 0.6148,
      "step": 2323
    },
    {
      "epoch": 0.1806030463164439,
      "grad_norm": 0.5992337465286255,
      "learning_rate": 9.096984768417782e-06,
      "loss": 0.1381,
      "step": 2324
    },
    {
      "epoch": 0.1806807584706248,
      "grad_norm": 0.5789361596107483,
      "learning_rate": 9.096596207646877e-06,
      "loss": 0.7783,
      "step": 2325
    },
    {
      "epoch": 0.1807584706248057,
      "grad_norm": 0.4133303165435791,
      "learning_rate": 9.096207646875972e-06,
      "loss": 0.2669,
      "step": 2326
    },
    {
      "epoch": 0.18083618277898664,
      "grad_norm": 0.26585280895233154,
      "learning_rate": 9.095819086105067e-06,
      "loss": 0.1555,
      "step": 2327
    },
    {
      "epoch": 0.18091389493316754,
      "grad_norm": 0.4739589989185333,
      "learning_rate": 9.095430525334164e-06,
      "loss": 0.3162,
      "step": 2328
    },
    {
      "epoch": 0.18099160708734846,
      "grad_norm": 0.1681641787290573,
      "learning_rate": 9.095041964563259e-06,
      "loss": 0.0761,
      "step": 2329
    },
    {
      "epoch": 0.1810693192415294,
      "grad_norm": 0.20584701001644135,
      "learning_rate": 9.094653403792354e-06,
      "loss": 0.0879,
      "step": 2330
    },
    {
      "epoch": 0.18114703139571028,
      "grad_norm": 0.4494481086730957,
      "learning_rate": 9.09426484302145e-06,
      "loss": 0.2145,
      "step": 2331
    },
    {
      "epoch": 0.1812247435498912,
      "grad_norm": 0.13987362384796143,
      "learning_rate": 9.093876282250545e-06,
      "loss": 0.0499,
      "step": 2332
    },
    {
      "epoch": 0.1813024557040721,
      "grad_norm": 0.16285105049610138,
      "learning_rate": 9.09348772147964e-06,
      "loss": 0.1069,
      "step": 2333
    },
    {
      "epoch": 0.18138016785825303,
      "grad_norm": 0.17851288616657257,
      "learning_rate": 9.093099160708737e-06,
      "loss": 0.0533,
      "step": 2334
    },
    {
      "epoch": 0.18145788001243393,
      "grad_norm": 0.714428722858429,
      "learning_rate": 9.09271059993783e-06,
      "loss": 0.4338,
      "step": 2335
    },
    {
      "epoch": 0.18153559216661486,
      "grad_norm": 0.17878134548664093,
      "learning_rate": 9.092322039166927e-06,
      "loss": 0.059,
      "step": 2336
    },
    {
      "epoch": 0.18161330432079578,
      "grad_norm": 0.3466661274433136,
      "learning_rate": 9.091933478396022e-06,
      "loss": 0.2494,
      "step": 2337
    },
    {
      "epoch": 0.18169101647497668,
      "grad_norm": 0.18234646320343018,
      "learning_rate": 9.091544917625117e-06,
      "loss": 0.0532,
      "step": 2338
    },
    {
      "epoch": 0.1817687286291576,
      "grad_norm": 0.13047213852405548,
      "learning_rate": 9.091156356854213e-06,
      "loss": 0.095,
      "step": 2339
    },
    {
      "epoch": 0.1818464407833385,
      "grad_norm": 0.1492830365896225,
      "learning_rate": 9.090767796083308e-06,
      "loss": 0.0857,
      "step": 2340
    },
    {
      "epoch": 0.18192415293751943,
      "grad_norm": 0.23883101344108582,
      "learning_rate": 9.090379235312403e-06,
      "loss": 0.1216,
      "step": 2341
    },
    {
      "epoch": 0.18200186509170035,
      "grad_norm": 0.7075985074043274,
      "learning_rate": 9.0899906745415e-06,
      "loss": 0.5455,
      "step": 2342
    },
    {
      "epoch": 0.18207957724588125,
      "grad_norm": 0.10556741058826447,
      "learning_rate": 9.089602113770595e-06,
      "loss": 0.1042,
      "step": 2343
    },
    {
      "epoch": 0.18215728940006218,
      "grad_norm": 0.44074639678001404,
      "learning_rate": 9.08921355299969e-06,
      "loss": 0.3349,
      "step": 2344
    },
    {
      "epoch": 0.18223500155424308,
      "grad_norm": 0.08402089774608612,
      "learning_rate": 9.088824992228785e-06,
      "loss": 0.0296,
      "step": 2345
    },
    {
      "epoch": 0.182312713708424,
      "grad_norm": 0.04890216886997223,
      "learning_rate": 9.088436431457881e-06,
      "loss": 0.0111,
      "step": 2346
    },
    {
      "epoch": 0.1823904258626049,
      "grad_norm": 0.12164860963821411,
      "learning_rate": 9.088047870686976e-06,
      "loss": 0.0284,
      "step": 2347
    },
    {
      "epoch": 0.18246813801678582,
      "grad_norm": 0.034707602113485336,
      "learning_rate": 9.087659309916071e-06,
      "loss": 0.0126,
      "step": 2348
    },
    {
      "epoch": 0.18254585017096675,
      "grad_norm": 0.6437204480171204,
      "learning_rate": 9.087270749145168e-06,
      "loss": 0.1468,
      "step": 2349
    },
    {
      "epoch": 0.18262356232514765,
      "grad_norm": 0.26611170172691345,
      "learning_rate": 9.086882188374263e-06,
      "loss": 0.1543,
      "step": 2350
    },
    {
      "epoch": 0.18270127447932857,
      "grad_norm": 0.13753481209278107,
      "learning_rate": 9.086493627603358e-06,
      "loss": 0.0907,
      "step": 2351
    },
    {
      "epoch": 0.18277898663350947,
      "grad_norm": 0.2858622372150421,
      "learning_rate": 9.086105066832454e-06,
      "loss": 0.1834,
      "step": 2352
    },
    {
      "epoch": 0.1828566987876904,
      "grad_norm": 0.2417210340499878,
      "learning_rate": 9.08571650606155e-06,
      "loss": 0.3431,
      "step": 2353
    },
    {
      "epoch": 0.1829344109418713,
      "grad_norm": 0.20241597294807434,
      "learning_rate": 9.085327945290644e-06,
      "loss": 0.0618,
      "step": 2354
    },
    {
      "epoch": 0.18301212309605222,
      "grad_norm": 0.3326801359653473,
      "learning_rate": 9.08493938451974e-06,
      "loss": 0.486,
      "step": 2355
    },
    {
      "epoch": 0.18308983525023315,
      "grad_norm": 0.368984192609787,
      "learning_rate": 9.084550823748836e-06,
      "loss": 0.1406,
      "step": 2356
    },
    {
      "epoch": 0.18316754740441404,
      "grad_norm": 0.5565983653068542,
      "learning_rate": 9.08416226297793e-06,
      "loss": 0.597,
      "step": 2357
    },
    {
      "epoch": 0.18324525955859497,
      "grad_norm": 0.16408437490463257,
      "learning_rate": 9.083773702207026e-06,
      "loss": 0.0364,
      "step": 2358
    },
    {
      "epoch": 0.18332297171277587,
      "grad_norm": 0.11145898699760437,
      "learning_rate": 9.083385141436122e-06,
      "loss": 0.0558,
      "step": 2359
    },
    {
      "epoch": 0.1834006838669568,
      "grad_norm": 0.08643808960914612,
      "learning_rate": 9.082996580665217e-06,
      "loss": 0.0301,
      "step": 2360
    },
    {
      "epoch": 0.18347839602113772,
      "grad_norm": 0.3105628490447998,
      "learning_rate": 9.082608019894312e-06,
      "loss": 0.1142,
      "step": 2361
    },
    {
      "epoch": 0.18355610817531862,
      "grad_norm": 0.31507211923599243,
      "learning_rate": 9.082219459123409e-06,
      "loss": 0.1661,
      "step": 2362
    },
    {
      "epoch": 0.18363382032949954,
      "grad_norm": 0.295580118894577,
      "learning_rate": 9.081830898352502e-06,
      "loss": 0.1522,
      "step": 2363
    },
    {
      "epoch": 0.18371153248368044,
      "grad_norm": 0.275128573179245,
      "learning_rate": 9.081442337581599e-06,
      "loss": 0.0396,
      "step": 2364
    },
    {
      "epoch": 0.18378924463786137,
      "grad_norm": 0.2924918532371521,
      "learning_rate": 9.081053776810694e-06,
      "loss": 0.1476,
      "step": 2365
    },
    {
      "epoch": 0.18386695679204226,
      "grad_norm": 0.3431544005870819,
      "learning_rate": 9.080665216039789e-06,
      "loss": 0.3717,
      "step": 2366
    },
    {
      "epoch": 0.1839446689462232,
      "grad_norm": 0.44061312079429626,
      "learning_rate": 9.080276655268885e-06,
      "loss": 0.1211,
      "step": 2367
    },
    {
      "epoch": 0.18402238110040411,
      "grad_norm": 0.3663148283958435,
      "learning_rate": 9.07988809449798e-06,
      "loss": 0.2931,
      "step": 2368
    },
    {
      "epoch": 0.184100093254585,
      "grad_norm": 0.21106992661952972,
      "learning_rate": 9.079499533727075e-06,
      "loss": 0.1052,
      "step": 2369
    },
    {
      "epoch": 0.18417780540876594,
      "grad_norm": 0.15587612986564636,
      "learning_rate": 9.079110972956172e-06,
      "loss": 0.0708,
      "step": 2370
    },
    {
      "epoch": 0.18425551756294684,
      "grad_norm": 0.16459473967552185,
      "learning_rate": 9.078722412185267e-06,
      "loss": 0.1498,
      "step": 2371
    },
    {
      "epoch": 0.18433322971712776,
      "grad_norm": 0.32154273986816406,
      "learning_rate": 9.078333851414362e-06,
      "loss": 0.1064,
      "step": 2372
    },
    {
      "epoch": 0.18441094187130866,
      "grad_norm": 0.573003888130188,
      "learning_rate": 9.077945290643457e-06,
      "loss": 0.3286,
      "step": 2373
    },
    {
      "epoch": 0.18448865402548958,
      "grad_norm": 0.12613379955291748,
      "learning_rate": 9.077556729872553e-06,
      "loss": 0.0536,
      "step": 2374
    },
    {
      "epoch": 0.1845663661796705,
      "grad_norm": 0.21075129508972168,
      "learning_rate": 9.077168169101648e-06,
      "loss": 0.1068,
      "step": 2375
    },
    {
      "epoch": 0.1846440783338514,
      "grad_norm": 0.1833825260400772,
      "learning_rate": 9.076779608330743e-06,
      "loss": 0.0826,
      "step": 2376
    },
    {
      "epoch": 0.18472179048803233,
      "grad_norm": 0.41171425580978394,
      "learning_rate": 9.07639104755984e-06,
      "loss": 0.3213,
      "step": 2377
    },
    {
      "epoch": 0.18479950264221323,
      "grad_norm": 0.195430725812912,
      "learning_rate": 9.076002486788933e-06,
      "loss": 0.1103,
      "step": 2378
    },
    {
      "epoch": 0.18487721479639416,
      "grad_norm": 2.4033305644989014,
      "learning_rate": 9.07561392601803e-06,
      "loss": 0.166,
      "step": 2379
    },
    {
      "epoch": 0.18495492695057508,
      "grad_norm": 0.5269885659217834,
      "learning_rate": 9.075225365247125e-06,
      "loss": 0.5013,
      "step": 2380
    },
    {
      "epoch": 0.18503263910475598,
      "grad_norm": 0.43805477023124695,
      "learning_rate": 9.07483680447622e-06,
      "loss": 0.2558,
      "step": 2381
    },
    {
      "epoch": 0.1851103512589369,
      "grad_norm": 0.2508372664451599,
      "learning_rate": 9.074448243705316e-06,
      "loss": 0.1811,
      "step": 2382
    },
    {
      "epoch": 0.1851880634131178,
      "grad_norm": 0.5227019190788269,
      "learning_rate": 9.074059682934411e-06,
      "loss": 0.3919,
      "step": 2383
    },
    {
      "epoch": 0.18526577556729873,
      "grad_norm": 0.1853630691766739,
      "learning_rate": 9.073671122163508e-06,
      "loss": 0.0696,
      "step": 2384
    },
    {
      "epoch": 0.18534348772147963,
      "grad_norm": 0.2760547995567322,
      "learning_rate": 9.073282561392603e-06,
      "loss": 0.1967,
      "step": 2385
    },
    {
      "epoch": 0.18542119987566055,
      "grad_norm": 0.2918325960636139,
      "learning_rate": 9.072894000621698e-06,
      "loss": 0.3438,
      "step": 2386
    },
    {
      "epoch": 0.18549891202984148,
      "grad_norm": 0.28922751545906067,
      "learning_rate": 9.072505439850795e-06,
      "loss": 0.2995,
      "step": 2387
    },
    {
      "epoch": 0.18557662418402238,
      "grad_norm": 0.19373327493667603,
      "learning_rate": 9.072116879079888e-06,
      "loss": 0.055,
      "step": 2388
    },
    {
      "epoch": 0.1856543363382033,
      "grad_norm": 0.21159198880195618,
      "learning_rate": 9.071728318308984e-06,
      "loss": 0.0837,
      "step": 2389
    },
    {
      "epoch": 0.1857320484923842,
      "grad_norm": 0.15338295698165894,
      "learning_rate": 9.07133975753808e-06,
      "loss": 0.0485,
      "step": 2390
    },
    {
      "epoch": 0.18580976064656513,
      "grad_norm": 0.34193551540374756,
      "learning_rate": 9.070951196767174e-06,
      "loss": 0.5444,
      "step": 2391
    },
    {
      "epoch": 0.18588747280074602,
      "grad_norm": 0.5387575030326843,
      "learning_rate": 9.070562635996271e-06,
      "loss": 0.1824,
      "step": 2392
    },
    {
      "epoch": 0.18596518495492695,
      "grad_norm": 0.43604445457458496,
      "learning_rate": 9.070174075225366e-06,
      "loss": 0.1236,
      "step": 2393
    },
    {
      "epoch": 0.18604289710910787,
      "grad_norm": 0.2732410728931427,
      "learning_rate": 9.069785514454461e-06,
      "loss": 0.1192,
      "step": 2394
    },
    {
      "epoch": 0.18612060926328877,
      "grad_norm": 0.3242870569229126,
      "learning_rate": 9.069396953683557e-06,
      "loss": 0.169,
      "step": 2395
    },
    {
      "epoch": 0.1861983214174697,
      "grad_norm": 0.13703644275665283,
      "learning_rate": 9.069008392912652e-06,
      "loss": 0.0196,
      "step": 2396
    },
    {
      "epoch": 0.1862760335716506,
      "grad_norm": 0.20858623087406158,
      "learning_rate": 9.068619832141747e-06,
      "loss": 0.114,
      "step": 2397
    },
    {
      "epoch": 0.18635374572583152,
      "grad_norm": 0.4790242910385132,
      "learning_rate": 9.068231271370842e-06,
      "loss": 0.231,
      "step": 2398
    },
    {
      "epoch": 0.18643145788001245,
      "grad_norm": 0.5611975193023682,
      "learning_rate": 9.067842710599939e-06,
      "loss": 0.441,
      "step": 2399
    },
    {
      "epoch": 0.18650917003419334,
      "grad_norm": 0.015309872105717659,
      "learning_rate": 9.067454149829034e-06,
      "loss": 0.0065,
      "step": 2400
    },
    {
      "epoch": 0.18658688218837427,
      "grad_norm": 0.029690418392419815,
      "learning_rate": 9.067065589058129e-06,
      "loss": 0.0184,
      "step": 2401
    },
    {
      "epoch": 0.18666459434255517,
      "grad_norm": 0.1468675434589386,
      "learning_rate": 9.066677028287226e-06,
      "loss": 0.0323,
      "step": 2402
    },
    {
      "epoch": 0.1867423064967361,
      "grad_norm": 0.15700314939022064,
      "learning_rate": 9.06628846751632e-06,
      "loss": 0.0765,
      "step": 2403
    },
    {
      "epoch": 0.186820018650917,
      "grad_norm": 0.14839127659797668,
      "learning_rate": 9.065899906745415e-06,
      "loss": 0.1122,
      "step": 2404
    },
    {
      "epoch": 0.18689773080509792,
      "grad_norm": 0.3367871046066284,
      "learning_rate": 9.065511345974512e-06,
      "loss": 0.5615,
      "step": 2405
    },
    {
      "epoch": 0.18697544295927884,
      "grad_norm": 0.7388120889663696,
      "learning_rate": 9.065122785203605e-06,
      "loss": 0.2514,
      "step": 2406
    },
    {
      "epoch": 0.18705315511345974,
      "grad_norm": 0.32701894640922546,
      "learning_rate": 9.064734224432702e-06,
      "loss": 0.1244,
      "step": 2407
    },
    {
      "epoch": 0.18713086726764067,
      "grad_norm": 0.14967067539691925,
      "learning_rate": 9.064345663661797e-06,
      "loss": 0.0846,
      "step": 2408
    },
    {
      "epoch": 0.18720857942182156,
      "grad_norm": 0.05486588180065155,
      "learning_rate": 9.063957102890892e-06,
      "loss": 0.0324,
      "step": 2409
    },
    {
      "epoch": 0.1872862915760025,
      "grad_norm": 0.6391128897666931,
      "learning_rate": 9.063568542119989e-06,
      "loss": 0.8975,
      "step": 2410
    },
    {
      "epoch": 0.1873640037301834,
      "grad_norm": 0.7584705948829651,
      "learning_rate": 9.063179981349083e-06,
      "loss": 0.8239,
      "step": 2411
    },
    {
      "epoch": 0.1874417158843643,
      "grad_norm": 0.5752057433128357,
      "learning_rate": 9.062791420578178e-06,
      "loss": 0.0538,
      "step": 2412
    },
    {
      "epoch": 0.18751942803854524,
      "grad_norm": 0.1166321188211441,
      "learning_rate": 9.062402859807275e-06,
      "loss": 0.0764,
      "step": 2413
    },
    {
      "epoch": 0.18759714019272614,
      "grad_norm": 0.3374147415161133,
      "learning_rate": 9.06201429903637e-06,
      "loss": 0.2948,
      "step": 2414
    },
    {
      "epoch": 0.18767485234690706,
      "grad_norm": 0.3471263349056244,
      "learning_rate": 9.061625738265467e-06,
      "loss": 0.2684,
      "step": 2415
    },
    {
      "epoch": 0.18775256450108796,
      "grad_norm": 0.13160909712314606,
      "learning_rate": 9.06123717749456e-06,
      "loss": 0.0434,
      "step": 2416
    },
    {
      "epoch": 0.18783027665526889,
      "grad_norm": 0.24469421803951263,
      "learning_rate": 9.060848616723657e-06,
      "loss": 0.1119,
      "step": 2417
    },
    {
      "epoch": 0.1879079888094498,
      "grad_norm": 0.5690969824790955,
      "learning_rate": 9.060460055952752e-06,
      "loss": 0.2378,
      "step": 2418
    },
    {
      "epoch": 0.1879857009636307,
      "grad_norm": 0.3929186165332794,
      "learning_rate": 9.060071495181846e-06,
      "loss": 0.2558,
      "step": 2419
    },
    {
      "epoch": 0.18806341311781163,
      "grad_norm": 0.3580375015735626,
      "learning_rate": 9.059682934410943e-06,
      "loss": 0.2998,
      "step": 2420
    },
    {
      "epoch": 0.18814112527199253,
      "grad_norm": 0.6829167604446411,
      "learning_rate": 9.059294373640038e-06,
      "loss": 0.2743,
      "step": 2421
    },
    {
      "epoch": 0.18821883742617346,
      "grad_norm": 0.14861300587654114,
      "learning_rate": 9.058905812869133e-06,
      "loss": 0.0517,
      "step": 2422
    },
    {
      "epoch": 0.18829654958035436,
      "grad_norm": 0.34302273392677307,
      "learning_rate": 9.05851725209823e-06,
      "loss": 0.779,
      "step": 2423
    },
    {
      "epoch": 0.18837426173453528,
      "grad_norm": 0.04349001869559288,
      "learning_rate": 9.058128691327325e-06,
      "loss": 0.0334,
      "step": 2424
    },
    {
      "epoch": 0.1884519738887162,
      "grad_norm": 0.4244973659515381,
      "learning_rate": 9.05774013055642e-06,
      "loss": 0.0685,
      "step": 2425
    },
    {
      "epoch": 0.1885296860428971,
      "grad_norm": 0.05300835520029068,
      "learning_rate": 9.057351569785514e-06,
      "loss": 0.0189,
      "step": 2426
    },
    {
      "epoch": 0.18860739819707803,
      "grad_norm": 0.24238990247249603,
      "learning_rate": 9.056963009014611e-06,
      "loss": 0.1418,
      "step": 2427
    },
    {
      "epoch": 0.18868511035125893,
      "grad_norm": 0.2661239504814148,
      "learning_rate": 9.056574448243706e-06,
      "loss": 0.1391,
      "step": 2428
    },
    {
      "epoch": 0.18876282250543985,
      "grad_norm": 0.2416432499885559,
      "learning_rate": 9.056185887472801e-06,
      "loss": 0.1636,
      "step": 2429
    },
    {
      "epoch": 0.18884053465962075,
      "grad_norm": 0.3672143518924713,
      "learning_rate": 9.055797326701898e-06,
      "loss": 0.126,
      "step": 2430
    },
    {
      "epoch": 0.18891824681380168,
      "grad_norm": 0.4368913471698761,
      "learning_rate": 9.055408765930993e-06,
      "loss": 0.1898,
      "step": 2431
    },
    {
      "epoch": 0.1889959589679826,
      "grad_norm": 0.37852010130882263,
      "learning_rate": 9.055020205160088e-06,
      "loss": 0.649,
      "step": 2432
    },
    {
      "epoch": 0.1890736711221635,
      "grad_norm": 0.23340916633605957,
      "learning_rate": 9.054631644389184e-06,
      "loss": 0.1717,
      "step": 2433
    },
    {
      "epoch": 0.18915138327634443,
      "grad_norm": 0.43460771441459656,
      "learning_rate": 9.054243083618277e-06,
      "loss": 0.7394,
      "step": 2434
    },
    {
      "epoch": 0.18922909543052532,
      "grad_norm": 0.23955953121185303,
      "learning_rate": 9.053854522847374e-06,
      "loss": 0.1825,
      "step": 2435
    },
    {
      "epoch": 0.18930680758470625,
      "grad_norm": 0.19038406014442444,
      "learning_rate": 9.053465962076469e-06,
      "loss": 0.1043,
      "step": 2436
    },
    {
      "epoch": 0.18938451973888717,
      "grad_norm": 0.47958603501319885,
      "learning_rate": 9.053077401305564e-06,
      "loss": 0.6631,
      "step": 2437
    },
    {
      "epoch": 0.18946223189306807,
      "grad_norm": 0.49636808037757874,
      "learning_rate": 9.05268884053466e-06,
      "loss": 0.2267,
      "step": 2438
    },
    {
      "epoch": 0.189539944047249,
      "grad_norm": 0.881585955619812,
      "learning_rate": 9.052300279763756e-06,
      "loss": 0.8639,
      "step": 2439
    },
    {
      "epoch": 0.1896176562014299,
      "grad_norm": 0.45436182618141174,
      "learning_rate": 9.05191171899285e-06,
      "loss": 0.1909,
      "step": 2440
    },
    {
      "epoch": 0.18969536835561082,
      "grad_norm": 0.5020185112953186,
      "learning_rate": 9.051523158221947e-06,
      "loss": 0.3338,
      "step": 2441
    },
    {
      "epoch": 0.18977308050979172,
      "grad_norm": 0.14727447926998138,
      "learning_rate": 9.051134597451042e-06,
      "loss": 0.0377,
      "step": 2442
    },
    {
      "epoch": 0.18985079266397265,
      "grad_norm": 0.309489905834198,
      "learning_rate": 9.050746036680137e-06,
      "loss": 0.3619,
      "step": 2443
    },
    {
      "epoch": 0.18992850481815357,
      "grad_norm": 0.1758011430501938,
      "learning_rate": 9.050357475909232e-06,
      "loss": 0.1102,
      "step": 2444
    },
    {
      "epoch": 0.19000621697233447,
      "grad_norm": 0.4658845365047455,
      "learning_rate": 9.049968915138329e-06,
      "loss": 0.174,
      "step": 2445
    },
    {
      "epoch": 0.1900839291265154,
      "grad_norm": 0.1856066733598709,
      "learning_rate": 9.049580354367424e-06,
      "loss": 0.021,
      "step": 2446
    },
    {
      "epoch": 0.1901616412806963,
      "grad_norm": 0.5522265434265137,
      "learning_rate": 9.049191793596519e-06,
      "loss": 0.4661,
      "step": 2447
    },
    {
      "epoch": 0.19023935343487722,
      "grad_norm": 0.5537559390068054,
      "learning_rate": 9.048803232825615e-06,
      "loss": 0.1857,
      "step": 2448
    },
    {
      "epoch": 0.19031706558905812,
      "grad_norm": 4.596399307250977,
      "learning_rate": 9.04841467205471e-06,
      "loss": 1.4512,
      "step": 2449
    },
    {
      "epoch": 0.19039477774323904,
      "grad_norm": 0.3513728380203247,
      "learning_rate": 9.048026111283805e-06,
      "loss": 0.295,
      "step": 2450
    },
    {
      "epoch": 0.19047248989741997,
      "grad_norm": 0.20726566016674042,
      "learning_rate": 9.047637550512902e-06,
      "loss": 0.0826,
      "step": 2451
    },
    {
      "epoch": 0.19055020205160086,
      "grad_norm": 0.3652939796447754,
      "learning_rate": 9.047248989741997e-06,
      "loss": 0.2485,
      "step": 2452
    },
    {
      "epoch": 0.1906279142057818,
      "grad_norm": 0.2564517855644226,
      "learning_rate": 9.046860428971092e-06,
      "loss": 0.187,
      "step": 2453
    },
    {
      "epoch": 0.1907056263599627,
      "grad_norm": 0.38285067677497864,
      "learning_rate": 9.046471868200187e-06,
      "loss": 0.1602,
      "step": 2454
    },
    {
      "epoch": 0.1907833385141436,
      "grad_norm": 0.23426130414009094,
      "learning_rate": 9.046083307429283e-06,
      "loss": 0.0797,
      "step": 2455
    },
    {
      "epoch": 0.19086105066832454,
      "grad_norm": 0.18483799695968628,
      "learning_rate": 9.045694746658378e-06,
      "loss": 0.0854,
      "step": 2456
    },
    {
      "epoch": 0.19093876282250544,
      "grad_norm": 0.41384488344192505,
      "learning_rate": 9.045306185887473e-06,
      "loss": 0.1342,
      "step": 2457
    },
    {
      "epoch": 0.19101647497668636,
      "grad_norm": 0.2071608603000641,
      "learning_rate": 9.04491762511657e-06,
      "loss": 0.0796,
      "step": 2458
    },
    {
      "epoch": 0.19109418713086726,
      "grad_norm": 0.2804660201072693,
      "learning_rate": 9.044529064345665e-06,
      "loss": 0.146,
      "step": 2459
    },
    {
      "epoch": 0.19117189928504819,
      "grad_norm": 0.20828206837177277,
      "learning_rate": 9.04414050357476e-06,
      "loss": 0.0755,
      "step": 2460
    },
    {
      "epoch": 0.19124961143922908,
      "grad_norm": 0.3147679567337036,
      "learning_rate": 9.043751942803856e-06,
      "loss": 0.1468,
      "step": 2461
    },
    {
      "epoch": 0.19132732359341,
      "grad_norm": 0.9122248291969299,
      "learning_rate": 9.04336338203295e-06,
      "loss": 0.3416,
      "step": 2462
    },
    {
      "epoch": 0.19140503574759093,
      "grad_norm": 0.3186103403568268,
      "learning_rate": 9.042974821262046e-06,
      "loss": 0.3145,
      "step": 2463
    },
    {
      "epoch": 0.19148274790177183,
      "grad_norm": 0.2701641321182251,
      "learning_rate": 9.042586260491141e-06,
      "loss": 0.1701,
      "step": 2464
    },
    {
      "epoch": 0.19156046005595276,
      "grad_norm": 1.621051549911499,
      "learning_rate": 9.042197699720236e-06,
      "loss": 0.1482,
      "step": 2465
    },
    {
      "epoch": 0.19163817221013366,
      "grad_norm": 0.42727118730545044,
      "learning_rate": 9.041809138949333e-06,
      "loss": 0.1914,
      "step": 2466
    },
    {
      "epoch": 0.19171588436431458,
      "grad_norm": 0.4288618564605713,
      "learning_rate": 9.041420578178428e-06,
      "loss": 0.1224,
      "step": 2467
    },
    {
      "epoch": 0.19179359651849548,
      "grad_norm": 0.22791104018688202,
      "learning_rate": 9.041032017407523e-06,
      "loss": 0.1195,
      "step": 2468
    },
    {
      "epoch": 0.1918713086726764,
      "grad_norm": 1.078535795211792,
      "learning_rate": 9.04064345663662e-06,
      "loss": 0.2871,
      "step": 2469
    },
    {
      "epoch": 0.19194902082685733,
      "grad_norm": 0.32769376039505005,
      "learning_rate": 9.040254895865714e-06,
      "loss": 0.1361,
      "step": 2470
    },
    {
      "epoch": 0.19202673298103823,
      "grad_norm": 0.180190309882164,
      "learning_rate": 9.03986633509481e-06,
      "loss": 0.0473,
      "step": 2471
    },
    {
      "epoch": 0.19210444513521915,
      "grad_norm": 0.2286665141582489,
      "learning_rate": 9.039477774323904e-06,
      "loss": 0.0956,
      "step": 2472
    },
    {
      "epoch": 0.19218215728940005,
      "grad_norm": 0.31105005741119385,
      "learning_rate": 9.039089213553e-06,
      "loss": 0.1935,
      "step": 2473
    },
    {
      "epoch": 0.19225986944358098,
      "grad_norm": 0.6965081691741943,
      "learning_rate": 9.038700652782096e-06,
      "loss": 0.4757,
      "step": 2474
    },
    {
      "epoch": 0.1923375815977619,
      "grad_norm": 0.21367976069450378,
      "learning_rate": 9.03831209201119e-06,
      "loss": 0.2396,
      "step": 2475
    },
    {
      "epoch": 0.1924152937519428,
      "grad_norm": 0.2864733934402466,
      "learning_rate": 9.037923531240287e-06,
      "loss": 0.1604,
      "step": 2476
    },
    {
      "epoch": 0.19249300590612373,
      "grad_norm": 0.15780708193778992,
      "learning_rate": 9.037534970469382e-06,
      "loss": 0.2131,
      "step": 2477
    },
    {
      "epoch": 0.19257071806030462,
      "grad_norm": 0.33312079310417175,
      "learning_rate": 9.037146409698477e-06,
      "loss": 0.1194,
      "step": 2478
    },
    {
      "epoch": 0.19264843021448555,
      "grad_norm": 0.4551585912704468,
      "learning_rate": 9.036757848927574e-06,
      "loss": 0.2104,
      "step": 2479
    },
    {
      "epoch": 0.19272614236866645,
      "grad_norm": 0.16112539172172546,
      "learning_rate": 9.036369288156669e-06,
      "loss": 0.0281,
      "step": 2480
    },
    {
      "epoch": 0.19280385452284737,
      "grad_norm": 0.3390618562698364,
      "learning_rate": 9.035980727385764e-06,
      "loss": 0.2312,
      "step": 2481
    },
    {
      "epoch": 0.1928815666770283,
      "grad_norm": 0.19782397150993347,
      "learning_rate": 9.035592166614859e-06,
      "loss": 0.1579,
      "step": 2482
    },
    {
      "epoch": 0.1929592788312092,
      "grad_norm": 0.5278567671775818,
      "learning_rate": 9.035203605843955e-06,
      "loss": 0.285,
      "step": 2483
    },
    {
      "epoch": 0.19303699098539012,
      "grad_norm": 0.5455343127250671,
      "learning_rate": 9.03481504507305e-06,
      "loss": 0.1331,
      "step": 2484
    },
    {
      "epoch": 0.19311470313957102,
      "grad_norm": 0.279655784368515,
      "learning_rate": 9.034426484302145e-06,
      "loss": 0.2449,
      "step": 2485
    },
    {
      "epoch": 0.19319241529375195,
      "grad_norm": 0.29986172914505005,
      "learning_rate": 9.034037923531242e-06,
      "loss": 0.1711,
      "step": 2486
    },
    {
      "epoch": 0.19327012744793284,
      "grad_norm": 0.7695366144180298,
      "learning_rate": 9.033649362760337e-06,
      "loss": 0.341,
      "step": 2487
    },
    {
      "epoch": 0.19334783960211377,
      "grad_norm": 0.24869368970394135,
      "learning_rate": 9.033260801989432e-06,
      "loss": 0.2707,
      "step": 2488
    },
    {
      "epoch": 0.1934255517562947,
      "grad_norm": 0.2786684036254883,
      "learning_rate": 9.032872241218529e-06,
      "loss": 0.1218,
      "step": 2489
    },
    {
      "epoch": 0.1935032639104756,
      "grad_norm": 0.16075584292411804,
      "learning_rate": 9.032483680447622e-06,
      "loss": 0.0433,
      "step": 2490
    },
    {
      "epoch": 0.19358097606465652,
      "grad_norm": 0.3471161127090454,
      "learning_rate": 9.032095119676718e-06,
      "loss": 0.1356,
      "step": 2491
    },
    {
      "epoch": 0.19365868821883742,
      "grad_norm": 0.2991296052932739,
      "learning_rate": 9.031706558905813e-06,
      "loss": 0.1712,
      "step": 2492
    },
    {
      "epoch": 0.19373640037301834,
      "grad_norm": 0.3162631094455719,
      "learning_rate": 9.031317998134908e-06,
      "loss": 0.235,
      "step": 2493
    },
    {
      "epoch": 0.19381411252719927,
      "grad_norm": 0.8176737427711487,
      "learning_rate": 9.030929437364005e-06,
      "loss": 0.404,
      "step": 2494
    },
    {
      "epoch": 0.19389182468138016,
      "grad_norm": 0.4941086173057556,
      "learning_rate": 9.0305408765931e-06,
      "loss": 0.1808,
      "step": 2495
    },
    {
      "epoch": 0.1939695368355611,
      "grad_norm": 0.5655688047409058,
      "learning_rate": 9.030152315822195e-06,
      "loss": 0.2223,
      "step": 2496
    },
    {
      "epoch": 0.194047248989742,
      "grad_norm": 0.12590070068836212,
      "learning_rate": 9.029763755051291e-06,
      "loss": 0.0456,
      "step": 2497
    },
    {
      "epoch": 0.19412496114392291,
      "grad_norm": 0.0710759311914444,
      "learning_rate": 9.029375194280386e-06,
      "loss": 0.0298,
      "step": 2498
    },
    {
      "epoch": 0.1942026732981038,
      "grad_norm": 0.35682883858680725,
      "learning_rate": 9.028986633509481e-06,
      "loss": 0.1524,
      "step": 2499
    },
    {
      "epoch": 0.19428038545228474,
      "grad_norm": 0.3777056336402893,
      "learning_rate": 9.028598072738576e-06,
      "loss": 0.1767,
      "step": 2500
    },
    {
      "epoch": 0.19435809760646566,
      "grad_norm": 0.2579096853733063,
      "learning_rate": 9.028209511967673e-06,
      "loss": 0.1294,
      "step": 2501
    },
    {
      "epoch": 0.19443580976064656,
      "grad_norm": 0.2223297357559204,
      "learning_rate": 9.027820951196768e-06,
      "loss": 0.1011,
      "step": 2502
    },
    {
      "epoch": 0.1945135219148275,
      "grad_norm": 0.1557760238647461,
      "learning_rate": 9.027432390425863e-06,
      "loss": 0.0936,
      "step": 2503
    },
    {
      "epoch": 0.19459123406900838,
      "grad_norm": 0.2995132505893707,
      "learning_rate": 9.02704382965496e-06,
      "loss": 0.1594,
      "step": 2504
    },
    {
      "epoch": 0.1946689462231893,
      "grad_norm": 0.06629060208797455,
      "learning_rate": 9.026655268884054e-06,
      "loss": 0.0447,
      "step": 2505
    },
    {
      "epoch": 0.1947466583773702,
      "grad_norm": 0.07700177282094955,
      "learning_rate": 9.02626670811315e-06,
      "loss": 0.0193,
      "step": 2506
    },
    {
      "epoch": 0.19482437053155113,
      "grad_norm": 0.04286614805459976,
      "learning_rate": 9.025878147342244e-06,
      "loss": 0.0159,
      "step": 2507
    },
    {
      "epoch": 0.19490208268573206,
      "grad_norm": 0.2816544473171234,
      "learning_rate": 9.025489586571341e-06,
      "loss": 0.0535,
      "step": 2508
    },
    {
      "epoch": 0.19497979483991296,
      "grad_norm": 0.40745803713798523,
      "learning_rate": 9.025101025800436e-06,
      "loss": 0.1249,
      "step": 2509
    },
    {
      "epoch": 0.19505750699409388,
      "grad_norm": 0.5781682729721069,
      "learning_rate": 9.024712465029531e-06,
      "loss": 0.3723,
      "step": 2510
    },
    {
      "epoch": 0.19513521914827478,
      "grad_norm": 0.08174534142017365,
      "learning_rate": 9.024323904258628e-06,
      "loss": 0.0437,
      "step": 2511
    },
    {
      "epoch": 0.1952129313024557,
      "grad_norm": 0.25378549098968506,
      "learning_rate": 9.023935343487723e-06,
      "loss": 0.1919,
      "step": 2512
    },
    {
      "epoch": 0.19529064345663663,
      "grad_norm": 0.2905593812465668,
      "learning_rate": 9.023546782716817e-06,
      "loss": 0.1089,
      "step": 2513
    },
    {
      "epoch": 0.19536835561081753,
      "grad_norm": 0.16816015541553497,
      "learning_rate": 9.023158221945914e-06,
      "loss": 0.0582,
      "step": 2514
    },
    {
      "epoch": 0.19544606776499845,
      "grad_norm": 0.1425361931324005,
      "learning_rate": 9.022769661175007e-06,
      "loss": 0.0542,
      "step": 2515
    },
    {
      "epoch": 0.19552377991917935,
      "grad_norm": 0.27348434925079346,
      "learning_rate": 9.022381100404104e-06,
      "loss": 0.1812,
      "step": 2516
    },
    {
      "epoch": 0.19560149207336028,
      "grad_norm": 0.12992674112319946,
      "learning_rate": 9.021992539633199e-06,
      "loss": 0.0421,
      "step": 2517
    },
    {
      "epoch": 0.19567920422754118,
      "grad_norm": 0.20778487622737885,
      "learning_rate": 9.021603978862294e-06,
      "loss": 0.1264,
      "step": 2518
    },
    {
      "epoch": 0.1957569163817221,
      "grad_norm": 0.08561256527900696,
      "learning_rate": 9.02121541809139e-06,
      "loss": 0.0217,
      "step": 2519
    },
    {
      "epoch": 0.19583462853590303,
      "grad_norm": 0.34609928727149963,
      "learning_rate": 9.020826857320486e-06,
      "loss": 0.2759,
      "step": 2520
    },
    {
      "epoch": 0.19591234069008392,
      "grad_norm": 0.2454015612602234,
      "learning_rate": 9.02043829654958e-06,
      "loss": 0.0636,
      "step": 2521
    },
    {
      "epoch": 0.19599005284426485,
      "grad_norm": 0.2991766035556793,
      "learning_rate": 9.020049735778677e-06,
      "loss": 0.187,
      "step": 2522
    },
    {
      "epoch": 0.19606776499844575,
      "grad_norm": 0.5456345081329346,
      "learning_rate": 9.019661175007772e-06,
      "loss": 0.2576,
      "step": 2523
    },
    {
      "epoch": 0.19614547715262667,
      "grad_norm": 0.32841360569000244,
      "learning_rate": 9.019272614236867e-06,
      "loss": 0.3966,
      "step": 2524
    },
    {
      "epoch": 0.19622318930680757,
      "grad_norm": 0.1111655980348587,
      "learning_rate": 9.018884053465962e-06,
      "loss": 0.0452,
      "step": 2525
    },
    {
      "epoch": 0.1963009014609885,
      "grad_norm": 0.35011160373687744,
      "learning_rate": 9.018495492695059e-06,
      "loss": 0.0916,
      "step": 2526
    },
    {
      "epoch": 0.19637861361516942,
      "grad_norm": 0.12258052080869675,
      "learning_rate": 9.018106931924154e-06,
      "loss": 0.0805,
      "step": 2527
    },
    {
      "epoch": 0.19645632576935032,
      "grad_norm": 0.3515639305114746,
      "learning_rate": 9.017718371153248e-06,
      "loss": 0.1617,
      "step": 2528
    },
    {
      "epoch": 0.19653403792353125,
      "grad_norm": 0.2800404727458954,
      "learning_rate": 9.017329810382345e-06,
      "loss": 0.0593,
      "step": 2529
    },
    {
      "epoch": 0.19661175007771214,
      "grad_norm": 0.3405412435531616,
      "learning_rate": 9.01694124961144e-06,
      "loss": 0.2573,
      "step": 2530
    },
    {
      "epoch": 0.19668946223189307,
      "grad_norm": 0.21487918496131897,
      "learning_rate": 9.016552688840535e-06,
      "loss": 0.1045,
      "step": 2531
    },
    {
      "epoch": 0.196767174386074,
      "grad_norm": 0.152665913105011,
      "learning_rate": 9.016164128069632e-06,
      "loss": 0.0618,
      "step": 2532
    },
    {
      "epoch": 0.1968448865402549,
      "grad_norm": 0.4593096971511841,
      "learning_rate": 9.015775567298725e-06,
      "loss": 0.2292,
      "step": 2533
    },
    {
      "epoch": 0.19692259869443582,
      "grad_norm": 0.3103533387184143,
      "learning_rate": 9.015387006527822e-06,
      "loss": 0.2431,
      "step": 2534
    },
    {
      "epoch": 0.19700031084861672,
      "grad_norm": 0.49208977818489075,
      "learning_rate": 9.014998445756917e-06,
      "loss": 0.1911,
      "step": 2535
    },
    {
      "epoch": 0.19707802300279764,
      "grad_norm": 0.26830366253852844,
      "learning_rate": 9.014609884986013e-06,
      "loss": 0.1493,
      "step": 2536
    },
    {
      "epoch": 0.19715573515697854,
      "grad_norm": 0.30857858061790466,
      "learning_rate": 9.014221324215108e-06,
      "loss": 0.1185,
      "step": 2537
    },
    {
      "epoch": 0.19723344731115947,
      "grad_norm": 0.1705373227596283,
      "learning_rate": 9.013832763444203e-06,
      "loss": 0.0329,
      "step": 2538
    },
    {
      "epoch": 0.1973111594653404,
      "grad_norm": 0.0741996169090271,
      "learning_rate": 9.0134442026733e-06,
      "loss": 0.0277,
      "step": 2539
    },
    {
      "epoch": 0.1973888716195213,
      "grad_norm": 0.09614101052284241,
      "learning_rate": 9.013055641902395e-06,
      "loss": 0.0583,
      "step": 2540
    },
    {
      "epoch": 0.19746658377370221,
      "grad_norm": 0.22544090449810028,
      "learning_rate": 9.01266708113149e-06,
      "loss": 0.0778,
      "step": 2541
    },
    {
      "epoch": 0.1975442959278831,
      "grad_norm": 0.12986962497234344,
      "learning_rate": 9.012278520360586e-06,
      "loss": 0.1129,
      "step": 2542
    },
    {
      "epoch": 0.19762200808206404,
      "grad_norm": 0.5075795650482178,
      "learning_rate": 9.01188995958968e-06,
      "loss": 0.6787,
      "step": 2543
    },
    {
      "epoch": 0.19769972023624494,
      "grad_norm": 0.26200544834136963,
      "learning_rate": 9.011501398818776e-06,
      "loss": 0.1405,
      "step": 2544
    },
    {
      "epoch": 0.19777743239042586,
      "grad_norm": 0.4211278259754181,
      "learning_rate": 9.011112838047871e-06,
      "loss": 0.2427,
      "step": 2545
    },
    {
      "epoch": 0.1978551445446068,
      "grad_norm": 0.15581074357032776,
      "learning_rate": 9.010724277276966e-06,
      "loss": 0.1276,
      "step": 2546
    },
    {
      "epoch": 0.19793285669878768,
      "grad_norm": 0.32891708612442017,
      "learning_rate": 9.010335716506063e-06,
      "loss": 0.1347,
      "step": 2547
    },
    {
      "epoch": 0.1980105688529686,
      "grad_norm": 0.11501327157020569,
      "learning_rate": 9.009947155735158e-06,
      "loss": 0.0641,
      "step": 2548
    },
    {
      "epoch": 0.1980882810071495,
      "grad_norm": 0.10103679448366165,
      "learning_rate": 9.009558594964253e-06,
      "loss": 0.0099,
      "step": 2549
    },
    {
      "epoch": 0.19816599316133043,
      "grad_norm": 0.29648464918136597,
      "learning_rate": 9.00917003419335e-06,
      "loss": 0.143,
      "step": 2550
    },
    {
      "epoch": 0.19824370531551136,
      "grad_norm": 0.2128811776638031,
      "learning_rate": 9.008781473422444e-06,
      "loss": 0.139,
      "step": 2551
    },
    {
      "epoch": 0.19832141746969226,
      "grad_norm": 0.2609002888202667,
      "learning_rate": 9.008392912651539e-06,
      "loss": 0.3153,
      "step": 2552
    },
    {
      "epoch": 0.19839912962387318,
      "grad_norm": 0.2825939655303955,
      "learning_rate": 9.008004351880634e-06,
      "loss": 0.2094,
      "step": 2553
    },
    {
      "epoch": 0.19847684177805408,
      "grad_norm": 0.20702335238456726,
      "learning_rate": 9.00761579110973e-06,
      "loss": 0.1056,
      "step": 2554
    },
    {
      "epoch": 0.198554553932235,
      "grad_norm": 0.16146183013916016,
      "learning_rate": 9.007227230338826e-06,
      "loss": 0.0358,
      "step": 2555
    },
    {
      "epoch": 0.1986322660864159,
      "grad_norm": 0.5788896679878235,
      "learning_rate": 9.00683866956792e-06,
      "loss": 0.3568,
      "step": 2556
    },
    {
      "epoch": 0.19870997824059683,
      "grad_norm": 0.09936308115720749,
      "learning_rate": 9.006450108797017e-06,
      "loss": 0.008,
      "step": 2557
    },
    {
      "epoch": 0.19878769039477776,
      "grad_norm": 0.3380591869354248,
      "learning_rate": 9.006061548026112e-06,
      "loss": 0.244,
      "step": 2558
    },
    {
      "epoch": 0.19886540254895865,
      "grad_norm": 0.2040485441684723,
      "learning_rate": 9.005672987255207e-06,
      "loss": 0.196,
      "step": 2559
    },
    {
      "epoch": 0.19894311470313958,
      "grad_norm": 0.36537203192710876,
      "learning_rate": 9.005284426484304e-06,
      "loss": 0.3549,
      "step": 2560
    },
    {
      "epoch": 0.19902082685732048,
      "grad_norm": 0.419681191444397,
      "learning_rate": 9.004895865713397e-06,
      "loss": 0.5235,
      "step": 2561
    },
    {
      "epoch": 0.1990985390115014,
      "grad_norm": 0.731323778629303,
      "learning_rate": 9.004507304942494e-06,
      "loss": 0.2529,
      "step": 2562
    },
    {
      "epoch": 0.1991762511656823,
      "grad_norm": 0.1404866874217987,
      "learning_rate": 9.004118744171589e-06,
      "loss": 0.1208,
      "step": 2563
    },
    {
      "epoch": 0.19925396331986323,
      "grad_norm": 0.3250691592693329,
      "learning_rate": 9.003730183400684e-06,
      "loss": 0.4866,
      "step": 2564
    },
    {
      "epoch": 0.19933167547404415,
      "grad_norm": 0.3296470642089844,
      "learning_rate": 9.00334162262978e-06,
      "loss": 0.1767,
      "step": 2565
    },
    {
      "epoch": 0.19940938762822505,
      "grad_norm": 0.42576584219932556,
      "learning_rate": 9.002953061858875e-06,
      "loss": 0.173,
      "step": 2566
    },
    {
      "epoch": 0.19948709978240597,
      "grad_norm": 0.14028210937976837,
      "learning_rate": 9.002564501087972e-06,
      "loss": 0.0352,
      "step": 2567
    },
    {
      "epoch": 0.19956481193658687,
      "grad_norm": 0.15643192827701569,
      "learning_rate": 9.002175940317067e-06,
      "loss": 0.1604,
      "step": 2568
    },
    {
      "epoch": 0.1996425240907678,
      "grad_norm": 0.2229585498571396,
      "learning_rate": 9.001787379546162e-06,
      "loss": 0.0663,
      "step": 2569
    },
    {
      "epoch": 0.19972023624494872,
      "grad_norm": 0.2592657506465912,
      "learning_rate": 9.001398818775258e-06,
      "loss": 0.1392,
      "step": 2570
    },
    {
      "epoch": 0.19979794839912962,
      "grad_norm": 0.279106467962265,
      "learning_rate": 9.001010258004352e-06,
      "loss": 0.2089,
      "step": 2571
    },
    {
      "epoch": 0.19987566055331055,
      "grad_norm": 0.4462115168571472,
      "learning_rate": 9.000621697233448e-06,
      "loss": 0.2184,
      "step": 2572
    },
    {
      "epoch": 0.19995337270749144,
      "grad_norm": 0.5122783780097961,
      "learning_rate": 9.000233136462543e-06,
      "loss": 0.378,
      "step": 2573
    },
    {
      "epoch": 0.20003108486167237,
      "grad_norm": 0.30072543025016785,
      "learning_rate": 8.999844575691638e-06,
      "loss": 0.2566,
      "step": 2574
    },
    {
      "epoch": 0.20010879701585327,
      "grad_norm": 0.3400286138057709,
      "learning_rate": 8.999456014920735e-06,
      "loss": 0.1868,
      "step": 2575
    },
    {
      "epoch": 0.2001865091700342,
      "grad_norm": 0.05811328813433647,
      "learning_rate": 8.99906745414983e-06,
      "loss": 0.0127,
      "step": 2576
    },
    {
      "epoch": 0.20026422132421512,
      "grad_norm": 0.1691545993089676,
      "learning_rate": 8.998678893378925e-06,
      "loss": 0.0876,
      "step": 2577
    },
    {
      "epoch": 0.20034193347839602,
      "grad_norm": 0.725536048412323,
      "learning_rate": 8.998290332608021e-06,
      "loss": 0.1916,
      "step": 2578
    },
    {
      "epoch": 0.20041964563257694,
      "grad_norm": 0.138086199760437,
      "learning_rate": 8.997901771837116e-06,
      "loss": 0.05,
      "step": 2579
    },
    {
      "epoch": 0.20049735778675784,
      "grad_norm": 0.5615873336791992,
      "learning_rate": 8.997513211066211e-06,
      "loss": 0.3279,
      "step": 2580
    },
    {
      "epoch": 0.20057506994093877,
      "grad_norm": 0.34524258971214294,
      "learning_rate": 8.997124650295306e-06,
      "loss": 0.3601,
      "step": 2581
    },
    {
      "epoch": 0.20065278209511966,
      "grad_norm": 0.7523316144943237,
      "learning_rate": 8.996736089524403e-06,
      "loss": 0.749,
      "step": 2582
    },
    {
      "epoch": 0.2007304942493006,
      "grad_norm": 0.0803581029176712,
      "learning_rate": 8.996347528753498e-06,
      "loss": 0.0216,
      "step": 2583
    },
    {
      "epoch": 0.20080820640348152,
      "grad_norm": 0.33993634581565857,
      "learning_rate": 8.995958967982593e-06,
      "loss": 0.196,
      "step": 2584
    },
    {
      "epoch": 0.2008859185576624,
      "grad_norm": 0.4035882353782654,
      "learning_rate": 8.99557040721169e-06,
      "loss": 0.3264,
      "step": 2585
    },
    {
      "epoch": 0.20096363071184334,
      "grad_norm": 0.048758432269096375,
      "learning_rate": 8.995181846440784e-06,
      "loss": 0.0178,
      "step": 2586
    },
    {
      "epoch": 0.20104134286602424,
      "grad_norm": 0.16454418003559113,
      "learning_rate": 8.99479328566988e-06,
      "loss": 0.1025,
      "step": 2587
    },
    {
      "epoch": 0.20111905502020516,
      "grad_norm": 0.17527782917022705,
      "learning_rate": 8.994404724898976e-06,
      "loss": 0.1689,
      "step": 2588
    },
    {
      "epoch": 0.2011967671743861,
      "grad_norm": 0.1345769762992859,
      "learning_rate": 8.99401616412807e-06,
      "loss": 0.0344,
      "step": 2589
    },
    {
      "epoch": 0.20127447932856699,
      "grad_norm": 0.6088166832923889,
      "learning_rate": 8.993627603357166e-06,
      "loss": 0.5253,
      "step": 2590
    },
    {
      "epoch": 0.2013521914827479,
      "grad_norm": 0.15342922508716583,
      "learning_rate": 8.99323904258626e-06,
      "loss": 0.0627,
      "step": 2591
    },
    {
      "epoch": 0.2014299036369288,
      "grad_norm": 0.4600609838962555,
      "learning_rate": 8.992850481815356e-06,
      "loss": 0.2571,
      "step": 2592
    },
    {
      "epoch": 0.20150761579110973,
      "grad_norm": 0.16355066001415253,
      "learning_rate": 8.992461921044452e-06,
      "loss": 0.0993,
      "step": 2593
    },
    {
      "epoch": 0.20158532794529063,
      "grad_norm": 0.31387728452682495,
      "learning_rate": 8.992073360273547e-06,
      "loss": 0.2012,
      "step": 2594
    },
    {
      "epoch": 0.20166304009947156,
      "grad_norm": 0.1636538952589035,
      "learning_rate": 8.991684799502644e-06,
      "loss": 0.1211,
      "step": 2595
    },
    {
      "epoch": 0.20174075225365248,
      "grad_norm": 0.040661755949258804,
      "learning_rate": 8.991296238731739e-06,
      "loss": 0.004,
      "step": 2596
    },
    {
      "epoch": 0.20181846440783338,
      "grad_norm": 0.276142418384552,
      "learning_rate": 8.990907677960834e-06,
      "loss": 0.1463,
      "step": 2597
    },
    {
      "epoch": 0.2018961765620143,
      "grad_norm": 0.5799576640129089,
      "learning_rate": 8.99051911718993e-06,
      "loss": 0.1229,
      "step": 2598
    },
    {
      "epoch": 0.2019738887161952,
      "grad_norm": 0.40063896775245667,
      "learning_rate": 8.990130556419024e-06,
      "loss": 0.2477,
      "step": 2599
    },
    {
      "epoch": 0.20205160087037613,
      "grad_norm": 0.3551604449748993,
      "learning_rate": 8.98974199564812e-06,
      "loss": 0.1919,
      "step": 2600
    },
    {
      "epoch": 0.20212931302455703,
      "grad_norm": 0.18364672362804413,
      "learning_rate": 8.989353434877215e-06,
      "loss": 0.1508,
      "step": 2601
    },
    {
      "epoch": 0.20220702517873795,
      "grad_norm": 0.1207309365272522,
      "learning_rate": 8.98896487410631e-06,
      "loss": 0.0228,
      "step": 2602
    },
    {
      "epoch": 0.20228473733291888,
      "grad_norm": 0.3214586079120636,
      "learning_rate": 8.988576313335407e-06,
      "loss": 0.0627,
      "step": 2603
    },
    {
      "epoch": 0.20236244948709978,
      "grad_norm": 0.0991767942905426,
      "learning_rate": 8.988187752564502e-06,
      "loss": 0.0168,
      "step": 2604
    },
    {
      "epoch": 0.2024401616412807,
      "grad_norm": 0.1669052541255951,
      "learning_rate": 8.987799191793597e-06,
      "loss": 0.0498,
      "step": 2605
    },
    {
      "epoch": 0.2025178737954616,
      "grad_norm": 0.2924916446208954,
      "learning_rate": 8.987410631022694e-06,
      "loss": 0.1595,
      "step": 2606
    },
    {
      "epoch": 0.20259558594964253,
      "grad_norm": 0.15926320850849152,
      "learning_rate": 8.987022070251788e-06,
      "loss": 0.05,
      "step": 2607
    },
    {
      "epoch": 0.20267329810382345,
      "grad_norm": 0.24779146909713745,
      "learning_rate": 8.986633509480883e-06,
      "loss": 0.1241,
      "step": 2608
    },
    {
      "epoch": 0.20275101025800435,
      "grad_norm": 0.3077913224697113,
      "learning_rate": 8.986244948709978e-06,
      "loss": 0.1173,
      "step": 2609
    },
    {
      "epoch": 0.20282872241218527,
      "grad_norm": 0.33095046877861023,
      "learning_rate": 8.985856387939075e-06,
      "loss": 0.0821,
      "step": 2610
    },
    {
      "epoch": 0.20290643456636617,
      "grad_norm": 0.10993720591068268,
      "learning_rate": 8.98546782716817e-06,
      "loss": 0.0322,
      "step": 2611
    },
    {
      "epoch": 0.2029841467205471,
      "grad_norm": 0.22425223886966705,
      "learning_rate": 8.985079266397265e-06,
      "loss": 0.0552,
      "step": 2612
    },
    {
      "epoch": 0.203061858874728,
      "grad_norm": 0.36837145686149597,
      "learning_rate": 8.984690705626362e-06,
      "loss": 0.6106,
      "step": 2613
    },
    {
      "epoch": 0.20313957102890892,
      "grad_norm": 0.4005891680717468,
      "learning_rate": 8.984302144855457e-06,
      "loss": 0.3683,
      "step": 2614
    },
    {
      "epoch": 0.20321728318308985,
      "grad_norm": 0.8145164847373962,
      "learning_rate": 8.983913584084551e-06,
      "loss": 0.8422,
      "step": 2615
    },
    {
      "epoch": 0.20329499533727075,
      "grad_norm": 0.18141062557697296,
      "learning_rate": 8.983525023313648e-06,
      "loss": 0.0693,
      "step": 2616
    },
    {
      "epoch": 0.20337270749145167,
      "grad_norm": 0.27380672097206116,
      "learning_rate": 8.983136462542741e-06,
      "loss": 0.1303,
      "step": 2617
    },
    {
      "epoch": 0.20345041964563257,
      "grad_norm": 0.09457610547542572,
      "learning_rate": 8.982747901771838e-06,
      "loss": 0.0256,
      "step": 2618
    },
    {
      "epoch": 0.2035281317998135,
      "grad_norm": 0.15289820730686188,
      "learning_rate": 8.982359341000933e-06,
      "loss": 0.0255,
      "step": 2619
    },
    {
      "epoch": 0.2036058439539944,
      "grad_norm": 0.12510834634304047,
      "learning_rate": 8.981970780230028e-06,
      "loss": 0.0834,
      "step": 2620
    },
    {
      "epoch": 0.20368355610817532,
      "grad_norm": 0.3315899968147278,
      "learning_rate": 8.981582219459125e-06,
      "loss": 0.0788,
      "step": 2621
    },
    {
      "epoch": 0.20376126826235624,
      "grad_norm": 0.19079378247261047,
      "learning_rate": 8.98119365868822e-06,
      "loss": 0.0842,
      "step": 2622
    },
    {
      "epoch": 0.20383898041653714,
      "grad_norm": 0.06541573256254196,
      "learning_rate": 8.980805097917314e-06,
      "loss": 0.0122,
      "step": 2623
    },
    {
      "epoch": 0.20391669257071807,
      "grad_norm": 0.570370078086853,
      "learning_rate": 8.980416537146411e-06,
      "loss": 1.0494,
      "step": 2624
    },
    {
      "epoch": 0.20399440472489896,
      "grad_norm": 0.2809237241744995,
      "learning_rate": 8.980027976375506e-06,
      "loss": 0.2037,
      "step": 2625
    },
    {
      "epoch": 0.2040721168790799,
      "grad_norm": 0.18801873922348022,
      "learning_rate": 8.979639415604601e-06,
      "loss": 0.0544,
      "step": 2626
    },
    {
      "epoch": 0.20414982903326082,
      "grad_norm": 0.44297313690185547,
      "learning_rate": 8.979250854833696e-06,
      "loss": 0.2698,
      "step": 2627
    },
    {
      "epoch": 0.2042275411874417,
      "grad_norm": 0.44270044565200806,
      "learning_rate": 8.978862294062793e-06,
      "loss": 0.212,
      "step": 2628
    },
    {
      "epoch": 0.20430525334162264,
      "grad_norm": 0.5703525543212891,
      "learning_rate": 8.978473733291888e-06,
      "loss": 0.4908,
      "step": 2629
    },
    {
      "epoch": 0.20438296549580354,
      "grad_norm": 0.24794845283031464,
      "learning_rate": 8.978085172520983e-06,
      "loss": 0.1483,
      "step": 2630
    },
    {
      "epoch": 0.20446067764998446,
      "grad_norm": 0.0520893931388855,
      "learning_rate": 8.977696611750079e-06,
      "loss": 0.0116,
      "step": 2631
    },
    {
      "epoch": 0.20453838980416536,
      "grad_norm": 0.23993659019470215,
      "learning_rate": 8.977308050979174e-06,
      "loss": 0.081,
      "step": 2632
    },
    {
      "epoch": 0.20461610195834629,
      "grad_norm": 0.09853681921958923,
      "learning_rate": 8.976919490208269e-06,
      "loss": 0.0456,
      "step": 2633
    },
    {
      "epoch": 0.2046938141125272,
      "grad_norm": 0.1353779435157776,
      "learning_rate": 8.976530929437364e-06,
      "loss": 0.0828,
      "step": 2634
    },
    {
      "epoch": 0.2047715262667081,
      "grad_norm": 0.3023377060890198,
      "learning_rate": 8.97614236866646e-06,
      "loss": 0.358,
      "step": 2635
    },
    {
      "epoch": 0.20484923842088903,
      "grad_norm": 0.2759465277194977,
      "learning_rate": 8.975753807895556e-06,
      "loss": 0.1288,
      "step": 2636
    },
    {
      "epoch": 0.20492695057506993,
      "grad_norm": 0.5591583251953125,
      "learning_rate": 8.97536524712465e-06,
      "loss": 0.5713,
      "step": 2637
    },
    {
      "epoch": 0.20500466272925086,
      "grad_norm": 0.2325611561536789,
      "learning_rate": 8.974976686353747e-06,
      "loss": 0.093,
      "step": 2638
    },
    {
      "epoch": 0.20508237488343176,
      "grad_norm": 0.14082805812358856,
      "learning_rate": 8.974588125582842e-06,
      "loss": 0.0835,
      "step": 2639
    },
    {
      "epoch": 0.20516008703761268,
      "grad_norm": 0.3138304650783539,
      "learning_rate": 8.974199564811937e-06,
      "loss": 0.2328,
      "step": 2640
    },
    {
      "epoch": 0.2052377991917936,
      "grad_norm": 0.2843203842639923,
      "learning_rate": 8.973811004041034e-06,
      "loss": 0.1366,
      "step": 2641
    },
    {
      "epoch": 0.2053155113459745,
      "grad_norm": 0.34020957350730896,
      "learning_rate": 8.973422443270127e-06,
      "loss": 0.4489,
      "step": 2642
    },
    {
      "epoch": 0.20539322350015543,
      "grad_norm": 0.36494359374046326,
      "learning_rate": 8.973033882499224e-06,
      "loss": 0.2495,
      "step": 2643
    },
    {
      "epoch": 0.20547093565433633,
      "grad_norm": 0.328619122505188,
      "learning_rate": 8.972645321728319e-06,
      "loss": 0.0733,
      "step": 2644
    },
    {
      "epoch": 0.20554864780851725,
      "grad_norm": 0.2540226876735687,
      "learning_rate": 8.972256760957414e-06,
      "loss": 0.0537,
      "step": 2645
    },
    {
      "epoch": 0.20562635996269818,
      "grad_norm": 0.2923775613307953,
      "learning_rate": 8.97186820018651e-06,
      "loss": 0.1319,
      "step": 2646
    },
    {
      "epoch": 0.20570407211687908,
      "grad_norm": 0.4060787856578827,
      "learning_rate": 8.971479639415605e-06,
      "loss": 0.1305,
      "step": 2647
    },
    {
      "epoch": 0.20578178427106,
      "grad_norm": 0.43854421377182007,
      "learning_rate": 8.9710910786447e-06,
      "loss": 0.2673,
      "step": 2648
    },
    {
      "epoch": 0.2058594964252409,
      "grad_norm": 0.3983169496059418,
      "learning_rate": 8.970702517873797e-06,
      "loss": 0.16,
      "step": 2649
    },
    {
      "epoch": 0.20593720857942183,
      "grad_norm": 0.3289245665073395,
      "learning_rate": 8.970313957102892e-06,
      "loss": 0.1211,
      "step": 2650
    },
    {
      "epoch": 0.20601492073360272,
      "grad_norm": 0.08260288834571838,
      "learning_rate": 8.969925396331987e-06,
      "loss": 0.0266,
      "step": 2651
    },
    {
      "epoch": 0.20609263288778365,
      "grad_norm": 0.9285670518875122,
      "learning_rate": 8.969536835561082e-06,
      "loss": 0.4343,
      "step": 2652
    },
    {
      "epoch": 0.20617034504196458,
      "grad_norm": 0.47829264402389526,
      "learning_rate": 8.969148274790178e-06,
      "loss": 0.4562,
      "step": 2653
    },
    {
      "epoch": 0.20624805719614547,
      "grad_norm": 0.31491419672966003,
      "learning_rate": 8.968759714019273e-06,
      "loss": 0.0926,
      "step": 2654
    },
    {
      "epoch": 0.2063257693503264,
      "grad_norm": 0.14193156361579895,
      "learning_rate": 8.968371153248368e-06,
      "loss": 0.0906,
      "step": 2655
    },
    {
      "epoch": 0.2064034815045073,
      "grad_norm": 0.06920497119426727,
      "learning_rate": 8.967982592477465e-06,
      "loss": 0.0197,
      "step": 2656
    },
    {
      "epoch": 0.20648119365868822,
      "grad_norm": 0.1245659664273262,
      "learning_rate": 8.96759403170656e-06,
      "loss": 0.0518,
      "step": 2657
    },
    {
      "epoch": 0.20655890581286912,
      "grad_norm": 0.3546273112297058,
      "learning_rate": 8.967205470935655e-06,
      "loss": 0.1398,
      "step": 2658
    },
    {
      "epoch": 0.20663661796705005,
      "grad_norm": 0.18729938566684723,
      "learning_rate": 8.966816910164751e-06,
      "loss": 0.0902,
      "step": 2659
    },
    {
      "epoch": 0.20671433012123097,
      "grad_norm": 0.27165326476097107,
      "learning_rate": 8.966428349393846e-06,
      "loss": 0.0479,
      "step": 2660
    },
    {
      "epoch": 0.20679204227541187,
      "grad_norm": 0.22962595522403717,
      "learning_rate": 8.966039788622941e-06,
      "loss": 0.0956,
      "step": 2661
    },
    {
      "epoch": 0.2068697544295928,
      "grad_norm": 0.6008846163749695,
      "learning_rate": 8.965651227852036e-06,
      "loss": 0.5111,
      "step": 2662
    },
    {
      "epoch": 0.2069474665837737,
      "grad_norm": 0.07258561253547668,
      "learning_rate": 8.965262667081133e-06,
      "loss": 0.0452,
      "step": 2663
    },
    {
      "epoch": 0.20702517873795462,
      "grad_norm": 0.19027480483055115,
      "learning_rate": 8.964874106310228e-06,
      "loss": 0.0923,
      "step": 2664
    },
    {
      "epoch": 0.20710289089213554,
      "grad_norm": 0.49776750802993774,
      "learning_rate": 8.964485545539323e-06,
      "loss": 0.5394,
      "step": 2665
    },
    {
      "epoch": 0.20718060304631644,
      "grad_norm": 0.17160287499427795,
      "learning_rate": 8.96409698476842e-06,
      "loss": 0.0234,
      "step": 2666
    },
    {
      "epoch": 0.20725831520049737,
      "grad_norm": 0.1480548232793808,
      "learning_rate": 8.963708423997514e-06,
      "loss": 0.0716,
      "step": 2667
    },
    {
      "epoch": 0.20733602735467827,
      "grad_norm": 0.36879515647888184,
      "learning_rate": 8.96331986322661e-06,
      "loss": 0.5913,
      "step": 2668
    },
    {
      "epoch": 0.2074137395088592,
      "grad_norm": 0.03714112564921379,
      "learning_rate": 8.962931302455706e-06,
      "loss": 0.0143,
      "step": 2669
    },
    {
      "epoch": 0.2074914516630401,
      "grad_norm": 0.16210314631462097,
      "learning_rate": 8.962542741684799e-06,
      "loss": 0.0685,
      "step": 2670
    },
    {
      "epoch": 0.20756916381722101,
      "grad_norm": 0.2652318775653839,
      "learning_rate": 8.962154180913896e-06,
      "loss": 0.2533,
      "step": 2671
    },
    {
      "epoch": 0.20764687597140194,
      "grad_norm": 0.08737421035766602,
      "learning_rate": 8.96176562014299e-06,
      "loss": 0.0538,
      "step": 2672
    },
    {
      "epoch": 0.20772458812558284,
      "grad_norm": 0.1887836903333664,
      "learning_rate": 8.961377059372086e-06,
      "loss": 0.1341,
      "step": 2673
    },
    {
      "epoch": 0.20780230027976376,
      "grad_norm": 0.20676498115062714,
      "learning_rate": 8.960988498601182e-06,
      "loss": 0.1321,
      "step": 2674
    },
    {
      "epoch": 0.20788001243394466,
      "grad_norm": 0.31396251916885376,
      "learning_rate": 8.960599937830277e-06,
      "loss": 0.6245,
      "step": 2675
    },
    {
      "epoch": 0.2079577245881256,
      "grad_norm": 0.419117271900177,
      "learning_rate": 8.960211377059372e-06,
      "loss": 0.2696,
      "step": 2676
    },
    {
      "epoch": 0.20803543674230648,
      "grad_norm": 0.1987770050764084,
      "learning_rate": 8.959822816288469e-06,
      "loss": 0.0808,
      "step": 2677
    },
    {
      "epoch": 0.2081131488964874,
      "grad_norm": 0.15479806065559387,
      "learning_rate": 8.959434255517564e-06,
      "loss": 0.0664,
      "step": 2678
    },
    {
      "epoch": 0.20819086105066834,
      "grad_norm": 0.12574468553066254,
      "learning_rate": 8.959045694746659e-06,
      "loss": 0.0087,
      "step": 2679
    },
    {
      "epoch": 0.20826857320484923,
      "grad_norm": 0.2913365960121155,
      "learning_rate": 8.958657133975754e-06,
      "loss": 0.1408,
      "step": 2680
    },
    {
      "epoch": 0.20834628535903016,
      "grad_norm": 0.07791014015674591,
      "learning_rate": 8.95826857320485e-06,
      "loss": 0.0251,
      "step": 2681
    },
    {
      "epoch": 0.20842399751321106,
      "grad_norm": 0.3249799311161041,
      "learning_rate": 8.957880012433945e-06,
      "loss": 0.3495,
      "step": 2682
    },
    {
      "epoch": 0.20850170966739198,
      "grad_norm": 0.4430907964706421,
      "learning_rate": 8.95749145166304e-06,
      "loss": 0.4525,
      "step": 2683
    },
    {
      "epoch": 0.20857942182157288,
      "grad_norm": 0.1694529801607132,
      "learning_rate": 8.957102890892137e-06,
      "loss": 0.0897,
      "step": 2684
    },
    {
      "epoch": 0.2086571339757538,
      "grad_norm": 0.5964108109474182,
      "learning_rate": 8.956714330121232e-06,
      "loss": 0.2259,
      "step": 2685
    },
    {
      "epoch": 0.20873484612993473,
      "grad_norm": 0.18327359855175018,
      "learning_rate": 8.956325769350327e-06,
      "loss": 0.0662,
      "step": 2686
    },
    {
      "epoch": 0.20881255828411563,
      "grad_norm": 0.19802545011043549,
      "learning_rate": 8.955937208579423e-06,
      "loss": 0.1245,
      "step": 2687
    },
    {
      "epoch": 0.20889027043829655,
      "grad_norm": 0.15467052161693573,
      "learning_rate": 8.955548647808518e-06,
      "loss": 0.1216,
      "step": 2688
    },
    {
      "epoch": 0.20896798259247745,
      "grad_norm": 0.3852892518043518,
      "learning_rate": 8.955160087037613e-06,
      "loss": 0.382,
      "step": 2689
    },
    {
      "epoch": 0.20904569474665838,
      "grad_norm": 0.7636879682540894,
      "learning_rate": 8.954771526266708e-06,
      "loss": 0.4716,
      "step": 2690
    },
    {
      "epoch": 0.2091234069008393,
      "grad_norm": 0.1840316504240036,
      "learning_rate": 8.954382965495805e-06,
      "loss": 0.0314,
      "step": 2691
    },
    {
      "epoch": 0.2092011190550202,
      "grad_norm": 0.236551433801651,
      "learning_rate": 8.9539944047249e-06,
      "loss": 0.8365,
      "step": 2692
    },
    {
      "epoch": 0.20927883120920113,
      "grad_norm": 0.544230580329895,
      "learning_rate": 8.953605843953995e-06,
      "loss": 0.8162,
      "step": 2693
    },
    {
      "epoch": 0.20935654336338202,
      "grad_norm": 0.2867508828639984,
      "learning_rate": 8.953217283183091e-06,
      "loss": 0.2016,
      "step": 2694
    },
    {
      "epoch": 0.20943425551756295,
      "grad_norm": 0.24242573976516724,
      "learning_rate": 8.952828722412186e-06,
      "loss": 0.0716,
      "step": 2695
    },
    {
      "epoch": 0.20951196767174385,
      "grad_norm": 0.11037572473287582,
      "learning_rate": 8.952440161641281e-06,
      "loss": 0.067,
      "step": 2696
    },
    {
      "epoch": 0.20958967982592477,
      "grad_norm": 0.1496778428554535,
      "learning_rate": 8.952051600870378e-06,
      "loss": 0.1355,
      "step": 2697
    },
    {
      "epoch": 0.2096673919801057,
      "grad_norm": 0.5038899183273315,
      "learning_rate": 8.951663040099471e-06,
      "loss": 0.2798,
      "step": 2698
    },
    {
      "epoch": 0.2097451041342866,
      "grad_norm": 0.21530400216579437,
      "learning_rate": 8.951274479328568e-06,
      "loss": 0.1303,
      "step": 2699
    },
    {
      "epoch": 0.20982281628846752,
      "grad_norm": 0.3379983603954315,
      "learning_rate": 8.950885918557663e-06,
      "loss": 0.0917,
      "step": 2700
    },
    {
      "epoch": 0.20990052844264842,
      "grad_norm": 0.22858819365501404,
      "learning_rate": 8.950497357786758e-06,
      "loss": 0.1298,
      "step": 2701
    },
    {
      "epoch": 0.20997824059682935,
      "grad_norm": 0.15222637355327606,
      "learning_rate": 8.950108797015854e-06,
      "loss": 0.0607,
      "step": 2702
    },
    {
      "epoch": 0.21005595275101024,
      "grad_norm": 0.5035241842269897,
      "learning_rate": 8.94972023624495e-06,
      "loss": 0.0852,
      "step": 2703
    },
    {
      "epoch": 0.21013366490519117,
      "grad_norm": 0.23560039699077606,
      "learning_rate": 8.949331675474044e-06,
      "loss": 0.1083,
      "step": 2704
    },
    {
      "epoch": 0.2102113770593721,
      "grad_norm": 0.2760806977748871,
      "learning_rate": 8.948943114703141e-06,
      "loss": 0.3648,
      "step": 2705
    },
    {
      "epoch": 0.210289089213553,
      "grad_norm": 0.4109695553779602,
      "learning_rate": 8.948554553932236e-06,
      "loss": 0.2626,
      "step": 2706
    },
    {
      "epoch": 0.21036680136773392,
      "grad_norm": 0.33768200874328613,
      "learning_rate": 8.948165993161331e-06,
      "loss": 0.1628,
      "step": 2707
    },
    {
      "epoch": 0.21044451352191482,
      "grad_norm": 0.42697620391845703,
      "learning_rate": 8.947777432390426e-06,
      "loss": 0.5389,
      "step": 2708
    },
    {
      "epoch": 0.21052222567609574,
      "grad_norm": 0.36090049147605896,
      "learning_rate": 8.947388871619522e-06,
      "loss": 0.1294,
      "step": 2709
    },
    {
      "epoch": 0.21059993783027667,
      "grad_norm": 0.09557570517063141,
      "learning_rate": 8.947000310848617e-06,
      "loss": 0.0312,
      "step": 2710
    },
    {
      "epoch": 0.21067764998445757,
      "grad_norm": 0.19022709131240845,
      "learning_rate": 8.946611750077712e-06,
      "loss": 0.0638,
      "step": 2711
    },
    {
      "epoch": 0.2107553621386385,
      "grad_norm": 0.17786522209644318,
      "learning_rate": 8.946223189306809e-06,
      "loss": 0.0774,
      "step": 2712
    },
    {
      "epoch": 0.2108330742928194,
      "grad_norm": 0.36742889881134033,
      "learning_rate": 8.945834628535904e-06,
      "loss": 0.1419,
      "step": 2713
    },
    {
      "epoch": 0.21091078644700031,
      "grad_norm": 0.17948000133037567,
      "learning_rate": 8.945446067764999e-06,
      "loss": 0.0851,
      "step": 2714
    },
    {
      "epoch": 0.2109884986011812,
      "grad_norm": 0.055765051394701004,
      "learning_rate": 8.945057506994096e-06,
      "loss": 0.0297,
      "step": 2715
    },
    {
      "epoch": 0.21106621075536214,
      "grad_norm": 0.32983776926994324,
      "learning_rate": 8.944668946223189e-06,
      "loss": 0.4205,
      "step": 2716
    },
    {
      "epoch": 0.21114392290954306,
      "grad_norm": 0.26436647772789,
      "learning_rate": 8.944280385452285e-06,
      "loss": 0.2315,
      "step": 2717
    },
    {
      "epoch": 0.21122163506372396,
      "grad_norm": 0.4573790431022644,
      "learning_rate": 8.94389182468138e-06,
      "loss": 0.3264,
      "step": 2718
    },
    {
      "epoch": 0.2112993472179049,
      "grad_norm": 0.2507200539112091,
      "learning_rate": 8.943503263910477e-06,
      "loss": 0.1099,
      "step": 2719
    },
    {
      "epoch": 0.21137705937208578,
      "grad_norm": 0.3318750262260437,
      "learning_rate": 8.943114703139572e-06,
      "loss": 0.5166,
      "step": 2720
    },
    {
      "epoch": 0.2114547715262667,
      "grad_norm": 0.4976733922958374,
      "learning_rate": 8.942726142368667e-06,
      "loss": 0.5078,
      "step": 2721
    },
    {
      "epoch": 0.2115324836804476,
      "grad_norm": 0.20368318259716034,
      "learning_rate": 8.942337581597764e-06,
      "loss": 0.0388,
      "step": 2722
    },
    {
      "epoch": 0.21161019583462853,
      "grad_norm": 0.22354213893413544,
      "learning_rate": 8.941949020826859e-06,
      "loss": 0.0472,
      "step": 2723
    },
    {
      "epoch": 0.21168790798880946,
      "grad_norm": 0.14182348549365997,
      "learning_rate": 8.941560460055954e-06,
      "loss": 0.0583,
      "step": 2724
    },
    {
      "epoch": 0.21176562014299036,
      "grad_norm": 0.5631523132324219,
      "learning_rate": 8.94117189928505e-06,
      "loss": 0.2687,
      "step": 2725
    },
    {
      "epoch": 0.21184333229717128,
      "grad_norm": 0.15252849459648132,
      "learning_rate": 8.940783338514143e-06,
      "loss": 0.1055,
      "step": 2726
    },
    {
      "epoch": 0.21192104445135218,
      "grad_norm": 0.742526113986969,
      "learning_rate": 8.94039477774324e-06,
      "loss": 0.0982,
      "step": 2727
    },
    {
      "epoch": 0.2119987566055331,
      "grad_norm": 0.4428442418575287,
      "learning_rate": 8.940006216972335e-06,
      "loss": 0.1762,
      "step": 2728
    },
    {
      "epoch": 0.21207646875971403,
      "grad_norm": 0.2780781090259552,
      "learning_rate": 8.93961765620143e-06,
      "loss": 0.161,
      "step": 2729
    },
    {
      "epoch": 0.21215418091389493,
      "grad_norm": 0.3292301893234253,
      "learning_rate": 8.939229095430527e-06,
      "loss": 0.0895,
      "step": 2730
    },
    {
      "epoch": 0.21223189306807586,
      "grad_norm": 0.3569249212741852,
      "learning_rate": 8.938840534659622e-06,
      "loss": 0.1644,
      "step": 2731
    },
    {
      "epoch": 0.21230960522225675,
      "grad_norm": 0.42255088686943054,
      "learning_rate": 8.938451973888717e-06,
      "loss": 0.2694,
      "step": 2732
    },
    {
      "epoch": 0.21238731737643768,
      "grad_norm": 0.16607654094696045,
      "learning_rate": 8.938063413117813e-06,
      "loss": 0.1068,
      "step": 2733
    },
    {
      "epoch": 0.21246502953061858,
      "grad_norm": 0.44843271374702454,
      "learning_rate": 8.937674852346908e-06,
      "loss": 0.2475,
      "step": 2734
    },
    {
      "epoch": 0.2125427416847995,
      "grad_norm": 0.2846960425376892,
      "learning_rate": 8.937286291576003e-06,
      "loss": 0.2073,
      "step": 2735
    },
    {
      "epoch": 0.21262045383898043,
      "grad_norm": 0.5523343086242676,
      "learning_rate": 8.936897730805098e-06,
      "loss": 0.1838,
      "step": 2736
    },
    {
      "epoch": 0.21269816599316133,
      "grad_norm": 0.20992569625377655,
      "learning_rate": 8.936509170034195e-06,
      "loss": 0.0886,
      "step": 2737
    },
    {
      "epoch": 0.21277587814734225,
      "grad_norm": 0.4516139626502991,
      "learning_rate": 8.93612060926329e-06,
      "loss": 0.5773,
      "step": 2738
    },
    {
      "epoch": 0.21285359030152315,
      "grad_norm": 0.034939445555210114,
      "learning_rate": 8.935732048492385e-06,
      "loss": 0.0124,
      "step": 2739
    },
    {
      "epoch": 0.21293130245570407,
      "grad_norm": 0.1666731983423233,
      "learning_rate": 8.935343487721481e-06,
      "loss": 0.0619,
      "step": 2740
    },
    {
      "epoch": 0.21300901460988497,
      "grad_norm": 0.12808683514595032,
      "learning_rate": 8.934954926950576e-06,
      "loss": 0.0671,
      "step": 2741
    },
    {
      "epoch": 0.2130867267640659,
      "grad_norm": 0.4075765907764435,
      "learning_rate": 8.934566366179671e-06,
      "loss": 0.2632,
      "step": 2742
    },
    {
      "epoch": 0.21316443891824682,
      "grad_norm": 0.4975985884666443,
      "learning_rate": 8.934177805408768e-06,
      "loss": 0.3089,
      "step": 2743
    },
    {
      "epoch": 0.21324215107242772,
      "grad_norm": 0.10378191620111465,
      "learning_rate": 8.933789244637861e-06,
      "loss": 0.064,
      "step": 2744
    },
    {
      "epoch": 0.21331986322660865,
      "grad_norm": 0.210996612906456,
      "learning_rate": 8.933400683866958e-06,
      "loss": 0.1652,
      "step": 2745
    },
    {
      "epoch": 0.21339757538078954,
      "grad_norm": 0.20217162370681763,
      "learning_rate": 8.933012123096053e-06,
      "loss": 0.0832,
      "step": 2746
    },
    {
      "epoch": 0.21347528753497047,
      "grad_norm": 0.1964516043663025,
      "learning_rate": 8.93262356232515e-06,
      "loss": 0.111,
      "step": 2747
    },
    {
      "epoch": 0.2135529996891514,
      "grad_norm": 0.25606444478034973,
      "learning_rate": 8.932235001554244e-06,
      "loss": 0.0958,
      "step": 2748
    },
    {
      "epoch": 0.2136307118433323,
      "grad_norm": 0.40650758147239685,
      "learning_rate": 8.931846440783339e-06,
      "loss": 0.1496,
      "step": 2749
    },
    {
      "epoch": 0.21370842399751322,
      "grad_norm": 0.06466734409332275,
      "learning_rate": 8.931457880012436e-06,
      "loss": 0.0115,
      "step": 2750
    },
    {
      "epoch": 0.21378613615169412,
      "grad_norm": 1.1436970233917236,
      "learning_rate": 8.931069319241529e-06,
      "loss": 0.4214,
      "step": 2751
    },
    {
      "epoch": 0.21386384830587504,
      "grad_norm": 0.2812860906124115,
      "learning_rate": 8.930680758470626e-06,
      "loss": 0.2247,
      "step": 2752
    },
    {
      "epoch": 0.21394156046005594,
      "grad_norm": 0.14718303084373474,
      "learning_rate": 8.93029219769972e-06,
      "loss": 0.0329,
      "step": 2753
    },
    {
      "epoch": 0.21401927261423687,
      "grad_norm": 0.240385040640831,
      "learning_rate": 8.929903636928816e-06,
      "loss": 0.1277,
      "step": 2754
    },
    {
      "epoch": 0.2140969847684178,
      "grad_norm": 0.2680395841598511,
      "learning_rate": 8.929515076157912e-06,
      "loss": 0.1263,
      "step": 2755
    },
    {
      "epoch": 0.2141746969225987,
      "grad_norm": 0.24416252970695496,
      "learning_rate": 8.929126515387007e-06,
      "loss": 0.3061,
      "step": 2756
    },
    {
      "epoch": 0.21425240907677962,
      "grad_norm": 0.1884177327156067,
      "learning_rate": 8.928737954616102e-06,
      "loss": 0.0674,
      "step": 2757
    },
    {
      "epoch": 0.2143301212309605,
      "grad_norm": 0.3320513665676117,
      "learning_rate": 8.928349393845199e-06,
      "loss": 0.2224,
      "step": 2758
    },
    {
      "epoch": 0.21440783338514144,
      "grad_norm": 0.4623323678970337,
      "learning_rate": 8.927960833074294e-06,
      "loss": 0.1888,
      "step": 2759
    },
    {
      "epoch": 0.21448554553932234,
      "grad_norm": 0.44861918687820435,
      "learning_rate": 8.927572272303389e-06,
      "loss": 0.2942,
      "step": 2760
    },
    {
      "epoch": 0.21456325769350326,
      "grad_norm": 0.16570080816745758,
      "learning_rate": 8.927183711532484e-06,
      "loss": 0.1198,
      "step": 2761
    },
    {
      "epoch": 0.2146409698476842,
      "grad_norm": 0.3321544826030731,
      "learning_rate": 8.92679515076158e-06,
      "loss": 0.3779,
      "step": 2762
    },
    {
      "epoch": 0.21471868200186509,
      "grad_norm": 0.30799826979637146,
      "learning_rate": 8.926406589990675e-06,
      "loss": 0.3183,
      "step": 2763
    },
    {
      "epoch": 0.214796394156046,
      "grad_norm": 0.5553287863731384,
      "learning_rate": 8.92601802921977e-06,
      "loss": 0.2543,
      "step": 2764
    },
    {
      "epoch": 0.2148741063102269,
      "grad_norm": 0.43577051162719727,
      "learning_rate": 8.925629468448867e-06,
      "loss": 0.2247,
      "step": 2765
    },
    {
      "epoch": 0.21495181846440783,
      "grad_norm": 0.11650560796260834,
      "learning_rate": 8.925240907677962e-06,
      "loss": 0.0545,
      "step": 2766
    },
    {
      "epoch": 0.21502953061858876,
      "grad_norm": 0.12155690044164658,
      "learning_rate": 8.924852346907057e-06,
      "loss": 0.0657,
      "step": 2767
    },
    {
      "epoch": 0.21510724277276966,
      "grad_norm": 0.2007843255996704,
      "learning_rate": 8.924463786136153e-06,
      "loss": 0.0601,
      "step": 2768
    },
    {
      "epoch": 0.21518495492695058,
      "grad_norm": 0.5155991315841675,
      "learning_rate": 8.924075225365247e-06,
      "loss": 0.82,
      "step": 2769
    },
    {
      "epoch": 0.21526266708113148,
      "grad_norm": 0.2835722267627716,
      "learning_rate": 8.923686664594343e-06,
      "loss": 0.1118,
      "step": 2770
    },
    {
      "epoch": 0.2153403792353124,
      "grad_norm": 0.5257936716079712,
      "learning_rate": 8.923298103823438e-06,
      "loss": 0.1557,
      "step": 2771
    },
    {
      "epoch": 0.2154180913894933,
      "grad_norm": 0.423898845911026,
      "learning_rate": 8.922909543052533e-06,
      "loss": 0.1713,
      "step": 2772
    },
    {
      "epoch": 0.21549580354367423,
      "grad_norm": 0.20899780094623566,
      "learning_rate": 8.92252098228163e-06,
      "loss": 0.12,
      "step": 2773
    },
    {
      "epoch": 0.21557351569785516,
      "grad_norm": 0.13124172389507294,
      "learning_rate": 8.922132421510725e-06,
      "loss": 0.0676,
      "step": 2774
    },
    {
      "epoch": 0.21565122785203605,
      "grad_norm": 0.1927809864282608,
      "learning_rate": 8.92174386073982e-06,
      "loss": 0.0453,
      "step": 2775
    },
    {
      "epoch": 0.21572894000621698,
      "grad_norm": 0.3381468653678894,
      "learning_rate": 8.921355299968916e-06,
      "loss": 0.1225,
      "step": 2776
    },
    {
      "epoch": 0.21580665216039788,
      "grad_norm": 0.12744276225566864,
      "learning_rate": 8.920966739198011e-06,
      "loss": 0.0268,
      "step": 2777
    },
    {
      "epoch": 0.2158843643145788,
      "grad_norm": 0.15244446694850922,
      "learning_rate": 8.920578178427108e-06,
      "loss": 0.0766,
      "step": 2778
    },
    {
      "epoch": 0.2159620764687597,
      "grad_norm": 0.2303047776222229,
      "learning_rate": 8.920189617656201e-06,
      "loss": 0.2104,
      "step": 2779
    },
    {
      "epoch": 0.21603978862294063,
      "grad_norm": 0.19967535138130188,
      "learning_rate": 8.919801056885298e-06,
      "loss": 0.1677,
      "step": 2780
    },
    {
      "epoch": 0.21611750077712155,
      "grad_norm": 0.3674333095550537,
      "learning_rate": 8.919412496114393e-06,
      "loss": 0.1759,
      "step": 2781
    },
    {
      "epoch": 0.21619521293130245,
      "grad_norm": 0.7379575371742249,
      "learning_rate": 8.919023935343488e-06,
      "loss": 0.2929,
      "step": 2782
    },
    {
      "epoch": 0.21627292508548338,
      "grad_norm": 0.44906866550445557,
      "learning_rate": 8.918635374572584e-06,
      "loss": 0.2155,
      "step": 2783
    },
    {
      "epoch": 0.21635063723966427,
      "grad_norm": 0.15660279989242554,
      "learning_rate": 8.91824681380168e-06,
      "loss": 0.0777,
      "step": 2784
    },
    {
      "epoch": 0.2164283493938452,
      "grad_norm": 0.47878140211105347,
      "learning_rate": 8.917858253030774e-06,
      "loss": 0.8614,
      "step": 2785
    },
    {
      "epoch": 0.21650606154802612,
      "grad_norm": 0.3173692524433136,
      "learning_rate": 8.917469692259871e-06,
      "loss": 0.3946,
      "step": 2786
    },
    {
      "epoch": 0.21658377370220702,
      "grad_norm": 0.32498106360435486,
      "learning_rate": 8.917081131488966e-06,
      "loss": 0.1533,
      "step": 2787
    },
    {
      "epoch": 0.21666148585638795,
      "grad_norm": 0.14481312036514282,
      "learning_rate": 8.91669257071806e-06,
      "loss": 0.08,
      "step": 2788
    },
    {
      "epoch": 0.21673919801056885,
      "grad_norm": 0.45522579550743103,
      "learning_rate": 8.916304009947156e-06,
      "loss": 0.3113,
      "step": 2789
    },
    {
      "epoch": 0.21681691016474977,
      "grad_norm": 0.14259353280067444,
      "learning_rate": 8.915915449176252e-06,
      "loss": 0.054,
      "step": 2790
    },
    {
      "epoch": 0.21689462231893067,
      "grad_norm": 0.11953915655612946,
      "learning_rate": 8.915526888405347e-06,
      "loss": 0.0423,
      "step": 2791
    },
    {
      "epoch": 0.2169723344731116,
      "grad_norm": 0.19231943786144257,
      "learning_rate": 8.915138327634442e-06,
      "loss": 0.0668,
      "step": 2792
    },
    {
      "epoch": 0.21705004662729252,
      "grad_norm": 0.37184375524520874,
      "learning_rate": 8.914749766863539e-06,
      "loss": 0.2365,
      "step": 2793
    },
    {
      "epoch": 0.21712775878147342,
      "grad_norm": 0.34183889627456665,
      "learning_rate": 8.914361206092634e-06,
      "loss": 0.6097,
      "step": 2794
    },
    {
      "epoch": 0.21720547093565434,
      "grad_norm": 0.38300633430480957,
      "learning_rate": 8.913972645321729e-06,
      "loss": 0.2185,
      "step": 2795
    },
    {
      "epoch": 0.21728318308983524,
      "grad_norm": 0.5923925042152405,
      "learning_rate": 8.913584084550825e-06,
      "loss": 0.1674,
      "step": 2796
    },
    {
      "epoch": 0.21736089524401617,
      "grad_norm": 0.1512625366449356,
      "learning_rate": 8.913195523779919e-06,
      "loss": 0.0798,
      "step": 2797
    },
    {
      "epoch": 0.21743860739819706,
      "grad_norm": 0.3562470078468323,
      "learning_rate": 8.912806963009015e-06,
      "loss": 0.2388,
      "step": 2798
    },
    {
      "epoch": 0.217516319552378,
      "grad_norm": 0.46393322944641113,
      "learning_rate": 8.91241840223811e-06,
      "loss": 0.3206,
      "step": 2799
    },
    {
      "epoch": 0.21759403170655892,
      "grad_norm": 0.3152809739112854,
      "learning_rate": 8.912029841467205e-06,
      "loss": 0.3055,
      "step": 2800
    },
    {
      "epoch": 0.2176717438607398,
      "grad_norm": 0.15220007300376892,
      "learning_rate": 8.911641280696302e-06,
      "loss": 0.0861,
      "step": 2801
    },
    {
      "epoch": 0.21774945601492074,
      "grad_norm": 0.2191038280725479,
      "learning_rate": 8.911252719925397e-06,
      "loss": 0.1156,
      "step": 2802
    },
    {
      "epoch": 0.21782716816910164,
      "grad_norm": 0.40598630905151367,
      "learning_rate": 8.910864159154492e-06,
      "loss": 0.2836,
      "step": 2803
    },
    {
      "epoch": 0.21790488032328256,
      "grad_norm": 0.08184147626161575,
      "learning_rate": 8.910475598383588e-06,
      "loss": 0.0243,
      "step": 2804
    },
    {
      "epoch": 0.2179825924774635,
      "grad_norm": 0.319854199886322,
      "learning_rate": 8.910087037612683e-06,
      "loss": 0.1661,
      "step": 2805
    },
    {
      "epoch": 0.21806030463164439,
      "grad_norm": 0.5182945132255554,
      "learning_rate": 8.909698476841778e-06,
      "loss": 0.2943,
      "step": 2806
    },
    {
      "epoch": 0.2181380167858253,
      "grad_norm": 0.1031702309846878,
      "learning_rate": 8.909309916070873e-06,
      "loss": 0.0363,
      "step": 2807
    },
    {
      "epoch": 0.2182157289400062,
      "grad_norm": 0.16104425489902496,
      "learning_rate": 8.90892135529997e-06,
      "loss": 0.0358,
      "step": 2808
    },
    {
      "epoch": 0.21829344109418714,
      "grad_norm": 1.0520803928375244,
      "learning_rate": 8.908532794529065e-06,
      "loss": 0.4546,
      "step": 2809
    },
    {
      "epoch": 0.21837115324836803,
      "grad_norm": 0.29649102687835693,
      "learning_rate": 8.90814423375816e-06,
      "loss": 0.1088,
      "step": 2810
    },
    {
      "epoch": 0.21844886540254896,
      "grad_norm": 0.049623943865299225,
      "learning_rate": 8.907755672987257e-06,
      "loss": 0.0174,
      "step": 2811
    },
    {
      "epoch": 0.21852657755672988,
      "grad_norm": 0.2681295573711395,
      "learning_rate": 8.907367112216351e-06,
      "loss": 0.2151,
      "step": 2812
    },
    {
      "epoch": 0.21860428971091078,
      "grad_norm": 0.2275753617286682,
      "learning_rate": 8.906978551445446e-06,
      "loss": 0.2271,
      "step": 2813
    },
    {
      "epoch": 0.2186820018650917,
      "grad_norm": 0.12245944887399673,
      "learning_rate": 8.906589990674543e-06,
      "loss": 0.0856,
      "step": 2814
    },
    {
      "epoch": 0.2187597140192726,
      "grad_norm": 0.28890460729599,
      "learning_rate": 8.906201429903638e-06,
      "loss": 0.172,
      "step": 2815
    },
    {
      "epoch": 0.21883742617345353,
      "grad_norm": 0.5717937350273132,
      "learning_rate": 8.905812869132733e-06,
      "loss": 0.2712,
      "step": 2816
    },
    {
      "epoch": 0.21891513832763443,
      "grad_norm": 0.5405265688896179,
      "learning_rate": 8.905424308361828e-06,
      "loss": 0.4567,
      "step": 2817
    },
    {
      "epoch": 0.21899285048181535,
      "grad_norm": 0.23556311428546906,
      "learning_rate": 8.905035747590925e-06,
      "loss": 0.0651,
      "step": 2818
    },
    {
      "epoch": 0.21907056263599628,
      "grad_norm": 0.33069857954978943,
      "learning_rate": 8.90464718682002e-06,
      "loss": 0.1795,
      "step": 2819
    },
    {
      "epoch": 0.21914827479017718,
      "grad_norm": 0.38064777851104736,
      "learning_rate": 8.904258626049114e-06,
      "loss": 0.3447,
      "step": 2820
    },
    {
      "epoch": 0.2192259869443581,
      "grad_norm": 0.20319373905658722,
      "learning_rate": 8.903870065278211e-06,
      "loss": 0.1147,
      "step": 2821
    },
    {
      "epoch": 0.219303699098539,
      "grad_norm": 0.24838440120220184,
      "learning_rate": 8.903481504507306e-06,
      "loss": 0.2019,
      "step": 2822
    },
    {
      "epoch": 0.21938141125271993,
      "grad_norm": 0.15130124986171722,
      "learning_rate": 8.903092943736401e-06,
      "loss": 0.0871,
      "step": 2823
    },
    {
      "epoch": 0.21945912340690085,
      "grad_norm": 0.32816165685653687,
      "learning_rate": 8.902704382965498e-06,
      "loss": 0.2407,
      "step": 2824
    },
    {
      "epoch": 0.21953683556108175,
      "grad_norm": 1.0095995664596558,
      "learning_rate": 8.902315822194591e-06,
      "loss": 2.2894,
      "step": 2825
    },
    {
      "epoch": 0.21961454771526268,
      "grad_norm": 0.450610488653183,
      "learning_rate": 8.901927261423688e-06,
      "loss": 0.1311,
      "step": 2826
    },
    {
      "epoch": 0.21969225986944357,
      "grad_norm": 0.1178603395819664,
      "learning_rate": 8.901538700652782e-06,
      "loss": 0.0681,
      "step": 2827
    },
    {
      "epoch": 0.2197699720236245,
      "grad_norm": 0.1378147453069687,
      "learning_rate": 8.901150139881877e-06,
      "loss": 0.0642,
      "step": 2828
    },
    {
      "epoch": 0.2198476841778054,
      "grad_norm": 0.945774495601654,
      "learning_rate": 8.900761579110974e-06,
      "loss": 0.5095,
      "step": 2829
    },
    {
      "epoch": 0.21992539633198632,
      "grad_norm": 0.1447785198688507,
      "learning_rate": 8.900373018340069e-06,
      "loss": 0.0532,
      "step": 2830
    },
    {
      "epoch": 0.22000310848616725,
      "grad_norm": 0.029026787728071213,
      "learning_rate": 8.899984457569164e-06,
      "loss": 0.0039,
      "step": 2831
    },
    {
      "epoch": 0.22008082064034815,
      "grad_norm": 0.22105374932289124,
      "learning_rate": 8.89959589679826e-06,
      "loss": 0.0727,
      "step": 2832
    },
    {
      "epoch": 0.22015853279452907,
      "grad_norm": 0.5414027571678162,
      "learning_rate": 8.899207336027356e-06,
      "loss": 0.4987,
      "step": 2833
    },
    {
      "epoch": 0.22023624494870997,
      "grad_norm": 0.5505779385566711,
      "learning_rate": 8.89881877525645e-06,
      "loss": 0.2211,
      "step": 2834
    },
    {
      "epoch": 0.2203139571028909,
      "grad_norm": 0.3747880160808563,
      "learning_rate": 8.898430214485545e-06,
      "loss": 0.1347,
      "step": 2835
    },
    {
      "epoch": 0.2203916692570718,
      "grad_norm": 0.22609132528305054,
      "learning_rate": 8.898041653714642e-06,
      "loss": 0.0653,
      "step": 2836
    },
    {
      "epoch": 0.22046938141125272,
      "grad_norm": 0.3684242069721222,
      "learning_rate": 8.897653092943737e-06,
      "loss": 0.2003,
      "step": 2837
    },
    {
      "epoch": 0.22054709356543364,
      "grad_norm": 0.5611814260482788,
      "learning_rate": 8.897264532172832e-06,
      "loss": 0.338,
      "step": 2838
    },
    {
      "epoch": 0.22062480571961454,
      "grad_norm": 0.26604968309402466,
      "learning_rate": 8.896875971401929e-06,
      "loss": 0.4085,
      "step": 2839
    },
    {
      "epoch": 0.22070251787379547,
      "grad_norm": 0.11558260768651962,
      "learning_rate": 8.896487410631024e-06,
      "loss": 0.0321,
      "step": 2840
    },
    {
      "epoch": 0.22078023002797637,
      "grad_norm": 0.3431009352207184,
      "learning_rate": 8.896098849860119e-06,
      "loss": 0.6451,
      "step": 2841
    },
    {
      "epoch": 0.2208579421821573,
      "grad_norm": 0.060799699276685715,
      "learning_rate": 8.895710289089215e-06,
      "loss": 0.0229,
      "step": 2842
    },
    {
      "epoch": 0.22093565433633822,
      "grad_norm": 0.20640775561332703,
      "learning_rate": 8.89532172831831e-06,
      "loss": 0.0964,
      "step": 2843
    },
    {
      "epoch": 0.22101336649051911,
      "grad_norm": 0.4956195056438446,
      "learning_rate": 8.894933167547405e-06,
      "loss": 0.3753,
      "step": 2844
    },
    {
      "epoch": 0.22109107864470004,
      "grad_norm": 1.0518699884414673,
      "learning_rate": 8.8945446067765e-06,
      "loss": 0.4619,
      "step": 2845
    },
    {
      "epoch": 0.22116879079888094,
      "grad_norm": 0.34874427318573,
      "learning_rate": 8.894156046005597e-06,
      "loss": 0.2914,
      "step": 2846
    },
    {
      "epoch": 0.22124650295306186,
      "grad_norm": 0.24905407428741455,
      "learning_rate": 8.893767485234692e-06,
      "loss": 0.1104,
      "step": 2847
    },
    {
      "epoch": 0.22132421510724276,
      "grad_norm": 0.7920320630073547,
      "learning_rate": 8.893378924463787e-06,
      "loss": 0.3931,
      "step": 2848
    },
    {
      "epoch": 0.2214019272614237,
      "grad_norm": 0.17234063148498535,
      "learning_rate": 8.892990363692883e-06,
      "loss": 0.0699,
      "step": 2849
    },
    {
      "epoch": 0.2214796394156046,
      "grad_norm": 0.38638535141944885,
      "learning_rate": 8.892601802921978e-06,
      "loss": 0.1026,
      "step": 2850
    },
    {
      "epoch": 0.2215573515697855,
      "grad_norm": 0.35355043411254883,
      "learning_rate": 8.892213242151073e-06,
      "loss": 0.1831,
      "step": 2851
    },
    {
      "epoch": 0.22163506372396644,
      "grad_norm": 0.41394010186195374,
      "learning_rate": 8.89182468138017e-06,
      "loss": 0.2363,
      "step": 2852
    },
    {
      "epoch": 0.22171277587814733,
      "grad_norm": 0.4114384055137634,
      "learning_rate": 8.891436120609263e-06,
      "loss": 0.3453,
      "step": 2853
    },
    {
      "epoch": 0.22179048803232826,
      "grad_norm": 0.27843424677848816,
      "learning_rate": 8.89104755983836e-06,
      "loss": 0.2466,
      "step": 2854
    },
    {
      "epoch": 0.22186820018650916,
      "grad_norm": 0.0547521635890007,
      "learning_rate": 8.890658999067455e-06,
      "loss": 0.0432,
      "step": 2855
    },
    {
      "epoch": 0.22194591234069008,
      "grad_norm": 0.830710232257843,
      "learning_rate": 8.89027043829655e-06,
      "loss": 0.1564,
      "step": 2856
    },
    {
      "epoch": 0.222023624494871,
      "grad_norm": 0.27805665135383606,
      "learning_rate": 8.889881877525646e-06,
      "loss": 0.1793,
      "step": 2857
    },
    {
      "epoch": 0.2221013366490519,
      "grad_norm": 0.8471415638923645,
      "learning_rate": 8.889493316754741e-06,
      "loss": 0.2317,
      "step": 2858
    },
    {
      "epoch": 0.22217904880323283,
      "grad_norm": 0.4894699454307556,
      "learning_rate": 8.889104755983836e-06,
      "loss": 0.4234,
      "step": 2859
    },
    {
      "epoch": 0.22225676095741373,
      "grad_norm": 0.4249657392501831,
      "learning_rate": 8.888716195212933e-06,
      "loss": 0.24,
      "step": 2860
    },
    {
      "epoch": 0.22233447311159465,
      "grad_norm": 0.04311384633183479,
      "learning_rate": 8.888327634442028e-06,
      "loss": 0.0121,
      "step": 2861
    },
    {
      "epoch": 0.22241218526577558,
      "grad_norm": 0.13587433099746704,
      "learning_rate": 8.887939073671123e-06,
      "loss": 0.0827,
      "step": 2862
    },
    {
      "epoch": 0.22248989741995648,
      "grad_norm": 0.7033357620239258,
      "learning_rate": 8.887550512900218e-06,
      "loss": 0.5037,
      "step": 2863
    },
    {
      "epoch": 0.2225676095741374,
      "grad_norm": 0.47835397720336914,
      "learning_rate": 8.887161952129314e-06,
      "loss": 0.8933,
      "step": 2864
    },
    {
      "epoch": 0.2226453217283183,
      "grad_norm": 0.16177035868167877,
      "learning_rate": 8.88677339135841e-06,
      "loss": 0.1092,
      "step": 2865
    },
    {
      "epoch": 0.22272303388249923,
      "grad_norm": 1.1802585124969482,
      "learning_rate": 8.886384830587504e-06,
      "loss": 0.3353,
      "step": 2866
    },
    {
      "epoch": 0.22280074603668013,
      "grad_norm": 0.6252862215042114,
      "learning_rate": 8.8859962698166e-06,
      "loss": 0.0647,
      "step": 2867
    },
    {
      "epoch": 0.22287845819086105,
      "grad_norm": 0.3741028606891632,
      "learning_rate": 8.885607709045696e-06,
      "loss": 0.125,
      "step": 2868
    },
    {
      "epoch": 0.22295617034504198,
      "grad_norm": 0.3237517178058624,
      "learning_rate": 8.88521914827479e-06,
      "loss": 0.1569,
      "step": 2869
    },
    {
      "epoch": 0.22303388249922287,
      "grad_norm": 0.2905910015106201,
      "learning_rate": 8.884830587503887e-06,
      "loss": 0.0874,
      "step": 2870
    },
    {
      "epoch": 0.2231115946534038,
      "grad_norm": 0.21376462280750275,
      "learning_rate": 8.884442026732982e-06,
      "loss": 0.1182,
      "step": 2871
    },
    {
      "epoch": 0.2231893068075847,
      "grad_norm": 0.25406914949417114,
      "learning_rate": 8.884053465962077e-06,
      "loss": 0.1766,
      "step": 2872
    },
    {
      "epoch": 0.22326701896176562,
      "grad_norm": 0.4333898425102234,
      "learning_rate": 8.883664905191172e-06,
      "loss": 0.1541,
      "step": 2873
    },
    {
      "epoch": 0.22334473111594652,
      "grad_norm": 0.16110824048519135,
      "learning_rate": 8.883276344420269e-06,
      "loss": 0.0343,
      "step": 2874
    },
    {
      "epoch": 0.22342244327012745,
      "grad_norm": 0.4364791512489319,
      "learning_rate": 8.882887783649364e-06,
      "loss": 0.2025,
      "step": 2875
    },
    {
      "epoch": 0.22350015542430837,
      "grad_norm": 0.41618576645851135,
      "learning_rate": 8.882499222878459e-06,
      "loss": 0.4227,
      "step": 2876
    },
    {
      "epoch": 0.22357786757848927,
      "grad_norm": 0.2536157965660095,
      "learning_rate": 8.882110662107555e-06,
      "loss": 0.2716,
      "step": 2877
    },
    {
      "epoch": 0.2236555797326702,
      "grad_norm": 0.09065359085798264,
      "learning_rate": 8.881722101336649e-06,
      "loss": 0.0515,
      "step": 2878
    },
    {
      "epoch": 0.2237332918868511,
      "grad_norm": 0.336028516292572,
      "learning_rate": 8.881333540565745e-06,
      "loss": 0.2222,
      "step": 2879
    },
    {
      "epoch": 0.22381100404103202,
      "grad_norm": 0.1833709478378296,
      "learning_rate": 8.88094497979484e-06,
      "loss": 0.1323,
      "step": 2880
    },
    {
      "epoch": 0.22388871619521294,
      "grad_norm": 0.4644373953342438,
      "learning_rate": 8.880556419023935e-06,
      "loss": 0.3854,
      "step": 2881
    },
    {
      "epoch": 0.22396642834939384,
      "grad_norm": 0.42446330189704895,
      "learning_rate": 8.880167858253032e-06,
      "loss": 0.2969,
      "step": 2882
    },
    {
      "epoch": 0.22404414050357477,
      "grad_norm": 0.2965160608291626,
      "learning_rate": 8.879779297482127e-06,
      "loss": 0.2512,
      "step": 2883
    },
    {
      "epoch": 0.22412185265775567,
      "grad_norm": 0.31602397561073303,
      "learning_rate": 8.879390736711222e-06,
      "loss": 0.313,
      "step": 2884
    },
    {
      "epoch": 0.2241995648119366,
      "grad_norm": 0.2707935571670532,
      "learning_rate": 8.879002175940318e-06,
      "loss": 0.2616,
      "step": 2885
    },
    {
      "epoch": 0.2242772769661175,
      "grad_norm": 0.4030033349990845,
      "learning_rate": 8.878613615169413e-06,
      "loss": 0.1722,
      "step": 2886
    },
    {
      "epoch": 0.22435498912029841,
      "grad_norm": 0.3520205020904541,
      "learning_rate": 8.878225054398508e-06,
      "loss": 0.3282,
      "step": 2887
    },
    {
      "epoch": 0.22443270127447934,
      "grad_norm": 0.2753934860229492,
      "learning_rate": 8.877836493627603e-06,
      "loss": 0.1311,
      "step": 2888
    },
    {
      "epoch": 0.22451041342866024,
      "grad_norm": 0.6744310855865479,
      "learning_rate": 8.8774479328567e-06,
      "loss": 0.3228,
      "step": 2889
    },
    {
      "epoch": 0.22458812558284116,
      "grad_norm": 0.14857344329357147,
      "learning_rate": 8.877059372085795e-06,
      "loss": 0.1085,
      "step": 2890
    },
    {
      "epoch": 0.22466583773702206,
      "grad_norm": 0.16302824020385742,
      "learning_rate": 8.87667081131489e-06,
      "loss": 0.1154,
      "step": 2891
    },
    {
      "epoch": 0.224743549891203,
      "grad_norm": 0.503512978553772,
      "learning_rate": 8.876282250543986e-06,
      "loss": 0.5577,
      "step": 2892
    },
    {
      "epoch": 0.22482126204538389,
      "grad_norm": 0.043301597237586975,
      "learning_rate": 8.875893689773081e-06,
      "loss": 0.0083,
      "step": 2893
    },
    {
      "epoch": 0.2248989741995648,
      "grad_norm": 0.18742047250270844,
      "learning_rate": 8.875505129002176e-06,
      "loss": 0.1042,
      "step": 2894
    },
    {
      "epoch": 0.22497668635374574,
      "grad_norm": 0.1853688806295395,
      "learning_rate": 8.875116568231273e-06,
      "loss": 0.0839,
      "step": 2895
    },
    {
      "epoch": 0.22505439850792663,
      "grad_norm": 0.334147185087204,
      "learning_rate": 8.874728007460366e-06,
      "loss": 0.3199,
      "step": 2896
    },
    {
      "epoch": 0.22513211066210756,
      "grad_norm": 0.21384206414222717,
      "learning_rate": 8.874339446689463e-06,
      "loss": 0.0579,
      "step": 2897
    },
    {
      "epoch": 0.22520982281628846,
      "grad_norm": 0.5895418524742126,
      "learning_rate": 8.873950885918558e-06,
      "loss": 0.7128,
      "step": 2898
    },
    {
      "epoch": 0.22528753497046938,
      "grad_norm": 0.19202615320682526,
      "learning_rate": 8.873562325147654e-06,
      "loss": 0.3506,
      "step": 2899
    },
    {
      "epoch": 0.2253652471246503,
      "grad_norm": 0.08515863865613937,
      "learning_rate": 8.87317376437675e-06,
      "loss": 0.0697,
      "step": 2900
    },
    {
      "epoch": 0.2254429592788312,
      "grad_norm": 0.2291904091835022,
      "learning_rate": 8.872785203605844e-06,
      "loss": 0.0884,
      "step": 2901
    },
    {
      "epoch": 0.22552067143301213,
      "grad_norm": 0.2858107388019562,
      "learning_rate": 8.872396642834941e-06,
      "loss": 0.0687,
      "step": 2902
    },
    {
      "epoch": 0.22559838358719303,
      "grad_norm": 0.33666640520095825,
      "learning_rate": 8.872008082064036e-06,
      "loss": 0.256,
      "step": 2903
    },
    {
      "epoch": 0.22567609574137396,
      "grad_norm": 0.29191598296165466,
      "learning_rate": 8.871619521293131e-06,
      "loss": 0.1524,
      "step": 2904
    },
    {
      "epoch": 0.22575380789555485,
      "grad_norm": 0.24490056931972504,
      "learning_rate": 8.871230960522228e-06,
      "loss": 0.0748,
      "step": 2905
    },
    {
      "epoch": 0.22583152004973578,
      "grad_norm": 0.13350029289722443,
      "learning_rate": 8.87084239975132e-06,
      "loss": 0.0356,
      "step": 2906
    },
    {
      "epoch": 0.2259092322039167,
      "grad_norm": 0.12973296642303467,
      "learning_rate": 8.870453838980417e-06,
      "loss": 0.0249,
      "step": 2907
    },
    {
      "epoch": 0.2259869443580976,
      "grad_norm": 0.24925313889980316,
      "learning_rate": 8.870065278209512e-06,
      "loss": 0.2051,
      "step": 2908
    },
    {
      "epoch": 0.22606465651227853,
      "grad_norm": 0.2402043640613556,
      "learning_rate": 8.869676717438607e-06,
      "loss": 0.4632,
      "step": 2909
    },
    {
      "epoch": 0.22614236866645943,
      "grad_norm": 0.20023512840270996,
      "learning_rate": 8.869288156667704e-06,
      "loss": 0.216,
      "step": 2910
    },
    {
      "epoch": 0.22622008082064035,
      "grad_norm": 0.6434566378593445,
      "learning_rate": 8.868899595896799e-06,
      "loss": 0.5633,
      "step": 2911
    },
    {
      "epoch": 0.22629779297482125,
      "grad_norm": 0.2054518759250641,
      "learning_rate": 8.868511035125894e-06,
      "loss": 0.2042,
      "step": 2912
    },
    {
      "epoch": 0.22637550512900217,
      "grad_norm": 0.3995898962020874,
      "learning_rate": 8.86812247435499e-06,
      "loss": 0.2608,
      "step": 2913
    },
    {
      "epoch": 0.2264532172831831,
      "grad_norm": 0.7175652384757996,
      "learning_rate": 8.867733913584085e-06,
      "loss": 0.3011,
      "step": 2914
    },
    {
      "epoch": 0.226530929437364,
      "grad_norm": 1.011476993560791,
      "learning_rate": 8.86734535281318e-06,
      "loss": 0.311,
      "step": 2915
    },
    {
      "epoch": 0.22660864159154492,
      "grad_norm": 0.3396071791648865,
      "learning_rate": 8.866956792042275e-06,
      "loss": 0.2692,
      "step": 2916
    },
    {
      "epoch": 0.22668635374572582,
      "grad_norm": 0.4008466303348541,
      "learning_rate": 8.866568231271372e-06,
      "loss": 0.468,
      "step": 2917
    },
    {
      "epoch": 0.22676406589990675,
      "grad_norm": 0.43580755591392517,
      "learning_rate": 8.866179670500467e-06,
      "loss": 0.2208,
      "step": 2918
    },
    {
      "epoch": 0.22684177805408767,
      "grad_norm": 0.21375808119773865,
      "learning_rate": 8.865791109729562e-06,
      "loss": 0.121,
      "step": 2919
    },
    {
      "epoch": 0.22691949020826857,
      "grad_norm": 0.18019594252109528,
      "learning_rate": 8.865402548958659e-06,
      "loss": 0.1192,
      "step": 2920
    },
    {
      "epoch": 0.2269972023624495,
      "grad_norm": 0.22725653648376465,
      "learning_rate": 8.865013988187753e-06,
      "loss": 0.0358,
      "step": 2921
    },
    {
      "epoch": 0.2270749145166304,
      "grad_norm": 0.3439403772354126,
      "learning_rate": 8.864625427416848e-06,
      "loss": 0.1356,
      "step": 2922
    },
    {
      "epoch": 0.22715262667081132,
      "grad_norm": 0.04324064776301384,
      "learning_rate": 8.864236866645945e-06,
      "loss": 0.0083,
      "step": 2923
    },
    {
      "epoch": 0.22723033882499222,
      "grad_norm": 0.2858041524887085,
      "learning_rate": 8.863848305875038e-06,
      "loss": 0.1628,
      "step": 2924
    },
    {
      "epoch": 0.22730805097917314,
      "grad_norm": 0.20954293012619019,
      "learning_rate": 8.863459745104135e-06,
      "loss": 0.4538,
      "step": 2925
    },
    {
      "epoch": 0.22738576313335407,
      "grad_norm": 0.2847844660282135,
      "learning_rate": 8.86307118433323e-06,
      "loss": 0.2089,
      "step": 2926
    },
    {
      "epoch": 0.22746347528753497,
      "grad_norm": 0.3405908942222595,
      "learning_rate": 8.862682623562325e-06,
      "loss": 0.1244,
      "step": 2927
    },
    {
      "epoch": 0.2275411874417159,
      "grad_norm": 0.28581979870796204,
      "learning_rate": 8.862294062791422e-06,
      "loss": 0.1688,
      "step": 2928
    },
    {
      "epoch": 0.2276188995958968,
      "grad_norm": 0.1860479861497879,
      "learning_rate": 8.861905502020516e-06,
      "loss": 0.0501,
      "step": 2929
    },
    {
      "epoch": 0.22769661175007772,
      "grad_norm": 0.442779541015625,
      "learning_rate": 8.861516941249613e-06,
      "loss": 0.3739,
      "step": 2930
    },
    {
      "epoch": 0.2277743239042586,
      "grad_norm": 0.20051318407058716,
      "learning_rate": 8.861128380478708e-06,
      "loss": 0.1374,
      "step": 2931
    },
    {
      "epoch": 0.22785203605843954,
      "grad_norm": 0.16121406853199005,
      "learning_rate": 8.860739819707803e-06,
      "loss": 0.0871,
      "step": 2932
    },
    {
      "epoch": 0.22792974821262046,
      "grad_norm": 0.6753173470497131,
      "learning_rate": 8.8603512589369e-06,
      "loss": 0.1694,
      "step": 2933
    },
    {
      "epoch": 0.22800746036680136,
      "grad_norm": 0.44287094473838806,
      "learning_rate": 8.859962698165993e-06,
      "loss": 0.4724,
      "step": 2934
    },
    {
      "epoch": 0.2280851725209823,
      "grad_norm": 0.621660590171814,
      "learning_rate": 8.85957413739509e-06,
      "loss": 0.1855,
      "step": 2935
    },
    {
      "epoch": 0.22816288467516319,
      "grad_norm": 0.11023513227701187,
      "learning_rate": 8.859185576624185e-06,
      "loss": 0.0498,
      "step": 2936
    },
    {
      "epoch": 0.2282405968293441,
      "grad_norm": 0.6923023462295532,
      "learning_rate": 8.85879701585328e-06,
      "loss": 0.3326,
      "step": 2937
    },
    {
      "epoch": 0.22831830898352504,
      "grad_norm": 0.2128245234489441,
      "learning_rate": 8.858408455082376e-06,
      "loss": 0.1042,
      "step": 2938
    },
    {
      "epoch": 0.22839602113770593,
      "grad_norm": 0.24137891829013824,
      "learning_rate": 8.858019894311471e-06,
      "loss": 0.0987,
      "step": 2939
    },
    {
      "epoch": 0.22847373329188686,
      "grad_norm": 0.20871376991271973,
      "learning_rate": 8.857631333540566e-06,
      "loss": 0.1442,
      "step": 2940
    },
    {
      "epoch": 0.22855144544606776,
      "grad_norm": 0.2707158923149109,
      "learning_rate": 8.857242772769663e-06,
      "loss": 0.1312,
      "step": 2941
    },
    {
      "epoch": 0.22862915760024868,
      "grad_norm": 0.5464361906051636,
      "learning_rate": 8.856854211998758e-06,
      "loss": 0.285,
      "step": 2942
    },
    {
      "epoch": 0.22870686975442958,
      "grad_norm": 0.6631530523300171,
      "learning_rate": 8.856465651227853e-06,
      "loss": 0.2062,
      "step": 2943
    },
    {
      "epoch": 0.2287845819086105,
      "grad_norm": 0.1578250378370285,
      "learning_rate": 8.856077090456948e-06,
      "loss": 0.1846,
      "step": 2944
    },
    {
      "epoch": 0.22886229406279143,
      "grad_norm": 0.10961180180311203,
      "learning_rate": 8.855688529686044e-06,
      "loss": 0.0464,
      "step": 2945
    },
    {
      "epoch": 0.22894000621697233,
      "grad_norm": 0.5634796619415283,
      "learning_rate": 8.855299968915139e-06,
      "loss": 0.3666,
      "step": 2946
    },
    {
      "epoch": 0.22901771837115326,
      "grad_norm": 0.24071729183197021,
      "learning_rate": 8.854911408144234e-06,
      "loss": 0.0832,
      "step": 2947
    },
    {
      "epoch": 0.22909543052533415,
      "grad_norm": 0.3908432424068451,
      "learning_rate": 8.85452284737333e-06,
      "loss": 0.1829,
      "step": 2948
    },
    {
      "epoch": 0.22917314267951508,
      "grad_norm": 0.2693590521812439,
      "learning_rate": 8.854134286602426e-06,
      "loss": 0.1768,
      "step": 2949
    },
    {
      "epoch": 0.22925085483369598,
      "grad_norm": 0.1615106165409088,
      "learning_rate": 8.85374572583152e-06,
      "loss": 0.1538,
      "step": 2950
    },
    {
      "epoch": 0.2293285669878769,
      "grad_norm": 0.11491785943508148,
      "learning_rate": 8.853357165060617e-06,
      "loss": 0.0539,
      "step": 2951
    },
    {
      "epoch": 0.22940627914205783,
      "grad_norm": 0.3906961679458618,
      "learning_rate": 8.85296860428971e-06,
      "loss": 0.2583,
      "step": 2952
    },
    {
      "epoch": 0.22948399129623873,
      "grad_norm": 0.25117170810699463,
      "learning_rate": 8.852580043518807e-06,
      "loss": 0.1842,
      "step": 2953
    },
    {
      "epoch": 0.22956170345041965,
      "grad_norm": 0.3079635798931122,
      "learning_rate": 8.852191482747902e-06,
      "loss": 0.2745,
      "step": 2954
    },
    {
      "epoch": 0.22963941560460055,
      "grad_norm": 0.5040006637573242,
      "learning_rate": 8.851802921976997e-06,
      "loss": 0.4996,
      "step": 2955
    },
    {
      "epoch": 0.22971712775878148,
      "grad_norm": 0.08183317631483078,
      "learning_rate": 8.851414361206094e-06,
      "loss": 0.0322,
      "step": 2956
    },
    {
      "epoch": 0.2297948399129624,
      "grad_norm": 0.30830880999565125,
      "learning_rate": 8.851025800435189e-06,
      "loss": 0.4325,
      "step": 2957
    },
    {
      "epoch": 0.2298725520671433,
      "grad_norm": 0.05587109178304672,
      "learning_rate": 8.850637239664284e-06,
      "loss": 0.0267,
      "step": 2958
    },
    {
      "epoch": 0.22995026422132422,
      "grad_norm": 0.3867436647415161,
      "learning_rate": 8.85024867889338e-06,
      "loss": 0.2839,
      "step": 2959
    },
    {
      "epoch": 0.23002797637550512,
      "grad_norm": 0.6734097599983215,
      "learning_rate": 8.849860118122475e-06,
      "loss": 0.1952,
      "step": 2960
    },
    {
      "epoch": 0.23010568852968605,
      "grad_norm": 0.28523099422454834,
      "learning_rate": 8.849471557351572e-06,
      "loss": 0.2145,
      "step": 2961
    },
    {
      "epoch": 0.23018340068386695,
      "grad_norm": 0.8980032205581665,
      "learning_rate": 8.849082996580665e-06,
      "loss": 0.2007,
      "step": 2962
    },
    {
      "epoch": 0.23026111283804787,
      "grad_norm": 0.2548500597476959,
      "learning_rate": 8.848694435809762e-06,
      "loss": 0.1875,
      "step": 2963
    },
    {
      "epoch": 0.2303388249922288,
      "grad_norm": 0.06775437295436859,
      "learning_rate": 8.848305875038857e-06,
      "loss": 0.0448,
      "step": 2964
    },
    {
      "epoch": 0.2304165371464097,
      "grad_norm": 0.3393878638744354,
      "learning_rate": 8.847917314267952e-06,
      "loss": 0.2343,
      "step": 2965
    },
    {
      "epoch": 0.23049424930059062,
      "grad_norm": 0.13741640746593475,
      "learning_rate": 8.847528753497048e-06,
      "loss": 0.0254,
      "step": 2966
    },
    {
      "epoch": 0.23057196145477152,
      "grad_norm": 0.5440437197685242,
      "learning_rate": 8.847140192726143e-06,
      "loss": 0.4647,
      "step": 2967
    },
    {
      "epoch": 0.23064967360895244,
      "grad_norm": 0.1385585218667984,
      "learning_rate": 8.846751631955238e-06,
      "loss": 0.0362,
      "step": 2968
    },
    {
      "epoch": 0.23072738576313334,
      "grad_norm": 0.21609528362751007,
      "learning_rate": 8.846363071184335e-06,
      "loss": 0.0801,
      "step": 2969
    },
    {
      "epoch": 0.23080509791731427,
      "grad_norm": 0.32392388582229614,
      "learning_rate": 8.84597451041343e-06,
      "loss": 0.3262,
      "step": 2970
    },
    {
      "epoch": 0.2308828100714952,
      "grad_norm": 0.30243149399757385,
      "learning_rate": 8.845585949642525e-06,
      "loss": 0.0862,
      "step": 2971
    },
    {
      "epoch": 0.2309605222256761,
      "grad_norm": 0.14196282625198364,
      "learning_rate": 8.84519738887162e-06,
      "loss": 0.0585,
      "step": 2972
    },
    {
      "epoch": 0.23103823437985702,
      "grad_norm": 0.44295868277549744,
      "learning_rate": 8.844808828100716e-06,
      "loss": 0.2369,
      "step": 2973
    },
    {
      "epoch": 0.2311159465340379,
      "grad_norm": 0.38102710247039795,
      "learning_rate": 8.844420267329811e-06,
      "loss": 0.3108,
      "step": 2974
    },
    {
      "epoch": 0.23119365868821884,
      "grad_norm": 0.11564202606678009,
      "learning_rate": 8.844031706558906e-06,
      "loss": 0.0723,
      "step": 2975
    },
    {
      "epoch": 0.23127137084239976,
      "grad_norm": 0.749660313129425,
      "learning_rate": 8.843643145788003e-06,
      "loss": 0.4003,
      "step": 2976
    },
    {
      "epoch": 0.23134908299658066,
      "grad_norm": 0.30599573254585266,
      "learning_rate": 8.843254585017098e-06,
      "loss": 0.2397,
      "step": 2977
    },
    {
      "epoch": 0.2314267951507616,
      "grad_norm": 0.608277440071106,
      "learning_rate": 8.842866024246193e-06,
      "loss": 0.2322,
      "step": 2978
    },
    {
      "epoch": 0.2315045073049425,
      "grad_norm": 0.37245553731918335,
      "learning_rate": 8.84247746347529e-06,
      "loss": 0.3268,
      "step": 2979
    },
    {
      "epoch": 0.2315822194591234,
      "grad_norm": 0.24465550482273102,
      "learning_rate": 8.842088902704383e-06,
      "loss": 0.1146,
      "step": 2980
    },
    {
      "epoch": 0.2316599316133043,
      "grad_norm": 0.4879167377948761,
      "learning_rate": 8.84170034193348e-06,
      "loss": 0.1964,
      "step": 2981
    },
    {
      "epoch": 0.23173764376748524,
      "grad_norm": 0.04017097130417824,
      "learning_rate": 8.841311781162574e-06,
      "loss": 0.0066,
      "step": 2982
    },
    {
      "epoch": 0.23181535592166616,
      "grad_norm": 0.2689836323261261,
      "learning_rate": 8.84092322039167e-06,
      "loss": 0.104,
      "step": 2983
    },
    {
      "epoch": 0.23189306807584706,
      "grad_norm": 0.043625324964523315,
      "learning_rate": 8.840534659620766e-06,
      "loss": 0.0055,
      "step": 2984
    },
    {
      "epoch": 0.23197078023002798,
      "grad_norm": 0.12414416670799255,
      "learning_rate": 8.84014609884986e-06,
      "loss": 0.0675,
      "step": 2985
    },
    {
      "epoch": 0.23204849238420888,
      "grad_norm": 0.23914629220962524,
      "learning_rate": 8.839757538078956e-06,
      "loss": 0.1416,
      "step": 2986
    },
    {
      "epoch": 0.2321262045383898,
      "grad_norm": 0.3494460880756378,
      "learning_rate": 8.839368977308052e-06,
      "loss": 0.2546,
      "step": 2987
    },
    {
      "epoch": 0.2322039166925707,
      "grad_norm": 0.3425518572330475,
      "learning_rate": 8.838980416537147e-06,
      "loss": 0.0908,
      "step": 2988
    },
    {
      "epoch": 0.23228162884675163,
      "grad_norm": 0.28777262568473816,
      "learning_rate": 8.838591855766242e-06,
      "loss": 0.4394,
      "step": 2989
    },
    {
      "epoch": 0.23235934100093256,
      "grad_norm": 0.22137510776519775,
      "learning_rate": 8.838203294995337e-06,
      "loss": 0.1507,
      "step": 2990
    },
    {
      "epoch": 0.23243705315511345,
      "grad_norm": 0.48434051871299744,
      "learning_rate": 8.837814734224434e-06,
      "loss": 0.3344,
      "step": 2991
    },
    {
      "epoch": 0.23251476530929438,
      "grad_norm": 0.14264948666095734,
      "learning_rate": 8.837426173453529e-06,
      "loss": 0.0642,
      "step": 2992
    },
    {
      "epoch": 0.23259247746347528,
      "grad_norm": 0.3669559061527252,
      "learning_rate": 8.837037612682624e-06,
      "loss": 0.2986,
      "step": 2993
    },
    {
      "epoch": 0.2326701896176562,
      "grad_norm": 0.04410224407911301,
      "learning_rate": 8.83664905191172e-06,
      "loss": 0.0084,
      "step": 2994
    },
    {
      "epoch": 0.23274790177183713,
      "grad_norm": 0.23043414950370789,
      "learning_rate": 8.836260491140815e-06,
      "loss": 0.1144,
      "step": 2995
    },
    {
      "epoch": 0.23282561392601803,
      "grad_norm": 0.448192834854126,
      "learning_rate": 8.83587193036991e-06,
      "loss": 0.697,
      "step": 2996
    },
    {
      "epoch": 0.23290332608019895,
      "grad_norm": 1.2814197540283203,
      "learning_rate": 8.835483369599007e-06,
      "loss": 0.3934,
      "step": 2997
    },
    {
      "epoch": 0.23298103823437985,
      "grad_norm": 0.16855110228061676,
      "learning_rate": 8.835094808828102e-06,
      "loss": 0.1534,
      "step": 2998
    },
    {
      "epoch": 0.23305875038856078,
      "grad_norm": 0.47686097025871277,
      "learning_rate": 8.834706248057197e-06,
      "loss": 0.1305,
      "step": 2999
    },
    {
      "epoch": 0.23313646254274167,
      "grad_norm": 0.9763937592506409,
      "learning_rate": 8.834317687286292e-06,
      "loss": 0.8875,
      "step": 3000
    },
    {
      "epoch": 0.2332141746969226,
      "grad_norm": 0.29018163681030273,
      "learning_rate": 8.833929126515388e-06,
      "loss": 0.1777,
      "step": 3001
    },
    {
      "epoch": 0.23329188685110352,
      "grad_norm": 0.317708820104599,
      "learning_rate": 8.833540565744483e-06,
      "loss": 0.156,
      "step": 3002
    },
    {
      "epoch": 0.23336959900528442,
      "grad_norm": 0.240007683634758,
      "learning_rate": 8.833152004973578e-06,
      "loss": 0.1015,
      "step": 3003
    },
    {
      "epoch": 0.23344731115946535,
      "grad_norm": 0.23227116465568542,
      "learning_rate": 8.832763444202675e-06,
      "loss": 0.2212,
      "step": 3004
    },
    {
      "epoch": 0.23352502331364625,
      "grad_norm": 1.1956835985183716,
      "learning_rate": 8.832374883431768e-06,
      "loss": 0.4511,
      "step": 3005
    },
    {
      "epoch": 0.23360273546782717,
      "grad_norm": 0.27344533801078796,
      "learning_rate": 8.831986322660865e-06,
      "loss": 0.2457,
      "step": 3006
    },
    {
      "epoch": 0.23368044762200807,
      "grad_norm": 0.239047110080719,
      "learning_rate": 8.83159776188996e-06,
      "loss": 0.1745,
      "step": 3007
    },
    {
      "epoch": 0.233758159776189,
      "grad_norm": 0.6556106805801392,
      "learning_rate": 8.831209201119055e-06,
      "loss": 0.4366,
      "step": 3008
    },
    {
      "epoch": 0.23383587193036992,
      "grad_norm": 0.6619144082069397,
      "learning_rate": 8.830820640348151e-06,
      "loss": 0.5722,
      "step": 3009
    },
    {
      "epoch": 0.23391358408455082,
      "grad_norm": 0.4127400815486908,
      "learning_rate": 8.830432079577246e-06,
      "loss": 0.2276,
      "step": 3010
    },
    {
      "epoch": 0.23399129623873174,
      "grad_norm": 0.3432689607143402,
      "learning_rate": 8.830043518806341e-06,
      "loss": 0.0473,
      "step": 3011
    },
    {
      "epoch": 0.23406900839291264,
      "grad_norm": 0.2831232249736786,
      "learning_rate": 8.829654958035438e-06,
      "loss": 0.1284,
      "step": 3012
    },
    {
      "epoch": 0.23414672054709357,
      "grad_norm": 0.22562383115291595,
      "learning_rate": 8.829266397264533e-06,
      "loss": 0.1015,
      "step": 3013
    },
    {
      "epoch": 0.2342244327012745,
      "grad_norm": 0.3465140163898468,
      "learning_rate": 8.828877836493628e-06,
      "loss": 0.1766,
      "step": 3014
    },
    {
      "epoch": 0.2343021448554554,
      "grad_norm": 0.33021673560142517,
      "learning_rate": 8.828489275722723e-06,
      "loss": 0.3158,
      "step": 3015
    },
    {
      "epoch": 0.23437985700963632,
      "grad_norm": 0.3250997066497803,
      "learning_rate": 8.82810071495182e-06,
      "loss": 0.2722,
      "step": 3016
    },
    {
      "epoch": 0.23445756916381721,
      "grad_norm": 0.42219457030296326,
      "learning_rate": 8.827712154180914e-06,
      "loss": 0.2379,
      "step": 3017
    },
    {
      "epoch": 0.23453528131799814,
      "grad_norm": 1.7745237350463867,
      "learning_rate": 8.82732359341001e-06,
      "loss": 0.4639,
      "step": 3018
    },
    {
      "epoch": 0.23461299347217904,
      "grad_norm": 0.047856442630290985,
      "learning_rate": 8.826935032639106e-06,
      "loss": 0.011,
      "step": 3019
    },
    {
      "epoch": 0.23469070562635996,
      "grad_norm": 0.23500822484493256,
      "learning_rate": 8.826546471868201e-06,
      "loss": 0.171,
      "step": 3020
    },
    {
      "epoch": 0.2347684177805409,
      "grad_norm": 0.18116141855716705,
      "learning_rate": 8.826157911097296e-06,
      "loss": 0.0684,
      "step": 3021
    },
    {
      "epoch": 0.2348461299347218,
      "grad_norm": 0.09356504678726196,
      "learning_rate": 8.825769350326393e-06,
      "loss": 0.0666,
      "step": 3022
    },
    {
      "epoch": 0.2349238420889027,
      "grad_norm": 0.50616854429245,
      "learning_rate": 8.825380789555487e-06,
      "loss": 0.3124,
      "step": 3023
    },
    {
      "epoch": 0.2350015542430836,
      "grad_norm": 0.21514210104942322,
      "learning_rate": 8.824992228784582e-06,
      "loss": 0.1804,
      "step": 3024
    },
    {
      "epoch": 0.23507926639726454,
      "grad_norm": 0.18033388257026672,
      "learning_rate": 8.824603668013677e-06,
      "loss": 0.1248,
      "step": 3025
    },
    {
      "epoch": 0.23515697855144543,
      "grad_norm": 0.19054457545280457,
      "learning_rate": 8.824215107242774e-06,
      "loss": 0.1933,
      "step": 3026
    },
    {
      "epoch": 0.23523469070562636,
      "grad_norm": 0.16743624210357666,
      "learning_rate": 8.823826546471869e-06,
      "loss": 0.0504,
      "step": 3027
    },
    {
      "epoch": 0.23531240285980728,
      "grad_norm": 0.21550194919109344,
      "learning_rate": 8.823437985700964e-06,
      "loss": 0.0986,
      "step": 3028
    },
    {
      "epoch": 0.23539011501398818,
      "grad_norm": 0.16508057713508606,
      "learning_rate": 8.82304942493006e-06,
      "loss": 0.103,
      "step": 3029
    },
    {
      "epoch": 0.2354678271681691,
      "grad_norm": 0.05871710553765297,
      "learning_rate": 8.822660864159156e-06,
      "loss": 0.0197,
      "step": 3030
    },
    {
      "epoch": 0.23554553932235,
      "grad_norm": 0.1747780293226242,
      "learning_rate": 8.82227230338825e-06,
      "loss": 0.1355,
      "step": 3031
    },
    {
      "epoch": 0.23562325147653093,
      "grad_norm": 0.11267241835594177,
      "learning_rate": 8.821883742617347e-06,
      "loss": 0.0746,
      "step": 3032
    },
    {
      "epoch": 0.23570096363071186,
      "grad_norm": 0.07676882296800613,
      "learning_rate": 8.82149518184644e-06,
      "loss": 0.0234,
      "step": 3033
    },
    {
      "epoch": 0.23577867578489276,
      "grad_norm": 0.251933217048645,
      "learning_rate": 8.821106621075537e-06,
      "loss": 0.1446,
      "step": 3034
    },
    {
      "epoch": 0.23585638793907368,
      "grad_norm": 0.2526416778564453,
      "learning_rate": 8.820718060304632e-06,
      "loss": 0.0577,
      "step": 3035
    },
    {
      "epoch": 0.23593410009325458,
      "grad_norm": 0.3548762798309326,
      "learning_rate": 8.820329499533727e-06,
      "loss": 0.1967,
      "step": 3036
    },
    {
      "epoch": 0.2360118122474355,
      "grad_norm": 0.5695173740386963,
      "learning_rate": 8.819940938762824e-06,
      "loss": 0.1815,
      "step": 3037
    },
    {
      "epoch": 0.2360895244016164,
      "grad_norm": 0.40515249967575073,
      "learning_rate": 8.819552377991919e-06,
      "loss": 0.3438,
      "step": 3038
    },
    {
      "epoch": 0.23616723655579733,
      "grad_norm": 0.11932596564292908,
      "learning_rate": 8.819163817221013e-06,
      "loss": 0.0449,
      "step": 3039
    },
    {
      "epoch": 0.23624494870997825,
      "grad_norm": 0.24380774796009064,
      "learning_rate": 8.81877525645011e-06,
      "loss": 0.0892,
      "step": 3040
    },
    {
      "epoch": 0.23632266086415915,
      "grad_norm": 0.39197975397109985,
      "learning_rate": 8.818386695679205e-06,
      "loss": 0.2105,
      "step": 3041
    },
    {
      "epoch": 0.23640037301834008,
      "grad_norm": 0.17065177857875824,
      "learning_rate": 8.8179981349083e-06,
      "loss": 0.0648,
      "step": 3042
    },
    {
      "epoch": 0.23647808517252097,
      "grad_norm": 0.2810422480106354,
      "learning_rate": 8.817609574137395e-06,
      "loss": 0.1524,
      "step": 3043
    },
    {
      "epoch": 0.2365557973267019,
      "grad_norm": 0.41387680172920227,
      "learning_rate": 8.817221013366492e-06,
      "loss": 0.7393,
      "step": 3044
    },
    {
      "epoch": 0.2366335094808828,
      "grad_norm": 0.0664859488606453,
      "learning_rate": 8.816832452595587e-06,
      "loss": 0.0133,
      "step": 3045
    },
    {
      "epoch": 0.23671122163506372,
      "grad_norm": 0.3218437433242798,
      "learning_rate": 8.816443891824682e-06,
      "loss": 0.13,
      "step": 3046
    },
    {
      "epoch": 0.23678893378924465,
      "grad_norm": 0.6362038850784302,
      "learning_rate": 8.816055331053778e-06,
      "loss": 0.2585,
      "step": 3047
    },
    {
      "epoch": 0.23686664594342555,
      "grad_norm": 0.1419796347618103,
      "learning_rate": 8.815666770282873e-06,
      "loss": 0.0537,
      "step": 3048
    },
    {
      "epoch": 0.23694435809760647,
      "grad_norm": 0.6795649528503418,
      "learning_rate": 8.815278209511968e-06,
      "loss": 0.6331,
      "step": 3049
    },
    {
      "epoch": 0.23702207025178737,
      "grad_norm": 0.11521003395318985,
      "learning_rate": 8.814889648741065e-06,
      "loss": 0.0565,
      "step": 3050
    },
    {
      "epoch": 0.2370997824059683,
      "grad_norm": 0.8699342608451843,
      "learning_rate": 8.81450108797016e-06,
      "loss": 0.3642,
      "step": 3051
    },
    {
      "epoch": 0.2371774945601492,
      "grad_norm": 0.23400233685970306,
      "learning_rate": 8.814112527199255e-06,
      "loss": 0.1022,
      "step": 3052
    },
    {
      "epoch": 0.23725520671433012,
      "grad_norm": 0.3957660496234894,
      "learning_rate": 8.81372396642835e-06,
      "loss": 0.3392,
      "step": 3053
    },
    {
      "epoch": 0.23733291886851104,
      "grad_norm": 0.5034388303756714,
      "learning_rate": 8.813335405657446e-06,
      "loss": 0.3011,
      "step": 3054
    },
    {
      "epoch": 0.23741063102269194,
      "grad_norm": 0.18871209025382996,
      "learning_rate": 8.812946844886541e-06,
      "loss": 0.0502,
      "step": 3055
    },
    {
      "epoch": 0.23748834317687287,
      "grad_norm": 0.6291317939758301,
      "learning_rate": 8.812558284115636e-06,
      "loss": 0.3734,
      "step": 3056
    },
    {
      "epoch": 0.23756605533105377,
      "grad_norm": 0.27582696080207825,
      "learning_rate": 8.812169723344733e-06,
      "loss": 0.076,
      "step": 3057
    },
    {
      "epoch": 0.2376437674852347,
      "grad_norm": 0.2623122036457062,
      "learning_rate": 8.811781162573828e-06,
      "loss": 0.2386,
      "step": 3058
    },
    {
      "epoch": 0.23772147963941562,
      "grad_norm": 0.20006312429904938,
      "learning_rate": 8.811392601802923e-06,
      "loss": 0.1017,
      "step": 3059
    },
    {
      "epoch": 0.23779919179359651,
      "grad_norm": 0.5812804698944092,
      "learning_rate": 8.81100404103202e-06,
      "loss": 0.1656,
      "step": 3060
    },
    {
      "epoch": 0.23787690394777744,
      "grad_norm": 0.8198652863502502,
      "learning_rate": 8.810615480261113e-06,
      "loss": 0.3933,
      "step": 3061
    },
    {
      "epoch": 0.23795461610195834,
      "grad_norm": 0.2763974368572235,
      "learning_rate": 8.81022691949021e-06,
      "loss": 0.1157,
      "step": 3062
    },
    {
      "epoch": 0.23803232825613926,
      "grad_norm": 0.06151997298002243,
      "learning_rate": 8.809838358719304e-06,
      "loss": 0.0221,
      "step": 3063
    },
    {
      "epoch": 0.23811004041032016,
      "grad_norm": 0.3644651770591736,
      "learning_rate": 8.809449797948399e-06,
      "loss": 0.221,
      "step": 3064
    },
    {
      "epoch": 0.2381877525645011,
      "grad_norm": 0.6838482022285461,
      "learning_rate": 8.809061237177496e-06,
      "loss": 0.9366,
      "step": 3065
    },
    {
      "epoch": 0.238265464718682,
      "grad_norm": 0.45475682616233826,
      "learning_rate": 8.80867267640659e-06,
      "loss": 0.8088,
      "step": 3066
    },
    {
      "epoch": 0.2383431768728629,
      "grad_norm": 0.10513380169868469,
      "learning_rate": 8.808284115635686e-06,
      "loss": 0.24,
      "step": 3067
    },
    {
      "epoch": 0.23842088902704384,
      "grad_norm": 0.33802610635757446,
      "learning_rate": 8.807895554864782e-06,
      "loss": 0.1792,
      "step": 3068
    },
    {
      "epoch": 0.23849860118122473,
      "grad_norm": 0.0985596776008606,
      "learning_rate": 8.807506994093877e-06,
      "loss": 0.0367,
      "step": 3069
    },
    {
      "epoch": 0.23857631333540566,
      "grad_norm": 0.21107028424739838,
      "learning_rate": 8.807118433322972e-06,
      "loss": 0.1404,
      "step": 3070
    },
    {
      "epoch": 0.23865402548958656,
      "grad_norm": 0.1485813558101654,
      "learning_rate": 8.806729872552067e-06,
      "loss": 0.0528,
      "step": 3071
    },
    {
      "epoch": 0.23873173764376748,
      "grad_norm": 0.3760125935077667,
      "learning_rate": 8.806341311781164e-06,
      "loss": 0.1485,
      "step": 3072
    },
    {
      "epoch": 0.2388094497979484,
      "grad_norm": 0.6430431008338928,
      "learning_rate": 8.805952751010259e-06,
      "loss": 0.4049,
      "step": 3073
    },
    {
      "epoch": 0.2388871619521293,
      "grad_norm": 0.43952423334121704,
      "learning_rate": 8.805564190239354e-06,
      "loss": 0.1887,
      "step": 3074
    },
    {
      "epoch": 0.23896487410631023,
      "grad_norm": 0.15402604639530182,
      "learning_rate": 8.80517562946845e-06,
      "loss": 0.0728,
      "step": 3075
    },
    {
      "epoch": 0.23904258626049113,
      "grad_norm": 0.21066215634346008,
      "learning_rate": 8.804787068697545e-06,
      "loss": 0.1324,
      "step": 3076
    },
    {
      "epoch": 0.23912029841467206,
      "grad_norm": 0.18053129315376282,
      "learning_rate": 8.80439850792664e-06,
      "loss": 0.0944,
      "step": 3077
    },
    {
      "epoch": 0.23919801056885298,
      "grad_norm": 0.5876092314720154,
      "learning_rate": 8.804009947155737e-06,
      "loss": 0.5207,
      "step": 3078
    },
    {
      "epoch": 0.23927572272303388,
      "grad_norm": 0.2786107659339905,
      "learning_rate": 8.80362138638483e-06,
      "loss": 0.125,
      "step": 3079
    },
    {
      "epoch": 0.2393534348772148,
      "grad_norm": 0.24668529629707336,
      "learning_rate": 8.803232825613927e-06,
      "loss": 0.2359,
      "step": 3080
    },
    {
      "epoch": 0.2394311470313957,
      "grad_norm": 0.7570204138755798,
      "learning_rate": 8.802844264843022e-06,
      "loss": 0.3385,
      "step": 3081
    },
    {
      "epoch": 0.23950885918557663,
      "grad_norm": 0.2599862515926361,
      "learning_rate": 8.802455704072118e-06,
      "loss": 0.2733,
      "step": 3082
    },
    {
      "epoch": 0.23958657133975753,
      "grad_norm": 0.2782539129257202,
      "learning_rate": 8.802067143301213e-06,
      "loss": 0.1059,
      "step": 3083
    },
    {
      "epoch": 0.23966428349393845,
      "grad_norm": 0.42749106884002686,
      "learning_rate": 8.801678582530308e-06,
      "loss": 0.1943,
      "step": 3084
    },
    {
      "epoch": 0.23974199564811938,
      "grad_norm": 0.1730339676141739,
      "learning_rate": 8.801290021759405e-06,
      "loss": 0.1289,
      "step": 3085
    },
    {
      "epoch": 0.23981970780230027,
      "grad_norm": 0.16474194824695587,
      "learning_rate": 8.8009014609885e-06,
      "loss": 0.0622,
      "step": 3086
    },
    {
      "epoch": 0.2398974199564812,
      "grad_norm": 0.5712648630142212,
      "learning_rate": 8.800512900217595e-06,
      "loss": 0.2379,
      "step": 3087
    },
    {
      "epoch": 0.2399751321106621,
      "grad_norm": 0.8915818929672241,
      "learning_rate": 8.800124339446691e-06,
      "loss": 0.7081,
      "step": 3088
    },
    {
      "epoch": 0.24005284426484302,
      "grad_norm": 0.6637679934501648,
      "learning_rate": 8.799735778675785e-06,
      "loss": 0.3808,
      "step": 3089
    },
    {
      "epoch": 0.24013055641902392,
      "grad_norm": 0.20169079303741455,
      "learning_rate": 8.799347217904881e-06,
      "loss": 0.0889,
      "step": 3090
    },
    {
      "epoch": 0.24020826857320485,
      "grad_norm": 0.15446552634239197,
      "learning_rate": 8.798958657133976e-06,
      "loss": 0.1153,
      "step": 3091
    },
    {
      "epoch": 0.24028598072738577,
      "grad_norm": 0.2528165876865387,
      "learning_rate": 8.798570096363071e-06,
      "loss": 0.107,
      "step": 3092
    },
    {
      "epoch": 0.24036369288156667,
      "grad_norm": 0.16140523552894592,
      "learning_rate": 8.798181535592168e-06,
      "loss": 0.0933,
      "step": 3093
    },
    {
      "epoch": 0.2404414050357476,
      "grad_norm": 0.22401344776153564,
      "learning_rate": 8.797792974821263e-06,
      "loss": 0.1168,
      "step": 3094
    },
    {
      "epoch": 0.2405191171899285,
      "grad_norm": 0.2529163360595703,
      "learning_rate": 8.797404414050358e-06,
      "loss": 0.1481,
      "step": 3095
    },
    {
      "epoch": 0.24059682934410942,
      "grad_norm": 0.35095492005348206,
      "learning_rate": 8.797015853279454e-06,
      "loss": 0.235,
      "step": 3096
    },
    {
      "epoch": 0.24067454149829035,
      "grad_norm": 0.1839705854654312,
      "learning_rate": 8.79662729250855e-06,
      "loss": 0.1383,
      "step": 3097
    },
    {
      "epoch": 0.24075225365247124,
      "grad_norm": 0.31232428550720215,
      "learning_rate": 8.796238731737644e-06,
      "loss": 0.1527,
      "step": 3098
    },
    {
      "epoch": 0.24082996580665217,
      "grad_norm": 0.6059442758560181,
      "learning_rate": 8.79585017096674e-06,
      "loss": 0.4731,
      "step": 3099
    },
    {
      "epoch": 0.24090767796083307,
      "grad_norm": 0.3903593420982361,
      "learning_rate": 8.795461610195836e-06,
      "loss": 0.2117,
      "step": 3100
    },
    {
      "epoch": 0.240985390115014,
      "grad_norm": 0.024416273459792137,
      "learning_rate": 8.795073049424931e-06,
      "loss": 0.0067,
      "step": 3101
    },
    {
      "epoch": 0.2410631022691949,
      "grad_norm": 0.5682592988014221,
      "learning_rate": 8.794684488654026e-06,
      "loss": 0.5264,
      "step": 3102
    },
    {
      "epoch": 0.24114081442337582,
      "grad_norm": 0.21675275266170502,
      "learning_rate": 8.794295927883122e-06,
      "loss": 0.1583,
      "step": 3103
    },
    {
      "epoch": 0.24121852657755674,
      "grad_norm": 0.2239808440208435,
      "learning_rate": 8.793907367112217e-06,
      "loss": 0.1252,
      "step": 3104
    },
    {
      "epoch": 0.24129623873173764,
      "grad_norm": 0.21403667330741882,
      "learning_rate": 8.793518806341312e-06,
      "loss": 0.1136,
      "step": 3105
    },
    {
      "epoch": 0.24137395088591856,
      "grad_norm": 0.3242662250995636,
      "learning_rate": 8.793130245570409e-06,
      "loss": 0.1733,
      "step": 3106
    },
    {
      "epoch": 0.24145166304009946,
      "grad_norm": 0.3767741918563843,
      "learning_rate": 8.792741684799502e-06,
      "loss": 0.2184,
      "step": 3107
    },
    {
      "epoch": 0.2415293751942804,
      "grad_norm": 0.26623308658599854,
      "learning_rate": 8.792353124028599e-06,
      "loss": 0.0758,
      "step": 3108
    },
    {
      "epoch": 0.24160708734846129,
      "grad_norm": 0.5187866687774658,
      "learning_rate": 8.791964563257694e-06,
      "loss": 0.4869,
      "step": 3109
    },
    {
      "epoch": 0.2416847995026422,
      "grad_norm": 0.23292586207389832,
      "learning_rate": 8.791576002486789e-06,
      "loss": 0.0792,
      "step": 3110
    },
    {
      "epoch": 0.24176251165682314,
      "grad_norm": 0.46485188603401184,
      "learning_rate": 8.791187441715885e-06,
      "loss": 0.4555,
      "step": 3111
    },
    {
      "epoch": 0.24184022381100403,
      "grad_norm": 0.2057521939277649,
      "learning_rate": 8.79079888094498e-06,
      "loss": 0.0939,
      "step": 3112
    },
    {
      "epoch": 0.24191793596518496,
      "grad_norm": 0.43594762682914734,
      "learning_rate": 8.790410320174077e-06,
      "loss": 0.1984,
      "step": 3113
    },
    {
      "epoch": 0.24199564811936586,
      "grad_norm": 0.6409888863563538,
      "learning_rate": 8.790021759403172e-06,
      "loss": 0.5622,
      "step": 3114
    },
    {
      "epoch": 0.24207336027354678,
      "grad_norm": 0.18021957576274872,
      "learning_rate": 8.789633198632267e-06,
      "loss": 0.0671,
      "step": 3115
    },
    {
      "epoch": 0.2421510724277277,
      "grad_norm": 0.31749486923217773,
      "learning_rate": 8.789244637861364e-06,
      "loss": 0.1002,
      "step": 3116
    },
    {
      "epoch": 0.2422287845819086,
      "grad_norm": 0.06453169137239456,
      "learning_rate": 8.788856077090457e-06,
      "loss": 0.0219,
      "step": 3117
    },
    {
      "epoch": 0.24230649673608953,
      "grad_norm": 0.4321551024913788,
      "learning_rate": 8.788467516319553e-06,
      "loss": 0.3251,
      "step": 3118
    },
    {
      "epoch": 0.24238420889027043,
      "grad_norm": 0.07024185359477997,
      "learning_rate": 8.788078955548648e-06,
      "loss": 0.0233,
      "step": 3119
    },
    {
      "epoch": 0.24246192104445136,
      "grad_norm": 0.29690060019493103,
      "learning_rate": 8.787690394777743e-06,
      "loss": 0.6537,
      "step": 3120
    },
    {
      "epoch": 0.24253963319863225,
      "grad_norm": 1.2331002950668335,
      "learning_rate": 8.78730183400684e-06,
      "loss": 0.5912,
      "step": 3121
    },
    {
      "epoch": 0.24261734535281318,
      "grad_norm": 0.28702592849731445,
      "learning_rate": 8.786913273235935e-06,
      "loss": 0.0756,
      "step": 3122
    },
    {
      "epoch": 0.2426950575069941,
      "grad_norm": 0.22457058727741241,
      "learning_rate": 8.78652471246503e-06,
      "loss": 0.0614,
      "step": 3123
    },
    {
      "epoch": 0.242772769661175,
      "grad_norm": 0.7849388718605042,
      "learning_rate": 8.786136151694125e-06,
      "loss": 0.2144,
      "step": 3124
    },
    {
      "epoch": 0.24285048181535593,
      "grad_norm": 0.7030155062675476,
      "learning_rate": 8.785747590923222e-06,
      "loss": 0.9815,
      "step": 3125
    },
    {
      "epoch": 0.24292819396953683,
      "grad_norm": 0.25701162219047546,
      "learning_rate": 8.785359030152316e-06,
      "loss": 0.0531,
      "step": 3126
    },
    {
      "epoch": 0.24300590612371775,
      "grad_norm": 0.1653738170862198,
      "learning_rate": 8.784970469381411e-06,
      "loss": 0.0656,
      "step": 3127
    },
    {
      "epoch": 0.24308361827789865,
      "grad_norm": 0.2891876697540283,
      "learning_rate": 8.784581908610508e-06,
      "loss": 0.1429,
      "step": 3128
    },
    {
      "epoch": 0.24316133043207958,
      "grad_norm": 0.02112414315342903,
      "learning_rate": 8.784193347839603e-06,
      "loss": 0.0156,
      "step": 3129
    },
    {
      "epoch": 0.2432390425862605,
      "grad_norm": 0.5614455938339233,
      "learning_rate": 8.783804787068698e-06,
      "loss": 0.1085,
      "step": 3130
    },
    {
      "epoch": 0.2433167547404414,
      "grad_norm": 0.2763136327266693,
      "learning_rate": 8.783416226297795e-06,
      "loss": 0.3987,
      "step": 3131
    },
    {
      "epoch": 0.24339446689462232,
      "grad_norm": 0.39660096168518066,
      "learning_rate": 8.783027665526888e-06,
      "loss": 0.2871,
      "step": 3132
    },
    {
      "epoch": 0.24347217904880322,
      "grad_norm": 0.20579186081886292,
      "learning_rate": 8.782639104755984e-06,
      "loss": 0.0369,
      "step": 3133
    },
    {
      "epoch": 0.24354989120298415,
      "grad_norm": 0.3616730272769928,
      "learning_rate": 8.78225054398508e-06,
      "loss": 0.2298,
      "step": 3134
    },
    {
      "epoch": 0.24362760335716507,
      "grad_norm": 0.23517870903015137,
      "learning_rate": 8.781861983214174e-06,
      "loss": 0.0798,
      "step": 3135
    },
    {
      "epoch": 0.24370531551134597,
      "grad_norm": 0.5905671715736389,
      "learning_rate": 8.781473422443271e-06,
      "loss": 0.1817,
      "step": 3136
    },
    {
      "epoch": 0.2437830276655269,
      "grad_norm": 0.20023734867572784,
      "learning_rate": 8.781084861672366e-06,
      "loss": 0.0483,
      "step": 3137
    },
    {
      "epoch": 0.2438607398197078,
      "grad_norm": 0.07902077585458755,
      "learning_rate": 8.780696300901461e-06,
      "loss": 0.0239,
      "step": 3138
    },
    {
      "epoch": 0.24393845197388872,
      "grad_norm": 0.778833270072937,
      "learning_rate": 8.780307740130558e-06,
      "loss": 0.3873,
      "step": 3139
    },
    {
      "epoch": 0.24401616412806962,
      "grad_norm": 0.07290472835302353,
      "learning_rate": 8.779919179359653e-06,
      "loss": 0.0402,
      "step": 3140
    },
    {
      "epoch": 0.24409387628225054,
      "grad_norm": 0.346706360578537,
      "learning_rate": 8.779530618588747e-06,
      "loss": 0.1324,
      "step": 3141
    },
    {
      "epoch": 0.24417158843643147,
      "grad_norm": 0.3033488392829895,
      "learning_rate": 8.779142057817842e-06,
      "loss": 0.1473,
      "step": 3142
    },
    {
      "epoch": 0.24424930059061237,
      "grad_norm": 1.1859230995178223,
      "learning_rate": 8.778753497046939e-06,
      "loss": 0.6848,
      "step": 3143
    },
    {
      "epoch": 0.2443270127447933,
      "grad_norm": 0.3464723527431488,
      "learning_rate": 8.778364936276034e-06,
      "loss": 0.1236,
      "step": 3144
    },
    {
      "epoch": 0.2444047248989742,
      "grad_norm": 0.24063865840435028,
      "learning_rate": 8.777976375505129e-06,
      "loss": 0.2571,
      "step": 3145
    },
    {
      "epoch": 0.24448243705315512,
      "grad_norm": 0.4135192632675171,
      "learning_rate": 8.777587814734226e-06,
      "loss": 0.1628,
      "step": 3146
    },
    {
      "epoch": 0.24456014920733601,
      "grad_norm": 0.24338802695274353,
      "learning_rate": 8.77719925396332e-06,
      "loss": 0.2026,
      "step": 3147
    },
    {
      "epoch": 0.24463786136151694,
      "grad_norm": 0.024334250018000603,
      "learning_rate": 8.776810693192416e-06,
      "loss": 0.0519,
      "step": 3148
    },
    {
      "epoch": 0.24471557351569787,
      "grad_norm": 0.42537814378738403,
      "learning_rate": 8.776422132421512e-06,
      "loss": 0.2649,
      "step": 3149
    },
    {
      "epoch": 0.24479328566987876,
      "grad_norm": 0.39927685260772705,
      "learning_rate": 8.776033571650607e-06,
      "loss": 0.1803,
      "step": 3150
    },
    {
      "epoch": 0.2448709978240597,
      "grad_norm": 0.7884750962257385,
      "learning_rate": 8.775645010879702e-06,
      "loss": 0.5391,
      "step": 3151
    },
    {
      "epoch": 0.2449487099782406,
      "grad_norm": 0.3385779857635498,
      "learning_rate": 8.775256450108797e-06,
      "loss": 0.502,
      "step": 3152
    },
    {
      "epoch": 0.2450264221324215,
      "grad_norm": 0.39235934615135193,
      "learning_rate": 8.774867889337894e-06,
      "loss": 0.1624,
      "step": 3153
    },
    {
      "epoch": 0.24510413428660244,
      "grad_norm": 0.18558654189109802,
      "learning_rate": 8.774479328566989e-06,
      "loss": 0.1853,
      "step": 3154
    },
    {
      "epoch": 0.24518184644078334,
      "grad_norm": 0.17754128575325012,
      "learning_rate": 8.774090767796084e-06,
      "loss": 0.1424,
      "step": 3155
    },
    {
      "epoch": 0.24525955859496426,
      "grad_norm": 0.8229268193244934,
      "learning_rate": 8.77370220702518e-06,
      "loss": 0.4926,
      "step": 3156
    },
    {
      "epoch": 0.24533727074914516,
      "grad_norm": 0.20564036071300507,
      "learning_rate": 8.773313646254275e-06,
      "loss": 0.1059,
      "step": 3157
    },
    {
      "epoch": 0.24541498290332608,
      "grad_norm": 0.18621696531772614,
      "learning_rate": 8.77292508548337e-06,
      "loss": 0.1022,
      "step": 3158
    },
    {
      "epoch": 0.24549269505750698,
      "grad_norm": 0.2728096544742584,
      "learning_rate": 8.772536524712467e-06,
      "loss": 0.095,
      "step": 3159
    },
    {
      "epoch": 0.2455704072116879,
      "grad_norm": 0.1794906109571457,
      "learning_rate": 8.77214796394156e-06,
      "loss": 0.0876,
      "step": 3160
    },
    {
      "epoch": 0.24564811936586883,
      "grad_norm": 0.09753824770450592,
      "learning_rate": 8.771759403170657e-06,
      "loss": 0.0342,
      "step": 3161
    },
    {
      "epoch": 0.24572583152004973,
      "grad_norm": 0.15768256783485413,
      "learning_rate": 8.771370842399752e-06,
      "loss": 0.0454,
      "step": 3162
    },
    {
      "epoch": 0.24580354367423066,
      "grad_norm": 0.2827136218547821,
      "learning_rate": 8.770982281628847e-06,
      "loss": 0.1968,
      "step": 3163
    },
    {
      "epoch": 0.24588125582841155,
      "grad_norm": 0.2699601352214813,
      "learning_rate": 8.770593720857943e-06,
      "loss": 0.0782,
      "step": 3164
    },
    {
      "epoch": 0.24595896798259248,
      "grad_norm": 0.23400691151618958,
      "learning_rate": 8.770205160087038e-06,
      "loss": 0.132,
      "step": 3165
    },
    {
      "epoch": 0.24603668013677338,
      "grad_norm": 0.2179417461156845,
      "learning_rate": 8.769816599316133e-06,
      "loss": 0.1392,
      "step": 3166
    },
    {
      "epoch": 0.2461143922909543,
      "grad_norm": 0.15917618572711945,
      "learning_rate": 8.76942803854523e-06,
      "loss": 0.0532,
      "step": 3167
    },
    {
      "epoch": 0.24619210444513523,
      "grad_norm": 0.35150688886642456,
      "learning_rate": 8.769039477774325e-06,
      "loss": 0.1164,
      "step": 3168
    },
    {
      "epoch": 0.24626981659931613,
      "grad_norm": 0.8689576983451843,
      "learning_rate": 8.76865091700342e-06,
      "loss": 0.3339,
      "step": 3169
    },
    {
      "epoch": 0.24634752875349705,
      "grad_norm": 0.3165825605392456,
      "learning_rate": 8.768262356232515e-06,
      "loss": 0.4153,
      "step": 3170
    },
    {
      "epoch": 0.24642524090767795,
      "grad_norm": 0.511851966381073,
      "learning_rate": 8.767873795461611e-06,
      "loss": 0.3935,
      "step": 3171
    },
    {
      "epoch": 0.24650295306185888,
      "grad_norm": 0.2911279499530792,
      "learning_rate": 8.767485234690706e-06,
      "loss": 0.0655,
      "step": 3172
    },
    {
      "epoch": 0.2465806652160398,
      "grad_norm": 0.22669008374214172,
      "learning_rate": 8.767096673919801e-06,
      "loss": 0.0292,
      "step": 3173
    },
    {
      "epoch": 0.2466583773702207,
      "grad_norm": 0.11081533879041672,
      "learning_rate": 8.766708113148898e-06,
      "loss": 0.0541,
      "step": 3174
    },
    {
      "epoch": 0.24673608952440163,
      "grad_norm": 0.5610638856887817,
      "learning_rate": 8.766319552377993e-06,
      "loss": 0.3272,
      "step": 3175
    },
    {
      "epoch": 0.24681380167858252,
      "grad_norm": 0.25501927733421326,
      "learning_rate": 8.765930991607088e-06,
      "loss": 0.0858,
      "step": 3176
    },
    {
      "epoch": 0.24689151383276345,
      "grad_norm": 1.1071685552597046,
      "learning_rate": 8.765542430836184e-06,
      "loss": 0.4207,
      "step": 3177
    },
    {
      "epoch": 0.24696922598694435,
      "grad_norm": 0.11958986520767212,
      "learning_rate": 8.76515387006528e-06,
      "loss": 0.0665,
      "step": 3178
    },
    {
      "epoch": 0.24704693814112527,
      "grad_norm": 0.11702616512775421,
      "learning_rate": 8.764765309294374e-06,
      "loss": 0.0312,
      "step": 3179
    },
    {
      "epoch": 0.2471246502953062,
      "grad_norm": 0.27995240688323975,
      "learning_rate": 8.764376748523469e-06,
      "loss": 0.223,
      "step": 3180
    },
    {
      "epoch": 0.2472023624494871,
      "grad_norm": 0.33574193716049194,
      "learning_rate": 8.763988187752566e-06,
      "loss": 0.1103,
      "step": 3181
    },
    {
      "epoch": 0.24728007460366802,
      "grad_norm": 0.14936606585979462,
      "learning_rate": 8.76359962698166e-06,
      "loss": 0.1023,
      "step": 3182
    },
    {
      "epoch": 0.24735778675784892,
      "grad_norm": 0.22231976687908173,
      "learning_rate": 8.763211066210756e-06,
      "loss": 0.0425,
      "step": 3183
    },
    {
      "epoch": 0.24743549891202984,
      "grad_norm": 0.13057921826839447,
      "learning_rate": 8.762822505439852e-06,
      "loss": 0.071,
      "step": 3184
    },
    {
      "epoch": 0.24751321106621074,
      "grad_norm": 0.11772409826517105,
      "learning_rate": 8.762433944668947e-06,
      "loss": 0.0563,
      "step": 3185
    },
    {
      "epoch": 0.24759092322039167,
      "grad_norm": 0.09163752943277359,
      "learning_rate": 8.762045383898042e-06,
      "loss": 0.0358,
      "step": 3186
    },
    {
      "epoch": 0.2476686353745726,
      "grad_norm": 0.44347694516181946,
      "learning_rate": 8.761656823127139e-06,
      "loss": 0.2499,
      "step": 3187
    },
    {
      "epoch": 0.2477463475287535,
      "grad_norm": 0.6547426581382751,
      "learning_rate": 8.761268262356232e-06,
      "loss": 0.8037,
      "step": 3188
    },
    {
      "epoch": 0.24782405968293442,
      "grad_norm": 0.1247691959142685,
      "learning_rate": 8.760879701585329e-06,
      "loss": 0.021,
      "step": 3189
    },
    {
      "epoch": 0.24790177183711531,
      "grad_norm": 1.3177549839019775,
      "learning_rate": 8.760491140814424e-06,
      "loss": 0.2334,
      "step": 3190
    },
    {
      "epoch": 0.24797948399129624,
      "grad_norm": 0.11859609931707382,
      "learning_rate": 8.760102580043519e-06,
      "loss": 0.0677,
      "step": 3191
    },
    {
      "epoch": 0.24805719614547717,
      "grad_norm": 0.8636000156402588,
      "learning_rate": 8.759714019272615e-06,
      "loss": 0.7175,
      "step": 3192
    },
    {
      "epoch": 0.24813490829965806,
      "grad_norm": 0.14261355996131897,
      "learning_rate": 8.75932545850171e-06,
      "loss": 0.0674,
      "step": 3193
    },
    {
      "epoch": 0.248212620453839,
      "grad_norm": 0.15616966784000397,
      "learning_rate": 8.758936897730805e-06,
      "loss": 0.0416,
      "step": 3194
    },
    {
      "epoch": 0.2482903326080199,
      "grad_norm": 0.7371833920478821,
      "learning_rate": 8.758548336959902e-06,
      "loss": 0.1887,
      "step": 3195
    },
    {
      "epoch": 0.2483680447622008,
      "grad_norm": 0.8122747540473938,
      "learning_rate": 8.758159776188997e-06,
      "loss": 0.6998,
      "step": 3196
    },
    {
      "epoch": 0.2484457569163817,
      "grad_norm": 0.2113473117351532,
      "learning_rate": 8.757771215418092e-06,
      "loss": 0.13,
      "step": 3197
    },
    {
      "epoch": 0.24852346907056264,
      "grad_norm": 0.3337230086326599,
      "learning_rate": 8.757382654647187e-06,
      "loss": 0.1222,
      "step": 3198
    },
    {
      "epoch": 0.24860118122474356,
      "grad_norm": 0.16492265462875366,
      "learning_rate": 8.756994093876283e-06,
      "loss": 0.065,
      "step": 3199
    },
    {
      "epoch": 0.24867889337892446,
      "grad_norm": 0.1315564662218094,
      "learning_rate": 8.756605533105378e-06,
      "loss": 0.1058,
      "step": 3200
    },
    {
      "epoch": 0.24875660553310538,
      "grad_norm": 0.11534659564495087,
      "learning_rate": 8.756216972334473e-06,
      "loss": 0.0518,
      "step": 3201
    },
    {
      "epoch": 0.24883431768728628,
      "grad_norm": 0.4720132350921631,
      "learning_rate": 8.75582841156357e-06,
      "loss": 0.2618,
      "step": 3202
    },
    {
      "epoch": 0.2489120298414672,
      "grad_norm": 0.3152860403060913,
      "learning_rate": 8.755439850792665e-06,
      "loss": 0.3616,
      "step": 3203
    },
    {
      "epoch": 0.2489897419956481,
      "grad_norm": 0.5174407362937927,
      "learning_rate": 8.75505129002176e-06,
      "loss": 0.1785,
      "step": 3204
    },
    {
      "epoch": 0.24906745414982903,
      "grad_norm": 0.2983332574367523,
      "learning_rate": 8.754662729250856e-06,
      "loss": 0.1735,
      "step": 3205
    },
    {
      "epoch": 0.24914516630400996,
      "grad_norm": 0.22204086184501648,
      "learning_rate": 8.754274168479951e-06,
      "loss": 0.1371,
      "step": 3206
    },
    {
      "epoch": 0.24922287845819086,
      "grad_norm": 0.21249285340309143,
      "learning_rate": 8.753885607709046e-06,
      "loss": 0.0515,
      "step": 3207
    },
    {
      "epoch": 0.24930059061237178,
      "grad_norm": 0.5055368542671204,
      "learning_rate": 8.753497046938141e-06,
      "loss": 0.4343,
      "step": 3208
    },
    {
      "epoch": 0.24937830276655268,
      "grad_norm": 0.44498124718666077,
      "learning_rate": 8.753108486167238e-06,
      "loss": 0.4498,
      "step": 3209
    },
    {
      "epoch": 0.2494560149207336,
      "grad_norm": 0.3094707727432251,
      "learning_rate": 8.752719925396333e-06,
      "loss": 0.1685,
      "step": 3210
    },
    {
      "epoch": 0.24953372707491453,
      "grad_norm": 0.2833738327026367,
      "learning_rate": 8.752331364625428e-06,
      "loss": 0.1257,
      "step": 3211
    },
    {
      "epoch": 0.24961143922909543,
      "grad_norm": 0.5034091472625732,
      "learning_rate": 8.751942803854524e-06,
      "loss": 0.4345,
      "step": 3212
    },
    {
      "epoch": 0.24968915138327635,
      "grad_norm": 0.18023233115673065,
      "learning_rate": 8.75155424308362e-06,
      "loss": 0.1767,
      "step": 3213
    },
    {
      "epoch": 0.24976686353745725,
      "grad_norm": 0.4988015592098236,
      "learning_rate": 8.751165682312714e-06,
      "loss": 0.1453,
      "step": 3214
    },
    {
      "epoch": 0.24984457569163818,
      "grad_norm": 0.36083975434303284,
      "learning_rate": 8.750777121541811e-06,
      "loss": 0.6382,
      "step": 3215
    },
    {
      "epoch": 0.24992228784581907,
      "grad_norm": 0.99800044298172,
      "learning_rate": 8.750388560770904e-06,
      "loss": 0.6775,
      "step": 3216
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.31030863523483276,
      "learning_rate": 8.750000000000001e-06,
      "loss": 0.083,
      "step": 3217
    },
    {
      "epoch": 0.2500777121541809,
      "grad_norm": 0.819849967956543,
      "learning_rate": 8.749611439229096e-06,
      "loss": 0.3732,
      "step": 3218
    },
    {
      "epoch": 0.25015542430836185,
      "grad_norm": 0.05442260578274727,
      "learning_rate": 8.74922287845819e-06,
      "loss": 0.0149,
      "step": 3219
    },
    {
      "epoch": 0.25023313646254275,
      "grad_norm": 0.21273989975452423,
      "learning_rate": 8.748834317687287e-06,
      "loss": 0.0606,
      "step": 3220
    },
    {
      "epoch": 0.25031084861672365,
      "grad_norm": 0.39311885833740234,
      "learning_rate": 8.748445756916382e-06,
      "loss": 0.3236,
      "step": 3221
    },
    {
      "epoch": 0.25038856077090454,
      "grad_norm": 0.175133615732193,
      "learning_rate": 8.748057196145477e-06,
      "loss": 0.0435,
      "step": 3222
    },
    {
      "epoch": 0.2504662729250855,
      "grad_norm": 0.6680512428283691,
      "learning_rate": 8.747668635374574e-06,
      "loss": 0.329,
      "step": 3223
    },
    {
      "epoch": 0.2505439850792664,
      "grad_norm": 0.09990613162517548,
      "learning_rate": 8.747280074603669e-06,
      "loss": 0.0885,
      "step": 3224
    },
    {
      "epoch": 0.2506216972334473,
      "grad_norm": 0.08547071367502213,
      "learning_rate": 8.746891513832764e-06,
      "loss": 0.0286,
      "step": 3225
    },
    {
      "epoch": 0.25069940938762825,
      "grad_norm": 0.1676117330789566,
      "learning_rate": 8.746502953061859e-06,
      "loss": 0.0689,
      "step": 3226
    },
    {
      "epoch": 0.25077712154180914,
      "grad_norm": 0.12132038176059723,
      "learning_rate": 8.746114392290956e-06,
      "loss": 0.0549,
      "step": 3227
    },
    {
      "epoch": 0.25085483369599004,
      "grad_norm": 0.2487950176000595,
      "learning_rate": 8.74572583152005e-06,
      "loss": 0.1241,
      "step": 3228
    },
    {
      "epoch": 0.25093254585017094,
      "grad_norm": 0.1531788408756256,
      "learning_rate": 8.745337270749145e-06,
      "loss": 0.0633,
      "step": 3229
    },
    {
      "epoch": 0.2510102580043519,
      "grad_norm": 0.3185107111930847,
      "learning_rate": 8.744948709978242e-06,
      "loss": 0.2827,
      "step": 3230
    },
    {
      "epoch": 0.2510879701585328,
      "grad_norm": 0.24200120568275452,
      "learning_rate": 8.744560149207337e-06,
      "loss": 0.1383,
      "step": 3231
    },
    {
      "epoch": 0.2511656823127137,
      "grad_norm": 0.3856286108493805,
      "learning_rate": 8.744171588436432e-06,
      "loss": 0.3983,
      "step": 3232
    },
    {
      "epoch": 0.25124339446689464,
      "grad_norm": 0.10145042091608047,
      "learning_rate": 8.743783027665529e-06,
      "loss": 0.0112,
      "step": 3233
    },
    {
      "epoch": 0.25132110662107554,
      "grad_norm": 0.14642295241355896,
      "learning_rate": 8.743394466894624e-06,
      "loss": 0.0906,
      "step": 3234
    },
    {
      "epoch": 0.25139881877525644,
      "grad_norm": 0.13029924035072327,
      "learning_rate": 8.743005906123718e-06,
      "loss": 0.0864,
      "step": 3235
    },
    {
      "epoch": 0.25147653092943734,
      "grad_norm": 0.22328683733940125,
      "learning_rate": 8.742617345352813e-06,
      "loss": 0.073,
      "step": 3236
    },
    {
      "epoch": 0.2515542430836183,
      "grad_norm": 0.2177753746509552,
      "learning_rate": 8.74222878458191e-06,
      "loss": 0.1928,
      "step": 3237
    },
    {
      "epoch": 0.2516319552377992,
      "grad_norm": 0.28782331943511963,
      "learning_rate": 8.741840223811005e-06,
      "loss": 0.0903,
      "step": 3238
    },
    {
      "epoch": 0.2517096673919801,
      "grad_norm": 0.16678133606910706,
      "learning_rate": 8.7414516630401e-06,
      "loss": 0.1157,
      "step": 3239
    },
    {
      "epoch": 0.25178737954616104,
      "grad_norm": 0.25309109687805176,
      "learning_rate": 8.741063102269197e-06,
      "loss": 0.2452,
      "step": 3240
    },
    {
      "epoch": 0.25186509170034194,
      "grad_norm": 0.31428855657577515,
      "learning_rate": 8.740674541498292e-06,
      "loss": 0.1027,
      "step": 3241
    },
    {
      "epoch": 0.25194280385452283,
      "grad_norm": 0.26511579751968384,
      "learning_rate": 8.740285980727387e-06,
      "loss": 0.194,
      "step": 3242
    },
    {
      "epoch": 0.2520205160087038,
      "grad_norm": 0.6580858826637268,
      "learning_rate": 8.739897419956483e-06,
      "loss": 0.3155,
      "step": 3243
    },
    {
      "epoch": 0.2520982281628847,
      "grad_norm": 0.09061531722545624,
      "learning_rate": 8.739508859185576e-06,
      "loss": 0.0272,
      "step": 3244
    },
    {
      "epoch": 0.2521759403170656,
      "grad_norm": 0.062033966183662415,
      "learning_rate": 8.739120298414673e-06,
      "loss": 0.0137,
      "step": 3245
    },
    {
      "epoch": 0.2522536524712465,
      "grad_norm": 0.6954224109649658,
      "learning_rate": 8.738731737643768e-06,
      "loss": 0.4543,
      "step": 3246
    },
    {
      "epoch": 0.25233136462542743,
      "grad_norm": 0.04666152596473694,
      "learning_rate": 8.738343176872863e-06,
      "loss": 0.0056,
      "step": 3247
    },
    {
      "epoch": 0.25240907677960833,
      "grad_norm": 0.4253096580505371,
      "learning_rate": 8.73795461610196e-06,
      "loss": 0.4191,
      "step": 3248
    },
    {
      "epoch": 0.25248678893378923,
      "grad_norm": 0.06907105445861816,
      "learning_rate": 8.737566055331055e-06,
      "loss": 0.0124,
      "step": 3249
    },
    {
      "epoch": 0.2525645010879702,
      "grad_norm": 0.36357560753822327,
      "learning_rate": 8.73717749456015e-06,
      "loss": 0.1826,
      "step": 3250
    },
    {
      "epoch": 0.2526422132421511,
      "grad_norm": 0.13714364171028137,
      "learning_rate": 8.736788933789244e-06,
      "loss": 0.0574,
      "step": 3251
    },
    {
      "epoch": 0.252719925396332,
      "grad_norm": 0.16718409955501556,
      "learning_rate": 8.736400373018341e-06,
      "loss": 0.1489,
      "step": 3252
    },
    {
      "epoch": 0.2527976375505129,
      "grad_norm": 0.5614030957221985,
      "learning_rate": 8.736011812247436e-06,
      "loss": 0.7254,
      "step": 3253
    },
    {
      "epoch": 0.25287534970469383,
      "grad_norm": 0.17544178664684296,
      "learning_rate": 8.735623251476531e-06,
      "loss": 0.1005,
      "step": 3254
    },
    {
      "epoch": 0.25295306185887473,
      "grad_norm": 0.2665485143661499,
      "learning_rate": 8.735234690705628e-06,
      "loss": 0.1676,
      "step": 3255
    },
    {
      "epoch": 0.2530307740130556,
      "grad_norm": 0.16153474152088165,
      "learning_rate": 8.734846129934723e-06,
      "loss": 0.0425,
      "step": 3256
    },
    {
      "epoch": 0.2531084861672366,
      "grad_norm": 0.34706592559814453,
      "learning_rate": 8.734457569163818e-06,
      "loss": 0.4984,
      "step": 3257
    },
    {
      "epoch": 0.2531861983214175,
      "grad_norm": 0.5265898108482361,
      "learning_rate": 8.734069008392914e-06,
      "loss": 0.1025,
      "step": 3258
    },
    {
      "epoch": 0.2532639104755984,
      "grad_norm": 0.1511656492948532,
      "learning_rate": 8.733680447622007e-06,
      "loss": 0.1284,
      "step": 3259
    },
    {
      "epoch": 0.2533416226297793,
      "grad_norm": 0.34680843353271484,
      "learning_rate": 8.733291886851104e-06,
      "loss": 0.1278,
      "step": 3260
    },
    {
      "epoch": 0.2534193347839602,
      "grad_norm": 0.4855296313762665,
      "learning_rate": 8.732903326080199e-06,
      "loss": 0.2607,
      "step": 3261
    },
    {
      "epoch": 0.2534970469381411,
      "grad_norm": 0.39621561765670776,
      "learning_rate": 8.732514765309294e-06,
      "loss": 0.2859,
      "step": 3262
    },
    {
      "epoch": 0.253574759092322,
      "grad_norm": 0.11253418028354645,
      "learning_rate": 8.73212620453839e-06,
      "loss": 0.036,
      "step": 3263
    },
    {
      "epoch": 0.253652471246503,
      "grad_norm": 0.10023486614227295,
      "learning_rate": 8.731737643767486e-06,
      "loss": 0.0386,
      "step": 3264
    },
    {
      "epoch": 0.2537301834006839,
      "grad_norm": 0.3049840033054352,
      "learning_rate": 8.731349082996582e-06,
      "loss": 0.2996,
      "step": 3265
    },
    {
      "epoch": 0.25380789555486477,
      "grad_norm": 0.3867550790309906,
      "learning_rate": 8.730960522225677e-06,
      "loss": 0.1768,
      "step": 3266
    },
    {
      "epoch": 0.25388560770904567,
      "grad_norm": 0.4118008613586426,
      "learning_rate": 8.730571961454772e-06,
      "loss": 0.421,
      "step": 3267
    },
    {
      "epoch": 0.2539633198632266,
      "grad_norm": 0.7445043325424194,
      "learning_rate": 8.730183400683869e-06,
      "loss": 0.1406,
      "step": 3268
    },
    {
      "epoch": 0.2540410320174075,
      "grad_norm": 0.09090302884578705,
      "learning_rate": 8.729794839912962e-06,
      "loss": 0.0308,
      "step": 3269
    },
    {
      "epoch": 0.2541187441715884,
      "grad_norm": 0.11784712225198746,
      "learning_rate": 8.729406279142059e-06,
      "loss": 0.0257,
      "step": 3270
    },
    {
      "epoch": 0.25419645632576937,
      "grad_norm": 0.6624245047569275,
      "learning_rate": 8.729017718371154e-06,
      "loss": 0.1055,
      "step": 3271
    },
    {
      "epoch": 0.25427416847995027,
      "grad_norm": 1.644360065460205,
      "learning_rate": 8.728629157600249e-06,
      "loss": 0.5404,
      "step": 3272
    },
    {
      "epoch": 0.25435188063413117,
      "grad_norm": 0.3342156708240509,
      "learning_rate": 8.728240596829345e-06,
      "loss": 0.112,
      "step": 3273
    },
    {
      "epoch": 0.25442959278831206,
      "grad_norm": 0.3407919704914093,
      "learning_rate": 8.72785203605844e-06,
      "loss": 0.2698,
      "step": 3274
    },
    {
      "epoch": 0.254507304942493,
      "grad_norm": 0.1934661865234375,
      "learning_rate": 8.727463475287535e-06,
      "loss": 0.084,
      "step": 3275
    },
    {
      "epoch": 0.2545850170966739,
      "grad_norm": 0.45179253816604614,
      "learning_rate": 8.727074914516632e-06,
      "loss": 0.0623,
      "step": 3276
    },
    {
      "epoch": 0.2546627292508548,
      "grad_norm": 0.25506460666656494,
      "learning_rate": 8.726686353745727e-06,
      "loss": 0.1554,
      "step": 3277
    },
    {
      "epoch": 0.25474044140503577,
      "grad_norm": 0.5265932679176331,
      "learning_rate": 8.726297792974822e-06,
      "loss": 0.3909,
      "step": 3278
    },
    {
      "epoch": 0.25481815355921666,
      "grad_norm": 0.16801102459430695,
      "learning_rate": 8.725909232203917e-06,
      "loss": 0.0672,
      "step": 3279
    },
    {
      "epoch": 0.25489586571339756,
      "grad_norm": 0.4407947063446045,
      "learning_rate": 8.725520671433013e-06,
      "loss": 0.2274,
      "step": 3280
    },
    {
      "epoch": 0.2549735778675785,
      "grad_norm": 0.24876682460308075,
      "learning_rate": 8.725132110662108e-06,
      "loss": 0.2901,
      "step": 3281
    },
    {
      "epoch": 0.2550512900217594,
      "grad_norm": 0.5291720628738403,
      "learning_rate": 8.724743549891203e-06,
      "loss": 0.2868,
      "step": 3282
    },
    {
      "epoch": 0.2551290021759403,
      "grad_norm": 0.399178147315979,
      "learning_rate": 8.7243549891203e-06,
      "loss": 0.5583,
      "step": 3283
    },
    {
      "epoch": 0.2552067143301212,
      "grad_norm": 0.2349359691143036,
      "learning_rate": 8.723966428349395e-06,
      "loss": 0.3971,
      "step": 3284
    },
    {
      "epoch": 0.25528442648430216,
      "grad_norm": 0.563105046749115,
      "learning_rate": 8.72357786757849e-06,
      "loss": 0.6736,
      "step": 3285
    },
    {
      "epoch": 0.25536213863848306,
      "grad_norm": 0.07197447121143341,
      "learning_rate": 8.723189306807586e-06,
      "loss": 0.0212,
      "step": 3286
    },
    {
      "epoch": 0.25543985079266396,
      "grad_norm": 0.3890429437160492,
      "learning_rate": 8.72280074603668e-06,
      "loss": 0.4031,
      "step": 3287
    },
    {
      "epoch": 0.2555175629468449,
      "grad_norm": 0.2562018632888794,
      "learning_rate": 8.722412185265776e-06,
      "loss": 0.1978,
      "step": 3288
    },
    {
      "epoch": 0.2555952751010258,
      "grad_norm": 0.08514176309108734,
      "learning_rate": 8.722023624494871e-06,
      "loss": 0.0315,
      "step": 3289
    },
    {
      "epoch": 0.2556729872552067,
      "grad_norm": 0.705794095993042,
      "learning_rate": 8.721635063723966e-06,
      "loss": 0.507,
      "step": 3290
    },
    {
      "epoch": 0.2557506994093876,
      "grad_norm": 0.25935056805610657,
      "learning_rate": 8.721246502953063e-06,
      "loss": 0.2477,
      "step": 3291
    },
    {
      "epoch": 0.25582841156356856,
      "grad_norm": 0.44790375232696533,
      "learning_rate": 8.720857942182158e-06,
      "loss": 0.2272,
      "step": 3292
    },
    {
      "epoch": 0.25590612371774946,
      "grad_norm": 0.0555887296795845,
      "learning_rate": 8.720469381411254e-06,
      "loss": 0.0049,
      "step": 3293
    },
    {
      "epoch": 0.25598383587193035,
      "grad_norm": 0.20185410976409912,
      "learning_rate": 8.72008082064035e-06,
      "loss": 0.0652,
      "step": 3294
    },
    {
      "epoch": 0.2560615480261113,
      "grad_norm": 0.144134521484375,
      "learning_rate": 8.719692259869444e-06,
      "loss": 0.0339,
      "step": 3295
    },
    {
      "epoch": 0.2561392601802922,
      "grad_norm": 0.3929058909416199,
      "learning_rate": 8.719303699098541e-06,
      "loss": 0.1125,
      "step": 3296
    },
    {
      "epoch": 0.2562169723344731,
      "grad_norm": 0.07466192543506622,
      "learning_rate": 8.718915138327634e-06,
      "loss": 0.0145,
      "step": 3297
    },
    {
      "epoch": 0.256294684488654,
      "grad_norm": 0.16649159789085388,
      "learning_rate": 8.71852657755673e-06,
      "loss": 0.0526,
      "step": 3298
    },
    {
      "epoch": 0.25637239664283495,
      "grad_norm": 0.537823498249054,
      "learning_rate": 8.718138016785826e-06,
      "loss": 0.1764,
      "step": 3299
    },
    {
      "epoch": 0.25645010879701585,
      "grad_norm": 0.4946708679199219,
      "learning_rate": 8.71774945601492e-06,
      "loss": 0.3754,
      "step": 3300
    },
    {
      "epoch": 0.25652782095119675,
      "grad_norm": 0.4439387917518616,
      "learning_rate": 8.717360895244017e-06,
      "loss": 0.5281,
      "step": 3301
    },
    {
      "epoch": 0.2566055331053777,
      "grad_norm": 0.2100982517004013,
      "learning_rate": 8.716972334473112e-06,
      "loss": 0.0326,
      "step": 3302
    },
    {
      "epoch": 0.2566832452595586,
      "grad_norm": 0.5573500990867615,
      "learning_rate": 8.716583773702207e-06,
      "loss": 1.0735,
      "step": 3303
    },
    {
      "epoch": 0.2567609574137395,
      "grad_norm": 0.057722996920347214,
      "learning_rate": 8.716195212931304e-06,
      "loss": 0.0118,
      "step": 3304
    },
    {
      "epoch": 0.2568386695679204,
      "grad_norm": 0.22357070446014404,
      "learning_rate": 8.715806652160399e-06,
      "loss": 0.1619,
      "step": 3305
    },
    {
      "epoch": 0.25691638172210135,
      "grad_norm": 0.6972671747207642,
      "learning_rate": 8.715418091389494e-06,
      "loss": 0.1496,
      "step": 3306
    },
    {
      "epoch": 0.25699409387628225,
      "grad_norm": 0.24197079241275787,
      "learning_rate": 8.715029530618589e-06,
      "loss": 0.159,
      "step": 3307
    },
    {
      "epoch": 0.25707180603046315,
      "grad_norm": 0.3012678027153015,
      "learning_rate": 8.714640969847685e-06,
      "loss": 0.2163,
      "step": 3308
    },
    {
      "epoch": 0.2571495181846441,
      "grad_norm": 0.2389831393957138,
      "learning_rate": 8.71425240907678e-06,
      "loss": 0.0965,
      "step": 3309
    },
    {
      "epoch": 0.257227230338825,
      "grad_norm": 0.3010295629501343,
      "learning_rate": 8.713863848305875e-06,
      "loss": 0.1283,
      "step": 3310
    },
    {
      "epoch": 0.2573049424930059,
      "grad_norm": 0.024206258356571198,
      "learning_rate": 8.713475287534972e-06,
      "loss": 0.0038,
      "step": 3311
    },
    {
      "epoch": 0.2573826546471868,
      "grad_norm": 0.18962381780147552,
      "learning_rate": 8.713086726764067e-06,
      "loss": 0.1889,
      "step": 3312
    },
    {
      "epoch": 0.25746036680136775,
      "grad_norm": 0.3393409252166748,
      "learning_rate": 8.712698165993162e-06,
      "loss": 0.2007,
      "step": 3313
    },
    {
      "epoch": 0.25753807895554864,
      "grad_norm": 0.4542042016983032,
      "learning_rate": 8.712309605222258e-06,
      "loss": 0.3258,
      "step": 3314
    },
    {
      "epoch": 0.25761579110972954,
      "grad_norm": 0.499922513961792,
      "learning_rate": 8.711921044451352e-06,
      "loss": 0.231,
      "step": 3315
    },
    {
      "epoch": 0.2576935032639105,
      "grad_norm": 0.3228487968444824,
      "learning_rate": 8.711532483680448e-06,
      "loss": 0.3181,
      "step": 3316
    },
    {
      "epoch": 0.2577712154180914,
      "grad_norm": 0.540378987789154,
      "learning_rate": 8.711143922909543e-06,
      "loss": 0.7331,
      "step": 3317
    },
    {
      "epoch": 0.2578489275722723,
      "grad_norm": 0.07450249046087265,
      "learning_rate": 8.710755362138638e-06,
      "loss": 0.0288,
      "step": 3318
    },
    {
      "epoch": 0.25792663972645324,
      "grad_norm": 0.39343151450157166,
      "learning_rate": 8.710366801367735e-06,
      "loss": 0.1882,
      "step": 3319
    },
    {
      "epoch": 0.25800435188063414,
      "grad_norm": 0.25607597827911377,
      "learning_rate": 8.70997824059683e-06,
      "loss": 0.2019,
      "step": 3320
    },
    {
      "epoch": 0.25808206403481504,
      "grad_norm": 0.34937790036201477,
      "learning_rate": 8.709589679825925e-06,
      "loss": 0.0591,
      "step": 3321
    },
    {
      "epoch": 0.25815977618899594,
      "grad_norm": 0.3843088746070862,
      "learning_rate": 8.709201119055021e-06,
      "loss": 0.0994,
      "step": 3322
    },
    {
      "epoch": 0.2582374883431769,
      "grad_norm": 0.21585358679294586,
      "learning_rate": 8.708812558284116e-06,
      "loss": 0.1613,
      "step": 3323
    },
    {
      "epoch": 0.2583152004973578,
      "grad_norm": 0.44950178265571594,
      "learning_rate": 8.708423997513213e-06,
      "loss": 0.522,
      "step": 3324
    },
    {
      "epoch": 0.2583929126515387,
      "grad_norm": 0.5034496784210205,
      "learning_rate": 8.708035436742306e-06,
      "loss": 0.4294,
      "step": 3325
    },
    {
      "epoch": 0.25847062480571964,
      "grad_norm": 0.6029012799263,
      "learning_rate": 8.707646875971403e-06,
      "loss": 0.4028,
      "step": 3326
    },
    {
      "epoch": 0.25854833695990054,
      "grad_norm": 0.2611978054046631,
      "learning_rate": 8.707258315200498e-06,
      "loss": 0.1501,
      "step": 3327
    },
    {
      "epoch": 0.25862604911408144,
      "grad_norm": 0.28061044216156006,
      "learning_rate": 8.706869754429593e-06,
      "loss": 0.1708,
      "step": 3328
    },
    {
      "epoch": 0.25870376126826233,
      "grad_norm": 0.4174415171146393,
      "learning_rate": 8.70648119365869e-06,
      "loss": 0.5215,
      "step": 3329
    },
    {
      "epoch": 0.2587814734224433,
      "grad_norm": 0.28531554341316223,
      "learning_rate": 8.706092632887784e-06,
      "loss": 0.2342,
      "step": 3330
    },
    {
      "epoch": 0.2588591855766242,
      "grad_norm": 0.40085113048553467,
      "learning_rate": 8.70570407211688e-06,
      "loss": 0.2313,
      "step": 3331
    },
    {
      "epoch": 0.2589368977308051,
      "grad_norm": 0.22361986339092255,
      "learning_rate": 8.705315511345976e-06,
      "loss": 0.1658,
      "step": 3332
    },
    {
      "epoch": 0.25901460988498604,
      "grad_norm": 0.46874845027923584,
      "learning_rate": 8.704926950575071e-06,
      "loss": 0.298,
      "step": 3333
    },
    {
      "epoch": 0.25909232203916693,
      "grad_norm": 0.11365511268377304,
      "learning_rate": 8.704538389804166e-06,
      "loss": 0.0828,
      "step": 3334
    },
    {
      "epoch": 0.25917003419334783,
      "grad_norm": 0.3577476143836975,
      "learning_rate": 8.704149829033261e-06,
      "loss": 0.097,
      "step": 3335
    },
    {
      "epoch": 0.25924774634752873,
      "grad_norm": 0.3981248736381531,
      "learning_rate": 8.703761268262358e-06,
      "loss": 0.1822,
      "step": 3336
    },
    {
      "epoch": 0.2593254585017097,
      "grad_norm": 0.09445186704397202,
      "learning_rate": 8.703372707491452e-06,
      "loss": 0.0631,
      "step": 3337
    },
    {
      "epoch": 0.2594031706558906,
      "grad_norm": 0.43926310539245605,
      "learning_rate": 8.702984146720547e-06,
      "loss": 0.2746,
      "step": 3338
    },
    {
      "epoch": 0.2594808828100715,
      "grad_norm": 0.2573917806148529,
      "learning_rate": 8.702595585949644e-06,
      "loss": 0.0806,
      "step": 3339
    },
    {
      "epoch": 0.25955859496425243,
      "grad_norm": 0.3123973309993744,
      "learning_rate": 8.702207025178739e-06,
      "loss": 0.2115,
      "step": 3340
    },
    {
      "epoch": 0.25963630711843333,
      "grad_norm": 0.244545117020607,
      "learning_rate": 8.701818464407834e-06,
      "loss": 0.2283,
      "step": 3341
    },
    {
      "epoch": 0.2597140192726142,
      "grad_norm": 0.024488339200615883,
      "learning_rate": 8.70142990363693e-06,
      "loss": 0.0049,
      "step": 3342
    },
    {
      "epoch": 0.2597917314267951,
      "grad_norm": 0.5547782182693481,
      "learning_rate": 8.701041342866024e-06,
      "loss": 0.156,
      "step": 3343
    },
    {
      "epoch": 0.2598694435809761,
      "grad_norm": 0.9025100469589233,
      "learning_rate": 8.70065278209512e-06,
      "loss": 0.4092,
      "step": 3344
    },
    {
      "epoch": 0.259947155735157,
      "grad_norm": 1.0486152172088623,
      "learning_rate": 8.700264221324215e-06,
      "loss": 0.5781,
      "step": 3345
    },
    {
      "epoch": 0.2600248678893379,
      "grad_norm": 0.4392399489879608,
      "learning_rate": 8.69987566055331e-06,
      "loss": 0.177,
      "step": 3346
    },
    {
      "epoch": 0.2601025800435188,
      "grad_norm": 0.17928731441497803,
      "learning_rate": 8.699487099782407e-06,
      "loss": 0.0664,
      "step": 3347
    },
    {
      "epoch": 0.2601802921976997,
      "grad_norm": 0.22442778944969177,
      "learning_rate": 8.699098539011502e-06,
      "loss": 0.0665,
      "step": 3348
    },
    {
      "epoch": 0.2602580043518806,
      "grad_norm": 0.2882080078125,
      "learning_rate": 8.698709978240597e-06,
      "loss": 0.254,
      "step": 3349
    },
    {
      "epoch": 0.2603357165060615,
      "grad_norm": 0.315969318151474,
      "learning_rate": 8.698321417469694e-06,
      "loss": 0.0884,
      "step": 3350
    },
    {
      "epoch": 0.2604134286602425,
      "grad_norm": 0.2701258659362793,
      "learning_rate": 8.697932856698789e-06,
      "loss": 0.2653,
      "step": 3351
    },
    {
      "epoch": 0.26049114081442337,
      "grad_norm": 0.12881970405578613,
      "learning_rate": 8.697544295927884e-06,
      "loss": 0.0621,
      "step": 3352
    },
    {
      "epoch": 0.26056885296860427,
      "grad_norm": 0.30702874064445496,
      "learning_rate": 8.697155735156978e-06,
      "loss": 0.1648,
      "step": 3353
    },
    {
      "epoch": 0.2606465651227852,
      "grad_norm": 0.6419205665588379,
      "learning_rate": 8.696767174386075e-06,
      "loss": 0.2217,
      "step": 3354
    },
    {
      "epoch": 0.2607242772769661,
      "grad_norm": 0.3901556730270386,
      "learning_rate": 8.69637861361517e-06,
      "loss": 0.0521,
      "step": 3355
    },
    {
      "epoch": 0.260801989431147,
      "grad_norm": 0.2358175814151764,
      "learning_rate": 8.695990052844265e-06,
      "loss": 0.1515,
      "step": 3356
    },
    {
      "epoch": 0.26087970158532797,
      "grad_norm": 0.114377960562706,
      "learning_rate": 8.695601492073362e-06,
      "loss": 0.0278,
      "step": 3357
    },
    {
      "epoch": 0.26095741373950887,
      "grad_norm": 0.24881009757518768,
      "learning_rate": 8.695212931302457e-06,
      "loss": 0.1211,
      "step": 3358
    },
    {
      "epoch": 0.26103512589368977,
      "grad_norm": 0.30797865986824036,
      "learning_rate": 8.694824370531552e-06,
      "loss": 0.0924,
      "step": 3359
    },
    {
      "epoch": 0.26111283804787067,
      "grad_norm": 0.3303314447402954,
      "learning_rate": 8.694435809760648e-06,
      "loss": 0.1212,
      "step": 3360
    },
    {
      "epoch": 0.2611905502020516,
      "grad_norm": 0.30562078952789307,
      "learning_rate": 8.694047248989743e-06,
      "loss": 0.2299,
      "step": 3361
    },
    {
      "epoch": 0.2612682623562325,
      "grad_norm": 0.3353275656700134,
      "learning_rate": 8.693658688218838e-06,
      "loss": 0.146,
      "step": 3362
    },
    {
      "epoch": 0.2613459745104134,
      "grad_norm": 0.16844770312309265,
      "learning_rate": 8.693270127447933e-06,
      "loss": 0.073,
      "step": 3363
    },
    {
      "epoch": 0.26142368666459437,
      "grad_norm": 0.1832028031349182,
      "learning_rate": 8.69288156667703e-06,
      "loss": 0.2758,
      "step": 3364
    },
    {
      "epoch": 0.26150139881877527,
      "grad_norm": 0.49898120760917664,
      "learning_rate": 8.692493005906125e-06,
      "loss": 0.1236,
      "step": 3365
    },
    {
      "epoch": 0.26157911097295616,
      "grad_norm": 0.26452362537384033,
      "learning_rate": 8.69210444513522e-06,
      "loss": 0.1312,
      "step": 3366
    },
    {
      "epoch": 0.26165682312713706,
      "grad_norm": 0.4768025875091553,
      "learning_rate": 8.691715884364316e-06,
      "loss": 0.7877,
      "step": 3367
    },
    {
      "epoch": 0.261734535281318,
      "grad_norm": 0.5594495534896851,
      "learning_rate": 8.691327323593411e-06,
      "loss": 0.3543,
      "step": 3368
    },
    {
      "epoch": 0.2618122474354989,
      "grad_norm": 0.4019341766834259,
      "learning_rate": 8.690938762822506e-06,
      "loss": 0.2094,
      "step": 3369
    },
    {
      "epoch": 0.2618899595896798,
      "grad_norm": 0.17517173290252686,
      "learning_rate": 8.690550202051603e-06,
      "loss": 0.0432,
      "step": 3370
    },
    {
      "epoch": 0.26196767174386076,
      "grad_norm": 1.2490994930267334,
      "learning_rate": 8.690161641280696e-06,
      "loss": 0.8652,
      "step": 3371
    },
    {
      "epoch": 0.26204538389804166,
      "grad_norm": 0.44659513235092163,
      "learning_rate": 8.689773080509793e-06,
      "loss": 0.4692,
      "step": 3372
    },
    {
      "epoch": 0.26212309605222256,
      "grad_norm": 0.7406107783317566,
      "learning_rate": 8.689384519738888e-06,
      "loss": 0.4901,
      "step": 3373
    },
    {
      "epoch": 0.26220080820640346,
      "grad_norm": 0.5638347268104553,
      "learning_rate": 8.688995958967983e-06,
      "loss": 0.1759,
      "step": 3374
    },
    {
      "epoch": 0.2622785203605844,
      "grad_norm": 0.28959453105926514,
      "learning_rate": 8.68860739819708e-06,
      "loss": 0.1684,
      "step": 3375
    },
    {
      "epoch": 0.2623562325147653,
      "grad_norm": 0.37852317094802856,
      "learning_rate": 8.688218837426174e-06,
      "loss": 0.0965,
      "step": 3376
    },
    {
      "epoch": 0.2624339446689462,
      "grad_norm": 0.3192363381385803,
      "learning_rate": 8.687830276655269e-06,
      "loss": 0.0682,
      "step": 3377
    },
    {
      "epoch": 0.26251165682312716,
      "grad_norm": 0.2500675916671753,
      "learning_rate": 8.687441715884364e-06,
      "loss": 0.2099,
      "step": 3378
    },
    {
      "epoch": 0.26258936897730806,
      "grad_norm": 0.5619367957115173,
      "learning_rate": 8.68705315511346e-06,
      "loss": 0.4076,
      "step": 3379
    },
    {
      "epoch": 0.26266708113148896,
      "grad_norm": 0.32186245918273926,
      "learning_rate": 8.686664594342556e-06,
      "loss": 0.1874,
      "step": 3380
    },
    {
      "epoch": 0.26274479328566985,
      "grad_norm": 0.291474848985672,
      "learning_rate": 8.68627603357165e-06,
      "loss": 0.1222,
      "step": 3381
    },
    {
      "epoch": 0.2628225054398508,
      "grad_norm": 0.27188557386398315,
      "learning_rate": 8.685887472800747e-06,
      "loss": 0.0728,
      "step": 3382
    },
    {
      "epoch": 0.2629002175940317,
      "grad_norm": 0.23784653842449188,
      "learning_rate": 8.685498912029842e-06,
      "loss": 0.1798,
      "step": 3383
    },
    {
      "epoch": 0.2629779297482126,
      "grad_norm": 0.10303139686584473,
      "learning_rate": 8.685110351258937e-06,
      "loss": 0.0305,
      "step": 3384
    },
    {
      "epoch": 0.26305564190239356,
      "grad_norm": 0.29240185022354126,
      "learning_rate": 8.684721790488034e-06,
      "loss": 0.1177,
      "step": 3385
    },
    {
      "epoch": 0.26313335405657445,
      "grad_norm": 0.2148912400007248,
      "learning_rate": 8.684333229717129e-06,
      "loss": 0.4283,
      "step": 3386
    },
    {
      "epoch": 0.26321106621075535,
      "grad_norm": 0.3370007872581482,
      "learning_rate": 8.683944668946224e-06,
      "loss": 0.1614,
      "step": 3387
    },
    {
      "epoch": 0.26328877836493625,
      "grad_norm": 0.357604056596756,
      "learning_rate": 8.683556108175319e-06,
      "loss": 0.4031,
      "step": 3388
    },
    {
      "epoch": 0.2633664905191172,
      "grad_norm": 0.19225946068763733,
      "learning_rate": 8.683167547404415e-06,
      "loss": 0.0962,
      "step": 3389
    },
    {
      "epoch": 0.2634442026732981,
      "grad_norm": 0.42032891511917114,
      "learning_rate": 8.68277898663351e-06,
      "loss": 0.3227,
      "step": 3390
    },
    {
      "epoch": 0.263521914827479,
      "grad_norm": 0.3669973313808441,
      "learning_rate": 8.682390425862605e-06,
      "loss": 0.1257,
      "step": 3391
    },
    {
      "epoch": 0.26359962698165995,
      "grad_norm": 0.40025490522384644,
      "learning_rate": 8.682001865091702e-06,
      "loss": 0.2427,
      "step": 3392
    },
    {
      "epoch": 0.26367733913584085,
      "grad_norm": 0.28214189410209656,
      "learning_rate": 8.681613304320797e-06,
      "loss": 0.1848,
      "step": 3393
    },
    {
      "epoch": 0.26375505129002175,
      "grad_norm": 0.7205567955970764,
      "learning_rate": 8.681224743549892e-06,
      "loss": 0.4857,
      "step": 3394
    },
    {
      "epoch": 0.2638327634442027,
      "grad_norm": 0.5763928890228271,
      "learning_rate": 8.680836182778988e-06,
      "loss": 0.6999,
      "step": 3395
    },
    {
      "epoch": 0.2639104755983836,
      "grad_norm": 0.7655661702156067,
      "learning_rate": 8.680447622008082e-06,
      "loss": 0.319,
      "step": 3396
    },
    {
      "epoch": 0.2639881877525645,
      "grad_norm": 0.4144831597805023,
      "learning_rate": 8.680059061237178e-06,
      "loss": 0.6849,
      "step": 3397
    },
    {
      "epoch": 0.2640658999067454,
      "grad_norm": 0.2787758708000183,
      "learning_rate": 8.679670500466273e-06,
      "loss": 0.1846,
      "step": 3398
    },
    {
      "epoch": 0.26414361206092635,
      "grad_norm": 0.14069800078868866,
      "learning_rate": 8.679281939695368e-06,
      "loss": 0.0886,
      "step": 3399
    },
    {
      "epoch": 0.26422132421510724,
      "grad_norm": 0.39985334873199463,
      "learning_rate": 8.678893378924465e-06,
      "loss": 0.1474,
      "step": 3400
    },
    {
      "epoch": 0.26429903636928814,
      "grad_norm": 0.3188965618610382,
      "learning_rate": 8.67850481815356e-06,
      "loss": 0.0949,
      "step": 3401
    },
    {
      "epoch": 0.2643767485234691,
      "grad_norm": 0.3513151705265045,
      "learning_rate": 8.678116257382655e-06,
      "loss": 0.1704,
      "step": 3402
    },
    {
      "epoch": 0.26445446067765,
      "grad_norm": 0.3501304090023041,
      "learning_rate": 8.677727696611751e-06,
      "loss": 0.1946,
      "step": 3403
    },
    {
      "epoch": 0.2645321728318309,
      "grad_norm": 0.3200378119945526,
      "learning_rate": 8.677339135840846e-06,
      "loss": 0.2636,
      "step": 3404
    },
    {
      "epoch": 0.2646098849860118,
      "grad_norm": 0.19047768414020538,
      "learning_rate": 8.676950575069941e-06,
      "loss": 0.048,
      "step": 3405
    },
    {
      "epoch": 0.26468759714019274,
      "grad_norm": 0.278130441904068,
      "learning_rate": 8.676562014299036e-06,
      "loss": 0.1425,
      "step": 3406
    },
    {
      "epoch": 0.26476530929437364,
      "grad_norm": 0.2160927653312683,
      "learning_rate": 8.676173453528133e-06,
      "loss": 0.0968,
      "step": 3407
    },
    {
      "epoch": 0.26484302144855454,
      "grad_norm": 1.1094170808792114,
      "learning_rate": 8.675784892757228e-06,
      "loss": 0.1608,
      "step": 3408
    },
    {
      "epoch": 0.2649207336027355,
      "grad_norm": 0.3514721393585205,
      "learning_rate": 8.675396331986323e-06,
      "loss": 0.1081,
      "step": 3409
    },
    {
      "epoch": 0.2649984457569164,
      "grad_norm": 0.28772348165512085,
      "learning_rate": 8.67500777121542e-06,
      "loss": 0.0728,
      "step": 3410
    },
    {
      "epoch": 0.2650761579110973,
      "grad_norm": 0.20169509947299957,
      "learning_rate": 8.674619210444514e-06,
      "loss": 0.1089,
      "step": 3411
    },
    {
      "epoch": 0.2651538700652782,
      "grad_norm": 0.38704004883766174,
      "learning_rate": 8.67423064967361e-06,
      "loss": 0.1615,
      "step": 3412
    },
    {
      "epoch": 0.26523158221945914,
      "grad_norm": 1.113864779472351,
      "learning_rate": 8.673842088902706e-06,
      "loss": 0.537,
      "step": 3413
    },
    {
      "epoch": 0.26530929437364004,
      "grad_norm": 0.1635119915008545,
      "learning_rate": 8.6734535281318e-06,
      "loss": 0.0479,
      "step": 3414
    },
    {
      "epoch": 0.26538700652782093,
      "grad_norm": 0.2959243953227997,
      "learning_rate": 8.673064967360896e-06,
      "loss": 0.1512,
      "step": 3415
    },
    {
      "epoch": 0.2654647186820019,
      "grad_norm": 0.3004668056964874,
      "learning_rate": 8.67267640658999e-06,
      "loss": 0.2384,
      "step": 3416
    },
    {
      "epoch": 0.2655424308361828,
      "grad_norm": 0.06595171242952347,
      "learning_rate": 8.672287845819087e-06,
      "loss": 0.0177,
      "step": 3417
    },
    {
      "epoch": 0.2656201429903637,
      "grad_norm": 0.13041630387306213,
      "learning_rate": 8.671899285048182e-06,
      "loss": 0.0521,
      "step": 3418
    },
    {
      "epoch": 0.2656978551445446,
      "grad_norm": 0.2384592592716217,
      "learning_rate": 8.671510724277277e-06,
      "loss": 0.0956,
      "step": 3419
    },
    {
      "epoch": 0.26577556729872553,
      "grad_norm": 0.48880526423454285,
      "learning_rate": 8.671122163506374e-06,
      "loss": 0.2936,
      "step": 3420
    },
    {
      "epoch": 0.26585327945290643,
      "grad_norm": 0.18771256506443024,
      "learning_rate": 8.670733602735469e-06,
      "loss": 0.0655,
      "step": 3421
    },
    {
      "epoch": 0.26593099160708733,
      "grad_norm": 0.1962544023990631,
      "learning_rate": 8.670345041964564e-06,
      "loss": 0.0451,
      "step": 3422
    },
    {
      "epoch": 0.2660087037612683,
      "grad_norm": 0.35366684198379517,
      "learning_rate": 8.66995648119366e-06,
      "loss": 0.2858,
      "step": 3423
    },
    {
      "epoch": 0.2660864159154492,
      "grad_norm": 0.20858357846736908,
      "learning_rate": 8.669567920422754e-06,
      "loss": 0.0678,
      "step": 3424
    },
    {
      "epoch": 0.2661641280696301,
      "grad_norm": 0.11828119307756424,
      "learning_rate": 8.66917935965185e-06,
      "loss": 0.1023,
      "step": 3425
    },
    {
      "epoch": 0.266241840223811,
      "grad_norm": 0.1743604838848114,
      "learning_rate": 8.668790798880945e-06,
      "loss": 0.1016,
      "step": 3426
    },
    {
      "epoch": 0.26631955237799193,
      "grad_norm": 0.6753678321838379,
      "learning_rate": 8.66840223811004e-06,
      "loss": 1.0664,
      "step": 3427
    },
    {
      "epoch": 0.26639726453217283,
      "grad_norm": 0.5372357368469238,
      "learning_rate": 8.668013677339137e-06,
      "loss": 0.5506,
      "step": 3428
    },
    {
      "epoch": 0.2664749766863537,
      "grad_norm": 0.7098186612129211,
      "learning_rate": 8.667625116568232e-06,
      "loss": 0.2454,
      "step": 3429
    },
    {
      "epoch": 0.2665526888405347,
      "grad_norm": 0.2284127175807953,
      "learning_rate": 8.667236555797327e-06,
      "loss": 0.2472,
      "step": 3430
    },
    {
      "epoch": 0.2666304009947156,
      "grad_norm": 0.9486936926841736,
      "learning_rate": 8.666847995026424e-06,
      "loss": 0.5856,
      "step": 3431
    },
    {
      "epoch": 0.2667081131488965,
      "grad_norm": 0.4789370000362396,
      "learning_rate": 8.666459434255518e-06,
      "loss": 0.277,
      "step": 3432
    },
    {
      "epoch": 0.26678582530307743,
      "grad_norm": 0.7157869935035706,
      "learning_rate": 8.666070873484613e-06,
      "loss": 0.6017,
      "step": 3433
    },
    {
      "epoch": 0.2668635374572583,
      "grad_norm": 0.3524741530418396,
      "learning_rate": 8.665682312713708e-06,
      "loss": 0.1131,
      "step": 3434
    },
    {
      "epoch": 0.2669412496114392,
      "grad_norm": 0.40798547863960266,
      "learning_rate": 8.665293751942805e-06,
      "loss": 0.202,
      "step": 3435
    },
    {
      "epoch": 0.2670189617656201,
      "grad_norm": 0.30328917503356934,
      "learning_rate": 8.6649051911719e-06,
      "loss": 0.1474,
      "step": 3436
    },
    {
      "epoch": 0.2670966739198011,
      "grad_norm": 0.4760506749153137,
      "learning_rate": 8.664516630400995e-06,
      "loss": 0.4193,
      "step": 3437
    },
    {
      "epoch": 0.267174386073982,
      "grad_norm": 0.691088855266571,
      "learning_rate": 8.664128069630092e-06,
      "loss": 0.0834,
      "step": 3438
    },
    {
      "epoch": 0.26725209822816287,
      "grad_norm": 0.4696526825428009,
      "learning_rate": 8.663739508859187e-06,
      "loss": 0.1333,
      "step": 3439
    },
    {
      "epoch": 0.2673298103823438,
      "grad_norm": 0.3755817413330078,
      "learning_rate": 8.663350948088281e-06,
      "loss": 0.0916,
      "step": 3440
    },
    {
      "epoch": 0.2674075225365247,
      "grad_norm": 0.449138879776001,
      "learning_rate": 8.662962387317378e-06,
      "loss": 0.2519,
      "step": 3441
    },
    {
      "epoch": 0.2674852346907056,
      "grad_norm": 0.2278764694929123,
      "learning_rate": 8.662573826546471e-06,
      "loss": 0.2564,
      "step": 3442
    },
    {
      "epoch": 0.2675629468448865,
      "grad_norm": 0.36483660340309143,
      "learning_rate": 8.662185265775568e-06,
      "loss": 0.3462,
      "step": 3443
    },
    {
      "epoch": 0.26764065899906747,
      "grad_norm": 0.16441063582897186,
      "learning_rate": 8.661796705004663e-06,
      "loss": 0.1013,
      "step": 3444
    },
    {
      "epoch": 0.26771837115324837,
      "grad_norm": 0.3105882406234741,
      "learning_rate": 8.66140814423376e-06,
      "loss": 0.1108,
      "step": 3445
    },
    {
      "epoch": 0.26779608330742927,
      "grad_norm": 0.2417924553155899,
      "learning_rate": 8.661019583462855e-06,
      "loss": 0.0987,
      "step": 3446
    },
    {
      "epoch": 0.2678737954616102,
      "grad_norm": 0.265585720539093,
      "learning_rate": 8.66063102269195e-06,
      "loss": 0.0888,
      "step": 3447
    },
    {
      "epoch": 0.2679515076157911,
      "grad_norm": 0.2466905415058136,
      "learning_rate": 8.660242461921046e-06,
      "loss": 0.1087,
      "step": 3448
    },
    {
      "epoch": 0.268029219769972,
      "grad_norm": 0.33523109555244446,
      "learning_rate": 8.659853901150141e-06,
      "loss": 0.2204,
      "step": 3449
    },
    {
      "epoch": 0.2681069319241529,
      "grad_norm": 0.4341454803943634,
      "learning_rate": 8.659465340379236e-06,
      "loss": 0.1488,
      "step": 3450
    },
    {
      "epoch": 0.26818464407833387,
      "grad_norm": 0.33899232745170593,
      "learning_rate": 8.659076779608333e-06,
      "loss": 0.4054,
      "step": 3451
    },
    {
      "epoch": 0.26826235623251476,
      "grad_norm": 0.1471046358346939,
      "learning_rate": 8.658688218837426e-06,
      "loss": 0.0832,
      "step": 3452
    },
    {
      "epoch": 0.26834006838669566,
      "grad_norm": 0.4837466776371002,
      "learning_rate": 8.658299658066523e-06,
      "loss": 0.4072,
      "step": 3453
    },
    {
      "epoch": 0.2684177805408766,
      "grad_norm": 0.4260751008987427,
      "learning_rate": 8.657911097295618e-06,
      "loss": 0.318,
      "step": 3454
    },
    {
      "epoch": 0.2684954926950575,
      "grad_norm": 0.8384549617767334,
      "learning_rate": 8.657522536524712e-06,
      "loss": 0.2356,
      "step": 3455
    },
    {
      "epoch": 0.2685732048492384,
      "grad_norm": 0.3340362012386322,
      "learning_rate": 8.657133975753809e-06,
      "loss": 0.096,
      "step": 3456
    },
    {
      "epoch": 0.2686509170034193,
      "grad_norm": 0.13967208564281464,
      "learning_rate": 8.656745414982904e-06,
      "loss": 0.0582,
      "step": 3457
    },
    {
      "epoch": 0.26872862915760026,
      "grad_norm": 0.5128057599067688,
      "learning_rate": 8.656356854211999e-06,
      "loss": 0.7901,
      "step": 3458
    },
    {
      "epoch": 0.26880634131178116,
      "grad_norm": 0.22012749314308167,
      "learning_rate": 8.655968293441096e-06,
      "loss": 0.0972,
      "step": 3459
    },
    {
      "epoch": 0.26888405346596206,
      "grad_norm": 0.14145709574222565,
      "learning_rate": 8.65557973267019e-06,
      "loss": 0.0818,
      "step": 3460
    },
    {
      "epoch": 0.268961765620143,
      "grad_norm": 0.09029773622751236,
      "learning_rate": 8.655191171899286e-06,
      "loss": 0.0314,
      "step": 3461
    },
    {
      "epoch": 0.2690394777743239,
      "grad_norm": 0.4565448760986328,
      "learning_rate": 8.65480261112838e-06,
      "loss": 0.1679,
      "step": 3462
    },
    {
      "epoch": 0.2691171899285048,
      "grad_norm": 0.3710451126098633,
      "learning_rate": 8.654414050357477e-06,
      "loss": 0.1691,
      "step": 3463
    },
    {
      "epoch": 0.2691949020826857,
      "grad_norm": 0.4751390814781189,
      "learning_rate": 8.654025489586572e-06,
      "loss": 0.0638,
      "step": 3464
    },
    {
      "epoch": 0.26927261423686666,
      "grad_norm": 0.8492887616157532,
      "learning_rate": 8.653636928815667e-06,
      "loss": 0.2652,
      "step": 3465
    },
    {
      "epoch": 0.26935032639104756,
      "grad_norm": 0.3505918085575104,
      "learning_rate": 8.653248368044764e-06,
      "loss": 0.0639,
      "step": 3466
    },
    {
      "epoch": 0.26942803854522845,
      "grad_norm": 0.17384622991085052,
      "learning_rate": 8.652859807273859e-06,
      "loss": 0.1304,
      "step": 3467
    },
    {
      "epoch": 0.2695057506994094,
      "grad_norm": 0.2523513734340668,
      "learning_rate": 8.652471246502954e-06,
      "loss": 0.1286,
      "step": 3468
    },
    {
      "epoch": 0.2695834628535903,
      "grad_norm": 0.38518577814102173,
      "learning_rate": 8.65208268573205e-06,
      "loss": 0.2462,
      "step": 3469
    },
    {
      "epoch": 0.2696611750077712,
      "grad_norm": 0.3621896803379059,
      "learning_rate": 8.651694124961143e-06,
      "loss": 0.2445,
      "step": 3470
    },
    {
      "epoch": 0.26973888716195216,
      "grad_norm": 0.26766687631607056,
      "learning_rate": 8.65130556419024e-06,
      "loss": 0.1355,
      "step": 3471
    },
    {
      "epoch": 0.26981659931613305,
      "grad_norm": 0.5069516897201538,
      "learning_rate": 8.650917003419335e-06,
      "loss": 0.4876,
      "step": 3472
    },
    {
      "epoch": 0.26989431147031395,
      "grad_norm": 0.4389420449733734,
      "learning_rate": 8.65052844264843e-06,
      "loss": 0.2801,
      "step": 3473
    },
    {
      "epoch": 0.26997202362449485,
      "grad_norm": 0.1863439679145813,
      "learning_rate": 8.650139881877527e-06,
      "loss": 0.1309,
      "step": 3474
    },
    {
      "epoch": 0.2700497357786758,
      "grad_norm": 0.23158733546733856,
      "learning_rate": 8.649751321106622e-06,
      "loss": 0.0758,
      "step": 3475
    },
    {
      "epoch": 0.2701274479328567,
      "grad_norm": 0.44587159156799316,
      "learning_rate": 8.649362760335718e-06,
      "loss": 0.2361,
      "step": 3476
    },
    {
      "epoch": 0.2702051600870376,
      "grad_norm": 0.6150342226028442,
      "learning_rate": 8.648974199564813e-06,
      "loss": 0.5149,
      "step": 3477
    },
    {
      "epoch": 0.27028287224121855,
      "grad_norm": 0.8269214034080505,
      "learning_rate": 8.648585638793908e-06,
      "loss": 0.4338,
      "step": 3478
    },
    {
      "epoch": 0.27036058439539945,
      "grad_norm": 0.3498789966106415,
      "learning_rate": 8.648197078023005e-06,
      "loss": 0.5026,
      "step": 3479
    },
    {
      "epoch": 0.27043829654958035,
      "grad_norm": 0.23184986412525177,
      "learning_rate": 8.647808517252098e-06,
      "loss": 0.2179,
      "step": 3480
    },
    {
      "epoch": 0.27051600870376125,
      "grad_norm": 0.21683086454868317,
      "learning_rate": 8.647419956481195e-06,
      "loss": 0.1134,
      "step": 3481
    },
    {
      "epoch": 0.2705937208579422,
      "grad_norm": 0.2182929813861847,
      "learning_rate": 8.64703139571029e-06,
      "loss": 0.1959,
      "step": 3482
    },
    {
      "epoch": 0.2706714330121231,
      "grad_norm": 0.17723476886749268,
      "learning_rate": 8.646642834939385e-06,
      "loss": 0.0677,
      "step": 3483
    },
    {
      "epoch": 0.270749145166304,
      "grad_norm": 0.22619614005088806,
      "learning_rate": 8.646254274168481e-06,
      "loss": 0.0991,
      "step": 3484
    },
    {
      "epoch": 0.27082685732048495,
      "grad_norm": 0.5330379605293274,
      "learning_rate": 8.645865713397576e-06,
      "loss": 0.7106,
      "step": 3485
    },
    {
      "epoch": 0.27090456947466585,
      "grad_norm": 0.1812898963689804,
      "learning_rate": 8.645477152626671e-06,
      "loss": 0.0588,
      "step": 3486
    },
    {
      "epoch": 0.27098228162884674,
      "grad_norm": 0.23866011202335358,
      "learning_rate": 8.645088591855768e-06,
      "loss": 0.1486,
      "step": 3487
    },
    {
      "epoch": 0.27105999378302764,
      "grad_norm": 0.1855454444885254,
      "learning_rate": 8.644700031084863e-06,
      "loss": 0.081,
      "step": 3488
    },
    {
      "epoch": 0.2711377059372086,
      "grad_norm": 0.4398312270641327,
      "learning_rate": 8.644311470313958e-06,
      "loss": 0.1267,
      "step": 3489
    },
    {
      "epoch": 0.2712154180913895,
      "grad_norm": 0.28042352199554443,
      "learning_rate": 8.643922909543053e-06,
      "loss": 0.1743,
      "step": 3490
    },
    {
      "epoch": 0.2712931302455704,
      "grad_norm": 0.2768431305885315,
      "learning_rate": 8.64353434877215e-06,
      "loss": 0.1437,
      "step": 3491
    },
    {
      "epoch": 0.27137084239975134,
      "grad_norm": 0.5673483610153198,
      "learning_rate": 8.643145788001244e-06,
      "loss": 0.3664,
      "step": 3492
    },
    {
      "epoch": 0.27144855455393224,
      "grad_norm": 0.3181093633174896,
      "learning_rate": 8.64275722723034e-06,
      "loss": 0.1911,
      "step": 3493
    },
    {
      "epoch": 0.27152626670811314,
      "grad_norm": 0.4391370117664337,
      "learning_rate": 8.642368666459436e-06,
      "loss": 0.3095,
      "step": 3494
    },
    {
      "epoch": 0.27160397886229404,
      "grad_norm": 0.7250528931617737,
      "learning_rate": 8.64198010568853e-06,
      "loss": 0.292,
      "step": 3495
    },
    {
      "epoch": 0.271681691016475,
      "grad_norm": 0.9773755669593811,
      "learning_rate": 8.641591544917626e-06,
      "loss": 0.6731,
      "step": 3496
    },
    {
      "epoch": 0.2717594031706559,
      "grad_norm": 0.10870170593261719,
      "learning_rate": 8.64120298414672e-06,
      "loss": 0.024,
      "step": 3497
    },
    {
      "epoch": 0.2718371153248368,
      "grad_norm": 0.376830518245697,
      "learning_rate": 8.640814423375816e-06,
      "loss": 0.4044,
      "step": 3498
    },
    {
      "epoch": 0.27191482747901774,
      "grad_norm": 0.27142030000686646,
      "learning_rate": 8.640425862604912e-06,
      "loss": 0.2168,
      "step": 3499
    },
    {
      "epoch": 0.27199253963319864,
      "grad_norm": 0.40549996495246887,
      "learning_rate": 8.640037301834007e-06,
      "loss": 0.2042,
      "step": 3500
    },
    {
      "epoch": 0.27207025178737954,
      "grad_norm": 0.3919588327407837,
      "learning_rate": 8.639648741063102e-06,
      "loss": 0.1427,
      "step": 3501
    },
    {
      "epoch": 0.27214796394156043,
      "grad_norm": 0.3996240794658661,
      "learning_rate": 8.639260180292199e-06,
      "loss": 0.1464,
      "step": 3502
    },
    {
      "epoch": 0.2722256760957414,
      "grad_norm": 0.34459251165390015,
      "learning_rate": 8.638871619521294e-06,
      "loss": 0.7524,
      "step": 3503
    },
    {
      "epoch": 0.2723033882499223,
      "grad_norm": 0.42402949929237366,
      "learning_rate": 8.638483058750389e-06,
      "loss": 0.2148,
      "step": 3504
    },
    {
      "epoch": 0.2723811004041032,
      "grad_norm": 1.7794804573059082,
      "learning_rate": 8.638094497979484e-06,
      "loss": 0.2947,
      "step": 3505
    },
    {
      "epoch": 0.27245881255828414,
      "grad_norm": 0.12180893123149872,
      "learning_rate": 8.63770593720858e-06,
      "loss": 0.0617,
      "step": 3506
    },
    {
      "epoch": 0.27253652471246503,
      "grad_norm": 0.20357902348041534,
      "learning_rate": 8.637317376437675e-06,
      "loss": 0.1395,
      "step": 3507
    },
    {
      "epoch": 0.27261423686664593,
      "grad_norm": 0.18157915771007538,
      "learning_rate": 8.63692881566677e-06,
      "loss": 0.0696,
      "step": 3508
    },
    {
      "epoch": 0.2726919490208269,
      "grad_norm": 0.2070898413658142,
      "learning_rate": 8.636540254895867e-06,
      "loss": 0.0802,
      "step": 3509
    },
    {
      "epoch": 0.2727696611750078,
      "grad_norm": 0.3613315224647522,
      "learning_rate": 8.636151694124962e-06,
      "loss": 0.2873,
      "step": 3510
    },
    {
      "epoch": 0.2728473733291887,
      "grad_norm": 0.2530859708786011,
      "learning_rate": 8.635763133354057e-06,
      "loss": 0.1091,
      "step": 3511
    },
    {
      "epoch": 0.2729250854833696,
      "grad_norm": 0.1622982770204544,
      "learning_rate": 8.635374572583153e-06,
      "loss": 0.0779,
      "step": 3512
    },
    {
      "epoch": 0.27300279763755053,
      "grad_norm": 0.523992121219635,
      "learning_rate": 8.634986011812248e-06,
      "loss": 0.4528,
      "step": 3513
    },
    {
      "epoch": 0.27308050979173143,
      "grad_norm": 0.17425404489040375,
      "learning_rate": 8.634597451041343e-06,
      "loss": 0.0706,
      "step": 3514
    },
    {
      "epoch": 0.2731582219459123,
      "grad_norm": 0.1443803608417511,
      "learning_rate": 8.634208890270438e-06,
      "loss": 0.0441,
      "step": 3515
    },
    {
      "epoch": 0.2732359341000933,
      "grad_norm": 0.48529016971588135,
      "learning_rate": 8.633820329499535e-06,
      "loss": 0.3776,
      "step": 3516
    },
    {
      "epoch": 0.2733136462542742,
      "grad_norm": 0.6819028854370117,
      "learning_rate": 8.63343176872863e-06,
      "loss": 0.3112,
      "step": 3517
    },
    {
      "epoch": 0.2733913584084551,
      "grad_norm": 0.6117618680000305,
      "learning_rate": 8.633043207957725e-06,
      "loss": 0.0754,
      "step": 3518
    },
    {
      "epoch": 0.273469070562636,
      "grad_norm": 0.17863553762435913,
      "learning_rate": 8.632654647186821e-06,
      "loss": 0.0833,
      "step": 3519
    },
    {
      "epoch": 0.2735467827168169,
      "grad_norm": 0.1203877404332161,
      "learning_rate": 8.632266086415916e-06,
      "loss": 0.0743,
      "step": 3520
    },
    {
      "epoch": 0.2736244948709978,
      "grad_norm": 0.37159979343414307,
      "learning_rate": 8.631877525645011e-06,
      "loss": 0.3106,
      "step": 3521
    },
    {
      "epoch": 0.2737022070251787,
      "grad_norm": 0.19411379098892212,
      "learning_rate": 8.631488964874108e-06,
      "loss": 0.0739,
      "step": 3522
    },
    {
      "epoch": 0.2737799191793597,
      "grad_norm": 0.7026755809783936,
      "learning_rate": 8.631100404103201e-06,
      "loss": 0.147,
      "step": 3523
    },
    {
      "epoch": 0.2738576313335406,
      "grad_norm": 0.1461140662431717,
      "learning_rate": 8.630711843332298e-06,
      "loss": 0.0556,
      "step": 3524
    },
    {
      "epoch": 0.27393534348772147,
      "grad_norm": 0.2294112890958786,
      "learning_rate": 8.630323282561393e-06,
      "loss": 0.1087,
      "step": 3525
    },
    {
      "epoch": 0.27401305564190237,
      "grad_norm": 0.29978927969932556,
      "learning_rate": 8.629934721790488e-06,
      "loss": 0.1268,
      "step": 3526
    },
    {
      "epoch": 0.2740907677960833,
      "grad_norm": 0.35093507170677185,
      "learning_rate": 8.629546161019584e-06,
      "loss": 0.1589,
      "step": 3527
    },
    {
      "epoch": 0.2741684799502642,
      "grad_norm": 0.08218114823102951,
      "learning_rate": 8.62915760024868e-06,
      "loss": 0.0127,
      "step": 3528
    },
    {
      "epoch": 0.2742461921044451,
      "grad_norm": 0.16097447276115417,
      "learning_rate": 8.628769039477774e-06,
      "loss": 0.0807,
      "step": 3529
    },
    {
      "epoch": 0.2743239042586261,
      "grad_norm": 0.29306888580322266,
      "learning_rate": 8.628380478706871e-06,
      "loss": 0.1363,
      "step": 3530
    },
    {
      "epoch": 0.27440161641280697,
      "grad_norm": 0.35616791248321533,
      "learning_rate": 8.627991917935966e-06,
      "loss": 0.084,
      "step": 3531
    },
    {
      "epoch": 0.27447932856698787,
      "grad_norm": 0.31190934777259827,
      "learning_rate": 8.627603357165061e-06,
      "loss": 0.0769,
      "step": 3532
    },
    {
      "epoch": 0.27455704072116877,
      "grad_norm": 0.17200268805027008,
      "learning_rate": 8.627214796394156e-06,
      "loss": 0.0725,
      "step": 3533
    },
    {
      "epoch": 0.2746347528753497,
      "grad_norm": 0.12101568281650543,
      "learning_rate": 8.626826235623252e-06,
      "loss": 0.0331,
      "step": 3534
    },
    {
      "epoch": 0.2747124650295306,
      "grad_norm": 0.5570086240768433,
      "learning_rate": 8.626437674852347e-06,
      "loss": 0.1504,
      "step": 3535
    },
    {
      "epoch": 0.2747901771837115,
      "grad_norm": 0.4105927050113678,
      "learning_rate": 8.626049114081442e-06,
      "loss": 0.4393,
      "step": 3536
    },
    {
      "epoch": 0.27486788933789247,
      "grad_norm": 0.20866239070892334,
      "learning_rate": 8.625660553310539e-06,
      "loss": 0.0667,
      "step": 3537
    },
    {
      "epoch": 0.27494560149207337,
      "grad_norm": 0.7277289628982544,
      "learning_rate": 8.625271992539634e-06,
      "loss": 0.3083,
      "step": 3538
    },
    {
      "epoch": 0.27502331364625426,
      "grad_norm": 0.728655993938446,
      "learning_rate": 8.624883431768729e-06,
      "loss": 0.4578,
      "step": 3539
    },
    {
      "epoch": 0.27510102580043516,
      "grad_norm": 0.18569894134998322,
      "learning_rate": 8.624494870997826e-06,
      "loss": 0.0782,
      "step": 3540
    },
    {
      "epoch": 0.2751787379546161,
      "grad_norm": 0.44976648688316345,
      "learning_rate": 8.62410631022692e-06,
      "loss": 0.177,
      "step": 3541
    },
    {
      "epoch": 0.275256450108797,
      "grad_norm": 0.15842579305171967,
      "learning_rate": 8.623717749456015e-06,
      "loss": 0.0627,
      "step": 3542
    },
    {
      "epoch": 0.2753341622629779,
      "grad_norm": 0.27781108021736145,
      "learning_rate": 8.62332918868511e-06,
      "loss": 0.4322,
      "step": 3543
    },
    {
      "epoch": 0.27541187441715886,
      "grad_norm": 0.8110105991363525,
      "learning_rate": 8.622940627914207e-06,
      "loss": 0.1497,
      "step": 3544
    },
    {
      "epoch": 0.27548958657133976,
      "grad_norm": 0.15791217982769012,
      "learning_rate": 8.622552067143302e-06,
      "loss": 0.1134,
      "step": 3545
    },
    {
      "epoch": 0.27556729872552066,
      "grad_norm": 0.44838184118270874,
      "learning_rate": 8.622163506372397e-06,
      "loss": 0.2701,
      "step": 3546
    },
    {
      "epoch": 0.2756450108797016,
      "grad_norm": 0.23031142354011536,
      "learning_rate": 8.621774945601494e-06,
      "loss": 0.0532,
      "step": 3547
    },
    {
      "epoch": 0.2757227230338825,
      "grad_norm": 0.5120829939842224,
      "learning_rate": 8.621386384830589e-06,
      "loss": 0.4099,
      "step": 3548
    },
    {
      "epoch": 0.2758004351880634,
      "grad_norm": 0.12671403586864471,
      "learning_rate": 8.620997824059683e-06,
      "loss": 0.0866,
      "step": 3549
    },
    {
      "epoch": 0.2758781473422443,
      "grad_norm": 0.275333046913147,
      "learning_rate": 8.62060926328878e-06,
      "loss": 0.1649,
      "step": 3550
    },
    {
      "epoch": 0.27595585949642526,
      "grad_norm": 0.4034195840358734,
      "learning_rate": 8.620220702517873e-06,
      "loss": 0.1026,
      "step": 3551
    },
    {
      "epoch": 0.27603357165060616,
      "grad_norm": 0.23379576206207275,
      "learning_rate": 8.61983214174697e-06,
      "loss": 0.1272,
      "step": 3552
    },
    {
      "epoch": 0.27611128380478706,
      "grad_norm": 0.3670170307159424,
      "learning_rate": 8.619443580976065e-06,
      "loss": 0.1434,
      "step": 3553
    },
    {
      "epoch": 0.276188995958968,
      "grad_norm": 2.4051599502563477,
      "learning_rate": 8.61905502020516e-06,
      "loss": 0.0802,
      "step": 3554
    },
    {
      "epoch": 0.2762667081131489,
      "grad_norm": 0.12097039818763733,
      "learning_rate": 8.618666459434257e-06,
      "loss": 0.0639,
      "step": 3555
    },
    {
      "epoch": 0.2763444202673298,
      "grad_norm": 0.42039820551872253,
      "learning_rate": 8.618277898663352e-06,
      "loss": 0.2031,
      "step": 3556
    },
    {
      "epoch": 0.2764221324215107,
      "grad_norm": 0.8312196135520935,
      "learning_rate": 8.617889337892446e-06,
      "loss": 0.427,
      "step": 3557
    },
    {
      "epoch": 0.27649984457569166,
      "grad_norm": 0.46089574694633484,
      "learning_rate": 8.617500777121543e-06,
      "loss": 0.1326,
      "step": 3558
    },
    {
      "epoch": 0.27657755672987255,
      "grad_norm": 0.11844765394926071,
      "learning_rate": 8.617112216350638e-06,
      "loss": 0.0469,
      "step": 3559
    },
    {
      "epoch": 0.27665526888405345,
      "grad_norm": 0.26122376322746277,
      "learning_rate": 8.616723655579733e-06,
      "loss": 0.1044,
      "step": 3560
    },
    {
      "epoch": 0.2767329810382344,
      "grad_norm": 0.1838594526052475,
      "learning_rate": 8.616335094808828e-06,
      "loss": 0.1378,
      "step": 3561
    },
    {
      "epoch": 0.2768106931924153,
      "grad_norm": 0.4060819447040558,
      "learning_rate": 8.615946534037925e-06,
      "loss": 0.1372,
      "step": 3562
    },
    {
      "epoch": 0.2768884053465962,
      "grad_norm": 0.9145359992980957,
      "learning_rate": 8.61555797326702e-06,
      "loss": 0.7548,
      "step": 3563
    },
    {
      "epoch": 0.2769661175007771,
      "grad_norm": 0.4036366045475006,
      "learning_rate": 8.615169412496115e-06,
      "loss": 0.1448,
      "step": 3564
    },
    {
      "epoch": 0.27704382965495805,
      "grad_norm": 0.27679768204689026,
      "learning_rate": 8.614780851725211e-06,
      "loss": 0.2741,
      "step": 3565
    },
    {
      "epoch": 0.27712154180913895,
      "grad_norm": 0.2882368862628937,
      "learning_rate": 8.614392290954306e-06,
      "loss": 0.0991,
      "step": 3566
    },
    {
      "epoch": 0.27719925396331985,
      "grad_norm": 0.3921625018119812,
      "learning_rate": 8.614003730183401e-06,
      "loss": 0.2834,
      "step": 3567
    },
    {
      "epoch": 0.2772769661175008,
      "grad_norm": 0.061226729303598404,
      "learning_rate": 8.613615169412498e-06,
      "loss": 0.0118,
      "step": 3568
    },
    {
      "epoch": 0.2773546782716817,
      "grad_norm": 0.40907013416290283,
      "learning_rate": 8.613226608641593e-06,
      "loss": 0.132,
      "step": 3569
    },
    {
      "epoch": 0.2774323904258626,
      "grad_norm": 0.6171413064002991,
      "learning_rate": 8.612838047870688e-06,
      "loss": 0.3722,
      "step": 3570
    },
    {
      "epoch": 0.2775101025800435,
      "grad_norm": 0.32698535919189453,
      "learning_rate": 8.612449487099783e-06,
      "loss": 0.5184,
      "step": 3571
    },
    {
      "epoch": 0.27758781473422445,
      "grad_norm": 0.08980563282966614,
      "learning_rate": 8.61206092632888e-06,
      "loss": 0.0483,
      "step": 3572
    },
    {
      "epoch": 0.27766552688840535,
      "grad_norm": 0.5660918354988098,
      "learning_rate": 8.611672365557974e-06,
      "loss": 0.2292,
      "step": 3573
    },
    {
      "epoch": 0.27774323904258624,
      "grad_norm": 0.47961702942848206,
      "learning_rate": 8.611283804787069e-06,
      "loss": 0.2236,
      "step": 3574
    },
    {
      "epoch": 0.2778209511967672,
      "grad_norm": 0.1459193378686905,
      "learning_rate": 8.610895244016166e-06,
      "loss": 0.1566,
      "step": 3575
    },
    {
      "epoch": 0.2778986633509481,
      "grad_norm": 0.3536983132362366,
      "learning_rate": 8.61050668324526e-06,
      "loss": 0.0635,
      "step": 3576
    },
    {
      "epoch": 0.277976375505129,
      "grad_norm": 0.6622627377510071,
      "learning_rate": 8.610118122474356e-06,
      "loss": 0.3899,
      "step": 3577
    },
    {
      "epoch": 0.2780540876593099,
      "grad_norm": 1.289451003074646,
      "learning_rate": 8.609729561703452e-06,
      "loss": 0.42,
      "step": 3578
    },
    {
      "epoch": 0.27813179981349084,
      "grad_norm": 0.07709097862243652,
      "learning_rate": 8.609341000932546e-06,
      "loss": 0.0098,
      "step": 3579
    },
    {
      "epoch": 0.27820951196767174,
      "grad_norm": 0.0706334114074707,
      "learning_rate": 8.608952440161642e-06,
      "loss": 0.0187,
      "step": 3580
    },
    {
      "epoch": 0.27828722412185264,
      "grad_norm": 0.3043144643306732,
      "learning_rate": 8.608563879390737e-06,
      "loss": 0.072,
      "step": 3581
    },
    {
      "epoch": 0.2783649362760336,
      "grad_norm": 0.512832760810852,
      "learning_rate": 8.608175318619832e-06,
      "loss": 0.1677,
      "step": 3582
    },
    {
      "epoch": 0.2784426484302145,
      "grad_norm": 0.4722461998462677,
      "learning_rate": 8.607786757848929e-06,
      "loss": 0.3535,
      "step": 3583
    },
    {
      "epoch": 0.2785203605843954,
      "grad_norm": 0.4271574020385742,
      "learning_rate": 8.607398197078024e-06,
      "loss": 0.2641,
      "step": 3584
    },
    {
      "epoch": 0.2785980727385763,
      "grad_norm": 0.17736698687076569,
      "learning_rate": 8.607009636307119e-06,
      "loss": 0.0897,
      "step": 3585
    },
    {
      "epoch": 0.27867578489275724,
      "grad_norm": 0.1601351648569107,
      "learning_rate": 8.606621075536215e-06,
      "loss": 0.1033,
      "step": 3586
    },
    {
      "epoch": 0.27875349704693814,
      "grad_norm": 0.32555413246154785,
      "learning_rate": 8.60623251476531e-06,
      "loss": 0.1021,
      "step": 3587
    },
    {
      "epoch": 0.27883120920111903,
      "grad_norm": 1.5037897825241089,
      "learning_rate": 8.605843953994405e-06,
      "loss": 0.3236,
      "step": 3588
    },
    {
      "epoch": 0.2789089213553,
      "grad_norm": 0.8595836758613586,
      "learning_rate": 8.6054553932235e-06,
      "loss": 0.7742,
      "step": 3589
    },
    {
      "epoch": 0.2789866335094809,
      "grad_norm": 0.2139735072851181,
      "learning_rate": 8.605066832452597e-06,
      "loss": 0.0908,
      "step": 3590
    },
    {
      "epoch": 0.2790643456636618,
      "grad_norm": 0.36566635966300964,
      "learning_rate": 8.604678271681692e-06,
      "loss": 0.0789,
      "step": 3591
    },
    {
      "epoch": 0.27914205781784274,
      "grad_norm": 0.15867334604263306,
      "learning_rate": 8.604289710910787e-06,
      "loss": 0.0761,
      "step": 3592
    },
    {
      "epoch": 0.27921976997202363,
      "grad_norm": 0.46138161420822144,
      "learning_rate": 8.603901150139883e-06,
      "loss": 0.4192,
      "step": 3593
    },
    {
      "epoch": 0.27929748212620453,
      "grad_norm": 0.1542886197566986,
      "learning_rate": 8.603512589368978e-06,
      "loss": 0.112,
      "step": 3594
    },
    {
      "epoch": 0.27937519428038543,
      "grad_norm": 0.2904740571975708,
      "learning_rate": 8.603124028598073e-06,
      "loss": 0.5234,
      "step": 3595
    },
    {
      "epoch": 0.2794529064345664,
      "grad_norm": 0.14536252617835999,
      "learning_rate": 8.60273546782717e-06,
      "loss": 0.0548,
      "step": 3596
    },
    {
      "epoch": 0.2795306185887473,
      "grad_norm": 0.303545206785202,
      "learning_rate": 8.602346907056265e-06,
      "loss": 0.2467,
      "step": 3597
    },
    {
      "epoch": 0.2796083307429282,
      "grad_norm": 0.26539552211761475,
      "learning_rate": 8.60195834628536e-06,
      "loss": 0.1906,
      "step": 3598
    },
    {
      "epoch": 0.27968604289710913,
      "grad_norm": 0.10920743644237518,
      "learning_rate": 8.601569785514455e-06,
      "loss": 0.061,
      "step": 3599
    },
    {
      "epoch": 0.27976375505129003,
      "grad_norm": 0.2923983037471771,
      "learning_rate": 8.601181224743551e-06,
      "loss": 0.1509,
      "step": 3600
    },
    {
      "epoch": 0.27984146720547093,
      "grad_norm": 0.2559923231601715,
      "learning_rate": 8.600792663972646e-06,
      "loss": 0.1679,
      "step": 3601
    },
    {
      "epoch": 0.2799191793596518,
      "grad_norm": 0.10088949650526047,
      "learning_rate": 8.600404103201741e-06,
      "loss": 0.0201,
      "step": 3602
    },
    {
      "epoch": 0.2799968915138328,
      "grad_norm": 0.37914758920669556,
      "learning_rate": 8.600015542430838e-06,
      "loss": 0.0284,
      "step": 3603
    },
    {
      "epoch": 0.2800746036680137,
      "grad_norm": 0.46703633666038513,
      "learning_rate": 8.599626981659933e-06,
      "loss": 0.162,
      "step": 3604
    },
    {
      "epoch": 0.2801523158221946,
      "grad_norm": 2.117551565170288,
      "learning_rate": 8.599238420889028e-06,
      "loss": 0.7595,
      "step": 3605
    },
    {
      "epoch": 0.28023002797637553,
      "grad_norm": 0.6493442058563232,
      "learning_rate": 8.598849860118124e-06,
      "loss": 0.3432,
      "step": 3606
    },
    {
      "epoch": 0.2803077401305564,
      "grad_norm": 0.21871857345104218,
      "learning_rate": 8.598461299347218e-06,
      "loss": 0.0508,
      "step": 3607
    },
    {
      "epoch": 0.2803854522847373,
      "grad_norm": 0.12020821869373322,
      "learning_rate": 8.598072738576314e-06,
      "loss": 0.0229,
      "step": 3608
    },
    {
      "epoch": 0.2804631644389182,
      "grad_norm": 0.3605567216873169,
      "learning_rate": 8.59768417780541e-06,
      "loss": 0.2657,
      "step": 3609
    },
    {
      "epoch": 0.2805408765930992,
      "grad_norm": 0.5530945658683777,
      "learning_rate": 8.597295617034504e-06,
      "loss": 0.958,
      "step": 3610
    },
    {
      "epoch": 0.2806185887472801,
      "grad_norm": 0.22691932320594788,
      "learning_rate": 8.596907056263601e-06,
      "loss": 0.1539,
      "step": 3611
    },
    {
      "epoch": 0.28069630090146097,
      "grad_norm": 0.8279405236244202,
      "learning_rate": 8.596518495492696e-06,
      "loss": 0.5395,
      "step": 3612
    },
    {
      "epoch": 0.2807740130556419,
      "grad_norm": 0.2588904798030853,
      "learning_rate": 8.59612993472179e-06,
      "loss": 0.0982,
      "step": 3613
    },
    {
      "epoch": 0.2808517252098228,
      "grad_norm": 0.1619672179222107,
      "learning_rate": 8.595741373950887e-06,
      "loss": 0.0736,
      "step": 3614
    },
    {
      "epoch": 0.2809294373640037,
      "grad_norm": 0.2213413268327713,
      "learning_rate": 8.595352813179982e-06,
      "loss": 0.082,
      "step": 3615
    },
    {
      "epoch": 0.2810071495181846,
      "grad_norm": 0.4686155617237091,
      "learning_rate": 8.594964252409077e-06,
      "loss": 0.3999,
      "step": 3616
    },
    {
      "epoch": 0.28108486167236557,
      "grad_norm": 0.4386276602745056,
      "learning_rate": 8.594575691638172e-06,
      "loss": 0.2598,
      "step": 3617
    },
    {
      "epoch": 0.28116257382654647,
      "grad_norm": 0.44341498613357544,
      "learning_rate": 8.594187130867269e-06,
      "loss": 0.1075,
      "step": 3618
    },
    {
      "epoch": 0.28124028598072737,
      "grad_norm": 0.40836483240127563,
      "learning_rate": 8.593798570096364e-06,
      "loss": 0.1603,
      "step": 3619
    },
    {
      "epoch": 0.2813179981349083,
      "grad_norm": 0.3157438337802887,
      "learning_rate": 8.593410009325459e-06,
      "loss": 0.3982,
      "step": 3620
    },
    {
      "epoch": 0.2813957102890892,
      "grad_norm": 0.6256620287895203,
      "learning_rate": 8.593021448554555e-06,
      "loss": 0.1855,
      "step": 3621
    },
    {
      "epoch": 0.2814734224432701,
      "grad_norm": 0.23279964923858643,
      "learning_rate": 8.59263288778365e-06,
      "loss": 0.1529,
      "step": 3622
    },
    {
      "epoch": 0.281551134597451,
      "grad_norm": 0.3770030736923218,
      "learning_rate": 8.592244327012745e-06,
      "loss": 0.3804,
      "step": 3623
    },
    {
      "epoch": 0.28162884675163197,
      "grad_norm": 0.544733464717865,
      "learning_rate": 8.59185576624184e-06,
      "loss": 0.5557,
      "step": 3624
    },
    {
      "epoch": 0.28170655890581286,
      "grad_norm": 0.33922675251960754,
      "learning_rate": 8.591467205470935e-06,
      "loss": 0.4256,
      "step": 3625
    },
    {
      "epoch": 0.28178427105999376,
      "grad_norm": 0.178669735789299,
      "learning_rate": 8.591078644700032e-06,
      "loss": 0.1038,
      "step": 3626
    },
    {
      "epoch": 0.2818619832141747,
      "grad_norm": 0.24866993725299835,
      "learning_rate": 8.590690083929127e-06,
      "loss": 0.1367,
      "step": 3627
    },
    {
      "epoch": 0.2819396953683556,
      "grad_norm": 0.20738407969474792,
      "learning_rate": 8.590301523158223e-06,
      "loss": 0.0817,
      "step": 3628
    },
    {
      "epoch": 0.2820174075225365,
      "grad_norm": 0.1853523701429367,
      "learning_rate": 8.589912962387318e-06,
      "loss": 0.0782,
      "step": 3629
    },
    {
      "epoch": 0.28209511967671747,
      "grad_norm": 0.9374611973762512,
      "learning_rate": 8.589524401616413e-06,
      "loss": 0.4086,
      "step": 3630
    },
    {
      "epoch": 0.28217283183089836,
      "grad_norm": 0.1537209451198578,
      "learning_rate": 8.58913584084551e-06,
      "loss": 0.0911,
      "step": 3631
    },
    {
      "epoch": 0.28225054398507926,
      "grad_norm": 0.17993687093257904,
      "learning_rate": 8.588747280074603e-06,
      "loss": 0.181,
      "step": 3632
    },
    {
      "epoch": 0.28232825613926016,
      "grad_norm": 0.3892255425453186,
      "learning_rate": 8.5883587193037e-06,
      "loss": 0.2219,
      "step": 3633
    },
    {
      "epoch": 0.2824059682934411,
      "grad_norm": 0.45675015449523926,
      "learning_rate": 8.587970158532795e-06,
      "loss": 0.2041,
      "step": 3634
    },
    {
      "epoch": 0.282483680447622,
      "grad_norm": 0.3466733992099762,
      "learning_rate": 8.58758159776189e-06,
      "loss": 0.1032,
      "step": 3635
    },
    {
      "epoch": 0.2825613926018029,
      "grad_norm": 0.3442978262901306,
      "learning_rate": 8.587193036990986e-06,
      "loss": 0.1485,
      "step": 3636
    },
    {
      "epoch": 0.28263910475598386,
      "grad_norm": 0.4987252950668335,
      "learning_rate": 8.586804476220081e-06,
      "loss": 0.1767,
      "step": 3637
    },
    {
      "epoch": 0.28271681691016476,
      "grad_norm": 0.46841853857040405,
      "learning_rate": 8.586415915449176e-06,
      "loss": 0.5568,
      "step": 3638
    },
    {
      "epoch": 0.28279452906434566,
      "grad_norm": 0.5304543972015381,
      "learning_rate": 8.586027354678273e-06,
      "loss": 0.1574,
      "step": 3639
    },
    {
      "epoch": 0.28287224121852655,
      "grad_norm": 0.7541822195053101,
      "learning_rate": 8.585638793907368e-06,
      "loss": 0.6537,
      "step": 3640
    },
    {
      "epoch": 0.2829499533727075,
      "grad_norm": 0.4866155982017517,
      "learning_rate": 8.585250233136463e-06,
      "loss": 0.2478,
      "step": 3641
    },
    {
      "epoch": 0.2830276655268884,
      "grad_norm": 0.36529624462127686,
      "learning_rate": 8.584861672365558e-06,
      "loss": 0.1543,
      "step": 3642
    },
    {
      "epoch": 0.2831053776810693,
      "grad_norm": 0.5996958017349243,
      "learning_rate": 8.584473111594655e-06,
      "loss": 0.625,
      "step": 3643
    },
    {
      "epoch": 0.28318308983525026,
      "grad_norm": 0.09043675661087036,
      "learning_rate": 8.58408455082375e-06,
      "loss": 0.0742,
      "step": 3644
    },
    {
      "epoch": 0.28326080198943115,
      "grad_norm": 0.4887719452381134,
      "learning_rate": 8.583695990052844e-06,
      "loss": 0.2448,
      "step": 3645
    },
    {
      "epoch": 0.28333851414361205,
      "grad_norm": 0.19555923342704773,
      "learning_rate": 8.583307429281941e-06,
      "loss": 0.0576,
      "step": 3646
    },
    {
      "epoch": 0.28341622629779295,
      "grad_norm": 2.0124058723449707,
      "learning_rate": 8.582918868511036e-06,
      "loss": 0.3269,
      "step": 3647
    },
    {
      "epoch": 0.2834939384519739,
      "grad_norm": 0.6902421116828918,
      "learning_rate": 8.582530307740131e-06,
      "loss": 0.2791,
      "step": 3648
    },
    {
      "epoch": 0.2835716506061548,
      "grad_norm": 0.7385401725769043,
      "learning_rate": 8.582141746969228e-06,
      "loss": 0.7121,
      "step": 3649
    },
    {
      "epoch": 0.2836493627603357,
      "grad_norm": 0.7702925801277161,
      "learning_rate": 8.581753186198321e-06,
      "loss": 0.919,
      "step": 3650
    },
    {
      "epoch": 0.28372707491451665,
      "grad_norm": 0.14940419793128967,
      "learning_rate": 8.581364625427418e-06,
      "loss": 0.0403,
      "step": 3651
    },
    {
      "epoch": 0.28380478706869755,
      "grad_norm": 0.253435879945755,
      "learning_rate": 8.580976064656512e-06,
      "loss": 0.099,
      "step": 3652
    },
    {
      "epoch": 0.28388249922287845,
      "grad_norm": 0.130395770072937,
      "learning_rate": 8.580587503885607e-06,
      "loss": 0.1174,
      "step": 3653
    },
    {
      "epoch": 0.28396021137705935,
      "grad_norm": 0.526639997959137,
      "learning_rate": 8.580198943114704e-06,
      "loss": 0.2987,
      "step": 3654
    },
    {
      "epoch": 0.2840379235312403,
      "grad_norm": 0.31143099069595337,
      "learning_rate": 8.579810382343799e-06,
      "loss": 0.1864,
      "step": 3655
    },
    {
      "epoch": 0.2841156356854212,
      "grad_norm": 0.217710942029953,
      "learning_rate": 8.579421821572894e-06,
      "loss": 0.0684,
      "step": 3656
    },
    {
      "epoch": 0.2841933478396021,
      "grad_norm": 1.0027503967285156,
      "learning_rate": 8.57903326080199e-06,
      "loss": 0.4816,
      "step": 3657
    },
    {
      "epoch": 0.28427105999378305,
      "grad_norm": 0.4732268154621124,
      "learning_rate": 8.578644700031086e-06,
      "loss": 0.5018,
      "step": 3658
    },
    {
      "epoch": 0.28434877214796395,
      "grad_norm": 0.3992486000061035,
      "learning_rate": 8.578256139260182e-06,
      "loss": 0.416,
      "step": 3659
    },
    {
      "epoch": 0.28442648430214484,
      "grad_norm": 0.18101951479911804,
      "learning_rate": 8.577867578489275e-06,
      "loss": 0.1128,
      "step": 3660
    },
    {
      "epoch": 0.28450419645632574,
      "grad_norm": 0.1502668410539627,
      "learning_rate": 8.577479017718372e-06,
      "loss": 0.0341,
      "step": 3661
    },
    {
      "epoch": 0.2845819086105067,
      "grad_norm": 0.13378728926181793,
      "learning_rate": 8.577090456947467e-06,
      "loss": 0.0336,
      "step": 3662
    },
    {
      "epoch": 0.2846596207646876,
      "grad_norm": 0.42824336886405945,
      "learning_rate": 8.576701896176562e-06,
      "loss": 0.2367,
      "step": 3663
    },
    {
      "epoch": 0.2847373329188685,
      "grad_norm": 0.47002899646759033,
      "learning_rate": 8.576313335405659e-06,
      "loss": 0.3175,
      "step": 3664
    },
    {
      "epoch": 0.28481504507304944,
      "grad_norm": 0.6000451445579529,
      "learning_rate": 8.575924774634754e-06,
      "loss": 0.7031,
      "step": 3665
    },
    {
      "epoch": 0.28489275722723034,
      "grad_norm": 0.14558376371860504,
      "learning_rate": 8.575536213863849e-06,
      "loss": 0.0301,
      "step": 3666
    },
    {
      "epoch": 0.28497046938141124,
      "grad_norm": 0.6084781289100647,
      "learning_rate": 8.575147653092945e-06,
      "loss": 0.5976,
      "step": 3667
    },
    {
      "epoch": 0.2850481815355922,
      "grad_norm": 0.33639609813690186,
      "learning_rate": 8.57475909232204e-06,
      "loss": 0.1274,
      "step": 3668
    },
    {
      "epoch": 0.2851258936897731,
      "grad_norm": 0.45703092217445374,
      "learning_rate": 8.574370531551135e-06,
      "loss": 0.6218,
      "step": 3669
    },
    {
      "epoch": 0.285203605843954,
      "grad_norm": 0.627058744430542,
      "learning_rate": 8.57398197078023e-06,
      "loss": 0.2531,
      "step": 3670
    },
    {
      "epoch": 0.2852813179981349,
      "grad_norm": 0.29138198494911194,
      "learning_rate": 8.573593410009327e-06,
      "loss": 0.1804,
      "step": 3671
    },
    {
      "epoch": 0.28535903015231584,
      "grad_norm": 0.1249929666519165,
      "learning_rate": 8.573204849238422e-06,
      "loss": 0.0617,
      "step": 3672
    },
    {
      "epoch": 0.28543674230649674,
      "grad_norm": 0.148574098944664,
      "learning_rate": 8.572816288467517e-06,
      "loss": 0.0781,
      "step": 3673
    },
    {
      "epoch": 0.28551445446067764,
      "grad_norm": 0.24299854040145874,
      "learning_rate": 8.572427727696613e-06,
      "loss": 0.1131,
      "step": 3674
    },
    {
      "epoch": 0.2855921666148586,
      "grad_norm": 1.1528912782669067,
      "learning_rate": 8.572039166925708e-06,
      "loss": 0.243,
      "step": 3675
    },
    {
      "epoch": 0.2856698787690395,
      "grad_norm": 0.4810813367366791,
      "learning_rate": 8.571650606154803e-06,
      "loss": 0.8415,
      "step": 3676
    },
    {
      "epoch": 0.2857475909232204,
      "grad_norm": 0.3781508505344391,
      "learning_rate": 8.5712620453839e-06,
      "loss": 0.3957,
      "step": 3677
    },
    {
      "epoch": 0.2858253030774013,
      "grad_norm": 0.2119142860174179,
      "learning_rate": 8.570873484612993e-06,
      "loss": 0.1204,
      "step": 3678
    },
    {
      "epoch": 0.28590301523158224,
      "grad_norm": 0.1264050006866455,
      "learning_rate": 8.57048492384209e-06,
      "loss": 0.0663,
      "step": 3679
    },
    {
      "epoch": 0.28598072738576313,
      "grad_norm": 0.402609258890152,
      "learning_rate": 8.570096363071185e-06,
      "loss": 0.4109,
      "step": 3680
    },
    {
      "epoch": 0.28605843953994403,
      "grad_norm": 0.17451582849025726,
      "learning_rate": 8.56970780230028e-06,
      "loss": 0.0529,
      "step": 3681
    },
    {
      "epoch": 0.286136151694125,
      "grad_norm": 0.13133175671100616,
      "learning_rate": 8.569319241529376e-06,
      "loss": 0.0282,
      "step": 3682
    },
    {
      "epoch": 0.2862138638483059,
      "grad_norm": 0.20847803354263306,
      "learning_rate": 8.568930680758471e-06,
      "loss": 0.1831,
      "step": 3683
    },
    {
      "epoch": 0.2862915760024868,
      "grad_norm": 0.0814942866563797,
      "learning_rate": 8.568542119987566e-06,
      "loss": 0.0367,
      "step": 3684
    },
    {
      "epoch": 0.2863692881566677,
      "grad_norm": 1.0407072305679321,
      "learning_rate": 8.568153559216663e-06,
      "loss": 0.2415,
      "step": 3685
    },
    {
      "epoch": 0.28644700031084863,
      "grad_norm": 0.2785276472568512,
      "learning_rate": 8.567764998445758e-06,
      "loss": 0.1863,
      "step": 3686
    },
    {
      "epoch": 0.28652471246502953,
      "grad_norm": 0.27175959944725037,
      "learning_rate": 8.567376437674853e-06,
      "loss": 0.1398,
      "step": 3687
    },
    {
      "epoch": 0.2866024246192104,
      "grad_norm": 0.1822969615459442,
      "learning_rate": 8.566987876903948e-06,
      "loss": 0.0646,
      "step": 3688
    },
    {
      "epoch": 0.2866801367733914,
      "grad_norm": 0.1515205353498459,
      "learning_rate": 8.566599316133044e-06,
      "loss": 0.0711,
      "step": 3689
    },
    {
      "epoch": 0.2867578489275723,
      "grad_norm": 0.0960649698972702,
      "learning_rate": 8.56621075536214e-06,
      "loss": 0.1427,
      "step": 3690
    },
    {
      "epoch": 0.2868355610817532,
      "grad_norm": 0.17202848196029663,
      "learning_rate": 8.565822194591234e-06,
      "loss": 0.0419,
      "step": 3691
    },
    {
      "epoch": 0.2869132732359341,
      "grad_norm": 0.33300578594207764,
      "learning_rate": 8.56543363382033e-06,
      "loss": 0.4151,
      "step": 3692
    },
    {
      "epoch": 0.286990985390115,
      "grad_norm": 0.19716903567314148,
      "learning_rate": 8.565045073049426e-06,
      "loss": 0.1642,
      "step": 3693
    },
    {
      "epoch": 0.2870686975442959,
      "grad_norm": 0.05868232995271683,
      "learning_rate": 8.56465651227852e-06,
      "loss": 0.0212,
      "step": 3694
    },
    {
      "epoch": 0.2871464096984768,
      "grad_norm": 0.5319008231163025,
      "learning_rate": 8.564267951507617e-06,
      "loss": 0.6262,
      "step": 3695
    },
    {
      "epoch": 0.2872241218526578,
      "grad_norm": 0.1426212042570114,
      "learning_rate": 8.563879390736712e-06,
      "loss": 0.0407,
      "step": 3696
    },
    {
      "epoch": 0.2873018340068387,
      "grad_norm": 0.22575531899929047,
      "learning_rate": 8.563490829965807e-06,
      "loss": 0.0611,
      "step": 3697
    },
    {
      "epoch": 0.2873795461610196,
      "grad_norm": 0.9744616150856018,
      "learning_rate": 8.563102269194902e-06,
      "loss": 0.2536,
      "step": 3698
    },
    {
      "epoch": 0.28745725831520047,
      "grad_norm": 0.14842762053012848,
      "learning_rate": 8.562713708423999e-06,
      "loss": 0.0518,
      "step": 3699
    },
    {
      "epoch": 0.2875349704693814,
      "grad_norm": 0.34890878200531006,
      "learning_rate": 8.562325147653094e-06,
      "loss": 0.2203,
      "step": 3700
    },
    {
      "epoch": 0.2876126826235623,
      "grad_norm": 0.2642963230609894,
      "learning_rate": 8.561936586882189e-06,
      "loss": 0.2856,
      "step": 3701
    },
    {
      "epoch": 0.2876903947777432,
      "grad_norm": 0.15136757493019104,
      "learning_rate": 8.561548026111285e-06,
      "loss": 0.0781,
      "step": 3702
    },
    {
      "epoch": 0.2877681069319242,
      "grad_norm": 1.176329493522644,
      "learning_rate": 8.56115946534038e-06,
      "loss": 0.367,
      "step": 3703
    },
    {
      "epoch": 0.28784581908610507,
      "grad_norm": 0.6583357453346252,
      "learning_rate": 8.560770904569475e-06,
      "loss": 0.5401,
      "step": 3704
    },
    {
      "epoch": 0.28792353124028597,
      "grad_norm": 0.21801050007343292,
      "learning_rate": 8.560382343798572e-06,
      "loss": 0.066,
      "step": 3705
    },
    {
      "epoch": 0.2880012433944669,
      "grad_norm": 0.26311373710632324,
      "learning_rate": 8.559993783027665e-06,
      "loss": 0.1391,
      "step": 3706
    },
    {
      "epoch": 0.2880789555486478,
      "grad_norm": 0.30086833238601685,
      "learning_rate": 8.559605222256762e-06,
      "loss": 0.0759,
      "step": 3707
    },
    {
      "epoch": 0.2881566677028287,
      "grad_norm": 0.20507478713989258,
      "learning_rate": 8.559216661485857e-06,
      "loss": 0.0889,
      "step": 3708
    },
    {
      "epoch": 0.2882343798570096,
      "grad_norm": 0.3126210570335388,
      "learning_rate": 8.558828100714952e-06,
      "loss": 0.2557,
      "step": 3709
    },
    {
      "epoch": 0.28831209201119057,
      "grad_norm": 0.2733933627605438,
      "learning_rate": 8.558439539944048e-06,
      "loss": 0.1924,
      "step": 3710
    },
    {
      "epoch": 0.28838980416537147,
      "grad_norm": 0.27666983008384705,
      "learning_rate": 8.558050979173143e-06,
      "loss": 0.1376,
      "step": 3711
    },
    {
      "epoch": 0.28846751631955236,
      "grad_norm": 0.25921013951301575,
      "learning_rate": 8.557662418402238e-06,
      "loss": 0.7134,
      "step": 3712
    },
    {
      "epoch": 0.2885452284737333,
      "grad_norm": 0.19319739937782288,
      "learning_rate": 8.557273857631335e-06,
      "loss": 0.1364,
      "step": 3713
    },
    {
      "epoch": 0.2886229406279142,
      "grad_norm": 0.28188326954841614,
      "learning_rate": 8.55688529686043e-06,
      "loss": 0.1981,
      "step": 3714
    },
    {
      "epoch": 0.2887006527820951,
      "grad_norm": 0.24090509116649628,
      "learning_rate": 8.556496736089525e-06,
      "loss": 0.1749,
      "step": 3715
    },
    {
      "epoch": 0.288778364936276,
      "grad_norm": 0.08462836593389511,
      "learning_rate": 8.55610817531862e-06,
      "loss": 0.0116,
      "step": 3716
    },
    {
      "epoch": 0.28885607709045696,
      "grad_norm": 0.33345210552215576,
      "learning_rate": 8.555719614547716e-06,
      "loss": 0.2254,
      "step": 3717
    },
    {
      "epoch": 0.28893378924463786,
      "grad_norm": 0.29943323135375977,
      "learning_rate": 8.555331053776811e-06,
      "loss": 0.2419,
      "step": 3718
    },
    {
      "epoch": 0.28901150139881876,
      "grad_norm": 0.28433990478515625,
      "learning_rate": 8.554942493005906e-06,
      "loss": 0.0921,
      "step": 3719
    },
    {
      "epoch": 0.2890892135529997,
      "grad_norm": 0.07851436734199524,
      "learning_rate": 8.554553932235003e-06,
      "loss": 0.0233,
      "step": 3720
    },
    {
      "epoch": 0.2891669257071806,
      "grad_norm": 0.1476336568593979,
      "learning_rate": 8.554165371464098e-06,
      "loss": 0.0804,
      "step": 3721
    },
    {
      "epoch": 0.2892446378613615,
      "grad_norm": 0.31539463996887207,
      "learning_rate": 8.553776810693193e-06,
      "loss": 0.083,
      "step": 3722
    },
    {
      "epoch": 0.2893223500155424,
      "grad_norm": 0.30166396498680115,
      "learning_rate": 8.55338824992229e-06,
      "loss": 0.2087,
      "step": 3723
    },
    {
      "epoch": 0.28940006216972336,
      "grad_norm": 0.28415048122406006,
      "learning_rate": 8.552999689151384e-06,
      "loss": 0.1003,
      "step": 3724
    },
    {
      "epoch": 0.28947777432390426,
      "grad_norm": 0.1478031873703003,
      "learning_rate": 8.55261112838048e-06,
      "loss": 0.0838,
      "step": 3725
    },
    {
      "epoch": 0.28955548647808516,
      "grad_norm": 0.18135616183280945,
      "learning_rate": 8.552222567609574e-06,
      "loss": 0.0127,
      "step": 3726
    },
    {
      "epoch": 0.2896331986322661,
      "grad_norm": 0.08370565623044968,
      "learning_rate": 8.551834006838671e-06,
      "loss": 0.0367,
      "step": 3727
    },
    {
      "epoch": 0.289710910786447,
      "grad_norm": 0.10584884881973267,
      "learning_rate": 8.551445446067766e-06,
      "loss": 0.0383,
      "step": 3728
    },
    {
      "epoch": 0.2897886229406279,
      "grad_norm": 0.3157038688659668,
      "learning_rate": 8.551056885296861e-06,
      "loss": 0.1147,
      "step": 3729
    },
    {
      "epoch": 0.2898663350948088,
      "grad_norm": 0.22773411870002747,
      "learning_rate": 8.550668324525957e-06,
      "loss": 0.0813,
      "step": 3730
    },
    {
      "epoch": 0.28994404724898976,
      "grad_norm": 0.1958082914352417,
      "learning_rate": 8.550279763755052e-06,
      "loss": 0.0484,
      "step": 3731
    },
    {
      "epoch": 0.29002175940317065,
      "grad_norm": 0.6101073026657104,
      "learning_rate": 8.549891202984147e-06,
      "loss": 0.1959,
      "step": 3732
    },
    {
      "epoch": 0.29009947155735155,
      "grad_norm": 0.21766842901706696,
      "learning_rate": 8.549502642213244e-06,
      "loss": 0.0856,
      "step": 3733
    },
    {
      "epoch": 0.2901771837115325,
      "grad_norm": 0.4242600202560425,
      "learning_rate": 8.549114081442337e-06,
      "loss": 0.2747,
      "step": 3734
    },
    {
      "epoch": 0.2902548958657134,
      "grad_norm": 0.016165224835276604,
      "learning_rate": 8.548725520671434e-06,
      "loss": 0.0029,
      "step": 3735
    },
    {
      "epoch": 0.2903326080198943,
      "grad_norm": 0.19358421862125397,
      "learning_rate": 8.548336959900529e-06,
      "loss": 0.105,
      "step": 3736
    },
    {
      "epoch": 0.2904103201740752,
      "grad_norm": 0.32012853026390076,
      "learning_rate": 8.547948399129624e-06,
      "loss": 0.0963,
      "step": 3737
    },
    {
      "epoch": 0.29048803232825615,
      "grad_norm": 0.12355316430330276,
      "learning_rate": 8.54755983835872e-06,
      "loss": 0.0556,
      "step": 3738
    },
    {
      "epoch": 0.29056574448243705,
      "grad_norm": 0.2744108736515045,
      "learning_rate": 8.547171277587815e-06,
      "loss": 0.0727,
      "step": 3739
    },
    {
      "epoch": 0.29064345663661795,
      "grad_norm": 0.5616836547851562,
      "learning_rate": 8.54678271681691e-06,
      "loss": 0.1289,
      "step": 3740
    },
    {
      "epoch": 0.2907211687907989,
      "grad_norm": 0.21761205792427063,
      "learning_rate": 8.546394156046007e-06,
      "loss": 0.0784,
      "step": 3741
    },
    {
      "epoch": 0.2907988809449798,
      "grad_norm": 0.7878205180168152,
      "learning_rate": 8.546005595275102e-06,
      "loss": 0.3818,
      "step": 3742
    },
    {
      "epoch": 0.2908765930991607,
      "grad_norm": 0.4570225775241852,
      "learning_rate": 8.545617034504197e-06,
      "loss": 0.6435,
      "step": 3743
    },
    {
      "epoch": 0.29095430525334165,
      "grad_norm": 0.27880558371543884,
      "learning_rate": 8.545228473733292e-06,
      "loss": 0.1319,
      "step": 3744
    },
    {
      "epoch": 0.29103201740752255,
      "grad_norm": 0.05401545390486717,
      "learning_rate": 8.544839912962389e-06,
      "loss": 0.0287,
      "step": 3745
    },
    {
      "epoch": 0.29110972956170345,
      "grad_norm": 0.4107643663883209,
      "learning_rate": 8.544451352191483e-06,
      "loss": 0.2528,
      "step": 3746
    },
    {
      "epoch": 0.29118744171588434,
      "grad_norm": 0.27611488103866577,
      "learning_rate": 8.544062791420578e-06,
      "loss": 0.1338,
      "step": 3747
    },
    {
      "epoch": 0.2912651538700653,
      "grad_norm": 0.09858786314725876,
      "learning_rate": 8.543674230649675e-06,
      "loss": 0.0604,
      "step": 3748
    },
    {
      "epoch": 0.2913428660242462,
      "grad_norm": 0.3605402112007141,
      "learning_rate": 8.54328566987877e-06,
      "loss": 0.1695,
      "step": 3749
    },
    {
      "epoch": 0.2914205781784271,
      "grad_norm": 0.15223126113414764,
      "learning_rate": 8.542897109107865e-06,
      "loss": 0.0785,
      "step": 3750
    },
    {
      "epoch": 0.29149829033260805,
      "grad_norm": 1.1225930452346802,
      "learning_rate": 8.54250854833696e-06,
      "loss": 0.7847,
      "step": 3751
    },
    {
      "epoch": 0.29157600248678894,
      "grad_norm": 0.8533692359924316,
      "learning_rate": 8.542119987566057e-06,
      "loss": 0.2908,
      "step": 3752
    },
    {
      "epoch": 0.29165371464096984,
      "grad_norm": 0.360083669424057,
      "learning_rate": 8.541731426795152e-06,
      "loss": 0.1746,
      "step": 3753
    },
    {
      "epoch": 0.29173142679515074,
      "grad_norm": 0.0668138861656189,
      "learning_rate": 8.541342866024246e-06,
      "loss": 0.0656,
      "step": 3754
    },
    {
      "epoch": 0.2918091389493317,
      "grad_norm": 0.4315973222255707,
      "learning_rate": 8.540954305253343e-06,
      "loss": 0.0731,
      "step": 3755
    },
    {
      "epoch": 0.2918868511035126,
      "grad_norm": 0.22355544567108154,
      "learning_rate": 8.540565744482438e-06,
      "loss": 0.1005,
      "step": 3756
    },
    {
      "epoch": 0.2919645632576935,
      "grad_norm": 0.05127790570259094,
      "learning_rate": 8.540177183711533e-06,
      "loss": 0.0174,
      "step": 3757
    },
    {
      "epoch": 0.29204227541187444,
      "grad_norm": 0.16710595786571503,
      "learning_rate": 8.53978862294063e-06,
      "loss": 0.0867,
      "step": 3758
    },
    {
      "epoch": 0.29211998756605534,
      "grad_norm": 0.3496634364128113,
      "learning_rate": 8.539400062169723e-06,
      "loss": 0.1567,
      "step": 3759
    },
    {
      "epoch": 0.29219769972023624,
      "grad_norm": 0.4176861643791199,
      "learning_rate": 8.53901150139882e-06,
      "loss": 0.334,
      "step": 3760
    },
    {
      "epoch": 0.29227541187441713,
      "grad_norm": 0.3887861967086792,
      "learning_rate": 8.538622940627914e-06,
      "loss": 0.3259,
      "step": 3761
    },
    {
      "epoch": 0.2923531240285981,
      "grad_norm": 0.22268228232860565,
      "learning_rate": 8.53823437985701e-06,
      "loss": 0.0305,
      "step": 3762
    },
    {
      "epoch": 0.292430836182779,
      "grad_norm": 0.2600523829460144,
      "learning_rate": 8.537845819086106e-06,
      "loss": 0.1292,
      "step": 3763
    },
    {
      "epoch": 0.2925085483369599,
      "grad_norm": 0.3196745216846466,
      "learning_rate": 8.537457258315201e-06,
      "loss": 0.344,
      "step": 3764
    },
    {
      "epoch": 0.29258626049114084,
      "grad_norm": 0.09568420052528381,
      "learning_rate": 8.537068697544296e-06,
      "loss": 0.0201,
      "step": 3765
    },
    {
      "epoch": 0.29266397264532173,
      "grad_norm": 0.10207362473011017,
      "learning_rate": 8.536680136773393e-06,
      "loss": 0.0684,
      "step": 3766
    },
    {
      "epoch": 0.29274168479950263,
      "grad_norm": 0.431855171918869,
      "learning_rate": 8.536291576002488e-06,
      "loss": 0.2538,
      "step": 3767
    },
    {
      "epoch": 0.29281939695368353,
      "grad_norm": 0.5686521530151367,
      "learning_rate": 8.535903015231583e-06,
      "loss": 0.787,
      "step": 3768
    },
    {
      "epoch": 0.2928971091078645,
      "grad_norm": 0.4614606201648712,
      "learning_rate": 8.535514454460677e-06,
      "loss": 0.3087,
      "step": 3769
    },
    {
      "epoch": 0.2929748212620454,
      "grad_norm": 0.26890119910240173,
      "learning_rate": 8.535125893689774e-06,
      "loss": 0.2438,
      "step": 3770
    },
    {
      "epoch": 0.2930525334162263,
      "grad_norm": 0.6303085684776306,
      "learning_rate": 8.534737332918869e-06,
      "loss": 1.0145,
      "step": 3771
    },
    {
      "epoch": 0.29313024557040723,
      "grad_norm": 0.34641197323799133,
      "learning_rate": 8.534348772147964e-06,
      "loss": 0.1916,
      "step": 3772
    },
    {
      "epoch": 0.29320795772458813,
      "grad_norm": 0.4775988757610321,
      "learning_rate": 8.53396021137706e-06,
      "loss": 0.1784,
      "step": 3773
    },
    {
      "epoch": 0.29328566987876903,
      "grad_norm": 0.07124573737382889,
      "learning_rate": 8.533571650606156e-06,
      "loss": 0.0214,
      "step": 3774
    },
    {
      "epoch": 0.2933633820329499,
      "grad_norm": 0.42739537358283997,
      "learning_rate": 8.53318308983525e-06,
      "loss": 0.2174,
      "step": 3775
    },
    {
      "epoch": 0.2934410941871309,
      "grad_norm": 0.17704765498638153,
      "learning_rate": 8.532794529064347e-06,
      "loss": 0.0422,
      "step": 3776
    },
    {
      "epoch": 0.2935188063413118,
      "grad_norm": 0.4890235364437103,
      "learning_rate": 8.53240596829344e-06,
      "loss": 0.7071,
      "step": 3777
    },
    {
      "epoch": 0.2935965184954927,
      "grad_norm": 0.24432560801506042,
      "learning_rate": 8.532017407522537e-06,
      "loss": 0.2087,
      "step": 3778
    },
    {
      "epoch": 0.29367423064967363,
      "grad_norm": 0.23875249922275543,
      "learning_rate": 8.531628846751632e-06,
      "loss": 0.4169,
      "step": 3779
    },
    {
      "epoch": 0.2937519428038545,
      "grad_norm": 0.24589556455612183,
      "learning_rate": 8.531240285980729e-06,
      "loss": 0.1001,
      "step": 3780
    },
    {
      "epoch": 0.2938296549580354,
      "grad_norm": 0.1354103833436966,
      "learning_rate": 8.530851725209824e-06,
      "loss": 0.0978,
      "step": 3781
    },
    {
      "epoch": 0.2939073671122164,
      "grad_norm": 0.2247384935617447,
      "learning_rate": 8.530463164438919e-06,
      "loss": 0.0971,
      "step": 3782
    },
    {
      "epoch": 0.2939850792663973,
      "grad_norm": 0.6005281209945679,
      "learning_rate": 8.530074603668015e-06,
      "loss": 0.133,
      "step": 3783
    },
    {
      "epoch": 0.2940627914205782,
      "grad_norm": 0.3467089831829071,
      "learning_rate": 8.52968604289711e-06,
      "loss": 0.2724,
      "step": 3784
    },
    {
      "epoch": 0.29414050357475907,
      "grad_norm": 0.22918789088726044,
      "learning_rate": 8.529297482126205e-06,
      "loss": 0.2295,
      "step": 3785
    },
    {
      "epoch": 0.29421821572894,
      "grad_norm": 0.5500487089157104,
      "learning_rate": 8.528908921355302e-06,
      "loss": 0.1825,
      "step": 3786
    },
    {
      "epoch": 0.2942959278831209,
      "grad_norm": 0.234807550907135,
      "learning_rate": 8.528520360584395e-06,
      "loss": 0.0303,
      "step": 3787
    },
    {
      "epoch": 0.2943736400373018,
      "grad_norm": 0.04771874099969864,
      "learning_rate": 8.528131799813492e-06,
      "loss": 0.0101,
      "step": 3788
    },
    {
      "epoch": 0.2944513521914828,
      "grad_norm": 0.30416616797447205,
      "learning_rate": 8.527743239042587e-06,
      "loss": 0.0652,
      "step": 3789
    },
    {
      "epoch": 0.29452906434566367,
      "grad_norm": 0.8992725610733032,
      "learning_rate": 8.527354678271682e-06,
      "loss": 0.5196,
      "step": 3790
    },
    {
      "epoch": 0.29460677649984457,
      "grad_norm": 1.1048799753189087,
      "learning_rate": 8.526966117500778e-06,
      "loss": 0.3962,
      "step": 3791
    },
    {
      "epoch": 0.29468448865402547,
      "grad_norm": 0.5902193188667297,
      "learning_rate": 8.526577556729873e-06,
      "loss": 0.4821,
      "step": 3792
    },
    {
      "epoch": 0.2947622008082064,
      "grad_norm": 0.5525211691856384,
      "learning_rate": 8.526188995958968e-06,
      "loss": 1.0096,
      "step": 3793
    },
    {
      "epoch": 0.2948399129623873,
      "grad_norm": 0.13327693939208984,
      "learning_rate": 8.525800435188065e-06,
      "loss": 0.0574,
      "step": 3794
    },
    {
      "epoch": 0.2949176251165682,
      "grad_norm": 0.43531534075737,
      "learning_rate": 8.52541187441716e-06,
      "loss": 0.1906,
      "step": 3795
    },
    {
      "epoch": 0.29499533727074917,
      "grad_norm": 0.9554761052131653,
      "learning_rate": 8.525023313646255e-06,
      "loss": 1.143,
      "step": 3796
    },
    {
      "epoch": 0.29507304942493007,
      "grad_norm": 0.7003501057624817,
      "learning_rate": 8.52463475287535e-06,
      "loss": 0.2009,
      "step": 3797
    },
    {
      "epoch": 0.29515076157911097,
      "grad_norm": 0.36726856231689453,
      "learning_rate": 8.524246192104446e-06,
      "loss": 0.1802,
      "step": 3798
    },
    {
      "epoch": 0.29522847373329186,
      "grad_norm": 0.2585068643093109,
      "learning_rate": 8.523857631333541e-06,
      "loss": 0.1626,
      "step": 3799
    },
    {
      "epoch": 0.2953061858874728,
      "grad_norm": 0.2161870300769806,
      "learning_rate": 8.523469070562636e-06,
      "loss": 0.0762,
      "step": 3800
    },
    {
      "epoch": 0.2953838980416537,
      "grad_norm": 0.5750772953033447,
      "learning_rate": 8.523080509791733e-06,
      "loss": 0.2372,
      "step": 3801
    },
    {
      "epoch": 0.2954616101958346,
      "grad_norm": 0.6319131255149841,
      "learning_rate": 8.522691949020828e-06,
      "loss": 0.3363,
      "step": 3802
    },
    {
      "epoch": 0.29553932235001557,
      "grad_norm": 0.8614090085029602,
      "learning_rate": 8.522303388249923e-06,
      "loss": 0.2754,
      "step": 3803
    },
    {
      "epoch": 0.29561703450419646,
      "grad_norm": 0.2259119153022766,
      "learning_rate": 8.52191482747902e-06,
      "loss": 0.0793,
      "step": 3804
    },
    {
      "epoch": 0.29569474665837736,
      "grad_norm": 0.2716376483440399,
      "learning_rate": 8.521526266708113e-06,
      "loss": 0.3376,
      "step": 3805
    },
    {
      "epoch": 0.29577245881255826,
      "grad_norm": 0.35760900378227234,
      "learning_rate": 8.52113770593721e-06,
      "loss": 0.376,
      "step": 3806
    },
    {
      "epoch": 0.2958501709667392,
      "grad_norm": 0.1840854287147522,
      "learning_rate": 8.520749145166304e-06,
      "loss": 0.0818,
      "step": 3807
    },
    {
      "epoch": 0.2959278831209201,
      "grad_norm": 0.20165744423866272,
      "learning_rate": 8.5203605843954e-06,
      "loss": 0.0769,
      "step": 3808
    },
    {
      "epoch": 0.296005595275101,
      "grad_norm": 0.16867315769195557,
      "learning_rate": 8.519972023624496e-06,
      "loss": 0.0491,
      "step": 3809
    },
    {
      "epoch": 0.29608330742928196,
      "grad_norm": 0.19892899692058563,
      "learning_rate": 8.51958346285359e-06,
      "loss": 0.1307,
      "step": 3810
    },
    {
      "epoch": 0.29616101958346286,
      "grad_norm": 0.14966607093811035,
      "learning_rate": 8.519194902082687e-06,
      "loss": 0.0797,
      "step": 3811
    },
    {
      "epoch": 0.29623873173764376,
      "grad_norm": 0.1618364155292511,
      "learning_rate": 8.518806341311782e-06,
      "loss": 0.0946,
      "step": 3812
    },
    {
      "epoch": 0.29631644389182465,
      "grad_norm": 0.39628374576568604,
      "learning_rate": 8.518417780540877e-06,
      "loss": 0.2017,
      "step": 3813
    },
    {
      "epoch": 0.2963941560460056,
      "grad_norm": 0.40173229575157166,
      "learning_rate": 8.518029219769974e-06,
      "loss": 0.3946,
      "step": 3814
    },
    {
      "epoch": 0.2964718682001865,
      "grad_norm": 1.0199425220489502,
      "learning_rate": 8.517640658999067e-06,
      "loss": 0.3382,
      "step": 3815
    },
    {
      "epoch": 0.2965495803543674,
      "grad_norm": 0.2259185016155243,
      "learning_rate": 8.517252098228164e-06,
      "loss": 0.0543,
      "step": 3816
    },
    {
      "epoch": 0.29662729250854836,
      "grad_norm": 0.12842896580696106,
      "learning_rate": 8.516863537457259e-06,
      "loss": 0.0397,
      "step": 3817
    },
    {
      "epoch": 0.29670500466272925,
      "grad_norm": 0.31007814407348633,
      "learning_rate": 8.516474976686354e-06,
      "loss": 0.1412,
      "step": 3818
    },
    {
      "epoch": 0.29678271681691015,
      "grad_norm": 0.42372632026672363,
      "learning_rate": 8.51608641591545e-06,
      "loss": 0.1057,
      "step": 3819
    },
    {
      "epoch": 0.2968604289710911,
      "grad_norm": 0.44207751750946045,
      "learning_rate": 8.515697855144545e-06,
      "loss": 0.1483,
      "step": 3820
    },
    {
      "epoch": 0.296938141125272,
      "grad_norm": 0.4822026789188385,
      "learning_rate": 8.51530929437364e-06,
      "loss": 0.1217,
      "step": 3821
    },
    {
      "epoch": 0.2970158532794529,
      "grad_norm": 0.4541012644767761,
      "learning_rate": 8.514920733602737e-06,
      "loss": 0.1209,
      "step": 3822
    },
    {
      "epoch": 0.2970935654336338,
      "grad_norm": 0.34001511335372925,
      "learning_rate": 8.514532172831832e-06,
      "loss": 0.3639,
      "step": 3823
    },
    {
      "epoch": 0.29717127758781475,
      "grad_norm": 0.2477695792913437,
      "learning_rate": 8.514143612060927e-06,
      "loss": 0.123,
      "step": 3824
    },
    {
      "epoch": 0.29724898974199565,
      "grad_norm": 0.29619157314300537,
      "learning_rate": 8.513755051290022e-06,
      "loss": 0.2471,
      "step": 3825
    },
    {
      "epoch": 0.29732670189617655,
      "grad_norm": 0.42517775297164917,
      "learning_rate": 8.513366490519118e-06,
      "loss": 0.2494,
      "step": 3826
    },
    {
      "epoch": 0.2974044140503575,
      "grad_norm": 0.19097614288330078,
      "learning_rate": 8.512977929748213e-06,
      "loss": 0.1314,
      "step": 3827
    },
    {
      "epoch": 0.2974821262045384,
      "grad_norm": 0.2683967649936676,
      "learning_rate": 8.512589368977308e-06,
      "loss": 0.3196,
      "step": 3828
    },
    {
      "epoch": 0.2975598383587193,
      "grad_norm": 0.22507131099700928,
      "learning_rate": 8.512200808206405e-06,
      "loss": 0.1287,
      "step": 3829
    },
    {
      "epoch": 0.2976375505129002,
      "grad_norm": 0.24127943813800812,
      "learning_rate": 8.5118122474355e-06,
      "loss": 0.1361,
      "step": 3830
    },
    {
      "epoch": 0.29771526266708115,
      "grad_norm": 0.30990177392959595,
      "learning_rate": 8.511423686664595e-06,
      "loss": 0.161,
      "step": 3831
    },
    {
      "epoch": 0.29779297482126205,
      "grad_norm": 0.48272454738616943,
      "learning_rate": 8.511035125893692e-06,
      "loss": 0.2809,
      "step": 3832
    },
    {
      "epoch": 0.29787068697544294,
      "grad_norm": 0.2958794832229614,
      "learning_rate": 8.510646565122785e-06,
      "loss": 0.1595,
      "step": 3833
    },
    {
      "epoch": 0.2979483991296239,
      "grad_norm": 0.15933935344219208,
      "learning_rate": 8.510258004351881e-06,
      "loss": 0.1797,
      "step": 3834
    },
    {
      "epoch": 0.2980261112838048,
      "grad_norm": 0.3026715815067291,
      "learning_rate": 8.509869443580976e-06,
      "loss": 0.1809,
      "step": 3835
    },
    {
      "epoch": 0.2981038234379857,
      "grad_norm": 0.3484313189983368,
      "learning_rate": 8.509480882810071e-06,
      "loss": 0.2376,
      "step": 3836
    },
    {
      "epoch": 0.2981815355921666,
      "grad_norm": 0.19349674880504608,
      "learning_rate": 8.509092322039168e-06,
      "loss": 0.0829,
      "step": 3837
    },
    {
      "epoch": 0.29825924774634754,
      "grad_norm": 0.8265522122383118,
      "learning_rate": 8.508703761268263e-06,
      "loss": 0.1704,
      "step": 3838
    },
    {
      "epoch": 0.29833695990052844,
      "grad_norm": 0.1285928636789322,
      "learning_rate": 8.508315200497358e-06,
      "loss": 0.0483,
      "step": 3839
    },
    {
      "epoch": 0.29841467205470934,
      "grad_norm": 0.14965292811393738,
      "learning_rate": 8.507926639726454e-06,
      "loss": 0.0367,
      "step": 3840
    },
    {
      "epoch": 0.2984923842088903,
      "grad_norm": 0.4813317358493805,
      "learning_rate": 8.50753807895555e-06,
      "loss": 0.5166,
      "step": 3841
    },
    {
      "epoch": 0.2985700963630712,
      "grad_norm": 0.32235482335090637,
      "learning_rate": 8.507149518184646e-06,
      "loss": 0.2122,
      "step": 3842
    },
    {
      "epoch": 0.2986478085172521,
      "grad_norm": 0.3836624324321747,
      "learning_rate": 8.50676095741374e-06,
      "loss": 0.2532,
      "step": 3843
    },
    {
      "epoch": 0.298725520671433,
      "grad_norm": 0.1490897685289383,
      "learning_rate": 8.506372396642836e-06,
      "loss": 0.0408,
      "step": 3844
    },
    {
      "epoch": 0.29880323282561394,
      "grad_norm": 0.5645236968994141,
      "learning_rate": 8.505983835871931e-06,
      "loss": 0.2821,
      "step": 3845
    },
    {
      "epoch": 0.29888094497979484,
      "grad_norm": 0.18741914629936218,
      "learning_rate": 8.505595275101026e-06,
      "loss": 0.0305,
      "step": 3846
    },
    {
      "epoch": 0.29895865713397574,
      "grad_norm": 0.15131357312202454,
      "learning_rate": 8.505206714330123e-06,
      "loss": 0.0341,
      "step": 3847
    },
    {
      "epoch": 0.2990363692881567,
      "grad_norm": 0.03994891047477722,
      "learning_rate": 8.504818153559217e-06,
      "loss": 0.0121,
      "step": 3848
    },
    {
      "epoch": 0.2991140814423376,
      "grad_norm": 0.1114325299859047,
      "learning_rate": 8.504429592788312e-06,
      "loss": 0.0301,
      "step": 3849
    },
    {
      "epoch": 0.2991917935965185,
      "grad_norm": 0.15944266319274902,
      "learning_rate": 8.504041032017409e-06,
      "loss": 0.1084,
      "step": 3850
    },
    {
      "epoch": 0.2992695057506994,
      "grad_norm": 0.49763166904449463,
      "learning_rate": 8.503652471246504e-06,
      "loss": 0.424,
      "step": 3851
    },
    {
      "epoch": 0.29934721790488034,
      "grad_norm": 0.3097277581691742,
      "learning_rate": 8.503263910475599e-06,
      "loss": 0.174,
      "step": 3852
    },
    {
      "epoch": 0.29942493005906123,
      "grad_norm": 0.14632083475589752,
      "learning_rate": 8.502875349704694e-06,
      "loss": 0.0885,
      "step": 3853
    },
    {
      "epoch": 0.29950264221324213,
      "grad_norm": 0.24825800955295563,
      "learning_rate": 8.50248678893379e-06,
      "loss": 0.0864,
      "step": 3854
    },
    {
      "epoch": 0.2995803543674231,
      "grad_norm": 0.14150471985340118,
      "learning_rate": 8.502098228162886e-06,
      "loss": 0.0758,
      "step": 3855
    },
    {
      "epoch": 0.299658066521604,
      "grad_norm": 0.7796023488044739,
      "learning_rate": 8.50170966739198e-06,
      "loss": 0.3367,
      "step": 3856
    },
    {
      "epoch": 0.2997357786757849,
      "grad_norm": 0.5282775163650513,
      "learning_rate": 8.501321106621077e-06,
      "loss": 0.2524,
      "step": 3857
    },
    {
      "epoch": 0.29981349082996583,
      "grad_norm": 0.4436013102531433,
      "learning_rate": 8.500932545850172e-06,
      "loss": 0.195,
      "step": 3858
    },
    {
      "epoch": 0.29989120298414673,
      "grad_norm": 0.08313753455877304,
      "learning_rate": 8.500543985079267e-06,
      "loss": 0.0484,
      "step": 3859
    },
    {
      "epoch": 0.29996891513832763,
      "grad_norm": 0.5642619729042053,
      "learning_rate": 8.500155424308364e-06,
      "loss": 0.1774,
      "step": 3860
    },
    {
      "epoch": 0.3000466272925085,
      "grad_norm": 0.04888792335987091,
      "learning_rate": 8.499766863537457e-06,
      "loss": 0.012,
      "step": 3861
    },
    {
      "epoch": 0.3001243394466895,
      "grad_norm": 0.4752972722053528,
      "learning_rate": 8.499378302766554e-06,
      "loss": 0.2068,
      "step": 3862
    },
    {
      "epoch": 0.3002020516008704,
      "grad_norm": 0.08578724414110184,
      "learning_rate": 8.498989741995648e-06,
      "loss": 0.0208,
      "step": 3863
    },
    {
      "epoch": 0.3002797637550513,
      "grad_norm": 0.12495999038219452,
      "learning_rate": 8.498601181224743e-06,
      "loss": 0.0589,
      "step": 3864
    },
    {
      "epoch": 0.30035747590923223,
      "grad_norm": 0.3535212278366089,
      "learning_rate": 8.49821262045384e-06,
      "loss": 0.286,
      "step": 3865
    },
    {
      "epoch": 0.30043518806341313,
      "grad_norm": 0.2898671627044678,
      "learning_rate": 8.497824059682935e-06,
      "loss": 0.0542,
      "step": 3866
    },
    {
      "epoch": 0.300512900217594,
      "grad_norm": 1.0619792938232422,
      "learning_rate": 8.49743549891203e-06,
      "loss": 0.1812,
      "step": 3867
    },
    {
      "epoch": 0.3005906123717749,
      "grad_norm": 0.23930934071540833,
      "learning_rate": 8.497046938141127e-06,
      "loss": 0.1851,
      "step": 3868
    },
    {
      "epoch": 0.3006683245259559,
      "grad_norm": 0.3236173689365387,
      "learning_rate": 8.496658377370222e-06,
      "loss": 0.1436,
      "step": 3869
    },
    {
      "epoch": 0.3007460366801368,
      "grad_norm": 0.5315862894058228,
      "learning_rate": 8.496269816599317e-06,
      "loss": 0.7691,
      "step": 3870
    },
    {
      "epoch": 0.3008237488343177,
      "grad_norm": 0.22066695988178253,
      "learning_rate": 8.495881255828411e-06,
      "loss": 0.0453,
      "step": 3871
    },
    {
      "epoch": 0.3009014609884986,
      "grad_norm": 0.28014060854911804,
      "learning_rate": 8.495492695057508e-06,
      "loss": 0.0219,
      "step": 3872
    },
    {
      "epoch": 0.3009791731426795,
      "grad_norm": 0.34854692220687866,
      "learning_rate": 8.495104134286603e-06,
      "loss": 0.1395,
      "step": 3873
    },
    {
      "epoch": 0.3010568852968604,
      "grad_norm": 0.17121157050132751,
      "learning_rate": 8.494715573515698e-06,
      "loss": 0.1106,
      "step": 3874
    },
    {
      "epoch": 0.3011345974510413,
      "grad_norm": 0.1864742636680603,
      "learning_rate": 8.494327012744795e-06,
      "loss": 0.08,
      "step": 3875
    },
    {
      "epoch": 0.3012123096052223,
      "grad_norm": 0.9385573267936707,
      "learning_rate": 8.49393845197389e-06,
      "loss": 0.4221,
      "step": 3876
    },
    {
      "epoch": 0.30129002175940317,
      "grad_norm": 0.10767760127782822,
      "learning_rate": 8.493549891202985e-06,
      "loss": 0.0361,
      "step": 3877
    },
    {
      "epoch": 0.30136773391358407,
      "grad_norm": 0.1713273823261261,
      "learning_rate": 8.49316133043208e-06,
      "loss": 0.1082,
      "step": 3878
    },
    {
      "epoch": 0.301445446067765,
      "grad_norm": 0.26329952478408813,
      "learning_rate": 8.492772769661176e-06,
      "loss": 0.1736,
      "step": 3879
    },
    {
      "epoch": 0.3015231582219459,
      "grad_norm": 0.3236745297908783,
      "learning_rate": 8.492384208890271e-06,
      "loss": 0.3168,
      "step": 3880
    },
    {
      "epoch": 0.3016008703761268,
      "grad_norm": 0.5629767179489136,
      "learning_rate": 8.491995648119366e-06,
      "loss": 0.802,
      "step": 3881
    },
    {
      "epoch": 0.3016785825303077,
      "grad_norm": 0.24784046411514282,
      "learning_rate": 8.491607087348463e-06,
      "loss": 0.0377,
      "step": 3882
    },
    {
      "epoch": 0.30175629468448867,
      "grad_norm": 0.8173538446426392,
      "learning_rate": 8.491218526577558e-06,
      "loss": 0.1328,
      "step": 3883
    },
    {
      "epoch": 0.30183400683866957,
      "grad_norm": 0.24401740729808807,
      "learning_rate": 8.490829965806653e-06,
      "loss": 0.0627,
      "step": 3884
    },
    {
      "epoch": 0.30191171899285046,
      "grad_norm": 0.35153481364250183,
      "learning_rate": 8.49044140503575e-06,
      "loss": 0.0697,
      "step": 3885
    },
    {
      "epoch": 0.3019894311470314,
      "grad_norm": 0.3505316972732544,
      "learning_rate": 8.490052844264843e-06,
      "loss": 0.0888,
      "step": 3886
    },
    {
      "epoch": 0.3020671433012123,
      "grad_norm": 0.28954023122787476,
      "learning_rate": 8.489664283493939e-06,
      "loss": 0.2049,
      "step": 3887
    },
    {
      "epoch": 0.3021448554553932,
      "grad_norm": 0.21111775934696198,
      "learning_rate": 8.489275722723034e-06,
      "loss": 0.3207,
      "step": 3888
    },
    {
      "epoch": 0.3022225676095741,
      "grad_norm": 0.9034615755081177,
      "learning_rate": 8.488887161952129e-06,
      "loss": 0.6076,
      "step": 3889
    },
    {
      "epoch": 0.30230027976375506,
      "grad_norm": 0.07614974677562714,
      "learning_rate": 8.488498601181226e-06,
      "loss": 0.0147,
      "step": 3890
    },
    {
      "epoch": 0.30237799191793596,
      "grad_norm": 0.07952519506216049,
      "learning_rate": 8.48811004041032e-06,
      "loss": 0.0271,
      "step": 3891
    },
    {
      "epoch": 0.30245570407211686,
      "grad_norm": 1.491833209991455,
      "learning_rate": 8.487721479639416e-06,
      "loss": 0.5647,
      "step": 3892
    },
    {
      "epoch": 0.3025334162262978,
      "grad_norm": 0.1827460527420044,
      "learning_rate": 8.487332918868512e-06,
      "loss": 0.0339,
      "step": 3893
    },
    {
      "epoch": 0.3026111283804787,
      "grad_norm": 0.4417284429073334,
      "learning_rate": 8.486944358097607e-06,
      "loss": 0.1754,
      "step": 3894
    },
    {
      "epoch": 0.3026888405346596,
      "grad_norm": 0.19206267595291138,
      "learning_rate": 8.486555797326702e-06,
      "loss": 0.0881,
      "step": 3895
    },
    {
      "epoch": 0.30276655268884056,
      "grad_norm": 0.233834907412529,
      "learning_rate": 8.486167236555797e-06,
      "loss": 0.0582,
      "step": 3896
    },
    {
      "epoch": 0.30284426484302146,
      "grad_norm": 0.855829119682312,
      "learning_rate": 8.485778675784894e-06,
      "loss": 0.1,
      "step": 3897
    },
    {
      "epoch": 0.30292197699720236,
      "grad_norm": 0.2336421012878418,
      "learning_rate": 8.485390115013989e-06,
      "loss": 0.1044,
      "step": 3898
    },
    {
      "epoch": 0.30299968915138326,
      "grad_norm": 0.3473040759563446,
      "learning_rate": 8.485001554243084e-06,
      "loss": 0.0863,
      "step": 3899
    },
    {
      "epoch": 0.3030774013055642,
      "grad_norm": 0.013565530069172382,
      "learning_rate": 8.48461299347218e-06,
      "loss": 0.002,
      "step": 3900
    },
    {
      "epoch": 0.3031551134597451,
      "grad_norm": 0.45927438139915466,
      "learning_rate": 8.484224432701275e-06,
      "loss": 0.4208,
      "step": 3901
    },
    {
      "epoch": 0.303232825613926,
      "grad_norm": 0.8934043049812317,
      "learning_rate": 8.48383587193037e-06,
      "loss": 0.3387,
      "step": 3902
    },
    {
      "epoch": 0.30331053776810696,
      "grad_norm": 0.2767360508441925,
      "learning_rate": 8.483447311159467e-06,
      "loss": 0.1491,
      "step": 3903
    },
    {
      "epoch": 0.30338824992228786,
      "grad_norm": 0.2740464210510254,
      "learning_rate": 8.483058750388562e-06,
      "loss": 0.3395,
      "step": 3904
    },
    {
      "epoch": 0.30346596207646875,
      "grad_norm": 0.37110283970832825,
      "learning_rate": 8.482670189617657e-06,
      "loss": 0.2726,
      "step": 3905
    },
    {
      "epoch": 0.30354367423064965,
      "grad_norm": 1.0472443103790283,
      "learning_rate": 8.482281628846752e-06,
      "loss": 0.2093,
      "step": 3906
    },
    {
      "epoch": 0.3036213863848306,
      "grad_norm": 0.16963191330432892,
      "learning_rate": 8.481893068075848e-06,
      "loss": 0.1227,
      "step": 3907
    },
    {
      "epoch": 0.3036990985390115,
      "grad_norm": 0.15324273705482483,
      "learning_rate": 8.481504507304943e-06,
      "loss": 0.0706,
      "step": 3908
    },
    {
      "epoch": 0.3037768106931924,
      "grad_norm": 0.44324856996536255,
      "learning_rate": 8.481115946534038e-06,
      "loss": 0.0873,
      "step": 3909
    },
    {
      "epoch": 0.30385452284737335,
      "grad_norm": 0.14271748065948486,
      "learning_rate": 8.480727385763135e-06,
      "loss": 0.016,
      "step": 3910
    },
    {
      "epoch": 0.30393223500155425,
      "grad_norm": 0.16581448912620544,
      "learning_rate": 8.48033882499223e-06,
      "loss": 0.2159,
      "step": 3911
    },
    {
      "epoch": 0.30400994715573515,
      "grad_norm": 0.24865224957466125,
      "learning_rate": 8.479950264221325e-06,
      "loss": 0.0378,
      "step": 3912
    },
    {
      "epoch": 0.30408765930991605,
      "grad_norm": 0.3128719627857208,
      "learning_rate": 8.479561703450421e-06,
      "loss": 0.1804,
      "step": 3913
    },
    {
      "epoch": 0.304165371464097,
      "grad_norm": 0.24041664600372314,
      "learning_rate": 8.479173142679515e-06,
      "loss": 0.1863,
      "step": 3914
    },
    {
      "epoch": 0.3042430836182779,
      "grad_norm": 0.7143844366073608,
      "learning_rate": 8.478784581908611e-06,
      "loss": 0.3578,
      "step": 3915
    },
    {
      "epoch": 0.3043207957724588,
      "grad_norm": 0.33261972665786743,
      "learning_rate": 8.478396021137706e-06,
      "loss": 0.1144,
      "step": 3916
    },
    {
      "epoch": 0.30439850792663975,
      "grad_norm": 0.7172540426254272,
      "learning_rate": 8.478007460366801e-06,
      "loss": 0.8411,
      "step": 3917
    },
    {
      "epoch": 0.30447622008082065,
      "grad_norm": 0.1480429321527481,
      "learning_rate": 8.477618899595898e-06,
      "loss": 0.0849,
      "step": 3918
    },
    {
      "epoch": 0.30455393223500155,
      "grad_norm": 0.9246009588241577,
      "learning_rate": 8.477230338824993e-06,
      "loss": 0.4954,
      "step": 3919
    },
    {
      "epoch": 0.30463164438918244,
      "grad_norm": 0.2959330081939697,
      "learning_rate": 8.476841778054088e-06,
      "loss": 0.2277,
      "step": 3920
    },
    {
      "epoch": 0.3047093565433634,
      "grad_norm": 0.14507004618644714,
      "learning_rate": 8.476453217283184e-06,
      "loss": 0.0694,
      "step": 3921
    },
    {
      "epoch": 0.3047870686975443,
      "grad_norm": 0.36422765254974365,
      "learning_rate": 8.47606465651228e-06,
      "loss": 0.3312,
      "step": 3922
    },
    {
      "epoch": 0.3048647808517252,
      "grad_norm": 0.4374304711818695,
      "learning_rate": 8.475676095741374e-06,
      "loss": 0.1625,
      "step": 3923
    },
    {
      "epoch": 0.30494249300590615,
      "grad_norm": 0.3288208544254303,
      "learning_rate": 8.47528753497047e-06,
      "loss": 0.2105,
      "step": 3924
    },
    {
      "epoch": 0.30502020516008704,
      "grad_norm": 0.344582736492157,
      "learning_rate": 8.474898974199566e-06,
      "loss": 0.1358,
      "step": 3925
    },
    {
      "epoch": 0.30509791731426794,
      "grad_norm": 0.1495305746793747,
      "learning_rate": 8.47451041342866e-06,
      "loss": 0.0628,
      "step": 3926
    },
    {
      "epoch": 0.30517562946844884,
      "grad_norm": 0.03487899899482727,
      "learning_rate": 8.474121852657756e-06,
      "loss": 0.0079,
      "step": 3927
    },
    {
      "epoch": 0.3052533416226298,
      "grad_norm": 0.9197744727134705,
      "learning_rate": 8.473733291886852e-06,
      "loss": 0.678,
      "step": 3928
    },
    {
      "epoch": 0.3053310537768107,
      "grad_norm": 0.13160832226276398,
      "learning_rate": 8.473344731115947e-06,
      "loss": 0.0604,
      "step": 3929
    },
    {
      "epoch": 0.3054087659309916,
      "grad_norm": 0.515997588634491,
      "learning_rate": 8.472956170345042e-06,
      "loss": 0.2778,
      "step": 3930
    },
    {
      "epoch": 0.30548647808517254,
      "grad_norm": 0.22064867615699768,
      "learning_rate": 8.472567609574139e-06,
      "loss": 0.0712,
      "step": 3931
    },
    {
      "epoch": 0.30556419023935344,
      "grad_norm": 0.34940940141677856,
      "learning_rate": 8.472179048803234e-06,
      "loss": 0.1495,
      "step": 3932
    },
    {
      "epoch": 0.30564190239353434,
      "grad_norm": 0.3534795939922333,
      "learning_rate": 8.471790488032329e-06,
      "loss": 0.1768,
      "step": 3933
    },
    {
      "epoch": 0.30571961454771523,
      "grad_norm": 0.3526681363582611,
      "learning_rate": 8.471401927261424e-06,
      "loss": 0.1069,
      "step": 3934
    },
    {
      "epoch": 0.3057973267018962,
      "grad_norm": 0.1807919591665268,
      "learning_rate": 8.47101336649052e-06,
      "loss": 0.05,
      "step": 3935
    },
    {
      "epoch": 0.3058750388560771,
      "grad_norm": 0.43769940733909607,
      "learning_rate": 8.470624805719615e-06,
      "loss": 0.2345,
      "step": 3936
    },
    {
      "epoch": 0.305952751010258,
      "grad_norm": 0.1363351047039032,
      "learning_rate": 8.47023624494871e-06,
      "loss": 0.0417,
      "step": 3937
    },
    {
      "epoch": 0.30603046316443894,
      "grad_norm": 0.5572249293327332,
      "learning_rate": 8.469847684177807e-06,
      "loss": 0.0509,
      "step": 3938
    },
    {
      "epoch": 0.30610817531861984,
      "grad_norm": 0.24631868302822113,
      "learning_rate": 8.469459123406902e-06,
      "loss": 0.1726,
      "step": 3939
    },
    {
      "epoch": 0.30618588747280073,
      "grad_norm": 0.33176708221435547,
      "learning_rate": 8.469070562635997e-06,
      "loss": 0.1899,
      "step": 3940
    },
    {
      "epoch": 0.3062635996269817,
      "grad_norm": 0.4970443546772003,
      "learning_rate": 8.468682001865094e-06,
      "loss": 0.6928,
      "step": 3941
    },
    {
      "epoch": 0.3063413117811626,
      "grad_norm": 0.08003878593444824,
      "learning_rate": 8.468293441094187e-06,
      "loss": 0.0419,
      "step": 3942
    },
    {
      "epoch": 0.3064190239353435,
      "grad_norm": 0.2264832854270935,
      "learning_rate": 8.467904880323283e-06,
      "loss": 0.1727,
      "step": 3943
    },
    {
      "epoch": 0.3064967360895244,
      "grad_norm": 0.1859905868768692,
      "learning_rate": 8.467516319552378e-06,
      "loss": 0.0314,
      "step": 3944
    },
    {
      "epoch": 0.30657444824370533,
      "grad_norm": 0.2360266000032425,
      "learning_rate": 8.467127758781473e-06,
      "loss": 0.1295,
      "step": 3945
    },
    {
      "epoch": 0.30665216039788623,
      "grad_norm": 0.5584412813186646,
      "learning_rate": 8.46673919801057e-06,
      "loss": 0.2315,
      "step": 3946
    },
    {
      "epoch": 0.30672987255206713,
      "grad_norm": 0.42251500487327576,
      "learning_rate": 8.466350637239665e-06,
      "loss": 0.2526,
      "step": 3947
    },
    {
      "epoch": 0.3068075847062481,
      "grad_norm": 0.6646386384963989,
      "learning_rate": 8.46596207646876e-06,
      "loss": 0.252,
      "step": 3948
    },
    {
      "epoch": 0.306885296860429,
      "grad_norm": 0.48680537939071655,
      "learning_rate": 8.465573515697857e-06,
      "loss": 0.1809,
      "step": 3949
    },
    {
      "epoch": 0.3069630090146099,
      "grad_norm": 0.37846508622169495,
      "learning_rate": 8.465184954926951e-06,
      "loss": 0.0759,
      "step": 3950
    },
    {
      "epoch": 0.3070407211687908,
      "grad_norm": 0.15253911912441254,
      "learning_rate": 8.464796394156046e-06,
      "loss": 0.0775,
      "step": 3951
    },
    {
      "epoch": 0.30711843332297173,
      "grad_norm": 0.28596267104148865,
      "learning_rate": 8.464407833385141e-06,
      "loss": 0.0959,
      "step": 3952
    },
    {
      "epoch": 0.3071961454771526,
      "grad_norm": 0.5273838043212891,
      "learning_rate": 8.464019272614238e-06,
      "loss": 0.4253,
      "step": 3953
    },
    {
      "epoch": 0.3072738576313335,
      "grad_norm": 0.16940590739250183,
      "learning_rate": 8.463630711843333e-06,
      "loss": 0.0263,
      "step": 3954
    },
    {
      "epoch": 0.3073515697855145,
      "grad_norm": 0.3442215919494629,
      "learning_rate": 8.463242151072428e-06,
      "loss": 0.1661,
      "step": 3955
    },
    {
      "epoch": 0.3074292819396954,
      "grad_norm": 0.5217562913894653,
      "learning_rate": 8.462853590301525e-06,
      "loss": 0.4288,
      "step": 3956
    },
    {
      "epoch": 0.3075069940938763,
      "grad_norm": 0.14205971360206604,
      "learning_rate": 8.46246502953062e-06,
      "loss": 0.061,
      "step": 3957
    },
    {
      "epoch": 0.30758470624805717,
      "grad_norm": 0.2582542896270752,
      "learning_rate": 8.462076468759714e-06,
      "loss": 0.0379,
      "step": 3958
    },
    {
      "epoch": 0.3076624184022381,
      "grad_norm": 0.2902573347091675,
      "learning_rate": 8.461687907988811e-06,
      "loss": 0.3653,
      "step": 3959
    },
    {
      "epoch": 0.307740130556419,
      "grad_norm": 0.5569120049476624,
      "learning_rate": 8.461299347217904e-06,
      "loss": 0.2526,
      "step": 3960
    },
    {
      "epoch": 0.3078178427105999,
      "grad_norm": 0.165651336312294,
      "learning_rate": 8.460910786447001e-06,
      "loss": 0.0922,
      "step": 3961
    },
    {
      "epoch": 0.3078955548647809,
      "grad_norm": 0.18701446056365967,
      "learning_rate": 8.460522225676096e-06,
      "loss": 0.1605,
      "step": 3962
    },
    {
      "epoch": 0.30797326701896177,
      "grad_norm": 0.2829475700855255,
      "learning_rate": 8.460133664905193e-06,
      "loss": 0.0998,
      "step": 3963
    },
    {
      "epoch": 0.30805097917314267,
      "grad_norm": 0.29736557602882385,
      "learning_rate": 8.459745104134288e-06,
      "loss": 0.1672,
      "step": 3964
    },
    {
      "epoch": 0.30812869132732357,
      "grad_norm": 0.12770558893680573,
      "learning_rate": 8.459356543363383e-06,
      "loss": 0.0897,
      "step": 3965
    },
    {
      "epoch": 0.3082064034815045,
      "grad_norm": 0.25155532360076904,
      "learning_rate": 8.458967982592479e-06,
      "loss": 0.0943,
      "step": 3966
    },
    {
      "epoch": 0.3082841156356854,
      "grad_norm": 0.43126535415649414,
      "learning_rate": 8.458579421821574e-06,
      "loss": 0.2703,
      "step": 3967
    },
    {
      "epoch": 0.3083618277898663,
      "grad_norm": 0.29325130581855774,
      "learning_rate": 8.458190861050669e-06,
      "loss": 0.0812,
      "step": 3968
    },
    {
      "epoch": 0.30843953994404727,
      "grad_norm": 0.12720324099063873,
      "learning_rate": 8.457802300279766e-06,
      "loss": 0.0473,
      "step": 3969
    },
    {
      "epoch": 0.30851725209822817,
      "grad_norm": 1.1916826963424683,
      "learning_rate": 8.457413739508859e-06,
      "loss": 0.1982,
      "step": 3970
    },
    {
      "epoch": 0.30859496425240907,
      "grad_norm": 0.11051654815673828,
      "learning_rate": 8.457025178737956e-06,
      "loss": 0.0299,
      "step": 3971
    },
    {
      "epoch": 0.30867267640658996,
      "grad_norm": 0.1444278210401535,
      "learning_rate": 8.45663661796705e-06,
      "loss": 0.0642,
      "step": 3972
    },
    {
      "epoch": 0.3087503885607709,
      "grad_norm": 0.19384020566940308,
      "learning_rate": 8.456248057196145e-06,
      "loss": 0.0756,
      "step": 3973
    },
    {
      "epoch": 0.3088281007149518,
      "grad_norm": 0.15433132648468018,
      "learning_rate": 8.455859496425242e-06,
      "loss": 0.0633,
      "step": 3974
    },
    {
      "epoch": 0.3089058128691327,
      "grad_norm": 0.2651699185371399,
      "learning_rate": 8.455470935654337e-06,
      "loss": 0.0813,
      "step": 3975
    },
    {
      "epoch": 0.30898352502331367,
      "grad_norm": 0.2777637243270874,
      "learning_rate": 8.455082374883432e-06,
      "loss": 0.1916,
      "step": 3976
    },
    {
      "epoch": 0.30906123717749456,
      "grad_norm": 0.38289883732795715,
      "learning_rate": 8.454693814112529e-06,
      "loss": 0.1292,
      "step": 3977
    },
    {
      "epoch": 0.30913894933167546,
      "grad_norm": 0.2652814984321594,
      "learning_rate": 8.454305253341624e-06,
      "loss": 0.3048,
      "step": 3978
    },
    {
      "epoch": 0.3092166614858564,
      "grad_norm": 0.17469219863414764,
      "learning_rate": 8.453916692570719e-06,
      "loss": 0.0677,
      "step": 3979
    },
    {
      "epoch": 0.3092943736400373,
      "grad_norm": 0.2981250584125519,
      "learning_rate": 8.453528131799814e-06,
      "loss": 0.0977,
      "step": 3980
    },
    {
      "epoch": 0.3093720857942182,
      "grad_norm": 0.10227912664413452,
      "learning_rate": 8.45313957102891e-06,
      "loss": 0.017,
      "step": 3981
    },
    {
      "epoch": 0.3094497979483991,
      "grad_norm": 0.2781471908092499,
      "learning_rate": 8.452751010258005e-06,
      "loss": 0.2866,
      "step": 3982
    },
    {
      "epoch": 0.30952751010258006,
      "grad_norm": 0.35514745116233826,
      "learning_rate": 8.4523624494871e-06,
      "loss": 0.1999,
      "step": 3983
    },
    {
      "epoch": 0.30960522225676096,
      "grad_norm": 0.3016003668308258,
      "learning_rate": 8.451973888716197e-06,
      "loss": 0.2896,
      "step": 3984
    },
    {
      "epoch": 0.30968293441094186,
      "grad_norm": 0.16600815951824188,
      "learning_rate": 8.451585327945292e-06,
      "loss": 0.0324,
      "step": 3985
    },
    {
      "epoch": 0.3097606465651228,
      "grad_norm": 0.6997098326683044,
      "learning_rate": 8.451196767174387e-06,
      "loss": 0.2397,
      "step": 3986
    },
    {
      "epoch": 0.3098383587193037,
      "grad_norm": 0.10230081528425217,
      "learning_rate": 8.450808206403483e-06,
      "loss": 0.061,
      "step": 3987
    },
    {
      "epoch": 0.3099160708734846,
      "grad_norm": 0.13703623414039612,
      "learning_rate": 8.450419645632577e-06,
      "loss": 0.055,
      "step": 3988
    },
    {
      "epoch": 0.3099937830276655,
      "grad_norm": 0.23346388339996338,
      "learning_rate": 8.450031084861673e-06,
      "loss": 0.1636,
      "step": 3989
    },
    {
      "epoch": 0.31007149518184646,
      "grad_norm": 0.2755289077758789,
      "learning_rate": 8.449642524090768e-06,
      "loss": 0.3159,
      "step": 3990
    },
    {
      "epoch": 0.31014920733602735,
      "grad_norm": 0.24176649749279022,
      "learning_rate": 8.449253963319865e-06,
      "loss": 0.0496,
      "step": 3991
    },
    {
      "epoch": 0.31022691949020825,
      "grad_norm": 0.33794307708740234,
      "learning_rate": 8.44886540254896e-06,
      "loss": 0.549,
      "step": 3992
    },
    {
      "epoch": 0.3103046316443892,
      "grad_norm": 0.3344168961048126,
      "learning_rate": 8.448476841778055e-06,
      "loss": 0.1521,
      "step": 3993
    },
    {
      "epoch": 0.3103823437985701,
      "grad_norm": 0.23576895892620087,
      "learning_rate": 8.448088281007151e-06,
      "loss": 0.2224,
      "step": 3994
    },
    {
      "epoch": 0.310460055952751,
      "grad_norm": 0.7010406851768494,
      "learning_rate": 8.447699720236246e-06,
      "loss": 0.3164,
      "step": 3995
    },
    {
      "epoch": 0.3105377681069319,
      "grad_norm": 0.1654353141784668,
      "learning_rate": 8.447311159465341e-06,
      "loss": 0.0363,
      "step": 3996
    },
    {
      "epoch": 0.31061548026111285,
      "grad_norm": 0.460032194852829,
      "learning_rate": 8.446922598694436e-06,
      "loss": 0.2586,
      "step": 3997
    },
    {
      "epoch": 0.31069319241529375,
      "grad_norm": 0.6728562116622925,
      "learning_rate": 8.446534037923531e-06,
      "loss": 0.4096,
      "step": 3998
    },
    {
      "epoch": 0.31077090456947465,
      "grad_norm": 0.6008276343345642,
      "learning_rate": 8.446145477152628e-06,
      "loss": 0.4091,
      "step": 3999
    },
    {
      "epoch": 0.3108486167236556,
      "grad_norm": 0.426375150680542,
      "learning_rate": 8.445756916381723e-06,
      "loss": 0.4501,
      "step": 4000
    },
    {
      "epoch": 0.3109263288778365,
      "grad_norm": 0.2729197144508362,
      "learning_rate": 8.445368355610818e-06,
      "loss": 0.1526,
      "step": 4001
    },
    {
      "epoch": 0.3110040410320174,
      "grad_norm": 0.4327390789985657,
      "learning_rate": 8.444979794839914e-06,
      "loss": 0.4247,
      "step": 4002
    },
    {
      "epoch": 0.3110817531861983,
      "grad_norm": 0.3427128195762634,
      "learning_rate": 8.44459123406901e-06,
      "loss": 0.1187,
      "step": 4003
    },
    {
      "epoch": 0.31115946534037925,
      "grad_norm": 0.1801127791404724,
      "learning_rate": 8.444202673298104e-06,
      "loss": 0.0748,
      "step": 4004
    },
    {
      "epoch": 0.31123717749456015,
      "grad_norm": 0.3132201135158539,
      "learning_rate": 8.443814112527199e-06,
      "loss": 0.1024,
      "step": 4005
    },
    {
      "epoch": 0.31131488964874104,
      "grad_norm": 0.38880789279937744,
      "learning_rate": 8.443425551756296e-06,
      "loss": 0.2192,
      "step": 4006
    },
    {
      "epoch": 0.311392601802922,
      "grad_norm": 0.3960207402706146,
      "learning_rate": 8.44303699098539e-06,
      "loss": 0.1787,
      "step": 4007
    },
    {
      "epoch": 0.3114703139571029,
      "grad_norm": 0.6403278708457947,
      "learning_rate": 8.442648430214486e-06,
      "loss": 0.4994,
      "step": 4008
    },
    {
      "epoch": 0.3115480261112838,
      "grad_norm": 0.040654174983501434,
      "learning_rate": 8.442259869443582e-06,
      "loss": 0.0046,
      "step": 4009
    },
    {
      "epoch": 0.3116257382654647,
      "grad_norm": 0.11760708689689636,
      "learning_rate": 8.441871308672677e-06,
      "loss": 0.0914,
      "step": 4010
    },
    {
      "epoch": 0.31170345041964564,
      "grad_norm": 0.11657480150461197,
      "learning_rate": 8.441482747901772e-06,
      "loss": 0.1002,
      "step": 4011
    },
    {
      "epoch": 0.31178116257382654,
      "grad_norm": 0.9466031789779663,
      "learning_rate": 8.441094187130869e-06,
      "loss": 0.5718,
      "step": 4012
    },
    {
      "epoch": 0.31185887472800744,
      "grad_norm": 0.5182207226753235,
      "learning_rate": 8.440705626359962e-06,
      "loss": 0.1368,
      "step": 4013
    },
    {
      "epoch": 0.3119365868821884,
      "grad_norm": 0.720389187335968,
      "learning_rate": 8.440317065589059e-06,
      "loss": 0.469,
      "step": 4014
    },
    {
      "epoch": 0.3120142990363693,
      "grad_norm": 0.6280940175056458,
      "learning_rate": 8.439928504818154e-06,
      "loss": 0.1015,
      "step": 4015
    },
    {
      "epoch": 0.3120920111905502,
      "grad_norm": 0.31036949157714844,
      "learning_rate": 8.439539944047249e-06,
      "loss": 0.1204,
      "step": 4016
    },
    {
      "epoch": 0.31216972334473114,
      "grad_norm": 0.506953239440918,
      "learning_rate": 8.439151383276345e-06,
      "loss": 0.1724,
      "step": 4017
    },
    {
      "epoch": 0.31224743549891204,
      "grad_norm": 0.10070985555648804,
      "learning_rate": 8.43876282250544e-06,
      "loss": 0.0295,
      "step": 4018
    },
    {
      "epoch": 0.31232514765309294,
      "grad_norm": 0.4631511867046356,
      "learning_rate": 8.438374261734535e-06,
      "loss": 0.162,
      "step": 4019
    },
    {
      "epoch": 0.31240285980727384,
      "grad_norm": 0.32006382942199707,
      "learning_rate": 8.437985700963632e-06,
      "loss": 0.1854,
      "step": 4020
    },
    {
      "epoch": 0.3124805719614548,
      "grad_norm": 0.5280055999755859,
      "learning_rate": 8.437597140192727e-06,
      "loss": 0.0722,
      "step": 4021
    },
    {
      "epoch": 0.3125582841156357,
      "grad_norm": 0.5529015064239502,
      "learning_rate": 8.437208579421823e-06,
      "loss": 0.2246,
      "step": 4022
    },
    {
      "epoch": 0.3126359962698166,
      "grad_norm": 0.3927219808101654,
      "learning_rate": 8.436820018650917e-06,
      "loss": 0.1866,
      "step": 4023
    },
    {
      "epoch": 0.31271370842399754,
      "grad_norm": 0.48408809304237366,
      "learning_rate": 8.436431457880013e-06,
      "loss": 0.7024,
      "step": 4024
    },
    {
      "epoch": 0.31279142057817844,
      "grad_norm": 0.17403210699558258,
      "learning_rate": 8.436042897109108e-06,
      "loss": 0.052,
      "step": 4025
    },
    {
      "epoch": 0.31286913273235933,
      "grad_norm": 0.49433478713035583,
      "learning_rate": 8.435654336338203e-06,
      "loss": 0.2324,
      "step": 4026
    },
    {
      "epoch": 0.31294684488654023,
      "grad_norm": 0.2855342924594879,
      "learning_rate": 8.4352657755673e-06,
      "loss": 0.0854,
      "step": 4027
    },
    {
      "epoch": 0.3130245570407212,
      "grad_norm": 0.1300061196088791,
      "learning_rate": 8.434877214796395e-06,
      "loss": 0.0331,
      "step": 4028
    },
    {
      "epoch": 0.3131022691949021,
      "grad_norm": 0.2847265303134918,
      "learning_rate": 8.43448865402549e-06,
      "loss": 0.1662,
      "step": 4029
    },
    {
      "epoch": 0.313179981349083,
      "grad_norm": 0.3018880784511566,
      "learning_rate": 8.434100093254586e-06,
      "loss": 0.1423,
      "step": 4030
    },
    {
      "epoch": 0.31325769350326393,
      "grad_norm": 1.1285109519958496,
      "learning_rate": 8.433711532483681e-06,
      "loss": 0.9743,
      "step": 4031
    },
    {
      "epoch": 0.31333540565744483,
      "grad_norm": 0.5514228940010071,
      "learning_rate": 8.433322971712776e-06,
      "loss": 0.3158,
      "step": 4032
    },
    {
      "epoch": 0.31341311781162573,
      "grad_norm": 0.19648851454257965,
      "learning_rate": 8.432934410941871e-06,
      "loss": 0.1126,
      "step": 4033
    },
    {
      "epoch": 0.3134908299658066,
      "grad_norm": 0.4147305488586426,
      "learning_rate": 8.432545850170968e-06,
      "loss": 0.3816,
      "step": 4034
    },
    {
      "epoch": 0.3135685421199876,
      "grad_norm": 0.368448406457901,
      "learning_rate": 8.432157289400063e-06,
      "loss": 0.1571,
      "step": 4035
    },
    {
      "epoch": 0.3136462542741685,
      "grad_norm": 0.14485964179039001,
      "learning_rate": 8.431768728629158e-06,
      "loss": 0.0765,
      "step": 4036
    },
    {
      "epoch": 0.3137239664283494,
      "grad_norm": 0.19812485575675964,
      "learning_rate": 8.431380167858254e-06,
      "loss": 0.0582,
      "step": 4037
    },
    {
      "epoch": 0.31380167858253033,
      "grad_norm": 0.24508623778820038,
      "learning_rate": 8.43099160708735e-06,
      "loss": 0.3118,
      "step": 4038
    },
    {
      "epoch": 0.31387939073671123,
      "grad_norm": 0.34820178151130676,
      "learning_rate": 8.430603046316444e-06,
      "loss": 0.2275,
      "step": 4039
    },
    {
      "epoch": 0.3139571028908921,
      "grad_norm": 0.41687485575675964,
      "learning_rate": 8.430214485545541e-06,
      "loss": 0.2858,
      "step": 4040
    },
    {
      "epoch": 0.314034815045073,
      "grad_norm": 0.0775255337357521,
      "learning_rate": 8.429825924774634e-06,
      "loss": 0.0334,
      "step": 4041
    },
    {
      "epoch": 0.314112527199254,
      "grad_norm": 0.18294571340084076,
      "learning_rate": 8.429437364003731e-06,
      "loss": 0.127,
      "step": 4042
    },
    {
      "epoch": 0.3141902393534349,
      "grad_norm": 0.23253975808620453,
      "learning_rate": 8.429048803232826e-06,
      "loss": 0.0361,
      "step": 4043
    },
    {
      "epoch": 0.3142679515076158,
      "grad_norm": 0.7320981025695801,
      "learning_rate": 8.42866024246192e-06,
      "loss": 1.1287,
      "step": 4044
    },
    {
      "epoch": 0.3143456636617967,
      "grad_norm": 0.11351567506790161,
      "learning_rate": 8.428271681691017e-06,
      "loss": 0.0563,
      "step": 4045
    },
    {
      "epoch": 0.3144233758159776,
      "grad_norm": 0.24485436081886292,
      "learning_rate": 8.427883120920112e-06,
      "loss": 0.1697,
      "step": 4046
    },
    {
      "epoch": 0.3145010879701585,
      "grad_norm": 0.17569500207901,
      "learning_rate": 8.427494560149207e-06,
      "loss": 0.086,
      "step": 4047
    },
    {
      "epoch": 0.3145788001243394,
      "grad_norm": 0.19300037622451782,
      "learning_rate": 8.427105999378304e-06,
      "loss": 0.4794,
      "step": 4048
    },
    {
      "epoch": 0.3146565122785204,
      "grad_norm": 0.282685250043869,
      "learning_rate": 8.426717438607399e-06,
      "loss": 0.0773,
      "step": 4049
    },
    {
      "epoch": 0.31473422443270127,
      "grad_norm": 0.3792349696159363,
      "learning_rate": 8.426328877836494e-06,
      "loss": 0.2533,
      "step": 4050
    },
    {
      "epoch": 0.31481193658688217,
      "grad_norm": 0.06660416722297668,
      "learning_rate": 8.425940317065589e-06,
      "loss": 0.0064,
      "step": 4051
    },
    {
      "epoch": 0.3148896487410631,
      "grad_norm": 0.39538875222206116,
      "learning_rate": 8.425551756294685e-06,
      "loss": 0.2117,
      "step": 4052
    },
    {
      "epoch": 0.314967360895244,
      "grad_norm": 0.6104893088340759,
      "learning_rate": 8.42516319552378e-06,
      "loss": 0.3039,
      "step": 4053
    },
    {
      "epoch": 0.3150450730494249,
      "grad_norm": 0.29035767912864685,
      "learning_rate": 8.424774634752875e-06,
      "loss": 0.2202,
      "step": 4054
    },
    {
      "epoch": 0.31512278520360587,
      "grad_norm": 0.20529267191886902,
      "learning_rate": 8.424386073981972e-06,
      "loss": 0.1237,
      "step": 4055
    },
    {
      "epoch": 0.31520049735778677,
      "grad_norm": 0.7967450618743896,
      "learning_rate": 8.423997513211067e-06,
      "loss": 0.8875,
      "step": 4056
    },
    {
      "epoch": 0.31527820951196767,
      "grad_norm": 0.14790742099285126,
      "learning_rate": 8.423608952440162e-06,
      "loss": 0.049,
      "step": 4057
    },
    {
      "epoch": 0.31535592166614856,
      "grad_norm": 0.07321318984031677,
      "learning_rate": 8.423220391669259e-06,
      "loss": 0.0183,
      "step": 4058
    },
    {
      "epoch": 0.3154336338203295,
      "grad_norm": 0.5949143171310425,
      "learning_rate": 8.422831830898354e-06,
      "loss": 0.2578,
      "step": 4059
    },
    {
      "epoch": 0.3155113459745104,
      "grad_norm": 0.16088734567165375,
      "learning_rate": 8.422443270127448e-06,
      "loss": 0.0936,
      "step": 4060
    },
    {
      "epoch": 0.3155890581286913,
      "grad_norm": 0.9361542463302612,
      "learning_rate": 8.422054709356543e-06,
      "loss": 0.408,
      "step": 4061
    },
    {
      "epoch": 0.31566677028287227,
      "grad_norm": 0.3430083692073822,
      "learning_rate": 8.42166614858564e-06,
      "loss": 0.3,
      "step": 4062
    },
    {
      "epoch": 0.31574448243705316,
      "grad_norm": 0.3589290976524353,
      "learning_rate": 8.421277587814735e-06,
      "loss": 0.1164,
      "step": 4063
    },
    {
      "epoch": 0.31582219459123406,
      "grad_norm": 0.5428174734115601,
      "learning_rate": 8.42088902704383e-06,
      "loss": 0.3275,
      "step": 4064
    },
    {
      "epoch": 0.31589990674541496,
      "grad_norm": 0.16693511605262756,
      "learning_rate": 8.420500466272927e-06,
      "loss": 0.111,
      "step": 4065
    },
    {
      "epoch": 0.3159776188995959,
      "grad_norm": 0.044514209032058716,
      "learning_rate": 8.420111905502022e-06,
      "loss": 0.0063,
      "step": 4066
    },
    {
      "epoch": 0.3160553310537768,
      "grad_norm": 1.3530150651931763,
      "learning_rate": 8.419723344731117e-06,
      "loss": 0.334,
      "step": 4067
    },
    {
      "epoch": 0.3161330432079577,
      "grad_norm": 0.32305118441581726,
      "learning_rate": 8.419334783960213e-06,
      "loss": 0.1511,
      "step": 4068
    },
    {
      "epoch": 0.31621075536213866,
      "grad_norm": 0.38629600405693054,
      "learning_rate": 8.418946223189306e-06,
      "loss": 0.1383,
      "step": 4069
    },
    {
      "epoch": 0.31628846751631956,
      "grad_norm": 0.6820474863052368,
      "learning_rate": 8.418557662418403e-06,
      "loss": 0.4027,
      "step": 4070
    },
    {
      "epoch": 0.31636617967050046,
      "grad_norm": 0.2384437471628189,
      "learning_rate": 8.418169101647498e-06,
      "loss": 0.2268,
      "step": 4071
    },
    {
      "epoch": 0.31644389182468136,
      "grad_norm": 0.47652024030685425,
      "learning_rate": 8.417780540876593e-06,
      "loss": 0.1941,
      "step": 4072
    },
    {
      "epoch": 0.3165216039788623,
      "grad_norm": 0.9979799389839172,
      "learning_rate": 8.41739198010569e-06,
      "loss": 0.3017,
      "step": 4073
    },
    {
      "epoch": 0.3165993161330432,
      "grad_norm": 0.1936732977628708,
      "learning_rate": 8.417003419334785e-06,
      "loss": 0.188,
      "step": 4074
    },
    {
      "epoch": 0.3166770282872241,
      "grad_norm": 0.13858285546302795,
      "learning_rate": 8.41661485856388e-06,
      "loss": 0.052,
      "step": 4075
    },
    {
      "epoch": 0.31675474044140506,
      "grad_norm": 0.39834603667259216,
      "learning_rate": 8.416226297792976e-06,
      "loss": 0.3326,
      "step": 4076
    },
    {
      "epoch": 0.31683245259558596,
      "grad_norm": 0.5146437883377075,
      "learning_rate": 8.415837737022071e-06,
      "loss": 0.4074,
      "step": 4077
    },
    {
      "epoch": 0.31691016474976685,
      "grad_norm": 0.48609474301338196,
      "learning_rate": 8.415449176251166e-06,
      "loss": 0.2053,
      "step": 4078
    },
    {
      "epoch": 0.31698787690394775,
      "grad_norm": 0.0868285745382309,
      "learning_rate": 8.415060615480261e-06,
      "loss": 0.022,
      "step": 4079
    },
    {
      "epoch": 0.3170655890581287,
      "grad_norm": 0.4691002368927002,
      "learning_rate": 8.414672054709358e-06,
      "loss": 0.3536,
      "step": 4080
    },
    {
      "epoch": 0.3171433012123096,
      "grad_norm": 0.4725453555583954,
      "learning_rate": 8.414283493938453e-06,
      "loss": 0.1768,
      "step": 4081
    },
    {
      "epoch": 0.3172210133664905,
      "grad_norm": 0.07240729033946991,
      "learning_rate": 8.413894933167548e-06,
      "loss": 0.0363,
      "step": 4082
    },
    {
      "epoch": 0.31729872552067145,
      "grad_norm": 0.6796598434448242,
      "learning_rate": 8.413506372396644e-06,
      "loss": 0.2245,
      "step": 4083
    },
    {
      "epoch": 0.31737643767485235,
      "grad_norm": 0.26411429047584534,
      "learning_rate": 8.413117811625739e-06,
      "loss": 0.1407,
      "step": 4084
    },
    {
      "epoch": 0.31745414982903325,
      "grad_norm": 0.08019145578145981,
      "learning_rate": 8.412729250854834e-06,
      "loss": 0.0292,
      "step": 4085
    },
    {
      "epoch": 0.31753186198321415,
      "grad_norm": 0.1134994849562645,
      "learning_rate": 8.41234069008393e-06,
      "loss": 0.0465,
      "step": 4086
    },
    {
      "epoch": 0.3176095741373951,
      "grad_norm": 0.24310392141342163,
      "learning_rate": 8.411952129313026e-06,
      "loss": 0.0375,
      "step": 4087
    },
    {
      "epoch": 0.317687286291576,
      "grad_norm": 0.12108471244573593,
      "learning_rate": 8.41156356854212e-06,
      "loss": 0.0625,
      "step": 4088
    },
    {
      "epoch": 0.3177649984457569,
      "grad_norm": 0.20677931606769562,
      "learning_rate": 8.411175007771216e-06,
      "loss": 0.1047,
      "step": 4089
    },
    {
      "epoch": 0.31784271059993785,
      "grad_norm": 0.34857407212257385,
      "learning_rate": 8.410786447000312e-06,
      "loss": 0.1647,
      "step": 4090
    },
    {
      "epoch": 0.31792042275411875,
      "grad_norm": 0.2038905918598175,
      "learning_rate": 8.410397886229407e-06,
      "loss": 0.0753,
      "step": 4091
    },
    {
      "epoch": 0.31799813490829965,
      "grad_norm": 0.28427931666374207,
      "learning_rate": 8.410009325458502e-06,
      "loss": 0.0394,
      "step": 4092
    },
    {
      "epoch": 0.3180758470624806,
      "grad_norm": 0.2835398316383362,
      "learning_rate": 8.409620764687599e-06,
      "loss": 0.3471,
      "step": 4093
    },
    {
      "epoch": 0.3181535592166615,
      "grad_norm": 0.6100184321403503,
      "learning_rate": 8.409232203916694e-06,
      "loss": 0.3154,
      "step": 4094
    },
    {
      "epoch": 0.3182312713708424,
      "grad_norm": 0.2642119824886322,
      "learning_rate": 8.408843643145789e-06,
      "loss": 0.1114,
      "step": 4095
    },
    {
      "epoch": 0.3183089835250233,
      "grad_norm": 1.0384517908096313,
      "learning_rate": 8.408455082374885e-06,
      "loss": 0.51,
      "step": 4096
    },
    {
      "epoch": 0.31838669567920425,
      "grad_norm": 0.1867246925830841,
      "learning_rate": 8.408066521603979e-06,
      "loss": 0.0398,
      "step": 4097
    },
    {
      "epoch": 0.31846440783338514,
      "grad_norm": 0.8759419322013855,
      "learning_rate": 8.407677960833075e-06,
      "loss": 0.1951,
      "step": 4098
    },
    {
      "epoch": 0.31854211998756604,
      "grad_norm": 0.5329065322875977,
      "learning_rate": 8.40728940006217e-06,
      "loss": 0.2843,
      "step": 4099
    },
    {
      "epoch": 0.318619832141747,
      "grad_norm": 0.42352867126464844,
      "learning_rate": 8.406900839291265e-06,
      "loss": 0.2859,
      "step": 4100
    },
    {
      "epoch": 0.3186975442959279,
      "grad_norm": 0.5961814522743225,
      "learning_rate": 8.406512278520362e-06,
      "loss": 0.348,
      "step": 4101
    },
    {
      "epoch": 0.3187752564501088,
      "grad_norm": 0.3239152133464813,
      "learning_rate": 8.406123717749457e-06,
      "loss": 0.1564,
      "step": 4102
    },
    {
      "epoch": 0.3188529686042897,
      "grad_norm": 0.20696885883808136,
      "learning_rate": 8.405735156978552e-06,
      "loss": 0.0459,
      "step": 4103
    },
    {
      "epoch": 0.31893068075847064,
      "grad_norm": 0.2760409414768219,
      "learning_rate": 8.405346596207648e-06,
      "loss": 0.1521,
      "step": 4104
    },
    {
      "epoch": 0.31900839291265154,
      "grad_norm": 0.10606645047664642,
      "learning_rate": 8.404958035436743e-06,
      "loss": 0.0528,
      "step": 4105
    },
    {
      "epoch": 0.31908610506683244,
      "grad_norm": 0.3333532512187958,
      "learning_rate": 8.404569474665838e-06,
      "loss": 0.1273,
      "step": 4106
    },
    {
      "epoch": 0.3191638172210134,
      "grad_norm": 0.501101553440094,
      "learning_rate": 8.404180913894933e-06,
      "loss": 0.3166,
      "step": 4107
    },
    {
      "epoch": 0.3192415293751943,
      "grad_norm": 0.4319054186344147,
      "learning_rate": 8.40379235312403e-06,
      "loss": 0.2517,
      "step": 4108
    },
    {
      "epoch": 0.3193192415293752,
      "grad_norm": 0.09417571127414703,
      "learning_rate": 8.403403792353125e-06,
      "loss": 0.0133,
      "step": 4109
    },
    {
      "epoch": 0.3193969536835561,
      "grad_norm": 0.6847530603408813,
      "learning_rate": 8.40301523158222e-06,
      "loss": 0.7128,
      "step": 4110
    },
    {
      "epoch": 0.31947466583773704,
      "grad_norm": 0.5164445638656616,
      "learning_rate": 8.402626670811316e-06,
      "loss": 0.1387,
      "step": 4111
    },
    {
      "epoch": 0.31955237799191794,
      "grad_norm": 0.28888317942619324,
      "learning_rate": 8.402238110040411e-06,
      "loss": 0.0877,
      "step": 4112
    },
    {
      "epoch": 0.31963009014609883,
      "grad_norm": 0.38237541913986206,
      "learning_rate": 8.401849549269506e-06,
      "loss": 0.1815,
      "step": 4113
    },
    {
      "epoch": 0.3197078023002798,
      "grad_norm": 0.4852190315723419,
      "learning_rate": 8.401460988498603e-06,
      "loss": 0.2548,
      "step": 4114
    },
    {
      "epoch": 0.3197855144544607,
      "grad_norm": 0.4975306987762451,
      "learning_rate": 8.401072427727698e-06,
      "loss": 0.5017,
      "step": 4115
    },
    {
      "epoch": 0.3198632266086416,
      "grad_norm": 0.3182952404022217,
      "learning_rate": 8.400683866956793e-06,
      "loss": 0.1605,
      "step": 4116
    },
    {
      "epoch": 0.3199409387628225,
      "grad_norm": 0.11761541664600372,
      "learning_rate": 8.400295306185888e-06,
      "loss": 0.0616,
      "step": 4117
    },
    {
      "epoch": 0.32001865091700343,
      "grad_norm": 0.389087051153183,
      "learning_rate": 8.399906745414984e-06,
      "loss": 0.2557,
      "step": 4118
    },
    {
      "epoch": 0.32009636307118433,
      "grad_norm": 0.15128536522388458,
      "learning_rate": 8.39951818464408e-06,
      "loss": 0.0757,
      "step": 4119
    },
    {
      "epoch": 0.32017407522536523,
      "grad_norm": 0.31448042392730713,
      "learning_rate": 8.399129623873174e-06,
      "loss": 0.3533,
      "step": 4120
    },
    {
      "epoch": 0.3202517873795462,
      "grad_norm": 0.4373478591442108,
      "learning_rate": 8.398741063102271e-06,
      "loss": 0.1371,
      "step": 4121
    },
    {
      "epoch": 0.3203294995337271,
      "grad_norm": 0.3750649690628052,
      "learning_rate": 8.398352502331366e-06,
      "loss": 0.0667,
      "step": 4122
    },
    {
      "epoch": 0.320407211687908,
      "grad_norm": 0.10773109644651413,
      "learning_rate": 8.39796394156046e-06,
      "loss": 0.0541,
      "step": 4123
    },
    {
      "epoch": 0.3204849238420889,
      "grad_norm": 0.23151323199272156,
      "learning_rate": 8.397575380789556e-06,
      "loss": 0.0906,
      "step": 4124
    },
    {
      "epoch": 0.32056263599626983,
      "grad_norm": 0.5357452630996704,
      "learning_rate": 8.39718682001865e-06,
      "loss": 0.1372,
      "step": 4125
    },
    {
      "epoch": 0.3206403481504507,
      "grad_norm": 0.16234181821346283,
      "learning_rate": 8.396798259247747e-06,
      "loss": 0.1804,
      "step": 4126
    },
    {
      "epoch": 0.3207180603046316,
      "grad_norm": 0.1181323304772377,
      "learning_rate": 8.396409698476842e-06,
      "loss": 0.0338,
      "step": 4127
    },
    {
      "epoch": 0.3207957724588126,
      "grad_norm": 0.20048771798610687,
      "learning_rate": 8.396021137705937e-06,
      "loss": 0.2053,
      "step": 4128
    },
    {
      "epoch": 0.3208734846129935,
      "grad_norm": 0.3290402293205261,
      "learning_rate": 8.395632576935034e-06,
      "loss": 0.2329,
      "step": 4129
    },
    {
      "epoch": 0.3209511967671744,
      "grad_norm": 0.41040706634521484,
      "learning_rate": 8.395244016164129e-06,
      "loss": 0.1885,
      "step": 4130
    },
    {
      "epoch": 0.3210289089213553,
      "grad_norm": 0.566271960735321,
      "learning_rate": 8.394855455393224e-06,
      "loss": 0.2861,
      "step": 4131
    },
    {
      "epoch": 0.3211066210755362,
      "grad_norm": 0.18312765657901764,
      "learning_rate": 8.394466894622319e-06,
      "loss": 0.2531,
      "step": 4132
    },
    {
      "epoch": 0.3211843332297171,
      "grad_norm": 0.4944171905517578,
      "learning_rate": 8.394078333851415e-06,
      "loss": 0.3323,
      "step": 4133
    },
    {
      "epoch": 0.321262045383898,
      "grad_norm": 0.11262200027704239,
      "learning_rate": 8.39368977308051e-06,
      "loss": 0.0401,
      "step": 4134
    },
    {
      "epoch": 0.321339757538079,
      "grad_norm": 0.24837438762187958,
      "learning_rate": 8.393301212309605e-06,
      "loss": 0.1908,
      "step": 4135
    },
    {
      "epoch": 0.32141746969225987,
      "grad_norm": 0.3259756565093994,
      "learning_rate": 8.392912651538702e-06,
      "loss": 0.1391,
      "step": 4136
    },
    {
      "epoch": 0.32149518184644077,
      "grad_norm": 0.6715362071990967,
      "learning_rate": 8.392524090767797e-06,
      "loss": 0.8832,
      "step": 4137
    },
    {
      "epoch": 0.3215728940006217,
      "grad_norm": 0.08602800220251083,
      "learning_rate": 8.392135529996892e-06,
      "loss": 0.0441,
      "step": 4138
    },
    {
      "epoch": 0.3216506061548026,
      "grad_norm": 0.22761602699756622,
      "learning_rate": 8.391746969225988e-06,
      "loss": 0.0654,
      "step": 4139
    },
    {
      "epoch": 0.3217283183089835,
      "grad_norm": 0.45839834213256836,
      "learning_rate": 8.391358408455082e-06,
      "loss": 0.2435,
      "step": 4140
    },
    {
      "epoch": 0.3218060304631644,
      "grad_norm": 0.24068792164325714,
      "learning_rate": 8.390969847684178e-06,
      "loss": 0.1199,
      "step": 4141
    },
    {
      "epoch": 0.32188374261734537,
      "grad_norm": 0.11092593520879745,
      "learning_rate": 8.390581286913273e-06,
      "loss": 0.0292,
      "step": 4142
    },
    {
      "epoch": 0.32196145477152627,
      "grad_norm": 0.12856890261173248,
      "learning_rate": 8.39019272614237e-06,
      "loss": 0.0694,
      "step": 4143
    },
    {
      "epoch": 0.32203916692570717,
      "grad_norm": 0.15344548225402832,
      "learning_rate": 8.389804165371465e-06,
      "loss": 0.0306,
      "step": 4144
    },
    {
      "epoch": 0.3221168790798881,
      "grad_norm": 0.2779906094074249,
      "learning_rate": 8.38941560460056e-06,
      "loss": 0.2651,
      "step": 4145
    },
    {
      "epoch": 0.322194591234069,
      "grad_norm": 0.5487786531448364,
      "learning_rate": 8.389027043829657e-06,
      "loss": 0.3199,
      "step": 4146
    },
    {
      "epoch": 0.3222723033882499,
      "grad_norm": 0.17292800545692444,
      "learning_rate": 8.388638483058751e-06,
      "loss": 0.031,
      "step": 4147
    },
    {
      "epoch": 0.3223500155424308,
      "grad_norm": 0.2509424686431885,
      "learning_rate": 8.388249922287846e-06,
      "loss": 0.3255,
      "step": 4148
    },
    {
      "epoch": 0.32242772769661177,
      "grad_norm": 0.3137662708759308,
      "learning_rate": 8.387861361516943e-06,
      "loss": 0.1993,
      "step": 4149
    },
    {
      "epoch": 0.32250543985079266,
      "grad_norm": 0.405975878238678,
      "learning_rate": 8.387472800746036e-06,
      "loss": 0.167,
      "step": 4150
    },
    {
      "epoch": 0.32258315200497356,
      "grad_norm": 0.6739945411682129,
      "learning_rate": 8.387084239975133e-06,
      "loss": 0.2133,
      "step": 4151
    },
    {
      "epoch": 0.3226608641591545,
      "grad_norm": 0.5458751320838928,
      "learning_rate": 8.386695679204228e-06,
      "loss": 0.4032,
      "step": 4152
    },
    {
      "epoch": 0.3227385763133354,
      "grad_norm": 0.10424278676509857,
      "learning_rate": 8.386307118433323e-06,
      "loss": 0.0516,
      "step": 4153
    },
    {
      "epoch": 0.3228162884675163,
      "grad_norm": 0.12816748023033142,
      "learning_rate": 8.38591855766242e-06,
      "loss": 0.0278,
      "step": 4154
    },
    {
      "epoch": 0.3228940006216972,
      "grad_norm": 0.5046656131744385,
      "learning_rate": 8.385529996891514e-06,
      "loss": 0.2944,
      "step": 4155
    },
    {
      "epoch": 0.32297171277587816,
      "grad_norm": 0.383369117975235,
      "learning_rate": 8.38514143612061e-06,
      "loss": 0.3271,
      "step": 4156
    },
    {
      "epoch": 0.32304942493005906,
      "grad_norm": 0.2326606661081314,
      "learning_rate": 8.384752875349706e-06,
      "loss": 0.1753,
      "step": 4157
    },
    {
      "epoch": 0.32312713708423996,
      "grad_norm": 0.708329439163208,
      "learning_rate": 8.384364314578801e-06,
      "loss": 0.208,
      "step": 4158
    },
    {
      "epoch": 0.3232048492384209,
      "grad_norm": 0.3238662779331207,
      "learning_rate": 8.383975753807896e-06,
      "loss": 0.2565,
      "step": 4159
    },
    {
      "epoch": 0.3232825613926018,
      "grad_norm": 0.8488096594810486,
      "learning_rate": 8.383587193036991e-06,
      "loss": 0.3332,
      "step": 4160
    },
    {
      "epoch": 0.3233602735467827,
      "grad_norm": 0.28282323479652405,
      "learning_rate": 8.383198632266088e-06,
      "loss": 0.1245,
      "step": 4161
    },
    {
      "epoch": 0.3234379857009636,
      "grad_norm": 0.4586236774921417,
      "learning_rate": 8.382810071495182e-06,
      "loss": 0.1773,
      "step": 4162
    },
    {
      "epoch": 0.32351569785514456,
      "grad_norm": 0.157584086060524,
      "learning_rate": 8.382421510724277e-06,
      "loss": 0.0859,
      "step": 4163
    },
    {
      "epoch": 0.32359341000932546,
      "grad_norm": 0.48590394854545593,
      "learning_rate": 8.382032949953374e-06,
      "loss": 0.2277,
      "step": 4164
    },
    {
      "epoch": 0.32367112216350635,
      "grad_norm": 0.385884553194046,
      "learning_rate": 8.381644389182469e-06,
      "loss": 0.4797,
      "step": 4165
    },
    {
      "epoch": 0.3237488343176873,
      "grad_norm": 0.40720048546791077,
      "learning_rate": 8.381255828411564e-06,
      "loss": 0.2655,
      "step": 4166
    },
    {
      "epoch": 0.3238265464718682,
      "grad_norm": 0.32484978437423706,
      "learning_rate": 8.38086726764066e-06,
      "loss": 0.1,
      "step": 4167
    },
    {
      "epoch": 0.3239042586260491,
      "grad_norm": 0.3547348976135254,
      "learning_rate": 8.380478706869754e-06,
      "loss": 0.1298,
      "step": 4168
    },
    {
      "epoch": 0.32398197078023006,
      "grad_norm": 0.3425856828689575,
      "learning_rate": 8.38009014609885e-06,
      "loss": 0.0876,
      "step": 4169
    },
    {
      "epoch": 0.32405968293441095,
      "grad_norm": 0.1790419965982437,
      "learning_rate": 8.379701585327945e-06,
      "loss": 0.0898,
      "step": 4170
    },
    {
      "epoch": 0.32413739508859185,
      "grad_norm": 0.553169846534729,
      "learning_rate": 8.37931302455704e-06,
      "loss": 0.2455,
      "step": 4171
    },
    {
      "epoch": 0.32421510724277275,
      "grad_norm": 0.0774725005030632,
      "learning_rate": 8.378924463786137e-06,
      "loss": 0.0199,
      "step": 4172
    },
    {
      "epoch": 0.3242928193969537,
      "grad_norm": 0.3211708664894104,
      "learning_rate": 8.378535903015232e-06,
      "loss": 0.208,
      "step": 4173
    },
    {
      "epoch": 0.3243705315511346,
      "grad_norm": 0.643825113773346,
      "learning_rate": 8.378147342244329e-06,
      "loss": 0.2528,
      "step": 4174
    },
    {
      "epoch": 0.3244482437053155,
      "grad_norm": 0.314074844121933,
      "learning_rate": 8.377758781473424e-06,
      "loss": 0.1286,
      "step": 4175
    },
    {
      "epoch": 0.32452595585949645,
      "grad_norm": 0.3359481394290924,
      "learning_rate": 8.377370220702519e-06,
      "loss": 0.2716,
      "step": 4176
    },
    {
      "epoch": 0.32460366801367735,
      "grad_norm": 0.08846871554851532,
      "learning_rate": 8.376981659931615e-06,
      "loss": 0.0267,
      "step": 4177
    },
    {
      "epoch": 0.32468138016785825,
      "grad_norm": 0.32580310106277466,
      "learning_rate": 8.376593099160708e-06,
      "loss": 0.2197,
      "step": 4178
    },
    {
      "epoch": 0.32475909232203914,
      "grad_norm": 0.32489973306655884,
      "learning_rate": 8.376204538389805e-06,
      "loss": 0.3725,
      "step": 4179
    },
    {
      "epoch": 0.3248368044762201,
      "grad_norm": 0.41950321197509766,
      "learning_rate": 8.3758159776189e-06,
      "loss": 0.5535,
      "step": 4180
    },
    {
      "epoch": 0.324914516630401,
      "grad_norm": 0.4986903965473175,
      "learning_rate": 8.375427416847995e-06,
      "loss": 0.5344,
      "step": 4181
    },
    {
      "epoch": 0.3249922287845819,
      "grad_norm": 0.09220121800899506,
      "learning_rate": 8.375038856077092e-06,
      "loss": 0.0518,
      "step": 4182
    },
    {
      "epoch": 0.32506994093876285,
      "grad_norm": 0.2762359380722046,
      "learning_rate": 8.374650295306187e-06,
      "loss": 0.0938,
      "step": 4183
    },
    {
      "epoch": 0.32514765309294374,
      "grad_norm": 0.48306575417518616,
      "learning_rate": 8.374261734535282e-06,
      "loss": 0.6406,
      "step": 4184
    },
    {
      "epoch": 0.32522536524712464,
      "grad_norm": 0.23591348528862,
      "learning_rate": 8.373873173764378e-06,
      "loss": 0.1383,
      "step": 4185
    },
    {
      "epoch": 0.32530307740130554,
      "grad_norm": 0.49952465295791626,
      "learning_rate": 8.373484612993473e-06,
      "loss": 0.2744,
      "step": 4186
    },
    {
      "epoch": 0.3253807895554865,
      "grad_norm": 0.29412317276000977,
      "learning_rate": 8.373096052222568e-06,
      "loss": 0.3209,
      "step": 4187
    },
    {
      "epoch": 0.3254585017096674,
      "grad_norm": 0.12992015480995178,
      "learning_rate": 8.372707491451663e-06,
      "loss": 0.0513,
      "step": 4188
    },
    {
      "epoch": 0.3255362138638483,
      "grad_norm": 0.34998971223831177,
      "learning_rate": 8.37231893068076e-06,
      "loss": 0.0863,
      "step": 4189
    },
    {
      "epoch": 0.32561392601802924,
      "grad_norm": 0.059676092118024826,
      "learning_rate": 8.371930369909855e-06,
      "loss": 0.019,
      "step": 4190
    },
    {
      "epoch": 0.32569163817221014,
      "grad_norm": 0.4757991433143616,
      "learning_rate": 8.37154180913895e-06,
      "loss": 0.5539,
      "step": 4191
    },
    {
      "epoch": 0.32576935032639104,
      "grad_norm": 0.38260042667388916,
      "learning_rate": 8.371153248368046e-06,
      "loss": 0.2229,
      "step": 4192
    },
    {
      "epoch": 0.32584706248057194,
      "grad_norm": 0.15616273880004883,
      "learning_rate": 8.370764687597141e-06,
      "loss": 0.0625,
      "step": 4193
    },
    {
      "epoch": 0.3259247746347529,
      "grad_norm": 0.14177410304546356,
      "learning_rate": 8.370376126826236e-06,
      "loss": 0.0287,
      "step": 4194
    },
    {
      "epoch": 0.3260024867889338,
      "grad_norm": 0.2815546989440918,
      "learning_rate": 8.369987566055333e-06,
      "loss": 0.6559,
      "step": 4195
    },
    {
      "epoch": 0.3260801989431147,
      "grad_norm": 0.1861838847398758,
      "learning_rate": 8.369599005284426e-06,
      "loss": 0.062,
      "step": 4196
    },
    {
      "epoch": 0.32615791109729564,
      "grad_norm": 0.24917005002498627,
      "learning_rate": 8.369210444513523e-06,
      "loss": 0.2449,
      "step": 4197
    },
    {
      "epoch": 0.32623562325147654,
      "grad_norm": 0.15659458935260773,
      "learning_rate": 8.368821883742618e-06,
      "loss": 0.0363,
      "step": 4198
    },
    {
      "epoch": 0.32631333540565743,
      "grad_norm": 0.21943306922912598,
      "learning_rate": 8.368433322971713e-06,
      "loss": 0.1512,
      "step": 4199
    },
    {
      "epoch": 0.32639104755983833,
      "grad_norm": 0.8488155603408813,
      "learning_rate": 8.36804476220081e-06,
      "loss": 0.3903,
      "step": 4200
    },
    {
      "epoch": 0.3264687597140193,
      "grad_norm": 0.17087849974632263,
      "learning_rate": 8.367656201429904e-06,
      "loss": 0.0457,
      "step": 4201
    },
    {
      "epoch": 0.3265464718682002,
      "grad_norm": 0.4387754797935486,
      "learning_rate": 8.367267640658999e-06,
      "loss": 0.5396,
      "step": 4202
    },
    {
      "epoch": 0.3266241840223811,
      "grad_norm": 0.14400647580623627,
      "learning_rate": 8.366879079888096e-06,
      "loss": 0.0611,
      "step": 4203
    },
    {
      "epoch": 0.32670189617656203,
      "grad_norm": 0.1500486582517624,
      "learning_rate": 8.36649051911719e-06,
      "loss": 0.0545,
      "step": 4204
    },
    {
      "epoch": 0.32677960833074293,
      "grad_norm": 0.10790934413671494,
      "learning_rate": 8.366101958346287e-06,
      "loss": 0.1019,
      "step": 4205
    },
    {
      "epoch": 0.32685732048492383,
      "grad_norm": 0.12018119543790817,
      "learning_rate": 8.36571339757538e-06,
      "loss": 0.0715,
      "step": 4206
    },
    {
      "epoch": 0.3269350326391048,
      "grad_norm": 0.34810903668403625,
      "learning_rate": 8.365324836804477e-06,
      "loss": 0.1997,
      "step": 4207
    },
    {
      "epoch": 0.3270127447932857,
      "grad_norm": 0.36462950706481934,
      "learning_rate": 8.364936276033572e-06,
      "loss": 0.4872,
      "step": 4208
    },
    {
      "epoch": 0.3270904569474666,
      "grad_norm": 0.26939424872398376,
      "learning_rate": 8.364547715262667e-06,
      "loss": 0.1227,
      "step": 4209
    },
    {
      "epoch": 0.3271681691016475,
      "grad_norm": 0.4909588098526001,
      "learning_rate": 8.364159154491764e-06,
      "loss": 0.2237,
      "step": 4210
    },
    {
      "epoch": 0.32724588125582843,
      "grad_norm": 0.41160064935684204,
      "learning_rate": 8.363770593720859e-06,
      "loss": 0.6184,
      "step": 4211
    },
    {
      "epoch": 0.32732359341000933,
      "grad_norm": 0.6801633834838867,
      "learning_rate": 8.363382032949954e-06,
      "loss": 0.446,
      "step": 4212
    },
    {
      "epoch": 0.3274013055641902,
      "grad_norm": 0.31661614775657654,
      "learning_rate": 8.36299347217905e-06,
      "loss": 0.2985,
      "step": 4213
    },
    {
      "epoch": 0.3274790177183712,
      "grad_norm": 0.3439919352531433,
      "learning_rate": 8.362604911408145e-06,
      "loss": 0.0946,
      "step": 4214
    },
    {
      "epoch": 0.3275567298725521,
      "grad_norm": 0.12361478060483932,
      "learning_rate": 8.36221635063724e-06,
      "loss": 0.0419,
      "step": 4215
    },
    {
      "epoch": 0.327634442026733,
      "grad_norm": 0.21520408987998962,
      "learning_rate": 8.361827789866335e-06,
      "loss": 0.3835,
      "step": 4216
    },
    {
      "epoch": 0.3277121541809139,
      "grad_norm": 0.4875209629535675,
      "learning_rate": 8.361439229095432e-06,
      "loss": 0.2371,
      "step": 4217
    },
    {
      "epoch": 0.3277898663350948,
      "grad_norm": 0.17355316877365112,
      "learning_rate": 8.361050668324527e-06,
      "loss": 0.0437,
      "step": 4218
    },
    {
      "epoch": 0.3278675784892757,
      "grad_norm": 0.2947615087032318,
      "learning_rate": 8.360662107553622e-06,
      "loss": 0.5146,
      "step": 4219
    },
    {
      "epoch": 0.3279452906434566,
      "grad_norm": 0.5202538371086121,
      "learning_rate": 8.360273546782718e-06,
      "loss": 0.1626,
      "step": 4220
    },
    {
      "epoch": 0.3280230027976376,
      "grad_norm": 0.19558817148208618,
      "learning_rate": 8.359884986011813e-06,
      "loss": 0.0319,
      "step": 4221
    },
    {
      "epoch": 0.3281007149518185,
      "grad_norm": 0.2189929038286209,
      "learning_rate": 8.359496425240908e-06,
      "loss": 0.1232,
      "step": 4222
    },
    {
      "epoch": 0.32817842710599937,
      "grad_norm": 0.1576031744480133,
      "learning_rate": 8.359107864470005e-06,
      "loss": 0.0591,
      "step": 4223
    },
    {
      "epoch": 0.32825613926018027,
      "grad_norm": 0.12953481078147888,
      "learning_rate": 8.358719303699098e-06,
      "loss": 0.064,
      "step": 4224
    },
    {
      "epoch": 0.3283338514143612,
      "grad_norm": 0.7123778462409973,
      "learning_rate": 8.358330742928195e-06,
      "loss": 0.3041,
      "step": 4225
    },
    {
      "epoch": 0.3284115635685421,
      "grad_norm": 0.09519726783037186,
      "learning_rate": 8.35794218215729e-06,
      "loss": 0.026,
      "step": 4226
    },
    {
      "epoch": 0.328489275722723,
      "grad_norm": 0.5682113766670227,
      "learning_rate": 8.357553621386385e-06,
      "loss": 0.2981,
      "step": 4227
    },
    {
      "epoch": 0.32856698787690397,
      "grad_norm": 0.44494539499282837,
      "learning_rate": 8.357165060615481e-06,
      "loss": 0.4537,
      "step": 4228
    },
    {
      "epoch": 0.32864470003108487,
      "grad_norm": 0.2667052149772644,
      "learning_rate": 8.356776499844576e-06,
      "loss": 0.0978,
      "step": 4229
    },
    {
      "epoch": 0.32872241218526577,
      "grad_norm": 0.23929449915885925,
      "learning_rate": 8.356387939073671e-06,
      "loss": 0.4478,
      "step": 4230
    },
    {
      "epoch": 0.32880012433944666,
      "grad_norm": 0.40014326572418213,
      "learning_rate": 8.355999378302768e-06,
      "loss": 0.4714,
      "step": 4231
    },
    {
      "epoch": 0.3288778364936276,
      "grad_norm": 0.2441687285900116,
      "learning_rate": 8.355610817531863e-06,
      "loss": 0.0649,
      "step": 4232
    },
    {
      "epoch": 0.3289555486478085,
      "grad_norm": 0.12239795178174973,
      "learning_rate": 8.355222256760958e-06,
      "loss": 0.018,
      "step": 4233
    },
    {
      "epoch": 0.3290332608019894,
      "grad_norm": 0.21404147148132324,
      "learning_rate": 8.354833695990053e-06,
      "loss": 0.0917,
      "step": 4234
    },
    {
      "epoch": 0.32911097295617037,
      "grad_norm": 0.5764687061309814,
      "learning_rate": 8.35444513521915e-06,
      "loss": 0.0956,
      "step": 4235
    },
    {
      "epoch": 0.32918868511035126,
      "grad_norm": 0.12730953097343445,
      "learning_rate": 8.354056574448244e-06,
      "loss": 0.0332,
      "step": 4236
    },
    {
      "epoch": 0.32926639726453216,
      "grad_norm": 0.1340394914150238,
      "learning_rate": 8.35366801367734e-06,
      "loss": 0.0276,
      "step": 4237
    },
    {
      "epoch": 0.32934410941871306,
      "grad_norm": 0.16416944563388824,
      "learning_rate": 8.353279452906436e-06,
      "loss": 0.0905,
      "step": 4238
    },
    {
      "epoch": 0.329421821572894,
      "grad_norm": 0.31949687004089355,
      "learning_rate": 8.352890892135531e-06,
      "loss": 0.3123,
      "step": 4239
    },
    {
      "epoch": 0.3294995337270749,
      "grad_norm": 0.2740880250930786,
      "learning_rate": 8.352502331364626e-06,
      "loss": 0.2401,
      "step": 4240
    },
    {
      "epoch": 0.3295772458812558,
      "grad_norm": 0.3574793040752411,
      "learning_rate": 8.352113770593722e-06,
      "loss": 0.4676,
      "step": 4241
    },
    {
      "epoch": 0.32965495803543676,
      "grad_norm": 0.19663043320178986,
      "learning_rate": 8.351725209822817e-06,
      "loss": 0.1739,
      "step": 4242
    },
    {
      "epoch": 0.32973267018961766,
      "grad_norm": 0.4578710198402405,
      "learning_rate": 8.351336649051912e-06,
      "loss": 0.1019,
      "step": 4243
    },
    {
      "epoch": 0.32981038234379856,
      "grad_norm": 0.5776473879814148,
      "learning_rate": 8.350948088281007e-06,
      "loss": 0.3891,
      "step": 4244
    },
    {
      "epoch": 0.3298880944979795,
      "grad_norm": 0.36364999413490295,
      "learning_rate": 8.350559527510104e-06,
      "loss": 0.2191,
      "step": 4245
    },
    {
      "epoch": 0.3299658066521604,
      "grad_norm": 0.49447229504585266,
      "learning_rate": 8.350170966739199e-06,
      "loss": 0.3127,
      "step": 4246
    },
    {
      "epoch": 0.3300435188063413,
      "grad_norm": 0.230502188205719,
      "learning_rate": 8.349782405968294e-06,
      "loss": 0.0551,
      "step": 4247
    },
    {
      "epoch": 0.3301212309605222,
      "grad_norm": 0.1986672729253769,
      "learning_rate": 8.34939384519739e-06,
      "loss": 0.063,
      "step": 4248
    },
    {
      "epoch": 0.33019894311470316,
      "grad_norm": 0.6601620316505432,
      "learning_rate": 8.349005284426485e-06,
      "loss": 0.0745,
      "step": 4249
    },
    {
      "epoch": 0.33027665526888406,
      "grad_norm": 0.46453991532325745,
      "learning_rate": 8.34861672365558e-06,
      "loss": 0.187,
      "step": 4250
    },
    {
      "epoch": 0.33035436742306495,
      "grad_norm": 0.24072155356407166,
      "learning_rate": 8.348228162884675e-06,
      "loss": 0.1542,
      "step": 4251
    },
    {
      "epoch": 0.3304320795772459,
      "grad_norm": 0.589156448841095,
      "learning_rate": 8.34783960211377e-06,
      "loss": 0.1518,
      "step": 4252
    },
    {
      "epoch": 0.3305097917314268,
      "grad_norm": 0.15218743681907654,
      "learning_rate": 8.347451041342867e-06,
      "loss": 0.076,
      "step": 4253
    },
    {
      "epoch": 0.3305875038856077,
      "grad_norm": 0.25545236468315125,
      "learning_rate": 8.347062480571962e-06,
      "loss": 0.0566,
      "step": 4254
    },
    {
      "epoch": 0.3306652160397886,
      "grad_norm": 0.13470973074436188,
      "learning_rate": 8.346673919801057e-06,
      "loss": 0.0368,
      "step": 4255
    },
    {
      "epoch": 0.33074292819396955,
      "grad_norm": 0.08515262603759766,
      "learning_rate": 8.346285359030153e-06,
      "loss": 0.0521,
      "step": 4256
    },
    {
      "epoch": 0.33082064034815045,
      "grad_norm": 0.6361961364746094,
      "learning_rate": 8.345896798259248e-06,
      "loss": 0.7375,
      "step": 4257
    },
    {
      "epoch": 0.33089835250233135,
      "grad_norm": 0.15939879417419434,
      "learning_rate": 8.345508237488343e-06,
      "loss": 0.1669,
      "step": 4258
    },
    {
      "epoch": 0.3309760646565123,
      "grad_norm": 0.6737861633300781,
      "learning_rate": 8.345119676717438e-06,
      "loss": 0.3814,
      "step": 4259
    },
    {
      "epoch": 0.3310537768106932,
      "grad_norm": 0.33971017599105835,
      "learning_rate": 8.344731115946535e-06,
      "loss": 0.181,
      "step": 4260
    },
    {
      "epoch": 0.3311314889648741,
      "grad_norm": 0.44150879979133606,
      "learning_rate": 8.34434255517563e-06,
      "loss": 0.2622,
      "step": 4261
    },
    {
      "epoch": 0.331209201119055,
      "grad_norm": 0.4272356927394867,
      "learning_rate": 8.343953994404725e-06,
      "loss": 0.2199,
      "step": 4262
    },
    {
      "epoch": 0.33128691327323595,
      "grad_norm": 0.20107890665531158,
      "learning_rate": 8.343565433633822e-06,
      "loss": 0.0852,
      "step": 4263
    },
    {
      "epoch": 0.33136462542741685,
      "grad_norm": 0.4697668254375458,
      "learning_rate": 8.343176872862916e-06,
      "loss": 0.4205,
      "step": 4264
    },
    {
      "epoch": 0.33144233758159775,
      "grad_norm": 0.21956002712249756,
      "learning_rate": 8.342788312092011e-06,
      "loss": 0.0664,
      "step": 4265
    },
    {
      "epoch": 0.3315200497357787,
      "grad_norm": 0.3918372094631195,
      "learning_rate": 8.342399751321108e-06,
      "loss": 0.348,
      "step": 4266
    },
    {
      "epoch": 0.3315977618899596,
      "grad_norm": 0.34912171959877014,
      "learning_rate": 8.342011190550203e-06,
      "loss": 0.2195,
      "step": 4267
    },
    {
      "epoch": 0.3316754740441405,
      "grad_norm": 0.4442375600337982,
      "learning_rate": 8.341622629779298e-06,
      "loss": 0.3637,
      "step": 4268
    },
    {
      "epoch": 0.3317531861983214,
      "grad_norm": 0.24763555824756622,
      "learning_rate": 8.341234069008393e-06,
      "loss": 0.1536,
      "step": 4269
    },
    {
      "epoch": 0.33183089835250235,
      "grad_norm": 0.3305835723876953,
      "learning_rate": 8.34084550823749e-06,
      "loss": 0.474,
      "step": 4270
    },
    {
      "epoch": 0.33190861050668324,
      "grad_norm": 0.07400823384523392,
      "learning_rate": 8.340456947466585e-06,
      "loss": 0.0204,
      "step": 4271
    },
    {
      "epoch": 0.33198632266086414,
      "grad_norm": 0.1464257687330246,
      "learning_rate": 8.34006838669568e-06,
      "loss": 0.1075,
      "step": 4272
    },
    {
      "epoch": 0.3320640348150451,
      "grad_norm": 0.6280048489570618,
      "learning_rate": 8.339679825924776e-06,
      "loss": 0.528,
      "step": 4273
    },
    {
      "epoch": 0.332141746969226,
      "grad_norm": 0.8102632164955139,
      "learning_rate": 8.339291265153871e-06,
      "loss": 1.1167,
      "step": 4274
    },
    {
      "epoch": 0.3322194591234069,
      "grad_norm": 0.43007010221481323,
      "learning_rate": 8.338902704382966e-06,
      "loss": 0.1257,
      "step": 4275
    },
    {
      "epoch": 0.3322971712775878,
      "grad_norm": 0.1959446668624878,
      "learning_rate": 8.338514143612063e-06,
      "loss": 0.0485,
      "step": 4276
    },
    {
      "epoch": 0.33237488343176874,
      "grad_norm": 0.21173150837421417,
      "learning_rate": 8.338125582841156e-06,
      "loss": 0.0242,
      "step": 4277
    },
    {
      "epoch": 0.33245259558594964,
      "grad_norm": 0.38997870683670044,
      "learning_rate": 8.337737022070253e-06,
      "loss": 0.6246,
      "step": 4278
    },
    {
      "epoch": 0.33253030774013054,
      "grad_norm": 0.39494654536247253,
      "learning_rate": 8.337348461299348e-06,
      "loss": 0.1662,
      "step": 4279
    },
    {
      "epoch": 0.3326080198943115,
      "grad_norm": 0.2192380726337433,
      "learning_rate": 8.336959900528442e-06,
      "loss": 0.1244,
      "step": 4280
    },
    {
      "epoch": 0.3326857320484924,
      "grad_norm": 7.130942344665527,
      "learning_rate": 8.336571339757539e-06,
      "loss": 3.7821,
      "step": 4281
    },
    {
      "epoch": 0.3327634442026733,
      "grad_norm": 0.748449444770813,
      "learning_rate": 8.336182778986634e-06,
      "loss": 0.2741,
      "step": 4282
    },
    {
      "epoch": 0.33284115635685424,
      "grad_norm": 0.0661454126238823,
      "learning_rate": 8.335794218215729e-06,
      "loss": 0.0061,
      "step": 4283
    },
    {
      "epoch": 0.33291886851103514,
      "grad_norm": 0.5168960690498352,
      "learning_rate": 8.335405657444826e-06,
      "loss": 0.2607,
      "step": 4284
    },
    {
      "epoch": 0.33299658066521604,
      "grad_norm": 0.18079523742198944,
      "learning_rate": 8.33501709667392e-06,
      "loss": 0.1285,
      "step": 4285
    },
    {
      "epoch": 0.33307429281939693,
      "grad_norm": 0.4239809215068817,
      "learning_rate": 8.334628535903016e-06,
      "loss": 0.1067,
      "step": 4286
    },
    {
      "epoch": 0.3331520049735779,
      "grad_norm": 0.6429277062416077,
      "learning_rate": 8.33423997513211e-06,
      "loss": 0.3333,
      "step": 4287
    },
    {
      "epoch": 0.3332297171277588,
      "grad_norm": 0.6958919167518616,
      "learning_rate": 8.333851414361207e-06,
      "loss": 0.2998,
      "step": 4288
    },
    {
      "epoch": 0.3333074292819397,
      "grad_norm": 0.0726858526468277,
      "learning_rate": 8.333462853590302e-06,
      "loss": 0.0243,
      "step": 4289
    },
    {
      "epoch": 0.33338514143612064,
      "grad_norm": 0.29528456926345825,
      "learning_rate": 8.333074292819397e-06,
      "loss": 0.1328,
      "step": 4290
    },
    {
      "epoch": 0.33346285359030153,
      "grad_norm": 0.12077866494655609,
      "learning_rate": 8.332685732048494e-06,
      "loss": 0.0617,
      "step": 4291
    },
    {
      "epoch": 0.33354056574448243,
      "grad_norm": 0.47814399003982544,
      "learning_rate": 8.332297171277589e-06,
      "loss": 0.2477,
      "step": 4292
    },
    {
      "epoch": 0.33361827789866333,
      "grad_norm": 0.6543601155281067,
      "learning_rate": 8.331908610506684e-06,
      "loss": 0.3777,
      "step": 4293
    },
    {
      "epoch": 0.3336959900528443,
      "grad_norm": 0.6707369089126587,
      "learning_rate": 8.33152004973578e-06,
      "loss": 0.9485,
      "step": 4294
    },
    {
      "epoch": 0.3337737022070252,
      "grad_norm": 0.41909152269363403,
      "learning_rate": 8.331131488964875e-06,
      "loss": 0.1265,
      "step": 4295
    },
    {
      "epoch": 0.3338514143612061,
      "grad_norm": 0.20208929479122162,
      "learning_rate": 8.33074292819397e-06,
      "loss": 0.0471,
      "step": 4296
    },
    {
      "epoch": 0.33392912651538703,
      "grad_norm": 0.37570133805274963,
      "learning_rate": 8.330354367423065e-06,
      "loss": 0.0497,
      "step": 4297
    },
    {
      "epoch": 0.33400683866956793,
      "grad_norm": 0.18009498715400696,
      "learning_rate": 8.329965806652162e-06,
      "loss": 0.2176,
      "step": 4298
    },
    {
      "epoch": 0.3340845508237488,
      "grad_norm": 0.3001267611980438,
      "learning_rate": 8.329577245881257e-06,
      "loss": 0.0635,
      "step": 4299
    },
    {
      "epoch": 0.3341622629779297,
      "grad_norm": 0.206398606300354,
      "learning_rate": 8.329188685110352e-06,
      "loss": 0.1049,
      "step": 4300
    },
    {
      "epoch": 0.3342399751321107,
      "grad_norm": 0.6423159837722778,
      "learning_rate": 8.328800124339448e-06,
      "loss": 0.2909,
      "step": 4301
    },
    {
      "epoch": 0.3343176872862916,
      "grad_norm": 0.37190183997154236,
      "learning_rate": 8.328411563568543e-06,
      "loss": 0.1616,
      "step": 4302
    },
    {
      "epoch": 0.3343953994404725,
      "grad_norm": 0.21426063776016235,
      "learning_rate": 8.328023002797638e-06,
      "loss": 0.0374,
      "step": 4303
    },
    {
      "epoch": 0.3344731115946534,
      "grad_norm": 0.7703372836112976,
      "learning_rate": 8.327634442026735e-06,
      "loss": 0.1691,
      "step": 4304
    },
    {
      "epoch": 0.3345508237488343,
      "grad_norm": 0.5975857377052307,
      "learning_rate": 8.327245881255828e-06,
      "loss": 0.3451,
      "step": 4305
    },
    {
      "epoch": 0.3346285359030152,
      "grad_norm": 0.08086249977350235,
      "learning_rate": 8.326857320484925e-06,
      "loss": 0.0131,
      "step": 4306
    },
    {
      "epoch": 0.3347062480571961,
      "grad_norm": 0.17563343048095703,
      "learning_rate": 8.32646875971402e-06,
      "loss": 0.1658,
      "step": 4307
    },
    {
      "epoch": 0.3347839602113771,
      "grad_norm": 0.2812390625476837,
      "learning_rate": 8.326080198943115e-06,
      "loss": 0.155,
      "step": 4308
    },
    {
      "epoch": 0.33486167236555797,
      "grad_norm": 0.6352200508117676,
      "learning_rate": 8.325691638172211e-06,
      "loss": 0.5087,
      "step": 4309
    },
    {
      "epoch": 0.33493938451973887,
      "grad_norm": 0.3213706314563751,
      "learning_rate": 8.325303077401306e-06,
      "loss": 0.0721,
      "step": 4310
    },
    {
      "epoch": 0.3350170966739198,
      "grad_norm": 0.9647884964942932,
      "learning_rate": 8.324914516630401e-06,
      "loss": 0.2356,
      "step": 4311
    },
    {
      "epoch": 0.3350948088281007,
      "grad_norm": 0.4095231890678406,
      "learning_rate": 8.324525955859498e-06,
      "loss": 0.2768,
      "step": 4312
    },
    {
      "epoch": 0.3351725209822816,
      "grad_norm": 0.6869603395462036,
      "learning_rate": 8.324137395088593e-06,
      "loss": 0.5903,
      "step": 4313
    },
    {
      "epoch": 0.3352502331364625,
      "grad_norm": 0.33709976077079773,
      "learning_rate": 8.323748834317688e-06,
      "loss": 0.1347,
      "step": 4314
    },
    {
      "epoch": 0.33532794529064347,
      "grad_norm": 0.2860832214355469,
      "learning_rate": 8.323360273546783e-06,
      "loss": 0.0944,
      "step": 4315
    },
    {
      "epoch": 0.33540565744482437,
      "grad_norm": 0.1407582014799118,
      "learning_rate": 8.32297171277588e-06,
      "loss": 0.1132,
      "step": 4316
    },
    {
      "epoch": 0.33548336959900527,
      "grad_norm": 0.5255858302116394,
      "learning_rate": 8.322583152004974e-06,
      "loss": 0.2585,
      "step": 4317
    },
    {
      "epoch": 0.3355610817531862,
      "grad_norm": 0.0674232542514801,
      "learning_rate": 8.32219459123407e-06,
      "loss": 0.0197,
      "step": 4318
    },
    {
      "epoch": 0.3356387939073671,
      "grad_norm": 0.14079934358596802,
      "learning_rate": 8.321806030463166e-06,
      "loss": 0.0565,
      "step": 4319
    },
    {
      "epoch": 0.335716506061548,
      "grad_norm": 0.0718807727098465,
      "learning_rate": 8.32141746969226e-06,
      "loss": 0.0245,
      "step": 4320
    },
    {
      "epoch": 0.3357942182157289,
      "grad_norm": 0.2614544630050659,
      "learning_rate": 8.321028908921356e-06,
      "loss": 0.0918,
      "step": 4321
    },
    {
      "epoch": 0.33587193036990987,
      "grad_norm": 0.5255246162414551,
      "learning_rate": 8.320640348150452e-06,
      "loss": 0.2871,
      "step": 4322
    },
    {
      "epoch": 0.33594964252409076,
      "grad_norm": 0.30706652998924255,
      "learning_rate": 8.320251787379546e-06,
      "loss": 0.1354,
      "step": 4323
    },
    {
      "epoch": 0.33602735467827166,
      "grad_norm": 0.27184489369392395,
      "learning_rate": 8.319863226608642e-06,
      "loss": 0.3414,
      "step": 4324
    },
    {
      "epoch": 0.3361050668324526,
      "grad_norm": 0.2199421525001526,
      "learning_rate": 8.319474665837737e-06,
      "loss": 0.1841,
      "step": 4325
    },
    {
      "epoch": 0.3361827789866335,
      "grad_norm": 0.6310422420501709,
      "learning_rate": 8.319086105066834e-06,
      "loss": 0.3958,
      "step": 4326
    },
    {
      "epoch": 0.3362604911408144,
      "grad_norm": 0.23012791574001312,
      "learning_rate": 8.318697544295929e-06,
      "loss": 0.0625,
      "step": 4327
    },
    {
      "epoch": 0.33633820329499536,
      "grad_norm": 0.7505234479904175,
      "learning_rate": 8.318308983525024e-06,
      "loss": 0.129,
      "step": 4328
    },
    {
      "epoch": 0.33641591544917626,
      "grad_norm": 0.3320600390434265,
      "learning_rate": 8.31792042275412e-06,
      "loss": 0.316,
      "step": 4329
    },
    {
      "epoch": 0.33649362760335716,
      "grad_norm": 0.34792619943618774,
      "learning_rate": 8.317531861983215e-06,
      "loss": 0.1762,
      "step": 4330
    },
    {
      "epoch": 0.33657133975753806,
      "grad_norm": 0.343795508146286,
      "learning_rate": 8.31714330121231e-06,
      "loss": 0.272,
      "step": 4331
    },
    {
      "epoch": 0.336649051911719,
      "grad_norm": 0.10789893567562103,
      "learning_rate": 8.316754740441407e-06,
      "loss": 0.0375,
      "step": 4332
    },
    {
      "epoch": 0.3367267640658999,
      "grad_norm": 0.13639818131923676,
      "learning_rate": 8.3163661796705e-06,
      "loss": 0.0913,
      "step": 4333
    },
    {
      "epoch": 0.3368044762200808,
      "grad_norm": 0.24189545214176178,
      "learning_rate": 8.315977618899597e-06,
      "loss": 0.167,
      "step": 4334
    },
    {
      "epoch": 0.33688218837426176,
      "grad_norm": 0.21251556277275085,
      "learning_rate": 8.315589058128692e-06,
      "loss": 0.1461,
      "step": 4335
    },
    {
      "epoch": 0.33695990052844266,
      "grad_norm": 0.411130428314209,
      "learning_rate": 8.315200497357787e-06,
      "loss": 0.1073,
      "step": 4336
    },
    {
      "epoch": 0.33703761268262356,
      "grad_norm": 0.34346088767051697,
      "learning_rate": 8.314811936586883e-06,
      "loss": 0.4637,
      "step": 4337
    },
    {
      "epoch": 0.33711532483680445,
      "grad_norm": 0.534814178943634,
      "learning_rate": 8.314423375815978e-06,
      "loss": 0.5705,
      "step": 4338
    },
    {
      "epoch": 0.3371930369909854,
      "grad_norm": 0.3743421137332916,
      "learning_rate": 8.314034815045073e-06,
      "loss": 0.1417,
      "step": 4339
    },
    {
      "epoch": 0.3372707491451663,
      "grad_norm": 0.690751314163208,
      "learning_rate": 8.31364625427417e-06,
      "loss": 0.6113,
      "step": 4340
    },
    {
      "epoch": 0.3373484612993472,
      "grad_norm": 0.3854754865169525,
      "learning_rate": 8.313257693503265e-06,
      "loss": 0.2949,
      "step": 4341
    },
    {
      "epoch": 0.33742617345352816,
      "grad_norm": 0.784504771232605,
      "learning_rate": 8.31286913273236e-06,
      "loss": 0.3159,
      "step": 4342
    },
    {
      "epoch": 0.33750388560770905,
      "grad_norm": 0.503507137298584,
      "learning_rate": 8.312480571961455e-06,
      "loss": 0.3873,
      "step": 4343
    },
    {
      "epoch": 0.33758159776188995,
      "grad_norm": 0.28648263216018677,
      "learning_rate": 8.312092011190551e-06,
      "loss": 0.0684,
      "step": 4344
    },
    {
      "epoch": 0.33765930991607085,
      "grad_norm": 0.21904437243938446,
      "learning_rate": 8.311703450419646e-06,
      "loss": 0.0959,
      "step": 4345
    },
    {
      "epoch": 0.3377370220702518,
      "grad_norm": 0.28475111722946167,
      "learning_rate": 8.311314889648741e-06,
      "loss": 0.0976,
      "step": 4346
    },
    {
      "epoch": 0.3378147342244327,
      "grad_norm": 0.5750284790992737,
      "learning_rate": 8.310926328877838e-06,
      "loss": 0.4805,
      "step": 4347
    },
    {
      "epoch": 0.3378924463786136,
      "grad_norm": 0.4269523322582245,
      "learning_rate": 8.310537768106933e-06,
      "loss": 0.1224,
      "step": 4348
    },
    {
      "epoch": 0.33797015853279455,
      "grad_norm": 1.0614511966705322,
      "learning_rate": 8.310149207336028e-06,
      "loss": 0.2777,
      "step": 4349
    },
    {
      "epoch": 0.33804787068697545,
      "grad_norm": 0.3613906502723694,
      "learning_rate": 8.309760646565125e-06,
      "loss": 0.2451,
      "step": 4350
    },
    {
      "epoch": 0.33812558284115635,
      "grad_norm": 0.45882800221443176,
      "learning_rate": 8.309372085794218e-06,
      "loss": 0.1244,
      "step": 4351
    },
    {
      "epoch": 0.33820329499533724,
      "grad_norm": 0.5156020522117615,
      "learning_rate": 8.308983525023314e-06,
      "loss": 0.156,
      "step": 4352
    },
    {
      "epoch": 0.3382810071495182,
      "grad_norm": 0.24298696219921112,
      "learning_rate": 8.30859496425241e-06,
      "loss": 0.1013,
      "step": 4353
    },
    {
      "epoch": 0.3383587193036991,
      "grad_norm": 0.16327030956745148,
      "learning_rate": 8.308206403481504e-06,
      "loss": 0.1232,
      "step": 4354
    },
    {
      "epoch": 0.33843643145788,
      "grad_norm": 0.29204073548316956,
      "learning_rate": 8.307817842710601e-06,
      "loss": 0.2013,
      "step": 4355
    },
    {
      "epoch": 0.33851414361206095,
      "grad_norm": 1.2211406230926514,
      "learning_rate": 8.307429281939696e-06,
      "loss": 0.2728,
      "step": 4356
    },
    {
      "epoch": 0.33859185576624184,
      "grad_norm": 0.2920275032520294,
      "learning_rate": 8.307040721168793e-06,
      "loss": 0.0694,
      "step": 4357
    },
    {
      "epoch": 0.33866956792042274,
      "grad_norm": 0.14543281495571136,
      "learning_rate": 8.306652160397887e-06,
      "loss": 0.0471,
      "step": 4358
    },
    {
      "epoch": 0.33874728007460364,
      "grad_norm": 0.23653696477413177,
      "learning_rate": 8.306263599626982e-06,
      "loss": 0.0729,
      "step": 4359
    },
    {
      "epoch": 0.3388249922287846,
      "grad_norm": 0.3235248923301697,
      "learning_rate": 8.305875038856079e-06,
      "loss": 0.2269,
      "step": 4360
    },
    {
      "epoch": 0.3389027043829655,
      "grad_norm": 0.6480511426925659,
      "learning_rate": 8.305486478085172e-06,
      "loss": 0.3304,
      "step": 4361
    },
    {
      "epoch": 0.3389804165371464,
      "grad_norm": 0.1119370087981224,
      "learning_rate": 8.305097917314269e-06,
      "loss": 0.0321,
      "step": 4362
    },
    {
      "epoch": 0.33905812869132734,
      "grad_norm": 0.7612937092781067,
      "learning_rate": 8.304709356543364e-06,
      "loss": 0.2028,
      "step": 4363
    },
    {
      "epoch": 0.33913584084550824,
      "grad_norm": 0.3705401122570038,
      "learning_rate": 8.304320795772459e-06,
      "loss": 0.0716,
      "step": 4364
    },
    {
      "epoch": 0.33921355299968914,
      "grad_norm": 0.2854240834712982,
      "learning_rate": 8.303932235001556e-06,
      "loss": 0.1709,
      "step": 4365
    },
    {
      "epoch": 0.3392912651538701,
      "grad_norm": 0.4065142571926117,
      "learning_rate": 8.30354367423065e-06,
      "loss": 0.2355,
      "step": 4366
    },
    {
      "epoch": 0.339368977308051,
      "grad_norm": 0.39992132782936096,
      "learning_rate": 8.303155113459745e-06,
      "loss": 0.2025,
      "step": 4367
    },
    {
      "epoch": 0.3394466894622319,
      "grad_norm": 0.300880491733551,
      "learning_rate": 8.302766552688842e-06,
      "loss": 0.1613,
      "step": 4368
    },
    {
      "epoch": 0.3395244016164128,
      "grad_norm": 0.27922043204307556,
      "learning_rate": 8.302377991917937e-06,
      "loss": 0.2445,
      "step": 4369
    },
    {
      "epoch": 0.33960211377059374,
      "grad_norm": 0.1484987884759903,
      "learning_rate": 8.301989431147032e-06,
      "loss": 0.0244,
      "step": 4370
    },
    {
      "epoch": 0.33967982592477464,
      "grad_norm": 0.32424744963645935,
      "learning_rate": 8.301600870376127e-06,
      "loss": 0.1255,
      "step": 4371
    },
    {
      "epoch": 0.33975753807895553,
      "grad_norm": 0.5684611201286316,
      "learning_rate": 8.301212309605224e-06,
      "loss": 0.3838,
      "step": 4372
    },
    {
      "epoch": 0.3398352502331365,
      "grad_norm": 0.22521646320819855,
      "learning_rate": 8.300823748834319e-06,
      "loss": 0.0523,
      "step": 4373
    },
    {
      "epoch": 0.3399129623873174,
      "grad_norm": 0.22864219546318054,
      "learning_rate": 8.300435188063413e-06,
      "loss": 0.0813,
      "step": 4374
    },
    {
      "epoch": 0.3399906745414983,
      "grad_norm": 0.9241098165512085,
      "learning_rate": 8.30004662729251e-06,
      "loss": 0.5671,
      "step": 4375
    },
    {
      "epoch": 0.3400683866956792,
      "grad_norm": 0.7555936574935913,
      "learning_rate": 8.299658066521603e-06,
      "loss": 0.4211,
      "step": 4376
    },
    {
      "epoch": 0.34014609884986013,
      "grad_norm": 0.30975884199142456,
      "learning_rate": 8.2992695057507e-06,
      "loss": 0.2423,
      "step": 4377
    },
    {
      "epoch": 0.34022381100404103,
      "grad_norm": 0.516611635684967,
      "learning_rate": 8.298880944979795e-06,
      "loss": 0.19,
      "step": 4378
    },
    {
      "epoch": 0.34030152315822193,
      "grad_norm": 0.24780993163585663,
      "learning_rate": 8.29849238420889e-06,
      "loss": 0.1104,
      "step": 4379
    },
    {
      "epoch": 0.3403792353124029,
      "grad_norm": 0.31228360533714294,
      "learning_rate": 8.298103823437987e-06,
      "loss": 0.0784,
      "step": 4380
    },
    {
      "epoch": 0.3404569474665838,
      "grad_norm": 0.44285744428634644,
      "learning_rate": 8.297715262667082e-06,
      "loss": 0.2983,
      "step": 4381
    },
    {
      "epoch": 0.3405346596207647,
      "grad_norm": 0.32215434312820435,
      "learning_rate": 8.297326701896176e-06,
      "loss": 0.7131,
      "step": 4382
    },
    {
      "epoch": 0.3406123717749456,
      "grad_norm": 0.1426520198583603,
      "learning_rate": 8.296938141125273e-06,
      "loss": 0.077,
      "step": 4383
    },
    {
      "epoch": 0.34069008392912653,
      "grad_norm": 0.28609734773635864,
      "learning_rate": 8.296549580354368e-06,
      "loss": 0.3991,
      "step": 4384
    },
    {
      "epoch": 0.34076779608330743,
      "grad_norm": 0.3478125333786011,
      "learning_rate": 8.296161019583463e-06,
      "loss": 0.3056,
      "step": 4385
    },
    {
      "epoch": 0.3408455082374883,
      "grad_norm": 0.6447163224220276,
      "learning_rate": 8.295772458812558e-06,
      "loss": 0.3688,
      "step": 4386
    },
    {
      "epoch": 0.3409232203916693,
      "grad_norm": 0.39204809069633484,
      "learning_rate": 8.295383898041655e-06,
      "loss": 0.0982,
      "step": 4387
    },
    {
      "epoch": 0.3410009325458502,
      "grad_norm": 0.2541835904121399,
      "learning_rate": 8.29499533727075e-06,
      "loss": 0.1228,
      "step": 4388
    },
    {
      "epoch": 0.3410786447000311,
      "grad_norm": 0.45153120160102844,
      "learning_rate": 8.294606776499844e-06,
      "loss": 0.0919,
      "step": 4389
    },
    {
      "epoch": 0.341156356854212,
      "grad_norm": 0.7634017467498779,
      "learning_rate": 8.294218215728941e-06,
      "loss": 1.0785,
      "step": 4390
    },
    {
      "epoch": 0.3412340690083929,
      "grad_norm": 0.1054120883345604,
      "learning_rate": 8.293829654958036e-06,
      "loss": 0.0501,
      "step": 4391
    },
    {
      "epoch": 0.3413117811625738,
      "grad_norm": 0.25556403398513794,
      "learning_rate": 8.293441094187131e-06,
      "loss": 0.0539,
      "step": 4392
    },
    {
      "epoch": 0.3413894933167547,
      "grad_norm": 1.0004273653030396,
      "learning_rate": 8.293052533416228e-06,
      "loss": 0.5214,
      "step": 4393
    },
    {
      "epoch": 0.3414672054709357,
      "grad_norm": 0.6970291137695312,
      "learning_rate": 8.292663972645323e-06,
      "loss": 0.2143,
      "step": 4394
    },
    {
      "epoch": 0.3415449176251166,
      "grad_norm": 0.41256117820739746,
      "learning_rate": 8.292275411874418e-06,
      "loss": 0.4178,
      "step": 4395
    },
    {
      "epoch": 0.34162262977929747,
      "grad_norm": 0.2774294316768646,
      "learning_rate": 8.291886851103513e-06,
      "loss": 0.1285,
      "step": 4396
    },
    {
      "epoch": 0.34170034193347837,
      "grad_norm": 0.43677738308906555,
      "learning_rate": 8.29149829033261e-06,
      "loss": 0.0773,
      "step": 4397
    },
    {
      "epoch": 0.3417780540876593,
      "grad_norm": 0.6478081345558167,
      "learning_rate": 8.291109729561704e-06,
      "loss": 0.1544,
      "step": 4398
    },
    {
      "epoch": 0.3418557662418402,
      "grad_norm": 0.1501866728067398,
      "learning_rate": 8.290721168790799e-06,
      "loss": 0.0655,
      "step": 4399
    },
    {
      "epoch": 0.3419334783960211,
      "grad_norm": 0.3208141326904297,
      "learning_rate": 8.290332608019896e-06,
      "loss": 0.1948,
      "step": 4400
    },
    {
      "epoch": 0.34201119055020207,
      "grad_norm": 0.39015546441078186,
      "learning_rate": 8.28994404724899e-06,
      "loss": 0.0833,
      "step": 4401
    },
    {
      "epoch": 0.34208890270438297,
      "grad_norm": 0.3755781650543213,
      "learning_rate": 8.289555486478086e-06,
      "loss": 0.1734,
      "step": 4402
    },
    {
      "epoch": 0.34216661485856387,
      "grad_norm": 0.2820712625980377,
      "learning_rate": 8.289166925707182e-06,
      "loss": 0.0944,
      "step": 4403
    },
    {
      "epoch": 0.3422443270127448,
      "grad_norm": 0.4376765191555023,
      "learning_rate": 8.288778364936276e-06,
      "loss": 0.3039,
      "step": 4404
    },
    {
      "epoch": 0.3423220391669257,
      "grad_norm": 0.14828570187091827,
      "learning_rate": 8.288389804165372e-06,
      "loss": 0.061,
      "step": 4405
    },
    {
      "epoch": 0.3423997513211066,
      "grad_norm": 0.6142695546150208,
      "learning_rate": 8.288001243394467e-06,
      "loss": 0.3552,
      "step": 4406
    },
    {
      "epoch": 0.3424774634752875,
      "grad_norm": 0.8502823114395142,
      "learning_rate": 8.287612682623562e-06,
      "loss": 0.2802,
      "step": 4407
    },
    {
      "epoch": 0.34255517562946847,
      "grad_norm": 0.4549318253993988,
      "learning_rate": 8.287224121852659e-06,
      "loss": 0.1983,
      "step": 4408
    },
    {
      "epoch": 0.34263288778364936,
      "grad_norm": 0.20479032397270203,
      "learning_rate": 8.286835561081754e-06,
      "loss": 0.0672,
      "step": 4409
    },
    {
      "epoch": 0.34271059993783026,
      "grad_norm": 0.6225382089614868,
      "learning_rate": 8.286447000310849e-06,
      "loss": 0.5466,
      "step": 4410
    },
    {
      "epoch": 0.3427883120920112,
      "grad_norm": 0.1394294947385788,
      "learning_rate": 8.286058439539945e-06,
      "loss": 0.0552,
      "step": 4411
    },
    {
      "epoch": 0.3428660242461921,
      "grad_norm": 0.9022563695907593,
      "learning_rate": 8.28566987876904e-06,
      "loss": 0.2969,
      "step": 4412
    },
    {
      "epoch": 0.342943736400373,
      "grad_norm": 0.8957381844520569,
      "learning_rate": 8.285281317998135e-06,
      "loss": 0.7663,
      "step": 4413
    },
    {
      "epoch": 0.3430214485545539,
      "grad_norm": 2.809903144836426,
      "learning_rate": 8.28489275722723e-06,
      "loss": 1.158,
      "step": 4414
    },
    {
      "epoch": 0.34309916070873486,
      "grad_norm": 0.46782606840133667,
      "learning_rate": 8.284504196456327e-06,
      "loss": 0.6557,
      "step": 4415
    },
    {
      "epoch": 0.34317687286291576,
      "grad_norm": 0.20746774971485138,
      "learning_rate": 8.284115635685422e-06,
      "loss": 0.0884,
      "step": 4416
    },
    {
      "epoch": 0.34325458501709666,
      "grad_norm": 0.17321491241455078,
      "learning_rate": 8.283727074914517e-06,
      "loss": 0.0819,
      "step": 4417
    },
    {
      "epoch": 0.3433322971712776,
      "grad_norm": 0.47929900884628296,
      "learning_rate": 8.283338514143613e-06,
      "loss": 0.2327,
      "step": 4418
    },
    {
      "epoch": 0.3434100093254585,
      "grad_norm": 0.21587470173835754,
      "learning_rate": 8.282949953372708e-06,
      "loss": 0.0993,
      "step": 4419
    },
    {
      "epoch": 0.3434877214796394,
      "grad_norm": 1.127126693725586,
      "learning_rate": 8.282561392601803e-06,
      "loss": 0.4379,
      "step": 4420
    },
    {
      "epoch": 0.3435654336338203,
      "grad_norm": 0.5067404508590698,
      "learning_rate": 8.2821728318309e-06,
      "loss": 0.9012,
      "step": 4421
    },
    {
      "epoch": 0.34364314578800126,
      "grad_norm": 0.09188276529312134,
      "learning_rate": 8.281784271059995e-06,
      "loss": 0.0501,
      "step": 4422
    },
    {
      "epoch": 0.34372085794218216,
      "grad_norm": 0.4212089776992798,
      "learning_rate": 8.28139571028909e-06,
      "loss": 0.3733,
      "step": 4423
    },
    {
      "epoch": 0.34379857009636305,
      "grad_norm": 0.26118358969688416,
      "learning_rate": 8.281007149518185e-06,
      "loss": 0.1241,
      "step": 4424
    },
    {
      "epoch": 0.343876282250544,
      "grad_norm": 2.325502395629883,
      "learning_rate": 8.280618588747281e-06,
      "loss": 1.5226,
      "step": 4425
    },
    {
      "epoch": 0.3439539944047249,
      "grad_norm": 0.10141973197460175,
      "learning_rate": 8.280230027976376e-06,
      "loss": 0.0496,
      "step": 4426
    },
    {
      "epoch": 0.3440317065589058,
      "grad_norm": 0.09880951792001724,
      "learning_rate": 8.279841467205471e-06,
      "loss": 0.0473,
      "step": 4427
    },
    {
      "epoch": 0.3441094187130867,
      "grad_norm": 0.7684199810028076,
      "learning_rate": 8.279452906434568e-06,
      "loss": 0.4592,
      "step": 4428
    },
    {
      "epoch": 0.34418713086726765,
      "grad_norm": 0.5628560185432434,
      "learning_rate": 8.279064345663663e-06,
      "loss": 0.0641,
      "step": 4429
    },
    {
      "epoch": 0.34426484302144855,
      "grad_norm": 0.742891252040863,
      "learning_rate": 8.278675784892758e-06,
      "loss": 0.5103,
      "step": 4430
    },
    {
      "epoch": 0.34434255517562945,
      "grad_norm": 0.22531628608703613,
      "learning_rate": 8.278287224121854e-06,
      "loss": 0.0952,
      "step": 4431
    },
    {
      "epoch": 0.3444202673298104,
      "grad_norm": 0.7438414096832275,
      "learning_rate": 8.277898663350948e-06,
      "loss": 0.6681,
      "step": 4432
    },
    {
      "epoch": 0.3444979794839913,
      "grad_norm": 0.19596879184246063,
      "learning_rate": 8.277510102580044e-06,
      "loss": 0.0722,
      "step": 4433
    },
    {
      "epoch": 0.3445756916381722,
      "grad_norm": 0.28438857197761536,
      "learning_rate": 8.27712154180914e-06,
      "loss": 0.1169,
      "step": 4434
    },
    {
      "epoch": 0.3446534037923531,
      "grad_norm": 0.21871118247509003,
      "learning_rate": 8.276732981038234e-06,
      "loss": 0.0584,
      "step": 4435
    },
    {
      "epoch": 0.34473111594653405,
      "grad_norm": 0.19041472673416138,
      "learning_rate": 8.276344420267331e-06,
      "loss": 0.0949,
      "step": 4436
    },
    {
      "epoch": 0.34480882810071495,
      "grad_norm": 0.2676226794719696,
      "learning_rate": 8.275955859496426e-06,
      "loss": 0.2381,
      "step": 4437
    },
    {
      "epoch": 0.34488654025489585,
      "grad_norm": 0.055938564240932465,
      "learning_rate": 8.27556729872552e-06,
      "loss": 0.03,
      "step": 4438
    },
    {
      "epoch": 0.3449642524090768,
      "grad_norm": 0.8474403619766235,
      "learning_rate": 8.275178737954617e-06,
      "loss": 0.2841,
      "step": 4439
    },
    {
      "epoch": 0.3450419645632577,
      "grad_norm": 0.28471535444259644,
      "learning_rate": 8.274790177183712e-06,
      "loss": 0.0752,
      "step": 4440
    },
    {
      "epoch": 0.3451196767174386,
      "grad_norm": 1.134301781654358,
      "learning_rate": 8.274401616412807e-06,
      "loss": 0.6164,
      "step": 4441
    },
    {
      "epoch": 0.34519738887161955,
      "grad_norm": 0.28710025548934937,
      "learning_rate": 8.274013055641902e-06,
      "loss": 0.1707,
      "step": 4442
    },
    {
      "epoch": 0.34527510102580045,
      "grad_norm": 0.3691175878047943,
      "learning_rate": 8.273624494870999e-06,
      "loss": 0.2067,
      "step": 4443
    },
    {
      "epoch": 0.34535281317998134,
      "grad_norm": 0.3385758697986603,
      "learning_rate": 8.273235934100094e-06,
      "loss": 0.0397,
      "step": 4444
    },
    {
      "epoch": 0.34543052533416224,
      "grad_norm": 0.43446534872055054,
      "learning_rate": 8.272847373329189e-06,
      "loss": 0.6001,
      "step": 4445
    },
    {
      "epoch": 0.3455082374883432,
      "grad_norm": 0.2526013255119324,
      "learning_rate": 8.272458812558285e-06,
      "loss": 0.1218,
      "step": 4446
    },
    {
      "epoch": 0.3455859496425241,
      "grad_norm": 0.24014897644519806,
      "learning_rate": 8.27207025178738e-06,
      "loss": 0.1122,
      "step": 4447
    },
    {
      "epoch": 0.345663661796705,
      "grad_norm": 0.6344782114028931,
      "learning_rate": 8.271681691016475e-06,
      "loss": 0.4113,
      "step": 4448
    },
    {
      "epoch": 0.34574137395088594,
      "grad_norm": 0.1740349382162094,
      "learning_rate": 8.271293130245572e-06,
      "loss": 0.0422,
      "step": 4449
    },
    {
      "epoch": 0.34581908610506684,
      "grad_norm": 0.43258729577064514,
      "learning_rate": 8.270904569474667e-06,
      "loss": 0.4001,
      "step": 4450
    },
    {
      "epoch": 0.34589679825924774,
      "grad_norm": 0.16245269775390625,
      "learning_rate": 8.270516008703762e-06,
      "loss": 0.0811,
      "step": 4451
    },
    {
      "epoch": 0.34597451041342864,
      "grad_norm": 0.33964601159095764,
      "learning_rate": 8.270127447932857e-06,
      "loss": 0.2523,
      "step": 4452
    },
    {
      "epoch": 0.3460522225676096,
      "grad_norm": 0.3157428503036499,
      "learning_rate": 8.269738887161953e-06,
      "loss": 0.1794,
      "step": 4453
    },
    {
      "epoch": 0.3461299347217905,
      "grad_norm": 0.34440410137176514,
      "learning_rate": 8.269350326391048e-06,
      "loss": 0.1406,
      "step": 4454
    },
    {
      "epoch": 0.3462076468759714,
      "grad_norm": 0.6843549013137817,
      "learning_rate": 8.268961765620143e-06,
      "loss": 0.6578,
      "step": 4455
    },
    {
      "epoch": 0.34628535903015234,
      "grad_norm": 0.3835013210773468,
      "learning_rate": 8.26857320484924e-06,
      "loss": 0.1854,
      "step": 4456
    },
    {
      "epoch": 0.34636307118433324,
      "grad_norm": 0.4750764071941376,
      "learning_rate": 8.268184644078335e-06,
      "loss": 0.1372,
      "step": 4457
    },
    {
      "epoch": 0.34644078333851414,
      "grad_norm": 0.4150875210762024,
      "learning_rate": 8.26779608330743e-06,
      "loss": 0.2883,
      "step": 4458
    },
    {
      "epoch": 0.34651849549269503,
      "grad_norm": 0.45713335275650024,
      "learning_rate": 8.267407522536527e-06,
      "loss": 0.2425,
      "step": 4459
    },
    {
      "epoch": 0.346596207646876,
      "grad_norm": 0.3454197347164154,
      "learning_rate": 8.26701896176562e-06,
      "loss": 0.2284,
      "step": 4460
    },
    {
      "epoch": 0.3466739198010569,
      "grad_norm": 0.34864503145217896,
      "learning_rate": 8.266630400994716e-06,
      "loss": 0.2209,
      "step": 4461
    },
    {
      "epoch": 0.3467516319552378,
      "grad_norm": 0.2290220558643341,
      "learning_rate": 8.266241840223811e-06,
      "loss": 0.0991,
      "step": 4462
    },
    {
      "epoch": 0.34682934410941874,
      "grad_norm": 0.41673025488853455,
      "learning_rate": 8.265853279452906e-06,
      "loss": 0.3541,
      "step": 4463
    },
    {
      "epoch": 0.34690705626359963,
      "grad_norm": 0.6502739787101746,
      "learning_rate": 8.265464718682003e-06,
      "loss": 0.3835,
      "step": 4464
    },
    {
      "epoch": 0.34698476841778053,
      "grad_norm": 0.5766749382019043,
      "learning_rate": 8.265076157911098e-06,
      "loss": 0.2078,
      "step": 4465
    },
    {
      "epoch": 0.34706248057196143,
      "grad_norm": 0.2346380203962326,
      "learning_rate": 8.264687597140193e-06,
      "loss": 0.0685,
      "step": 4466
    },
    {
      "epoch": 0.3471401927261424,
      "grad_norm": 0.18845738470554352,
      "learning_rate": 8.26429903636929e-06,
      "loss": 0.0835,
      "step": 4467
    },
    {
      "epoch": 0.3472179048803233,
      "grad_norm": 0.7888187766075134,
      "learning_rate": 8.263910475598384e-06,
      "loss": 0.1782,
      "step": 4468
    },
    {
      "epoch": 0.3472956170345042,
      "grad_norm": 0.1760178506374359,
      "learning_rate": 8.26352191482748e-06,
      "loss": 0.0463,
      "step": 4469
    },
    {
      "epoch": 0.34737332918868513,
      "grad_norm": 0.22530615329742432,
      "learning_rate": 8.263133354056574e-06,
      "loss": 0.1425,
      "step": 4470
    },
    {
      "epoch": 0.34745104134286603,
      "grad_norm": 0.38053587079048157,
      "learning_rate": 8.262744793285671e-06,
      "loss": 0.1314,
      "step": 4471
    },
    {
      "epoch": 0.3475287534970469,
      "grad_norm": 0.5334651470184326,
      "learning_rate": 8.262356232514766e-06,
      "loss": 0.2923,
      "step": 4472
    },
    {
      "epoch": 0.3476064656512278,
      "grad_norm": 0.298665851354599,
      "learning_rate": 8.261967671743861e-06,
      "loss": 0.2304,
      "step": 4473
    },
    {
      "epoch": 0.3476841778054088,
      "grad_norm": 0.1488829106092453,
      "learning_rate": 8.261579110972958e-06,
      "loss": 0.0755,
      "step": 4474
    },
    {
      "epoch": 0.3477618899595897,
      "grad_norm": 0.5062716603279114,
      "learning_rate": 8.261190550202053e-06,
      "loss": 0.2964,
      "step": 4475
    },
    {
      "epoch": 0.3478396021137706,
      "grad_norm": 0.1231730505824089,
      "learning_rate": 8.260801989431147e-06,
      "loss": 0.1124,
      "step": 4476
    },
    {
      "epoch": 0.3479173142679515,
      "grad_norm": 0.20773309469223022,
      "learning_rate": 8.260413428660244e-06,
      "loss": 0.0402,
      "step": 4477
    },
    {
      "epoch": 0.3479950264221324,
      "grad_norm": 0.1958111971616745,
      "learning_rate": 8.260024867889339e-06,
      "loss": 0.0287,
      "step": 4478
    },
    {
      "epoch": 0.3480727385763133,
      "grad_norm": 0.326242595911026,
      "learning_rate": 8.259636307118434e-06,
      "loss": 0.1989,
      "step": 4479
    },
    {
      "epoch": 0.3481504507304943,
      "grad_norm": 0.31731629371643066,
      "learning_rate": 8.259247746347529e-06,
      "loss": 0.1177,
      "step": 4480
    },
    {
      "epoch": 0.3482281628846752,
      "grad_norm": 0.5029410123825073,
      "learning_rate": 8.258859185576626e-06,
      "loss": 0.4663,
      "step": 4481
    },
    {
      "epoch": 0.34830587503885607,
      "grad_norm": 0.21009773015975952,
      "learning_rate": 8.25847062480572e-06,
      "loss": 0.0752,
      "step": 4482
    },
    {
      "epoch": 0.34838358719303697,
      "grad_norm": 0.49527063965797424,
      "learning_rate": 8.258082064034816e-06,
      "loss": 0.3697,
      "step": 4483
    },
    {
      "epoch": 0.3484612993472179,
      "grad_norm": 0.24093176424503326,
      "learning_rate": 8.257693503263912e-06,
      "loss": 0.1007,
      "step": 4484
    },
    {
      "epoch": 0.3485390115013988,
      "grad_norm": 0.2717406153678894,
      "learning_rate": 8.257304942493007e-06,
      "loss": 0.123,
      "step": 4485
    },
    {
      "epoch": 0.3486167236555797,
      "grad_norm": 0.33562564849853516,
      "learning_rate": 8.256916381722102e-06,
      "loss": 0.1132,
      "step": 4486
    },
    {
      "epoch": 0.34869443580976067,
      "grad_norm": 0.5530438423156738,
      "learning_rate": 8.256527820951199e-06,
      "loss": 0.1757,
      "step": 4487
    },
    {
      "epoch": 0.34877214796394157,
      "grad_norm": 0.23442453145980835,
      "learning_rate": 8.256139260180292e-06,
      "loss": 0.095,
      "step": 4488
    },
    {
      "epoch": 0.34884986011812247,
      "grad_norm": 0.683703601360321,
      "learning_rate": 8.255750699409389e-06,
      "loss": 0.2958,
      "step": 4489
    },
    {
      "epoch": 0.34892757227230337,
      "grad_norm": 0.5253425240516663,
      "learning_rate": 8.255362138638484e-06,
      "loss": 0.4008,
      "step": 4490
    },
    {
      "epoch": 0.3490052844264843,
      "grad_norm": 1.2906088829040527,
      "learning_rate": 8.254973577867578e-06,
      "loss": 0.2118,
      "step": 4491
    },
    {
      "epoch": 0.3490829965806652,
      "grad_norm": 0.16923388838768005,
      "learning_rate": 8.254585017096675e-06,
      "loss": 0.1307,
      "step": 4492
    },
    {
      "epoch": 0.3491607087348461,
      "grad_norm": 0.3991187512874603,
      "learning_rate": 8.25419645632577e-06,
      "loss": 0.7453,
      "step": 4493
    },
    {
      "epoch": 0.34923842088902707,
      "grad_norm": 0.5281537771224976,
      "learning_rate": 8.253807895554865e-06,
      "loss": 0.1977,
      "step": 4494
    },
    {
      "epoch": 0.34931613304320797,
      "grad_norm": 0.505234956741333,
      "learning_rate": 8.253419334783962e-06,
      "loss": 0.2481,
      "step": 4495
    },
    {
      "epoch": 0.34939384519738886,
      "grad_norm": 0.6660442352294922,
      "learning_rate": 8.253030774013057e-06,
      "loss": 0.2193,
      "step": 4496
    },
    {
      "epoch": 0.34947155735156976,
      "grad_norm": 0.16847291588783264,
      "learning_rate": 8.252642213242152e-06,
      "loss": 0.1592,
      "step": 4497
    },
    {
      "epoch": 0.3495492695057507,
      "grad_norm": 0.06523403525352478,
      "learning_rate": 8.252253652471247e-06,
      "loss": 0.0362,
      "step": 4498
    },
    {
      "epoch": 0.3496269816599316,
      "grad_norm": 0.531773030757904,
      "learning_rate": 8.251865091700343e-06,
      "loss": 0.466,
      "step": 4499
    },
    {
      "epoch": 0.3497046938141125,
      "grad_norm": 0.4174346625804901,
      "learning_rate": 8.251476530929438e-06,
      "loss": 0.2384,
      "step": 4500
    },
    {
      "epoch": 0.34978240596829346,
      "grad_norm": 0.36199137568473816,
      "learning_rate": 8.251087970158533e-06,
      "loss": 0.3945,
      "step": 4501
    },
    {
      "epoch": 0.34986011812247436,
      "grad_norm": 0.34057679772377014,
      "learning_rate": 8.25069940938763e-06,
      "loss": 0.2528,
      "step": 4502
    },
    {
      "epoch": 0.34993783027665526,
      "grad_norm": 0.18643352389335632,
      "learning_rate": 8.250310848616723e-06,
      "loss": 0.0711,
      "step": 4503
    },
    {
      "epoch": 0.35001554243083616,
      "grad_norm": 0.05193823203444481,
      "learning_rate": 8.24992228784582e-06,
      "loss": 0.0083,
      "step": 4504
    },
    {
      "epoch": 0.3500932545850171,
      "grad_norm": 0.18923145532608032,
      "learning_rate": 8.249533727074915e-06,
      "loss": 0.1722,
      "step": 4505
    },
    {
      "epoch": 0.350170966739198,
      "grad_norm": 0.6036897301673889,
      "learning_rate": 8.24914516630401e-06,
      "loss": 0.2486,
      "step": 4506
    },
    {
      "epoch": 0.3502486788933789,
      "grad_norm": 0.575692355632782,
      "learning_rate": 8.248756605533106e-06,
      "loss": 0.2533,
      "step": 4507
    },
    {
      "epoch": 0.35032639104755986,
      "grad_norm": 0.1409282386302948,
      "learning_rate": 8.248368044762201e-06,
      "loss": 0.0161,
      "step": 4508
    },
    {
      "epoch": 0.35040410320174076,
      "grad_norm": 0.19780156016349792,
      "learning_rate": 8.247979483991298e-06,
      "loss": 0.0687,
      "step": 4509
    },
    {
      "epoch": 0.35048181535592166,
      "grad_norm": 0.9676075577735901,
      "learning_rate": 8.247590923220393e-06,
      "loss": 0.4312,
      "step": 4510
    },
    {
      "epoch": 0.35055952751010255,
      "grad_norm": 0.3007114827632904,
      "learning_rate": 8.247202362449488e-06,
      "loss": 0.0852,
      "step": 4511
    },
    {
      "epoch": 0.3506372396642835,
      "grad_norm": 0.2678280770778656,
      "learning_rate": 8.246813801678584e-06,
      "loss": 0.2158,
      "step": 4512
    },
    {
      "epoch": 0.3507149518184644,
      "grad_norm": 0.6045551300048828,
      "learning_rate": 8.246425240907678e-06,
      "loss": 0.2104,
      "step": 4513
    },
    {
      "epoch": 0.3507926639726453,
      "grad_norm": 0.5087646842002869,
      "learning_rate": 8.246036680136774e-06,
      "loss": 0.2831,
      "step": 4514
    },
    {
      "epoch": 0.35087037612682626,
      "grad_norm": 0.19095194339752197,
      "learning_rate": 8.245648119365869e-06,
      "loss": 0.0602,
      "step": 4515
    },
    {
      "epoch": 0.35094808828100715,
      "grad_norm": 0.811675488948822,
      "learning_rate": 8.245259558594964e-06,
      "loss": 0.1559,
      "step": 4516
    },
    {
      "epoch": 0.35102580043518805,
      "grad_norm": 0.48896104097366333,
      "learning_rate": 8.24487099782406e-06,
      "loss": 0.1844,
      "step": 4517
    },
    {
      "epoch": 0.351103512589369,
      "grad_norm": 0.40828201174736023,
      "learning_rate": 8.244482437053156e-06,
      "loss": 0.203,
      "step": 4518
    },
    {
      "epoch": 0.3511812247435499,
      "grad_norm": 0.25156399607658386,
      "learning_rate": 8.24409387628225e-06,
      "loss": 0.1047,
      "step": 4519
    },
    {
      "epoch": 0.3512589368977308,
      "grad_norm": 0.6075503826141357,
      "learning_rate": 8.243705315511347e-06,
      "loss": 0.1229,
      "step": 4520
    },
    {
      "epoch": 0.3513366490519117,
      "grad_norm": 0.39570507407188416,
      "learning_rate": 8.243316754740442e-06,
      "loss": 0.1625,
      "step": 4521
    },
    {
      "epoch": 0.35141436120609265,
      "grad_norm": 0.3096269369125366,
      "learning_rate": 8.242928193969537e-06,
      "loss": 0.1467,
      "step": 4522
    },
    {
      "epoch": 0.35149207336027355,
      "grad_norm": 0.2897239923477173,
      "learning_rate": 8.242539633198632e-06,
      "loss": 0.0696,
      "step": 4523
    },
    {
      "epoch": 0.35156978551445445,
      "grad_norm": 0.5261724591255188,
      "learning_rate": 8.242151072427729e-06,
      "loss": 0.151,
      "step": 4524
    },
    {
      "epoch": 0.3516474976686354,
      "grad_norm": 0.2879827618598938,
      "learning_rate": 8.241762511656824e-06,
      "loss": 0.2093,
      "step": 4525
    },
    {
      "epoch": 0.3517252098228163,
      "grad_norm": 0.3018302321434021,
      "learning_rate": 8.241373950885919e-06,
      "loss": 0.2119,
      "step": 4526
    },
    {
      "epoch": 0.3518029219769972,
      "grad_norm": 0.17429181933403015,
      "learning_rate": 8.240985390115015e-06,
      "loss": 0.1971,
      "step": 4527
    },
    {
      "epoch": 0.3518806341311781,
      "grad_norm": 0.5608114004135132,
      "learning_rate": 8.24059682934411e-06,
      "loss": 0.1991,
      "step": 4528
    },
    {
      "epoch": 0.35195834628535905,
      "grad_norm": 0.7103559970855713,
      "learning_rate": 8.240208268573205e-06,
      "loss": 0.6966,
      "step": 4529
    },
    {
      "epoch": 0.35203605843953995,
      "grad_norm": 0.6281055808067322,
      "learning_rate": 8.239819707802302e-06,
      "loss": 0.6316,
      "step": 4530
    },
    {
      "epoch": 0.35211377059372084,
      "grad_norm": 0.7001237869262695,
      "learning_rate": 8.239431147031395e-06,
      "loss": 0.5375,
      "step": 4531
    },
    {
      "epoch": 0.3521914827479018,
      "grad_norm": 0.08233107626438141,
      "learning_rate": 8.239042586260492e-06,
      "loss": 0.0217,
      "step": 4532
    },
    {
      "epoch": 0.3522691949020827,
      "grad_norm": 0.38253360986709595,
      "learning_rate": 8.238654025489587e-06,
      "loss": 0.3378,
      "step": 4533
    },
    {
      "epoch": 0.3523469070562636,
      "grad_norm": 0.2475496530532837,
      "learning_rate": 8.238265464718682e-06,
      "loss": 0.0717,
      "step": 4534
    },
    {
      "epoch": 0.3524246192104445,
      "grad_norm": 0.1756865531206131,
      "learning_rate": 8.237876903947778e-06,
      "loss": 0.0773,
      "step": 4535
    },
    {
      "epoch": 0.35250233136462544,
      "grad_norm": 0.18534795939922333,
      "learning_rate": 8.237488343176873e-06,
      "loss": 0.1726,
      "step": 4536
    },
    {
      "epoch": 0.35258004351880634,
      "grad_norm": 0.11834566295146942,
      "learning_rate": 8.237099782405968e-06,
      "loss": 0.0374,
      "step": 4537
    },
    {
      "epoch": 0.35265775567298724,
      "grad_norm": 0.2835242450237274,
      "learning_rate": 8.236711221635065e-06,
      "loss": 0.1562,
      "step": 4538
    },
    {
      "epoch": 0.3527354678271682,
      "grad_norm": 0.14560860395431519,
      "learning_rate": 8.23632266086416e-06,
      "loss": 0.0687,
      "step": 4539
    },
    {
      "epoch": 0.3528131799813491,
      "grad_norm": 0.25483646988868713,
      "learning_rate": 8.235934100093256e-06,
      "loss": 0.0952,
      "step": 4540
    },
    {
      "epoch": 0.35289089213553,
      "grad_norm": 0.45126792788505554,
      "learning_rate": 8.23554553932235e-06,
      "loss": 0.2619,
      "step": 4541
    },
    {
      "epoch": 0.3529686042897109,
      "grad_norm": 0.2616193890571594,
      "learning_rate": 8.235156978551446e-06,
      "loss": 0.1226,
      "step": 4542
    },
    {
      "epoch": 0.35304631644389184,
      "grad_norm": 0.19503049552440643,
      "learning_rate": 8.234768417780541e-06,
      "loss": 0.0378,
      "step": 4543
    },
    {
      "epoch": 0.35312402859807274,
      "grad_norm": 0.17263764142990112,
      "learning_rate": 8.234379857009636e-06,
      "loss": 0.0411,
      "step": 4544
    },
    {
      "epoch": 0.35320174075225363,
      "grad_norm": 0.21495530009269714,
      "learning_rate": 8.233991296238733e-06,
      "loss": 0.1163,
      "step": 4545
    },
    {
      "epoch": 0.3532794529064346,
      "grad_norm": 0.414227157831192,
      "learning_rate": 8.233602735467828e-06,
      "loss": 0.1229,
      "step": 4546
    },
    {
      "epoch": 0.3533571650606155,
      "grad_norm": 0.20034635066986084,
      "learning_rate": 8.233214174696923e-06,
      "loss": 0.0262,
      "step": 4547
    },
    {
      "epoch": 0.3534348772147964,
      "grad_norm": 0.16827115416526794,
      "learning_rate": 8.23282561392602e-06,
      "loss": 0.0457,
      "step": 4548
    },
    {
      "epoch": 0.3535125893689773,
      "grad_norm": 0.6053371429443359,
      "learning_rate": 8.232437053155114e-06,
      "loss": 0.3496,
      "step": 4549
    },
    {
      "epoch": 0.35359030152315823,
      "grad_norm": 0.8461157083511353,
      "learning_rate": 8.23204849238421e-06,
      "loss": 0.2456,
      "step": 4550
    },
    {
      "epoch": 0.35366801367733913,
      "grad_norm": 0.34672459959983826,
      "learning_rate": 8.231659931613304e-06,
      "loss": 0.1046,
      "step": 4551
    },
    {
      "epoch": 0.35374572583152003,
      "grad_norm": 0.5285590291023254,
      "learning_rate": 8.231271370842401e-06,
      "loss": 0.0785,
      "step": 4552
    },
    {
      "epoch": 0.353823437985701,
      "grad_norm": 0.5277419090270996,
      "learning_rate": 8.230882810071496e-06,
      "loss": 0.1412,
      "step": 4553
    },
    {
      "epoch": 0.3539011501398819,
      "grad_norm": 0.21171103417873383,
      "learning_rate": 8.23049424930059e-06,
      "loss": 0.2781,
      "step": 4554
    },
    {
      "epoch": 0.3539788622940628,
      "grad_norm": 0.6631761789321899,
      "learning_rate": 8.230105688529687e-06,
      "loss": 0.3602,
      "step": 4555
    },
    {
      "epoch": 0.35405657444824373,
      "grad_norm": 0.4216974973678589,
      "learning_rate": 8.229717127758782e-06,
      "loss": 0.2858,
      "step": 4556
    },
    {
      "epoch": 0.35413428660242463,
      "grad_norm": 0.6772071123123169,
      "learning_rate": 8.229328566987877e-06,
      "loss": 0.3321,
      "step": 4557
    },
    {
      "epoch": 0.35421199875660553,
      "grad_norm": 0.26034921407699585,
      "learning_rate": 8.228940006216974e-06,
      "loss": 0.1202,
      "step": 4558
    },
    {
      "epoch": 0.3542897109107864,
      "grad_norm": 0.6126654744148254,
      "learning_rate": 8.228551445446067e-06,
      "loss": 0.3381,
      "step": 4559
    },
    {
      "epoch": 0.3543674230649674,
      "grad_norm": 0.26319625973701477,
      "learning_rate": 8.228162884675164e-06,
      "loss": 0.2598,
      "step": 4560
    },
    {
      "epoch": 0.3544451352191483,
      "grad_norm": 0.26465973258018494,
      "learning_rate": 8.227774323904259e-06,
      "loss": 0.3191,
      "step": 4561
    },
    {
      "epoch": 0.3545228473733292,
      "grad_norm": 0.27241551876068115,
      "learning_rate": 8.227385763133354e-06,
      "loss": 0.0326,
      "step": 4562
    },
    {
      "epoch": 0.35460055952751013,
      "grad_norm": 0.18151773512363434,
      "learning_rate": 8.22699720236245e-06,
      "loss": 0.1679,
      "step": 4563
    },
    {
      "epoch": 0.354678271681691,
      "grad_norm": 0.6681652069091797,
      "learning_rate": 8.226608641591545e-06,
      "loss": 0.2644,
      "step": 4564
    },
    {
      "epoch": 0.3547559838358719,
      "grad_norm": 0.3160361349582672,
      "learning_rate": 8.22622008082064e-06,
      "loss": 0.1418,
      "step": 4565
    },
    {
      "epoch": 0.3548336959900528,
      "grad_norm": 0.4064631760120392,
      "learning_rate": 8.225831520049737e-06,
      "loss": 0.0663,
      "step": 4566
    },
    {
      "epoch": 0.3549114081442338,
      "grad_norm": 2.0236825942993164,
      "learning_rate": 8.225442959278832e-06,
      "loss": 0.2761,
      "step": 4567
    },
    {
      "epoch": 0.3549891202984147,
      "grad_norm": 0.13781283795833588,
      "learning_rate": 8.225054398507929e-06,
      "loss": 0.0493,
      "step": 4568
    },
    {
      "epoch": 0.35506683245259557,
      "grad_norm": 0.5112195611000061,
      "learning_rate": 8.224665837737022e-06,
      "loss": 0.3199,
      "step": 4569
    },
    {
      "epoch": 0.3551445446067765,
      "grad_norm": 0.5694904327392578,
      "learning_rate": 8.224277276966118e-06,
      "loss": 0.2516,
      "step": 4570
    },
    {
      "epoch": 0.3552222567609574,
      "grad_norm": 1.1728160381317139,
      "learning_rate": 8.223888716195213e-06,
      "loss": 0.284,
      "step": 4571
    },
    {
      "epoch": 0.3552999689151383,
      "grad_norm": 0.17552532255649567,
      "learning_rate": 8.223500155424308e-06,
      "loss": 0.0956,
      "step": 4572
    },
    {
      "epoch": 0.3553776810693192,
      "grad_norm": 0.3052450716495514,
      "learning_rate": 8.223111594653405e-06,
      "loss": 0.1206,
      "step": 4573
    },
    {
      "epoch": 0.35545539322350017,
      "grad_norm": 0.24338474869728088,
      "learning_rate": 8.2227230338825e-06,
      "loss": 0.243,
      "step": 4574
    },
    {
      "epoch": 0.35553310537768107,
      "grad_norm": 0.18021893501281738,
      "learning_rate": 8.222334473111595e-06,
      "loss": 0.0649,
      "step": 4575
    },
    {
      "epoch": 0.35561081753186197,
      "grad_norm": 0.3486904799938202,
      "learning_rate": 8.221945912340692e-06,
      "loss": 0.144,
      "step": 4576
    },
    {
      "epoch": 0.3556885296860429,
      "grad_norm": 0.3541295826435089,
      "learning_rate": 8.221557351569787e-06,
      "loss": 0.3441,
      "step": 4577
    },
    {
      "epoch": 0.3557662418402238,
      "grad_norm": 0.10768727958202362,
      "learning_rate": 8.221168790798881e-06,
      "loss": 0.0171,
      "step": 4578
    },
    {
      "epoch": 0.3558439539944047,
      "grad_norm": 2.6906914710998535,
      "learning_rate": 8.220780230027976e-06,
      "loss": 0.9507,
      "step": 4579
    },
    {
      "epoch": 0.3559216661485856,
      "grad_norm": 0.5341877341270447,
      "learning_rate": 8.220391669257073e-06,
      "loss": 0.2805,
      "step": 4580
    },
    {
      "epoch": 0.35599937830276657,
      "grad_norm": 0.1534944623708725,
      "learning_rate": 8.220003108486168e-06,
      "loss": 0.0358,
      "step": 4581
    },
    {
      "epoch": 0.35607709045694746,
      "grad_norm": 0.25906580686569214,
      "learning_rate": 8.219614547715263e-06,
      "loss": 0.1022,
      "step": 4582
    },
    {
      "epoch": 0.35615480261112836,
      "grad_norm": 0.8587820529937744,
      "learning_rate": 8.21922598694436e-06,
      "loss": 0.7404,
      "step": 4583
    },
    {
      "epoch": 0.3562325147653093,
      "grad_norm": 0.20796987414360046,
      "learning_rate": 8.218837426173455e-06,
      "loss": 0.077,
      "step": 4584
    },
    {
      "epoch": 0.3563102269194902,
      "grad_norm": 0.627761721611023,
      "learning_rate": 8.21844886540255e-06,
      "loss": 0.2378,
      "step": 4585
    },
    {
      "epoch": 0.3563879390736711,
      "grad_norm": 0.04069127142429352,
      "learning_rate": 8.218060304631646e-06,
      "loss": 0.0102,
      "step": 4586
    },
    {
      "epoch": 0.356465651227852,
      "grad_norm": 0.15222913026809692,
      "learning_rate": 8.21767174386074e-06,
      "loss": 0.0484,
      "step": 4587
    },
    {
      "epoch": 0.35654336338203296,
      "grad_norm": 0.10760928690433502,
      "learning_rate": 8.217283183089836e-06,
      "loss": 0.0279,
      "step": 4588
    },
    {
      "epoch": 0.35662107553621386,
      "grad_norm": 0.4167524576187134,
      "learning_rate": 8.216894622318931e-06,
      "loss": 0.315,
      "step": 4589
    },
    {
      "epoch": 0.35669878769039476,
      "grad_norm": 0.25232866406440735,
      "learning_rate": 8.216506061548026e-06,
      "loss": 0.075,
      "step": 4590
    },
    {
      "epoch": 0.3567764998445757,
      "grad_norm": 0.2155177742242813,
      "learning_rate": 8.216117500777123e-06,
      "loss": 0.1465,
      "step": 4591
    },
    {
      "epoch": 0.3568542119987566,
      "grad_norm": 0.44835320115089417,
      "learning_rate": 8.215728940006218e-06,
      "loss": 0.3254,
      "step": 4592
    },
    {
      "epoch": 0.3569319241529375,
      "grad_norm": 0.22702091932296753,
      "learning_rate": 8.215340379235313e-06,
      "loss": 0.0736,
      "step": 4593
    },
    {
      "epoch": 0.35700963630711846,
      "grad_norm": 0.44440484046936035,
      "learning_rate": 8.214951818464409e-06,
      "loss": 0.7152,
      "step": 4594
    },
    {
      "epoch": 0.35708734846129936,
      "grad_norm": 0.3387252390384674,
      "learning_rate": 8.214563257693504e-06,
      "loss": 0.1524,
      "step": 4595
    },
    {
      "epoch": 0.35716506061548026,
      "grad_norm": 0.2948799133300781,
      "learning_rate": 8.214174696922599e-06,
      "loss": 0.1311,
      "step": 4596
    },
    {
      "epoch": 0.35724277276966115,
      "grad_norm": 0.528024435043335,
      "learning_rate": 8.213786136151694e-06,
      "loss": 0.5635,
      "step": 4597
    },
    {
      "epoch": 0.3573204849238421,
      "grad_norm": 0.07165386527776718,
      "learning_rate": 8.21339757538079e-06,
      "loss": 0.0347,
      "step": 4598
    },
    {
      "epoch": 0.357398197078023,
      "grad_norm": 0.28869348764419556,
      "learning_rate": 8.213009014609886e-06,
      "loss": 0.2271,
      "step": 4599
    },
    {
      "epoch": 0.3574759092322039,
      "grad_norm": 0.28379660844802856,
      "learning_rate": 8.21262045383898e-06,
      "loss": 0.2438,
      "step": 4600
    },
    {
      "epoch": 0.35755362138638486,
      "grad_norm": 0.2490370124578476,
      "learning_rate": 8.212231893068077e-06,
      "loss": 0.0764,
      "step": 4601
    },
    {
      "epoch": 0.35763133354056575,
      "grad_norm": 0.8474363684654236,
      "learning_rate": 8.211843332297172e-06,
      "loss": 0.2351,
      "step": 4602
    },
    {
      "epoch": 0.35770904569474665,
      "grad_norm": 0.30170634388923645,
      "learning_rate": 8.211454771526267e-06,
      "loss": 0.1323,
      "step": 4603
    },
    {
      "epoch": 0.35778675784892755,
      "grad_norm": 0.14141251146793365,
      "learning_rate": 8.211066210755364e-06,
      "loss": 0.0707,
      "step": 4604
    },
    {
      "epoch": 0.3578644700031085,
      "grad_norm": 0.3663788139820099,
      "learning_rate": 8.210677649984459e-06,
      "loss": 0.1326,
      "step": 4605
    },
    {
      "epoch": 0.3579421821572894,
      "grad_norm": 0.2962270975112915,
      "learning_rate": 8.210289089213554e-06,
      "loss": 0.0781,
      "step": 4606
    },
    {
      "epoch": 0.3580198943114703,
      "grad_norm": 0.2991808354854584,
      "learning_rate": 8.209900528442649e-06,
      "loss": 0.0713,
      "step": 4607
    },
    {
      "epoch": 0.35809760646565125,
      "grad_norm": 0.21437960863113403,
      "learning_rate": 8.209511967671745e-06,
      "loss": 0.0565,
      "step": 4608
    },
    {
      "epoch": 0.35817531861983215,
      "grad_norm": 0.1682863086462021,
      "learning_rate": 8.20912340690084e-06,
      "loss": 0.0512,
      "step": 4609
    },
    {
      "epoch": 0.35825303077401305,
      "grad_norm": 0.10867799073457718,
      "learning_rate": 8.208734846129935e-06,
      "loss": 0.0314,
      "step": 4610
    },
    {
      "epoch": 0.35833074292819395,
      "grad_norm": 0.11874092370271683,
      "learning_rate": 8.208346285359032e-06,
      "loss": 0.011,
      "step": 4611
    },
    {
      "epoch": 0.3584084550823749,
      "grad_norm": 0.9569076895713806,
      "learning_rate": 8.207957724588127e-06,
      "loss": 0.4833,
      "step": 4612
    },
    {
      "epoch": 0.3584861672365558,
      "grad_norm": 0.39615195989608765,
      "learning_rate": 8.207569163817222e-06,
      "loss": 0.0496,
      "step": 4613
    },
    {
      "epoch": 0.3585638793907367,
      "grad_norm": 0.2682178020477295,
      "learning_rate": 8.207180603046318e-06,
      "loss": 0.2125,
      "step": 4614
    },
    {
      "epoch": 0.35864159154491765,
      "grad_norm": 0.28729248046875,
      "learning_rate": 8.206792042275412e-06,
      "loss": 0.1685,
      "step": 4615
    },
    {
      "epoch": 0.35871930369909855,
      "grad_norm": 0.6532491445541382,
      "learning_rate": 8.206403481504508e-06,
      "loss": 0.5875,
      "step": 4616
    },
    {
      "epoch": 0.35879701585327944,
      "grad_norm": 0.3133585751056671,
      "learning_rate": 8.206014920733603e-06,
      "loss": 0.1375,
      "step": 4617
    },
    {
      "epoch": 0.35887472800746034,
      "grad_norm": 0.3389909863471985,
      "learning_rate": 8.205626359962698e-06,
      "loss": 0.0401,
      "step": 4618
    },
    {
      "epoch": 0.3589524401616413,
      "grad_norm": 0.17240320146083832,
      "learning_rate": 8.205237799191795e-06,
      "loss": 0.1184,
      "step": 4619
    },
    {
      "epoch": 0.3590301523158222,
      "grad_norm": 0.219480499625206,
      "learning_rate": 8.20484923842089e-06,
      "loss": 0.0303,
      "step": 4620
    },
    {
      "epoch": 0.3591078644700031,
      "grad_norm": 1.015533208847046,
      "learning_rate": 8.204460677649985e-06,
      "loss": 0.4167,
      "step": 4621
    },
    {
      "epoch": 0.35918557662418404,
      "grad_norm": 0.08581245690584183,
      "learning_rate": 8.204072116879081e-06,
      "loss": 0.0105,
      "step": 4622
    },
    {
      "epoch": 0.35926328877836494,
      "grad_norm": 0.6159589290618896,
      "learning_rate": 8.203683556108176e-06,
      "loss": 0.294,
      "step": 4623
    },
    {
      "epoch": 0.35934100093254584,
      "grad_norm": 0.5144232511520386,
      "learning_rate": 8.203294995337271e-06,
      "loss": 0.1925,
      "step": 4624
    },
    {
      "epoch": 0.35941871308672674,
      "grad_norm": 0.12077361345291138,
      "learning_rate": 8.202906434566366e-06,
      "loss": 0.0458,
      "step": 4625
    },
    {
      "epoch": 0.3594964252409077,
      "grad_norm": 0.13760817050933838,
      "learning_rate": 8.202517873795463e-06,
      "loss": 0.0334,
      "step": 4626
    },
    {
      "epoch": 0.3595741373950886,
      "grad_norm": 0.28556060791015625,
      "learning_rate": 8.202129313024558e-06,
      "loss": 0.0523,
      "step": 4627
    },
    {
      "epoch": 0.3596518495492695,
      "grad_norm": 0.21661724150180817,
      "learning_rate": 8.201740752253653e-06,
      "loss": 0.1803,
      "step": 4628
    },
    {
      "epoch": 0.35972956170345044,
      "grad_norm": 0.2749234437942505,
      "learning_rate": 8.20135219148275e-06,
      "loss": 0.0927,
      "step": 4629
    },
    {
      "epoch": 0.35980727385763134,
      "grad_norm": 0.2631528973579407,
      "learning_rate": 8.200963630711844e-06,
      "loss": 0.0646,
      "step": 4630
    },
    {
      "epoch": 0.35988498601181224,
      "grad_norm": 0.4133315682411194,
      "learning_rate": 8.20057506994094e-06,
      "loss": 0.5337,
      "step": 4631
    },
    {
      "epoch": 0.3599626981659932,
      "grad_norm": 1.2268812656402588,
      "learning_rate": 8.200186509170034e-06,
      "loss": 0.4032,
      "step": 4632
    },
    {
      "epoch": 0.3600404103201741,
      "grad_norm": 0.40107300877571106,
      "learning_rate": 8.19979794839913e-06,
      "loss": 0.4004,
      "step": 4633
    },
    {
      "epoch": 0.360118122474355,
      "grad_norm": 0.14431360363960266,
      "learning_rate": 8.199409387628226e-06,
      "loss": 0.085,
      "step": 4634
    },
    {
      "epoch": 0.3601958346285359,
      "grad_norm": 0.09997712820768356,
      "learning_rate": 8.19902082685732e-06,
      "loss": 0.0264,
      "step": 4635
    },
    {
      "epoch": 0.36027354678271684,
      "grad_norm": 1.883919596672058,
      "learning_rate": 8.198632266086417e-06,
      "loss": 1.8579,
      "step": 4636
    },
    {
      "epoch": 0.36035125893689773,
      "grad_norm": 0.2693002223968506,
      "learning_rate": 8.198243705315512e-06,
      "loss": 0.1604,
      "step": 4637
    },
    {
      "epoch": 0.36042897109107863,
      "grad_norm": 0.12804067134857178,
      "learning_rate": 8.197855144544607e-06,
      "loss": 0.0307,
      "step": 4638
    },
    {
      "epoch": 0.3605066832452596,
      "grad_norm": 0.4169532060623169,
      "learning_rate": 8.197466583773704e-06,
      "loss": 0.7106,
      "step": 4639
    },
    {
      "epoch": 0.3605843953994405,
      "grad_norm": 0.7407878637313843,
      "learning_rate": 8.197078023002797e-06,
      "loss": 0.4732,
      "step": 4640
    },
    {
      "epoch": 0.3606621075536214,
      "grad_norm": 0.3026592433452606,
      "learning_rate": 8.196689462231894e-06,
      "loss": 0.1463,
      "step": 4641
    },
    {
      "epoch": 0.3607398197078023,
      "grad_norm": 0.5428406596183777,
      "learning_rate": 8.196300901460989e-06,
      "loss": 0.1443,
      "step": 4642
    },
    {
      "epoch": 0.36081753186198323,
      "grad_norm": 0.5986459255218506,
      "learning_rate": 8.195912340690084e-06,
      "loss": 0.181,
      "step": 4643
    },
    {
      "epoch": 0.36089524401616413,
      "grad_norm": 0.20410510897636414,
      "learning_rate": 8.19552377991918e-06,
      "loss": 0.1528,
      "step": 4644
    },
    {
      "epoch": 0.360972956170345,
      "grad_norm": 0.4879930913448334,
      "learning_rate": 8.195135219148275e-06,
      "loss": 0.4899,
      "step": 4645
    },
    {
      "epoch": 0.361050668324526,
      "grad_norm": 0.35404255986213684,
      "learning_rate": 8.19474665837737e-06,
      "loss": 0.1412,
      "step": 4646
    },
    {
      "epoch": 0.3611283804787069,
      "grad_norm": 0.5128779411315918,
      "learning_rate": 8.194358097606467e-06,
      "loss": 0.2736,
      "step": 4647
    },
    {
      "epoch": 0.3612060926328878,
      "grad_norm": 0.3592507243156433,
      "learning_rate": 8.193969536835562e-06,
      "loss": 0.4649,
      "step": 4648
    },
    {
      "epoch": 0.3612838047870687,
      "grad_norm": 0.08403503149747849,
      "learning_rate": 8.193580976064657e-06,
      "loss": 0.0265,
      "step": 4649
    },
    {
      "epoch": 0.3613615169412496,
      "grad_norm": 0.4207760691642761,
      "learning_rate": 8.193192415293752e-06,
      "loss": 0.2983,
      "step": 4650
    },
    {
      "epoch": 0.3614392290954305,
      "grad_norm": 0.05240621417760849,
      "learning_rate": 8.192803854522848e-06,
      "loss": 0.0119,
      "step": 4651
    },
    {
      "epoch": 0.3615169412496114,
      "grad_norm": 0.057679396122694016,
      "learning_rate": 8.192415293751943e-06,
      "loss": 0.0147,
      "step": 4652
    },
    {
      "epoch": 0.3615946534037924,
      "grad_norm": 0.2547418475151062,
      "learning_rate": 8.192026732981038e-06,
      "loss": 0.1078,
      "step": 4653
    },
    {
      "epoch": 0.3616723655579733,
      "grad_norm": 0.3604634702205658,
      "learning_rate": 8.191638172210135e-06,
      "loss": 0.3899,
      "step": 4654
    },
    {
      "epoch": 0.36175007771215417,
      "grad_norm": 0.2695045471191406,
      "learning_rate": 8.19124961143923e-06,
      "loss": 0.0986,
      "step": 4655
    },
    {
      "epoch": 0.36182778986633507,
      "grad_norm": 0.23993803560733795,
      "learning_rate": 8.190861050668325e-06,
      "loss": 0.0861,
      "step": 4656
    },
    {
      "epoch": 0.361905502020516,
      "grad_norm": 1.320326328277588,
      "learning_rate": 8.190472489897421e-06,
      "loss": 1.5225,
      "step": 4657
    },
    {
      "epoch": 0.3619832141746969,
      "grad_norm": 0.3806147575378418,
      "learning_rate": 8.190083929126515e-06,
      "loss": 0.346,
      "step": 4658
    },
    {
      "epoch": 0.3620609263288778,
      "grad_norm": 0.19102369248867035,
      "learning_rate": 8.189695368355611e-06,
      "loss": 0.0789,
      "step": 4659
    },
    {
      "epoch": 0.3621386384830588,
      "grad_norm": 0.34062665700912476,
      "learning_rate": 8.189306807584706e-06,
      "loss": 0.0977,
      "step": 4660
    },
    {
      "epoch": 0.36221635063723967,
      "grad_norm": 0.3957887589931488,
      "learning_rate": 8.188918246813803e-06,
      "loss": 0.1256,
      "step": 4661
    },
    {
      "epoch": 0.36229406279142057,
      "grad_norm": 0.17974580824375153,
      "learning_rate": 8.188529686042898e-06,
      "loss": 0.0377,
      "step": 4662
    },
    {
      "epoch": 0.36237177494560147,
      "grad_norm": 0.962914228439331,
      "learning_rate": 8.188141125271993e-06,
      "loss": 0.3601,
      "step": 4663
    },
    {
      "epoch": 0.3624494870997824,
      "grad_norm": 0.15390510857105255,
      "learning_rate": 8.18775256450109e-06,
      "loss": 0.0751,
      "step": 4664
    },
    {
      "epoch": 0.3625271992539633,
      "grad_norm": 0.4513295590877533,
      "learning_rate": 8.187364003730184e-06,
      "loss": 0.5113,
      "step": 4665
    },
    {
      "epoch": 0.3626049114081442,
      "grad_norm": 0.16401690244674683,
      "learning_rate": 8.18697544295928e-06,
      "loss": 0.0958,
      "step": 4666
    },
    {
      "epoch": 0.36268262356232517,
      "grad_norm": 0.18108370900154114,
      "learning_rate": 8.186586882188376e-06,
      "loss": 0.0617,
      "step": 4667
    },
    {
      "epoch": 0.36276033571650607,
      "grad_norm": 0.3839532732963562,
      "learning_rate": 8.18619832141747e-06,
      "loss": 0.1851,
      "step": 4668
    },
    {
      "epoch": 0.36283804787068696,
      "grad_norm": 0.21333768963813782,
      "learning_rate": 8.185809760646566e-06,
      "loss": 0.0284,
      "step": 4669
    },
    {
      "epoch": 0.36291576002486786,
      "grad_norm": 0.14954523742198944,
      "learning_rate": 8.185421199875661e-06,
      "loss": 0.0919,
      "step": 4670
    },
    {
      "epoch": 0.3629934721790488,
      "grad_norm": 0.47871536016464233,
      "learning_rate": 8.185032639104756e-06,
      "loss": 0.3453,
      "step": 4671
    },
    {
      "epoch": 0.3630711843332297,
      "grad_norm": 0.17760124802589417,
      "learning_rate": 8.184644078333852e-06,
      "loss": 0.0253,
      "step": 4672
    },
    {
      "epoch": 0.3631488964874106,
      "grad_norm": 0.1377326101064682,
      "learning_rate": 8.184255517562947e-06,
      "loss": 0.0296,
      "step": 4673
    },
    {
      "epoch": 0.36322660864159156,
      "grad_norm": 0.2504476010799408,
      "learning_rate": 8.183866956792042e-06,
      "loss": 0.1721,
      "step": 4674
    },
    {
      "epoch": 0.36330432079577246,
      "grad_norm": 0.2761668860912323,
      "learning_rate": 8.183478396021139e-06,
      "loss": 0.153,
      "step": 4675
    },
    {
      "epoch": 0.36338203294995336,
      "grad_norm": 0.1214287057518959,
      "learning_rate": 8.183089835250234e-06,
      "loss": 0.0335,
      "step": 4676
    },
    {
      "epoch": 0.3634597451041343,
      "grad_norm": 0.10437130182981491,
      "learning_rate": 8.182701274479329e-06,
      "loss": 0.0229,
      "step": 4677
    },
    {
      "epoch": 0.3635374572583152,
      "grad_norm": 0.3195275664329529,
      "learning_rate": 8.182312713708424e-06,
      "loss": 0.1189,
      "step": 4678
    },
    {
      "epoch": 0.3636151694124961,
      "grad_norm": 1.1572456359863281,
      "learning_rate": 8.18192415293752e-06,
      "loss": 0.905,
      "step": 4679
    },
    {
      "epoch": 0.363692881566677,
      "grad_norm": 0.27733296155929565,
      "learning_rate": 8.181535592166615e-06,
      "loss": 0.3725,
      "step": 4680
    },
    {
      "epoch": 0.36377059372085796,
      "grad_norm": 0.44161343574523926,
      "learning_rate": 8.18114703139571e-06,
      "loss": 0.329,
      "step": 4681
    },
    {
      "epoch": 0.36384830587503886,
      "grad_norm": 0.38958752155303955,
      "learning_rate": 8.180758470624807e-06,
      "loss": 0.0981,
      "step": 4682
    },
    {
      "epoch": 0.36392601802921976,
      "grad_norm": 0.065674789249897,
      "learning_rate": 8.180369909853902e-06,
      "loss": 0.0194,
      "step": 4683
    },
    {
      "epoch": 0.3640037301834007,
      "grad_norm": 0.3027344346046448,
      "learning_rate": 8.179981349082997e-06,
      "loss": 0.2319,
      "step": 4684
    },
    {
      "epoch": 0.3640814423375816,
      "grad_norm": 0.24329856038093567,
      "learning_rate": 8.179592788312094e-06,
      "loss": 0.0453,
      "step": 4685
    },
    {
      "epoch": 0.3641591544917625,
      "grad_norm": 0.31238463521003723,
      "learning_rate": 8.179204227541187e-06,
      "loss": 0.111,
      "step": 4686
    },
    {
      "epoch": 0.3642368666459434,
      "grad_norm": 0.6145371198654175,
      "learning_rate": 8.178815666770284e-06,
      "loss": 0.1319,
      "step": 4687
    },
    {
      "epoch": 0.36431457880012436,
      "grad_norm": 0.485282838344574,
      "learning_rate": 8.178427105999378e-06,
      "loss": 0.1697,
      "step": 4688
    },
    {
      "epoch": 0.36439229095430525,
      "grad_norm": 0.23373253643512726,
      "learning_rate": 8.178038545228475e-06,
      "loss": 0.1687,
      "step": 4689
    },
    {
      "epoch": 0.36447000310848615,
      "grad_norm": 0.5336052775382996,
      "learning_rate": 8.17764998445757e-06,
      "loss": 0.3843,
      "step": 4690
    },
    {
      "epoch": 0.3645477152626671,
      "grad_norm": 0.28681182861328125,
      "learning_rate": 8.177261423686665e-06,
      "loss": 0.1002,
      "step": 4691
    },
    {
      "epoch": 0.364625427416848,
      "grad_norm": 0.6400207281112671,
      "learning_rate": 8.176872862915762e-06,
      "loss": 0.5391,
      "step": 4692
    },
    {
      "epoch": 0.3647031395710289,
      "grad_norm": 0.18902726471424103,
      "learning_rate": 8.176484302144857e-06,
      "loss": 0.075,
      "step": 4693
    },
    {
      "epoch": 0.3647808517252098,
      "grad_norm": 0.24352490901947021,
      "learning_rate": 8.176095741373952e-06,
      "loss": 0.1074,
      "step": 4694
    },
    {
      "epoch": 0.36485856387939075,
      "grad_norm": 0.28015491366386414,
      "learning_rate": 8.175707180603048e-06,
      "loss": 0.2645,
      "step": 4695
    },
    {
      "epoch": 0.36493627603357165,
      "grad_norm": 0.29757899045944214,
      "learning_rate": 8.175318619832141e-06,
      "loss": 0.1196,
      "step": 4696
    },
    {
      "epoch": 0.36501398818775255,
      "grad_norm": 0.835041880607605,
      "learning_rate": 8.174930059061238e-06,
      "loss": 0.2163,
      "step": 4697
    },
    {
      "epoch": 0.3650917003419335,
      "grad_norm": 0.6389099359512329,
      "learning_rate": 8.174541498290333e-06,
      "loss": 0.8083,
      "step": 4698
    },
    {
      "epoch": 0.3651694124961144,
      "grad_norm": 0.21919652819633484,
      "learning_rate": 8.174152937519428e-06,
      "loss": 0.1404,
      "step": 4699
    },
    {
      "epoch": 0.3652471246502953,
      "grad_norm": 0.2634170353412628,
      "learning_rate": 8.173764376748525e-06,
      "loss": 0.0594,
      "step": 4700
    },
    {
      "epoch": 0.3653248368044762,
      "grad_norm": 0.19690704345703125,
      "learning_rate": 8.17337581597762e-06,
      "loss": 0.0598,
      "step": 4701
    },
    {
      "epoch": 0.36540254895865715,
      "grad_norm": 0.2875707447528839,
      "learning_rate": 8.172987255206715e-06,
      "loss": 0.5938,
      "step": 4702
    },
    {
      "epoch": 0.36548026111283805,
      "grad_norm": 0.39009585976600647,
      "learning_rate": 8.172598694435811e-06,
      "loss": 0.1681,
      "step": 4703
    },
    {
      "epoch": 0.36555797326701894,
      "grad_norm": 0.35682135820388794,
      "learning_rate": 8.172210133664906e-06,
      "loss": 0.133,
      "step": 4704
    },
    {
      "epoch": 0.3656356854211999,
      "grad_norm": 0.12699288129806519,
      "learning_rate": 8.171821572894001e-06,
      "loss": 0.0409,
      "step": 4705
    },
    {
      "epoch": 0.3657133975753808,
      "grad_norm": 0.12486189603805542,
      "learning_rate": 8.171433012123096e-06,
      "loss": 0.0622,
      "step": 4706
    },
    {
      "epoch": 0.3657911097295617,
      "grad_norm": 0.14408156275749207,
      "learning_rate": 8.171044451352193e-06,
      "loss": 0.0567,
      "step": 4707
    },
    {
      "epoch": 0.3658688218837426,
      "grad_norm": 0.15182271599769592,
      "learning_rate": 8.170655890581288e-06,
      "loss": 0.0681,
      "step": 4708
    },
    {
      "epoch": 0.36594653403792354,
      "grad_norm": 0.46018290519714355,
      "learning_rate": 8.170267329810383e-06,
      "loss": 0.2155,
      "step": 4709
    },
    {
      "epoch": 0.36602424619210444,
      "grad_norm": 0.4694400131702423,
      "learning_rate": 8.16987876903948e-06,
      "loss": 0.1141,
      "step": 4710
    },
    {
      "epoch": 0.36610195834628534,
      "grad_norm": 0.2022901326417923,
      "learning_rate": 8.169490208268574e-06,
      "loss": 0.1088,
      "step": 4711
    },
    {
      "epoch": 0.3661796705004663,
      "grad_norm": 0.25110384821891785,
      "learning_rate": 8.169101647497669e-06,
      "loss": 0.1412,
      "step": 4712
    },
    {
      "epoch": 0.3662573826546472,
      "grad_norm": 0.12538044154644012,
      "learning_rate": 8.168713086726766e-06,
      "loss": 0.0348,
      "step": 4713
    },
    {
      "epoch": 0.3663350948088281,
      "grad_norm": 0.40099799633026123,
      "learning_rate": 8.168324525955859e-06,
      "loss": 0.4207,
      "step": 4714
    },
    {
      "epoch": 0.36641280696300904,
      "grad_norm": 0.19515253603458405,
      "learning_rate": 8.167935965184956e-06,
      "loss": 0.054,
      "step": 4715
    },
    {
      "epoch": 0.36649051911718994,
      "grad_norm": 0.23364309966564178,
      "learning_rate": 8.16754740441405e-06,
      "loss": 0.1564,
      "step": 4716
    },
    {
      "epoch": 0.36656823127137084,
      "grad_norm": 0.5895026326179504,
      "learning_rate": 8.167158843643146e-06,
      "loss": 0.5072,
      "step": 4717
    },
    {
      "epoch": 0.36664594342555173,
      "grad_norm": 0.217454731464386,
      "learning_rate": 8.166770282872242e-06,
      "loss": 0.2118,
      "step": 4718
    },
    {
      "epoch": 0.3667236555797327,
      "grad_norm": 0.27731114625930786,
      "learning_rate": 8.166381722101337e-06,
      "loss": 0.043,
      "step": 4719
    },
    {
      "epoch": 0.3668013677339136,
      "grad_norm": 0.4033067226409912,
      "learning_rate": 8.165993161330434e-06,
      "loss": 0.1089,
      "step": 4720
    },
    {
      "epoch": 0.3668790798880945,
      "grad_norm": 0.6454675793647766,
      "learning_rate": 8.165604600559529e-06,
      "loss": 0.1778,
      "step": 4721
    },
    {
      "epoch": 0.36695679204227544,
      "grad_norm": 0.46241751313209534,
      "learning_rate": 8.165216039788624e-06,
      "loss": 0.0927,
      "step": 4722
    },
    {
      "epoch": 0.36703450419645633,
      "grad_norm": 0.1958845555782318,
      "learning_rate": 8.16482747901772e-06,
      "loss": 0.0458,
      "step": 4723
    },
    {
      "epoch": 0.36711221635063723,
      "grad_norm": 0.10841378569602966,
      "learning_rate": 8.164438918246814e-06,
      "loss": 0.022,
      "step": 4724
    },
    {
      "epoch": 0.36718992850481813,
      "grad_norm": 0.030398624017834663,
      "learning_rate": 8.16405035747591e-06,
      "loss": 0.0069,
      "step": 4725
    },
    {
      "epoch": 0.3672676406589991,
      "grad_norm": 0.3964315354824066,
      "learning_rate": 8.163661796705005e-06,
      "loss": 0.4615,
      "step": 4726
    },
    {
      "epoch": 0.36734535281318,
      "grad_norm": 0.5343881249427795,
      "learning_rate": 8.1632732359341e-06,
      "loss": 0.2859,
      "step": 4727
    },
    {
      "epoch": 0.3674230649673609,
      "grad_norm": 0.16626685857772827,
      "learning_rate": 8.162884675163197e-06,
      "loss": 0.0439,
      "step": 4728
    },
    {
      "epoch": 0.36750077712154183,
      "grad_norm": 0.13997919857501984,
      "learning_rate": 8.162496114392292e-06,
      "loss": 0.0466,
      "step": 4729
    },
    {
      "epoch": 0.36757848927572273,
      "grad_norm": 0.28963494300842285,
      "learning_rate": 8.162107553621387e-06,
      "loss": 0.1554,
      "step": 4730
    },
    {
      "epoch": 0.36765620142990363,
      "grad_norm": 0.2046310156583786,
      "learning_rate": 8.161718992850483e-06,
      "loss": 0.3161,
      "step": 4731
    },
    {
      "epoch": 0.3677339135840845,
      "grad_norm": 0.48170238733291626,
      "learning_rate": 8.161330432079578e-06,
      "loss": 0.183,
      "step": 4732
    },
    {
      "epoch": 0.3678116257382655,
      "grad_norm": 0.18640545010566711,
      "learning_rate": 8.160941871308673e-06,
      "loss": 0.0834,
      "step": 4733
    },
    {
      "epoch": 0.3678893378924464,
      "grad_norm": 0.3029864430427551,
      "learning_rate": 8.160553310537768e-06,
      "loss": 0.0381,
      "step": 4734
    },
    {
      "epoch": 0.3679670500466273,
      "grad_norm": 0.10067799687385559,
      "learning_rate": 8.160164749766865e-06,
      "loss": 0.0439,
      "step": 4735
    },
    {
      "epoch": 0.36804476220080823,
      "grad_norm": 0.07852394878864288,
      "learning_rate": 8.15977618899596e-06,
      "loss": 0.0389,
      "step": 4736
    },
    {
      "epoch": 0.3681224743549891,
      "grad_norm": 0.24166469275951385,
      "learning_rate": 8.159387628225055e-06,
      "loss": 0.0626,
      "step": 4737
    },
    {
      "epoch": 0.36820018650917,
      "grad_norm": 0.27459394931793213,
      "learning_rate": 8.158999067454151e-06,
      "loss": 0.126,
      "step": 4738
    },
    {
      "epoch": 0.3682778986633509,
      "grad_norm": 0.2403727024793625,
      "learning_rate": 8.158610506683246e-06,
      "loss": 0.2075,
      "step": 4739
    },
    {
      "epoch": 0.3683556108175319,
      "grad_norm": 0.499863862991333,
      "learning_rate": 8.158221945912341e-06,
      "loss": 0.445,
      "step": 4740
    },
    {
      "epoch": 0.3684333229717128,
      "grad_norm": 0.3288167715072632,
      "learning_rate": 8.157833385141438e-06,
      "loss": 0.1873,
      "step": 4741
    },
    {
      "epoch": 0.36851103512589367,
      "grad_norm": 0.4468742907047272,
      "learning_rate": 8.157444824370531e-06,
      "loss": 0.0791,
      "step": 4742
    },
    {
      "epoch": 0.3685887472800746,
      "grad_norm": 0.6985996961593628,
      "learning_rate": 8.157056263599628e-06,
      "loss": 0.5685,
      "step": 4743
    },
    {
      "epoch": 0.3686664594342555,
      "grad_norm": 0.12121181935071945,
      "learning_rate": 8.156667702828723e-06,
      "loss": 0.0312,
      "step": 4744
    },
    {
      "epoch": 0.3687441715884364,
      "grad_norm": 0.1578715592622757,
      "learning_rate": 8.156279142057818e-06,
      "loss": 0.0662,
      "step": 4745
    },
    {
      "epoch": 0.3688218837426173,
      "grad_norm": 0.11100362241268158,
      "learning_rate": 8.155890581286914e-06,
      "loss": 0.0501,
      "step": 4746
    },
    {
      "epoch": 0.36889959589679827,
      "grad_norm": 0.1626601368188858,
      "learning_rate": 8.15550202051601e-06,
      "loss": 0.0599,
      "step": 4747
    },
    {
      "epoch": 0.36897730805097917,
      "grad_norm": 0.35843947529792786,
      "learning_rate": 8.155113459745104e-06,
      "loss": 0.2121,
      "step": 4748
    },
    {
      "epoch": 0.36905502020516007,
      "grad_norm": 0.12493031471967697,
      "learning_rate": 8.1547248989742e-06,
      "loss": 0.0413,
      "step": 4749
    },
    {
      "epoch": 0.369132732359341,
      "grad_norm": 0.21364104747772217,
      "learning_rate": 8.154336338203296e-06,
      "loss": 0.1157,
      "step": 4750
    },
    {
      "epoch": 0.3692104445135219,
      "grad_norm": 0.3041357100009918,
      "learning_rate": 8.15394777743239e-06,
      "loss": 0.1024,
      "step": 4751
    },
    {
      "epoch": 0.3692881566677028,
      "grad_norm": 0.16112591326236725,
      "learning_rate": 8.153559216661486e-06,
      "loss": 0.0329,
      "step": 4752
    },
    {
      "epoch": 0.36936586882188377,
      "grad_norm": 0.142837256193161,
      "learning_rate": 8.153170655890582e-06,
      "loss": 0.0975,
      "step": 4753
    },
    {
      "epoch": 0.36944358097606467,
      "grad_norm": 0.183870330452919,
      "learning_rate": 8.152782095119677e-06,
      "loss": 0.0428,
      "step": 4754
    },
    {
      "epoch": 0.36952129313024557,
      "grad_norm": 0.4659372866153717,
      "learning_rate": 8.152393534348772e-06,
      "loss": 0.0917,
      "step": 4755
    },
    {
      "epoch": 0.36959900528442646,
      "grad_norm": 0.03822647035121918,
      "learning_rate": 8.152004973577869e-06,
      "loss": 0.0103,
      "step": 4756
    },
    {
      "epoch": 0.3696767174386074,
      "grad_norm": 0.3603190779685974,
      "learning_rate": 8.151616412806964e-06,
      "loss": 0.153,
      "step": 4757
    },
    {
      "epoch": 0.3697544295927883,
      "grad_norm": 0.4211376905441284,
      "learning_rate": 8.151227852036059e-06,
      "loss": 0.2845,
      "step": 4758
    },
    {
      "epoch": 0.3698321417469692,
      "grad_norm": 0.8101918697357178,
      "learning_rate": 8.150839291265154e-06,
      "loss": 0.4612,
      "step": 4759
    },
    {
      "epoch": 0.36990985390115017,
      "grad_norm": 0.2354288101196289,
      "learning_rate": 8.15045073049425e-06,
      "loss": 0.2513,
      "step": 4760
    },
    {
      "epoch": 0.36998756605533106,
      "grad_norm": 1.3536980152130127,
      "learning_rate": 8.150062169723345e-06,
      "loss": 0.2781,
      "step": 4761
    },
    {
      "epoch": 0.37006527820951196,
      "grad_norm": 0.08099788427352905,
      "learning_rate": 8.14967360895244e-06,
      "loss": 0.0239,
      "step": 4762
    },
    {
      "epoch": 0.37014299036369286,
      "grad_norm": 0.30491089820861816,
      "learning_rate": 8.149285048181537e-06,
      "loss": 0.6022,
      "step": 4763
    },
    {
      "epoch": 0.3702207025178738,
      "grad_norm": 0.16774386167526245,
      "learning_rate": 8.148896487410632e-06,
      "loss": 0.1031,
      "step": 4764
    },
    {
      "epoch": 0.3702984146720547,
      "grad_norm": 0.47360527515411377,
      "learning_rate": 8.148507926639727e-06,
      "loss": 0.1149,
      "step": 4765
    },
    {
      "epoch": 0.3703761268262356,
      "grad_norm": 0.19873492419719696,
      "learning_rate": 8.148119365868824e-06,
      "loss": 0.0706,
      "step": 4766
    },
    {
      "epoch": 0.37045383898041656,
      "grad_norm": 0.37789517641067505,
      "learning_rate": 8.147730805097917e-06,
      "loss": 0.1067,
      "step": 4767
    },
    {
      "epoch": 0.37053155113459746,
      "grad_norm": 0.5655208826065063,
      "learning_rate": 8.147342244327013e-06,
      "loss": 0.1044,
      "step": 4768
    },
    {
      "epoch": 0.37060926328877836,
      "grad_norm": 0.4095967411994934,
      "learning_rate": 8.146953683556108e-06,
      "loss": 0.1642,
      "step": 4769
    },
    {
      "epoch": 0.37068697544295925,
      "grad_norm": 0.3386698067188263,
      "learning_rate": 8.146565122785203e-06,
      "loss": 0.1792,
      "step": 4770
    },
    {
      "epoch": 0.3707646875971402,
      "grad_norm": 0.18043498694896698,
      "learning_rate": 8.1461765620143e-06,
      "loss": 0.0516,
      "step": 4771
    },
    {
      "epoch": 0.3708423997513211,
      "grad_norm": 0.05575263872742653,
      "learning_rate": 8.145788001243395e-06,
      "loss": 0.0096,
      "step": 4772
    },
    {
      "epoch": 0.370920111905502,
      "grad_norm": 0.2894902229309082,
      "learning_rate": 8.14539944047249e-06,
      "loss": 0.0971,
      "step": 4773
    },
    {
      "epoch": 0.37099782405968296,
      "grad_norm": 0.7381629943847656,
      "learning_rate": 8.145010879701587e-06,
      "loss": 0.2453,
      "step": 4774
    },
    {
      "epoch": 0.37107553621386385,
      "grad_norm": 0.3350391089916229,
      "learning_rate": 8.144622318930681e-06,
      "loss": 0.138,
      "step": 4775
    },
    {
      "epoch": 0.37115324836804475,
      "grad_norm": 0.8378434181213379,
      "learning_rate": 8.144233758159776e-06,
      "loss": 0.208,
      "step": 4776
    },
    {
      "epoch": 0.37123096052222565,
      "grad_norm": 0.3865618109703064,
      "learning_rate": 8.143845197388871e-06,
      "loss": 0.0861,
      "step": 4777
    },
    {
      "epoch": 0.3713086726764066,
      "grad_norm": 0.09435176849365234,
      "learning_rate": 8.143456636617968e-06,
      "loss": 0.0558,
      "step": 4778
    },
    {
      "epoch": 0.3713863848305875,
      "grad_norm": 0.11299286782741547,
      "learning_rate": 8.143068075847063e-06,
      "loss": 0.0491,
      "step": 4779
    },
    {
      "epoch": 0.3714640969847684,
      "grad_norm": 0.09924747794866562,
      "learning_rate": 8.142679515076158e-06,
      "loss": 0.0357,
      "step": 4780
    },
    {
      "epoch": 0.37154180913894935,
      "grad_norm": 0.10834002494812012,
      "learning_rate": 8.142290954305255e-06,
      "loss": 0.0184,
      "step": 4781
    },
    {
      "epoch": 0.37161952129313025,
      "grad_norm": 0.2908678948879242,
      "learning_rate": 8.14190239353435e-06,
      "loss": 0.4545,
      "step": 4782
    },
    {
      "epoch": 0.37169723344731115,
      "grad_norm": 0.23428970575332642,
      "learning_rate": 8.141513832763444e-06,
      "loss": 0.1128,
      "step": 4783
    },
    {
      "epoch": 0.37177494560149205,
      "grad_norm": 0.11817502975463867,
      "learning_rate": 8.141125271992541e-06,
      "loss": 0.019,
      "step": 4784
    },
    {
      "epoch": 0.371852657755673,
      "grad_norm": 0.151650071144104,
      "learning_rate": 8.140736711221636e-06,
      "loss": 0.0186,
      "step": 4785
    },
    {
      "epoch": 0.3719303699098539,
      "grad_norm": 0.5440642237663269,
      "learning_rate": 8.140348150450731e-06,
      "loss": 0.1958,
      "step": 4786
    },
    {
      "epoch": 0.3720080820640348,
      "grad_norm": 0.19120264053344727,
      "learning_rate": 8.139959589679826e-06,
      "loss": 0.0412,
      "step": 4787
    },
    {
      "epoch": 0.37208579421821575,
      "grad_norm": 0.2510359585285187,
      "learning_rate": 8.139571028908923e-06,
      "loss": 0.0774,
      "step": 4788
    },
    {
      "epoch": 0.37216350637239665,
      "grad_norm": 1.2208582162857056,
      "learning_rate": 8.139182468138018e-06,
      "loss": 0.4353,
      "step": 4789
    },
    {
      "epoch": 0.37224121852657754,
      "grad_norm": 0.504235565662384,
      "learning_rate": 8.138793907367112e-06,
      "loss": 0.368,
      "step": 4790
    },
    {
      "epoch": 0.3723189306807585,
      "grad_norm": 0.42102545499801636,
      "learning_rate": 8.138405346596209e-06,
      "loss": 0.1831,
      "step": 4791
    },
    {
      "epoch": 0.3723966428349394,
      "grad_norm": 0.29221171140670776,
      "learning_rate": 8.138016785825304e-06,
      "loss": 0.2453,
      "step": 4792
    },
    {
      "epoch": 0.3724743549891203,
      "grad_norm": 0.3996557295322418,
      "learning_rate": 8.137628225054399e-06,
      "loss": 0.6245,
      "step": 4793
    },
    {
      "epoch": 0.3725520671433012,
      "grad_norm": 0.3379179537296295,
      "learning_rate": 8.137239664283496e-06,
      "loss": 0.206,
      "step": 4794
    },
    {
      "epoch": 0.37262977929748214,
      "grad_norm": 0.497027188539505,
      "learning_rate": 8.136851103512589e-06,
      "loss": 0.2531,
      "step": 4795
    },
    {
      "epoch": 0.37270749145166304,
      "grad_norm": 0.22441309690475464,
      "learning_rate": 8.136462542741686e-06,
      "loss": 0.0393,
      "step": 4796
    },
    {
      "epoch": 0.37278520360584394,
      "grad_norm": 0.21771977841854095,
      "learning_rate": 8.13607398197078e-06,
      "loss": 0.1356,
      "step": 4797
    },
    {
      "epoch": 0.3728629157600249,
      "grad_norm": 0.4019004702568054,
      "learning_rate": 8.135685421199875e-06,
      "loss": 0.1061,
      "step": 4798
    },
    {
      "epoch": 0.3729406279142058,
      "grad_norm": 0.15282732248306274,
      "learning_rate": 8.135296860428972e-06,
      "loss": 0.0652,
      "step": 4799
    },
    {
      "epoch": 0.3730183400683867,
      "grad_norm": 0.30144497752189636,
      "learning_rate": 8.134908299658067e-06,
      "loss": 0.1824,
      "step": 4800
    },
    {
      "epoch": 0.3730960522225676,
      "grad_norm": 0.47768595814704895,
      "learning_rate": 8.134519738887162e-06,
      "loss": 0.2198,
      "step": 4801
    },
    {
      "epoch": 0.37317376437674854,
      "grad_norm": 0.20181904733181,
      "learning_rate": 8.134131178116259e-06,
      "loss": 0.1027,
      "step": 4802
    },
    {
      "epoch": 0.37325147653092944,
      "grad_norm": 0.24713647365570068,
      "learning_rate": 8.133742617345354e-06,
      "loss": 0.0702,
      "step": 4803
    },
    {
      "epoch": 0.37332918868511034,
      "grad_norm": 0.4590666592121124,
      "learning_rate": 8.133354056574449e-06,
      "loss": 0.2239,
      "step": 4804
    },
    {
      "epoch": 0.3734069008392913,
      "grad_norm": 0.8134438991546631,
      "learning_rate": 8.132965495803544e-06,
      "loss": 0.5768,
      "step": 4805
    },
    {
      "epoch": 0.3734846129934722,
      "grad_norm": 0.30043473839759827,
      "learning_rate": 8.13257693503264e-06,
      "loss": 0.1549,
      "step": 4806
    },
    {
      "epoch": 0.3735623251476531,
      "grad_norm": 0.3923438489437103,
      "learning_rate": 8.132188374261735e-06,
      "loss": 0.1771,
      "step": 4807
    },
    {
      "epoch": 0.373640037301834,
      "grad_norm": 0.4925355911254883,
      "learning_rate": 8.13179981349083e-06,
      "loss": 0.1795,
      "step": 4808
    },
    {
      "epoch": 0.37371774945601494,
      "grad_norm": 0.2652586102485657,
      "learning_rate": 8.131411252719927e-06,
      "loss": 0.1203,
      "step": 4809
    },
    {
      "epoch": 0.37379546161019583,
      "grad_norm": 0.1842738837003708,
      "learning_rate": 8.131022691949022e-06,
      "loss": 0.0999,
      "step": 4810
    },
    {
      "epoch": 0.37387317376437673,
      "grad_norm": 0.4370998442173004,
      "learning_rate": 8.130634131178117e-06,
      "loss": 0.363,
      "step": 4811
    },
    {
      "epoch": 0.3739508859185577,
      "grad_norm": 0.324006050825119,
      "learning_rate": 8.130245570407213e-06,
      "loss": 0.1298,
      "step": 4812
    },
    {
      "epoch": 0.3740285980727386,
      "grad_norm": 0.2965884804725647,
      "learning_rate": 8.129857009636308e-06,
      "loss": 0.2227,
      "step": 4813
    },
    {
      "epoch": 0.3741063102269195,
      "grad_norm": 0.24633583426475525,
      "learning_rate": 8.129468448865403e-06,
      "loss": 0.0124,
      "step": 4814
    },
    {
      "epoch": 0.3741840223811004,
      "grad_norm": 0.28223416209220886,
      "learning_rate": 8.129079888094498e-06,
      "loss": 0.1969,
      "step": 4815
    },
    {
      "epoch": 0.37426173453528133,
      "grad_norm": 0.5815720558166504,
      "learning_rate": 8.128691327323595e-06,
      "loss": 0.2831,
      "step": 4816
    },
    {
      "epoch": 0.37433944668946223,
      "grad_norm": 0.6956375241279602,
      "learning_rate": 8.12830276655269e-06,
      "loss": 0.1666,
      "step": 4817
    },
    {
      "epoch": 0.3744171588436431,
      "grad_norm": 0.718520998954773,
      "learning_rate": 8.127914205781785e-06,
      "loss": 0.2345,
      "step": 4818
    },
    {
      "epoch": 0.3744948709978241,
      "grad_norm": 0.3549518585205078,
      "learning_rate": 8.127525645010881e-06,
      "loss": 0.2315,
      "step": 4819
    },
    {
      "epoch": 0.374572583152005,
      "grad_norm": 0.44720742106437683,
      "learning_rate": 8.127137084239976e-06,
      "loss": 0.0715,
      "step": 4820
    },
    {
      "epoch": 0.3746502953061859,
      "grad_norm": 0.326496958732605,
      "learning_rate": 8.126748523469071e-06,
      "loss": 0.4854,
      "step": 4821
    },
    {
      "epoch": 0.3747280074603668,
      "grad_norm": 0.3185969293117523,
      "learning_rate": 8.126359962698168e-06,
      "loss": 0.0431,
      "step": 4822
    },
    {
      "epoch": 0.3748057196145477,
      "grad_norm": 0.45420005917549133,
      "learning_rate": 8.125971401927261e-06,
      "loss": 0.1226,
      "step": 4823
    },
    {
      "epoch": 0.3748834317687286,
      "grad_norm": 0.3249237835407257,
      "learning_rate": 8.125582841156358e-06,
      "loss": 0.1535,
      "step": 4824
    },
    {
      "epoch": 0.3749611439229095,
      "grad_norm": 0.5288820266723633,
      "learning_rate": 8.125194280385453e-06,
      "loss": 0.1116,
      "step": 4825
    },
    {
      "epoch": 0.3750388560770905,
      "grad_norm": 0.3731250762939453,
      "learning_rate": 8.124805719614548e-06,
      "loss": 0.1378,
      "step": 4826
    },
    {
      "epoch": 0.3751165682312714,
      "grad_norm": 0.28931641578674316,
      "learning_rate": 8.124417158843644e-06,
      "loss": 0.1597,
      "step": 4827
    },
    {
      "epoch": 0.3751942803854523,
      "grad_norm": 0.3399127721786499,
      "learning_rate": 8.12402859807274e-06,
      "loss": 0.116,
      "step": 4828
    },
    {
      "epoch": 0.3752719925396332,
      "grad_norm": 0.09981109946966171,
      "learning_rate": 8.123640037301834e-06,
      "loss": 0.0323,
      "step": 4829
    },
    {
      "epoch": 0.3753497046938141,
      "grad_norm": 0.25447389483451843,
      "learning_rate": 8.12325147653093e-06,
      "loss": 0.0462,
      "step": 4830
    },
    {
      "epoch": 0.375427416847995,
      "grad_norm": 0.3015136122703552,
      "learning_rate": 8.122862915760026e-06,
      "loss": 0.1195,
      "step": 4831
    },
    {
      "epoch": 0.3755051290021759,
      "grad_norm": 0.3149011731147766,
      "learning_rate": 8.12247435498912e-06,
      "loss": 0.194,
      "step": 4832
    },
    {
      "epoch": 0.3755828411563569,
      "grad_norm": 0.2421233355998993,
      "learning_rate": 8.122085794218216e-06,
      "loss": 0.1745,
      "step": 4833
    },
    {
      "epoch": 0.37566055331053777,
      "grad_norm": 0.19536499679088593,
      "learning_rate": 8.121697233447312e-06,
      "loss": 0.0937,
      "step": 4834
    },
    {
      "epoch": 0.37573826546471867,
      "grad_norm": 0.5431289672851562,
      "learning_rate": 8.121308672676407e-06,
      "loss": 0.2416,
      "step": 4835
    },
    {
      "epoch": 0.3758159776188996,
      "grad_norm": 0.49961984157562256,
      "learning_rate": 8.120920111905502e-06,
      "loss": 0.0996,
      "step": 4836
    },
    {
      "epoch": 0.3758936897730805,
      "grad_norm": 0.3420919179916382,
      "learning_rate": 8.120531551134599e-06,
      "loss": 0.1536,
      "step": 4837
    },
    {
      "epoch": 0.3759714019272614,
      "grad_norm": 0.04663155600428581,
      "learning_rate": 8.120142990363694e-06,
      "loss": 0.0255,
      "step": 4838
    },
    {
      "epoch": 0.3760491140814423,
      "grad_norm": 0.36568206548690796,
      "learning_rate": 8.119754429592789e-06,
      "loss": 0.2446,
      "step": 4839
    },
    {
      "epoch": 0.37612682623562327,
      "grad_norm": 0.7571645975112915,
      "learning_rate": 8.119365868821885e-06,
      "loss": 0.1912,
      "step": 4840
    },
    {
      "epoch": 0.37620453838980417,
      "grad_norm": 0.0669693723320961,
      "learning_rate": 8.11897730805098e-06,
      "loss": 0.023,
      "step": 4841
    },
    {
      "epoch": 0.37628225054398506,
      "grad_norm": 0.31481844186782837,
      "learning_rate": 8.118588747280075e-06,
      "loss": 0.1549,
      "step": 4842
    },
    {
      "epoch": 0.376359962698166,
      "grad_norm": 0.6091675758361816,
      "learning_rate": 8.11820018650917e-06,
      "loss": 0.3621,
      "step": 4843
    },
    {
      "epoch": 0.3764376748523469,
      "grad_norm": 0.25201383233070374,
      "learning_rate": 8.117811625738267e-06,
      "loss": 0.1549,
      "step": 4844
    },
    {
      "epoch": 0.3765153870065278,
      "grad_norm": 2.747710704803467,
      "learning_rate": 8.117423064967362e-06,
      "loss": 0.4226,
      "step": 4845
    },
    {
      "epoch": 0.3765930991607087,
      "grad_norm": 0.5053659677505493,
      "learning_rate": 8.117034504196457e-06,
      "loss": 0.3359,
      "step": 4846
    },
    {
      "epoch": 0.37667081131488966,
      "grad_norm": 0.2450869381427765,
      "learning_rate": 8.116645943425553e-06,
      "loss": 0.0451,
      "step": 4847
    },
    {
      "epoch": 0.37674852346907056,
      "grad_norm": 0.425479531288147,
      "learning_rate": 8.116257382654648e-06,
      "loss": 0.3356,
      "step": 4848
    },
    {
      "epoch": 0.37682623562325146,
      "grad_norm": 0.18317143619060516,
      "learning_rate": 8.115868821883743e-06,
      "loss": 0.0586,
      "step": 4849
    },
    {
      "epoch": 0.3769039477774324,
      "grad_norm": 0.2101927399635315,
      "learning_rate": 8.11548026111284e-06,
      "loss": 0.0989,
      "step": 4850
    },
    {
      "epoch": 0.3769816599316133,
      "grad_norm": 0.3235171139240265,
      "learning_rate": 8.115091700341933e-06,
      "loss": 0.1262,
      "step": 4851
    },
    {
      "epoch": 0.3770593720857942,
      "grad_norm": 0.7328769564628601,
      "learning_rate": 8.11470313957103e-06,
      "loss": 0.4675,
      "step": 4852
    },
    {
      "epoch": 0.3771370842399751,
      "grad_norm": 0.37441685795783997,
      "learning_rate": 8.114314578800125e-06,
      "loss": 0.175,
      "step": 4853
    },
    {
      "epoch": 0.37721479639415606,
      "grad_norm": 0.26102903485298157,
      "learning_rate": 8.11392601802922e-06,
      "loss": 0.0576,
      "step": 4854
    },
    {
      "epoch": 0.37729250854833696,
      "grad_norm": 0.6892828345298767,
      "learning_rate": 8.113537457258316e-06,
      "loss": 0.2243,
      "step": 4855
    },
    {
      "epoch": 0.37737022070251786,
      "grad_norm": 0.24961698055267334,
      "learning_rate": 8.113148896487411e-06,
      "loss": 0.1079,
      "step": 4856
    },
    {
      "epoch": 0.3774479328566988,
      "grad_norm": 0.28672686219215393,
      "learning_rate": 8.112760335716506e-06,
      "loss": 0.6118,
      "step": 4857
    },
    {
      "epoch": 0.3775256450108797,
      "grad_norm": 0.1727517992258072,
      "learning_rate": 8.112371774945603e-06,
      "loss": 0.0568,
      "step": 4858
    },
    {
      "epoch": 0.3776033571650606,
      "grad_norm": 0.3595626652240753,
      "learning_rate": 8.111983214174698e-06,
      "loss": 0.1917,
      "step": 4859
    },
    {
      "epoch": 0.3776810693192415,
      "grad_norm": 0.5955677628517151,
      "learning_rate": 8.111594653403793e-06,
      "loss": 0.2729,
      "step": 4860
    },
    {
      "epoch": 0.37775878147342246,
      "grad_norm": 0.44793203473091125,
      "learning_rate": 8.111206092632888e-06,
      "loss": 0.4032,
      "step": 4861
    },
    {
      "epoch": 0.37783649362760335,
      "grad_norm": 0.368502140045166,
      "learning_rate": 8.110817531861984e-06,
      "loss": 0.3231,
      "step": 4862
    },
    {
      "epoch": 0.37791420578178425,
      "grad_norm": 0.749491810798645,
      "learning_rate": 8.11042897109108e-06,
      "loss": 0.1529,
      "step": 4863
    },
    {
      "epoch": 0.3779919179359652,
      "grad_norm": 0.33705517649650574,
      "learning_rate": 8.110040410320174e-06,
      "loss": 0.535,
      "step": 4864
    },
    {
      "epoch": 0.3780696300901461,
      "grad_norm": 0.3233799934387207,
      "learning_rate": 8.109651849549271e-06,
      "loss": 0.112,
      "step": 4865
    },
    {
      "epoch": 0.378147342244327,
      "grad_norm": 0.3021874725818634,
      "learning_rate": 8.109263288778366e-06,
      "loss": 0.2981,
      "step": 4866
    },
    {
      "epoch": 0.37822505439850795,
      "grad_norm": 0.2988370358943939,
      "learning_rate": 8.108874728007461e-06,
      "loss": 0.2465,
      "step": 4867
    },
    {
      "epoch": 0.37830276655268885,
      "grad_norm": 0.2001708298921585,
      "learning_rate": 8.108486167236558e-06,
      "loss": 0.0703,
      "step": 4868
    },
    {
      "epoch": 0.37838047870686975,
      "grad_norm": 0.34324851632118225,
      "learning_rate": 8.10809760646565e-06,
      "loss": 0.1787,
      "step": 4869
    },
    {
      "epoch": 0.37845819086105065,
      "grad_norm": 0.1202830821275711,
      "learning_rate": 8.107709045694747e-06,
      "loss": 0.0205,
      "step": 4870
    },
    {
      "epoch": 0.3785359030152316,
      "grad_norm": 0.2294386327266693,
      "learning_rate": 8.107320484923842e-06,
      "loss": 0.206,
      "step": 4871
    },
    {
      "epoch": 0.3786136151694125,
      "grad_norm": 0.16659125685691833,
      "learning_rate": 8.106931924152939e-06,
      "loss": 0.0374,
      "step": 4872
    },
    {
      "epoch": 0.3786913273235934,
      "grad_norm": 0.7863404154777527,
      "learning_rate": 8.106543363382034e-06,
      "loss": 0.3622,
      "step": 4873
    },
    {
      "epoch": 0.37876903947777435,
      "grad_norm": 0.5000191330909729,
      "learning_rate": 8.106154802611129e-06,
      "loss": 0.1722,
      "step": 4874
    },
    {
      "epoch": 0.37884675163195525,
      "grad_norm": 5.33585262298584,
      "learning_rate": 8.105766241840226e-06,
      "loss": 1.8072,
      "step": 4875
    },
    {
      "epoch": 0.37892446378613615,
      "grad_norm": 0.49372273683547974,
      "learning_rate": 8.105377681069319e-06,
      "loss": 0.2329,
      "step": 4876
    },
    {
      "epoch": 0.37900217594031704,
      "grad_norm": 0.06300342082977295,
      "learning_rate": 8.104989120298415e-06,
      "loss": 0.013,
      "step": 4877
    },
    {
      "epoch": 0.379079888094498,
      "grad_norm": 0.3744194805622101,
      "learning_rate": 8.10460055952751e-06,
      "loss": 0.2743,
      "step": 4878
    },
    {
      "epoch": 0.3791576002486789,
      "grad_norm": 0.6251475811004639,
      "learning_rate": 8.104211998756605e-06,
      "loss": 0.2876,
      "step": 4879
    },
    {
      "epoch": 0.3792353124028598,
      "grad_norm": 0.06418098509311676,
      "learning_rate": 8.103823437985702e-06,
      "loss": 0.0098,
      "step": 4880
    },
    {
      "epoch": 0.37931302455704075,
      "grad_norm": 0.4929006099700928,
      "learning_rate": 8.103434877214797e-06,
      "loss": 0.6017,
      "step": 4881
    },
    {
      "epoch": 0.37939073671122164,
      "grad_norm": 0.5855623483657837,
      "learning_rate": 8.103046316443892e-06,
      "loss": 0.1368,
      "step": 4882
    },
    {
      "epoch": 0.37946844886540254,
      "grad_norm": 0.21606580913066864,
      "learning_rate": 8.102657755672989e-06,
      "loss": 0.0804,
      "step": 4883
    },
    {
      "epoch": 0.37954616101958344,
      "grad_norm": 0.1258893609046936,
      "learning_rate": 8.102269194902083e-06,
      "loss": 0.0778,
      "step": 4884
    },
    {
      "epoch": 0.3796238731737644,
      "grad_norm": 0.1687341183423996,
      "learning_rate": 8.101880634131178e-06,
      "loss": 0.0175,
      "step": 4885
    },
    {
      "epoch": 0.3797015853279453,
      "grad_norm": 0.08578096330165863,
      "learning_rate": 8.101492073360273e-06,
      "loss": 0.0259,
      "step": 4886
    },
    {
      "epoch": 0.3797792974821262,
      "grad_norm": 0.10038263350725174,
      "learning_rate": 8.10110351258937e-06,
      "loss": 0.0326,
      "step": 4887
    },
    {
      "epoch": 0.37985700963630714,
      "grad_norm": 0.1727287322282791,
      "learning_rate": 8.100714951818465e-06,
      "loss": 0.142,
      "step": 4888
    },
    {
      "epoch": 0.37993472179048804,
      "grad_norm": 0.24715043604373932,
      "learning_rate": 8.10032639104756e-06,
      "loss": 0.0811,
      "step": 4889
    },
    {
      "epoch": 0.38001243394466894,
      "grad_norm": 0.28774482011795044,
      "learning_rate": 8.099937830276657e-06,
      "loss": 0.2433,
      "step": 4890
    },
    {
      "epoch": 0.38009014609884983,
      "grad_norm": 0.35815638303756714,
      "learning_rate": 8.099549269505752e-06,
      "loss": 0.1355,
      "step": 4891
    },
    {
      "epoch": 0.3801678582530308,
      "grad_norm": 0.22295087575912476,
      "learning_rate": 8.099160708734846e-06,
      "loss": 0.0746,
      "step": 4892
    },
    {
      "epoch": 0.3802455704072117,
      "grad_norm": 0.2080841064453125,
      "learning_rate": 8.098772147963943e-06,
      "loss": 0.0703,
      "step": 4893
    },
    {
      "epoch": 0.3803232825613926,
      "grad_norm": 0.009848182089626789,
      "learning_rate": 8.098383587193036e-06,
      "loss": 0.0008,
      "step": 4894
    },
    {
      "epoch": 0.38040099471557354,
      "grad_norm": 4.006491661071777,
      "learning_rate": 8.097995026422133e-06,
      "loss": 0.7367,
      "step": 4895
    },
    {
      "epoch": 0.38047870686975443,
      "grad_norm": 0.9143891930580139,
      "learning_rate": 8.097606465651228e-06,
      "loss": 0.2547,
      "step": 4896
    },
    {
      "epoch": 0.38055641902393533,
      "grad_norm": 0.3579655587673187,
      "learning_rate": 8.097217904880323e-06,
      "loss": 0.155,
      "step": 4897
    },
    {
      "epoch": 0.38063413117811623,
      "grad_norm": 0.21663837134838104,
      "learning_rate": 8.09682934410942e-06,
      "loss": 0.0296,
      "step": 4898
    },
    {
      "epoch": 0.3807118433322972,
      "grad_norm": 0.4664693772792816,
      "learning_rate": 8.096440783338515e-06,
      "loss": 0.1981,
      "step": 4899
    },
    {
      "epoch": 0.3807895554864781,
      "grad_norm": 0.08268257975578308,
      "learning_rate": 8.09605222256761e-06,
      "loss": 0.0511,
      "step": 4900
    },
    {
      "epoch": 0.380867267640659,
      "grad_norm": 0.2289280742406845,
      "learning_rate": 8.095663661796706e-06,
      "loss": 0.0952,
      "step": 4901
    },
    {
      "epoch": 0.38094497979483993,
      "grad_norm": 0.05463741719722748,
      "learning_rate": 8.095275101025801e-06,
      "loss": 0.0067,
      "step": 4902
    },
    {
      "epoch": 0.38102269194902083,
      "grad_norm": 0.37568607926368713,
      "learning_rate": 8.094886540254898e-06,
      "loss": 0.2691,
      "step": 4903
    },
    {
      "epoch": 0.38110040410320173,
      "grad_norm": 0.41605323553085327,
      "learning_rate": 8.094497979483991e-06,
      "loss": 0.3343,
      "step": 4904
    },
    {
      "epoch": 0.3811781162573827,
      "grad_norm": 0.27988937497138977,
      "learning_rate": 8.094109418713088e-06,
      "loss": 0.1238,
      "step": 4905
    },
    {
      "epoch": 0.3812558284115636,
      "grad_norm": 0.3429948389530182,
      "learning_rate": 8.093720857942183e-06,
      "loss": 0.2236,
      "step": 4906
    },
    {
      "epoch": 0.3813335405657445,
      "grad_norm": 0.4730164408683777,
      "learning_rate": 8.093332297171278e-06,
      "loss": 0.547,
      "step": 4907
    },
    {
      "epoch": 0.3814112527199254,
      "grad_norm": 0.2885899841785431,
      "learning_rate": 8.092943736400374e-06,
      "loss": 0.1874,
      "step": 4908
    },
    {
      "epoch": 0.38148896487410633,
      "grad_norm": 0.6134086847305298,
      "learning_rate": 8.092555175629469e-06,
      "loss": 0.1591,
      "step": 4909
    },
    {
      "epoch": 0.3815666770282872,
      "grad_norm": 0.33641064167022705,
      "learning_rate": 8.092166614858564e-06,
      "loss": 0.1791,
      "step": 4910
    },
    {
      "epoch": 0.3816443891824681,
      "grad_norm": 0.6207249164581299,
      "learning_rate": 8.09177805408766e-06,
      "loss": 0.53,
      "step": 4911
    },
    {
      "epoch": 0.3817221013366491,
      "grad_norm": 0.4002520442008972,
      "learning_rate": 8.091389493316756e-06,
      "loss": 0.1213,
      "step": 4912
    },
    {
      "epoch": 0.38179981349083,
      "grad_norm": 0.3204752504825592,
      "learning_rate": 8.09100093254585e-06,
      "loss": 0.197,
      "step": 4913
    },
    {
      "epoch": 0.3818775256450109,
      "grad_norm": 0.1835228055715561,
      "learning_rate": 8.090612371774946e-06,
      "loss": 0.1067,
      "step": 4914
    },
    {
      "epoch": 0.38195523779919177,
      "grad_norm": 0.5489489436149597,
      "learning_rate": 8.090223811004042e-06,
      "loss": 0.2648,
      "step": 4915
    },
    {
      "epoch": 0.3820329499533727,
      "grad_norm": 0.8196207880973816,
      "learning_rate": 8.089835250233137e-06,
      "loss": 0.248,
      "step": 4916
    },
    {
      "epoch": 0.3821106621075536,
      "grad_norm": 0.3964884877204895,
      "learning_rate": 8.089446689462232e-06,
      "loss": 0.2165,
      "step": 4917
    },
    {
      "epoch": 0.3821883742617345,
      "grad_norm": 0.35241350531578064,
      "learning_rate": 8.089058128691329e-06,
      "loss": 0.2635,
      "step": 4918
    },
    {
      "epoch": 0.3822660864159155,
      "grad_norm": 1.3829667568206787,
      "learning_rate": 8.088669567920424e-06,
      "loss": 0.2477,
      "step": 4919
    },
    {
      "epoch": 0.38234379857009637,
      "grad_norm": 0.6320708394050598,
      "learning_rate": 8.088281007149519e-06,
      "loss": 0.2981,
      "step": 4920
    },
    {
      "epoch": 0.38242151072427727,
      "grad_norm": 0.4167127311229706,
      "learning_rate": 8.087892446378615e-06,
      "loss": 0.4271,
      "step": 4921
    },
    {
      "epoch": 0.38249922287845817,
      "grad_norm": 1.0003200769424438,
      "learning_rate": 8.087503885607709e-06,
      "loss": 1.15,
      "step": 4922
    },
    {
      "epoch": 0.3825769350326391,
      "grad_norm": 0.3147754371166229,
      "learning_rate": 8.087115324836805e-06,
      "loss": 0.1827,
      "step": 4923
    },
    {
      "epoch": 0.38265464718682,
      "grad_norm": 0.5164177417755127,
      "learning_rate": 8.0867267640659e-06,
      "loss": 0.1329,
      "step": 4924
    },
    {
      "epoch": 0.3827323593410009,
      "grad_norm": 0.30741769075393677,
      "learning_rate": 8.086338203294995e-06,
      "loss": 0.1258,
      "step": 4925
    },
    {
      "epoch": 0.38281007149518187,
      "grad_norm": 0.31636983156204224,
      "learning_rate": 8.085949642524092e-06,
      "loss": 0.1065,
      "step": 4926
    },
    {
      "epoch": 0.38288778364936277,
      "grad_norm": 0.24570995569229126,
      "learning_rate": 8.085561081753187e-06,
      "loss": 0.0824,
      "step": 4927
    },
    {
      "epoch": 0.38296549580354367,
      "grad_norm": 0.6166520118713379,
      "learning_rate": 8.085172520982282e-06,
      "loss": 0.1099,
      "step": 4928
    },
    {
      "epoch": 0.38304320795772456,
      "grad_norm": 0.16103187203407288,
      "learning_rate": 8.084783960211378e-06,
      "loss": 0.1046,
      "step": 4929
    },
    {
      "epoch": 0.3831209201119055,
      "grad_norm": 0.24080075323581696,
      "learning_rate": 8.084395399440473e-06,
      "loss": 0.0277,
      "step": 4930
    },
    {
      "epoch": 0.3831986322660864,
      "grad_norm": 0.484082967042923,
      "learning_rate": 8.084006838669568e-06,
      "loss": 0.1706,
      "step": 4931
    },
    {
      "epoch": 0.3832763444202673,
      "grad_norm": 0.3855322301387787,
      "learning_rate": 8.083618277898663e-06,
      "loss": 0.1757,
      "step": 4932
    },
    {
      "epoch": 0.38335405657444827,
      "grad_norm": 0.4868912398815155,
      "learning_rate": 8.08322971712776e-06,
      "loss": 0.3054,
      "step": 4933
    },
    {
      "epoch": 0.38343176872862916,
      "grad_norm": 0.5563400387763977,
      "learning_rate": 8.082841156356855e-06,
      "loss": 0.4696,
      "step": 4934
    },
    {
      "epoch": 0.38350948088281006,
      "grad_norm": 0.6286424398422241,
      "learning_rate": 8.08245259558595e-06,
      "loss": 0.3769,
      "step": 4935
    },
    {
      "epoch": 0.38358719303699096,
      "grad_norm": 0.20773713290691376,
      "learning_rate": 8.082064034815046e-06,
      "loss": 0.0948,
      "step": 4936
    },
    {
      "epoch": 0.3836649051911719,
      "grad_norm": 0.5310293436050415,
      "learning_rate": 8.081675474044141e-06,
      "loss": 0.2272,
      "step": 4937
    },
    {
      "epoch": 0.3837426173453528,
      "grad_norm": 0.09866724908351898,
      "learning_rate": 8.081286913273236e-06,
      "loss": 0.05,
      "step": 4938
    },
    {
      "epoch": 0.3838203294995337,
      "grad_norm": 2.5633721351623535,
      "learning_rate": 8.080898352502333e-06,
      "loss": 0.7476,
      "step": 4939
    },
    {
      "epoch": 0.38389804165371466,
      "grad_norm": 0.3456264138221741,
      "learning_rate": 8.080509791731428e-06,
      "loss": 0.1734,
      "step": 4940
    },
    {
      "epoch": 0.38397575380789556,
      "grad_norm": 0.7467876672744751,
      "learning_rate": 8.080121230960523e-06,
      "loss": 0.3485,
      "step": 4941
    },
    {
      "epoch": 0.38405346596207646,
      "grad_norm": 0.44560006260871887,
      "learning_rate": 8.079732670189618e-06,
      "loss": 0.1643,
      "step": 4942
    },
    {
      "epoch": 0.3841311781162574,
      "grad_norm": 0.17560020089149475,
      "learning_rate": 8.079344109418714e-06,
      "loss": 0.0683,
      "step": 4943
    },
    {
      "epoch": 0.3842088902704383,
      "grad_norm": 0.47273704409599304,
      "learning_rate": 8.07895554864781e-06,
      "loss": 0.3954,
      "step": 4944
    },
    {
      "epoch": 0.3842866024246192,
      "grad_norm": 0.3160091042518616,
      "learning_rate": 8.078566987876904e-06,
      "loss": 0.1566,
      "step": 4945
    },
    {
      "epoch": 0.3843643145788001,
      "grad_norm": 0.025302516296505928,
      "learning_rate": 8.078178427106001e-06,
      "loss": 0.0016,
      "step": 4946
    },
    {
      "epoch": 0.38444202673298106,
      "grad_norm": 0.15624213218688965,
      "learning_rate": 8.077789866335096e-06,
      "loss": 0.0304,
      "step": 4947
    },
    {
      "epoch": 0.38451973888716195,
      "grad_norm": 0.8258417844772339,
      "learning_rate": 8.07740130556419e-06,
      "loss": 0.5008,
      "step": 4948
    },
    {
      "epoch": 0.38459745104134285,
      "grad_norm": 0.46752235293388367,
      "learning_rate": 8.077012744793287e-06,
      "loss": 0.6151,
      "step": 4949
    },
    {
      "epoch": 0.3846751631955238,
      "grad_norm": 1.2246776819229126,
      "learning_rate": 8.07662418402238e-06,
      "loss": 0.1134,
      "step": 4950
    },
    {
      "epoch": 0.3847528753497047,
      "grad_norm": 0.18828707933425903,
      "learning_rate": 8.076235623251477e-06,
      "loss": 0.0889,
      "step": 4951
    },
    {
      "epoch": 0.3848305875038856,
      "grad_norm": 0.12897071242332458,
      "learning_rate": 8.075847062480572e-06,
      "loss": 0.013,
      "step": 4952
    },
    {
      "epoch": 0.3849082996580665,
      "grad_norm": 0.522928774356842,
      "learning_rate": 8.075458501709667e-06,
      "loss": 0.4213,
      "step": 4953
    },
    {
      "epoch": 0.38498601181224745,
      "grad_norm": 0.2877126932144165,
      "learning_rate": 8.075069940938764e-06,
      "loss": 0.3462,
      "step": 4954
    },
    {
      "epoch": 0.38506372396642835,
      "grad_norm": 0.39826861023902893,
      "learning_rate": 8.074681380167859e-06,
      "loss": 0.3937,
      "step": 4955
    },
    {
      "epoch": 0.38514143612060925,
      "grad_norm": 0.7427448630332947,
      "learning_rate": 8.074292819396954e-06,
      "loss": 0.2893,
      "step": 4956
    },
    {
      "epoch": 0.3852191482747902,
      "grad_norm": 0.3522871732711792,
      "learning_rate": 8.07390425862605e-06,
      "loss": 0.0794,
      "step": 4957
    },
    {
      "epoch": 0.3852968604289711,
      "grad_norm": 0.38466504216194153,
      "learning_rate": 8.073515697855145e-06,
      "loss": 0.1043,
      "step": 4958
    },
    {
      "epoch": 0.385374572583152,
      "grad_norm": 0.5319218635559082,
      "learning_rate": 8.07312713708424e-06,
      "loss": 0.3372,
      "step": 4959
    },
    {
      "epoch": 0.3854522847373329,
      "grad_norm": 0.24022984504699707,
      "learning_rate": 8.072738576313335e-06,
      "loss": 0.0929,
      "step": 4960
    },
    {
      "epoch": 0.38552999689151385,
      "grad_norm": 0.060726191848516464,
      "learning_rate": 8.072350015542432e-06,
      "loss": 0.0159,
      "step": 4961
    },
    {
      "epoch": 0.38560770904569475,
      "grad_norm": 0.20040149986743927,
      "learning_rate": 8.071961454771527e-06,
      "loss": 0.1478,
      "step": 4962
    },
    {
      "epoch": 0.38568542119987564,
      "grad_norm": 0.45756664872169495,
      "learning_rate": 8.071572894000622e-06,
      "loss": 0.0765,
      "step": 4963
    },
    {
      "epoch": 0.3857631333540566,
      "grad_norm": 0.1097729355096817,
      "learning_rate": 8.071184333229718e-06,
      "loss": 0.0373,
      "step": 4964
    },
    {
      "epoch": 0.3858408455082375,
      "grad_norm": 0.1542736142873764,
      "learning_rate": 8.070795772458813e-06,
      "loss": 0.0365,
      "step": 4965
    },
    {
      "epoch": 0.3859185576624184,
      "grad_norm": 0.14097237586975098,
      "learning_rate": 8.070407211687908e-06,
      "loss": 0.0265,
      "step": 4966
    },
    {
      "epoch": 0.3859962698165993,
      "grad_norm": 0.23794792592525482,
      "learning_rate": 8.070018650917005e-06,
      "loss": 0.1113,
      "step": 4967
    },
    {
      "epoch": 0.38607398197078024,
      "grad_norm": 1.7629445791244507,
      "learning_rate": 8.0696300901461e-06,
      "loss": 0.6358,
      "step": 4968
    },
    {
      "epoch": 0.38615169412496114,
      "grad_norm": 0.36800503730773926,
      "learning_rate": 8.069241529375195e-06,
      "loss": 0.2247,
      "step": 4969
    },
    {
      "epoch": 0.38622940627914204,
      "grad_norm": 0.25960904359817505,
      "learning_rate": 8.06885296860429e-06,
      "loss": 0.0767,
      "step": 4970
    },
    {
      "epoch": 0.386307118433323,
      "grad_norm": 0.11199575662612915,
      "learning_rate": 8.068464407833386e-06,
      "loss": 0.0256,
      "step": 4971
    },
    {
      "epoch": 0.3863848305875039,
      "grad_norm": 0.5286092758178711,
      "learning_rate": 8.068075847062481e-06,
      "loss": 0.1613,
      "step": 4972
    },
    {
      "epoch": 0.3864625427416848,
      "grad_norm": 0.24306125938892365,
      "learning_rate": 8.067687286291576e-06,
      "loss": 0.0978,
      "step": 4973
    },
    {
      "epoch": 0.3865402548958657,
      "grad_norm": 0.13175630569458008,
      "learning_rate": 8.067298725520673e-06,
      "loss": 0.0202,
      "step": 4974
    },
    {
      "epoch": 0.38661796705004664,
      "grad_norm": 0.4697842299938202,
      "learning_rate": 8.066910164749768e-06,
      "loss": 0.1622,
      "step": 4975
    },
    {
      "epoch": 0.38669567920422754,
      "grad_norm": 0.29951801896095276,
      "learning_rate": 8.066521603978863e-06,
      "loss": 0.4021,
      "step": 4976
    },
    {
      "epoch": 0.38677339135840844,
      "grad_norm": 1.4872114658355713,
      "learning_rate": 8.06613304320796e-06,
      "loss": 0.0793,
      "step": 4977
    },
    {
      "epoch": 0.3868511035125894,
      "grad_norm": 0.31089746952056885,
      "learning_rate": 8.065744482437053e-06,
      "loss": 0.1326,
      "step": 4978
    },
    {
      "epoch": 0.3869288156667703,
      "grad_norm": 0.08933384716510773,
      "learning_rate": 8.06535592166615e-06,
      "loss": 0.0344,
      "step": 4979
    },
    {
      "epoch": 0.3870065278209512,
      "grad_norm": 1.2321107387542725,
      "learning_rate": 8.064967360895244e-06,
      "loss": 0.296,
      "step": 4980
    },
    {
      "epoch": 0.38708423997513214,
      "grad_norm": 0.34267458319664,
      "learning_rate": 8.06457880012434e-06,
      "loss": 0.0748,
      "step": 4981
    },
    {
      "epoch": 0.38716195212931304,
      "grad_norm": 0.16195553541183472,
      "learning_rate": 8.064190239353436e-06,
      "loss": 0.0374,
      "step": 4982
    },
    {
      "epoch": 0.38723966428349393,
      "grad_norm": 0.19519822299480438,
      "learning_rate": 8.063801678582531e-06,
      "loss": 0.1348,
      "step": 4983
    },
    {
      "epoch": 0.38731737643767483,
      "grad_norm": 0.5442309379577637,
      "learning_rate": 8.063413117811626e-06,
      "loss": 0.1686,
      "step": 4984
    },
    {
      "epoch": 0.3873950885918558,
      "grad_norm": 0.19614173471927643,
      "learning_rate": 8.063024557040723e-06,
      "loss": 0.0704,
      "step": 4985
    },
    {
      "epoch": 0.3874728007460367,
      "grad_norm": 0.5094757080078125,
      "learning_rate": 8.062635996269818e-06,
      "loss": 0.342,
      "step": 4986
    },
    {
      "epoch": 0.3875505129002176,
      "grad_norm": 0.6048939824104309,
      "learning_rate": 8.062247435498912e-06,
      "loss": 0.1844,
      "step": 4987
    },
    {
      "epoch": 0.38762822505439853,
      "grad_norm": 0.13999971747398376,
      "learning_rate": 8.061858874728007e-06,
      "loss": 0.0161,
      "step": 4988
    },
    {
      "epoch": 0.38770593720857943,
      "grad_norm": 0.714468240737915,
      "learning_rate": 8.061470313957104e-06,
      "loss": 0.2265,
      "step": 4989
    },
    {
      "epoch": 0.38778364936276033,
      "grad_norm": 0.3657175898551941,
      "learning_rate": 8.061081753186199e-06,
      "loss": 0.4231,
      "step": 4990
    },
    {
      "epoch": 0.3878613615169412,
      "grad_norm": 0.12126962840557098,
      "learning_rate": 8.060693192415294e-06,
      "loss": 0.0547,
      "step": 4991
    },
    {
      "epoch": 0.3879390736711222,
      "grad_norm": 0.5264377593994141,
      "learning_rate": 8.06030463164439e-06,
      "loss": 0.1851,
      "step": 4992
    },
    {
      "epoch": 0.3880167858253031,
      "grad_norm": 0.6928036212921143,
      "learning_rate": 8.059916070873486e-06,
      "loss": 0.2854,
      "step": 4993
    },
    {
      "epoch": 0.388094497979484,
      "grad_norm": 0.16571268439292908,
      "learning_rate": 8.05952751010258e-06,
      "loss": 0.1071,
      "step": 4994
    },
    {
      "epoch": 0.38817221013366493,
      "grad_norm": 0.8454629778862,
      "learning_rate": 8.059138949331677e-06,
      "loss": 0.5612,
      "step": 4995
    },
    {
      "epoch": 0.38824992228784583,
      "grad_norm": 0.3309096395969391,
      "learning_rate": 8.058750388560772e-06,
      "loss": 0.2061,
      "step": 4996
    },
    {
      "epoch": 0.3883276344420267,
      "grad_norm": 0.4334586262702942,
      "learning_rate": 8.058361827789867e-06,
      "loss": 0.0824,
      "step": 4997
    },
    {
      "epoch": 0.3884053465962076,
      "grad_norm": 0.20132222771644592,
      "learning_rate": 8.057973267018962e-06,
      "loss": 0.0676,
      "step": 4998
    },
    {
      "epoch": 0.3884830587503886,
      "grad_norm": 0.47972381114959717,
      "learning_rate": 8.057584706248059e-06,
      "loss": 0.425,
      "step": 4999
    },
    {
      "epoch": 0.3885607709045695,
      "grad_norm": 0.15006309747695923,
      "learning_rate": 8.057196145477154e-06,
      "loss": 0.0272,
      "step": 5000
    },
    {
      "epoch": 0.3886384830587504,
      "grad_norm": 0.1342613697052002,
      "learning_rate": 8.056807584706249e-06,
      "loss": 0.0734,
      "step": 5001
    },
    {
      "epoch": 0.3887161952129313,
      "grad_norm": 0.7591637969017029,
      "learning_rate": 8.056419023935345e-06,
      "loss": 0.4752,
      "step": 5002
    },
    {
      "epoch": 0.3887939073671122,
      "grad_norm": 0.42975324392318726,
      "learning_rate": 8.056030463164438e-06,
      "loss": 0.1114,
      "step": 5003
    },
    {
      "epoch": 0.3888716195212931,
      "grad_norm": 0.26440101861953735,
      "learning_rate": 8.055641902393535e-06,
      "loss": 0.1852,
      "step": 5004
    },
    {
      "epoch": 0.388949331675474,
      "grad_norm": 0.7417724132537842,
      "learning_rate": 8.05525334162263e-06,
      "loss": 0.1892,
      "step": 5005
    },
    {
      "epoch": 0.389027043829655,
      "grad_norm": 0.7380980849266052,
      "learning_rate": 8.054864780851725e-06,
      "loss": 0.2067,
      "step": 5006
    },
    {
      "epoch": 0.38910475598383587,
      "grad_norm": 0.46729937195777893,
      "learning_rate": 8.054476220080822e-06,
      "loss": 0.1925,
      "step": 5007
    },
    {
      "epoch": 0.38918246813801677,
      "grad_norm": 0.16947077214717865,
      "learning_rate": 8.054087659309917e-06,
      "loss": 0.0527,
      "step": 5008
    },
    {
      "epoch": 0.3892601802921977,
      "grad_norm": 0.06720717251300812,
      "learning_rate": 8.053699098539012e-06,
      "loss": 0.0203,
      "step": 5009
    },
    {
      "epoch": 0.3893378924463786,
      "grad_norm": 0.7060096263885498,
      "learning_rate": 8.053310537768108e-06,
      "loss": 0.1878,
      "step": 5010
    },
    {
      "epoch": 0.3894156046005595,
      "grad_norm": 0.04064007103443146,
      "learning_rate": 8.052921976997203e-06,
      "loss": 0.0066,
      "step": 5011
    },
    {
      "epoch": 0.3894933167547404,
      "grad_norm": 0.4016024172306061,
      "learning_rate": 8.052533416226298e-06,
      "loss": 0.2238,
      "step": 5012
    },
    {
      "epoch": 0.38957102890892137,
      "grad_norm": 0.4898904860019684,
      "learning_rate": 8.052144855455393e-06,
      "loss": 0.2816,
      "step": 5013
    },
    {
      "epoch": 0.38964874106310227,
      "grad_norm": 0.19621555507183075,
      "learning_rate": 8.05175629468449e-06,
      "loss": 0.0541,
      "step": 5014
    },
    {
      "epoch": 0.38972645321728316,
      "grad_norm": 0.20996412634849548,
      "learning_rate": 8.051367733913585e-06,
      "loss": 0.0504,
      "step": 5015
    },
    {
      "epoch": 0.3898041653714641,
      "grad_norm": 0.5083997249603271,
      "learning_rate": 8.05097917314268e-06,
      "loss": 0.2085,
      "step": 5016
    },
    {
      "epoch": 0.389881877525645,
      "grad_norm": 0.31883078813552856,
      "learning_rate": 8.050590612371776e-06,
      "loss": 0.5907,
      "step": 5017
    },
    {
      "epoch": 0.3899595896798259,
      "grad_norm": 0.322751522064209,
      "learning_rate": 8.050202051600871e-06,
      "loss": 0.0793,
      "step": 5018
    },
    {
      "epoch": 0.3900373018340068,
      "grad_norm": 0.5569324493408203,
      "learning_rate": 8.049813490829966e-06,
      "loss": 0.1218,
      "step": 5019
    },
    {
      "epoch": 0.39011501398818776,
      "grad_norm": 0.12613436579704285,
      "learning_rate": 8.049424930059063e-06,
      "loss": 0.0271,
      "step": 5020
    },
    {
      "epoch": 0.39019272614236866,
      "grad_norm": 0.2025073617696762,
      "learning_rate": 8.049036369288156e-06,
      "loss": 0.1432,
      "step": 5021
    },
    {
      "epoch": 0.39027043829654956,
      "grad_norm": 0.2055363953113556,
      "learning_rate": 8.048647808517253e-06,
      "loss": 0.1901,
      "step": 5022
    },
    {
      "epoch": 0.3903481504507305,
      "grad_norm": 0.18547621369361877,
      "learning_rate": 8.048259247746348e-06,
      "loss": 0.0825,
      "step": 5023
    },
    {
      "epoch": 0.3904258626049114,
      "grad_norm": 0.30423983931541443,
      "learning_rate": 8.047870686975444e-06,
      "loss": 0.0847,
      "step": 5024
    },
    {
      "epoch": 0.3905035747590923,
      "grad_norm": 0.19318024814128876,
      "learning_rate": 8.04748212620454e-06,
      "loss": 0.0689,
      "step": 5025
    },
    {
      "epoch": 0.39058128691327326,
      "grad_norm": 0.3206501007080078,
      "learning_rate": 8.047093565433634e-06,
      "loss": 0.2736,
      "step": 5026
    },
    {
      "epoch": 0.39065899906745416,
      "grad_norm": 0.2140347957611084,
      "learning_rate": 8.04670500466273e-06,
      "loss": 0.0723,
      "step": 5027
    },
    {
      "epoch": 0.39073671122163506,
      "grad_norm": 0.16962899267673492,
      "learning_rate": 8.046316443891826e-06,
      "loss": 0.0272,
      "step": 5028
    },
    {
      "epoch": 0.39081442337581596,
      "grad_norm": 0.5556616187095642,
      "learning_rate": 8.04592788312092e-06,
      "loss": 0.2828,
      "step": 5029
    },
    {
      "epoch": 0.3908921355299969,
      "grad_norm": 0.15149183571338654,
      "learning_rate": 8.045539322350017e-06,
      "loss": 0.0464,
      "step": 5030
    },
    {
      "epoch": 0.3909698476841778,
      "grad_norm": 0.44700777530670166,
      "learning_rate": 8.04515076157911e-06,
      "loss": 0.4456,
      "step": 5031
    },
    {
      "epoch": 0.3910475598383587,
      "grad_norm": 0.30298203229904175,
      "learning_rate": 8.044762200808207e-06,
      "loss": 0.0915,
      "step": 5032
    },
    {
      "epoch": 0.39112527199253966,
      "grad_norm": 0.07290896028280258,
      "learning_rate": 8.044373640037302e-06,
      "loss": 0.0295,
      "step": 5033
    },
    {
      "epoch": 0.39120298414672056,
      "grad_norm": 0.48763370513916016,
      "learning_rate": 8.043985079266397e-06,
      "loss": 0.3198,
      "step": 5034
    },
    {
      "epoch": 0.39128069630090145,
      "grad_norm": 0.21617336571216583,
      "learning_rate": 8.043596518495494e-06,
      "loss": 0.0823,
      "step": 5035
    },
    {
      "epoch": 0.39135840845508235,
      "grad_norm": 0.3173614740371704,
      "learning_rate": 8.043207957724589e-06,
      "loss": 0.0948,
      "step": 5036
    },
    {
      "epoch": 0.3914361206092633,
      "grad_norm": 0.07843277603387833,
      "learning_rate": 8.042819396953684e-06,
      "loss": 0.0305,
      "step": 5037
    },
    {
      "epoch": 0.3915138327634442,
      "grad_norm": 0.5197681188583374,
      "learning_rate": 8.04243083618278e-06,
      "loss": 0.3363,
      "step": 5038
    },
    {
      "epoch": 0.3915915449176251,
      "grad_norm": 0.4489583373069763,
      "learning_rate": 8.042042275411875e-06,
      "loss": 0.2048,
      "step": 5039
    },
    {
      "epoch": 0.39166925707180605,
      "grad_norm": 0.22000004351139069,
      "learning_rate": 8.04165371464097e-06,
      "loss": 0.2019,
      "step": 5040
    },
    {
      "epoch": 0.39174696922598695,
      "grad_norm": 0.5735598802566528,
      "learning_rate": 8.041265153870065e-06,
      "loss": 0.491,
      "step": 5041
    },
    {
      "epoch": 0.39182468138016785,
      "grad_norm": 0.8131895065307617,
      "learning_rate": 8.040876593099162e-06,
      "loss": 0.4936,
      "step": 5042
    },
    {
      "epoch": 0.39190239353434875,
      "grad_norm": 0.02824573777616024,
      "learning_rate": 8.040488032328257e-06,
      "loss": 0.0104,
      "step": 5043
    },
    {
      "epoch": 0.3919801056885297,
      "grad_norm": 0.27394118905067444,
      "learning_rate": 8.040099471557352e-06,
      "loss": 0.193,
      "step": 5044
    },
    {
      "epoch": 0.3920578178427106,
      "grad_norm": 0.7331512570381165,
      "learning_rate": 8.039710910786448e-06,
      "loss": 0.4806,
      "step": 5045
    },
    {
      "epoch": 0.3921355299968915,
      "grad_norm": 0.448341965675354,
      "learning_rate": 8.039322350015543e-06,
      "loss": 0.1621,
      "step": 5046
    },
    {
      "epoch": 0.39221324215107245,
      "grad_norm": 0.3694121837615967,
      "learning_rate": 8.038933789244638e-06,
      "loss": 0.1514,
      "step": 5047
    },
    {
      "epoch": 0.39229095430525335,
      "grad_norm": 0.18366429209709167,
      "learning_rate": 8.038545228473735e-06,
      "loss": 0.0594,
      "step": 5048
    },
    {
      "epoch": 0.39236866645943425,
      "grad_norm": 0.7537749409675598,
      "learning_rate": 8.038156667702828e-06,
      "loss": 0.3319,
      "step": 5049
    },
    {
      "epoch": 0.39244637861361514,
      "grad_norm": 0.21954388916492462,
      "learning_rate": 8.037768106931925e-06,
      "loss": 0.1138,
      "step": 5050
    },
    {
      "epoch": 0.3925240907677961,
      "grad_norm": 0.4798330068588257,
      "learning_rate": 8.03737954616102e-06,
      "loss": 0.2819,
      "step": 5051
    },
    {
      "epoch": 0.392601802921977,
      "grad_norm": 0.24431471526622772,
      "learning_rate": 8.036990985390115e-06,
      "loss": 0.1316,
      "step": 5052
    },
    {
      "epoch": 0.3926795150761579,
      "grad_norm": 0.4402111768722534,
      "learning_rate": 8.036602424619211e-06,
      "loss": 0.3319,
      "step": 5053
    },
    {
      "epoch": 0.39275722723033885,
      "grad_norm": 0.2184937596321106,
      "learning_rate": 8.036213863848306e-06,
      "loss": 0.096,
      "step": 5054
    },
    {
      "epoch": 0.39283493938451974,
      "grad_norm": 0.4252791404724121,
      "learning_rate": 8.035825303077403e-06,
      "loss": 0.2404,
      "step": 5055
    },
    {
      "epoch": 0.39291265153870064,
      "grad_norm": 0.2604978084564209,
      "learning_rate": 8.035436742306498e-06,
      "loss": 0.0427,
      "step": 5056
    },
    {
      "epoch": 0.39299036369288154,
      "grad_norm": 0.21882036328315735,
      "learning_rate": 8.035048181535593e-06,
      "loss": 0.1054,
      "step": 5057
    },
    {
      "epoch": 0.3930680758470625,
      "grad_norm": 0.38075149059295654,
      "learning_rate": 8.03465962076469e-06,
      "loss": 0.4202,
      "step": 5058
    },
    {
      "epoch": 0.3931457880012434,
      "grad_norm": 0.3170256018638611,
      "learning_rate": 8.034271059993783e-06,
      "loss": 0.2719,
      "step": 5059
    },
    {
      "epoch": 0.3932235001554243,
      "grad_norm": 0.3479918837547302,
      "learning_rate": 8.03388249922288e-06,
      "loss": 0.0833,
      "step": 5060
    },
    {
      "epoch": 0.39330121230960524,
      "grad_norm": 1.1159290075302124,
      "learning_rate": 8.033493938451974e-06,
      "loss": 2.1418,
      "step": 5061
    },
    {
      "epoch": 0.39337892446378614,
      "grad_norm": 0.2446621060371399,
      "learning_rate": 8.03310537768107e-06,
      "loss": 0.133,
      "step": 5062
    },
    {
      "epoch": 0.39345663661796704,
      "grad_norm": 0.08185569196939468,
      "learning_rate": 8.032716816910166e-06,
      "loss": 0.0267,
      "step": 5063
    },
    {
      "epoch": 0.393534348772148,
      "grad_norm": 0.10620236396789551,
      "learning_rate": 8.032328256139261e-06,
      "loss": 0.0722,
      "step": 5064
    },
    {
      "epoch": 0.3936120609263289,
      "grad_norm": 0.1267055869102478,
      "learning_rate": 8.031939695368356e-06,
      "loss": 0.0511,
      "step": 5065
    },
    {
      "epoch": 0.3936897730805098,
      "grad_norm": 0.3274766802787781,
      "learning_rate": 8.031551134597452e-06,
      "loss": 0.621,
      "step": 5066
    },
    {
      "epoch": 0.3937674852346907,
      "grad_norm": 0.2542060613632202,
      "learning_rate": 8.031162573826547e-06,
      "loss": 0.1016,
      "step": 5067
    },
    {
      "epoch": 0.39384519738887164,
      "grad_norm": 0.25532928109169006,
      "learning_rate": 8.030774013055642e-06,
      "loss": 0.0969,
      "step": 5068
    },
    {
      "epoch": 0.39392290954305254,
      "grad_norm": 0.265011727809906,
      "learning_rate": 8.030385452284737e-06,
      "loss": 0.0333,
      "step": 5069
    },
    {
      "epoch": 0.39400062169723343,
      "grad_norm": 0.27226707339286804,
      "learning_rate": 8.029996891513834e-06,
      "loss": 0.1743,
      "step": 5070
    },
    {
      "epoch": 0.3940783338514144,
      "grad_norm": 0.29629871249198914,
      "learning_rate": 8.029608330742929e-06,
      "loss": 0.0897,
      "step": 5071
    },
    {
      "epoch": 0.3941560460055953,
      "grad_norm": 0.46613770723342896,
      "learning_rate": 8.029219769972024e-06,
      "loss": 0.1486,
      "step": 5072
    },
    {
      "epoch": 0.3942337581597762,
      "grad_norm": 0.4989273250102997,
      "learning_rate": 8.02883120920112e-06,
      "loss": 0.3375,
      "step": 5073
    },
    {
      "epoch": 0.3943114703139571,
      "grad_norm": 0.195639967918396,
      "learning_rate": 8.028442648430215e-06,
      "loss": 0.0921,
      "step": 5074
    },
    {
      "epoch": 0.39438918246813803,
      "grad_norm": 0.14595310389995575,
      "learning_rate": 8.02805408765931e-06,
      "loss": 0.0372,
      "step": 5075
    },
    {
      "epoch": 0.39446689462231893,
      "grad_norm": 0.5998244285583496,
      "learning_rate": 8.027665526888407e-06,
      "loss": 0.4119,
      "step": 5076
    },
    {
      "epoch": 0.39454460677649983,
      "grad_norm": 0.09109426289796829,
      "learning_rate": 8.0272769661175e-06,
      "loss": 0.0135,
      "step": 5077
    },
    {
      "epoch": 0.3946223189306808,
      "grad_norm": 0.23563840985298157,
      "learning_rate": 8.026888405346597e-06,
      "loss": 0.2241,
      "step": 5078
    },
    {
      "epoch": 0.3947000310848617,
      "grad_norm": 0.2828775644302368,
      "learning_rate": 8.026499844575692e-06,
      "loss": 0.0359,
      "step": 5079
    },
    {
      "epoch": 0.3947777432390426,
      "grad_norm": 0.33044561743736267,
      "learning_rate": 8.026111283804787e-06,
      "loss": 0.1072,
      "step": 5080
    },
    {
      "epoch": 0.3948554553932235,
      "grad_norm": 0.49189597368240356,
      "learning_rate": 8.025722723033883e-06,
      "loss": 0.6299,
      "step": 5081
    },
    {
      "epoch": 0.39493316754740443,
      "grad_norm": 0.21647998690605164,
      "learning_rate": 8.025334162262978e-06,
      "loss": 0.0336,
      "step": 5082
    },
    {
      "epoch": 0.3950108797015853,
      "grad_norm": 0.47144851088523865,
      "learning_rate": 8.024945601492073e-06,
      "loss": 0.1783,
      "step": 5083
    },
    {
      "epoch": 0.3950885918557662,
      "grad_norm": 0.13743028044700623,
      "learning_rate": 8.02455704072117e-06,
      "loss": 0.0574,
      "step": 5084
    },
    {
      "epoch": 0.3951663040099472,
      "grad_norm": 0.7567151188850403,
      "learning_rate": 8.024168479950265e-06,
      "loss": 0.3496,
      "step": 5085
    },
    {
      "epoch": 0.3952440161641281,
      "grad_norm": 0.12328118085861206,
      "learning_rate": 8.023779919179362e-06,
      "loss": 0.0874,
      "step": 5086
    },
    {
      "epoch": 0.395321728318309,
      "grad_norm": 0.6244256496429443,
      "learning_rate": 8.023391358408455e-06,
      "loss": 0.2667,
      "step": 5087
    },
    {
      "epoch": 0.39539944047248987,
      "grad_norm": 0.5082359313964844,
      "learning_rate": 8.023002797637552e-06,
      "loss": 0.8227,
      "step": 5088
    },
    {
      "epoch": 0.3954771526266708,
      "grad_norm": 0.16025981307029724,
      "learning_rate": 8.022614236866646e-06,
      "loss": 0.0246,
      "step": 5089
    },
    {
      "epoch": 0.3955548647808517,
      "grad_norm": 0.14052709937095642,
      "learning_rate": 8.022225676095741e-06,
      "loss": 0.0359,
      "step": 5090
    },
    {
      "epoch": 0.3956325769350326,
      "grad_norm": 0.9367546439170837,
      "learning_rate": 8.021837115324838e-06,
      "loss": 0.2007,
      "step": 5091
    },
    {
      "epoch": 0.3957102890892136,
      "grad_norm": 0.3142347037792206,
      "learning_rate": 8.021448554553933e-06,
      "loss": 0.2151,
      "step": 5092
    },
    {
      "epoch": 0.39578800124339447,
      "grad_norm": 0.19126111268997192,
      "learning_rate": 8.021059993783028e-06,
      "loss": 0.0924,
      "step": 5093
    },
    {
      "epoch": 0.39586571339757537,
      "grad_norm": 0.3001691997051239,
      "learning_rate": 8.020671433012125e-06,
      "loss": 0.1675,
      "step": 5094
    },
    {
      "epoch": 0.39594342555175627,
      "grad_norm": 0.5893726944923401,
      "learning_rate": 8.02028287224122e-06,
      "loss": 0.3284,
      "step": 5095
    },
    {
      "epoch": 0.3960211377059372,
      "grad_norm": 0.5431085824966431,
      "learning_rate": 8.019894311470314e-06,
      "loss": 0.2339,
      "step": 5096
    },
    {
      "epoch": 0.3960988498601181,
      "grad_norm": 0.15248586237430573,
      "learning_rate": 8.01950575069941e-06,
      "loss": 0.0404,
      "step": 5097
    },
    {
      "epoch": 0.396176562014299,
      "grad_norm": 0.44839417934417725,
      "learning_rate": 8.019117189928506e-06,
      "loss": 0.2503,
      "step": 5098
    },
    {
      "epoch": 0.39625427416847997,
      "grad_norm": 0.318972647190094,
      "learning_rate": 8.018728629157601e-06,
      "loss": 0.0925,
      "step": 5099
    },
    {
      "epoch": 0.39633198632266087,
      "grad_norm": 0.18405216932296753,
      "learning_rate": 8.018340068386696e-06,
      "loss": 0.051,
      "step": 5100
    },
    {
      "epoch": 0.39640969847684177,
      "grad_norm": 0.7572065591812134,
      "learning_rate": 8.017951507615793e-06,
      "loss": 0.3934,
      "step": 5101
    },
    {
      "epoch": 0.3964874106310227,
      "grad_norm": 0.2124631255865097,
      "learning_rate": 8.017562946844888e-06,
      "loss": 0.1092,
      "step": 5102
    },
    {
      "epoch": 0.3965651227852036,
      "grad_norm": 0.45716118812561035,
      "learning_rate": 8.017174386073983e-06,
      "loss": 0.2908,
      "step": 5103
    },
    {
      "epoch": 0.3966428349393845,
      "grad_norm": 0.6317610144615173,
      "learning_rate": 8.01678582530308e-06,
      "loss": 0.2301,
      "step": 5104
    },
    {
      "epoch": 0.3967205470935654,
      "grad_norm": 1.0005815029144287,
      "learning_rate": 8.016397264532172e-06,
      "loss": 0.6511,
      "step": 5105
    },
    {
      "epoch": 0.39679825924774637,
      "grad_norm": 0.3738531768321991,
      "learning_rate": 8.016008703761269e-06,
      "loss": 0.2376,
      "step": 5106
    },
    {
      "epoch": 0.39687597140192726,
      "grad_norm": 0.14267100393772125,
      "learning_rate": 8.015620142990364e-06,
      "loss": 0.0742,
      "step": 5107
    },
    {
      "epoch": 0.39695368355610816,
      "grad_norm": 0.4469051957130432,
      "learning_rate": 8.015231582219459e-06,
      "loss": 0.1747,
      "step": 5108
    },
    {
      "epoch": 0.3970313957102891,
      "grad_norm": 0.904731273651123,
      "learning_rate": 8.014843021448556e-06,
      "loss": 0.9008,
      "step": 5109
    },
    {
      "epoch": 0.39710910786447,
      "grad_norm": 0.08716368675231934,
      "learning_rate": 8.01445446067765e-06,
      "loss": 0.034,
      "step": 5110
    },
    {
      "epoch": 0.3971868200186509,
      "grad_norm": 0.2747105360031128,
      "learning_rate": 8.014065899906746e-06,
      "loss": 0.1428,
      "step": 5111
    },
    {
      "epoch": 0.3972645321728318,
      "grad_norm": 0.40884825587272644,
      "learning_rate": 8.013677339135842e-06,
      "loss": 0.1536,
      "step": 5112
    },
    {
      "epoch": 0.39734224432701276,
      "grad_norm": 0.11472778022289276,
      "learning_rate": 8.013288778364937e-06,
      "loss": 0.0253,
      "step": 5113
    },
    {
      "epoch": 0.39741995648119366,
      "grad_norm": 0.40151679515838623,
      "learning_rate": 8.012900217594034e-06,
      "loss": 0.3575,
      "step": 5114
    },
    {
      "epoch": 0.39749766863537456,
      "grad_norm": 0.19100604951381683,
      "learning_rate": 8.012511656823127e-06,
      "loss": 0.0508,
      "step": 5115
    },
    {
      "epoch": 0.3975753807895555,
      "grad_norm": 0.7000388503074646,
      "learning_rate": 8.012123096052224e-06,
      "loss": 0.2572,
      "step": 5116
    },
    {
      "epoch": 0.3976530929437364,
      "grad_norm": 0.43671998381614685,
      "learning_rate": 8.011734535281319e-06,
      "loss": 0.2999,
      "step": 5117
    },
    {
      "epoch": 0.3977308050979173,
      "grad_norm": 0.5019144415855408,
      "learning_rate": 8.011345974510414e-06,
      "loss": 0.3492,
      "step": 5118
    },
    {
      "epoch": 0.3978085172520982,
      "grad_norm": 0.258166640996933,
      "learning_rate": 8.01095741373951e-06,
      "loss": 0.1614,
      "step": 5119
    },
    {
      "epoch": 0.39788622940627916,
      "grad_norm": 0.4711824655532837,
      "learning_rate": 8.010568852968605e-06,
      "loss": 0.2114,
      "step": 5120
    },
    {
      "epoch": 0.39796394156046005,
      "grad_norm": 0.22852596640586853,
      "learning_rate": 8.0101802921977e-06,
      "loss": 0.1453,
      "step": 5121
    },
    {
      "epoch": 0.39804165371464095,
      "grad_norm": 0.2006232589483261,
      "learning_rate": 8.009791731426795e-06,
      "loss": 0.1036,
      "step": 5122
    },
    {
      "epoch": 0.3981193658688219,
      "grad_norm": 0.40970438718795776,
      "learning_rate": 8.009403170655892e-06,
      "loss": 0.2541,
      "step": 5123
    },
    {
      "epoch": 0.3981970780230028,
      "grad_norm": 0.3182395398616791,
      "learning_rate": 8.009014609884987e-06,
      "loss": 0.1136,
      "step": 5124
    },
    {
      "epoch": 0.3982747901771837,
      "grad_norm": 0.546913743019104,
      "learning_rate": 8.008626049114082e-06,
      "loss": 0.3419,
      "step": 5125
    },
    {
      "epoch": 0.3983525023313646,
      "grad_norm": 0.42441704869270325,
      "learning_rate": 8.008237488343178e-06,
      "loss": 0.4868,
      "step": 5126
    },
    {
      "epoch": 0.39843021448554555,
      "grad_norm": 0.7532647848129272,
      "learning_rate": 8.007848927572273e-06,
      "loss": 0.271,
      "step": 5127
    },
    {
      "epoch": 0.39850792663972645,
      "grad_norm": 0.26715999841690063,
      "learning_rate": 8.007460366801368e-06,
      "loss": 0.0703,
      "step": 5128
    },
    {
      "epoch": 0.39858563879390735,
      "grad_norm": 0.2268437296152115,
      "learning_rate": 8.007071806030465e-06,
      "loss": 0.0257,
      "step": 5129
    },
    {
      "epoch": 0.3986633509480883,
      "grad_norm": 0.16309182345867157,
      "learning_rate": 8.006683245259558e-06,
      "loss": 0.117,
      "step": 5130
    },
    {
      "epoch": 0.3987410631022692,
      "grad_norm": 0.4764980375766754,
      "learning_rate": 8.006294684488655e-06,
      "loss": 0.2509,
      "step": 5131
    },
    {
      "epoch": 0.3988187752564501,
      "grad_norm": 0.19925422966480255,
      "learning_rate": 8.00590612371775e-06,
      "loss": 0.0235,
      "step": 5132
    },
    {
      "epoch": 0.398896487410631,
      "grad_norm": 0.702034056186676,
      "learning_rate": 8.005517562946845e-06,
      "loss": 0.6347,
      "step": 5133
    },
    {
      "epoch": 0.39897419956481195,
      "grad_norm": 0.2092008888721466,
      "learning_rate": 8.005129002175941e-06,
      "loss": 0.0774,
      "step": 5134
    },
    {
      "epoch": 0.39905191171899285,
      "grad_norm": 0.3036535382270813,
      "learning_rate": 8.004740441405036e-06,
      "loss": 0.0418,
      "step": 5135
    },
    {
      "epoch": 0.39912962387317374,
      "grad_norm": 0.3545704185962677,
      "learning_rate": 8.004351880634131e-06,
      "loss": 0.2831,
      "step": 5136
    },
    {
      "epoch": 0.3992073360273547,
      "grad_norm": 0.3652098774909973,
      "learning_rate": 8.003963319863228e-06,
      "loss": 0.193,
      "step": 5137
    },
    {
      "epoch": 0.3992850481815356,
      "grad_norm": 0.24554020166397095,
      "learning_rate": 8.003574759092323e-06,
      "loss": 0.2215,
      "step": 5138
    },
    {
      "epoch": 0.3993627603357165,
      "grad_norm": 0.5147998332977295,
      "learning_rate": 8.003186198321418e-06,
      "loss": 0.2985,
      "step": 5139
    },
    {
      "epoch": 0.39944047248989745,
      "grad_norm": 0.16410040855407715,
      "learning_rate": 8.002797637550513e-06,
      "loss": 0.1025,
      "step": 5140
    },
    {
      "epoch": 0.39951818464407834,
      "grad_norm": 0.20686785876750946,
      "learning_rate": 8.00240907677961e-06,
      "loss": 0.0815,
      "step": 5141
    },
    {
      "epoch": 0.39959589679825924,
      "grad_norm": 0.28435400128364563,
      "learning_rate": 8.002020516008704e-06,
      "loss": 0.3749,
      "step": 5142
    },
    {
      "epoch": 0.39967360895244014,
      "grad_norm": 0.4638686776161194,
      "learning_rate": 8.0016319552378e-06,
      "loss": 0.1219,
      "step": 5143
    },
    {
      "epoch": 0.3997513211066211,
      "grad_norm": 0.19252683222293854,
      "learning_rate": 8.001243394466896e-06,
      "loss": 0.0515,
      "step": 5144
    },
    {
      "epoch": 0.399829033260802,
      "grad_norm": 0.3162948489189148,
      "learning_rate": 8.00085483369599e-06,
      "loss": 0.2087,
      "step": 5145
    },
    {
      "epoch": 0.3999067454149829,
      "grad_norm": 0.1740408092737198,
      "learning_rate": 8.000466272925086e-06,
      "loss": 0.0697,
      "step": 5146
    },
    {
      "epoch": 0.39998445756916384,
      "grad_norm": 0.48739150166511536,
      "learning_rate": 8.000077712154182e-06,
      "loss": 0.3727,
      "step": 5147
    },
    {
      "epoch": 0.40006216972334474,
      "grad_norm": 1.1450613737106323,
      "learning_rate": 7.999689151383277e-06,
      "loss": 0.5006,
      "step": 5148
    },
    {
      "epoch": 0.40013988187752564,
      "grad_norm": 0.061556097120046616,
      "learning_rate": 7.999300590612372e-06,
      "loss": 0.0485,
      "step": 5149
    },
    {
      "epoch": 0.40021759403170654,
      "grad_norm": 0.07641719281673431,
      "learning_rate": 7.998912029841467e-06,
      "loss": 0.0276,
      "step": 5150
    },
    {
      "epoch": 0.4002953061858875,
      "grad_norm": 0.5461304783821106,
      "learning_rate": 7.998523469070564e-06,
      "loss": 0.5164,
      "step": 5151
    },
    {
      "epoch": 0.4003730183400684,
      "grad_norm": 0.21054859459400177,
      "learning_rate": 7.998134908299659e-06,
      "loss": 0.0997,
      "step": 5152
    },
    {
      "epoch": 0.4004507304942493,
      "grad_norm": 0.24876071512699127,
      "learning_rate": 7.997746347528754e-06,
      "loss": 0.1448,
      "step": 5153
    },
    {
      "epoch": 0.40052844264843024,
      "grad_norm": 0.2609604597091675,
      "learning_rate": 7.99735778675785e-06,
      "loss": 0.154,
      "step": 5154
    },
    {
      "epoch": 0.40060615480261114,
      "grad_norm": 0.45766156911849976,
      "learning_rate": 7.996969225986945e-06,
      "loss": 0.2457,
      "step": 5155
    },
    {
      "epoch": 0.40068386695679203,
      "grad_norm": 1.7465660572052002,
      "learning_rate": 7.99658066521604e-06,
      "loss": 0.3957,
      "step": 5156
    },
    {
      "epoch": 0.40076157911097293,
      "grad_norm": 0.10163912922143936,
      "learning_rate": 7.996192104445137e-06,
      "loss": 0.0184,
      "step": 5157
    },
    {
      "epoch": 0.4008392912651539,
      "grad_norm": 0.22896310687065125,
      "learning_rate": 7.99580354367423e-06,
      "loss": 0.1064,
      "step": 5158
    },
    {
      "epoch": 0.4009170034193348,
      "grad_norm": 0.33360886573791504,
      "learning_rate": 7.995414982903327e-06,
      "loss": 0.1275,
      "step": 5159
    },
    {
      "epoch": 0.4009947155735157,
      "grad_norm": 0.3740141689777374,
      "learning_rate": 7.995026422132422e-06,
      "loss": 0.2596,
      "step": 5160
    },
    {
      "epoch": 0.40107242772769663,
      "grad_norm": 0.3418865203857422,
      "learning_rate": 7.994637861361517e-06,
      "loss": 0.1656,
      "step": 5161
    },
    {
      "epoch": 0.40115013988187753,
      "grad_norm": 0.30733826756477356,
      "learning_rate": 7.994249300590613e-06,
      "loss": 0.1578,
      "step": 5162
    },
    {
      "epoch": 0.40122785203605843,
      "grad_norm": 0.36315980553627014,
      "learning_rate": 7.993860739819708e-06,
      "loss": 0.1724,
      "step": 5163
    },
    {
      "epoch": 0.40130556419023933,
      "grad_norm": 0.3637665808200836,
      "learning_rate": 7.993472179048803e-06,
      "loss": 0.1231,
      "step": 5164
    },
    {
      "epoch": 0.4013832763444203,
      "grad_norm": 0.38628366589546204,
      "learning_rate": 7.9930836182779e-06,
      "loss": 0.2937,
      "step": 5165
    },
    {
      "epoch": 0.4014609884986012,
      "grad_norm": 0.3241387605667114,
      "learning_rate": 7.992695057506995e-06,
      "loss": 0.1409,
      "step": 5166
    },
    {
      "epoch": 0.4015387006527821,
      "grad_norm": 0.43944892287254333,
      "learning_rate": 7.99230649673609e-06,
      "loss": 0.1453,
      "step": 5167
    },
    {
      "epoch": 0.40161641280696303,
      "grad_norm": 0.5340015292167664,
      "learning_rate": 7.991917935965185e-06,
      "loss": 0.1554,
      "step": 5168
    },
    {
      "epoch": 0.40169412496114393,
      "grad_norm": 0.24807174503803253,
      "learning_rate": 7.991529375194281e-06,
      "loss": 0.1775,
      "step": 5169
    },
    {
      "epoch": 0.4017718371153248,
      "grad_norm": 0.20678606629371643,
      "learning_rate": 7.991140814423376e-06,
      "loss": 0.1516,
      "step": 5170
    },
    {
      "epoch": 0.4018495492695057,
      "grad_norm": 0.30535051226615906,
      "learning_rate": 7.990752253652471e-06,
      "loss": 0.2247,
      "step": 5171
    },
    {
      "epoch": 0.4019272614236867,
      "grad_norm": 0.6663866639137268,
      "learning_rate": 7.990363692881568e-06,
      "loss": 0.4995,
      "step": 5172
    },
    {
      "epoch": 0.4020049735778676,
      "grad_norm": 0.3808789551258087,
      "learning_rate": 7.989975132110663e-06,
      "loss": 0.2448,
      "step": 5173
    },
    {
      "epoch": 0.4020826857320485,
      "grad_norm": 0.11045187711715698,
      "learning_rate": 7.989586571339758e-06,
      "loss": 0.0572,
      "step": 5174
    },
    {
      "epoch": 0.4021603978862294,
      "grad_norm": 0.8884294033050537,
      "learning_rate": 7.989198010568854e-06,
      "loss": 0.3576,
      "step": 5175
    },
    {
      "epoch": 0.4022381100404103,
      "grad_norm": 0.7000548243522644,
      "learning_rate": 7.98880944979795e-06,
      "loss": 0.1945,
      "step": 5176
    },
    {
      "epoch": 0.4023158221945912,
      "grad_norm": 0.2873108983039856,
      "learning_rate": 7.988420889027044e-06,
      "loss": 0.1405,
      "step": 5177
    },
    {
      "epoch": 0.4023935343487722,
      "grad_norm": 0.3660067617893219,
      "learning_rate": 7.98803232825614e-06,
      "loss": 0.0837,
      "step": 5178
    },
    {
      "epoch": 0.4024712465029531,
      "grad_norm": 0.48462527990341187,
      "learning_rate": 7.987643767485236e-06,
      "loss": 0.1501,
      "step": 5179
    },
    {
      "epoch": 0.40254895865713397,
      "grad_norm": 0.30580711364746094,
      "learning_rate": 7.987255206714331e-06,
      "loss": 0.1221,
      "step": 5180
    },
    {
      "epoch": 0.40262667081131487,
      "grad_norm": 0.29892057180404663,
      "learning_rate": 7.986866645943426e-06,
      "loss": 0.1204,
      "step": 5181
    },
    {
      "epoch": 0.4027043829654958,
      "grad_norm": 0.38175755739212036,
      "learning_rate": 7.986478085172523e-06,
      "loss": 0.2061,
      "step": 5182
    },
    {
      "epoch": 0.4027820951196767,
      "grad_norm": 0.8226561546325684,
      "learning_rate": 7.986089524401617e-06,
      "loss": 0.4083,
      "step": 5183
    },
    {
      "epoch": 0.4028598072738576,
      "grad_norm": 0.3031638264656067,
      "learning_rate": 7.985700963630712e-06,
      "loss": 0.0642,
      "step": 5184
    },
    {
      "epoch": 0.40293751942803857,
      "grad_norm": 0.4583997428417206,
      "learning_rate": 7.985312402859809e-06,
      "loss": 0.1414,
      "step": 5185
    },
    {
      "epoch": 0.40301523158221947,
      "grad_norm": 0.1638047844171524,
      "learning_rate": 7.984923842088902e-06,
      "loss": 0.0206,
      "step": 5186
    },
    {
      "epoch": 0.40309294373640037,
      "grad_norm": 0.4674546420574188,
      "learning_rate": 7.984535281317999e-06,
      "loss": 0.1353,
      "step": 5187
    },
    {
      "epoch": 0.40317065589058126,
      "grad_norm": 0.7517274022102356,
      "learning_rate": 7.984146720547094e-06,
      "loss": 0.2564,
      "step": 5188
    },
    {
      "epoch": 0.4032483680447622,
      "grad_norm": 0.5611795783042908,
      "learning_rate": 7.983758159776189e-06,
      "loss": 0.5954,
      "step": 5189
    },
    {
      "epoch": 0.4033260801989431,
      "grad_norm": 0.10462887585163116,
      "learning_rate": 7.983369599005286e-06,
      "loss": 0.0339,
      "step": 5190
    },
    {
      "epoch": 0.403403792353124,
      "grad_norm": 0.7404597997665405,
      "learning_rate": 7.98298103823438e-06,
      "loss": 0.4475,
      "step": 5191
    },
    {
      "epoch": 0.40348150450730497,
      "grad_norm": 0.16841773688793182,
      "learning_rate": 7.982592477463475e-06,
      "loss": 0.037,
      "step": 5192
    },
    {
      "epoch": 0.40355921666148586,
      "grad_norm": 0.42995530366897583,
      "learning_rate": 7.982203916692572e-06,
      "loss": 0.1024,
      "step": 5193
    },
    {
      "epoch": 0.40363692881566676,
      "grad_norm": 0.3192594051361084,
      "learning_rate": 7.981815355921667e-06,
      "loss": 0.2842,
      "step": 5194
    },
    {
      "epoch": 0.40371464096984766,
      "grad_norm": 0.32541412115097046,
      "learning_rate": 7.981426795150762e-06,
      "loss": 0.2586,
      "step": 5195
    },
    {
      "epoch": 0.4037923531240286,
      "grad_norm": 0.24013766646385193,
      "learning_rate": 7.981038234379857e-06,
      "loss": 0.0862,
      "step": 5196
    },
    {
      "epoch": 0.4038700652782095,
      "grad_norm": 0.22725807130336761,
      "learning_rate": 7.980649673608954e-06,
      "loss": 0.2836,
      "step": 5197
    },
    {
      "epoch": 0.4039477774323904,
      "grad_norm": 0.14985619485378265,
      "learning_rate": 7.980261112838048e-06,
      "loss": 0.0812,
      "step": 5198
    },
    {
      "epoch": 0.40402548958657136,
      "grad_norm": 0.09233850985765457,
      "learning_rate": 7.979872552067143e-06,
      "loss": 0.0832,
      "step": 5199
    },
    {
      "epoch": 0.40410320174075226,
      "grad_norm": 0.037170037627220154,
      "learning_rate": 7.97948399129624e-06,
      "loss": 0.0104,
      "step": 5200
    },
    {
      "epoch": 0.40418091389493316,
      "grad_norm": 0.1679864376783371,
      "learning_rate": 7.979095430525335e-06,
      "loss": 0.0602,
      "step": 5201
    },
    {
      "epoch": 0.40425862604911406,
      "grad_norm": 0.18515081703662872,
      "learning_rate": 7.97870686975443e-06,
      "loss": 0.0484,
      "step": 5202
    },
    {
      "epoch": 0.404336338203295,
      "grad_norm": 0.17820249497890472,
      "learning_rate": 7.978318308983527e-06,
      "loss": 0.0952,
      "step": 5203
    },
    {
      "epoch": 0.4044140503574759,
      "grad_norm": 0.5211523771286011,
      "learning_rate": 7.97792974821262e-06,
      "loss": 0.4061,
      "step": 5204
    },
    {
      "epoch": 0.4044917625116568,
      "grad_norm": 0.347307026386261,
      "learning_rate": 7.977541187441717e-06,
      "loss": 0.1883,
      "step": 5205
    },
    {
      "epoch": 0.40456947466583776,
      "grad_norm": 0.4667050540447235,
      "learning_rate": 7.977152626670811e-06,
      "loss": 0.6569,
      "step": 5206
    },
    {
      "epoch": 0.40464718682001866,
      "grad_norm": 0.34169960021972656,
      "learning_rate": 7.976764065899908e-06,
      "loss": 0.1349,
      "step": 5207
    },
    {
      "epoch": 0.40472489897419955,
      "grad_norm": 0.17992913722991943,
      "learning_rate": 7.976375505129003e-06,
      "loss": 0.1121,
      "step": 5208
    },
    {
      "epoch": 0.40480261112838045,
      "grad_norm": 0.1834665834903717,
      "learning_rate": 7.975986944358098e-06,
      "loss": 0.0825,
      "step": 5209
    },
    {
      "epoch": 0.4048803232825614,
      "grad_norm": 0.6814107298851013,
      "learning_rate": 7.975598383587195e-06,
      "loss": 0.1861,
      "step": 5210
    },
    {
      "epoch": 0.4049580354367423,
      "grad_norm": 0.4617449641227722,
      "learning_rate": 7.97520982281629e-06,
      "loss": 0.2207,
      "step": 5211
    },
    {
      "epoch": 0.4050357475909232,
      "grad_norm": 0.39913424849510193,
      "learning_rate": 7.974821262045385e-06,
      "loss": 0.193,
      "step": 5212
    },
    {
      "epoch": 0.40511345974510415,
      "grad_norm": 0.1146881952881813,
      "learning_rate": 7.974432701274481e-06,
      "loss": 0.0327,
      "step": 5213
    },
    {
      "epoch": 0.40519117189928505,
      "grad_norm": 0.4274952709674835,
      "learning_rate": 7.974044140503574e-06,
      "loss": 0.3345,
      "step": 5214
    },
    {
      "epoch": 0.40526888405346595,
      "grad_norm": 0.4422767758369446,
      "learning_rate": 7.973655579732671e-06,
      "loss": 0.2675,
      "step": 5215
    },
    {
      "epoch": 0.4053465962076469,
      "grad_norm": 0.8734308481216431,
      "learning_rate": 7.973267018961766e-06,
      "loss": 0.9427,
      "step": 5216
    },
    {
      "epoch": 0.4054243083618278,
      "grad_norm": 0.13781419396400452,
      "learning_rate": 7.972878458190861e-06,
      "loss": 0.0452,
      "step": 5217
    },
    {
      "epoch": 0.4055020205160087,
      "grad_norm": 0.13137656450271606,
      "learning_rate": 7.972489897419958e-06,
      "loss": 0.0457,
      "step": 5218
    },
    {
      "epoch": 0.4055797326701896,
      "grad_norm": 0.3972918391227722,
      "learning_rate": 7.972101336649053e-06,
      "loss": 0.0907,
      "step": 5219
    },
    {
      "epoch": 0.40565744482437055,
      "grad_norm": 0.06651818752288818,
      "learning_rate": 7.971712775878148e-06,
      "loss": 0.0113,
      "step": 5220
    },
    {
      "epoch": 0.40573515697855145,
      "grad_norm": 0.28788065910339355,
      "learning_rate": 7.971324215107244e-06,
      "loss": 0.0876,
      "step": 5221
    },
    {
      "epoch": 0.40581286913273235,
      "grad_norm": 1.0428715944290161,
      "learning_rate": 7.970935654336339e-06,
      "loss": 0.6147,
      "step": 5222
    },
    {
      "epoch": 0.4058905812869133,
      "grad_norm": 0.7465882897377014,
      "learning_rate": 7.970547093565434e-06,
      "loss": 0.2164,
      "step": 5223
    },
    {
      "epoch": 0.4059682934410942,
      "grad_norm": 0.842644453048706,
      "learning_rate": 7.970158532794529e-06,
      "loss": 0.2867,
      "step": 5224
    },
    {
      "epoch": 0.4060460055952751,
      "grad_norm": 0.22854988276958466,
      "learning_rate": 7.969769972023626e-06,
      "loss": 0.0243,
      "step": 5225
    },
    {
      "epoch": 0.406123717749456,
      "grad_norm": 0.8831176161766052,
      "learning_rate": 7.96938141125272e-06,
      "loss": 0.3371,
      "step": 5226
    },
    {
      "epoch": 0.40620142990363695,
      "grad_norm": 0.17667409777641296,
      "learning_rate": 7.968992850481816e-06,
      "loss": 0.1228,
      "step": 5227
    },
    {
      "epoch": 0.40627914205781784,
      "grad_norm": 0.18924032151699066,
      "learning_rate": 7.968604289710912e-06,
      "loss": 0.0499,
      "step": 5228
    },
    {
      "epoch": 0.40635685421199874,
      "grad_norm": 0.39086541533470154,
      "learning_rate": 7.968215728940007e-06,
      "loss": 0.1164,
      "step": 5229
    },
    {
      "epoch": 0.4064345663661797,
      "grad_norm": 0.49490803480148315,
      "learning_rate": 7.967827168169102e-06,
      "loss": 0.2827,
      "step": 5230
    },
    {
      "epoch": 0.4065122785203606,
      "grad_norm": 0.24129706621170044,
      "learning_rate": 7.967438607398199e-06,
      "loss": 0.1089,
      "step": 5231
    },
    {
      "epoch": 0.4065899906745415,
      "grad_norm": 0.4549843370914459,
      "learning_rate": 7.967050046627292e-06,
      "loss": 0.2597,
      "step": 5232
    },
    {
      "epoch": 0.4066677028287224,
      "grad_norm": 0.3591702878475189,
      "learning_rate": 7.966661485856389e-06,
      "loss": 0.1799,
      "step": 5233
    },
    {
      "epoch": 0.40674541498290334,
      "grad_norm": 0.3634495735168457,
      "learning_rate": 7.966272925085484e-06,
      "loss": 0.1613,
      "step": 5234
    },
    {
      "epoch": 0.40682312713708424,
      "grad_norm": 0.662400484085083,
      "learning_rate": 7.965884364314579e-06,
      "loss": 0.2766,
      "step": 5235
    },
    {
      "epoch": 0.40690083929126514,
      "grad_norm": 0.17900338768959045,
      "learning_rate": 7.965495803543675e-06,
      "loss": 0.1243,
      "step": 5236
    },
    {
      "epoch": 0.4069785514454461,
      "grad_norm": 0.519389808177948,
      "learning_rate": 7.96510724277277e-06,
      "loss": 0.2976,
      "step": 5237
    },
    {
      "epoch": 0.407056263599627,
      "grad_norm": 0.03756837174296379,
      "learning_rate": 7.964718682001867e-06,
      "loss": 0.0037,
      "step": 5238
    },
    {
      "epoch": 0.4071339757538079,
      "grad_norm": 0.6719371676445007,
      "learning_rate": 7.964330121230962e-06,
      "loss": 0.5504,
      "step": 5239
    },
    {
      "epoch": 0.4072116879079888,
      "grad_norm": 0.3470713794231415,
      "learning_rate": 7.963941560460057e-06,
      "loss": 0.3281,
      "step": 5240
    },
    {
      "epoch": 0.40728940006216974,
      "grad_norm": 0.5768056511878967,
      "learning_rate": 7.963552999689153e-06,
      "loss": 0.6061,
      "step": 5241
    },
    {
      "epoch": 0.40736711221635064,
      "grad_norm": 0.49632591009140015,
      "learning_rate": 7.963164438918247e-06,
      "loss": 0.3255,
      "step": 5242
    },
    {
      "epoch": 0.40744482437053153,
      "grad_norm": 0.13680300116539001,
      "learning_rate": 7.962775878147343e-06,
      "loss": 0.0294,
      "step": 5243
    },
    {
      "epoch": 0.4075225365247125,
      "grad_norm": 0.38999655842781067,
      "learning_rate": 7.962387317376438e-06,
      "loss": 0.1599,
      "step": 5244
    },
    {
      "epoch": 0.4076002486788934,
      "grad_norm": 1.2274236679077148,
      "learning_rate": 7.961998756605533e-06,
      "loss": 0.5819,
      "step": 5245
    },
    {
      "epoch": 0.4076779608330743,
      "grad_norm": 0.12401372194290161,
      "learning_rate": 7.96161019583463e-06,
      "loss": 0.0089,
      "step": 5246
    },
    {
      "epoch": 0.4077556729872552,
      "grad_norm": 0.2450415939092636,
      "learning_rate": 7.961221635063725e-06,
      "loss": 0.0824,
      "step": 5247
    },
    {
      "epoch": 0.40783338514143613,
      "grad_norm": 0.3721980154514313,
      "learning_rate": 7.96083307429282e-06,
      "loss": 0.0823,
      "step": 5248
    },
    {
      "epoch": 0.40791109729561703,
      "grad_norm": 0.2303452044725418,
      "learning_rate": 7.960444513521915e-06,
      "loss": 0.1223,
      "step": 5249
    },
    {
      "epoch": 0.40798880944979793,
      "grad_norm": 0.3170677423477173,
      "learning_rate": 7.960055952751011e-06,
      "loss": 0.0871,
      "step": 5250
    },
    {
      "epoch": 0.4080665216039789,
      "grad_norm": 0.4303264319896698,
      "learning_rate": 7.959667391980106e-06,
      "loss": 0.2218,
      "step": 5251
    },
    {
      "epoch": 0.4081442337581598,
      "grad_norm": 0.9511129260063171,
      "learning_rate": 7.959278831209201e-06,
      "loss": 0.361,
      "step": 5252
    },
    {
      "epoch": 0.4082219459123407,
      "grad_norm": 0.3097671568393707,
      "learning_rate": 7.958890270438298e-06,
      "loss": 0.17,
      "step": 5253
    },
    {
      "epoch": 0.40829965806652163,
      "grad_norm": 0.10589871555566788,
      "learning_rate": 7.958501709667393e-06,
      "loss": 0.0608,
      "step": 5254
    },
    {
      "epoch": 0.40837737022070253,
      "grad_norm": 0.12912356853485107,
      "learning_rate": 7.958113148896488e-06,
      "loss": 0.024,
      "step": 5255
    },
    {
      "epoch": 0.4084550823748834,
      "grad_norm": 0.20751608908176422,
      "learning_rate": 7.957724588125584e-06,
      "loss": 0.03,
      "step": 5256
    },
    {
      "epoch": 0.4085327945290643,
      "grad_norm": 0.5530218482017517,
      "learning_rate": 7.957336027354678e-06,
      "loss": 0.2379,
      "step": 5257
    },
    {
      "epoch": 0.4086105066832453,
      "grad_norm": 0.3105661869049072,
      "learning_rate": 7.956947466583774e-06,
      "loss": 0.2582,
      "step": 5258
    },
    {
      "epoch": 0.4086882188374262,
      "grad_norm": 0.3568991422653198,
      "learning_rate": 7.95655890581287e-06,
      "loss": 0.2245,
      "step": 5259
    },
    {
      "epoch": 0.4087659309916071,
      "grad_norm": 0.4378388822078705,
      "learning_rate": 7.956170345041964e-06,
      "loss": 0.1484,
      "step": 5260
    },
    {
      "epoch": 0.408843643145788,
      "grad_norm": 0.6130912899971008,
      "learning_rate": 7.95578178427106e-06,
      "loss": 0.3684,
      "step": 5261
    },
    {
      "epoch": 0.4089213552999689,
      "grad_norm": 0.3462024927139282,
      "learning_rate": 7.955393223500156e-06,
      "loss": 0.0904,
      "step": 5262
    },
    {
      "epoch": 0.4089990674541498,
      "grad_norm": 0.5893684029579163,
      "learning_rate": 7.95500466272925e-06,
      "loss": 0.2176,
      "step": 5263
    },
    {
      "epoch": 0.4090767796083307,
      "grad_norm": 0.2445422261953354,
      "learning_rate": 7.954616101958347e-06,
      "loss": 0.4299,
      "step": 5264
    },
    {
      "epoch": 0.4091544917625117,
      "grad_norm": 0.13755005598068237,
      "learning_rate": 7.954227541187442e-06,
      "loss": 0.056,
      "step": 5265
    },
    {
      "epoch": 0.40923220391669257,
      "grad_norm": 0.5404200553894043,
      "learning_rate": 7.953838980416539e-06,
      "loss": 0.0775,
      "step": 5266
    },
    {
      "epoch": 0.40930991607087347,
      "grad_norm": 0.42647963762283325,
      "learning_rate": 7.953450419645632e-06,
      "loss": 0.1326,
      "step": 5267
    },
    {
      "epoch": 0.4093876282250544,
      "grad_norm": 0.03657729551196098,
      "learning_rate": 7.953061858874729e-06,
      "loss": 0.0086,
      "step": 5268
    },
    {
      "epoch": 0.4094653403792353,
      "grad_norm": 0.35102587938308716,
      "learning_rate": 7.952673298103824e-06,
      "loss": 0.2041,
      "step": 5269
    },
    {
      "epoch": 0.4095430525334162,
      "grad_norm": 0.29776668548583984,
      "learning_rate": 7.952284737332919e-06,
      "loss": 0.0686,
      "step": 5270
    },
    {
      "epoch": 0.4096207646875971,
      "grad_norm": 0.3538944125175476,
      "learning_rate": 7.951896176562015e-06,
      "loss": 0.2453,
      "step": 5271
    },
    {
      "epoch": 0.40969847684177807,
      "grad_norm": 0.6015125513076782,
      "learning_rate": 7.95150761579111e-06,
      "loss": 0.4197,
      "step": 5272
    },
    {
      "epoch": 0.40977618899595897,
      "grad_norm": 0.09967521578073502,
      "learning_rate": 7.951119055020205e-06,
      "loss": 0.0305,
      "step": 5273
    },
    {
      "epoch": 0.40985390115013987,
      "grad_norm": 0.10844752192497253,
      "learning_rate": 7.950730494249302e-06,
      "loss": 0.0567,
      "step": 5274
    },
    {
      "epoch": 0.4099316133043208,
      "grad_norm": 0.5197717547416687,
      "learning_rate": 7.950341933478397e-06,
      "loss": 0.1666,
      "step": 5275
    },
    {
      "epoch": 0.4100093254585017,
      "grad_norm": 0.4588817059993744,
      "learning_rate": 7.949953372707492e-06,
      "loss": 0.3589,
      "step": 5276
    },
    {
      "epoch": 0.4100870376126826,
      "grad_norm": 0.32755765318870544,
      "learning_rate": 7.949564811936587e-06,
      "loss": 0.2273,
      "step": 5277
    },
    {
      "epoch": 0.4101647497668635,
      "grad_norm": 0.21604785323143005,
      "learning_rate": 7.949176251165683e-06,
      "loss": 0.0773,
      "step": 5278
    },
    {
      "epoch": 0.41024246192104447,
      "grad_norm": 0.17833290994167328,
      "learning_rate": 7.948787690394778e-06,
      "loss": 0.0449,
      "step": 5279
    },
    {
      "epoch": 0.41032017407522536,
      "grad_norm": 0.3219108283519745,
      "learning_rate": 7.948399129623873e-06,
      "loss": 0.2581,
      "step": 5280
    },
    {
      "epoch": 0.41039788622940626,
      "grad_norm": 0.217861145734787,
      "learning_rate": 7.94801056885297e-06,
      "loss": 0.0415,
      "step": 5281
    },
    {
      "epoch": 0.4104755983835872,
      "grad_norm": 0.2710091471672058,
      "learning_rate": 7.947622008082065e-06,
      "loss": 0.1788,
      "step": 5282
    },
    {
      "epoch": 0.4105533105377681,
      "grad_norm": 0.1567518711090088,
      "learning_rate": 7.94723344731116e-06,
      "loss": 0.0655,
      "step": 5283
    },
    {
      "epoch": 0.410631022691949,
      "grad_norm": 1.2607401609420776,
      "learning_rate": 7.946844886540257e-06,
      "loss": 0.5455,
      "step": 5284
    },
    {
      "epoch": 0.4107087348461299,
      "grad_norm": 0.2877828776836395,
      "learning_rate": 7.94645632576935e-06,
      "loss": 0.1637,
      "step": 5285
    },
    {
      "epoch": 0.41078644700031086,
      "grad_norm": 0.19550077617168427,
      "learning_rate": 7.946067764998446e-06,
      "loss": 0.0758,
      "step": 5286
    },
    {
      "epoch": 0.41086415915449176,
      "grad_norm": 0.07147254794836044,
      "learning_rate": 7.945679204227541e-06,
      "loss": 0.0357,
      "step": 5287
    },
    {
      "epoch": 0.41094187130867266,
      "grad_norm": 0.04631464183330536,
      "learning_rate": 7.945290643456636e-06,
      "loss": 0.0133,
      "step": 5288
    },
    {
      "epoch": 0.4110195834628536,
      "grad_norm": 0.3768083453178406,
      "learning_rate": 7.944902082685733e-06,
      "loss": 0.2188,
      "step": 5289
    },
    {
      "epoch": 0.4110972956170345,
      "grad_norm": 0.1701553910970688,
      "learning_rate": 7.944513521914828e-06,
      "loss": 0.0645,
      "step": 5290
    },
    {
      "epoch": 0.4111750077712154,
      "grad_norm": 0.32506027817726135,
      "learning_rate": 7.944124961143923e-06,
      "loss": 0.4463,
      "step": 5291
    },
    {
      "epoch": 0.41125271992539636,
      "grad_norm": 0.19580863416194916,
      "learning_rate": 7.94373640037302e-06,
      "loss": 0.0759,
      "step": 5292
    },
    {
      "epoch": 0.41133043207957726,
      "grad_norm": 0.31265509128570557,
      "learning_rate": 7.943347839602114e-06,
      "loss": 0.1732,
      "step": 5293
    },
    {
      "epoch": 0.41140814423375816,
      "grad_norm": 0.32944247126579285,
      "learning_rate": 7.94295927883121e-06,
      "loss": 0.0977,
      "step": 5294
    },
    {
      "epoch": 0.41148585638793905,
      "grad_norm": 0.50467848777771,
      "learning_rate": 7.942570718060304e-06,
      "loss": 0.3333,
      "step": 5295
    },
    {
      "epoch": 0.41156356854212,
      "grad_norm": 0.3179946541786194,
      "learning_rate": 7.942182157289401e-06,
      "loss": 0.1731,
      "step": 5296
    },
    {
      "epoch": 0.4116412806963009,
      "grad_norm": 0.5505880117416382,
      "learning_rate": 7.941793596518496e-06,
      "loss": 0.1048,
      "step": 5297
    },
    {
      "epoch": 0.4117189928504818,
      "grad_norm": 0.22006329894065857,
      "learning_rate": 7.941405035747591e-06,
      "loss": 0.2971,
      "step": 5298
    },
    {
      "epoch": 0.41179670500466276,
      "grad_norm": 0.38257473707199097,
      "learning_rate": 7.941016474976688e-06,
      "loss": 0.2136,
      "step": 5299
    },
    {
      "epoch": 0.41187441715884365,
      "grad_norm": 0.15937967598438263,
      "learning_rate": 7.940627914205783e-06,
      "loss": 0.0739,
      "step": 5300
    },
    {
      "epoch": 0.41195212931302455,
      "grad_norm": 0.425778865814209,
      "learning_rate": 7.940239353434877e-06,
      "loss": 0.2099,
      "step": 5301
    },
    {
      "epoch": 0.41202984146720545,
      "grad_norm": 0.15393181145191193,
      "learning_rate": 7.939850792663974e-06,
      "loss": 0.0513,
      "step": 5302
    },
    {
      "epoch": 0.4121075536213864,
      "grad_norm": 0.40534508228302,
      "learning_rate": 7.939462231893069e-06,
      "loss": 0.2122,
      "step": 5303
    },
    {
      "epoch": 0.4121852657755673,
      "grad_norm": 0.1591288298368454,
      "learning_rate": 7.939073671122164e-06,
      "loss": 0.0478,
      "step": 5304
    },
    {
      "epoch": 0.4122629779297482,
      "grad_norm": 0.3459895849227905,
      "learning_rate": 7.938685110351259e-06,
      "loss": 0.2464,
      "step": 5305
    },
    {
      "epoch": 0.41234069008392915,
      "grad_norm": 1.0935100317001343,
      "learning_rate": 7.938296549580356e-06,
      "loss": 0.5816,
      "step": 5306
    },
    {
      "epoch": 0.41241840223811005,
      "grad_norm": 0.2449663281440735,
      "learning_rate": 7.93790798880945e-06,
      "loss": 0.1378,
      "step": 5307
    },
    {
      "epoch": 0.41249611439229095,
      "grad_norm": 0.4040111005306244,
      "learning_rate": 7.937519428038545e-06,
      "loss": 0.1429,
      "step": 5308
    },
    {
      "epoch": 0.41257382654647184,
      "grad_norm": 0.3385580778121948,
      "learning_rate": 7.937130867267642e-06,
      "loss": 0.1719,
      "step": 5309
    },
    {
      "epoch": 0.4126515387006528,
      "grad_norm": 0.2536506950855255,
      "learning_rate": 7.936742306496737e-06,
      "loss": 0.1541,
      "step": 5310
    },
    {
      "epoch": 0.4127292508548337,
      "grad_norm": 0.26554611325263977,
      "learning_rate": 7.936353745725832e-06,
      "loss": 0.0559,
      "step": 5311
    },
    {
      "epoch": 0.4128069630090146,
      "grad_norm": 0.28835755586624146,
      "learning_rate": 7.935965184954929e-06,
      "loss": 0.2082,
      "step": 5312
    },
    {
      "epoch": 0.41288467516319555,
      "grad_norm": 0.4825587570667267,
      "learning_rate": 7.935576624184022e-06,
      "loss": 0.2498,
      "step": 5313
    },
    {
      "epoch": 0.41296238731737644,
      "grad_norm": 0.39099687337875366,
      "learning_rate": 7.935188063413119e-06,
      "loss": 0.2,
      "step": 5314
    },
    {
      "epoch": 0.41304009947155734,
      "grad_norm": 0.07879065722227097,
      "learning_rate": 7.934799502642214e-06,
      "loss": 0.0302,
      "step": 5315
    },
    {
      "epoch": 0.41311781162573824,
      "grad_norm": 0.2096686065196991,
      "learning_rate": 7.934410941871308e-06,
      "loss": 0.0927,
      "step": 5316
    },
    {
      "epoch": 0.4131955237799192,
      "grad_norm": 0.2531166672706604,
      "learning_rate": 7.934022381100405e-06,
      "loss": 0.1851,
      "step": 5317
    },
    {
      "epoch": 0.4132732359341001,
      "grad_norm": 0.16855381429195404,
      "learning_rate": 7.9336338203295e-06,
      "loss": 0.0726,
      "step": 5318
    },
    {
      "epoch": 0.413350948088281,
      "grad_norm": 0.3392021954059601,
      "learning_rate": 7.933245259558595e-06,
      "loss": 0.0498,
      "step": 5319
    },
    {
      "epoch": 0.41342866024246194,
      "grad_norm": 0.25503212213516235,
      "learning_rate": 7.932856698787692e-06,
      "loss": 0.179,
      "step": 5320
    },
    {
      "epoch": 0.41350637239664284,
      "grad_norm": 0.3030228614807129,
      "learning_rate": 7.932468138016787e-06,
      "loss": 0.168,
      "step": 5321
    },
    {
      "epoch": 0.41358408455082374,
      "grad_norm": 0.11553756147623062,
      "learning_rate": 7.932079577245882e-06,
      "loss": 0.0278,
      "step": 5322
    },
    {
      "epoch": 0.41366179670500464,
      "grad_norm": 0.36120742559432983,
      "learning_rate": 7.931691016474977e-06,
      "loss": 0.0882,
      "step": 5323
    },
    {
      "epoch": 0.4137395088591856,
      "grad_norm": 0.2498953640460968,
      "learning_rate": 7.931302455704073e-06,
      "loss": 0.0802,
      "step": 5324
    },
    {
      "epoch": 0.4138172210133665,
      "grad_norm": 0.32901662588119507,
      "learning_rate": 7.930913894933168e-06,
      "loss": 0.1167,
      "step": 5325
    },
    {
      "epoch": 0.4138949331675474,
      "grad_norm": 0.453320175409317,
      "learning_rate": 7.930525334162263e-06,
      "loss": 0.2168,
      "step": 5326
    },
    {
      "epoch": 0.41397264532172834,
      "grad_norm": 0.562388002872467,
      "learning_rate": 7.93013677339136e-06,
      "loss": 0.2127,
      "step": 5327
    },
    {
      "epoch": 0.41405035747590924,
      "grad_norm": 0.368365615606308,
      "learning_rate": 7.929748212620455e-06,
      "loss": 0.1823,
      "step": 5328
    },
    {
      "epoch": 0.41412806963009013,
      "grad_norm": 0.7065823674201965,
      "learning_rate": 7.92935965184955e-06,
      "loss": 0.4143,
      "step": 5329
    },
    {
      "epoch": 0.4142057817842711,
      "grad_norm": 0.10178488492965698,
      "learning_rate": 7.928971091078646e-06,
      "loss": 0.0233,
      "step": 5330
    },
    {
      "epoch": 0.414283493938452,
      "grad_norm": 0.5865825414657593,
      "learning_rate": 7.928582530307741e-06,
      "loss": 0.1738,
      "step": 5331
    },
    {
      "epoch": 0.4143612060926329,
      "grad_norm": 0.24215470254421234,
      "learning_rate": 7.928193969536836e-06,
      "loss": 0.1479,
      "step": 5332
    },
    {
      "epoch": 0.4144389182468138,
      "grad_norm": 0.38369956612586975,
      "learning_rate": 7.927805408765931e-06,
      "loss": 0.1277,
      "step": 5333
    },
    {
      "epoch": 0.41451663040099473,
      "grad_norm": 0.2641570568084717,
      "learning_rate": 7.927416847995028e-06,
      "loss": 0.0673,
      "step": 5334
    },
    {
      "epoch": 0.41459434255517563,
      "grad_norm": 0.47723618149757385,
      "learning_rate": 7.927028287224123e-06,
      "loss": 0.6587,
      "step": 5335
    },
    {
      "epoch": 0.41467205470935653,
      "grad_norm": 0.567948579788208,
      "learning_rate": 7.926639726453218e-06,
      "loss": 0.3087,
      "step": 5336
    },
    {
      "epoch": 0.4147497668635375,
      "grad_norm": 0.25674283504486084,
      "learning_rate": 7.926251165682314e-06,
      "loss": 0.1052,
      "step": 5337
    },
    {
      "epoch": 0.4148274790177184,
      "grad_norm": 0.4200570285320282,
      "learning_rate": 7.92586260491141e-06,
      "loss": 0.2651,
      "step": 5338
    },
    {
      "epoch": 0.4149051911718993,
      "grad_norm": 0.9416331648826599,
      "learning_rate": 7.925474044140504e-06,
      "loss": 0.1854,
      "step": 5339
    },
    {
      "epoch": 0.4149829033260802,
      "grad_norm": 0.7356389760971069,
      "learning_rate": 7.9250854833696e-06,
      "loss": 0.1979,
      "step": 5340
    },
    {
      "epoch": 0.41506061548026113,
      "grad_norm": 0.8238320350646973,
      "learning_rate": 7.924696922598694e-06,
      "loss": 0.4552,
      "step": 5341
    },
    {
      "epoch": 0.41513832763444203,
      "grad_norm": 0.1087891086935997,
      "learning_rate": 7.92430836182779e-06,
      "loss": 0.0374,
      "step": 5342
    },
    {
      "epoch": 0.4152160397886229,
      "grad_norm": 0.20686011016368866,
      "learning_rate": 7.923919801056886e-06,
      "loss": 0.0412,
      "step": 5343
    },
    {
      "epoch": 0.4152937519428039,
      "grad_norm": 0.2135903239250183,
      "learning_rate": 7.92353124028598e-06,
      "loss": 0.2813,
      "step": 5344
    },
    {
      "epoch": 0.4153714640969848,
      "grad_norm": 0.32745590806007385,
      "learning_rate": 7.923142679515077e-06,
      "loss": 0.507,
      "step": 5345
    },
    {
      "epoch": 0.4154491762511657,
      "grad_norm": 0.7068589925765991,
      "learning_rate": 7.922754118744172e-06,
      "loss": 0.5834,
      "step": 5346
    },
    {
      "epoch": 0.4155268884053466,
      "grad_norm": 0.12616200745105743,
      "learning_rate": 7.922365557973267e-06,
      "loss": 0.0169,
      "step": 5347
    },
    {
      "epoch": 0.4156046005595275,
      "grad_norm": 0.5448500514030457,
      "learning_rate": 7.921976997202364e-06,
      "loss": 0.3056,
      "step": 5348
    },
    {
      "epoch": 0.4156823127137084,
      "grad_norm": 0.2729000747203827,
      "learning_rate": 7.921588436431459e-06,
      "loss": 0.2892,
      "step": 5349
    },
    {
      "epoch": 0.4157600248678893,
      "grad_norm": 0.6090372800827026,
      "learning_rate": 7.921199875660554e-06,
      "loss": 0.2254,
      "step": 5350
    },
    {
      "epoch": 0.4158377370220703,
      "grad_norm": 0.33151835203170776,
      "learning_rate": 7.920811314889649e-06,
      "loss": 0.2468,
      "step": 5351
    },
    {
      "epoch": 0.4159154491762512,
      "grad_norm": 0.08277596533298492,
      "learning_rate": 7.920422754118745e-06,
      "loss": 0.0325,
      "step": 5352
    },
    {
      "epoch": 0.41599316133043207,
      "grad_norm": 0.08729754388332367,
      "learning_rate": 7.92003419334784e-06,
      "loss": 0.0162,
      "step": 5353
    },
    {
      "epoch": 0.41607087348461297,
      "grad_norm": 0.1808929592370987,
      "learning_rate": 7.919645632576935e-06,
      "loss": 0.0751,
      "step": 5354
    },
    {
      "epoch": 0.4161485856387939,
      "grad_norm": 0.3070942163467407,
      "learning_rate": 7.919257071806032e-06,
      "loss": 0.1189,
      "step": 5355
    },
    {
      "epoch": 0.4162262977929748,
      "grad_norm": 0.5430571436882019,
      "learning_rate": 7.918868511035127e-06,
      "loss": 0.1043,
      "step": 5356
    },
    {
      "epoch": 0.4163040099471557,
      "grad_norm": 0.12882272899150848,
      "learning_rate": 7.918479950264222e-06,
      "loss": 0.0237,
      "step": 5357
    },
    {
      "epoch": 0.41638172210133667,
      "grad_norm": 0.25485169887542725,
      "learning_rate": 7.918091389493318e-06,
      "loss": 0.0856,
      "step": 5358
    },
    {
      "epoch": 0.41645943425551757,
      "grad_norm": 2.286402702331543,
      "learning_rate": 7.917702828722413e-06,
      "loss": 0.873,
      "step": 5359
    },
    {
      "epoch": 0.41653714640969847,
      "grad_norm": 0.0930701196193695,
      "learning_rate": 7.917314267951508e-06,
      "loss": 0.0251,
      "step": 5360
    },
    {
      "epoch": 0.41661485856387936,
      "grad_norm": 0.2817293405532837,
      "learning_rate": 7.916925707180603e-06,
      "loss": 0.0579,
      "step": 5361
    },
    {
      "epoch": 0.4166925707180603,
      "grad_norm": 0.3412818908691406,
      "learning_rate": 7.9165371464097e-06,
      "loss": 0.0586,
      "step": 5362
    },
    {
      "epoch": 0.4167702828722412,
      "grad_norm": 0.3806041479110718,
      "learning_rate": 7.916148585638795e-06,
      "loss": 0.198,
      "step": 5363
    },
    {
      "epoch": 0.4168479950264221,
      "grad_norm": 0.07803074270486832,
      "learning_rate": 7.91576002486789e-06,
      "loss": 0.0398,
      "step": 5364
    },
    {
      "epoch": 0.41692570718060307,
      "grad_norm": 0.8472108244895935,
      "learning_rate": 7.915371464096986e-06,
      "loss": 0.2381,
      "step": 5365
    },
    {
      "epoch": 0.41700341933478396,
      "grad_norm": 0.4209112524986267,
      "learning_rate": 7.914982903326081e-06,
      "loss": 0.3044,
      "step": 5366
    },
    {
      "epoch": 0.41708113148896486,
      "grad_norm": 0.5144661664962769,
      "learning_rate": 7.914594342555176e-06,
      "loss": 0.1538,
      "step": 5367
    },
    {
      "epoch": 0.41715884364314576,
      "grad_norm": 0.5372070074081421,
      "learning_rate": 7.914205781784273e-06,
      "loss": 0.6416,
      "step": 5368
    },
    {
      "epoch": 0.4172365557973267,
      "grad_norm": 0.45046138763427734,
      "learning_rate": 7.913817221013366e-06,
      "loss": 0.7408,
      "step": 5369
    },
    {
      "epoch": 0.4173142679515076,
      "grad_norm": 0.15219075977802277,
      "learning_rate": 7.913428660242463e-06,
      "loss": 0.1118,
      "step": 5370
    },
    {
      "epoch": 0.4173919801056885,
      "grad_norm": 0.2151755690574646,
      "learning_rate": 7.913040099471558e-06,
      "loss": 0.0141,
      "step": 5371
    },
    {
      "epoch": 0.41746969225986946,
      "grad_norm": 0.18221712112426758,
      "learning_rate": 7.912651538700653e-06,
      "loss": 0.0646,
      "step": 5372
    },
    {
      "epoch": 0.41754740441405036,
      "grad_norm": 0.2611260712146759,
      "learning_rate": 7.91226297792975e-06,
      "loss": 0.1208,
      "step": 5373
    },
    {
      "epoch": 0.41762511656823126,
      "grad_norm": 0.16731101274490356,
      "learning_rate": 7.911874417158844e-06,
      "loss": 0.0362,
      "step": 5374
    },
    {
      "epoch": 0.4177028287224122,
      "grad_norm": 0.09785059094429016,
      "learning_rate": 7.91148585638794e-06,
      "loss": 0.0134,
      "step": 5375
    },
    {
      "epoch": 0.4177805408765931,
      "grad_norm": 0.8306058049201965,
      "learning_rate": 7.911097295617034e-06,
      "loss": 0.312,
      "step": 5376
    },
    {
      "epoch": 0.417858253030774,
      "grad_norm": 0.47572168707847595,
      "learning_rate": 7.910708734846131e-06,
      "loss": 0.3729,
      "step": 5377
    },
    {
      "epoch": 0.4179359651849549,
      "grad_norm": 0.5066795349121094,
      "learning_rate": 7.910320174075226e-06,
      "loss": 0.2262,
      "step": 5378
    },
    {
      "epoch": 0.41801367733913586,
      "grad_norm": 0.24807412922382355,
      "learning_rate": 7.90993161330432e-06,
      "loss": 0.1311,
      "step": 5379
    },
    {
      "epoch": 0.41809138949331676,
      "grad_norm": 0.871512234210968,
      "learning_rate": 7.909543052533417e-06,
      "loss": 0.5673,
      "step": 5380
    },
    {
      "epoch": 0.41816910164749765,
      "grad_norm": 0.32429933547973633,
      "learning_rate": 7.909154491762512e-06,
      "loss": 0.1198,
      "step": 5381
    },
    {
      "epoch": 0.4182468138016786,
      "grad_norm": 0.3733876347541809,
      "learning_rate": 7.908765930991607e-06,
      "loss": 0.1428,
      "step": 5382
    },
    {
      "epoch": 0.4183245259558595,
      "grad_norm": 0.26285138726234436,
      "learning_rate": 7.908377370220704e-06,
      "loss": 0.3676,
      "step": 5383
    },
    {
      "epoch": 0.4184022381100404,
      "grad_norm": 0.5462828278541565,
      "learning_rate": 7.907988809449797e-06,
      "loss": 0.2035,
      "step": 5384
    },
    {
      "epoch": 0.4184799502642213,
      "grad_norm": 0.528670072555542,
      "learning_rate": 7.907600248678894e-06,
      "loss": 0.2117,
      "step": 5385
    },
    {
      "epoch": 0.41855766241840225,
      "grad_norm": 0.4559358060359955,
      "learning_rate": 7.907211687907989e-06,
      "loss": 0.2147,
      "step": 5386
    },
    {
      "epoch": 0.41863537457258315,
      "grad_norm": 0.4468812942504883,
      "learning_rate": 7.906823127137085e-06,
      "loss": 0.1992,
      "step": 5387
    },
    {
      "epoch": 0.41871308672676405,
      "grad_norm": 0.16025541722774506,
      "learning_rate": 7.90643456636618e-06,
      "loss": 0.039,
      "step": 5388
    },
    {
      "epoch": 0.418790798880945,
      "grad_norm": 0.36643195152282715,
      "learning_rate": 7.906046005595275e-06,
      "loss": 0.1672,
      "step": 5389
    },
    {
      "epoch": 0.4188685110351259,
      "grad_norm": 0.31434905529022217,
      "learning_rate": 7.905657444824372e-06,
      "loss": 0.1346,
      "step": 5390
    },
    {
      "epoch": 0.4189462231893068,
      "grad_norm": 0.5096296072006226,
      "learning_rate": 7.905268884053467e-06,
      "loss": 0.3043,
      "step": 5391
    },
    {
      "epoch": 0.4190239353434877,
      "grad_norm": 0.30022329092025757,
      "learning_rate": 7.904880323282562e-06,
      "loss": 0.0965,
      "step": 5392
    },
    {
      "epoch": 0.41910164749766865,
      "grad_norm": 0.31503963470458984,
      "learning_rate": 7.904491762511659e-06,
      "loss": 0.1582,
      "step": 5393
    },
    {
      "epoch": 0.41917935965184955,
      "grad_norm": 0.4705553352832794,
      "learning_rate": 7.904103201740752e-06,
      "loss": 0.1915,
      "step": 5394
    },
    {
      "epoch": 0.41925707180603045,
      "grad_norm": 0.4569406509399414,
      "learning_rate": 7.903714640969848e-06,
      "loss": 0.626,
      "step": 5395
    },
    {
      "epoch": 0.4193347839602114,
      "grad_norm": 0.20435559749603271,
      "learning_rate": 7.903326080198943e-06,
      "loss": 0.078,
      "step": 5396
    },
    {
      "epoch": 0.4194124961143923,
      "grad_norm": 0.2555345892906189,
      "learning_rate": 7.902937519428038e-06,
      "loss": 0.0796,
      "step": 5397
    },
    {
      "epoch": 0.4194902082685732,
      "grad_norm": 0.6458295583724976,
      "learning_rate": 7.902548958657135e-06,
      "loss": 0.5269,
      "step": 5398
    },
    {
      "epoch": 0.4195679204227541,
      "grad_norm": 0.44210097193717957,
      "learning_rate": 7.90216039788623e-06,
      "loss": 0.1999,
      "step": 5399
    },
    {
      "epoch": 0.41964563257693505,
      "grad_norm": 0.1205335184931755,
      "learning_rate": 7.901771837115325e-06,
      "loss": 0.0285,
      "step": 5400
    },
    {
      "epoch": 0.41972334473111594,
      "grad_norm": 0.13779671490192413,
      "learning_rate": 7.901383276344422e-06,
      "loss": 0.2474,
      "step": 5401
    },
    {
      "epoch": 0.41980105688529684,
      "grad_norm": 0.5835418701171875,
      "learning_rate": 7.900994715573517e-06,
      "loss": 0.4056,
      "step": 5402
    },
    {
      "epoch": 0.4198787690394778,
      "grad_norm": 0.4904371500015259,
      "learning_rate": 7.900606154802611e-06,
      "loss": 0.5959,
      "step": 5403
    },
    {
      "epoch": 0.4199564811936587,
      "grad_norm": 0.5095245242118835,
      "learning_rate": 7.900217594031706e-06,
      "loss": 0.2714,
      "step": 5404
    },
    {
      "epoch": 0.4200341933478396,
      "grad_norm": 0.24835701286792755,
      "learning_rate": 7.899829033260803e-06,
      "loss": 0.3708,
      "step": 5405
    },
    {
      "epoch": 0.4201119055020205,
      "grad_norm": 0.03735102340579033,
      "learning_rate": 7.899440472489898e-06,
      "loss": 0.0182,
      "step": 5406
    },
    {
      "epoch": 0.42018961765620144,
      "grad_norm": 0.1621403694152832,
      "learning_rate": 7.899051911718993e-06,
      "loss": 0.0238,
      "step": 5407
    },
    {
      "epoch": 0.42026732981038234,
      "grad_norm": 0.06721962243318558,
      "learning_rate": 7.89866335094809e-06,
      "loss": 0.0127,
      "step": 5408
    },
    {
      "epoch": 0.42034504196456324,
      "grad_norm": 0.6637813448905945,
      "learning_rate": 7.898274790177185e-06,
      "loss": 0.3422,
      "step": 5409
    },
    {
      "epoch": 0.4204227541187442,
      "grad_norm": 0.7716641426086426,
      "learning_rate": 7.89788622940628e-06,
      "loss": 0.2558,
      "step": 5410
    },
    {
      "epoch": 0.4205004662729251,
      "grad_norm": 0.3866155743598938,
      "learning_rate": 7.897497668635376e-06,
      "loss": 0.1843,
      "step": 5411
    },
    {
      "epoch": 0.420578178427106,
      "grad_norm": 0.1636730134487152,
      "learning_rate": 7.89710910786447e-06,
      "loss": 0.0521,
      "step": 5412
    },
    {
      "epoch": 0.42065589058128694,
      "grad_norm": 0.3255208730697632,
      "learning_rate": 7.896720547093566e-06,
      "loss": 0.188,
      "step": 5413
    },
    {
      "epoch": 0.42073360273546784,
      "grad_norm": 0.6029853224754333,
      "learning_rate": 7.896331986322661e-06,
      "loss": 0.3578,
      "step": 5414
    },
    {
      "epoch": 0.42081131488964874,
      "grad_norm": 1.4997608661651611,
      "learning_rate": 7.895943425551756e-06,
      "loss": 0.5171,
      "step": 5415
    },
    {
      "epoch": 0.42088902704382963,
      "grad_norm": 0.3742319941520691,
      "learning_rate": 7.895554864780853e-06,
      "loss": 0.1035,
      "step": 5416
    },
    {
      "epoch": 0.4209667391980106,
      "grad_norm": 0.7065902948379517,
      "learning_rate": 7.895166304009948e-06,
      "loss": 0.2926,
      "step": 5417
    },
    {
      "epoch": 0.4210444513521915,
      "grad_norm": 0.07664161920547485,
      "learning_rate": 7.894777743239044e-06,
      "loss": 0.0168,
      "step": 5418
    },
    {
      "epoch": 0.4211221635063724,
      "grad_norm": 0.17085659503936768,
      "learning_rate": 7.894389182468139e-06,
      "loss": 0.0433,
      "step": 5419
    },
    {
      "epoch": 0.42119987566055334,
      "grad_norm": 0.21957407891750336,
      "learning_rate": 7.894000621697234e-06,
      "loss": 0.0557,
      "step": 5420
    },
    {
      "epoch": 0.42127758781473423,
      "grad_norm": 0.07857874780893326,
      "learning_rate": 7.89361206092633e-06,
      "loss": 0.0446,
      "step": 5421
    },
    {
      "epoch": 0.42135529996891513,
      "grad_norm": 0.17641586065292358,
      "learning_rate": 7.893223500155424e-06,
      "loss": 0.055,
      "step": 5422
    },
    {
      "epoch": 0.42143301212309603,
      "grad_norm": 0.30302080512046814,
      "learning_rate": 7.89283493938452e-06,
      "loss": 0.1024,
      "step": 5423
    },
    {
      "epoch": 0.421510724277277,
      "grad_norm": 0.4710153341293335,
      "learning_rate": 7.892446378613616e-06,
      "loss": 0.7216,
      "step": 5424
    },
    {
      "epoch": 0.4215884364314579,
      "grad_norm": 0.37966009974479675,
      "learning_rate": 7.89205781784271e-06,
      "loss": 0.2002,
      "step": 5425
    },
    {
      "epoch": 0.4216661485856388,
      "grad_norm": 0.1976768523454666,
      "learning_rate": 7.891669257071807e-06,
      "loss": 0.0675,
      "step": 5426
    },
    {
      "epoch": 0.42174386073981973,
      "grad_norm": 0.13963475823402405,
      "learning_rate": 7.891280696300902e-06,
      "loss": 0.038,
      "step": 5427
    },
    {
      "epoch": 0.42182157289400063,
      "grad_norm": 0.5338717699050903,
      "learning_rate": 7.890892135529997e-06,
      "loss": 0.2531,
      "step": 5428
    },
    {
      "epoch": 0.4218992850481815,
      "grad_norm": 0.7340571880340576,
      "learning_rate": 7.890503574759094e-06,
      "loss": 0.1498,
      "step": 5429
    },
    {
      "epoch": 0.4219769972023624,
      "grad_norm": 0.14210771024227142,
      "learning_rate": 7.890115013988189e-06,
      "loss": 0.0365,
      "step": 5430
    },
    {
      "epoch": 0.4220547093565434,
      "grad_norm": 0.20003406703472137,
      "learning_rate": 7.889726453217284e-06,
      "loss": 0.1021,
      "step": 5431
    },
    {
      "epoch": 0.4221324215107243,
      "grad_norm": 0.09059534966945648,
      "learning_rate": 7.889337892446379e-06,
      "loss": 0.0142,
      "step": 5432
    },
    {
      "epoch": 0.4222101336649052,
      "grad_norm": 0.19665883481502533,
      "learning_rate": 7.888949331675475e-06,
      "loss": 0.0325,
      "step": 5433
    },
    {
      "epoch": 0.4222878458190861,
      "grad_norm": 0.4332825541496277,
      "learning_rate": 7.88856077090457e-06,
      "loss": 0.1496,
      "step": 5434
    },
    {
      "epoch": 0.422365557973267,
      "grad_norm": 0.11786848306655884,
      "learning_rate": 7.888172210133665e-06,
      "loss": 0.0414,
      "step": 5435
    },
    {
      "epoch": 0.4224432701274479,
      "grad_norm": 0.3945908546447754,
      "learning_rate": 7.887783649362762e-06,
      "loss": 0.0425,
      "step": 5436
    },
    {
      "epoch": 0.4225209822816288,
      "grad_norm": 0.28136247396469116,
      "learning_rate": 7.887395088591857e-06,
      "loss": 0.073,
      "step": 5437
    },
    {
      "epoch": 0.4225986944358098,
      "grad_norm": 0.6654068827629089,
      "learning_rate": 7.887006527820952e-06,
      "loss": 0.2245,
      "step": 5438
    },
    {
      "epoch": 0.42267640658999067,
      "grad_norm": 0.15986749529838562,
      "learning_rate": 7.886617967050048e-06,
      "loss": 0.0482,
      "step": 5439
    },
    {
      "epoch": 0.42275411874417157,
      "grad_norm": 0.27735310792922974,
      "learning_rate": 7.886229406279142e-06,
      "loss": 0.0657,
      "step": 5440
    },
    {
      "epoch": 0.4228318308983525,
      "grad_norm": 0.4650880694389343,
      "learning_rate": 7.885840845508238e-06,
      "loss": 0.1683,
      "step": 5441
    },
    {
      "epoch": 0.4229095430525334,
      "grad_norm": 0.39449596405029297,
      "learning_rate": 7.885452284737333e-06,
      "loss": 0.4228,
      "step": 5442
    },
    {
      "epoch": 0.4229872552067143,
      "grad_norm": 0.36482974886894226,
      "learning_rate": 7.885063723966428e-06,
      "loss": 0.2325,
      "step": 5443
    },
    {
      "epoch": 0.4230649673608952,
      "grad_norm": 0.30845052003860474,
      "learning_rate": 7.884675163195525e-06,
      "loss": 0.085,
      "step": 5444
    },
    {
      "epoch": 0.42314267951507617,
      "grad_norm": 0.9425726532936096,
      "learning_rate": 7.88428660242462e-06,
      "loss": 0.3341,
      "step": 5445
    },
    {
      "epoch": 0.42322039166925707,
      "grad_norm": 0.5077589154243469,
      "learning_rate": 7.883898041653715e-06,
      "loss": 0.1141,
      "step": 5446
    },
    {
      "epoch": 0.42329810382343797,
      "grad_norm": 0.07627764344215393,
      "learning_rate": 7.883509480882811e-06,
      "loss": 0.0182,
      "step": 5447
    },
    {
      "epoch": 0.4233758159776189,
      "grad_norm": 0.47910284996032715,
      "learning_rate": 7.883120920111906e-06,
      "loss": 0.5471,
      "step": 5448
    },
    {
      "epoch": 0.4234535281317998,
      "grad_norm": 0.26355627179145813,
      "learning_rate": 7.882732359341003e-06,
      "loss": 0.0815,
      "step": 5449
    },
    {
      "epoch": 0.4235312402859807,
      "grad_norm": 0.31806474924087524,
      "learning_rate": 7.882343798570096e-06,
      "loss": 0.3013,
      "step": 5450
    },
    {
      "epoch": 0.42360895244016167,
      "grad_norm": 0.5339274406433105,
      "learning_rate": 7.881955237799193e-06,
      "loss": 0.1706,
      "step": 5451
    },
    {
      "epoch": 0.42368666459434257,
      "grad_norm": 0.1811453402042389,
      "learning_rate": 7.881566677028288e-06,
      "loss": 0.0976,
      "step": 5452
    },
    {
      "epoch": 0.42376437674852346,
      "grad_norm": 0.10060413926839828,
      "learning_rate": 7.881178116257383e-06,
      "loss": 0.0221,
      "step": 5453
    },
    {
      "epoch": 0.42384208890270436,
      "grad_norm": 0.3834323287010193,
      "learning_rate": 7.88078955548648e-06,
      "loss": 0.185,
      "step": 5454
    },
    {
      "epoch": 0.4239198010568853,
      "grad_norm": 0.7473152279853821,
      "learning_rate": 7.880400994715574e-06,
      "loss": 0.2611,
      "step": 5455
    },
    {
      "epoch": 0.4239975132110662,
      "grad_norm": 0.3986910581588745,
      "learning_rate": 7.88001243394467e-06,
      "loss": 0.2417,
      "step": 5456
    },
    {
      "epoch": 0.4240752253652471,
      "grad_norm": 0.11747180670499802,
      "learning_rate": 7.879623873173766e-06,
      "loss": 0.0689,
      "step": 5457
    },
    {
      "epoch": 0.42415293751942806,
      "grad_norm": 0.25019344687461853,
      "learning_rate": 7.87923531240286e-06,
      "loss": 0.2039,
      "step": 5458
    },
    {
      "epoch": 0.42423064967360896,
      "grad_norm": 0.17488832771778107,
      "learning_rate": 7.878846751631956e-06,
      "loss": 0.0192,
      "step": 5459
    },
    {
      "epoch": 0.42430836182778986,
      "grad_norm": 0.2927516996860504,
      "learning_rate": 7.87845819086105e-06,
      "loss": 0.1223,
      "step": 5460
    },
    {
      "epoch": 0.42438607398197076,
      "grad_norm": 0.3351037800312042,
      "learning_rate": 7.878069630090147e-06,
      "loss": 0.0783,
      "step": 5461
    },
    {
      "epoch": 0.4244637861361517,
      "grad_norm": 0.5928686261177063,
      "learning_rate": 7.877681069319242e-06,
      "loss": 0.8839,
      "step": 5462
    },
    {
      "epoch": 0.4245414982903326,
      "grad_norm": 0.3757184147834778,
      "learning_rate": 7.877292508548337e-06,
      "loss": 0.3236,
      "step": 5463
    },
    {
      "epoch": 0.4246192104445135,
      "grad_norm": 0.8256353735923767,
      "learning_rate": 7.876903947777434e-06,
      "loss": 0.1239,
      "step": 5464
    },
    {
      "epoch": 0.42469692259869446,
      "grad_norm": 0.3735959827899933,
      "learning_rate": 7.876515387006529e-06,
      "loss": 0.1068,
      "step": 5465
    },
    {
      "epoch": 0.42477463475287536,
      "grad_norm": 0.3877714276313782,
      "learning_rate": 7.876126826235624e-06,
      "loss": 0.175,
      "step": 5466
    },
    {
      "epoch": 0.42485234690705626,
      "grad_norm": 0.1796521544456482,
      "learning_rate": 7.87573826546472e-06,
      "loss": 0.0643,
      "step": 5467
    },
    {
      "epoch": 0.42493005906123715,
      "grad_norm": 0.3177945613861084,
      "learning_rate": 7.875349704693814e-06,
      "loss": 0.1618,
      "step": 5468
    },
    {
      "epoch": 0.4250077712154181,
      "grad_norm": 0.12788568437099457,
      "learning_rate": 7.87496114392291e-06,
      "loss": 0.0197,
      "step": 5469
    },
    {
      "epoch": 0.425085483369599,
      "grad_norm": 0.3665510416030884,
      "learning_rate": 7.874572583152005e-06,
      "loss": 0.2271,
      "step": 5470
    },
    {
      "epoch": 0.4251631955237799,
      "grad_norm": 0.55585116147995,
      "learning_rate": 7.8741840223811e-06,
      "loss": 0.3654,
      "step": 5471
    },
    {
      "epoch": 0.42524090767796086,
      "grad_norm": 0.6536270380020142,
      "learning_rate": 7.873795461610197e-06,
      "loss": 0.5429,
      "step": 5472
    },
    {
      "epoch": 0.42531861983214175,
      "grad_norm": 0.2134547084569931,
      "learning_rate": 7.873406900839292e-06,
      "loss": 0.0654,
      "step": 5473
    },
    {
      "epoch": 0.42539633198632265,
      "grad_norm": 0.3683605492115021,
      "learning_rate": 7.873018340068387e-06,
      "loss": 0.2422,
      "step": 5474
    },
    {
      "epoch": 0.42547404414050355,
      "grad_norm": 0.23919081687927246,
      "learning_rate": 7.872629779297483e-06,
      "loss": 0.2114,
      "step": 5475
    },
    {
      "epoch": 0.4255517562946845,
      "grad_norm": 0.26164305210113525,
      "learning_rate": 7.872241218526578e-06,
      "loss": 0.1081,
      "step": 5476
    },
    {
      "epoch": 0.4256294684488654,
      "grad_norm": 0.41507917642593384,
      "learning_rate": 7.871852657755673e-06,
      "loss": 0.3978,
      "step": 5477
    },
    {
      "epoch": 0.4257071806030463,
      "grad_norm": 0.08748601377010345,
      "learning_rate": 7.871464096984768e-06,
      "loss": 0.0509,
      "step": 5478
    },
    {
      "epoch": 0.42578489275722725,
      "grad_norm": 0.4611404538154602,
      "learning_rate": 7.871075536213865e-06,
      "loss": 0.2938,
      "step": 5479
    },
    {
      "epoch": 0.42586260491140815,
      "grad_norm": 0.35500508546829224,
      "learning_rate": 7.87068697544296e-06,
      "loss": 0.3646,
      "step": 5480
    },
    {
      "epoch": 0.42594031706558905,
      "grad_norm": 0.0868111252784729,
      "learning_rate": 7.870298414672055e-06,
      "loss": 0.0312,
      "step": 5481
    },
    {
      "epoch": 0.42601802921976994,
      "grad_norm": 0.13861282169818878,
      "learning_rate": 7.869909853901151e-06,
      "loss": 0.0333,
      "step": 5482
    },
    {
      "epoch": 0.4260957413739509,
      "grad_norm": 0.15268582105636597,
      "learning_rate": 7.869521293130246e-06,
      "loss": 0.061,
      "step": 5483
    },
    {
      "epoch": 0.4261734535281318,
      "grad_norm": 0.07414014637470245,
      "learning_rate": 7.869132732359341e-06,
      "loss": 0.0383,
      "step": 5484
    },
    {
      "epoch": 0.4262511656823127,
      "grad_norm": 0.27676019072532654,
      "learning_rate": 7.868744171588438e-06,
      "loss": 0.0761,
      "step": 5485
    },
    {
      "epoch": 0.42632887783649365,
      "grad_norm": 0.43659403920173645,
      "learning_rate": 7.868355610817533e-06,
      "loss": 0.1848,
      "step": 5486
    },
    {
      "epoch": 0.42640658999067454,
      "grad_norm": 0.13068191707134247,
      "learning_rate": 7.867967050046628e-06,
      "loss": 0.0519,
      "step": 5487
    },
    {
      "epoch": 0.42648430214485544,
      "grad_norm": 0.10018861293792725,
      "learning_rate": 7.867578489275723e-06,
      "loss": 0.0472,
      "step": 5488
    },
    {
      "epoch": 0.4265620142990364,
      "grad_norm": 0.35409218072891235,
      "learning_rate": 7.86718992850482e-06,
      "loss": 0.2723,
      "step": 5489
    },
    {
      "epoch": 0.4266397264532173,
      "grad_norm": 0.35272470116615295,
      "learning_rate": 7.866801367733914e-06,
      "loss": 0.1884,
      "step": 5490
    },
    {
      "epoch": 0.4267174386073982,
      "grad_norm": 0.11844440549612045,
      "learning_rate": 7.86641280696301e-06,
      "loss": 0.1634,
      "step": 5491
    },
    {
      "epoch": 0.4267951507615791,
      "grad_norm": 0.3041606545448303,
      "learning_rate": 7.866024246192106e-06,
      "loss": 0.0781,
      "step": 5492
    },
    {
      "epoch": 0.42687286291576004,
      "grad_norm": 0.3377753496170044,
      "learning_rate": 7.865635685421201e-06,
      "loss": 0.1676,
      "step": 5493
    },
    {
      "epoch": 0.42695057506994094,
      "grad_norm": 1.109018087387085,
      "learning_rate": 7.865247124650296e-06,
      "loss": 0.4633,
      "step": 5494
    },
    {
      "epoch": 0.42702828722412184,
      "grad_norm": 0.751221776008606,
      "learning_rate": 7.864858563879391e-06,
      "loss": 0.3823,
      "step": 5495
    },
    {
      "epoch": 0.4271059993783028,
      "grad_norm": 0.1297314465045929,
      "learning_rate": 7.864470003108486e-06,
      "loss": 0.1047,
      "step": 5496
    },
    {
      "epoch": 0.4271837115324837,
      "grad_norm": 0.5201635360717773,
      "learning_rate": 7.864081442337582e-06,
      "loss": 0.1196,
      "step": 5497
    },
    {
      "epoch": 0.4272614236866646,
      "grad_norm": 0.8567744493484497,
      "learning_rate": 7.863692881566677e-06,
      "loss": 0.2022,
      "step": 5498
    },
    {
      "epoch": 0.4273391358408455,
      "grad_norm": 0.21939730644226074,
      "learning_rate": 7.863304320795772e-06,
      "loss": 0.1341,
      "step": 5499
    },
    {
      "epoch": 0.42741684799502644,
      "grad_norm": 0.4981297552585602,
      "learning_rate": 7.862915760024869e-06,
      "loss": 0.5146,
      "step": 5500
    },
    {
      "epoch": 0.42749456014920734,
      "grad_norm": 0.28955841064453125,
      "learning_rate": 7.862527199253964e-06,
      "loss": 0.0981,
      "step": 5501
    },
    {
      "epoch": 0.42757227230338823,
      "grad_norm": 0.23204462230205536,
      "learning_rate": 7.862138638483059e-06,
      "loss": 0.2016,
      "step": 5502
    },
    {
      "epoch": 0.4276499844575692,
      "grad_norm": 0.37268367409706116,
      "learning_rate": 7.861750077712154e-06,
      "loss": 0.1148,
      "step": 5503
    },
    {
      "epoch": 0.4277276966117501,
      "grad_norm": 0.2126004546880722,
      "learning_rate": 7.86136151694125e-06,
      "loss": 0.0523,
      "step": 5504
    },
    {
      "epoch": 0.427805408765931,
      "grad_norm": 0.4399271607398987,
      "learning_rate": 7.860972956170345e-06,
      "loss": 0.038,
      "step": 5505
    },
    {
      "epoch": 0.4278831209201119,
      "grad_norm": 0.2830919623374939,
      "learning_rate": 7.86058439539944e-06,
      "loss": 0.1146,
      "step": 5506
    },
    {
      "epoch": 0.42796083307429283,
      "grad_norm": 0.3471481204032898,
      "learning_rate": 7.860195834628537e-06,
      "loss": 0.2,
      "step": 5507
    },
    {
      "epoch": 0.42803854522847373,
      "grad_norm": 0.6097347736358643,
      "learning_rate": 7.859807273857632e-06,
      "loss": 0.6157,
      "step": 5508
    },
    {
      "epoch": 0.42811625738265463,
      "grad_norm": 0.17690153419971466,
      "learning_rate": 7.859418713086727e-06,
      "loss": 0.1142,
      "step": 5509
    },
    {
      "epoch": 0.4281939695368356,
      "grad_norm": 0.6224048137664795,
      "learning_rate": 7.859030152315824e-06,
      "loss": 0.4575,
      "step": 5510
    },
    {
      "epoch": 0.4282716816910165,
      "grad_norm": 0.234243243932724,
      "learning_rate": 7.858641591544919e-06,
      "loss": 0.0797,
      "step": 5511
    },
    {
      "epoch": 0.4283493938451974,
      "grad_norm": 0.19558171927928925,
      "learning_rate": 7.858253030774013e-06,
      "loss": 0.1402,
      "step": 5512
    },
    {
      "epoch": 0.4284271059993783,
      "grad_norm": 0.14959535002708435,
      "learning_rate": 7.857864470003108e-06,
      "loss": 0.026,
      "step": 5513
    },
    {
      "epoch": 0.42850481815355923,
      "grad_norm": 0.5388457179069519,
      "learning_rate": 7.857475909232205e-06,
      "loss": 0.1283,
      "step": 5514
    },
    {
      "epoch": 0.42858253030774013,
      "grad_norm": 0.5456027388572693,
      "learning_rate": 7.8570873484613e-06,
      "loss": 0.3191,
      "step": 5515
    },
    {
      "epoch": 0.428660242461921,
      "grad_norm": 0.8734795451164246,
      "learning_rate": 7.856698787690395e-06,
      "loss": 0.3767,
      "step": 5516
    },
    {
      "epoch": 0.428737954616102,
      "grad_norm": 0.08779110014438629,
      "learning_rate": 7.856310226919492e-06,
      "loss": 0.0656,
      "step": 5517
    },
    {
      "epoch": 0.4288156667702829,
      "grad_norm": 0.3284124732017517,
      "learning_rate": 7.855921666148587e-06,
      "loss": 0.0459,
      "step": 5518
    },
    {
      "epoch": 0.4288933789244638,
      "grad_norm": 0.5110110640525818,
      "learning_rate": 7.855533105377682e-06,
      "loss": 0.2658,
      "step": 5519
    },
    {
      "epoch": 0.4289710910786447,
      "grad_norm": 0.4566764235496521,
      "learning_rate": 7.855144544606778e-06,
      "loss": 0.2999,
      "step": 5520
    },
    {
      "epoch": 0.4290488032328256,
      "grad_norm": 0.33281344175338745,
      "learning_rate": 7.854755983835871e-06,
      "loss": 0.2541,
      "step": 5521
    },
    {
      "epoch": 0.4291265153870065,
      "grad_norm": 0.27304568886756897,
      "learning_rate": 7.854367423064968e-06,
      "loss": 0.1687,
      "step": 5522
    },
    {
      "epoch": 0.4292042275411874,
      "grad_norm": 0.14080333709716797,
      "learning_rate": 7.853978862294063e-06,
      "loss": 0.0335,
      "step": 5523
    },
    {
      "epoch": 0.4292819396953684,
      "grad_norm": 0.2683371901512146,
      "learning_rate": 7.853590301523158e-06,
      "loss": 0.2375,
      "step": 5524
    },
    {
      "epoch": 0.4293596518495493,
      "grad_norm": 1.2834656238555908,
      "learning_rate": 7.853201740752255e-06,
      "loss": 0.7698,
      "step": 5525
    },
    {
      "epoch": 0.42943736400373017,
      "grad_norm": 0.22951939702033997,
      "learning_rate": 7.85281317998135e-06,
      "loss": 0.2767,
      "step": 5526
    },
    {
      "epoch": 0.4295150761579111,
      "grad_norm": 0.5718129277229309,
      "learning_rate": 7.852424619210445e-06,
      "loss": 0.2895,
      "step": 5527
    },
    {
      "epoch": 0.429592788312092,
      "grad_norm": 0.3062054514884949,
      "learning_rate": 7.852036058439541e-06,
      "loss": 0.0825,
      "step": 5528
    },
    {
      "epoch": 0.4296705004662729,
      "grad_norm": 0.23770272731781006,
      "learning_rate": 7.851647497668636e-06,
      "loss": 0.0788,
      "step": 5529
    },
    {
      "epoch": 0.4297482126204538,
      "grad_norm": 0.3051416575908661,
      "learning_rate": 7.851258936897731e-06,
      "loss": 0.3297,
      "step": 5530
    },
    {
      "epoch": 0.42982592477463477,
      "grad_norm": 0.9918294548988342,
      "learning_rate": 7.850870376126826e-06,
      "loss": 0.4955,
      "step": 5531
    },
    {
      "epoch": 0.42990363692881567,
      "grad_norm": 0.2627007067203522,
      "learning_rate": 7.850481815355923e-06,
      "loss": 0.175,
      "step": 5532
    },
    {
      "epoch": 0.42998134908299657,
      "grad_norm": 0.3809431195259094,
      "learning_rate": 7.850093254585018e-06,
      "loss": 0.2064,
      "step": 5533
    },
    {
      "epoch": 0.4300590612371775,
      "grad_norm": 0.37500855326652527,
      "learning_rate": 7.849704693814113e-06,
      "loss": 0.1587,
      "step": 5534
    },
    {
      "epoch": 0.4301367733913584,
      "grad_norm": 0.48106345534324646,
      "learning_rate": 7.84931613304321e-06,
      "loss": 0.6748,
      "step": 5535
    },
    {
      "epoch": 0.4302144855455393,
      "grad_norm": 0.15417857468128204,
      "learning_rate": 7.848927572272304e-06,
      "loss": 0.0469,
      "step": 5536
    },
    {
      "epoch": 0.4302921976997202,
      "grad_norm": 0.338462769985199,
      "learning_rate": 7.848539011501399e-06,
      "loss": 0.1076,
      "step": 5537
    },
    {
      "epoch": 0.43036990985390117,
      "grad_norm": 0.49352046847343445,
      "learning_rate": 7.848150450730496e-06,
      "loss": 0.2424,
      "step": 5538
    },
    {
      "epoch": 0.43044762200808206,
      "grad_norm": 0.035632796585559845,
      "learning_rate": 7.84776188995959e-06,
      "loss": 0.0085,
      "step": 5539
    },
    {
      "epoch": 0.43052533416226296,
      "grad_norm": 0.09890581667423248,
      "learning_rate": 7.847373329188686e-06,
      "loss": 0.0759,
      "step": 5540
    },
    {
      "epoch": 0.4306030463164439,
      "grad_norm": 0.24521353840827942,
      "learning_rate": 7.84698476841778e-06,
      "loss": 0.0509,
      "step": 5541
    },
    {
      "epoch": 0.4306807584706248,
      "grad_norm": 1.6632322072982788,
      "learning_rate": 7.846596207646877e-06,
      "loss": 0.4474,
      "step": 5542
    },
    {
      "epoch": 0.4307584706248057,
      "grad_norm": 0.2466893494129181,
      "learning_rate": 7.846207646875972e-06,
      "loss": 0.0666,
      "step": 5543
    },
    {
      "epoch": 0.4308361827789866,
      "grad_norm": 0.31763797998428345,
      "learning_rate": 7.845819086105067e-06,
      "loss": 0.2537,
      "step": 5544
    },
    {
      "epoch": 0.43091389493316756,
      "grad_norm": 0.9716278314590454,
      "learning_rate": 7.845430525334164e-06,
      "loss": 0.5308,
      "step": 5545
    },
    {
      "epoch": 0.43099160708734846,
      "grad_norm": 0.48699280619621277,
      "learning_rate": 7.845041964563259e-06,
      "loss": 0.3315,
      "step": 5546
    },
    {
      "epoch": 0.43106931924152936,
      "grad_norm": 0.9607455730438232,
      "learning_rate": 7.844653403792354e-06,
      "loss": 0.3871,
      "step": 5547
    },
    {
      "epoch": 0.4311470313957103,
      "grad_norm": 0.46872174739837646,
      "learning_rate": 7.84426484302145e-06,
      "loss": 0.0534,
      "step": 5548
    },
    {
      "epoch": 0.4312247435498912,
      "grad_norm": 0.25796931982040405,
      "learning_rate": 7.843876282250544e-06,
      "loss": 0.1307,
      "step": 5549
    },
    {
      "epoch": 0.4313024557040721,
      "grad_norm": 0.2049301117658615,
      "learning_rate": 7.84348772147964e-06,
      "loss": 0.1476,
      "step": 5550
    },
    {
      "epoch": 0.431380167858253,
      "grad_norm": 0.4310629367828369,
      "learning_rate": 7.843099160708735e-06,
      "loss": 0.2473,
      "step": 5551
    },
    {
      "epoch": 0.43145788001243396,
      "grad_norm": 0.2745000123977661,
      "learning_rate": 7.84271059993783e-06,
      "loss": 0.1383,
      "step": 5552
    },
    {
      "epoch": 0.43153559216661486,
      "grad_norm": 0.19784776866436005,
      "learning_rate": 7.842322039166927e-06,
      "loss": 0.0766,
      "step": 5553
    },
    {
      "epoch": 0.43161330432079575,
      "grad_norm": 0.8505277633666992,
      "learning_rate": 7.841933478396022e-06,
      "loss": 0.2799,
      "step": 5554
    },
    {
      "epoch": 0.4316910164749767,
      "grad_norm": 0.290601909160614,
      "learning_rate": 7.841544917625117e-06,
      "loss": 0.0836,
      "step": 5555
    },
    {
      "epoch": 0.4317687286291576,
      "grad_norm": 0.5583800673484802,
      "learning_rate": 7.841156356854213e-06,
      "loss": 0.3466,
      "step": 5556
    },
    {
      "epoch": 0.4318464407833385,
      "grad_norm": 0.5542705059051514,
      "learning_rate": 7.840767796083308e-06,
      "loss": 1.3187,
      "step": 5557
    },
    {
      "epoch": 0.4319241529375194,
      "grad_norm": 0.21275866031646729,
      "learning_rate": 7.840379235312403e-06,
      "loss": 0.0902,
      "step": 5558
    },
    {
      "epoch": 0.43200186509170035,
      "grad_norm": 0.6925176382064819,
      "learning_rate": 7.839990674541498e-06,
      "loss": 0.1028,
      "step": 5559
    },
    {
      "epoch": 0.43207957724588125,
      "grad_norm": 0.21234217286109924,
      "learning_rate": 7.839602113770595e-06,
      "loss": 0.1248,
      "step": 5560
    },
    {
      "epoch": 0.43215728940006215,
      "grad_norm": 0.2363526076078415,
      "learning_rate": 7.83921355299969e-06,
      "loss": 0.0418,
      "step": 5561
    },
    {
      "epoch": 0.4322350015542431,
      "grad_norm": 0.48319053649902344,
      "learning_rate": 7.838824992228785e-06,
      "loss": 0.1822,
      "step": 5562
    },
    {
      "epoch": 0.432312713708424,
      "grad_norm": 0.600475549697876,
      "learning_rate": 7.838436431457881e-06,
      "loss": 0.7493,
      "step": 5563
    },
    {
      "epoch": 0.4323904258626049,
      "grad_norm": 0.1835509091615677,
      "learning_rate": 7.838047870686976e-06,
      "loss": 0.1087,
      "step": 5564
    },
    {
      "epoch": 0.43246813801678585,
      "grad_norm": 0.365812212228775,
      "learning_rate": 7.837659309916071e-06,
      "loss": 0.0985,
      "step": 5565
    },
    {
      "epoch": 0.43254585017096675,
      "grad_norm": 0.15348847210407257,
      "learning_rate": 7.837270749145168e-06,
      "loss": 0.0523,
      "step": 5566
    },
    {
      "epoch": 0.43262356232514765,
      "grad_norm": 0.42765671014785767,
      "learning_rate": 7.836882188374261e-06,
      "loss": 0.3138,
      "step": 5567
    },
    {
      "epoch": 0.43270127447932855,
      "grad_norm": 0.44290590286254883,
      "learning_rate": 7.836493627603358e-06,
      "loss": 0.4298,
      "step": 5568
    },
    {
      "epoch": 0.4327789866335095,
      "grad_norm": 0.3981776833534241,
      "learning_rate": 7.836105066832453e-06,
      "loss": 0.1383,
      "step": 5569
    },
    {
      "epoch": 0.4328566987876904,
      "grad_norm": 0.18357598781585693,
      "learning_rate": 7.83571650606155e-06,
      "loss": 0.1089,
      "step": 5570
    },
    {
      "epoch": 0.4329344109418713,
      "grad_norm": 0.09715556353330612,
      "learning_rate": 7.835327945290644e-06,
      "loss": 0.0199,
      "step": 5571
    },
    {
      "epoch": 0.43301212309605225,
      "grad_norm": 0.8067864179611206,
      "learning_rate": 7.83493938451974e-06,
      "loss": 0.4872,
      "step": 5572
    },
    {
      "epoch": 0.43308983525023315,
      "grad_norm": 0.032955750823020935,
      "learning_rate": 7.834550823748836e-06,
      "loss": 0.004,
      "step": 5573
    },
    {
      "epoch": 0.43316754740441404,
      "grad_norm": 0.37839633226394653,
      "learning_rate": 7.834162262977931e-06,
      "loss": 0.112,
      "step": 5574
    },
    {
      "epoch": 0.43324525955859494,
      "grad_norm": 0.4017895460128784,
      "learning_rate": 7.833773702207026e-06,
      "loss": 0.222,
      "step": 5575
    },
    {
      "epoch": 0.4333229717127759,
      "grad_norm": 0.2135610431432724,
      "learning_rate": 7.833385141436122e-06,
      "loss": 0.0549,
      "step": 5576
    },
    {
      "epoch": 0.4334006838669568,
      "grad_norm": 0.3866879343986511,
      "learning_rate": 7.832996580665216e-06,
      "loss": 0.1258,
      "step": 5577
    },
    {
      "epoch": 0.4334783960211377,
      "grad_norm": 0.7024663090705872,
      "learning_rate": 7.832608019894312e-06,
      "loss": 0.5923,
      "step": 5578
    },
    {
      "epoch": 0.43355610817531864,
      "grad_norm": 0.33364397287368774,
      "learning_rate": 7.832219459123407e-06,
      "loss": 0.4267,
      "step": 5579
    },
    {
      "epoch": 0.43363382032949954,
      "grad_norm": 0.22460800409317017,
      "learning_rate": 7.831830898352502e-06,
      "loss": 0.0868,
      "step": 5580
    },
    {
      "epoch": 0.43371153248368044,
      "grad_norm": 0.3433138132095337,
      "learning_rate": 7.831442337581599e-06,
      "loss": 0.1119,
      "step": 5581
    },
    {
      "epoch": 0.43378924463786134,
      "grad_norm": 0.1624433845281601,
      "learning_rate": 7.831053776810694e-06,
      "loss": 0.1039,
      "step": 5582
    },
    {
      "epoch": 0.4338669567920423,
      "grad_norm": 0.30136731266975403,
      "learning_rate": 7.830665216039789e-06,
      "loss": 0.0856,
      "step": 5583
    },
    {
      "epoch": 0.4339446689462232,
      "grad_norm": 0.7933450937271118,
      "learning_rate": 7.830276655268885e-06,
      "loss": 0.0832,
      "step": 5584
    },
    {
      "epoch": 0.4340223811004041,
      "grad_norm": 0.29931336641311646,
      "learning_rate": 7.82988809449798e-06,
      "loss": 0.232,
      "step": 5585
    },
    {
      "epoch": 0.43410009325458504,
      "grad_norm": 0.31341344118118286,
      "learning_rate": 7.829499533727075e-06,
      "loss": 0.2003,
      "step": 5586
    },
    {
      "epoch": 0.43417780540876594,
      "grad_norm": 0.18004456162452698,
      "learning_rate": 7.82911097295617e-06,
      "loss": 0.0805,
      "step": 5587
    },
    {
      "epoch": 0.43425551756294684,
      "grad_norm": 0.570073664188385,
      "learning_rate": 7.828722412185267e-06,
      "loss": 0.3814,
      "step": 5588
    },
    {
      "epoch": 0.43433322971712773,
      "grad_norm": 0.1403878629207611,
      "learning_rate": 7.828333851414362e-06,
      "loss": 0.0112,
      "step": 5589
    },
    {
      "epoch": 0.4344109418713087,
      "grad_norm": 0.11956460028886795,
      "learning_rate": 7.827945290643457e-06,
      "loss": 0.0843,
      "step": 5590
    },
    {
      "epoch": 0.4344886540254896,
      "grad_norm": 0.17162784934043884,
      "learning_rate": 7.827556729872553e-06,
      "loss": 0.0554,
      "step": 5591
    },
    {
      "epoch": 0.4345663661796705,
      "grad_norm": 0.11486813426017761,
      "learning_rate": 7.827168169101648e-06,
      "loss": 0.0295,
      "step": 5592
    },
    {
      "epoch": 0.43464407833385144,
      "grad_norm": 0.1551143079996109,
      "learning_rate": 7.826779608330743e-06,
      "loss": 0.0675,
      "step": 5593
    },
    {
      "epoch": 0.43472179048803233,
      "grad_norm": 0.359560489654541,
      "learning_rate": 7.82639104755984e-06,
      "loss": 0.3362,
      "step": 5594
    },
    {
      "epoch": 0.43479950264221323,
      "grad_norm": 0.45937052369117737,
      "learning_rate": 7.826002486788933e-06,
      "loss": 0.2735,
      "step": 5595
    },
    {
      "epoch": 0.43487721479639413,
      "grad_norm": 0.5819528698921204,
      "learning_rate": 7.82561392601803e-06,
      "loss": 0.1526,
      "step": 5596
    },
    {
      "epoch": 0.4349549269505751,
      "grad_norm": 0.27386540174484253,
      "learning_rate": 7.825225365247125e-06,
      "loss": 0.1067,
      "step": 5597
    },
    {
      "epoch": 0.435032639104756,
      "grad_norm": 0.25583741068840027,
      "learning_rate": 7.82483680447622e-06,
      "loss": 0.0816,
      "step": 5598
    },
    {
      "epoch": 0.4351103512589369,
      "grad_norm": 0.22942668199539185,
      "learning_rate": 7.824448243705316e-06,
      "loss": 0.1617,
      "step": 5599
    },
    {
      "epoch": 0.43518806341311783,
      "grad_norm": 0.10035838931798935,
      "learning_rate": 7.824059682934411e-06,
      "loss": 0.0447,
      "step": 5600
    },
    {
      "epoch": 0.43526577556729873,
      "grad_norm": 0.644311785697937,
      "learning_rate": 7.823671122163508e-06,
      "loss": 0.251,
      "step": 5601
    },
    {
      "epoch": 0.4353434877214796,
      "grad_norm": 0.18623992800712585,
      "learning_rate": 7.823282561392603e-06,
      "loss": 0.0963,
      "step": 5602
    },
    {
      "epoch": 0.4354211998756606,
      "grad_norm": 0.5705534219741821,
      "learning_rate": 7.822894000621698e-06,
      "loss": 0.1778,
      "step": 5603
    },
    {
      "epoch": 0.4354989120298415,
      "grad_norm": 0.2961917519569397,
      "learning_rate": 7.822505439850795e-06,
      "loss": 0.2375,
      "step": 5604
    },
    {
      "epoch": 0.4355766241840224,
      "grad_norm": 0.10481537133455276,
      "learning_rate": 7.822116879079888e-06,
      "loss": 0.0159,
      "step": 5605
    },
    {
      "epoch": 0.4356543363382033,
      "grad_norm": 0.1664341688156128,
      "learning_rate": 7.821728318308985e-06,
      "loss": 0.0378,
      "step": 5606
    },
    {
      "epoch": 0.4357320484923842,
      "grad_norm": 0.12057662755250931,
      "learning_rate": 7.82133975753808e-06,
      "loss": 0.0291,
      "step": 5607
    },
    {
      "epoch": 0.4358097606465651,
      "grad_norm": 0.3583916127681732,
      "learning_rate": 7.820951196767174e-06,
      "loss": 0.2137,
      "step": 5608
    },
    {
      "epoch": 0.435887472800746,
      "grad_norm": 0.4349517822265625,
      "learning_rate": 7.820562635996271e-06,
      "loss": 0.572,
      "step": 5609
    },
    {
      "epoch": 0.435965184954927,
      "grad_norm": 0.2580903172492981,
      "learning_rate": 7.820174075225366e-06,
      "loss": 0.1126,
      "step": 5610
    },
    {
      "epoch": 0.4360428971091079,
      "grad_norm": 0.08990988880395889,
      "learning_rate": 7.819785514454461e-06,
      "loss": 0.0402,
      "step": 5611
    },
    {
      "epoch": 0.43612060926328877,
      "grad_norm": 0.5783153772354126,
      "learning_rate": 7.819396953683558e-06,
      "loss": 0.218,
      "step": 5612
    },
    {
      "epoch": 0.43619832141746967,
      "grad_norm": 0.2131430208683014,
      "learning_rate": 7.819008392912653e-06,
      "loss": 0.0865,
      "step": 5613
    },
    {
      "epoch": 0.4362760335716506,
      "grad_norm": 0.6972929835319519,
      "learning_rate": 7.818619832141748e-06,
      "loss": 0.1232,
      "step": 5614
    },
    {
      "epoch": 0.4363537457258315,
      "grad_norm": 0.28091198205947876,
      "learning_rate": 7.818231271370842e-06,
      "loss": 0.1897,
      "step": 5615
    },
    {
      "epoch": 0.4364314578800124,
      "grad_norm": 0.3772388994693756,
      "learning_rate": 7.817842710599939e-06,
      "loss": 0.184,
      "step": 5616
    },
    {
      "epoch": 0.4365091700341934,
      "grad_norm": 0.28275322914123535,
      "learning_rate": 7.817454149829034e-06,
      "loss": 0.087,
      "step": 5617
    },
    {
      "epoch": 0.43658688218837427,
      "grad_norm": 0.3563711643218994,
      "learning_rate": 7.817065589058129e-06,
      "loss": 0.143,
      "step": 5618
    },
    {
      "epoch": 0.43666459434255517,
      "grad_norm": 0.5123684406280518,
      "learning_rate": 7.816677028287226e-06,
      "loss": 0.1975,
      "step": 5619
    },
    {
      "epoch": 0.43674230649673607,
      "grad_norm": 0.34148284792900085,
      "learning_rate": 7.81628846751632e-06,
      "loss": 0.0909,
      "step": 5620
    },
    {
      "epoch": 0.436820018650917,
      "grad_norm": 0.7822409868240356,
      "learning_rate": 7.815899906745416e-06,
      "loss": 0.4,
      "step": 5621
    },
    {
      "epoch": 0.4368977308050979,
      "grad_norm": 0.2829231917858124,
      "learning_rate": 7.81551134597451e-06,
      "loss": 0.1359,
      "step": 5622
    },
    {
      "epoch": 0.4369754429592788,
      "grad_norm": 0.23497214913368225,
      "learning_rate": 7.815122785203605e-06,
      "loss": 0.0685,
      "step": 5623
    },
    {
      "epoch": 0.43705315511345977,
      "grad_norm": 0.30065590143203735,
      "learning_rate": 7.814734224432702e-06,
      "loss": 0.1605,
      "step": 5624
    },
    {
      "epoch": 0.43713086726764067,
      "grad_norm": 0.33264869451522827,
      "learning_rate": 7.814345663661797e-06,
      "loss": 0.1802,
      "step": 5625
    },
    {
      "epoch": 0.43720857942182156,
      "grad_norm": 0.08261337876319885,
      "learning_rate": 7.813957102890892e-06,
      "loss": 0.0222,
      "step": 5626
    },
    {
      "epoch": 0.43728629157600246,
      "grad_norm": 0.27262985706329346,
      "learning_rate": 7.813568542119989e-06,
      "loss": 0.199,
      "step": 5627
    },
    {
      "epoch": 0.4373640037301834,
      "grad_norm": 0.5119444131851196,
      "learning_rate": 7.813179981349084e-06,
      "loss": 0.7525,
      "step": 5628
    },
    {
      "epoch": 0.4374417158843643,
      "grad_norm": 0.14669759571552277,
      "learning_rate": 7.812791420578179e-06,
      "loss": 0.0469,
      "step": 5629
    },
    {
      "epoch": 0.4375194280385452,
      "grad_norm": 0.8431745171546936,
      "learning_rate": 7.812402859807273e-06,
      "loss": 0.3333,
      "step": 5630
    },
    {
      "epoch": 0.43759714019272616,
      "grad_norm": 0.06730151176452637,
      "learning_rate": 7.81201429903637e-06,
      "loss": 0.0098,
      "step": 5631
    },
    {
      "epoch": 0.43767485234690706,
      "grad_norm": 0.27709832787513733,
      "learning_rate": 7.811625738265465e-06,
      "loss": 0.0943,
      "step": 5632
    },
    {
      "epoch": 0.43775256450108796,
      "grad_norm": 0.17709462344646454,
      "learning_rate": 7.81123717749456e-06,
      "loss": 0.0633,
      "step": 5633
    },
    {
      "epoch": 0.43783027665526886,
      "grad_norm": 0.7204132676124573,
      "learning_rate": 7.810848616723657e-06,
      "loss": 0.7134,
      "step": 5634
    },
    {
      "epoch": 0.4379079888094498,
      "grad_norm": 0.43107762932777405,
      "learning_rate": 7.810460055952752e-06,
      "loss": 0.2138,
      "step": 5635
    },
    {
      "epoch": 0.4379857009636307,
      "grad_norm": 0.2826685905456543,
      "learning_rate": 7.810071495181847e-06,
      "loss": 0.0825,
      "step": 5636
    },
    {
      "epoch": 0.4380634131178116,
      "grad_norm": 0.5017817616462708,
      "learning_rate": 7.809682934410943e-06,
      "loss": 0.4322,
      "step": 5637
    },
    {
      "epoch": 0.43814112527199256,
      "grad_norm": 0.9436925053596497,
      "learning_rate": 7.809294373640038e-06,
      "loss": 0.4941,
      "step": 5638
    },
    {
      "epoch": 0.43821883742617346,
      "grad_norm": 0.48679956793785095,
      "learning_rate": 7.808905812869133e-06,
      "loss": 0.3329,
      "step": 5639
    },
    {
      "epoch": 0.43829654958035436,
      "grad_norm": 0.3259842097759247,
      "learning_rate": 7.808517252098228e-06,
      "loss": 0.253,
      "step": 5640
    },
    {
      "epoch": 0.4383742617345353,
      "grad_norm": 0.25781551003456116,
      "learning_rate": 7.808128691327325e-06,
      "loss": 0.134,
      "step": 5641
    },
    {
      "epoch": 0.4384519738887162,
      "grad_norm": 0.2644049823284149,
      "learning_rate": 7.80774013055642e-06,
      "loss": 0.1516,
      "step": 5642
    },
    {
      "epoch": 0.4385296860428971,
      "grad_norm": 0.2152208685874939,
      "learning_rate": 7.807351569785515e-06,
      "loss": 0.0953,
      "step": 5643
    },
    {
      "epoch": 0.438607398197078,
      "grad_norm": 0.23507624864578247,
      "learning_rate": 7.806963009014611e-06,
      "loss": 0.0695,
      "step": 5644
    },
    {
      "epoch": 0.43868511035125896,
      "grad_norm": 0.24904420971870422,
      "learning_rate": 7.806574448243706e-06,
      "loss": 0.0892,
      "step": 5645
    },
    {
      "epoch": 0.43876282250543985,
      "grad_norm": 0.1943696290254593,
      "learning_rate": 7.806185887472801e-06,
      "loss": 0.0961,
      "step": 5646
    },
    {
      "epoch": 0.43884053465962075,
      "grad_norm": 0.13603536784648895,
      "learning_rate": 7.805797326701898e-06,
      "loss": 0.0497,
      "step": 5647
    },
    {
      "epoch": 0.4389182468138017,
      "grad_norm": 0.15415869653224945,
      "learning_rate": 7.805408765930991e-06,
      "loss": 0.0322,
      "step": 5648
    },
    {
      "epoch": 0.4389959589679826,
      "grad_norm": 0.2028251439332962,
      "learning_rate": 7.805020205160088e-06,
      "loss": 0.0611,
      "step": 5649
    },
    {
      "epoch": 0.4390736711221635,
      "grad_norm": 0.047998566180467606,
      "learning_rate": 7.804631644389183e-06,
      "loss": 0.01,
      "step": 5650
    },
    {
      "epoch": 0.4391513832763444,
      "grad_norm": 0.7118031978607178,
      "learning_rate": 7.804243083618278e-06,
      "loss": 0.0792,
      "step": 5651
    },
    {
      "epoch": 0.43922909543052535,
      "grad_norm": 0.4119691550731659,
      "learning_rate": 7.803854522847374e-06,
      "loss": 0.2008,
      "step": 5652
    },
    {
      "epoch": 0.43930680758470625,
      "grad_norm": 0.5596392154693604,
      "learning_rate": 7.80346596207647e-06,
      "loss": 0.1975,
      "step": 5653
    },
    {
      "epoch": 0.43938451973888715,
      "grad_norm": 0.13881780207157135,
      "learning_rate": 7.803077401305564e-06,
      "loss": 0.0325,
      "step": 5654
    },
    {
      "epoch": 0.4394622318930681,
      "grad_norm": 0.29907771944999695,
      "learning_rate": 7.80268884053466e-06,
      "loss": 0.0934,
      "step": 5655
    },
    {
      "epoch": 0.439539944047249,
      "grad_norm": 0.14056162536144257,
      "learning_rate": 7.802300279763756e-06,
      "loss": 0.0171,
      "step": 5656
    },
    {
      "epoch": 0.4396176562014299,
      "grad_norm": 0.08834332972764969,
      "learning_rate": 7.80191171899285e-06,
      "loss": 0.0212,
      "step": 5657
    },
    {
      "epoch": 0.4396953683556108,
      "grad_norm": 0.1228768602013588,
      "learning_rate": 7.801523158221946e-06,
      "loss": 0.0448,
      "step": 5658
    },
    {
      "epoch": 0.43977308050979175,
      "grad_norm": 0.4473601281642914,
      "learning_rate": 7.801134597451042e-06,
      "loss": 0.1605,
      "step": 5659
    },
    {
      "epoch": 0.43985079266397265,
      "grad_norm": 0.4110126495361328,
      "learning_rate": 7.800746036680137e-06,
      "loss": 0.2404,
      "step": 5660
    },
    {
      "epoch": 0.43992850481815354,
      "grad_norm": 0.19312746822834015,
      "learning_rate": 7.800357475909232e-06,
      "loss": 0.1003,
      "step": 5661
    },
    {
      "epoch": 0.4400062169723345,
      "grad_norm": 0.34736573696136475,
      "learning_rate": 7.799968915138329e-06,
      "loss": 0.1447,
      "step": 5662
    },
    {
      "epoch": 0.4400839291265154,
      "grad_norm": 0.3897961974143982,
      "learning_rate": 7.799580354367424e-06,
      "loss": 0.2175,
      "step": 5663
    },
    {
      "epoch": 0.4401616412806963,
      "grad_norm": 0.48721396923065186,
      "learning_rate": 7.799191793596519e-06,
      "loss": 0.1228,
      "step": 5664
    },
    {
      "epoch": 0.4402393534348772,
      "grad_norm": 0.21623916923999786,
      "learning_rate": 7.798803232825615e-06,
      "loss": 0.0952,
      "step": 5665
    },
    {
      "epoch": 0.44031706558905814,
      "grad_norm": 0.1982453465461731,
      "learning_rate": 7.79841467205471e-06,
      "loss": 0.0448,
      "step": 5666
    },
    {
      "epoch": 0.44039477774323904,
      "grad_norm": 0.8636532425880432,
      "learning_rate": 7.798026111283805e-06,
      "loss": 0.6859,
      "step": 5667
    },
    {
      "epoch": 0.44047248989741994,
      "grad_norm": 0.2135830968618393,
      "learning_rate": 7.7976375505129e-06,
      "loss": 0.0842,
      "step": 5668
    },
    {
      "epoch": 0.4405502020516009,
      "grad_norm": 0.3015099763870239,
      "learning_rate": 7.797248989741997e-06,
      "loss": 0.0914,
      "step": 5669
    },
    {
      "epoch": 0.4406279142057818,
      "grad_norm": 0.08528327941894531,
      "learning_rate": 7.796860428971092e-06,
      "loss": 0.0162,
      "step": 5670
    },
    {
      "epoch": 0.4407056263599627,
      "grad_norm": 0.4861958920955658,
      "learning_rate": 7.796471868200187e-06,
      "loss": 0.1486,
      "step": 5671
    },
    {
      "epoch": 0.4407833385141436,
      "grad_norm": 0.2222099006175995,
      "learning_rate": 7.796083307429283e-06,
      "loss": 0.103,
      "step": 5672
    },
    {
      "epoch": 0.44086105066832454,
      "grad_norm": 0.3245975077152252,
      "learning_rate": 7.795694746658378e-06,
      "loss": 0.1391,
      "step": 5673
    },
    {
      "epoch": 0.44093876282250544,
      "grad_norm": 0.42869001626968384,
      "learning_rate": 7.795306185887473e-06,
      "loss": 0.3034,
      "step": 5674
    },
    {
      "epoch": 0.44101647497668633,
      "grad_norm": 0.18134264647960663,
      "learning_rate": 7.79491762511657e-06,
      "loss": 0.0483,
      "step": 5675
    },
    {
      "epoch": 0.4410941871308673,
      "grad_norm": 0.2485959231853485,
      "learning_rate": 7.794529064345663e-06,
      "loss": 0.1018,
      "step": 5676
    },
    {
      "epoch": 0.4411718992850482,
      "grad_norm": 0.17225612699985504,
      "learning_rate": 7.79414050357476e-06,
      "loss": 0.0586,
      "step": 5677
    },
    {
      "epoch": 0.4412496114392291,
      "grad_norm": 0.05818630009889603,
      "learning_rate": 7.793751942803855e-06,
      "loss": 0.0103,
      "step": 5678
    },
    {
      "epoch": 0.44132732359341004,
      "grad_norm": 0.18699580430984497,
      "learning_rate": 7.79336338203295e-06,
      "loss": 0.0758,
      "step": 5679
    },
    {
      "epoch": 0.44140503574759093,
      "grad_norm": 0.32774510979652405,
      "learning_rate": 7.792974821262046e-06,
      "loss": 0.1703,
      "step": 5680
    },
    {
      "epoch": 0.44148274790177183,
      "grad_norm": 1.4338284730911255,
      "learning_rate": 7.792586260491141e-06,
      "loss": 0.822,
      "step": 5681
    },
    {
      "epoch": 0.44156046005595273,
      "grad_norm": 0.2580065131187439,
      "learning_rate": 7.792197699720236e-06,
      "loss": 0.1576,
      "step": 5682
    },
    {
      "epoch": 0.4416381722101337,
      "grad_norm": 0.4703981280326843,
      "learning_rate": 7.791809138949333e-06,
      "loss": 0.2483,
      "step": 5683
    },
    {
      "epoch": 0.4417158843643146,
      "grad_norm": 0.4212467074394226,
      "learning_rate": 7.791420578178428e-06,
      "loss": 0.2613,
      "step": 5684
    },
    {
      "epoch": 0.4417935965184955,
      "grad_norm": 0.28624099493026733,
      "learning_rate": 7.791032017407523e-06,
      "loss": 0.0789,
      "step": 5685
    },
    {
      "epoch": 0.44187130867267643,
      "grad_norm": 0.21052104234695435,
      "learning_rate": 7.790643456636618e-06,
      "loss": 0.0884,
      "step": 5686
    },
    {
      "epoch": 0.44194902082685733,
      "grad_norm": 0.21841265261173248,
      "learning_rate": 7.790254895865714e-06,
      "loss": 0.0892,
      "step": 5687
    },
    {
      "epoch": 0.44202673298103823,
      "grad_norm": 0.1562076359987259,
      "learning_rate": 7.78986633509481e-06,
      "loss": 0.088,
      "step": 5688
    },
    {
      "epoch": 0.4421044451352191,
      "grad_norm": 0.6994473338127136,
      "learning_rate": 7.789477774323904e-06,
      "loss": 0.189,
      "step": 5689
    },
    {
      "epoch": 0.4421821572894001,
      "grad_norm": 0.18416568636894226,
      "learning_rate": 7.789089213553001e-06,
      "loss": 0.0971,
      "step": 5690
    },
    {
      "epoch": 0.442259869443581,
      "grad_norm": 0.2547443211078644,
      "learning_rate": 7.788700652782096e-06,
      "loss": 0.0882,
      "step": 5691
    },
    {
      "epoch": 0.4423375815977619,
      "grad_norm": 0.5228924751281738,
      "learning_rate": 7.788312092011191e-06,
      "loss": 0.1658,
      "step": 5692
    },
    {
      "epoch": 0.44241529375194283,
      "grad_norm": 0.3215712904930115,
      "learning_rate": 7.787923531240287e-06,
      "loss": 0.0835,
      "step": 5693
    },
    {
      "epoch": 0.4424930059061237,
      "grad_norm": 0.6542723774909973,
      "learning_rate": 7.787534970469382e-06,
      "loss": 0.2046,
      "step": 5694
    },
    {
      "epoch": 0.4425707180603046,
      "grad_norm": 0.06699495017528534,
      "learning_rate": 7.787146409698477e-06,
      "loss": 0.0117,
      "step": 5695
    },
    {
      "epoch": 0.4426484302144855,
      "grad_norm": 0.36346814036369324,
      "learning_rate": 7.786757848927572e-06,
      "loss": 0.3596,
      "step": 5696
    },
    {
      "epoch": 0.4427261423686665,
      "grad_norm": 0.46917930245399475,
      "learning_rate": 7.786369288156669e-06,
      "loss": 0.21,
      "step": 5697
    },
    {
      "epoch": 0.4428038545228474,
      "grad_norm": 0.5376502275466919,
      "learning_rate": 7.785980727385764e-06,
      "loss": 0.2051,
      "step": 5698
    },
    {
      "epoch": 0.44288156667702827,
      "grad_norm": 0.06513257324695587,
      "learning_rate": 7.785592166614859e-06,
      "loss": 0.0132,
      "step": 5699
    },
    {
      "epoch": 0.4429592788312092,
      "grad_norm": 0.6540224552154541,
      "learning_rate": 7.785203605843956e-06,
      "loss": 0.208,
      "step": 5700
    },
    {
      "epoch": 0.4430369909853901,
      "grad_norm": 0.17659299075603485,
      "learning_rate": 7.78481504507305e-06,
      "loss": 0.1379,
      "step": 5701
    },
    {
      "epoch": 0.443114703139571,
      "grad_norm": 0.2512700855731964,
      "learning_rate": 7.784426484302145e-06,
      "loss": 0.1782,
      "step": 5702
    },
    {
      "epoch": 0.4431924152937519,
      "grad_norm": 0.4755041003227234,
      "learning_rate": 7.784037923531242e-06,
      "loss": 0.1286,
      "step": 5703
    },
    {
      "epoch": 0.44327012744793287,
      "grad_norm": 0.3953265845775604,
      "learning_rate": 7.783649362760335e-06,
      "loss": 0.3632,
      "step": 5704
    },
    {
      "epoch": 0.44334783960211377,
      "grad_norm": 0.4553280174732208,
      "learning_rate": 7.783260801989432e-06,
      "loss": 0.1169,
      "step": 5705
    },
    {
      "epoch": 0.44342555175629467,
      "grad_norm": 0.4884974956512451,
      "learning_rate": 7.782872241218527e-06,
      "loss": 0.1451,
      "step": 5706
    },
    {
      "epoch": 0.4435032639104756,
      "grad_norm": 0.3023937940597534,
      "learning_rate": 7.782483680447622e-06,
      "loss": 0.1759,
      "step": 5707
    },
    {
      "epoch": 0.4435809760646565,
      "grad_norm": 0.24903789162635803,
      "learning_rate": 7.782095119676719e-06,
      "loss": 0.1223,
      "step": 5708
    },
    {
      "epoch": 0.4436586882188374,
      "grad_norm": 0.27350765466690063,
      "learning_rate": 7.781706558905813e-06,
      "loss": 0.1898,
      "step": 5709
    },
    {
      "epoch": 0.4437364003730183,
      "grad_norm": 0.14822718501091003,
      "learning_rate": 7.781317998134908e-06,
      "loss": 0.0729,
      "step": 5710
    },
    {
      "epoch": 0.44381411252719927,
      "grad_norm": 0.2040875256061554,
      "learning_rate": 7.780929437364005e-06,
      "loss": 0.1556,
      "step": 5711
    },
    {
      "epoch": 0.44389182468138016,
      "grad_norm": 0.08134354650974274,
      "learning_rate": 7.7805408765931e-06,
      "loss": 0.0127,
      "step": 5712
    },
    {
      "epoch": 0.44396953683556106,
      "grad_norm": 0.33735811710357666,
      "learning_rate": 7.780152315822195e-06,
      "loss": 0.0923,
      "step": 5713
    },
    {
      "epoch": 0.444047248989742,
      "grad_norm": 0.33814939856529236,
      "learning_rate": 7.77976375505129e-06,
      "loss": 0.3863,
      "step": 5714
    },
    {
      "epoch": 0.4441249611439229,
      "grad_norm": 0.3041362166404724,
      "learning_rate": 7.779375194280387e-06,
      "loss": 0.0611,
      "step": 5715
    },
    {
      "epoch": 0.4442026732981038,
      "grad_norm": 0.05634591728448868,
      "learning_rate": 7.778986633509482e-06,
      "loss": 0.0237,
      "step": 5716
    },
    {
      "epoch": 0.44428038545228477,
      "grad_norm": 0.2545226514339447,
      "learning_rate": 7.778598072738576e-06,
      "loss": 0.1588,
      "step": 5717
    },
    {
      "epoch": 0.44435809760646566,
      "grad_norm": 0.18533039093017578,
      "learning_rate": 7.778209511967673e-06,
      "loss": 0.0406,
      "step": 5718
    },
    {
      "epoch": 0.44443580976064656,
      "grad_norm": 0.4333965480327606,
      "learning_rate": 7.777820951196768e-06,
      "loss": 0.1616,
      "step": 5719
    },
    {
      "epoch": 0.44451352191482746,
      "grad_norm": 0.5141727328300476,
      "learning_rate": 7.777432390425863e-06,
      "loss": 0.3292,
      "step": 5720
    },
    {
      "epoch": 0.4445912340690084,
      "grad_norm": 0.13420403003692627,
      "learning_rate": 7.77704382965496e-06,
      "loss": 0.028,
      "step": 5721
    },
    {
      "epoch": 0.4446689462231893,
      "grad_norm": 0.2945733666419983,
      "learning_rate": 7.776655268884055e-06,
      "loss": 0.1036,
      "step": 5722
    },
    {
      "epoch": 0.4447466583773702,
      "grad_norm": 0.7856845259666443,
      "learning_rate": 7.77626670811315e-06,
      "loss": 0.2319,
      "step": 5723
    },
    {
      "epoch": 0.44482437053155116,
      "grad_norm": 0.43506574630737305,
      "learning_rate": 7.775878147342244e-06,
      "loss": 0.1598,
      "step": 5724
    },
    {
      "epoch": 0.44490208268573206,
      "grad_norm": 0.2801841199398041,
      "learning_rate": 7.775489586571341e-06,
      "loss": 0.178,
      "step": 5725
    },
    {
      "epoch": 0.44497979483991296,
      "grad_norm": 0.35068216919898987,
      "learning_rate": 7.775101025800436e-06,
      "loss": 0.1008,
      "step": 5726
    },
    {
      "epoch": 0.44505750699409385,
      "grad_norm": 0.33559277653694153,
      "learning_rate": 7.774712465029531e-06,
      "loss": 0.2248,
      "step": 5727
    },
    {
      "epoch": 0.4451352191482748,
      "grad_norm": 0.3460739552974701,
      "learning_rate": 7.774323904258628e-06,
      "loss": 0.122,
      "step": 5728
    },
    {
      "epoch": 0.4452129313024557,
      "grad_norm": 0.6821785569190979,
      "learning_rate": 7.773935343487723e-06,
      "loss": 0.0832,
      "step": 5729
    },
    {
      "epoch": 0.4452906434566366,
      "grad_norm": 0.15732397139072418,
      "learning_rate": 7.773546782716818e-06,
      "loss": 0.0571,
      "step": 5730
    },
    {
      "epoch": 0.44536835561081756,
      "grad_norm": 0.6700318455696106,
      "learning_rate": 7.773158221945914e-06,
      "loss": 0.4366,
      "step": 5731
    },
    {
      "epoch": 0.44544606776499845,
      "grad_norm": 0.5485164523124695,
      "learning_rate": 7.772769661175007e-06,
      "loss": 0.3531,
      "step": 5732
    },
    {
      "epoch": 0.44552377991917935,
      "grad_norm": 0.2435988485813141,
      "learning_rate": 7.772381100404104e-06,
      "loss": 0.0313,
      "step": 5733
    },
    {
      "epoch": 0.44560149207336025,
      "grad_norm": 0.3620500862598419,
      "learning_rate": 7.771992539633199e-06,
      "loss": 0.3244,
      "step": 5734
    },
    {
      "epoch": 0.4456792042275412,
      "grad_norm": 0.1573552042245865,
      "learning_rate": 7.771603978862294e-06,
      "loss": 0.0811,
      "step": 5735
    },
    {
      "epoch": 0.4457569163817221,
      "grad_norm": 0.11582070589065552,
      "learning_rate": 7.77121541809139e-06,
      "loss": 0.0392,
      "step": 5736
    },
    {
      "epoch": 0.445834628535903,
      "grad_norm": 0.6754757761955261,
      "learning_rate": 7.770826857320486e-06,
      "loss": 0.2951,
      "step": 5737
    },
    {
      "epoch": 0.44591234069008395,
      "grad_norm": 0.46032872796058655,
      "learning_rate": 7.77043829654958e-06,
      "loss": 0.098,
      "step": 5738
    },
    {
      "epoch": 0.44599005284426485,
      "grad_norm": 0.0830153077840805,
      "learning_rate": 7.770049735778677e-06,
      "loss": 0.0513,
      "step": 5739
    },
    {
      "epoch": 0.44606776499844575,
      "grad_norm": 0.16361521184444427,
      "learning_rate": 7.769661175007772e-06,
      "loss": 0.095,
      "step": 5740
    },
    {
      "epoch": 0.44614547715262665,
      "grad_norm": 0.09821352362632751,
      "learning_rate": 7.769272614236867e-06,
      "loss": 0.049,
      "step": 5741
    },
    {
      "epoch": 0.4462231893068076,
      "grad_norm": 0.19248196482658386,
      "learning_rate": 7.768884053465962e-06,
      "loss": 0.0825,
      "step": 5742
    },
    {
      "epoch": 0.4463009014609885,
      "grad_norm": 0.4493378698825836,
      "learning_rate": 7.768495492695059e-06,
      "loss": 0.1947,
      "step": 5743
    },
    {
      "epoch": 0.4463786136151694,
      "grad_norm": 0.19476959109306335,
      "learning_rate": 7.768106931924154e-06,
      "loss": 0.0396,
      "step": 5744
    },
    {
      "epoch": 0.44645632576935035,
      "grad_norm": 0.47053033113479614,
      "learning_rate": 7.767718371153249e-06,
      "loss": 0.2374,
      "step": 5745
    },
    {
      "epoch": 0.44653403792353125,
      "grad_norm": 0.34592026472091675,
      "learning_rate": 7.767329810382345e-06,
      "loss": 0.2974,
      "step": 5746
    },
    {
      "epoch": 0.44661175007771214,
      "grad_norm": 0.41509032249450684,
      "learning_rate": 7.76694124961144e-06,
      "loss": 0.4072,
      "step": 5747
    },
    {
      "epoch": 0.44668946223189304,
      "grad_norm": 0.17327682673931122,
      "learning_rate": 7.766552688840535e-06,
      "loss": 0.0937,
      "step": 5748
    },
    {
      "epoch": 0.446767174386074,
      "grad_norm": 0.3200139105319977,
      "learning_rate": 7.76616412806963e-06,
      "loss": 0.0822,
      "step": 5749
    },
    {
      "epoch": 0.4468448865402549,
      "grad_norm": 0.4850757122039795,
      "learning_rate": 7.765775567298725e-06,
      "loss": 0.2404,
      "step": 5750
    },
    {
      "epoch": 0.4469225986944358,
      "grad_norm": 0.2777074873447418,
      "learning_rate": 7.765387006527822e-06,
      "loss": 0.3705,
      "step": 5751
    },
    {
      "epoch": 0.44700031084861674,
      "grad_norm": 0.3869377076625824,
      "learning_rate": 7.764998445756917e-06,
      "loss": 0.1047,
      "step": 5752
    },
    {
      "epoch": 0.44707802300279764,
      "grad_norm": 0.17241019010543823,
      "learning_rate": 7.764609884986013e-06,
      "loss": 0.058,
      "step": 5753
    },
    {
      "epoch": 0.44715573515697854,
      "grad_norm": 1.4883477687835693,
      "learning_rate": 7.764221324215108e-06,
      "loss": 0.746,
      "step": 5754
    },
    {
      "epoch": 0.44723344731115944,
      "grad_norm": 1.0688663721084595,
      "learning_rate": 7.763832763444203e-06,
      "loss": 0.2678,
      "step": 5755
    },
    {
      "epoch": 0.4473111594653404,
      "grad_norm": 0.42601466178894043,
      "learning_rate": 7.7634442026733e-06,
      "loss": 0.1481,
      "step": 5756
    },
    {
      "epoch": 0.4473888716195213,
      "grad_norm": 0.2884750962257385,
      "learning_rate": 7.763055641902393e-06,
      "loss": 0.169,
      "step": 5757
    },
    {
      "epoch": 0.4474665837737022,
      "grad_norm": 0.22554661333560944,
      "learning_rate": 7.76266708113149e-06,
      "loss": 0.1936,
      "step": 5758
    },
    {
      "epoch": 0.44754429592788314,
      "grad_norm": 1.2884279489517212,
      "learning_rate": 7.762278520360585e-06,
      "loss": 0.8797,
      "step": 5759
    },
    {
      "epoch": 0.44762200808206404,
      "grad_norm": 0.42527446150779724,
      "learning_rate": 7.76188995958968e-06,
      "loss": 0.1198,
      "step": 5760
    },
    {
      "epoch": 0.44769972023624494,
      "grad_norm": 0.5510068535804749,
      "learning_rate": 7.761501398818776e-06,
      "loss": 0.2234,
      "step": 5761
    },
    {
      "epoch": 0.4477774323904259,
      "grad_norm": 0.5734753608703613,
      "learning_rate": 7.761112838047871e-06,
      "loss": 0.3243,
      "step": 5762
    },
    {
      "epoch": 0.4478551445446068,
      "grad_norm": 0.28010520339012146,
      "learning_rate": 7.760724277276966e-06,
      "loss": 0.1981,
      "step": 5763
    },
    {
      "epoch": 0.4479328566987877,
      "grad_norm": 0.15293079614639282,
      "learning_rate": 7.760335716506063e-06,
      "loss": 0.0481,
      "step": 5764
    },
    {
      "epoch": 0.4480105688529686,
      "grad_norm": 0.47020187973976135,
      "learning_rate": 7.759947155735158e-06,
      "loss": 0.1938,
      "step": 5765
    },
    {
      "epoch": 0.44808828100714954,
      "grad_norm": 0.38226279616355896,
      "learning_rate": 7.759558594964253e-06,
      "loss": 0.4285,
      "step": 5766
    },
    {
      "epoch": 0.44816599316133043,
      "grad_norm": 0.3997914791107178,
      "learning_rate": 7.759170034193348e-06,
      "loss": 0.2647,
      "step": 5767
    },
    {
      "epoch": 0.44824370531551133,
      "grad_norm": 0.6157105565071106,
      "learning_rate": 7.758781473422444e-06,
      "loss": 0.056,
      "step": 5768
    },
    {
      "epoch": 0.4483214174696923,
      "grad_norm": 0.3435029685497284,
      "learning_rate": 7.75839291265154e-06,
      "loss": 0.2563,
      "step": 5769
    },
    {
      "epoch": 0.4483991296238732,
      "grad_norm": 0.3428694009780884,
      "learning_rate": 7.758004351880634e-06,
      "loss": 0.0511,
      "step": 5770
    },
    {
      "epoch": 0.4484768417780541,
      "grad_norm": 0.49404993653297424,
      "learning_rate": 7.757615791109731e-06,
      "loss": 0.2994,
      "step": 5771
    },
    {
      "epoch": 0.448554553932235,
      "grad_norm": 0.2531921863555908,
      "learning_rate": 7.757227230338826e-06,
      "loss": 0.0811,
      "step": 5772
    },
    {
      "epoch": 0.44863226608641593,
      "grad_norm": 0.3833353519439697,
      "learning_rate": 7.75683866956792e-06,
      "loss": 0.5485,
      "step": 5773
    },
    {
      "epoch": 0.44870997824059683,
      "grad_norm": 0.5512410402297974,
      "learning_rate": 7.756450108797017e-06,
      "loss": 0.555,
      "step": 5774
    },
    {
      "epoch": 0.4487876903947777,
      "grad_norm": 0.3851306438446045,
      "learning_rate": 7.75606154802611e-06,
      "loss": 0.5366,
      "step": 5775
    },
    {
      "epoch": 0.4488654025489587,
      "grad_norm": 0.30073148012161255,
      "learning_rate": 7.755672987255207e-06,
      "loss": 0.2473,
      "step": 5776
    },
    {
      "epoch": 0.4489431147031396,
      "grad_norm": 0.45348796248435974,
      "learning_rate": 7.755284426484302e-06,
      "loss": 0.2999,
      "step": 5777
    },
    {
      "epoch": 0.4490208268573205,
      "grad_norm": 0.5168076157569885,
      "learning_rate": 7.754895865713397e-06,
      "loss": 0.2271,
      "step": 5778
    },
    {
      "epoch": 0.4490985390115014,
      "grad_norm": 0.4494282007217407,
      "learning_rate": 7.754507304942494e-06,
      "loss": 0.499,
      "step": 5779
    },
    {
      "epoch": 0.4491762511656823,
      "grad_norm": 0.6805302500724792,
      "learning_rate": 7.754118744171589e-06,
      "loss": 0.2217,
      "step": 5780
    },
    {
      "epoch": 0.4492539633198632,
      "grad_norm": 0.09735077619552612,
      "learning_rate": 7.753730183400684e-06,
      "loss": 0.0557,
      "step": 5781
    },
    {
      "epoch": 0.4493316754740441,
      "grad_norm": 0.44483324885368347,
      "learning_rate": 7.75334162262978e-06,
      "loss": 0.1821,
      "step": 5782
    },
    {
      "epoch": 0.4494093876282251,
      "grad_norm": 0.5666873455047607,
      "learning_rate": 7.752953061858875e-06,
      "loss": 0.3447,
      "step": 5783
    },
    {
      "epoch": 0.449487099782406,
      "grad_norm": 0.5047902464866638,
      "learning_rate": 7.752564501087972e-06,
      "loss": 0.2621,
      "step": 5784
    },
    {
      "epoch": 0.44956481193658687,
      "grad_norm": 0.34589266777038574,
      "learning_rate": 7.752175940317065e-06,
      "loss": 0.0335,
      "step": 5785
    },
    {
      "epoch": 0.44964252409076777,
      "grad_norm": 0.11516598612070084,
      "learning_rate": 7.751787379546162e-06,
      "loss": 0.0511,
      "step": 5786
    },
    {
      "epoch": 0.4497202362449487,
      "grad_norm": 0.7410493493080139,
      "learning_rate": 7.751398818775257e-06,
      "loss": 0.4925,
      "step": 5787
    },
    {
      "epoch": 0.4497979483991296,
      "grad_norm": 0.48388606309890747,
      "learning_rate": 7.751010258004352e-06,
      "loss": 0.2524,
      "step": 5788
    },
    {
      "epoch": 0.4498756605533105,
      "grad_norm": 0.21100740134716034,
      "learning_rate": 7.750621697233448e-06,
      "loss": 0.0252,
      "step": 5789
    },
    {
      "epoch": 0.4499533727074915,
      "grad_norm": 0.18049457669258118,
      "learning_rate": 7.750233136462543e-06,
      "loss": 0.1216,
      "step": 5790
    },
    {
      "epoch": 0.45003108486167237,
      "grad_norm": 0.30624982714653015,
      "learning_rate": 7.749844575691638e-06,
      "loss": 0.1363,
      "step": 5791
    },
    {
      "epoch": 0.45010879701585327,
      "grad_norm": 0.3409326374530792,
      "learning_rate": 7.749456014920735e-06,
      "loss": 0.1971,
      "step": 5792
    },
    {
      "epoch": 0.45018650917003417,
      "grad_norm": 0.4193960130214691,
      "learning_rate": 7.74906745414983e-06,
      "loss": 0.1833,
      "step": 5793
    },
    {
      "epoch": 0.4502642213242151,
      "grad_norm": 0.7361227869987488,
      "learning_rate": 7.748678893378925e-06,
      "loss": 0.1947,
      "step": 5794
    },
    {
      "epoch": 0.450341933478396,
      "grad_norm": 0.2703405022621155,
      "learning_rate": 7.74829033260802e-06,
      "loss": 0.0781,
      "step": 5795
    },
    {
      "epoch": 0.4504196456325769,
      "grad_norm": 0.49423331022262573,
      "learning_rate": 7.747901771837116e-06,
      "loss": 0.5344,
      "step": 5796
    },
    {
      "epoch": 0.45049735778675787,
      "grad_norm": 2.0336151123046875,
      "learning_rate": 7.747513211066211e-06,
      "loss": 0.2462,
      "step": 5797
    },
    {
      "epoch": 0.45057506994093877,
      "grad_norm": 0.2276172637939453,
      "learning_rate": 7.747124650295306e-06,
      "loss": 0.1196,
      "step": 5798
    },
    {
      "epoch": 0.45065278209511966,
      "grad_norm": 0.6903955340385437,
      "learning_rate": 7.746736089524403e-06,
      "loss": 0.2231,
      "step": 5799
    },
    {
      "epoch": 0.4507304942493006,
      "grad_norm": 0.4429530203342438,
      "learning_rate": 7.746347528753498e-06,
      "loss": 0.1834,
      "step": 5800
    },
    {
      "epoch": 0.4508082064034815,
      "grad_norm": 0.2183530181646347,
      "learning_rate": 7.745958967982593e-06,
      "loss": 0.0862,
      "step": 5801
    },
    {
      "epoch": 0.4508859185576624,
      "grad_norm": 0.5334006547927856,
      "learning_rate": 7.74557040721169e-06,
      "loss": 0.3198,
      "step": 5802
    },
    {
      "epoch": 0.4509636307118433,
      "grad_norm": 0.5481284260749817,
      "learning_rate": 7.745181846440783e-06,
      "loss": 0.1712,
      "step": 5803
    },
    {
      "epoch": 0.45104134286602426,
      "grad_norm": 0.2865948975086212,
      "learning_rate": 7.74479328566988e-06,
      "loss": 0.1585,
      "step": 5804
    },
    {
      "epoch": 0.45111905502020516,
      "grad_norm": 0.2551043629646301,
      "learning_rate": 7.744404724898974e-06,
      "loss": 0.1073,
      "step": 5805
    },
    {
      "epoch": 0.45119676717438606,
      "grad_norm": 0.2106359452009201,
      "learning_rate": 7.74401616412807e-06,
      "loss": 0.0368,
      "step": 5806
    },
    {
      "epoch": 0.451274479328567,
      "grad_norm": 0.143976092338562,
      "learning_rate": 7.743627603357166e-06,
      "loss": 0.0574,
      "step": 5807
    },
    {
      "epoch": 0.4513521914827479,
      "grad_norm": 0.16939020156860352,
      "learning_rate": 7.743239042586261e-06,
      "loss": 0.0553,
      "step": 5808
    },
    {
      "epoch": 0.4514299036369288,
      "grad_norm": 0.2581923305988312,
      "learning_rate": 7.742850481815356e-06,
      "loss": 0.244,
      "step": 5809
    },
    {
      "epoch": 0.4515076157911097,
      "grad_norm": 0.1473090797662735,
      "learning_rate": 7.742461921044453e-06,
      "loss": 0.0365,
      "step": 5810
    },
    {
      "epoch": 0.45158532794529066,
      "grad_norm": 0.3034794330596924,
      "learning_rate": 7.742073360273547e-06,
      "loss": 0.2445,
      "step": 5811
    },
    {
      "epoch": 0.45166304009947156,
      "grad_norm": 0.2849572002887726,
      "learning_rate": 7.741684799502644e-06,
      "loss": 0.1749,
      "step": 5812
    },
    {
      "epoch": 0.45174075225365246,
      "grad_norm": 1.6940265893936157,
      "learning_rate": 7.741296238731737e-06,
      "loss": 0.657,
      "step": 5813
    },
    {
      "epoch": 0.4518184644078334,
      "grad_norm": 1.3543381690979004,
      "learning_rate": 7.740907677960834e-06,
      "loss": 0.5596,
      "step": 5814
    },
    {
      "epoch": 0.4518961765620143,
      "grad_norm": 0.8099579215049744,
      "learning_rate": 7.740519117189929e-06,
      "loss": 0.1858,
      "step": 5815
    },
    {
      "epoch": 0.4519738887161952,
      "grad_norm": 0.8326883316040039,
      "learning_rate": 7.740130556419024e-06,
      "loss": 0.1605,
      "step": 5816
    },
    {
      "epoch": 0.4520516008703761,
      "grad_norm": 0.32411763072013855,
      "learning_rate": 7.73974199564812e-06,
      "loss": 0.2053,
      "step": 5817
    },
    {
      "epoch": 0.45212931302455706,
      "grad_norm": 0.24583812057971954,
      "learning_rate": 7.739353434877216e-06,
      "loss": 0.4028,
      "step": 5818
    },
    {
      "epoch": 0.45220702517873795,
      "grad_norm": 0.05911325663328171,
      "learning_rate": 7.73896487410631e-06,
      "loss": 0.031,
      "step": 5819
    },
    {
      "epoch": 0.45228473733291885,
      "grad_norm": 0.32411253452301025,
      "learning_rate": 7.738576313335407e-06,
      "loss": 0.225,
      "step": 5820
    },
    {
      "epoch": 0.4523624494870998,
      "grad_norm": 1.3012586832046509,
      "learning_rate": 7.738187752564502e-06,
      "loss": 0.2462,
      "step": 5821
    },
    {
      "epoch": 0.4524401616412807,
      "grad_norm": 0.3496304750442505,
      "learning_rate": 7.737799191793597e-06,
      "loss": 0.1028,
      "step": 5822
    },
    {
      "epoch": 0.4525178737954616,
      "grad_norm": 0.10720917582511902,
      "learning_rate": 7.737410631022692e-06,
      "loss": 0.0778,
      "step": 5823
    },
    {
      "epoch": 0.4525955859496425,
      "grad_norm": 0.06738028675317764,
      "learning_rate": 7.737022070251789e-06,
      "loss": 0.0398,
      "step": 5824
    },
    {
      "epoch": 0.45267329810382345,
      "grad_norm": 0.3853718042373657,
      "learning_rate": 7.736633509480884e-06,
      "loss": 0.3083,
      "step": 5825
    },
    {
      "epoch": 0.45275101025800435,
      "grad_norm": 0.06941504031419754,
      "learning_rate": 7.736244948709979e-06,
      "loss": 0.0379,
      "step": 5826
    },
    {
      "epoch": 0.45282872241218525,
      "grad_norm": 0.41835492849349976,
      "learning_rate": 7.735856387939075e-06,
      "loss": 0.1535,
      "step": 5827
    },
    {
      "epoch": 0.4529064345663662,
      "grad_norm": 0.4164809584617615,
      "learning_rate": 7.73546782716817e-06,
      "loss": 0.1515,
      "step": 5828
    },
    {
      "epoch": 0.4529841467205471,
      "grad_norm": 0.13885332643985748,
      "learning_rate": 7.735079266397265e-06,
      "loss": 0.0573,
      "step": 5829
    },
    {
      "epoch": 0.453061858874728,
      "grad_norm": 0.6143588423728943,
      "learning_rate": 7.734690705626362e-06,
      "loss": 0.1971,
      "step": 5830
    },
    {
      "epoch": 0.4531395710289089,
      "grad_norm": 0.26340973377227783,
      "learning_rate": 7.734302144855455e-06,
      "loss": 0.0512,
      "step": 5831
    },
    {
      "epoch": 0.45321728318308985,
      "grad_norm": 0.2600937783718109,
      "learning_rate": 7.733913584084552e-06,
      "loss": 0.5496,
      "step": 5832
    },
    {
      "epoch": 0.45329499533727075,
      "grad_norm": 0.05065780133008957,
      "learning_rate": 7.733525023313647e-06,
      "loss": 0.0213,
      "step": 5833
    },
    {
      "epoch": 0.45337270749145164,
      "grad_norm": 0.668563723564148,
      "learning_rate": 7.733136462542741e-06,
      "loss": 0.1936,
      "step": 5834
    },
    {
      "epoch": 0.4534504196456326,
      "grad_norm": 0.16157622635364532,
      "learning_rate": 7.732747901771838e-06,
      "loss": 0.0812,
      "step": 5835
    },
    {
      "epoch": 0.4535281317998135,
      "grad_norm": 0.4039803743362427,
      "learning_rate": 7.732359341000933e-06,
      "loss": 0.0659,
      "step": 5836
    },
    {
      "epoch": 0.4536058439539944,
      "grad_norm": 0.3997746407985687,
      "learning_rate": 7.731970780230028e-06,
      "loss": 0.2141,
      "step": 5837
    },
    {
      "epoch": 0.45368355610817535,
      "grad_norm": 0.14684359729290009,
      "learning_rate": 7.731582219459125e-06,
      "loss": 0.0456,
      "step": 5838
    },
    {
      "epoch": 0.45376126826235624,
      "grad_norm": 0.19532494246959686,
      "learning_rate": 7.73119365868822e-06,
      "loss": 0.1458,
      "step": 5839
    },
    {
      "epoch": 0.45383898041653714,
      "grad_norm": 0.384421169757843,
      "learning_rate": 7.730805097917315e-06,
      "loss": 0.2029,
      "step": 5840
    },
    {
      "epoch": 0.45391669257071804,
      "grad_norm": 0.48008471727371216,
      "learning_rate": 7.73041653714641e-06,
      "loss": 0.3412,
      "step": 5841
    },
    {
      "epoch": 0.453994404724899,
      "grad_norm": 0.7666360139846802,
      "learning_rate": 7.730027976375506e-06,
      "loss": 0.2196,
      "step": 5842
    },
    {
      "epoch": 0.4540721168790799,
      "grad_norm": 0.3517744243144989,
      "learning_rate": 7.729639415604601e-06,
      "loss": 0.1625,
      "step": 5843
    },
    {
      "epoch": 0.4541498290332608,
      "grad_norm": 0.24851463735103607,
      "learning_rate": 7.729250854833696e-06,
      "loss": 0.0602,
      "step": 5844
    },
    {
      "epoch": 0.45422754118744174,
      "grad_norm": 0.48934781551361084,
      "learning_rate": 7.728862294062793e-06,
      "loss": 0.1777,
      "step": 5845
    },
    {
      "epoch": 0.45430525334162264,
      "grad_norm": 0.34718626737594604,
      "learning_rate": 7.728473733291888e-06,
      "loss": 0.1964,
      "step": 5846
    },
    {
      "epoch": 0.45438296549580354,
      "grad_norm": 0.46870946884155273,
      "learning_rate": 7.728085172520983e-06,
      "loss": 0.1394,
      "step": 5847
    },
    {
      "epoch": 0.45446067764998443,
      "grad_norm": 0.49923479557037354,
      "learning_rate": 7.72769661175008e-06,
      "loss": 0.0571,
      "step": 5848
    },
    {
      "epoch": 0.4545383898041654,
      "grad_norm": 0.4363022744655609,
      "learning_rate": 7.727308050979174e-06,
      "loss": 0.2331,
      "step": 5849
    },
    {
      "epoch": 0.4546161019583463,
      "grad_norm": 0.25956106185913086,
      "learning_rate": 7.72691949020827e-06,
      "loss": 0.1241,
      "step": 5850
    },
    {
      "epoch": 0.4546938141125272,
      "grad_norm": 0.20658724009990692,
      "learning_rate": 7.726530929437364e-06,
      "loss": 0.0605,
      "step": 5851
    },
    {
      "epoch": 0.45477152626670814,
      "grad_norm": 0.3063165545463562,
      "learning_rate": 7.72614236866646e-06,
      "loss": 0.0841,
      "step": 5852
    },
    {
      "epoch": 0.45484923842088903,
      "grad_norm": 0.5128291249275208,
      "learning_rate": 7.725753807895556e-06,
      "loss": 0.1978,
      "step": 5853
    },
    {
      "epoch": 0.45492695057506993,
      "grad_norm": 0.1541319638490677,
      "learning_rate": 7.72536524712465e-06,
      "loss": 0.0427,
      "step": 5854
    },
    {
      "epoch": 0.45500466272925083,
      "grad_norm": 0.20974136888980865,
      "learning_rate": 7.724976686353747e-06,
      "loss": 0.0695,
      "step": 5855
    },
    {
      "epoch": 0.4550823748834318,
      "grad_norm": 0.24323700368404388,
      "learning_rate": 7.724588125582842e-06,
      "loss": 0.1061,
      "step": 5856
    },
    {
      "epoch": 0.4551600870376127,
      "grad_norm": 0.3870404064655304,
      "learning_rate": 7.724199564811937e-06,
      "loss": 0.2976,
      "step": 5857
    },
    {
      "epoch": 0.4552377991917936,
      "grad_norm": 0.15179699659347534,
      "learning_rate": 7.723811004041034e-06,
      "loss": 0.043,
      "step": 5858
    },
    {
      "epoch": 0.45531551134597453,
      "grad_norm": 0.13221238553524017,
      "learning_rate": 7.723422443270127e-06,
      "loss": 0.0379,
      "step": 5859
    },
    {
      "epoch": 0.45539322350015543,
      "grad_norm": 0.7904393672943115,
      "learning_rate": 7.723033882499224e-06,
      "loss": 0.4934,
      "step": 5860
    },
    {
      "epoch": 0.45547093565433633,
      "grad_norm": 0.6750176548957825,
      "learning_rate": 7.722645321728319e-06,
      "loss": 0.5913,
      "step": 5861
    },
    {
      "epoch": 0.4555486478085172,
      "grad_norm": 0.26161128282546997,
      "learning_rate": 7.722256760957414e-06,
      "loss": 0.0911,
      "step": 5862
    },
    {
      "epoch": 0.4556263599626982,
      "grad_norm": 0.12308409810066223,
      "learning_rate": 7.72186820018651e-06,
      "loss": 0.0306,
      "step": 5863
    },
    {
      "epoch": 0.4557040721168791,
      "grad_norm": 0.1193937435746193,
      "learning_rate": 7.721479639415605e-06,
      "loss": 0.0204,
      "step": 5864
    },
    {
      "epoch": 0.45578178427106,
      "grad_norm": 0.5045771598815918,
      "learning_rate": 7.7210910786447e-06,
      "loss": 0.2643,
      "step": 5865
    },
    {
      "epoch": 0.45585949642524093,
      "grad_norm": 0.17625294625759125,
      "learning_rate": 7.720702517873797e-06,
      "loss": 0.0371,
      "step": 5866
    },
    {
      "epoch": 0.4559372085794218,
      "grad_norm": 0.437548965215683,
      "learning_rate": 7.720313957102892e-06,
      "loss": 0.2359,
      "step": 5867
    },
    {
      "epoch": 0.4560149207336027,
      "grad_norm": 0.40705400705337524,
      "learning_rate": 7.719925396331987e-06,
      "loss": 0.1912,
      "step": 5868
    },
    {
      "epoch": 0.4560926328877836,
      "grad_norm": 0.17765843868255615,
      "learning_rate": 7.719536835561082e-06,
      "loss": 0.0434,
      "step": 5869
    },
    {
      "epoch": 0.4561703450419646,
      "grad_norm": 0.2724566161632538,
      "learning_rate": 7.719148274790178e-06,
      "loss": 0.1063,
      "step": 5870
    },
    {
      "epoch": 0.4562480571961455,
      "grad_norm": 0.7936854362487793,
      "learning_rate": 7.718759714019273e-06,
      "loss": 0.2286,
      "step": 5871
    },
    {
      "epoch": 0.45632576935032637,
      "grad_norm": 0.3919124901294708,
      "learning_rate": 7.718371153248368e-06,
      "loss": 0.1069,
      "step": 5872
    },
    {
      "epoch": 0.4564034815045073,
      "grad_norm": 0.10799899697303772,
      "learning_rate": 7.717982592477465e-06,
      "loss": 0.0207,
      "step": 5873
    },
    {
      "epoch": 0.4564811936586882,
      "grad_norm": 0.1361207664012909,
      "learning_rate": 7.71759403170656e-06,
      "loss": 0.039,
      "step": 5874
    },
    {
      "epoch": 0.4565589058128691,
      "grad_norm": 0.1955263465642929,
      "learning_rate": 7.717205470935655e-06,
      "loss": 0.1904,
      "step": 5875
    },
    {
      "epoch": 0.4566366179670501,
      "grad_norm": 0.9412963390350342,
      "learning_rate": 7.71681691016475e-06,
      "loss": 0.2644,
      "step": 5876
    },
    {
      "epoch": 0.45671433012123097,
      "grad_norm": 0.2089793086051941,
      "learning_rate": 7.716428349393846e-06,
      "loss": 0.0685,
      "step": 5877
    },
    {
      "epoch": 0.45679204227541187,
      "grad_norm": 0.16179150342941284,
      "learning_rate": 7.716039788622941e-06,
      "loss": 0.0305,
      "step": 5878
    },
    {
      "epoch": 0.45686975442959277,
      "grad_norm": 0.3881005048751831,
      "learning_rate": 7.715651227852036e-06,
      "loss": 0.2214,
      "step": 5879
    },
    {
      "epoch": 0.4569474665837737,
      "grad_norm": 0.9880638718605042,
      "learning_rate": 7.715262667081133e-06,
      "loss": 0.3135,
      "step": 5880
    },
    {
      "epoch": 0.4570251787379546,
      "grad_norm": 1.6867049932479858,
      "learning_rate": 7.714874106310228e-06,
      "loss": 0.6328,
      "step": 5881
    },
    {
      "epoch": 0.4571028908921355,
      "grad_norm": 0.19753915071487427,
      "learning_rate": 7.714485545539323e-06,
      "loss": 0.0885,
      "step": 5882
    },
    {
      "epoch": 0.45718060304631647,
      "grad_norm": 0.16111308336257935,
      "learning_rate": 7.71409698476842e-06,
      "loss": 0.0818,
      "step": 5883
    },
    {
      "epoch": 0.45725831520049737,
      "grad_norm": 0.26981186866760254,
      "learning_rate": 7.713708423997513e-06,
      "loss": 0.2286,
      "step": 5884
    },
    {
      "epoch": 0.45733602735467827,
      "grad_norm": 0.2180173397064209,
      "learning_rate": 7.71331986322661e-06,
      "loss": 0.074,
      "step": 5885
    },
    {
      "epoch": 0.45741373950885916,
      "grad_norm": 0.5038893222808838,
      "learning_rate": 7.712931302455704e-06,
      "loss": 0.2996,
      "step": 5886
    },
    {
      "epoch": 0.4574914516630401,
      "grad_norm": 0.31213223934173584,
      "learning_rate": 7.7125427416848e-06,
      "loss": 0.181,
      "step": 5887
    },
    {
      "epoch": 0.457569163817221,
      "grad_norm": 0.11956214904785156,
      "learning_rate": 7.712154180913896e-06,
      "loss": 0.026,
      "step": 5888
    },
    {
      "epoch": 0.4576468759714019,
      "grad_norm": 0.7535921335220337,
      "learning_rate": 7.71176562014299e-06,
      "loss": 0.1382,
      "step": 5889
    },
    {
      "epoch": 0.45772458812558287,
      "grad_norm": 0.27202561497688293,
      "learning_rate": 7.711377059372086e-06,
      "loss": 0.0903,
      "step": 5890
    },
    {
      "epoch": 0.45780230027976376,
      "grad_norm": 0.19380085170269012,
      "learning_rate": 7.710988498601182e-06,
      "loss": 0.0472,
      "step": 5891
    },
    {
      "epoch": 0.45788001243394466,
      "grad_norm": 0.16003242135047913,
      "learning_rate": 7.710599937830277e-06,
      "loss": 0.0273,
      "step": 5892
    },
    {
      "epoch": 0.45795772458812556,
      "grad_norm": 0.8982831835746765,
      "learning_rate": 7.710211377059372e-06,
      "loss": 0.3727,
      "step": 5893
    },
    {
      "epoch": 0.4580354367423065,
      "grad_norm": 0.29547643661499023,
      "learning_rate": 7.709822816288467e-06,
      "loss": 0.127,
      "step": 5894
    },
    {
      "epoch": 0.4581131488964874,
      "grad_norm": 0.2100450098514557,
      "learning_rate": 7.709434255517564e-06,
      "loss": 0.1029,
      "step": 5895
    },
    {
      "epoch": 0.4581908610506683,
      "grad_norm": 0.3535193204879761,
      "learning_rate": 7.709045694746659e-06,
      "loss": 0.35,
      "step": 5896
    },
    {
      "epoch": 0.45826857320484926,
      "grad_norm": 0.14990369975566864,
      "learning_rate": 7.708657133975754e-06,
      "loss": 0.0544,
      "step": 5897
    },
    {
      "epoch": 0.45834628535903016,
      "grad_norm": 0.21601957082748413,
      "learning_rate": 7.70826857320485e-06,
      "loss": 0.192,
      "step": 5898
    },
    {
      "epoch": 0.45842399751321106,
      "grad_norm": 0.2908204197883606,
      "learning_rate": 7.707880012433945e-06,
      "loss": 0.365,
      "step": 5899
    },
    {
      "epoch": 0.45850170966739195,
      "grad_norm": 0.20778800547122955,
      "learning_rate": 7.70749145166304e-06,
      "loss": 0.0204,
      "step": 5900
    },
    {
      "epoch": 0.4585794218215729,
      "grad_norm": 0.36607977747917175,
      "learning_rate": 7.707102890892137e-06,
      "loss": 0.1755,
      "step": 5901
    },
    {
      "epoch": 0.4586571339757538,
      "grad_norm": 0.26537227630615234,
      "learning_rate": 7.70671433012123e-06,
      "loss": 0.0702,
      "step": 5902
    },
    {
      "epoch": 0.4587348461299347,
      "grad_norm": 0.5547257661819458,
      "learning_rate": 7.706325769350327e-06,
      "loss": 0.2825,
      "step": 5903
    },
    {
      "epoch": 0.45881255828411566,
      "grad_norm": 0.589608371257782,
      "learning_rate": 7.705937208579422e-06,
      "loss": 0.711,
      "step": 5904
    },
    {
      "epoch": 0.45889027043829655,
      "grad_norm": 0.9180530905723572,
      "learning_rate": 7.705548647808518e-06,
      "loss": 0.1104,
      "step": 5905
    },
    {
      "epoch": 0.45896798259247745,
      "grad_norm": 0.12630118429660797,
      "learning_rate": 7.705160087037613e-06,
      "loss": 0.0627,
      "step": 5906
    },
    {
      "epoch": 0.45904569474665835,
      "grad_norm": 0.2874831557273865,
      "learning_rate": 7.704771526266708e-06,
      "loss": 0.3691,
      "step": 5907
    },
    {
      "epoch": 0.4591234069008393,
      "grad_norm": 0.2005845308303833,
      "learning_rate": 7.704382965495805e-06,
      "loss": 0.1155,
      "step": 5908
    },
    {
      "epoch": 0.4592011190550202,
      "grad_norm": 0.10926477611064911,
      "learning_rate": 7.7039944047249e-06,
      "loss": 0.0404,
      "step": 5909
    },
    {
      "epoch": 0.4592788312092011,
      "grad_norm": 0.45234987139701843,
      "learning_rate": 7.703605843953995e-06,
      "loss": 0.3707,
      "step": 5910
    },
    {
      "epoch": 0.45935654336338205,
      "grad_norm": 0.35584771633148193,
      "learning_rate": 7.703217283183092e-06,
      "loss": 0.154,
      "step": 5911
    },
    {
      "epoch": 0.45943425551756295,
      "grad_norm": 0.21145281195640564,
      "learning_rate": 7.702828722412185e-06,
      "loss": 0.0926,
      "step": 5912
    },
    {
      "epoch": 0.45951196767174385,
      "grad_norm": 0.29278963804244995,
      "learning_rate": 7.702440161641281e-06,
      "loss": 0.1293,
      "step": 5913
    },
    {
      "epoch": 0.4595896798259248,
      "grad_norm": 0.3766901195049286,
      "learning_rate": 7.702051600870376e-06,
      "loss": 0.1151,
      "step": 5914
    },
    {
      "epoch": 0.4596673919801057,
      "grad_norm": 0.36171817779541016,
      "learning_rate": 7.701663040099471e-06,
      "loss": 0.1641,
      "step": 5915
    },
    {
      "epoch": 0.4597451041342866,
      "grad_norm": 0.13607774674892426,
      "learning_rate": 7.701274479328568e-06,
      "loss": 0.0732,
      "step": 5916
    },
    {
      "epoch": 0.4598228162884675,
      "grad_norm": 0.2825165092945099,
      "learning_rate": 7.700885918557663e-06,
      "loss": 0.1691,
      "step": 5917
    },
    {
      "epoch": 0.45990052844264845,
      "grad_norm": 0.12660785019397736,
      "learning_rate": 7.700497357786758e-06,
      "loss": 0.0238,
      "step": 5918
    },
    {
      "epoch": 0.45997824059682935,
      "grad_norm": 0.6530978083610535,
      "learning_rate": 7.700108797015855e-06,
      "loss": 0.2836,
      "step": 5919
    },
    {
      "epoch": 0.46005595275101024,
      "grad_norm": 0.28625810146331787,
      "learning_rate": 7.69972023624495e-06,
      "loss": 0.0742,
      "step": 5920
    },
    {
      "epoch": 0.4601336649051912,
      "grad_norm": 0.23232460021972656,
      "learning_rate": 7.699331675474044e-06,
      "loss": 0.1051,
      "step": 5921
    },
    {
      "epoch": 0.4602113770593721,
      "grad_norm": 0.1399902105331421,
      "learning_rate": 7.69894311470314e-06,
      "loss": 0.0381,
      "step": 5922
    },
    {
      "epoch": 0.460289089213553,
      "grad_norm": 0.2800557315349579,
      "learning_rate": 7.698554553932236e-06,
      "loss": 0.1481,
      "step": 5923
    },
    {
      "epoch": 0.4603668013677339,
      "grad_norm": 0.14260344207286835,
      "learning_rate": 7.698165993161331e-06,
      "loss": 0.0425,
      "step": 5924
    },
    {
      "epoch": 0.46044451352191484,
      "grad_norm": 0.12673057615756989,
      "learning_rate": 7.697777432390426e-06,
      "loss": 0.0347,
      "step": 5925
    },
    {
      "epoch": 0.46052222567609574,
      "grad_norm": 0.30806460976600647,
      "learning_rate": 7.697388871619523e-06,
      "loss": 0.1045,
      "step": 5926
    },
    {
      "epoch": 0.46059993783027664,
      "grad_norm": 0.7284033894538879,
      "learning_rate": 7.697000310848618e-06,
      "loss": 0.0712,
      "step": 5927
    },
    {
      "epoch": 0.4606776499844576,
      "grad_norm": 0.10449718683958054,
      "learning_rate": 7.696611750077713e-06,
      "loss": 0.0144,
      "step": 5928
    },
    {
      "epoch": 0.4607553621386385,
      "grad_norm": 0.06345950067043304,
      "learning_rate": 7.696223189306809e-06,
      "loss": 0.0106,
      "step": 5929
    },
    {
      "epoch": 0.4608330742928194,
      "grad_norm": 0.1561804860830307,
      "learning_rate": 7.695834628535902e-06,
      "loss": 0.061,
      "step": 5930
    },
    {
      "epoch": 0.4609107864470003,
      "grad_norm": 0.5186201930046082,
      "learning_rate": 7.695446067764999e-06,
      "loss": 0.0685,
      "step": 5931
    },
    {
      "epoch": 0.46098849860118124,
      "grad_norm": 0.11413652449846268,
      "learning_rate": 7.695057506994094e-06,
      "loss": 0.0491,
      "step": 5932
    },
    {
      "epoch": 0.46106621075536214,
      "grad_norm": 0.3435741364955902,
      "learning_rate": 7.694668946223189e-06,
      "loss": 0.158,
      "step": 5933
    },
    {
      "epoch": 0.46114392290954304,
      "grad_norm": 0.5938175916671753,
      "learning_rate": 7.694280385452286e-06,
      "loss": 0.6993,
      "step": 5934
    },
    {
      "epoch": 0.461221635063724,
      "grad_norm": 0.03861697018146515,
      "learning_rate": 7.69389182468138e-06,
      "loss": 0.0043,
      "step": 5935
    },
    {
      "epoch": 0.4612993472179049,
      "grad_norm": 0.3513447940349579,
      "learning_rate": 7.693503263910477e-06,
      "loss": 0.2264,
      "step": 5936
    },
    {
      "epoch": 0.4613770593720858,
      "grad_norm": 0.26073870062828064,
      "learning_rate": 7.693114703139572e-06,
      "loss": 0.2023,
      "step": 5937
    },
    {
      "epoch": 0.4614547715262667,
      "grad_norm": 0.3375892639160156,
      "learning_rate": 7.692726142368667e-06,
      "loss": 0.2864,
      "step": 5938
    },
    {
      "epoch": 0.46153248368044764,
      "grad_norm": 0.33941560983657837,
      "learning_rate": 7.692337581597764e-06,
      "loss": 0.1708,
      "step": 5939
    },
    {
      "epoch": 0.46161019583462853,
      "grad_norm": 0.8621644973754883,
      "learning_rate": 7.691949020826857e-06,
      "loss": 0.4296,
      "step": 5940
    },
    {
      "epoch": 0.46168790798880943,
      "grad_norm": 0.8146262764930725,
      "learning_rate": 7.691560460055954e-06,
      "loss": 0.3088,
      "step": 5941
    },
    {
      "epoch": 0.4617656201429904,
      "grad_norm": 0.14574535191059113,
      "learning_rate": 7.691171899285049e-06,
      "loss": 0.0235,
      "step": 5942
    },
    {
      "epoch": 0.4618433322971713,
      "grad_norm": 0.38396698236465454,
      "learning_rate": 7.690783338514144e-06,
      "loss": 0.0743,
      "step": 5943
    },
    {
      "epoch": 0.4619210444513522,
      "grad_norm": 12.697837829589844,
      "learning_rate": 7.69039477774324e-06,
      "loss": 0.8554,
      "step": 5944
    },
    {
      "epoch": 0.4619987566055331,
      "grad_norm": 0.6748328804969788,
      "learning_rate": 7.690006216972335e-06,
      "loss": 0.0804,
      "step": 5945
    },
    {
      "epoch": 0.46207646875971403,
      "grad_norm": 0.19361340999603271,
      "learning_rate": 7.68961765620143e-06,
      "loss": 0.0354,
      "step": 5946
    },
    {
      "epoch": 0.46215418091389493,
      "grad_norm": 0.34105661511421204,
      "learning_rate": 7.689229095430527e-06,
      "loss": 0.1302,
      "step": 5947
    },
    {
      "epoch": 0.4622318930680758,
      "grad_norm": 0.2872297465801239,
      "learning_rate": 7.688840534659622e-06,
      "loss": 0.2271,
      "step": 5948
    },
    {
      "epoch": 0.4623096052222568,
      "grad_norm": 0.14261385798454285,
      "learning_rate": 7.688451973888717e-06,
      "loss": 0.0433,
      "step": 5949
    },
    {
      "epoch": 0.4623873173764377,
      "grad_norm": 0.1088404655456543,
      "learning_rate": 7.688063413117812e-06,
      "loss": 0.0446,
      "step": 5950
    },
    {
      "epoch": 0.4624650295306186,
      "grad_norm": 0.880986750125885,
      "learning_rate": 7.687674852346908e-06,
      "loss": 0.4517,
      "step": 5951
    },
    {
      "epoch": 0.46254274168479953,
      "grad_norm": 0.43207719922065735,
      "learning_rate": 7.687286291576003e-06,
      "loss": 0.3294,
      "step": 5952
    },
    {
      "epoch": 0.4626204538389804,
      "grad_norm": 0.08446339517831802,
      "learning_rate": 7.686897730805098e-06,
      "loss": 0.0405,
      "step": 5953
    },
    {
      "epoch": 0.4626981659931613,
      "grad_norm": 0.4387670159339905,
      "learning_rate": 7.686509170034195e-06,
      "loss": 0.1957,
      "step": 5954
    },
    {
      "epoch": 0.4627758781473422,
      "grad_norm": 0.4491085708141327,
      "learning_rate": 7.68612060926329e-06,
      "loss": 0.3691,
      "step": 5955
    },
    {
      "epoch": 0.4628535903015232,
      "grad_norm": 0.2775525748729706,
      "learning_rate": 7.685732048492385e-06,
      "loss": 0.1283,
      "step": 5956
    },
    {
      "epoch": 0.4629313024557041,
      "grad_norm": 0.6859575510025024,
      "learning_rate": 7.685343487721481e-06,
      "loss": 0.2246,
      "step": 5957
    },
    {
      "epoch": 0.463009014609885,
      "grad_norm": 0.9028173089027405,
      "learning_rate": 7.684954926950575e-06,
      "loss": 0.3279,
      "step": 5958
    },
    {
      "epoch": 0.4630867267640659,
      "grad_norm": 0.17624840140342712,
      "learning_rate": 7.684566366179671e-06,
      "loss": 0.2122,
      "step": 5959
    },
    {
      "epoch": 0.4631644389182468,
      "grad_norm": 0.9697539210319519,
      "learning_rate": 7.684177805408766e-06,
      "loss": 0.1254,
      "step": 5960
    },
    {
      "epoch": 0.4632421510724277,
      "grad_norm": 0.2678942084312439,
      "learning_rate": 7.683789244637861e-06,
      "loss": 0.0987,
      "step": 5961
    },
    {
      "epoch": 0.4633198632266086,
      "grad_norm": 0.22082936763763428,
      "learning_rate": 7.683400683866958e-06,
      "loss": 0.1513,
      "step": 5962
    },
    {
      "epoch": 0.4633975753807896,
      "grad_norm": 0.44676798582077026,
      "learning_rate": 7.683012123096053e-06,
      "loss": 0.1762,
      "step": 5963
    },
    {
      "epoch": 0.46347528753497047,
      "grad_norm": 0.14530536532402039,
      "learning_rate": 7.68262356232515e-06,
      "loss": 0.0421,
      "step": 5964
    },
    {
      "epoch": 0.46355299968915137,
      "grad_norm": 0.20474979281425476,
      "learning_rate": 7.682235001554244e-06,
      "loss": 0.0433,
      "step": 5965
    },
    {
      "epoch": 0.4636307118433323,
      "grad_norm": 0.20138972997665405,
      "learning_rate": 7.68184644078334e-06,
      "loss": 0.0535,
      "step": 5966
    },
    {
      "epoch": 0.4637084239975132,
      "grad_norm": 0.5312819480895996,
      "learning_rate": 7.681457880012436e-06,
      "loss": 0.1799,
      "step": 5967
    },
    {
      "epoch": 0.4637861361516941,
      "grad_norm": 0.34010404348373413,
      "learning_rate": 7.681069319241529e-06,
      "loss": 0.159,
      "step": 5968
    },
    {
      "epoch": 0.463863848305875,
      "grad_norm": 0.37774673104286194,
      "learning_rate": 7.680680758470626e-06,
      "loss": 0.2668,
      "step": 5969
    },
    {
      "epoch": 0.46394156046005597,
      "grad_norm": 0.7112846374511719,
      "learning_rate": 7.68029219769972e-06,
      "loss": 0.7705,
      "step": 5970
    },
    {
      "epoch": 0.46401927261423687,
      "grad_norm": 0.690656840801239,
      "learning_rate": 7.679903636928816e-06,
      "loss": 0.4609,
      "step": 5971
    },
    {
      "epoch": 0.46409698476841776,
      "grad_norm": 0.4977957010269165,
      "learning_rate": 7.679515076157912e-06,
      "loss": 0.9049,
      "step": 5972
    },
    {
      "epoch": 0.4641746969225987,
      "grad_norm": 0.22940391302108765,
      "learning_rate": 7.679126515387007e-06,
      "loss": 0.117,
      "step": 5973
    },
    {
      "epoch": 0.4642524090767796,
      "grad_norm": 0.09584223479032516,
      "learning_rate": 7.678737954616102e-06,
      "loss": 0.0959,
      "step": 5974
    },
    {
      "epoch": 0.4643301212309605,
      "grad_norm": 0.0762108713388443,
      "learning_rate": 7.678349393845199e-06,
      "loss": 0.0185,
      "step": 5975
    },
    {
      "epoch": 0.4644078333851414,
      "grad_norm": 0.34918808937072754,
      "learning_rate": 7.677960833074294e-06,
      "loss": 0.3205,
      "step": 5976
    },
    {
      "epoch": 0.46448554553932236,
      "grad_norm": 1.0273817777633667,
      "learning_rate": 7.677572272303389e-06,
      "loss": 0.7568,
      "step": 5977
    },
    {
      "epoch": 0.46456325769350326,
      "grad_norm": 0.5620936155319214,
      "learning_rate": 7.677183711532484e-06,
      "loss": 0.3567,
      "step": 5978
    },
    {
      "epoch": 0.46464096984768416,
      "grad_norm": 0.19869333505630493,
      "learning_rate": 7.67679515076158e-06,
      "loss": 0.0616,
      "step": 5979
    },
    {
      "epoch": 0.4647186820018651,
      "grad_norm": 0.27610617876052856,
      "learning_rate": 7.676406589990675e-06,
      "loss": 0.1146,
      "step": 5980
    },
    {
      "epoch": 0.464796394156046,
      "grad_norm": 0.38871070742607117,
      "learning_rate": 7.67601802921977e-06,
      "loss": 0.1088,
      "step": 5981
    },
    {
      "epoch": 0.4648741063102269,
      "grad_norm": 0.23649713397026062,
      "learning_rate": 7.675629468448867e-06,
      "loss": 0.1289,
      "step": 5982
    },
    {
      "epoch": 0.4649518184644078,
      "grad_norm": 0.38569799065589905,
      "learning_rate": 7.675240907677962e-06,
      "loss": 0.169,
      "step": 5983
    },
    {
      "epoch": 0.46502953061858876,
      "grad_norm": 0.09475356340408325,
      "learning_rate": 7.674852346907057e-06,
      "loss": 0.0357,
      "step": 5984
    },
    {
      "epoch": 0.46510724277276966,
      "grad_norm": 0.15745045244693756,
      "learning_rate": 7.674463786136153e-06,
      "loss": 0.1086,
      "step": 5985
    },
    {
      "epoch": 0.46518495492695056,
      "grad_norm": 0.6669245362281799,
      "learning_rate": 7.674075225365247e-06,
      "loss": 0.8008,
      "step": 5986
    },
    {
      "epoch": 0.4652626670811315,
      "grad_norm": 0.24687257409095764,
      "learning_rate": 7.673686664594343e-06,
      "loss": 0.057,
      "step": 5987
    },
    {
      "epoch": 0.4653403792353124,
      "grad_norm": 0.16606034338474274,
      "learning_rate": 7.673298103823438e-06,
      "loss": 0.0675,
      "step": 5988
    },
    {
      "epoch": 0.4654180913894933,
      "grad_norm": 0.2026175558567047,
      "learning_rate": 7.672909543052533e-06,
      "loss": 0.1277,
      "step": 5989
    },
    {
      "epoch": 0.46549580354367426,
      "grad_norm": 0.233934685587883,
      "learning_rate": 7.67252098228163e-06,
      "loss": 0.0302,
      "step": 5990
    },
    {
      "epoch": 0.46557351569785516,
      "grad_norm": 0.4612186849117279,
      "learning_rate": 7.672132421510725e-06,
      "loss": 0.1581,
      "step": 5991
    },
    {
      "epoch": 0.46565122785203605,
      "grad_norm": 0.08257222920656204,
      "learning_rate": 7.67174386073982e-06,
      "loss": 0.0127,
      "step": 5992
    },
    {
      "epoch": 0.46572894000621695,
      "grad_norm": 1.0812116861343384,
      "learning_rate": 7.671355299968916e-06,
      "loss": 0.2589,
      "step": 5993
    },
    {
      "epoch": 0.4658066521603979,
      "grad_norm": 0.2904980778694153,
      "learning_rate": 7.670966739198011e-06,
      "loss": 0.1636,
      "step": 5994
    },
    {
      "epoch": 0.4658843643145788,
      "grad_norm": 0.4078381657600403,
      "learning_rate": 7.670578178427106e-06,
      "loss": 0.253,
      "step": 5995
    },
    {
      "epoch": 0.4659620764687597,
      "grad_norm": 0.2514244318008423,
      "learning_rate": 7.670189617656201e-06,
      "loss": 0.2009,
      "step": 5996
    },
    {
      "epoch": 0.46603978862294065,
      "grad_norm": 0.7089028358459473,
      "learning_rate": 7.669801056885298e-06,
      "loss": 0.4711,
      "step": 5997
    },
    {
      "epoch": 0.46611750077712155,
      "grad_norm": 0.34316587448120117,
      "learning_rate": 7.669412496114393e-06,
      "loss": 0.2059,
      "step": 5998
    },
    {
      "epoch": 0.46619521293130245,
      "grad_norm": 0.07762309908866882,
      "learning_rate": 7.669023935343488e-06,
      "loss": 0.0353,
      "step": 5999
    },
    {
      "epoch": 0.46627292508548335,
      "grad_norm": 0.19984987378120422,
      "learning_rate": 7.668635374572584e-06,
      "loss": 0.0251,
      "step": 6000
    },
    {
      "epoch": 0.4663506372396643,
      "grad_norm": 0.5231903791427612,
      "learning_rate": 7.66824681380168e-06,
      "loss": 0.3655,
      "step": 6001
    },
    {
      "epoch": 0.4664283493938452,
      "grad_norm": 0.4826318025588989,
      "learning_rate": 7.667858253030774e-06,
      "loss": 0.299,
      "step": 6002
    },
    {
      "epoch": 0.4665060615480261,
      "grad_norm": 0.8008408546447754,
      "learning_rate": 7.66746969225987e-06,
      "loss": 0.6319,
      "step": 6003
    },
    {
      "epoch": 0.46658377370220705,
      "grad_norm": 0.2668916583061218,
      "learning_rate": 7.667081131488966e-06,
      "loss": 0.0463,
      "step": 6004
    },
    {
      "epoch": 0.46666148585638795,
      "grad_norm": 0.41116657853126526,
      "learning_rate": 7.666692570718061e-06,
      "loss": 0.2685,
      "step": 6005
    },
    {
      "epoch": 0.46673919801056885,
      "grad_norm": 0.16692404448986053,
      "learning_rate": 7.666304009947156e-06,
      "loss": 0.1118,
      "step": 6006
    },
    {
      "epoch": 0.46681691016474974,
      "grad_norm": 0.4212568700313568,
      "learning_rate": 7.665915449176253e-06,
      "loss": 0.4606,
      "step": 6007
    },
    {
      "epoch": 0.4668946223189307,
      "grad_norm": 0.2302589863538742,
      "learning_rate": 7.665526888405347e-06,
      "loss": 0.1251,
      "step": 6008
    },
    {
      "epoch": 0.4669723344731116,
      "grad_norm": 0.523567259311676,
      "learning_rate": 7.665138327634442e-06,
      "loss": 0.1554,
      "step": 6009
    },
    {
      "epoch": 0.4670500466272925,
      "grad_norm": 0.19364164769649506,
      "learning_rate": 7.664749766863539e-06,
      "loss": 0.0732,
      "step": 6010
    },
    {
      "epoch": 0.46712775878147345,
      "grad_norm": 0.45056360960006714,
      "learning_rate": 7.664361206092632e-06,
      "loss": 0.1619,
      "step": 6011
    },
    {
      "epoch": 0.46720547093565434,
      "grad_norm": 0.21835674345493317,
      "learning_rate": 7.663972645321729e-06,
      "loss": 0.2373,
      "step": 6012
    },
    {
      "epoch": 0.46728318308983524,
      "grad_norm": 0.22956714034080505,
      "learning_rate": 7.663584084550824e-06,
      "loss": 0.0689,
      "step": 6013
    },
    {
      "epoch": 0.46736089524401614,
      "grad_norm": 0.1905064880847931,
      "learning_rate": 7.663195523779919e-06,
      "loss": 0.0859,
      "step": 6014
    },
    {
      "epoch": 0.4674386073981971,
      "grad_norm": 0.2105167955160141,
      "learning_rate": 7.662806963009015e-06,
      "loss": 0.0805,
      "step": 6015
    },
    {
      "epoch": 0.467516319552378,
      "grad_norm": 0.22830845415592194,
      "learning_rate": 7.66241840223811e-06,
      "loss": 0.0499,
      "step": 6016
    },
    {
      "epoch": 0.4675940317065589,
      "grad_norm": 0.2456602305173874,
      "learning_rate": 7.662029841467205e-06,
      "loss": 0.0436,
      "step": 6017
    },
    {
      "epoch": 0.46767174386073984,
      "grad_norm": 0.07776198536157608,
      "learning_rate": 7.661641280696302e-06,
      "loss": 0.04,
      "step": 6018
    },
    {
      "epoch": 0.46774945601492074,
      "grad_norm": 0.5009505748748779,
      "learning_rate": 7.661252719925397e-06,
      "loss": 0.3716,
      "step": 6019
    },
    {
      "epoch": 0.46782716816910164,
      "grad_norm": 0.08428385108709335,
      "learning_rate": 7.660864159154492e-06,
      "loss": 0.0199,
      "step": 6020
    },
    {
      "epoch": 0.46790488032328253,
      "grad_norm": 0.15466460585594177,
      "learning_rate": 7.660475598383587e-06,
      "loss": 0.0919,
      "step": 6021
    },
    {
      "epoch": 0.4679825924774635,
      "grad_norm": 0.3282579183578491,
      "learning_rate": 7.660087037612684e-06,
      "loss": 0.1683,
      "step": 6022
    },
    {
      "epoch": 0.4680603046316444,
      "grad_norm": 0.8245526552200317,
      "learning_rate": 7.659698476841778e-06,
      "loss": 0.1946,
      "step": 6023
    },
    {
      "epoch": 0.4681380167858253,
      "grad_norm": 0.10716897249221802,
      "learning_rate": 7.659309916070873e-06,
      "loss": 0.0211,
      "step": 6024
    },
    {
      "epoch": 0.46821572894000624,
      "grad_norm": 0.36061209440231323,
      "learning_rate": 7.65892135529997e-06,
      "loss": 0.1446,
      "step": 6025
    },
    {
      "epoch": 0.46829344109418714,
      "grad_norm": 0.22262835502624512,
      "learning_rate": 7.658532794529065e-06,
      "loss": 0.0921,
      "step": 6026
    },
    {
      "epoch": 0.46837115324836803,
      "grad_norm": 0.4407535195350647,
      "learning_rate": 7.65814423375816e-06,
      "loss": 0.7157,
      "step": 6027
    },
    {
      "epoch": 0.468448865402549,
      "grad_norm": 0.3395233154296875,
      "learning_rate": 7.657755672987257e-06,
      "loss": 0.1733,
      "step": 6028
    },
    {
      "epoch": 0.4685265775567299,
      "grad_norm": 0.5357279181480408,
      "learning_rate": 7.657367112216352e-06,
      "loss": 0.206,
      "step": 6029
    },
    {
      "epoch": 0.4686042897109108,
      "grad_norm": 1.0161570310592651,
      "learning_rate": 7.656978551445447e-06,
      "loss": 0.271,
      "step": 6030
    },
    {
      "epoch": 0.4686820018650917,
      "grad_norm": 0.2244245857000351,
      "learning_rate": 7.656589990674541e-06,
      "loss": 0.0887,
      "step": 6031
    },
    {
      "epoch": 0.46875971401927263,
      "grad_norm": 0.3254300355911255,
      "learning_rate": 7.656201429903638e-06,
      "loss": 0.1094,
      "step": 6032
    },
    {
      "epoch": 0.46883742617345353,
      "grad_norm": 0.6039347052574158,
      "learning_rate": 7.655812869132733e-06,
      "loss": 0.2613,
      "step": 6033
    },
    {
      "epoch": 0.46891513832763443,
      "grad_norm": 0.31450334191322327,
      "learning_rate": 7.655424308361828e-06,
      "loss": 0.0778,
      "step": 6034
    },
    {
      "epoch": 0.4689928504818154,
      "grad_norm": 0.4724292457103729,
      "learning_rate": 7.655035747590925e-06,
      "loss": 0.2493,
      "step": 6035
    },
    {
      "epoch": 0.4690705626359963,
      "grad_norm": 1.0958874225616455,
      "learning_rate": 7.65464718682002e-06,
      "loss": 0.3365,
      "step": 6036
    },
    {
      "epoch": 0.4691482747901772,
      "grad_norm": 0.537478506565094,
      "learning_rate": 7.654258626049115e-06,
      "loss": 0.2405,
      "step": 6037
    },
    {
      "epoch": 0.4692259869443581,
      "grad_norm": 0.7418683767318726,
      "learning_rate": 7.653870065278211e-06,
      "loss": 0.0621,
      "step": 6038
    },
    {
      "epoch": 0.46930369909853903,
      "grad_norm": 0.1072096973657608,
      "learning_rate": 7.653481504507304e-06,
      "loss": 0.0321,
      "step": 6039
    },
    {
      "epoch": 0.4693814112527199,
      "grad_norm": 1.027265191078186,
      "learning_rate": 7.653092943736401e-06,
      "loss": 0.2761,
      "step": 6040
    },
    {
      "epoch": 0.4694591234069008,
      "grad_norm": 0.16576698422431946,
      "learning_rate": 7.652704382965496e-06,
      "loss": 0.0808,
      "step": 6041
    },
    {
      "epoch": 0.4695368355610818,
      "grad_norm": 0.1920320987701416,
      "learning_rate": 7.652315822194591e-06,
      "loss": 0.0288,
      "step": 6042
    },
    {
      "epoch": 0.4696145477152627,
      "grad_norm": 0.24400998651981354,
      "learning_rate": 7.651927261423688e-06,
      "loss": 0.0857,
      "step": 6043
    },
    {
      "epoch": 0.4696922598694436,
      "grad_norm": 0.28679129481315613,
      "learning_rate": 7.651538700652783e-06,
      "loss": 0.0192,
      "step": 6044
    },
    {
      "epoch": 0.46976997202362447,
      "grad_norm": 0.3050583302974701,
      "learning_rate": 7.651150139881878e-06,
      "loss": 0.1262,
      "step": 6045
    },
    {
      "epoch": 0.4698476841778054,
      "grad_norm": 0.24542905390262604,
      "learning_rate": 7.650761579110974e-06,
      "loss": 0.1824,
      "step": 6046
    },
    {
      "epoch": 0.4699253963319863,
      "grad_norm": 0.39312925934791565,
      "learning_rate": 7.650373018340069e-06,
      "loss": 0.1792,
      "step": 6047
    },
    {
      "epoch": 0.4700031084861672,
      "grad_norm": 0.2792505919933319,
      "learning_rate": 7.649984457569164e-06,
      "loss": 0.492,
      "step": 6048
    },
    {
      "epoch": 0.4700808206403482,
      "grad_norm": 0.28301432728767395,
      "learning_rate": 7.649595896798259e-06,
      "loss": 0.1365,
      "step": 6049
    },
    {
      "epoch": 0.47015853279452907,
      "grad_norm": 0.4630777835845947,
      "learning_rate": 7.649207336027356e-06,
      "loss": 0.3857,
      "step": 6050
    },
    {
      "epoch": 0.47023624494870997,
      "grad_norm": 0.20732654631137848,
      "learning_rate": 7.64881877525645e-06,
      "loss": 0.111,
      "step": 6051
    },
    {
      "epoch": 0.47031395710289087,
      "grad_norm": 0.49691125750541687,
      "learning_rate": 7.648430214485546e-06,
      "loss": 0.2895,
      "step": 6052
    },
    {
      "epoch": 0.4703916692570718,
      "grad_norm": 2.6821258068084717,
      "learning_rate": 7.648041653714642e-06,
      "loss": 0.123,
      "step": 6053
    },
    {
      "epoch": 0.4704693814112527,
      "grad_norm": 8.533013343811035,
      "learning_rate": 7.647653092943737e-06,
      "loss": 2.6447,
      "step": 6054
    },
    {
      "epoch": 0.4705470935654336,
      "grad_norm": 0.4012466073036194,
      "learning_rate": 7.647264532172832e-06,
      "loss": 0.0871,
      "step": 6055
    },
    {
      "epoch": 0.47062480571961457,
      "grad_norm": 0.42372778058052063,
      "learning_rate": 7.646875971401929e-06,
      "loss": 0.2491,
      "step": 6056
    },
    {
      "epoch": 0.47070251787379547,
      "grad_norm": 0.624961793422699,
      "learning_rate": 7.646487410631024e-06,
      "loss": 0.3964,
      "step": 6057
    },
    {
      "epoch": 0.47078023002797637,
      "grad_norm": 0.1734859198331833,
      "learning_rate": 7.646098849860119e-06,
      "loss": 0.0536,
      "step": 6058
    },
    {
      "epoch": 0.47085794218215726,
      "grad_norm": 0.11536587029695511,
      "learning_rate": 7.645710289089214e-06,
      "loss": 0.0349,
      "step": 6059
    },
    {
      "epoch": 0.4709356543363382,
      "grad_norm": 0.19846278429031372,
      "learning_rate": 7.64532172831831e-06,
      "loss": 0.1334,
      "step": 6060
    },
    {
      "epoch": 0.4710133664905191,
      "grad_norm": 1.9370967149734497,
      "learning_rate": 7.644933167547405e-06,
      "loss": 0.1414,
      "step": 6061
    },
    {
      "epoch": 0.4710910786447,
      "grad_norm": 0.15632323920726776,
      "learning_rate": 7.6445446067765e-06,
      "loss": 0.0403,
      "step": 6062
    },
    {
      "epoch": 0.47116879079888097,
      "grad_norm": 0.12698718905448914,
      "learning_rate": 7.644156046005597e-06,
      "loss": 0.0328,
      "step": 6063
    },
    {
      "epoch": 0.47124650295306186,
      "grad_norm": 1.0203750133514404,
      "learning_rate": 7.643767485234692e-06,
      "loss": 0.4964,
      "step": 6064
    },
    {
      "epoch": 0.47132421510724276,
      "grad_norm": 0.19788624346256256,
      "learning_rate": 7.643378924463787e-06,
      "loss": 0.0791,
      "step": 6065
    },
    {
      "epoch": 0.4714019272614237,
      "grad_norm": 0.7573451399803162,
      "learning_rate": 7.642990363692883e-06,
      "loss": 0.5444,
      "step": 6066
    },
    {
      "epoch": 0.4714796394156046,
      "grad_norm": 0.2975744307041168,
      "learning_rate": 7.642601802921977e-06,
      "loss": 0.3793,
      "step": 6067
    },
    {
      "epoch": 0.4715573515697855,
      "grad_norm": 0.33327406644821167,
      "learning_rate": 7.642213242151073e-06,
      "loss": 0.2516,
      "step": 6068
    },
    {
      "epoch": 0.4716350637239664,
      "grad_norm": 0.4042165279388428,
      "learning_rate": 7.641824681380168e-06,
      "loss": 0.1996,
      "step": 6069
    },
    {
      "epoch": 0.47171277587814736,
      "grad_norm": 0.3493470251560211,
      "learning_rate": 7.641436120609263e-06,
      "loss": 0.0757,
      "step": 6070
    },
    {
      "epoch": 0.47179048803232826,
      "grad_norm": 0.23734445869922638,
      "learning_rate": 7.64104755983836e-06,
      "loss": 0.1047,
      "step": 6071
    },
    {
      "epoch": 0.47186820018650916,
      "grad_norm": 0.1056344285607338,
      "learning_rate": 7.640658999067455e-06,
      "loss": 0.0341,
      "step": 6072
    },
    {
      "epoch": 0.4719459123406901,
      "grad_norm": 0.5203769207000732,
      "learning_rate": 7.64027043829655e-06,
      "loss": 0.1608,
      "step": 6073
    },
    {
      "epoch": 0.472023624494871,
      "grad_norm": 0.05672352761030197,
      "learning_rate": 7.639881877525646e-06,
      "loss": 0.0138,
      "step": 6074
    },
    {
      "epoch": 0.4721013366490519,
      "grad_norm": 0.5685981512069702,
      "learning_rate": 7.639493316754741e-06,
      "loss": 0.5915,
      "step": 6075
    },
    {
      "epoch": 0.4721790488032328,
      "grad_norm": 0.6023061275482178,
      "learning_rate": 7.639104755983836e-06,
      "loss": 0.323,
      "step": 6076
    },
    {
      "epoch": 0.47225676095741376,
      "grad_norm": 0.3902325928211212,
      "learning_rate": 7.638716195212931e-06,
      "loss": 0.217,
      "step": 6077
    },
    {
      "epoch": 0.47233447311159465,
      "grad_norm": 0.7779473662376404,
      "learning_rate": 7.638327634442028e-06,
      "loss": 0.65,
      "step": 6078
    },
    {
      "epoch": 0.47241218526577555,
      "grad_norm": 0.18314418196678162,
      "learning_rate": 7.637939073671123e-06,
      "loss": 0.0972,
      "step": 6079
    },
    {
      "epoch": 0.4724898974199565,
      "grad_norm": 0.42616358399391174,
      "learning_rate": 7.637550512900218e-06,
      "loss": 0.1733,
      "step": 6080
    },
    {
      "epoch": 0.4725676095741374,
      "grad_norm": 0.20976559817790985,
      "learning_rate": 7.637161952129314e-06,
      "loss": 0.0732,
      "step": 6081
    },
    {
      "epoch": 0.4726453217283183,
      "grad_norm": 0.5279043316841125,
      "learning_rate": 7.63677339135841e-06,
      "loss": 0.8855,
      "step": 6082
    },
    {
      "epoch": 0.4727230338824992,
      "grad_norm": 0.322012722492218,
      "learning_rate": 7.636384830587504e-06,
      "loss": 0.1751,
      "step": 6083
    },
    {
      "epoch": 0.47280074603668015,
      "grad_norm": 0.21640124917030334,
      "learning_rate": 7.635996269816601e-06,
      "loss": 0.0611,
      "step": 6084
    },
    {
      "epoch": 0.47287845819086105,
      "grad_norm": 0.20693933963775635,
      "learning_rate": 7.635607709045696e-06,
      "loss": 0.0651,
      "step": 6085
    },
    {
      "epoch": 0.47295617034504195,
      "grad_norm": 0.11204572021961212,
      "learning_rate": 7.63521914827479e-06,
      "loss": 0.046,
      "step": 6086
    },
    {
      "epoch": 0.4730338824992229,
      "grad_norm": 0.8794181942939758,
      "learning_rate": 7.634830587503886e-06,
      "loss": 0.1905,
      "step": 6087
    },
    {
      "epoch": 0.4731115946534038,
      "grad_norm": 0.36792826652526855,
      "learning_rate": 7.634442026732982e-06,
      "loss": 0.3086,
      "step": 6088
    },
    {
      "epoch": 0.4731893068075847,
      "grad_norm": 0.0915125161409378,
      "learning_rate": 7.634053465962077e-06,
      "loss": 0.0534,
      "step": 6089
    },
    {
      "epoch": 0.4732670189617656,
      "grad_norm": 0.32806795835494995,
      "learning_rate": 7.633664905191172e-06,
      "loss": 0.1655,
      "step": 6090
    },
    {
      "epoch": 0.47334473111594655,
      "grad_norm": 0.45446717739105225,
      "learning_rate": 7.633276344420269e-06,
      "loss": 0.0848,
      "step": 6091
    },
    {
      "epoch": 0.47342244327012745,
      "grad_norm": 0.1345943808555603,
      "learning_rate": 7.632887783649364e-06,
      "loss": 0.0727,
      "step": 6092
    },
    {
      "epoch": 0.47350015542430834,
      "grad_norm": 0.28189021348953247,
      "learning_rate": 7.632499222878459e-06,
      "loss": 0.1803,
      "step": 6093
    },
    {
      "epoch": 0.4735778675784893,
      "grad_norm": 0.14507250487804413,
      "learning_rate": 7.632110662107555e-06,
      "loss": 0.0393,
      "step": 6094
    },
    {
      "epoch": 0.4736555797326702,
      "grad_norm": 0.24097280204296112,
      "learning_rate": 7.631722101336649e-06,
      "loss": 0.1979,
      "step": 6095
    },
    {
      "epoch": 0.4737332918868511,
      "grad_norm": 0.08515667915344238,
      "learning_rate": 7.631333540565745e-06,
      "loss": 0.0408,
      "step": 6096
    },
    {
      "epoch": 0.473811004041032,
      "grad_norm": 0.6448085308074951,
      "learning_rate": 7.63094497979484e-06,
      "loss": 0.3064,
      "step": 6097
    },
    {
      "epoch": 0.47388871619521294,
      "grad_norm": 0.08221354335546494,
      "learning_rate": 7.630556419023935e-06,
      "loss": 0.0636,
      "step": 6098
    },
    {
      "epoch": 0.47396642834939384,
      "grad_norm": 0.17480877041816711,
      "learning_rate": 7.630167858253032e-06,
      "loss": 0.0476,
      "step": 6099
    },
    {
      "epoch": 0.47404414050357474,
      "grad_norm": 0.9801283478736877,
      "learning_rate": 7.629779297482127e-06,
      "loss": 0.4729,
      "step": 6100
    },
    {
      "epoch": 0.4741218526577557,
      "grad_norm": 0.33123987913131714,
      "learning_rate": 7.629390736711222e-06,
      "loss": 0.1776,
      "step": 6101
    },
    {
      "epoch": 0.4741995648119366,
      "grad_norm": 0.7112501263618469,
      "learning_rate": 7.629002175940318e-06,
      "loss": 0.466,
      "step": 6102
    },
    {
      "epoch": 0.4742772769661175,
      "grad_norm": 0.39299702644348145,
      "learning_rate": 7.628613615169413e-06,
      "loss": 0.2345,
      "step": 6103
    },
    {
      "epoch": 0.4743549891202984,
      "grad_norm": 0.11698034405708313,
      "learning_rate": 7.628225054398508e-06,
      "loss": 0.0342,
      "step": 6104
    },
    {
      "epoch": 0.47443270127447934,
      "grad_norm": 0.4747954308986664,
      "learning_rate": 7.627836493627604e-06,
      "loss": 0.374,
      "step": 6105
    },
    {
      "epoch": 0.47451041342866024,
      "grad_norm": 0.45990118384361267,
      "learning_rate": 7.6274479328567e-06,
      "loss": 0.2309,
      "step": 6106
    },
    {
      "epoch": 0.47458812558284114,
      "grad_norm": 0.6809170246124268,
      "learning_rate": 7.627059372085794e-06,
      "loss": 0.2755,
      "step": 6107
    },
    {
      "epoch": 0.4746658377370221,
      "grad_norm": 0.12151064723730087,
      "learning_rate": 7.62667081131489e-06,
      "loss": 0.0332,
      "step": 6108
    },
    {
      "epoch": 0.474743549891203,
      "grad_norm": 0.47194239497184753,
      "learning_rate": 7.626282250543986e-06,
      "loss": 0.3461,
      "step": 6109
    },
    {
      "epoch": 0.4748212620453839,
      "grad_norm": 0.24084541201591492,
      "learning_rate": 7.625893689773081e-06,
      "loss": 0.0993,
      "step": 6110
    },
    {
      "epoch": 0.47489897419956484,
      "grad_norm": 0.1800742894411087,
      "learning_rate": 7.625505129002176e-06,
      "loss": 0.085,
      "step": 6111
    },
    {
      "epoch": 0.47497668635374574,
      "grad_norm": 0.37725844979286194,
      "learning_rate": 7.625116568231272e-06,
      "loss": 0.2683,
      "step": 6112
    },
    {
      "epoch": 0.47505439850792663,
      "grad_norm": 0.2988334000110626,
      "learning_rate": 7.624728007460367e-06,
      "loss": 0.1007,
      "step": 6113
    },
    {
      "epoch": 0.47513211066210753,
      "grad_norm": 0.3703744113445282,
      "learning_rate": 7.624339446689463e-06,
      "loss": 0.1266,
      "step": 6114
    },
    {
      "epoch": 0.4752098228162885,
      "grad_norm": 0.5491392612457275,
      "learning_rate": 7.623950885918559e-06,
      "loss": 0.2951,
      "step": 6115
    },
    {
      "epoch": 0.4752875349704694,
      "grad_norm": 0.5733228325843811,
      "learning_rate": 7.6235623251476545e-06,
      "loss": 0.4133,
      "step": 6116
    },
    {
      "epoch": 0.4753652471246503,
      "grad_norm": 0.18534721434116364,
      "learning_rate": 7.623173764376749e-06,
      "loss": 0.0395,
      "step": 6117
    },
    {
      "epoch": 0.47544295927883123,
      "grad_norm": 0.40907543897628784,
      "learning_rate": 7.6227852036058444e-06,
      "loss": 0.4842,
      "step": 6118
    },
    {
      "epoch": 0.47552067143301213,
      "grad_norm": 0.8734750747680664,
      "learning_rate": 7.62239664283494e-06,
      "loss": 0.6827,
      "step": 6119
    },
    {
      "epoch": 0.47559838358719303,
      "grad_norm": 0.3361126184463501,
      "learning_rate": 7.622008082064035e-06,
      "loss": 0.594,
      "step": 6120
    },
    {
      "epoch": 0.4756760957413739,
      "grad_norm": 0.8608564734458923,
      "learning_rate": 7.621619521293131e-06,
      "loss": 0.1098,
      "step": 6121
    },
    {
      "epoch": 0.4757538078955549,
      "grad_norm": 0.3261996805667877,
      "learning_rate": 7.621230960522227e-06,
      "loss": 0.2744,
      "step": 6122
    },
    {
      "epoch": 0.4758315200497358,
      "grad_norm": 0.7520728707313538,
      "learning_rate": 7.620842399751322e-06,
      "loss": 0.2548,
      "step": 6123
    },
    {
      "epoch": 0.4759092322039167,
      "grad_norm": 0.2807248532772064,
      "learning_rate": 7.6204538389804175e-06,
      "loss": 0.1417,
      "step": 6124
    },
    {
      "epoch": 0.47598694435809763,
      "grad_norm": 0.22564195096492767,
      "learning_rate": 7.620065278209513e-06,
      "loss": 0.1041,
      "step": 6125
    },
    {
      "epoch": 0.47606465651227853,
      "grad_norm": 0.20882785320281982,
      "learning_rate": 7.6196767174386074e-06,
      "loss": 0.1683,
      "step": 6126
    },
    {
      "epoch": 0.4761423686664594,
      "grad_norm": 0.5640479922294617,
      "learning_rate": 7.619288156667703e-06,
      "loss": 0.5598,
      "step": 6127
    },
    {
      "epoch": 0.4762200808206403,
      "grad_norm": 0.17164772748947144,
      "learning_rate": 7.618899595896799e-06,
      "loss": 0.1093,
      "step": 6128
    },
    {
      "epoch": 0.4762977929748213,
      "grad_norm": 0.240390345454216,
      "learning_rate": 7.618511035125894e-06,
      "loss": 0.1155,
      "step": 6129
    },
    {
      "epoch": 0.4763755051290022,
      "grad_norm": 0.239461287856102,
      "learning_rate": 7.61812247435499e-06,
      "loss": 0.045,
      "step": 6130
    },
    {
      "epoch": 0.4764532172831831,
      "grad_norm": 0.3004301190376282,
      "learning_rate": 7.6177339135840856e-06,
      "loss": 0.1557,
      "step": 6131
    },
    {
      "epoch": 0.476530929437364,
      "grad_norm": 0.3982793390750885,
      "learning_rate": 7.6173453528131805e-06,
      "loss": 0.3413,
      "step": 6132
    },
    {
      "epoch": 0.4766086415915449,
      "grad_norm": 0.1782611757516861,
      "learning_rate": 7.616956792042276e-06,
      "loss": 0.0454,
      "step": 6133
    },
    {
      "epoch": 0.4766863537457258,
      "grad_norm": 0.08908277004957199,
      "learning_rate": 7.616568231271372e-06,
      "loss": 0.0184,
      "step": 6134
    },
    {
      "epoch": 0.4767640658999067,
      "grad_norm": 0.4184317886829376,
      "learning_rate": 7.616179670500466e-06,
      "loss": 0.1734,
      "step": 6135
    },
    {
      "epoch": 0.4768417780540877,
      "grad_norm": 0.12819638848304749,
      "learning_rate": 7.615791109729562e-06,
      "loss": 0.037,
      "step": 6136
    },
    {
      "epoch": 0.47691949020826857,
      "grad_norm": 0.07792702317237854,
      "learning_rate": 7.615402548958658e-06,
      "loss": 0.0533,
      "step": 6137
    },
    {
      "epoch": 0.47699720236244947,
      "grad_norm": 0.4233514666557312,
      "learning_rate": 7.615013988187753e-06,
      "loss": 0.7263,
      "step": 6138
    },
    {
      "epoch": 0.4770749145166304,
      "grad_norm": 1.8152189254760742,
      "learning_rate": 7.6146254274168486e-06,
      "loss": 0.8538,
      "step": 6139
    },
    {
      "epoch": 0.4771526266708113,
      "grad_norm": 0.15058065950870514,
      "learning_rate": 7.614236866645944e-06,
      "loss": 0.0936,
      "step": 6140
    },
    {
      "epoch": 0.4772303388249922,
      "grad_norm": 0.33475372195243835,
      "learning_rate": 7.613848305875039e-06,
      "loss": 0.1037,
      "step": 6141
    },
    {
      "epoch": 0.4773080509791731,
      "grad_norm": 0.45632079243659973,
      "learning_rate": 7.613459745104135e-06,
      "loss": 0.2113,
      "step": 6142
    },
    {
      "epoch": 0.47738576313335407,
      "grad_norm": 0.5225318670272827,
      "learning_rate": 7.613071184333231e-06,
      "loss": 0.5752,
      "step": 6143
    },
    {
      "epoch": 0.47746347528753497,
      "grad_norm": 0.057733938097953796,
      "learning_rate": 7.612682623562325e-06,
      "loss": 0.0046,
      "step": 6144
    },
    {
      "epoch": 0.47754118744171586,
      "grad_norm": 0.358684241771698,
      "learning_rate": 7.612294062791421e-06,
      "loss": 0.1911,
      "step": 6145
    },
    {
      "epoch": 0.4776188995958968,
      "grad_norm": 0.26200705766677856,
      "learning_rate": 7.611905502020517e-06,
      "loss": 0.2498,
      "step": 6146
    },
    {
      "epoch": 0.4776966117500777,
      "grad_norm": 0.7036116719245911,
      "learning_rate": 7.611516941249612e-06,
      "loss": 0.2154,
      "step": 6147
    },
    {
      "epoch": 0.4777743239042586,
      "grad_norm": 0.26750844717025757,
      "learning_rate": 7.611128380478707e-06,
      "loss": 0.0996,
      "step": 6148
    },
    {
      "epoch": 0.47785203605843957,
      "grad_norm": 0.12094199657440186,
      "learning_rate": 7.610739819707803e-06,
      "loss": 0.0338,
      "step": 6149
    },
    {
      "epoch": 0.47792974821262046,
      "grad_norm": 0.4209313690662384,
      "learning_rate": 7.610351258936899e-06,
      "loss": 0.2233,
      "step": 6150
    },
    {
      "epoch": 0.47800746036680136,
      "grad_norm": 0.7401988506317139,
      "learning_rate": 7.609962698165994e-06,
      "loss": 0.3283,
      "step": 6151
    },
    {
      "epoch": 0.47808517252098226,
      "grad_norm": 0.2032146006822586,
      "learning_rate": 7.60957413739509e-06,
      "loss": 0.0622,
      "step": 6152
    },
    {
      "epoch": 0.4781628846751632,
      "grad_norm": 0.040659349411726,
      "learning_rate": 7.6091855766241855e-06,
      "loss": 0.0064,
      "step": 6153
    },
    {
      "epoch": 0.4782405968293441,
      "grad_norm": 0.687038004398346,
      "learning_rate": 7.6087970158532796e-06,
      "loss": 0.4421,
      "step": 6154
    },
    {
      "epoch": 0.478318308983525,
      "grad_norm": 0.07923758029937744,
      "learning_rate": 7.608408455082375e-06,
      "loss": 0.0368,
      "step": 6155
    },
    {
      "epoch": 0.47839602113770596,
      "grad_norm": 0.10996166616678238,
      "learning_rate": 7.608019894311471e-06,
      "loss": 0.0468,
      "step": 6156
    },
    {
      "epoch": 0.47847373329188686,
      "grad_norm": 0.40292468667030334,
      "learning_rate": 7.607631333540566e-06,
      "loss": 0.3424,
      "step": 6157
    },
    {
      "epoch": 0.47855144544606776,
      "grad_norm": 0.3998274505138397,
      "learning_rate": 7.607242772769662e-06,
      "loss": 0.0861,
      "step": 6158
    },
    {
      "epoch": 0.47862915760024866,
      "grad_norm": 0.4686291217803955,
      "learning_rate": 7.606854211998758e-06,
      "loss": 0.2068,
      "step": 6159
    },
    {
      "epoch": 0.4787068697544296,
      "grad_norm": 0.3903198540210724,
      "learning_rate": 7.606465651227853e-06,
      "loss": 0.1053,
      "step": 6160
    },
    {
      "epoch": 0.4787845819086105,
      "grad_norm": 0.2838238477706909,
      "learning_rate": 7.6060770904569485e-06,
      "loss": 0.1042,
      "step": 6161
    },
    {
      "epoch": 0.4788622940627914,
      "grad_norm": 0.20682187378406525,
      "learning_rate": 7.605688529686044e-06,
      "loss": 0.085,
      "step": 6162
    },
    {
      "epoch": 0.47894000621697236,
      "grad_norm": 0.23111078143119812,
      "learning_rate": 7.605299968915138e-06,
      "loss": 0.135,
      "step": 6163
    },
    {
      "epoch": 0.47901771837115326,
      "grad_norm": 0.4449721872806549,
      "learning_rate": 7.604911408144234e-06,
      "loss": 0.1429,
      "step": 6164
    },
    {
      "epoch": 0.47909543052533415,
      "grad_norm": 0.3158448040485382,
      "learning_rate": 7.60452284737333e-06,
      "loss": 0.1443,
      "step": 6165
    },
    {
      "epoch": 0.47917314267951505,
      "grad_norm": 0.4799635112285614,
      "learning_rate": 7.604134286602425e-06,
      "loss": 0.2276,
      "step": 6166
    },
    {
      "epoch": 0.479250854833696,
      "grad_norm": 0.23969215154647827,
      "learning_rate": 7.603745725831521e-06,
      "loss": 0.0528,
      "step": 6167
    },
    {
      "epoch": 0.4793285669878769,
      "grad_norm": 0.8861228227615356,
      "learning_rate": 7.6033571650606165e-06,
      "loss": 0.5673,
      "step": 6168
    },
    {
      "epoch": 0.4794062791420578,
      "grad_norm": 0.49626895785331726,
      "learning_rate": 7.6029686042897114e-06,
      "loss": 0.1241,
      "step": 6169
    },
    {
      "epoch": 0.47948399129623875,
      "grad_norm": 0.19828353822231293,
      "learning_rate": 7.602580043518807e-06,
      "loss": 0.0762,
      "step": 6170
    },
    {
      "epoch": 0.47956170345041965,
      "grad_norm": 0.1252165585756302,
      "learning_rate": 7.602191482747903e-06,
      "loss": 0.056,
      "step": 6171
    },
    {
      "epoch": 0.47963941560460055,
      "grad_norm": 0.3483944535255432,
      "learning_rate": 7.601802921976997e-06,
      "loss": 0.0622,
      "step": 6172
    },
    {
      "epoch": 0.47971712775878145,
      "grad_norm": 0.1230781078338623,
      "learning_rate": 7.601414361206093e-06,
      "loss": 0.0434,
      "step": 6173
    },
    {
      "epoch": 0.4797948399129624,
      "grad_norm": 0.713163435459137,
      "learning_rate": 7.601025800435189e-06,
      "loss": 0.5985,
      "step": 6174
    },
    {
      "epoch": 0.4798725520671433,
      "grad_norm": 0.6306192278862,
      "learning_rate": 7.600637239664284e-06,
      "loss": 0.1908,
      "step": 6175
    },
    {
      "epoch": 0.4799502642213242,
      "grad_norm": 0.21132126450538635,
      "learning_rate": 7.6002486788933795e-06,
      "loss": 0.0695,
      "step": 6176
    },
    {
      "epoch": 0.48002797637550515,
      "grad_norm": 0.10595781356096268,
      "learning_rate": 7.599860118122475e-06,
      "loss": 0.0302,
      "step": 6177
    },
    {
      "epoch": 0.48010568852968605,
      "grad_norm": 0.11918046325445175,
      "learning_rate": 7.599471557351571e-06,
      "loss": 0.0202,
      "step": 6178
    },
    {
      "epoch": 0.48018340068386695,
      "grad_norm": 0.1778651773929596,
      "learning_rate": 7.599082996580666e-06,
      "loss": 0.0738,
      "step": 6179
    },
    {
      "epoch": 0.48026111283804784,
      "grad_norm": 0.3108411729335785,
      "learning_rate": 7.598694435809762e-06,
      "loss": 0.3479,
      "step": 6180
    },
    {
      "epoch": 0.4803388249922288,
      "grad_norm": 0.20151816308498383,
      "learning_rate": 7.598305875038857e-06,
      "loss": 0.0875,
      "step": 6181
    },
    {
      "epoch": 0.4804165371464097,
      "grad_norm": 0.798265278339386,
      "learning_rate": 7.597917314267952e-06,
      "loss": 0.375,
      "step": 6182
    },
    {
      "epoch": 0.4804942493005906,
      "grad_norm": 0.8248039484024048,
      "learning_rate": 7.5975287534970475e-06,
      "loss": 0.2941,
      "step": 6183
    },
    {
      "epoch": 0.48057196145477155,
      "grad_norm": 0.28180164098739624,
      "learning_rate": 7.597140192726143e-06,
      "loss": 0.0626,
      "step": 6184
    },
    {
      "epoch": 0.48064967360895244,
      "grad_norm": 0.5293457508087158,
      "learning_rate": 7.596751631955238e-06,
      "loss": 0.1607,
      "step": 6185
    },
    {
      "epoch": 0.48072738576313334,
      "grad_norm": 0.22840654850006104,
      "learning_rate": 7.596363071184334e-06,
      "loss": 0.0981,
      "step": 6186
    },
    {
      "epoch": 0.4808050979173143,
      "grad_norm": 0.2897127568721771,
      "learning_rate": 7.59597451041343e-06,
      "loss": 0.1085,
      "step": 6187
    },
    {
      "epoch": 0.4808828100714952,
      "grad_norm": 0.48643526434898376,
      "learning_rate": 7.595585949642524e-06,
      "loss": 0.2559,
      "step": 6188
    },
    {
      "epoch": 0.4809605222256761,
      "grad_norm": 0.7331008315086365,
      "learning_rate": 7.59519738887162e-06,
      "loss": 0.9431,
      "step": 6189
    },
    {
      "epoch": 0.481038234379857,
      "grad_norm": 0.07534711807966232,
      "learning_rate": 7.5948088281007156e-06,
      "loss": 0.0255,
      "step": 6190
    },
    {
      "epoch": 0.48111594653403794,
      "grad_norm": 0.3369947373867035,
      "learning_rate": 7.5944202673298105e-06,
      "loss": 0.0693,
      "step": 6191
    },
    {
      "epoch": 0.48119365868821884,
      "grad_norm": 0.19912280142307281,
      "learning_rate": 7.594031706558906e-06,
      "loss": 0.0379,
      "step": 6192
    },
    {
      "epoch": 0.48127137084239974,
      "grad_norm": 0.5467541813850403,
      "learning_rate": 7.593643145788002e-06,
      "loss": 0.3994,
      "step": 6193
    },
    {
      "epoch": 0.4813490829965807,
      "grad_norm": 0.22594542801380157,
      "learning_rate": 7.593254585017097e-06,
      "loss": 0.0521,
      "step": 6194
    },
    {
      "epoch": 0.4814267951507616,
      "grad_norm": 0.46389755606651306,
      "learning_rate": 7.592866024246193e-06,
      "loss": 0.0865,
      "step": 6195
    },
    {
      "epoch": 0.4815045073049425,
      "grad_norm": 1.4879000186920166,
      "learning_rate": 7.592477463475289e-06,
      "loss": 1.0268,
      "step": 6196
    },
    {
      "epoch": 0.4815822194591234,
      "grad_norm": 0.12023302912712097,
      "learning_rate": 7.592088902704383e-06,
      "loss": 0.0457,
      "step": 6197
    },
    {
      "epoch": 0.48165993161330434,
      "grad_norm": 0.7168689370155334,
      "learning_rate": 7.5917003419334785e-06,
      "loss": 0.2184,
      "step": 6198
    },
    {
      "epoch": 0.48173764376748524,
      "grad_norm": 0.2683701813220978,
      "learning_rate": 7.591311781162574e-06,
      "loss": 0.1887,
      "step": 6199
    },
    {
      "epoch": 0.48181535592166613,
      "grad_norm": 0.5129011869430542,
      "learning_rate": 7.590923220391669e-06,
      "loss": 0.1662,
      "step": 6200
    },
    {
      "epoch": 0.4818930680758471,
      "grad_norm": 1.0808135271072388,
      "learning_rate": 7.590534659620765e-06,
      "loss": 0.5554,
      "step": 6201
    },
    {
      "epoch": 0.481970780230028,
      "grad_norm": 0.2888089716434479,
      "learning_rate": 7.590146098849861e-06,
      "loss": 0.0493,
      "step": 6202
    },
    {
      "epoch": 0.4820484923842089,
      "grad_norm": 0.16167253255844116,
      "learning_rate": 7.589757538078956e-06,
      "loss": 0.0376,
      "step": 6203
    },
    {
      "epoch": 0.4821262045383898,
      "grad_norm": 0.2550380825996399,
      "learning_rate": 7.589368977308052e-06,
      "loss": 0.1542,
      "step": 6204
    },
    {
      "epoch": 0.48220391669257073,
      "grad_norm": 0.3665831685066223,
      "learning_rate": 7.5889804165371474e-06,
      "loss": 0.1533,
      "step": 6205
    },
    {
      "epoch": 0.48228162884675163,
      "grad_norm": 0.32671254873275757,
      "learning_rate": 7.5885918557662415e-06,
      "loss": 0.118,
      "step": 6206
    },
    {
      "epoch": 0.48235934100093253,
      "grad_norm": 0.5440211296081543,
      "learning_rate": 7.588203294995337e-06,
      "loss": 0.4984,
      "step": 6207
    },
    {
      "epoch": 0.4824370531551135,
      "grad_norm": 0.4229818880558014,
      "learning_rate": 7.587814734224433e-06,
      "loss": 0.1696,
      "step": 6208
    },
    {
      "epoch": 0.4825147653092944,
      "grad_norm": 0.3775857090950012,
      "learning_rate": 7.587426173453529e-06,
      "loss": 0.1331,
      "step": 6209
    },
    {
      "epoch": 0.4825924774634753,
      "grad_norm": 0.4002828598022461,
      "learning_rate": 7.587037612682624e-06,
      "loss": 0.122,
      "step": 6210
    },
    {
      "epoch": 0.4826701896176562,
      "grad_norm": 0.6432350873947144,
      "learning_rate": 7.58664905191172e-06,
      "loss": 0.2978,
      "step": 6211
    },
    {
      "epoch": 0.48274790177183713,
      "grad_norm": 0.4196672737598419,
      "learning_rate": 7.5862604911408155e-06,
      "loss": 0.2527,
      "step": 6212
    },
    {
      "epoch": 0.482825613926018,
      "grad_norm": 0.4197159707546234,
      "learning_rate": 7.58587193036991e-06,
      "loss": 0.2235,
      "step": 6213
    },
    {
      "epoch": 0.4829033260801989,
      "grad_norm": 0.9118462204933167,
      "learning_rate": 7.585483369599006e-06,
      "loss": 0.5979,
      "step": 6214
    },
    {
      "epoch": 0.4829810382343799,
      "grad_norm": 0.15405429899692535,
      "learning_rate": 7.585094808828102e-06,
      "loss": 0.0531,
      "step": 6215
    },
    {
      "epoch": 0.4830587503885608,
      "grad_norm": 0.14309941232204437,
      "learning_rate": 7.584706248057196e-06,
      "loss": 0.2254,
      "step": 6216
    },
    {
      "epoch": 0.4831364625427417,
      "grad_norm": 0.08383580297231674,
      "learning_rate": 7.584317687286292e-06,
      "loss": 0.0209,
      "step": 6217
    },
    {
      "epoch": 0.48321417469692257,
      "grad_norm": 0.32194074988365173,
      "learning_rate": 7.583929126515388e-06,
      "loss": 0.0819,
      "step": 6218
    },
    {
      "epoch": 0.4832918868511035,
      "grad_norm": 0.10055040568113327,
      "learning_rate": 7.583540565744483e-06,
      "loss": 0.029,
      "step": 6219
    },
    {
      "epoch": 0.4833695990052844,
      "grad_norm": 0.552699863910675,
      "learning_rate": 7.5831520049735784e-06,
      "loss": 0.2791,
      "step": 6220
    },
    {
      "epoch": 0.4834473111594653,
      "grad_norm": 0.08326839655637741,
      "learning_rate": 7.582763444202674e-06,
      "loss": 0.0246,
      "step": 6221
    },
    {
      "epoch": 0.4835250233136463,
      "grad_norm": 0.4975249171257019,
      "learning_rate": 7.582374883431769e-06,
      "loss": 0.2017,
      "step": 6222
    },
    {
      "epoch": 0.48360273546782717,
      "grad_norm": 0.0661407932639122,
      "learning_rate": 7.581986322660865e-06,
      "loss": 0.0151,
      "step": 6223
    },
    {
      "epoch": 0.48368044762200807,
      "grad_norm": 0.4224126636981964,
      "learning_rate": 7.581597761889961e-06,
      "loss": 0.1493,
      "step": 6224
    },
    {
      "epoch": 0.483758159776189,
      "grad_norm": 0.38320687413215637,
      "learning_rate": 7.581209201119055e-06,
      "loss": 0.212,
      "step": 6225
    },
    {
      "epoch": 0.4838358719303699,
      "grad_norm": 0.38906916975975037,
      "learning_rate": 7.580820640348151e-06,
      "loss": 0.234,
      "step": 6226
    },
    {
      "epoch": 0.4839135840845508,
      "grad_norm": 0.5685698390007019,
      "learning_rate": 7.5804320795772465e-06,
      "loss": 0.3871,
      "step": 6227
    },
    {
      "epoch": 0.4839912962387317,
      "grad_norm": 0.0854402557015419,
      "learning_rate": 7.5800435188063414e-06,
      "loss": 0.0119,
      "step": 6228
    },
    {
      "epoch": 0.48406900839291267,
      "grad_norm": 0.40703701972961426,
      "learning_rate": 7.579654958035437e-06,
      "loss": 0.1459,
      "step": 6229
    },
    {
      "epoch": 0.48414672054709357,
      "grad_norm": 0.055824413895606995,
      "learning_rate": 7.579266397264533e-06,
      "loss": 0.0135,
      "step": 6230
    },
    {
      "epoch": 0.48422443270127447,
      "grad_norm": 0.22050528228282928,
      "learning_rate": 7.578877836493628e-06,
      "loss": 0.1547,
      "step": 6231
    },
    {
      "epoch": 0.4843021448554554,
      "grad_norm": 0.23705892264842987,
      "learning_rate": 7.578489275722724e-06,
      "loss": 0.0648,
      "step": 6232
    },
    {
      "epoch": 0.4843798570096363,
      "grad_norm": 0.23516906797885895,
      "learning_rate": 7.5781007149518196e-06,
      "loss": 0.1006,
      "step": 6233
    },
    {
      "epoch": 0.4844575691638172,
      "grad_norm": 0.22011706233024597,
      "learning_rate": 7.577712154180914e-06,
      "loss": 0.1155,
      "step": 6234
    },
    {
      "epoch": 0.4845352813179981,
      "grad_norm": 0.22971218824386597,
      "learning_rate": 7.5773235934100095e-06,
      "loss": 0.1205,
      "step": 6235
    },
    {
      "epoch": 0.48461299347217907,
      "grad_norm": 0.1714678704738617,
      "learning_rate": 7.576935032639105e-06,
      "loss": 0.1143,
      "step": 6236
    },
    {
      "epoch": 0.48469070562635996,
      "grad_norm": 0.2555576264858246,
      "learning_rate": 7.576546471868201e-06,
      "loss": 0.129,
      "step": 6237
    },
    {
      "epoch": 0.48476841778054086,
      "grad_norm": 0.32286447286605835,
      "learning_rate": 7.576157911097296e-06,
      "loss": 0.1052,
      "step": 6238
    },
    {
      "epoch": 0.4848461299347218,
      "grad_norm": 0.498712420463562,
      "learning_rate": 7.575769350326392e-06,
      "loss": 0.1156,
      "step": 6239
    },
    {
      "epoch": 0.4849238420889027,
      "grad_norm": 0.11278186738491058,
      "learning_rate": 7.575380789555488e-06,
      "loss": 0.0147,
      "step": 6240
    },
    {
      "epoch": 0.4850015542430836,
      "grad_norm": 0.15788350999355316,
      "learning_rate": 7.5749922287845826e-06,
      "loss": 0.2454,
      "step": 6241
    },
    {
      "epoch": 0.4850792663972645,
      "grad_norm": 0.598854660987854,
      "learning_rate": 7.574603668013678e-06,
      "loss": 0.4129,
      "step": 6242
    },
    {
      "epoch": 0.48515697855144546,
      "grad_norm": 0.05223334953188896,
      "learning_rate": 7.574215107242774e-06,
      "loss": 0.0141,
      "step": 6243
    },
    {
      "epoch": 0.48523469070562636,
      "grad_norm": 0.39190641045570374,
      "learning_rate": 7.573826546471868e-06,
      "loss": 0.2386,
      "step": 6244
    },
    {
      "epoch": 0.48531240285980726,
      "grad_norm": 0.3118574023246765,
      "learning_rate": 7.573437985700964e-06,
      "loss": 0.3136,
      "step": 6245
    },
    {
      "epoch": 0.4853901150139882,
      "grad_norm": 0.3052201271057129,
      "learning_rate": 7.57304942493006e-06,
      "loss": 0.1029,
      "step": 6246
    },
    {
      "epoch": 0.4854678271681691,
      "grad_norm": 0.403158962726593,
      "learning_rate": 7.572660864159155e-06,
      "loss": 0.134,
      "step": 6247
    },
    {
      "epoch": 0.48554553932235,
      "grad_norm": 0.15527857840061188,
      "learning_rate": 7.572272303388251e-06,
      "loss": 0.0453,
      "step": 6248
    },
    {
      "epoch": 0.4856232514765309,
      "grad_norm": 0.08421052247285843,
      "learning_rate": 7.571883742617346e-06,
      "loss": 0.0228,
      "step": 6249
    },
    {
      "epoch": 0.48570096363071186,
      "grad_norm": 0.3069544732570648,
      "learning_rate": 7.571495181846441e-06,
      "loss": 0.2245,
      "step": 6250
    },
    {
      "epoch": 0.48577867578489276,
      "grad_norm": 0.2495078444480896,
      "learning_rate": 7.571106621075537e-06,
      "loss": 0.1715,
      "step": 6251
    },
    {
      "epoch": 0.48585638793907365,
      "grad_norm": 0.3439858853816986,
      "learning_rate": 7.570718060304633e-06,
      "loss": 0.5512,
      "step": 6252
    },
    {
      "epoch": 0.4859341000932546,
      "grad_norm": 0.23793751001358032,
      "learning_rate": 7.570329499533727e-06,
      "loss": 0.0882,
      "step": 6253
    },
    {
      "epoch": 0.4860118122474355,
      "grad_norm": 0.22097530961036682,
      "learning_rate": 7.569940938762823e-06,
      "loss": 0.0621,
      "step": 6254
    },
    {
      "epoch": 0.4860895244016164,
      "grad_norm": 0.302570641040802,
      "learning_rate": 7.569552377991919e-06,
      "loss": 0.0728,
      "step": 6255
    },
    {
      "epoch": 0.4861672365557973,
      "grad_norm": 0.1585383266210556,
      "learning_rate": 7.569163817221014e-06,
      "loss": 0.0598,
      "step": 6256
    },
    {
      "epoch": 0.48624494870997825,
      "grad_norm": 0.415377140045166,
      "learning_rate": 7.568775256450109e-06,
      "loss": 0.1098,
      "step": 6257
    },
    {
      "epoch": 0.48632266086415915,
      "grad_norm": 0.2584080696105957,
      "learning_rate": 7.568386695679205e-06,
      "loss": 0.1916,
      "step": 6258
    },
    {
      "epoch": 0.48640037301834005,
      "grad_norm": 0.8263434171676636,
      "learning_rate": 7.5679981349083e-06,
      "loss": 0.3932,
      "step": 6259
    },
    {
      "epoch": 0.486478085172521,
      "grad_norm": 0.4962102472782135,
      "learning_rate": 7.567609574137396e-06,
      "loss": 0.2729,
      "step": 6260
    },
    {
      "epoch": 0.4865557973267019,
      "grad_norm": 0.0645759105682373,
      "learning_rate": 7.567221013366492e-06,
      "loss": 0.0311,
      "step": 6261
    },
    {
      "epoch": 0.4866335094808828,
      "grad_norm": 0.5762884616851807,
      "learning_rate": 7.566832452595586e-06,
      "loss": 0.1653,
      "step": 6262
    },
    {
      "epoch": 0.48671122163506375,
      "grad_norm": 0.4379007816314697,
      "learning_rate": 7.566443891824682e-06,
      "loss": 0.1866,
      "step": 6263
    },
    {
      "epoch": 0.48678893378924465,
      "grad_norm": 0.24030575156211853,
      "learning_rate": 7.566055331053777e-06,
      "loss": 0.1504,
      "step": 6264
    },
    {
      "epoch": 0.48686664594342555,
      "grad_norm": 0.2537068724632263,
      "learning_rate": 7.565666770282872e-06,
      "loss": 0.0855,
      "step": 6265
    },
    {
      "epoch": 0.48694435809760644,
      "grad_norm": 0.5885174870491028,
      "learning_rate": 7.565278209511968e-06,
      "loss": 0.4265,
      "step": 6266
    },
    {
      "epoch": 0.4870220702517874,
      "grad_norm": 0.7781051397323608,
      "learning_rate": 7.564889648741064e-06,
      "loss": 0.4897,
      "step": 6267
    },
    {
      "epoch": 0.4870997824059683,
      "grad_norm": 0.10130562633275986,
      "learning_rate": 7.56450108797016e-06,
      "loss": 0.018,
      "step": 6268
    },
    {
      "epoch": 0.4871774945601492,
      "grad_norm": 0.5387492775917053,
      "learning_rate": 7.564112527199255e-06,
      "loss": 0.2865,
      "step": 6269
    },
    {
      "epoch": 0.48725520671433015,
      "grad_norm": 0.3945004343986511,
      "learning_rate": 7.5637239664283505e-06,
      "loss": 0.1683,
      "step": 6270
    },
    {
      "epoch": 0.48733291886851104,
      "grad_norm": 0.21279199421405792,
      "learning_rate": 7.563335405657446e-06,
      "loss": 0.0237,
      "step": 6271
    },
    {
      "epoch": 0.48741063102269194,
      "grad_norm": 0.4454955756664276,
      "learning_rate": 7.56294684488654e-06,
      "loss": 0.2385,
      "step": 6272
    },
    {
      "epoch": 0.48748834317687284,
      "grad_norm": 0.2605464458465576,
      "learning_rate": 7.562558284115636e-06,
      "loss": 0.0917,
      "step": 6273
    },
    {
      "epoch": 0.4875660553310538,
      "grad_norm": 0.22761638462543488,
      "learning_rate": 7.562169723344732e-06,
      "loss": 0.1388,
      "step": 6274
    },
    {
      "epoch": 0.4876437674852347,
      "grad_norm": 0.00808383896946907,
      "learning_rate": 7.561781162573827e-06,
      "loss": 0.0022,
      "step": 6275
    },
    {
      "epoch": 0.4877214796394156,
      "grad_norm": 0.24472571909427643,
      "learning_rate": 7.561392601802923e-06,
      "loss": 0.1631,
      "step": 6276
    },
    {
      "epoch": 0.48779919179359654,
      "grad_norm": 1.5868641138076782,
      "learning_rate": 7.5610040410320185e-06,
      "loss": 0.8014,
      "step": 6277
    },
    {
      "epoch": 0.48787690394777744,
      "grad_norm": 0.50105220079422,
      "learning_rate": 7.5606154802611135e-06,
      "loss": 0.2369,
      "step": 6278
    },
    {
      "epoch": 0.48795461610195834,
      "grad_norm": 0.2973394989967346,
      "learning_rate": 7.560226919490209e-06,
      "loss": 0.1217,
      "step": 6279
    },
    {
      "epoch": 0.48803232825613924,
      "grad_norm": 0.4656396806240082,
      "learning_rate": 7.559838358719305e-06,
      "loss": 0.1784,
      "step": 6280
    },
    {
      "epoch": 0.4881100404103202,
      "grad_norm": 0.19680476188659668,
      "learning_rate": 7.559449797948399e-06,
      "loss": 0.0836,
      "step": 6281
    },
    {
      "epoch": 0.4881877525645011,
      "grad_norm": 0.4582827389240265,
      "learning_rate": 7.559061237177495e-06,
      "loss": 0.1865,
      "step": 6282
    },
    {
      "epoch": 0.488265464718682,
      "grad_norm": 0.5592995882034302,
      "learning_rate": 7.558672676406591e-06,
      "loss": 0.4553,
      "step": 6283
    },
    {
      "epoch": 0.48834317687286294,
      "grad_norm": 0.4389652609825134,
      "learning_rate": 7.558284115635686e-06,
      "loss": 0.5236,
      "step": 6284
    },
    {
      "epoch": 0.48842088902704384,
      "grad_norm": 0.10795710980892181,
      "learning_rate": 7.5578955548647815e-06,
      "loss": 0.054,
      "step": 6285
    },
    {
      "epoch": 0.48849860118122473,
      "grad_norm": 0.8215603828430176,
      "learning_rate": 7.557506994093877e-06,
      "loss": 0.377,
      "step": 6286
    },
    {
      "epoch": 0.48857631333540563,
      "grad_norm": 0.6411195397377014,
      "learning_rate": 7.557118433322972e-06,
      "loss": 0.2726,
      "step": 6287
    },
    {
      "epoch": 0.4886540254895866,
      "grad_norm": 0.7911441922187805,
      "learning_rate": 7.556729872552068e-06,
      "loss": 0.5205,
      "step": 6288
    },
    {
      "epoch": 0.4887317376437675,
      "grad_norm": 0.7352065443992615,
      "learning_rate": 7.556341311781164e-06,
      "loss": 0.1581,
      "step": 6289
    },
    {
      "epoch": 0.4888094497979484,
      "grad_norm": 0.07660841941833496,
      "learning_rate": 7.555952751010258e-06,
      "loss": 0.0192,
      "step": 6290
    },
    {
      "epoch": 0.48888716195212933,
      "grad_norm": 0.3884487450122833,
      "learning_rate": 7.555564190239354e-06,
      "loss": 0.2568,
      "step": 6291
    },
    {
      "epoch": 0.48896487410631023,
      "grad_norm": 0.5654793977737427,
      "learning_rate": 7.5551756294684496e-06,
      "loss": 0.4586,
      "step": 6292
    },
    {
      "epoch": 0.48904258626049113,
      "grad_norm": 1.0328551530838013,
      "learning_rate": 7.5547870686975445e-06,
      "loss": 0.0612,
      "step": 6293
    },
    {
      "epoch": 0.48912029841467203,
      "grad_norm": 0.2925252616405487,
      "learning_rate": 7.55439850792664e-06,
      "loss": 0.1539,
      "step": 6294
    },
    {
      "epoch": 0.489198010568853,
      "grad_norm": 0.33271127939224243,
      "learning_rate": 7.554009947155736e-06,
      "loss": 0.1002,
      "step": 6295
    },
    {
      "epoch": 0.4892757227230339,
      "grad_norm": 0.2459917664527893,
      "learning_rate": 7.553621386384831e-06,
      "loss": 0.1548,
      "step": 6296
    },
    {
      "epoch": 0.4893534348772148,
      "grad_norm": 0.3644295334815979,
      "learning_rate": 7.553232825613927e-06,
      "loss": 0.3475,
      "step": 6297
    },
    {
      "epoch": 0.48943114703139573,
      "grad_norm": 0.17672099173069,
      "learning_rate": 7.552844264843023e-06,
      "loss": 0.0323,
      "step": 6298
    },
    {
      "epoch": 0.48950885918557663,
      "grad_norm": 0.3656955063343048,
      "learning_rate": 7.5524557040721184e-06,
      "loss": 0.2437,
      "step": 6299
    },
    {
      "epoch": 0.4895865713397575,
      "grad_norm": 0.6641601920127869,
      "learning_rate": 7.5520671433012125e-06,
      "loss": 0.1964,
      "step": 6300
    },
    {
      "epoch": 0.4896642834939385,
      "grad_norm": 0.2132704257965088,
      "learning_rate": 7.551678582530308e-06,
      "loss": 0.0455,
      "step": 6301
    },
    {
      "epoch": 0.4897419956481194,
      "grad_norm": 0.5599313378334045,
      "learning_rate": 7.551290021759404e-06,
      "loss": 0.1899,
      "step": 6302
    },
    {
      "epoch": 0.4898197078023003,
      "grad_norm": 0.237041175365448,
      "learning_rate": 7.550901460988499e-06,
      "loss": 0.2622,
      "step": 6303
    },
    {
      "epoch": 0.4898974199564812,
      "grad_norm": 0.23249590396881104,
      "learning_rate": 7.550512900217595e-06,
      "loss": 0.156,
      "step": 6304
    },
    {
      "epoch": 0.4899751321106621,
      "grad_norm": 0.3408096134662628,
      "learning_rate": 7.550124339446691e-06,
      "loss": 0.1868,
      "step": 6305
    },
    {
      "epoch": 0.490052844264843,
      "grad_norm": 0.18730570375919342,
      "learning_rate": 7.549735778675786e-06,
      "loss": 0.1226,
      "step": 6306
    },
    {
      "epoch": 0.4901305564190239,
      "grad_norm": 0.6419654488563538,
      "learning_rate": 7.5493472179048814e-06,
      "loss": 0.1991,
      "step": 6307
    },
    {
      "epoch": 0.4902082685732049,
      "grad_norm": 0.14978568255901337,
      "learning_rate": 7.548958657133976e-06,
      "loss": 0.0337,
      "step": 6308
    },
    {
      "epoch": 0.4902859807273858,
      "grad_norm": 0.6890478730201721,
      "learning_rate": 7.548570096363071e-06,
      "loss": 0.3541,
      "step": 6309
    },
    {
      "epoch": 0.49036369288156667,
      "grad_norm": 0.3337981700897217,
      "learning_rate": 7.548181535592167e-06,
      "loss": 0.1435,
      "step": 6310
    },
    {
      "epoch": 0.49044140503574757,
      "grad_norm": 0.3151499330997467,
      "learning_rate": 7.547792974821263e-06,
      "loss": 0.1877,
      "step": 6311
    },
    {
      "epoch": 0.4905191171899285,
      "grad_norm": 0.5384941101074219,
      "learning_rate": 7.547404414050358e-06,
      "loss": 0.6751,
      "step": 6312
    },
    {
      "epoch": 0.4905968293441094,
      "grad_norm": 0.14399535953998566,
      "learning_rate": 7.547015853279454e-06,
      "loss": 0.0824,
      "step": 6313
    },
    {
      "epoch": 0.4906745414982903,
      "grad_norm": 0.21086685359477997,
      "learning_rate": 7.5466272925085495e-06,
      "loss": 0.1054,
      "step": 6314
    },
    {
      "epoch": 0.49075225365247127,
      "grad_norm": 0.2416694611310959,
      "learning_rate": 7.5462387317376436e-06,
      "loss": 0.1092,
      "step": 6315
    },
    {
      "epoch": 0.49082996580665217,
      "grad_norm": 0.33096009492874146,
      "learning_rate": 7.545850170966739e-06,
      "loss": 0.1644,
      "step": 6316
    },
    {
      "epoch": 0.49090767796083307,
      "grad_norm": 0.6027475595474243,
      "learning_rate": 7.545461610195835e-06,
      "loss": 0.4192,
      "step": 6317
    },
    {
      "epoch": 0.49098539011501396,
      "grad_norm": 0.21720896661281586,
      "learning_rate": 7.54507304942493e-06,
      "loss": 0.091,
      "step": 6318
    },
    {
      "epoch": 0.4910631022691949,
      "grad_norm": 0.23417054116725922,
      "learning_rate": 7.544684488654026e-06,
      "loss": 0.1551,
      "step": 6319
    },
    {
      "epoch": 0.4911408144233758,
      "grad_norm": 0.28577426075935364,
      "learning_rate": 7.544295927883122e-06,
      "loss": 0.1557,
      "step": 6320
    },
    {
      "epoch": 0.4912185265775567,
      "grad_norm": 0.6699457168579102,
      "learning_rate": 7.543907367112217e-06,
      "loss": 0.2418,
      "step": 6321
    },
    {
      "epoch": 0.49129623873173767,
      "grad_norm": 0.24769741296768188,
      "learning_rate": 7.5435188063413125e-06,
      "loss": 0.0884,
      "step": 6322
    },
    {
      "epoch": 0.49137395088591856,
      "grad_norm": 1.0499248504638672,
      "learning_rate": 7.543130245570408e-06,
      "loss": 0.4088,
      "step": 6323
    },
    {
      "epoch": 0.49145166304009946,
      "grad_norm": 0.31169989705085754,
      "learning_rate": 7.542741684799502e-06,
      "loss": 0.5309,
      "step": 6324
    },
    {
      "epoch": 0.49152937519428036,
      "grad_norm": 0.2721480429172516,
      "learning_rate": 7.542353124028598e-06,
      "loss": 0.0905,
      "step": 6325
    },
    {
      "epoch": 0.4916070873484613,
      "grad_norm": 0.14005614817142487,
      "learning_rate": 7.541964563257694e-06,
      "loss": 0.0593,
      "step": 6326
    },
    {
      "epoch": 0.4916847995026422,
      "grad_norm": 0.5872453451156616,
      "learning_rate": 7.541576002486789e-06,
      "loss": 0.4164,
      "step": 6327
    },
    {
      "epoch": 0.4917625116568231,
      "grad_norm": 0.23294441401958466,
      "learning_rate": 7.541187441715885e-06,
      "loss": 0.1225,
      "step": 6328
    },
    {
      "epoch": 0.49184022381100406,
      "grad_norm": 0.6344305276870728,
      "learning_rate": 7.5407988809449805e-06,
      "loss": 0.3029,
      "step": 6329
    },
    {
      "epoch": 0.49191793596518496,
      "grad_norm": 0.2349611222743988,
      "learning_rate": 7.540410320174076e-06,
      "loss": 0.1573,
      "step": 6330
    },
    {
      "epoch": 0.49199564811936586,
      "grad_norm": 1.445169448852539,
      "learning_rate": 7.540021759403171e-06,
      "loss": 0.4364,
      "step": 6331
    },
    {
      "epoch": 0.49207336027354676,
      "grad_norm": 0.0801519826054573,
      "learning_rate": 7.539633198632267e-06,
      "loss": 0.0212,
      "step": 6332
    },
    {
      "epoch": 0.4921510724277277,
      "grad_norm": 0.1919044554233551,
      "learning_rate": 7.539244637861363e-06,
      "loss": 0.1329,
      "step": 6333
    },
    {
      "epoch": 0.4922287845819086,
      "grad_norm": 1.7566417455673218,
      "learning_rate": 7.538856077090457e-06,
      "loss": 0.9287,
      "step": 6334
    },
    {
      "epoch": 0.4923064967360895,
      "grad_norm": 0.397868812084198,
      "learning_rate": 7.538467516319553e-06,
      "loss": 0.1679,
      "step": 6335
    },
    {
      "epoch": 0.49238420889027046,
      "grad_norm": 0.18459928035736084,
      "learning_rate": 7.5380789555486485e-06,
      "loss": 0.0738,
      "step": 6336
    },
    {
      "epoch": 0.49246192104445136,
      "grad_norm": 0.3444526195526123,
      "learning_rate": 7.5376903947777435e-06,
      "loss": 0.3199,
      "step": 6337
    },
    {
      "epoch": 0.49253963319863225,
      "grad_norm": 0.2810966968536377,
      "learning_rate": 7.537301834006839e-06,
      "loss": 0.2119,
      "step": 6338
    },
    {
      "epoch": 0.4926173453528132,
      "grad_norm": 0.44236335158348083,
      "learning_rate": 7.536913273235935e-06,
      "loss": 0.44,
      "step": 6339
    },
    {
      "epoch": 0.4926950575069941,
      "grad_norm": 0.6211532950401306,
      "learning_rate": 7.53652471246503e-06,
      "loss": 0.2894,
      "step": 6340
    },
    {
      "epoch": 0.492772769661175,
      "grad_norm": 0.4079442322254181,
      "learning_rate": 7.536136151694126e-06,
      "loss": 0.6821,
      "step": 6341
    },
    {
      "epoch": 0.4928504818153559,
      "grad_norm": 0.5235435962677002,
      "learning_rate": 7.535747590923222e-06,
      "loss": 0.5351,
      "step": 6342
    },
    {
      "epoch": 0.49292819396953685,
      "grad_norm": 0.5941757559776306,
      "learning_rate": 7.535359030152316e-06,
      "loss": 0.7475,
      "step": 6343
    },
    {
      "epoch": 0.49300590612371775,
      "grad_norm": 0.4393465518951416,
      "learning_rate": 7.5349704693814115e-06,
      "loss": 0.2173,
      "step": 6344
    },
    {
      "epoch": 0.49308361827789865,
      "grad_norm": 0.2412387728691101,
      "learning_rate": 7.534581908610507e-06,
      "loss": 0.0205,
      "step": 6345
    },
    {
      "epoch": 0.4931613304320796,
      "grad_norm": 0.38298866152763367,
      "learning_rate": 7.534193347839602e-06,
      "loss": 0.6415,
      "step": 6346
    },
    {
      "epoch": 0.4932390425862605,
      "grad_norm": 0.10872761160135269,
      "learning_rate": 7.533804787068698e-06,
      "loss": 0.0381,
      "step": 6347
    },
    {
      "epoch": 0.4933167547404414,
      "grad_norm": 0.4474833607673645,
      "learning_rate": 7.533416226297794e-06,
      "loss": 0.3382,
      "step": 6348
    },
    {
      "epoch": 0.4933944668946223,
      "grad_norm": 0.4066478908061981,
      "learning_rate": 7.533027665526889e-06,
      "loss": 0.1737,
      "step": 6349
    },
    {
      "epoch": 0.49347217904880325,
      "grad_norm": 0.12674954533576965,
      "learning_rate": 7.532639104755985e-06,
      "loss": 0.0787,
      "step": 6350
    },
    {
      "epoch": 0.49354989120298415,
      "grad_norm": 0.21261082589626312,
      "learning_rate": 7.53225054398508e-06,
      "loss": 0.1169,
      "step": 6351
    },
    {
      "epoch": 0.49362760335716505,
      "grad_norm": 0.4682393968105316,
      "learning_rate": 7.5318619832141745e-06,
      "loss": 0.3084,
      "step": 6352
    },
    {
      "epoch": 0.493705315511346,
      "grad_norm": 0.6233207583427429,
      "learning_rate": 7.53147342244327e-06,
      "loss": 0.2443,
      "step": 6353
    },
    {
      "epoch": 0.4937830276655269,
      "grad_norm": 0.15720006823539734,
      "learning_rate": 7.531084861672366e-06,
      "loss": 0.0397,
      "step": 6354
    },
    {
      "epoch": 0.4938607398197078,
      "grad_norm": 0.04000981152057648,
      "learning_rate": 7.530696300901461e-06,
      "loss": 0.0024,
      "step": 6355
    },
    {
      "epoch": 0.4939384519738887,
      "grad_norm": 0.2774297297000885,
      "learning_rate": 7.530307740130557e-06,
      "loss": 0.1529,
      "step": 6356
    },
    {
      "epoch": 0.49401616412806965,
      "grad_norm": 0.14887776970863342,
      "learning_rate": 7.529919179359653e-06,
      "loss": 0.018,
      "step": 6357
    },
    {
      "epoch": 0.49409387628225054,
      "grad_norm": 0.2967066168785095,
      "learning_rate": 7.529530618588748e-06,
      "loss": 0.0691,
      "step": 6358
    },
    {
      "epoch": 0.49417158843643144,
      "grad_norm": 0.29720404744148254,
      "learning_rate": 7.529142057817843e-06,
      "loss": 0.2506,
      "step": 6359
    },
    {
      "epoch": 0.4942493005906124,
      "grad_norm": 0.14552634954452515,
      "learning_rate": 7.528753497046939e-06,
      "loss": 0.0381,
      "step": 6360
    },
    {
      "epoch": 0.4943270127447933,
      "grad_norm": 0.360954225063324,
      "learning_rate": 7.528364936276035e-06,
      "loss": 0.155,
      "step": 6361
    },
    {
      "epoch": 0.4944047248989742,
      "grad_norm": 0.8899397850036621,
      "learning_rate": 7.527976375505129e-06,
      "loss": 0.5525,
      "step": 6362
    },
    {
      "epoch": 0.4944824370531551,
      "grad_norm": 0.5320417284965515,
      "learning_rate": 7.527587814734225e-06,
      "loss": 0.1183,
      "step": 6363
    },
    {
      "epoch": 0.49456014920733604,
      "grad_norm": 0.23041582107543945,
      "learning_rate": 7.527199253963321e-06,
      "loss": 0.0709,
      "step": 6364
    },
    {
      "epoch": 0.49463786136151694,
      "grad_norm": 0.6390089392662048,
      "learning_rate": 7.526810693192416e-06,
      "loss": 0.3401,
      "step": 6365
    },
    {
      "epoch": 0.49471557351569784,
      "grad_norm": 0.4007602632045746,
      "learning_rate": 7.526422132421511e-06,
      "loss": 0.4608,
      "step": 6366
    },
    {
      "epoch": 0.4947932856698788,
      "grad_norm": 0.2622906267642975,
      "learning_rate": 7.526033571650607e-06,
      "loss": 0.0753,
      "step": 6367
    },
    {
      "epoch": 0.4948709978240597,
      "grad_norm": 0.6272789835929871,
      "learning_rate": 7.525645010879702e-06,
      "loss": 0.1821,
      "step": 6368
    },
    {
      "epoch": 0.4949487099782406,
      "grad_norm": 0.3795579969882965,
      "learning_rate": 7.525256450108798e-06,
      "loss": 0.4679,
      "step": 6369
    },
    {
      "epoch": 0.4950264221324215,
      "grad_norm": 0.4687783718109131,
      "learning_rate": 7.524867889337894e-06,
      "loss": 0.2568,
      "step": 6370
    },
    {
      "epoch": 0.49510413428660244,
      "grad_norm": 0.20944863557815552,
      "learning_rate": 7.524479328566988e-06,
      "loss": 0.0928,
      "step": 6371
    },
    {
      "epoch": 0.49518184644078334,
      "grad_norm": 0.21116414666175842,
      "learning_rate": 7.524090767796084e-06,
      "loss": 0.0342,
      "step": 6372
    },
    {
      "epoch": 0.49525955859496423,
      "grad_norm": 0.1623811274766922,
      "learning_rate": 7.5237022070251795e-06,
      "loss": 0.0551,
      "step": 6373
    },
    {
      "epoch": 0.4953372707491452,
      "grad_norm": 0.39992430806159973,
      "learning_rate": 7.523313646254274e-06,
      "loss": 0.1836,
      "step": 6374
    },
    {
      "epoch": 0.4954149829033261,
      "grad_norm": 0.1945323646068573,
      "learning_rate": 7.52292508548337e-06,
      "loss": 0.0875,
      "step": 6375
    },
    {
      "epoch": 0.495492695057507,
      "grad_norm": 0.8207849264144897,
      "learning_rate": 7.522536524712466e-06,
      "loss": 0.2607,
      "step": 6376
    },
    {
      "epoch": 0.49557040721168794,
      "grad_norm": 1.4332395792007446,
      "learning_rate": 7.522147963941561e-06,
      "loss": 0.7022,
      "step": 6377
    },
    {
      "epoch": 0.49564811936586883,
      "grad_norm": 0.26075661182403564,
      "learning_rate": 7.521759403170657e-06,
      "loss": 0.0537,
      "step": 6378
    },
    {
      "epoch": 0.49572583152004973,
      "grad_norm": 0.2702697515487671,
      "learning_rate": 7.5213708423997525e-06,
      "loss": 0.0539,
      "step": 6379
    },
    {
      "epoch": 0.49580354367423063,
      "grad_norm": 0.47857269644737244,
      "learning_rate": 7.520982281628847e-06,
      "loss": 0.5153,
      "step": 6380
    },
    {
      "epoch": 0.4958812558284116,
      "grad_norm": 0.27601873874664307,
      "learning_rate": 7.5205937208579424e-06,
      "loss": 0.2292,
      "step": 6381
    },
    {
      "epoch": 0.4959589679825925,
      "grad_norm": 0.5283384919166565,
      "learning_rate": 7.520205160087038e-06,
      "loss": 0.2046,
      "step": 6382
    },
    {
      "epoch": 0.4960366801367734,
      "grad_norm": 0.0720367431640625,
      "learning_rate": 7.519816599316133e-06,
      "loss": 0.0269,
      "step": 6383
    },
    {
      "epoch": 0.49611439229095433,
      "grad_norm": 0.1457434743642807,
      "learning_rate": 7.519428038545229e-06,
      "loss": 0.0356,
      "step": 6384
    },
    {
      "epoch": 0.49619210444513523,
      "grad_norm": 0.3725054860115051,
      "learning_rate": 7.519039477774325e-06,
      "loss": 0.09,
      "step": 6385
    },
    {
      "epoch": 0.4962698165993161,
      "grad_norm": 0.32692697644233704,
      "learning_rate": 7.51865091700342e-06,
      "loss": 0.3479,
      "step": 6386
    },
    {
      "epoch": 0.496347528753497,
      "grad_norm": 0.23856167495250702,
      "learning_rate": 7.5182623562325155e-06,
      "loss": 0.1624,
      "step": 6387
    },
    {
      "epoch": 0.496425240907678,
      "grad_norm": 0.5578672885894775,
      "learning_rate": 7.517873795461611e-06,
      "loss": 0.1175,
      "step": 6388
    },
    {
      "epoch": 0.4965029530618589,
      "grad_norm": 0.48441603779792786,
      "learning_rate": 7.517485234690707e-06,
      "loss": 0.3517,
      "step": 6389
    },
    {
      "epoch": 0.4965806652160398,
      "grad_norm": 0.5584884881973267,
      "learning_rate": 7.517096673919801e-06,
      "loss": 0.1842,
      "step": 6390
    },
    {
      "epoch": 0.4966583773702207,
      "grad_norm": 0.4651942551136017,
      "learning_rate": 7.516708113148897e-06,
      "loss": 0.101,
      "step": 6391
    },
    {
      "epoch": 0.4967360895244016,
      "grad_norm": 0.8982315063476562,
      "learning_rate": 7.516319552377993e-06,
      "loss": 0.5207,
      "step": 6392
    },
    {
      "epoch": 0.4968138016785825,
      "grad_norm": 0.5939143896102905,
      "learning_rate": 7.515930991607088e-06,
      "loss": 0.2505,
      "step": 6393
    },
    {
      "epoch": 0.4968915138327634,
      "grad_norm": 0.5726954936981201,
      "learning_rate": 7.5155424308361836e-06,
      "loss": 0.8877,
      "step": 6394
    },
    {
      "epoch": 0.4969692259869444,
      "grad_norm": 0.12238706648349762,
      "learning_rate": 7.515153870065279e-06,
      "loss": 0.064,
      "step": 6395
    },
    {
      "epoch": 0.49704693814112527,
      "grad_norm": 0.33659282326698303,
      "learning_rate": 7.514765309294374e-06,
      "loss": 0.4504,
      "step": 6396
    },
    {
      "epoch": 0.49712465029530617,
      "grad_norm": 0.49200406670570374,
      "learning_rate": 7.51437674852347e-06,
      "loss": 0.29,
      "step": 6397
    },
    {
      "epoch": 0.4972023624494871,
      "grad_norm": 0.00321388547308743,
      "learning_rate": 7.513988187752566e-06,
      "loss": 0.0002,
      "step": 6398
    },
    {
      "epoch": 0.497280074603668,
      "grad_norm": 0.5105602145195007,
      "learning_rate": 7.51359962698166e-06,
      "loss": 0.2057,
      "step": 6399
    },
    {
      "epoch": 0.4973577867578489,
      "grad_norm": 0.13588812947273254,
      "learning_rate": 7.513211066210756e-06,
      "loss": 0.0884,
      "step": 6400
    },
    {
      "epoch": 0.4974354989120298,
      "grad_norm": 0.7414443492889404,
      "learning_rate": 7.512822505439852e-06,
      "loss": 0.2432,
      "step": 6401
    },
    {
      "epoch": 0.49751321106621077,
      "grad_norm": 0.05506543442606926,
      "learning_rate": 7.5124339446689466e-06,
      "loss": 0.0072,
      "step": 6402
    },
    {
      "epoch": 0.49759092322039167,
      "grad_norm": 0.3140079081058502,
      "learning_rate": 7.512045383898042e-06,
      "loss": 0.1874,
      "step": 6403
    },
    {
      "epoch": 0.49766863537457257,
      "grad_norm": 0.13572150468826294,
      "learning_rate": 7.511656823127138e-06,
      "loss": 0.0312,
      "step": 6404
    },
    {
      "epoch": 0.4977463475287535,
      "grad_norm": 1.077641487121582,
      "learning_rate": 7.511268262356233e-06,
      "loss": 0.6863,
      "step": 6405
    },
    {
      "epoch": 0.4978240596829344,
      "grad_norm": 0.7368242740631104,
      "learning_rate": 7.510879701585329e-06,
      "loss": 0.2842,
      "step": 6406
    },
    {
      "epoch": 0.4979017718371153,
      "grad_norm": 0.35478246212005615,
      "learning_rate": 7.510491140814425e-06,
      "loss": 0.1667,
      "step": 6407
    },
    {
      "epoch": 0.4979794839912962,
      "grad_norm": 0.14590902626514435,
      "learning_rate": 7.510102580043519e-06,
      "loss": 0.0672,
      "step": 6408
    },
    {
      "epoch": 0.49805719614547717,
      "grad_norm": 0.16724896430969238,
      "learning_rate": 7.509714019272615e-06,
      "loss": 0.0402,
      "step": 6409
    },
    {
      "epoch": 0.49813490829965806,
      "grad_norm": 0.09770605713129044,
      "learning_rate": 7.50932545850171e-06,
      "loss": 0.0337,
      "step": 6410
    },
    {
      "epoch": 0.49821262045383896,
      "grad_norm": 0.20617853105068207,
      "learning_rate": 7.508936897730805e-06,
      "loss": 0.0353,
      "step": 6411
    },
    {
      "epoch": 0.4982903326080199,
      "grad_norm": 0.38342997431755066,
      "learning_rate": 7.508548336959901e-06,
      "loss": 0.0573,
      "step": 6412
    },
    {
      "epoch": 0.4983680447622008,
      "grad_norm": 0.3912104368209839,
      "learning_rate": 7.508159776188997e-06,
      "loss": 0.1154,
      "step": 6413
    },
    {
      "epoch": 0.4984457569163817,
      "grad_norm": 0.24582087993621826,
      "learning_rate": 7.507771215418092e-06,
      "loss": 0.1115,
      "step": 6414
    },
    {
      "epoch": 0.49852346907056266,
      "grad_norm": 0.2193305939435959,
      "learning_rate": 7.507382654647188e-06,
      "loss": 0.1043,
      "step": 6415
    },
    {
      "epoch": 0.49860118122474356,
      "grad_norm": 0.17658314108848572,
      "learning_rate": 7.5069940938762835e-06,
      "loss": 0.0506,
      "step": 6416
    },
    {
      "epoch": 0.49867889337892446,
      "grad_norm": 0.23230239748954773,
      "learning_rate": 7.5066055331053776e-06,
      "loss": 0.2172,
      "step": 6417
    },
    {
      "epoch": 0.49875660553310536,
      "grad_norm": 0.0605204775929451,
      "learning_rate": 7.506216972334473e-06,
      "loss": 0.0346,
      "step": 6418
    },
    {
      "epoch": 0.4988343176872863,
      "grad_norm": 0.35337769985198975,
      "learning_rate": 7.505828411563569e-06,
      "loss": 0.5858,
      "step": 6419
    },
    {
      "epoch": 0.4989120298414672,
      "grad_norm": 0.16762126982212067,
      "learning_rate": 7.505439850792665e-06,
      "loss": 0.0713,
      "step": 6420
    },
    {
      "epoch": 0.4989897419956481,
      "grad_norm": 0.40154311060905457,
      "learning_rate": 7.50505129002176e-06,
      "loss": 0.1938,
      "step": 6421
    },
    {
      "epoch": 0.49906745414982906,
      "grad_norm": 0.6731374263763428,
      "learning_rate": 7.504662729250856e-06,
      "loss": 0.2195,
      "step": 6422
    },
    {
      "epoch": 0.49914516630400996,
      "grad_norm": 0.2874501347541809,
      "learning_rate": 7.5042741684799515e-06,
      "loss": 0.252,
      "step": 6423
    },
    {
      "epoch": 0.49922287845819086,
      "grad_norm": 1.0110526084899902,
      "learning_rate": 7.5038856077090465e-06,
      "loss": 0.6289,
      "step": 6424
    },
    {
      "epoch": 0.49930059061237175,
      "grad_norm": 0.2740022838115692,
      "learning_rate": 7.503497046938142e-06,
      "loss": 0.031,
      "step": 6425
    },
    {
      "epoch": 0.4993783027665527,
      "grad_norm": 0.6361388564109802,
      "learning_rate": 7.503108486167238e-06,
      "loss": 0.4278,
      "step": 6426
    },
    {
      "epoch": 0.4994560149207336,
      "grad_norm": 0.23758721351623535,
      "learning_rate": 7.502719925396332e-06,
      "loss": 0.1252,
      "step": 6427
    },
    {
      "epoch": 0.4995337270749145,
      "grad_norm": 0.8125579357147217,
      "learning_rate": 7.502331364625428e-06,
      "loss": 0.1661,
      "step": 6428
    },
    {
      "epoch": 0.49961143922909546,
      "grad_norm": 0.24401505291461945,
      "learning_rate": 7.501942803854524e-06,
      "loss": 0.0903,
      "step": 6429
    },
    {
      "epoch": 0.49968915138327635,
      "grad_norm": 0.4798624515533447,
      "learning_rate": 7.501554243083619e-06,
      "loss": 0.2542,
      "step": 6430
    },
    {
      "epoch": 0.49976686353745725,
      "grad_norm": 0.3578699231147766,
      "learning_rate": 7.5011656823127145e-06,
      "loss": 0.2193,
      "step": 6431
    },
    {
      "epoch": 0.49984457569163815,
      "grad_norm": 0.2653433680534363,
      "learning_rate": 7.50077712154181e-06,
      "loss": 0.1033,
      "step": 6432
    },
    {
      "epoch": 0.4999222878458191,
      "grad_norm": 0.5660281777381897,
      "learning_rate": 7.500388560770905e-06,
      "loss": 0.3466,
      "step": 6433
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4315914213657379,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.3919,
      "step": 6434
    },
    {
      "epoch": 0.500077712154181,
      "grad_norm": 6.081927299499512,
      "learning_rate": 7.499611439229096e-06,
      "loss": 2.5913,
      "step": 6435
    },
    {
      "epoch": 0.5001554243083618,
      "grad_norm": 0.1919330209493637,
      "learning_rate": 7.499222878458191e-06,
      "loss": 0.0616,
      "step": 6436
    },
    {
      "epoch": 0.5002331364625427,
      "grad_norm": 1.019830346107483,
      "learning_rate": 7.498834317687287e-06,
      "loss": 0.2138,
      "step": 6437
    },
    {
      "epoch": 0.5003108486167237,
      "grad_norm": 0.33915382623672485,
      "learning_rate": 7.4984457569163825e-06,
      "loss": 0.1211,
      "step": 6438
    },
    {
      "epoch": 0.5003885607709045,
      "grad_norm": 0.4324222207069397,
      "learning_rate": 7.4980571961454775e-06,
      "loss": 0.3114,
      "step": 6439
    },
    {
      "epoch": 0.5004662729250855,
      "grad_norm": 0.47892314195632935,
      "learning_rate": 7.497668635374573e-06,
      "loss": 0.0679,
      "step": 6440
    },
    {
      "epoch": 0.5005439850792665,
      "grad_norm": 0.5536345839500427,
      "learning_rate": 7.497280074603669e-06,
      "loss": 0.6826,
      "step": 6441
    },
    {
      "epoch": 0.5006216972334473,
      "grad_norm": 0.35647061467170715,
      "learning_rate": 7.496891513832763e-06,
      "loss": 0.2239,
      "step": 6442
    },
    {
      "epoch": 0.5006994093876282,
      "grad_norm": 0.5264776349067688,
      "learning_rate": 7.496502953061859e-06,
      "loss": 0.151,
      "step": 6443
    },
    {
      "epoch": 0.5007771215418091,
      "grad_norm": 0.3372080624103546,
      "learning_rate": 7.496114392290955e-06,
      "loss": 0.1798,
      "step": 6444
    },
    {
      "epoch": 0.50085483369599,
      "grad_norm": 0.41259363293647766,
      "learning_rate": 7.49572583152005e-06,
      "loss": 0.1972,
      "step": 6445
    },
    {
      "epoch": 0.500932545850171,
      "grad_norm": 0.2573331296443939,
      "learning_rate": 7.4953372707491455e-06,
      "loss": 0.0461,
      "step": 6446
    },
    {
      "epoch": 0.5010102580043518,
      "grad_norm": 0.21894361078739166,
      "learning_rate": 7.494948709978241e-06,
      "loss": 0.0299,
      "step": 6447
    },
    {
      "epoch": 0.5010879701585328,
      "grad_norm": 0.2250373214483261,
      "learning_rate": 7.494560149207336e-06,
      "loss": 0.1086,
      "step": 6448
    },
    {
      "epoch": 0.5011656823127137,
      "grad_norm": 0.6163913607597351,
      "learning_rate": 7.494171588436432e-06,
      "loss": 0.3403,
      "step": 6449
    },
    {
      "epoch": 0.5012433944668946,
      "grad_norm": 0.37837889790534973,
      "learning_rate": 7.493783027665528e-06,
      "loss": 0.2356,
      "step": 6450
    },
    {
      "epoch": 0.5013211066210755,
      "grad_norm": 0.45785436034202576,
      "learning_rate": 7.493394466894624e-06,
      "loss": 0.2031,
      "step": 6451
    },
    {
      "epoch": 0.5013988187752565,
      "grad_norm": 0.5038836598396301,
      "learning_rate": 7.493005906123718e-06,
      "loss": 0.3231,
      "step": 6452
    },
    {
      "epoch": 0.5014765309294373,
      "grad_norm": 0.46928027272224426,
      "learning_rate": 7.4926173453528136e-06,
      "loss": 0.1208,
      "step": 6453
    },
    {
      "epoch": 0.5015542430836183,
      "grad_norm": 0.22155524790287018,
      "learning_rate": 7.492228784581909e-06,
      "loss": 0.0658,
      "step": 6454
    },
    {
      "epoch": 0.5016319552377992,
      "grad_norm": 0.4048825204372406,
      "learning_rate": 7.491840223811004e-06,
      "loss": 0.3557,
      "step": 6455
    },
    {
      "epoch": 0.5017096673919801,
      "grad_norm": 0.48235023021698,
      "learning_rate": 7.4914516630401e-06,
      "loss": 0.7275,
      "step": 6456
    },
    {
      "epoch": 0.501787379546161,
      "grad_norm": 0.292579710483551,
      "learning_rate": 7.491063102269196e-06,
      "loss": 0.2527,
      "step": 6457
    },
    {
      "epoch": 0.5018650917003419,
      "grad_norm": 0.33716195821762085,
      "learning_rate": 7.490674541498291e-06,
      "loss": 0.1096,
      "step": 6458
    },
    {
      "epoch": 0.5019428038545228,
      "grad_norm": 0.5894354581832886,
      "learning_rate": 7.490285980727387e-06,
      "loss": 0.2164,
      "step": 6459
    },
    {
      "epoch": 0.5020205160087038,
      "grad_norm": 0.25443029403686523,
      "learning_rate": 7.4898974199564824e-06,
      "loss": 0.0307,
      "step": 6460
    },
    {
      "epoch": 0.5020982281628846,
      "grad_norm": 0.2662332355976105,
      "learning_rate": 7.4895088591855765e-06,
      "loss": 0.1399,
      "step": 6461
    },
    {
      "epoch": 0.5021759403170656,
      "grad_norm": 0.27288874983787537,
      "learning_rate": 7.489120298414672e-06,
      "loss": 0.1355,
      "step": 6462
    },
    {
      "epoch": 0.5022536524712465,
      "grad_norm": 0.3031315207481384,
      "learning_rate": 7.488731737643768e-06,
      "loss": 0.2601,
      "step": 6463
    },
    {
      "epoch": 0.5023313646254274,
      "grad_norm": 0.19838853180408478,
      "learning_rate": 7.488343176872863e-06,
      "loss": 0.0704,
      "step": 6464
    },
    {
      "epoch": 0.5024090767796083,
      "grad_norm": 0.32119348645210266,
      "learning_rate": 7.487954616101959e-06,
      "loss": 0.0848,
      "step": 6465
    },
    {
      "epoch": 0.5024867889337893,
      "grad_norm": 0.11519734561443329,
      "learning_rate": 7.487566055331055e-06,
      "loss": 0.0178,
      "step": 6466
    },
    {
      "epoch": 0.5025645010879701,
      "grad_norm": 0.4048369824886322,
      "learning_rate": 7.48717749456015e-06,
      "loss": 0.1835,
      "step": 6467
    },
    {
      "epoch": 0.5026422132421511,
      "grad_norm": 0.4750935435295105,
      "learning_rate": 7.486788933789245e-06,
      "loss": 0.2411,
      "step": 6468
    },
    {
      "epoch": 0.502719925396332,
      "grad_norm": 0.06727511435747147,
      "learning_rate": 7.486400373018341e-06,
      "loss": 0.0159,
      "step": 6469
    },
    {
      "epoch": 0.5027976375505129,
      "grad_norm": 0.07930557429790497,
      "learning_rate": 7.486011812247435e-06,
      "loss": 0.0512,
      "step": 6470
    },
    {
      "epoch": 0.5028753497046938,
      "grad_norm": 0.2060314565896988,
      "learning_rate": 7.485623251476531e-06,
      "loss": 0.0784,
      "step": 6471
    },
    {
      "epoch": 0.5029530618588747,
      "grad_norm": 0.2656661868095398,
      "learning_rate": 7.485234690705627e-06,
      "loss": 0.1008,
      "step": 6472
    },
    {
      "epoch": 0.5030307740130556,
      "grad_norm": 0.4103213846683502,
      "learning_rate": 7.484846129934722e-06,
      "loss": 0.0348,
      "step": 6473
    },
    {
      "epoch": 0.5031084861672366,
      "grad_norm": 0.08693784475326538,
      "learning_rate": 7.484457569163818e-06,
      "loss": 0.0475,
      "step": 6474
    },
    {
      "epoch": 0.5031861983214174,
      "grad_norm": 0.2990110516548157,
      "learning_rate": 7.4840690083929135e-06,
      "loss": 0.0848,
      "step": 6475
    },
    {
      "epoch": 0.5032639104755984,
      "grad_norm": 0.46700984239578247,
      "learning_rate": 7.483680447622008e-06,
      "loss": 0.1156,
      "step": 6476
    },
    {
      "epoch": 0.5033416226297793,
      "grad_norm": 0.45157602429389954,
      "learning_rate": 7.483291886851104e-06,
      "loss": 0.1086,
      "step": 6477
    },
    {
      "epoch": 0.5034193347839602,
      "grad_norm": 0.671145498752594,
      "learning_rate": 7.4829033260802e-06,
      "loss": 0.1772,
      "step": 6478
    },
    {
      "epoch": 0.5034970469381411,
      "grad_norm": 0.14104622602462769,
      "learning_rate": 7.482514765309294e-06,
      "loss": 0.0405,
      "step": 6479
    },
    {
      "epoch": 0.5035747590923221,
      "grad_norm": 0.4885302186012268,
      "learning_rate": 7.48212620453839e-06,
      "loss": 0.256,
      "step": 6480
    },
    {
      "epoch": 0.5036524712465029,
      "grad_norm": 0.08192798495292664,
      "learning_rate": 7.481737643767486e-06,
      "loss": 0.0368,
      "step": 6481
    },
    {
      "epoch": 0.5037301834006839,
      "grad_norm": 0.14524874091148376,
      "learning_rate": 7.4813490829965815e-06,
      "loss": 0.0963,
      "step": 6482
    },
    {
      "epoch": 0.5038078955548648,
      "grad_norm": 0.4359239935874939,
      "learning_rate": 7.4809605222256764e-06,
      "loss": 0.7875,
      "step": 6483
    },
    {
      "epoch": 0.5038856077090457,
      "grad_norm": 0.13112224638462067,
      "learning_rate": 7.480571961454772e-06,
      "loss": 0.1261,
      "step": 6484
    },
    {
      "epoch": 0.5039633198632266,
      "grad_norm": 0.1639743596315384,
      "learning_rate": 7.480183400683868e-06,
      "loss": 0.0368,
      "step": 6485
    },
    {
      "epoch": 0.5040410320174076,
      "grad_norm": 0.15796871483325958,
      "learning_rate": 7.479794839912963e-06,
      "loss": 0.0304,
      "step": 6486
    },
    {
      "epoch": 0.5041187441715884,
      "grad_norm": 0.6089651584625244,
      "learning_rate": 7.479406279142059e-06,
      "loss": 0.1598,
      "step": 6487
    },
    {
      "epoch": 0.5041964563257694,
      "grad_norm": 0.2522258758544922,
      "learning_rate": 7.479017718371155e-06,
      "loss": 0.0605,
      "step": 6488
    },
    {
      "epoch": 0.5042741684799502,
      "grad_norm": 0.3687066435813904,
      "learning_rate": 7.478629157600249e-06,
      "loss": 0.2073,
      "step": 6489
    },
    {
      "epoch": 0.5043518806341312,
      "grad_norm": 0.18378496170043945,
      "learning_rate": 7.4782405968293445e-06,
      "loss": 0.0349,
      "step": 6490
    },
    {
      "epoch": 0.5044295927883121,
      "grad_norm": 0.27762550115585327,
      "learning_rate": 7.47785203605844e-06,
      "loss": 0.1301,
      "step": 6491
    },
    {
      "epoch": 0.504507304942493,
      "grad_norm": 0.5178013443946838,
      "learning_rate": 7.477463475287535e-06,
      "loss": 0.3614,
      "step": 6492
    },
    {
      "epoch": 0.5045850170966739,
      "grad_norm": 0.5759729146957397,
      "learning_rate": 7.477074914516631e-06,
      "loss": 0.246,
      "step": 6493
    },
    {
      "epoch": 0.5046627292508549,
      "grad_norm": 0.06751120835542679,
      "learning_rate": 7.476686353745727e-06,
      "loss": 0.0229,
      "step": 6494
    },
    {
      "epoch": 0.5047404414050357,
      "grad_norm": 0.6483569145202637,
      "learning_rate": 7.476297792974822e-06,
      "loss": 0.2935,
      "step": 6495
    },
    {
      "epoch": 0.5048181535592167,
      "grad_norm": 0.09799972921609879,
      "learning_rate": 7.4759092322039176e-06,
      "loss": 0.0266,
      "step": 6496
    },
    {
      "epoch": 0.5048958657133976,
      "grad_norm": 0.24300409853458405,
      "learning_rate": 7.475520671433013e-06,
      "loss": 0.1894,
      "step": 6497
    },
    {
      "epoch": 0.5049735778675785,
      "grad_norm": 0.45307260751724243,
      "learning_rate": 7.4751321106621075e-06,
      "loss": 0.5968,
      "step": 6498
    },
    {
      "epoch": 0.5050512900217594,
      "grad_norm": 0.6040929555892944,
      "learning_rate": 7.474743549891203e-06,
      "loss": 0.3187,
      "step": 6499
    },
    {
      "epoch": 0.5051290021759404,
      "grad_norm": 0.2069820612668991,
      "learning_rate": 7.474354989120299e-06,
      "loss": 0.0732,
      "step": 6500
    },
    {
      "epoch": 0.5052067143301212,
      "grad_norm": 0.12138339877128601,
      "learning_rate": 7.473966428349394e-06,
      "loss": 0.0674,
      "step": 6501
    },
    {
      "epoch": 0.5052844264843022,
      "grad_norm": 0.3436395227909088,
      "learning_rate": 7.47357786757849e-06,
      "loss": 0.2295,
      "step": 6502
    },
    {
      "epoch": 0.505362138638483,
      "grad_norm": 0.23763293027877808,
      "learning_rate": 7.473189306807586e-06,
      "loss": 0.1465,
      "step": 6503
    },
    {
      "epoch": 0.505439850792664,
      "grad_norm": 0.6036723256111145,
      "learning_rate": 7.4728007460366806e-06,
      "loss": 0.3923,
      "step": 6504
    },
    {
      "epoch": 0.5055175629468449,
      "grad_norm": 0.1704818606376648,
      "learning_rate": 7.472412185265776e-06,
      "loss": 0.0533,
      "step": 6505
    },
    {
      "epoch": 0.5055952751010258,
      "grad_norm": 0.513092041015625,
      "learning_rate": 7.472023624494872e-06,
      "loss": 1.0115,
      "step": 6506
    },
    {
      "epoch": 0.5056729872552067,
      "grad_norm": 0.8155979514122009,
      "learning_rate": 7.471635063723966e-06,
      "loss": 0.2692,
      "step": 6507
    },
    {
      "epoch": 0.5057506994093877,
      "grad_norm": 0.37340500950813293,
      "learning_rate": 7.471246502953062e-06,
      "loss": 0.5344,
      "step": 6508
    },
    {
      "epoch": 0.5058284115635685,
      "grad_norm": 0.3024955689907074,
      "learning_rate": 7.470857942182158e-06,
      "loss": 0.2438,
      "step": 6509
    },
    {
      "epoch": 0.5059061237177495,
      "grad_norm": 0.34329402446746826,
      "learning_rate": 7.470469381411254e-06,
      "loss": 0.5491,
      "step": 6510
    },
    {
      "epoch": 0.5059838358719304,
      "grad_norm": 0.34942060708999634,
      "learning_rate": 7.470080820640349e-06,
      "loss": 0.1381,
      "step": 6511
    },
    {
      "epoch": 0.5060615480261113,
      "grad_norm": 0.44662097096443176,
      "learning_rate": 7.469692259869444e-06,
      "loss": 0.2988,
      "step": 6512
    },
    {
      "epoch": 0.5061392601802922,
      "grad_norm": 0.3945285677909851,
      "learning_rate": 7.46930369909854e-06,
      "loss": 0.2495,
      "step": 6513
    },
    {
      "epoch": 0.5062169723344732,
      "grad_norm": 0.2776453197002411,
      "learning_rate": 7.468915138327635e-06,
      "loss": 0.127,
      "step": 6514
    },
    {
      "epoch": 0.506294684488654,
      "grad_norm": 0.10198026150465012,
      "learning_rate": 7.468526577556731e-06,
      "loss": 0.01,
      "step": 6515
    },
    {
      "epoch": 0.506372396642835,
      "grad_norm": 0.22683297097682953,
      "learning_rate": 7.468138016785827e-06,
      "loss": 0.0569,
      "step": 6516
    },
    {
      "epoch": 0.5064501087970159,
      "grad_norm": 0.6554194092750549,
      "learning_rate": 7.467749456014921e-06,
      "loss": 0.1957,
      "step": 6517
    },
    {
      "epoch": 0.5065278209511967,
      "grad_norm": 0.8210456371307373,
      "learning_rate": 7.467360895244017e-06,
      "loss": 0.5652,
      "step": 6518
    },
    {
      "epoch": 0.5066055331053777,
      "grad_norm": 1.0095406770706177,
      "learning_rate": 7.4669723344731124e-06,
      "loss": 0.4064,
      "step": 6519
    },
    {
      "epoch": 0.5066832452595585,
      "grad_norm": 0.15979038178920746,
      "learning_rate": 7.466583773702207e-06,
      "loss": 0.0191,
      "step": 6520
    },
    {
      "epoch": 0.5067609574137395,
      "grad_norm": 0.4941154718399048,
      "learning_rate": 7.466195212931303e-06,
      "loss": 0.2076,
      "step": 6521
    },
    {
      "epoch": 0.5068386695679205,
      "grad_norm": 0.33418095111846924,
      "learning_rate": 7.465806652160399e-06,
      "loss": 0.1795,
      "step": 6522
    },
    {
      "epoch": 0.5069163817221013,
      "grad_norm": 0.4506169855594635,
      "learning_rate": 7.465418091389494e-06,
      "loss": 0.2002,
      "step": 6523
    },
    {
      "epoch": 0.5069940938762822,
      "grad_norm": 0.4971415400505066,
      "learning_rate": 7.46502953061859e-06,
      "loss": 0.1994,
      "step": 6524
    },
    {
      "epoch": 0.5070718060304632,
      "grad_norm": 1.5215412378311157,
      "learning_rate": 7.4646409698476855e-06,
      "loss": 0.4406,
      "step": 6525
    },
    {
      "epoch": 0.507149518184644,
      "grad_norm": 0.5334457755088806,
      "learning_rate": 7.46425240907678e-06,
      "loss": 0.7256,
      "step": 6526
    },
    {
      "epoch": 0.507227230338825,
      "grad_norm": 0.208576962351799,
      "learning_rate": 7.463863848305875e-06,
      "loss": 0.0881,
      "step": 6527
    },
    {
      "epoch": 0.507304942493006,
      "grad_norm": 0.6121864914894104,
      "learning_rate": 7.463475287534971e-06,
      "loss": 0.259,
      "step": 6528
    },
    {
      "epoch": 0.5073826546471868,
      "grad_norm": 0.7402744889259338,
      "learning_rate": 7.463086726764066e-06,
      "loss": 0.3209,
      "step": 6529
    },
    {
      "epoch": 0.5074603668013677,
      "grad_norm": 0.20987039804458618,
      "learning_rate": 7.462698165993162e-06,
      "loss": 0.0778,
      "step": 6530
    },
    {
      "epoch": 0.5075380789555487,
      "grad_norm": 0.12690488994121552,
      "learning_rate": 7.462309605222258e-06,
      "loss": 0.027,
      "step": 6531
    },
    {
      "epoch": 0.5076157911097295,
      "grad_norm": 0.28171536326408386,
      "learning_rate": 7.461921044451353e-06,
      "loss": 0.3624,
      "step": 6532
    },
    {
      "epoch": 0.5076935032639105,
      "grad_norm": 0.5480257272720337,
      "learning_rate": 7.4615324836804485e-06,
      "loss": 0.1706,
      "step": 6533
    },
    {
      "epoch": 0.5077712154180913,
      "grad_norm": 0.4527764916419983,
      "learning_rate": 7.461143922909544e-06,
      "loss": 0.2192,
      "step": 6534
    },
    {
      "epoch": 0.5078489275722723,
      "grad_norm": 0.7291644811630249,
      "learning_rate": 7.460755362138638e-06,
      "loss": 0.3728,
      "step": 6535
    },
    {
      "epoch": 0.5079266397264532,
      "grad_norm": 0.4806181788444519,
      "learning_rate": 7.460366801367734e-06,
      "loss": 0.1548,
      "step": 6536
    },
    {
      "epoch": 0.5080043518806341,
      "grad_norm": 0.28589800000190735,
      "learning_rate": 7.45997824059683e-06,
      "loss": 0.149,
      "step": 6537
    },
    {
      "epoch": 0.508082064034815,
      "grad_norm": 0.410429984331131,
      "learning_rate": 7.459589679825925e-06,
      "loss": 0.2058,
      "step": 6538
    },
    {
      "epoch": 0.508159776188996,
      "grad_norm": 0.21026013791561127,
      "learning_rate": 7.459201119055021e-06,
      "loss": 0.0722,
      "step": 6539
    },
    {
      "epoch": 0.5082374883431768,
      "grad_norm": 0.17659172415733337,
      "learning_rate": 7.4588125582841165e-06,
      "loss": 0.0472,
      "step": 6540
    },
    {
      "epoch": 0.5083152004973578,
      "grad_norm": 0.2914372682571411,
      "learning_rate": 7.458423997513212e-06,
      "loss": 0.228,
      "step": 6541
    },
    {
      "epoch": 0.5083929126515387,
      "grad_norm": 0.3315107524394989,
      "learning_rate": 7.458035436742307e-06,
      "loss": 0.2209,
      "step": 6542
    },
    {
      "epoch": 0.5084706248057196,
      "grad_norm": 0.8972575664520264,
      "learning_rate": 7.457646875971403e-06,
      "loss": 0.2389,
      "step": 6543
    },
    {
      "epoch": 0.5085483369599005,
      "grad_norm": 1.154090404510498,
      "learning_rate": 7.457258315200499e-06,
      "loss": 0.6455,
      "step": 6544
    },
    {
      "epoch": 0.5086260491140815,
      "grad_norm": 0.39904868602752686,
      "learning_rate": 7.456869754429593e-06,
      "loss": 0.1534,
      "step": 6545
    },
    {
      "epoch": 0.5087037612682623,
      "grad_norm": 0.7817997932434082,
      "learning_rate": 7.456481193658689e-06,
      "loss": 0.3763,
      "step": 6546
    },
    {
      "epoch": 0.5087814734224433,
      "grad_norm": 0.3387141525745392,
      "learning_rate": 7.4560926328877846e-06,
      "loss": 0.1381,
      "step": 6547
    },
    {
      "epoch": 0.5088591855766241,
      "grad_norm": 0.20276802778244019,
      "learning_rate": 7.4557040721168795e-06,
      "loss": 0.0698,
      "step": 6548
    },
    {
      "epoch": 0.5089368977308051,
      "grad_norm": 0.12508700788021088,
      "learning_rate": 7.455315511345975e-06,
      "loss": 0.0546,
      "step": 6549
    },
    {
      "epoch": 0.509014609884986,
      "grad_norm": 0.35413894057273865,
      "learning_rate": 7.454926950575071e-06,
      "loss": 0.0905,
      "step": 6550
    },
    {
      "epoch": 0.5090923220391669,
      "grad_norm": 0.11720865964889526,
      "learning_rate": 7.454538389804166e-06,
      "loss": 0.1132,
      "step": 6551
    },
    {
      "epoch": 0.5091700341933478,
      "grad_norm": 0.11696403473615646,
      "learning_rate": 7.454149829033262e-06,
      "loss": 0.0636,
      "step": 6552
    },
    {
      "epoch": 0.5092477463475288,
      "grad_norm": 0.11371244490146637,
      "learning_rate": 7.453761268262358e-06,
      "loss": 0.0384,
      "step": 6553
    },
    {
      "epoch": 0.5093254585017096,
      "grad_norm": 0.34880611300468445,
      "learning_rate": 7.453372707491452e-06,
      "loss": 0.1895,
      "step": 6554
    },
    {
      "epoch": 0.5094031706558906,
      "grad_norm": 0.3145195245742798,
      "learning_rate": 7.4529841467205476e-06,
      "loss": 0.1579,
      "step": 6555
    },
    {
      "epoch": 0.5094808828100715,
      "grad_norm": 0.18607443571090698,
      "learning_rate": 7.452595585949643e-06,
      "loss": 0.0879,
      "step": 6556
    },
    {
      "epoch": 0.5095585949642524,
      "grad_norm": 0.4891919195652008,
      "learning_rate": 7.452207025178738e-06,
      "loss": 0.0965,
      "step": 6557
    },
    {
      "epoch": 0.5096363071184333,
      "grad_norm": 0.07412626594305038,
      "learning_rate": 7.451818464407834e-06,
      "loss": 0.0085,
      "step": 6558
    },
    {
      "epoch": 0.5097140192726143,
      "grad_norm": 0.49532780051231384,
      "learning_rate": 7.45142990363693e-06,
      "loss": 0.0616,
      "step": 6559
    },
    {
      "epoch": 0.5097917314267951,
      "grad_norm": 0.3487599194049835,
      "learning_rate": 7.451041342866025e-06,
      "loss": 0.1917,
      "step": 6560
    },
    {
      "epoch": 0.5098694435809761,
      "grad_norm": 0.19478833675384521,
      "learning_rate": 7.45065278209512e-06,
      "loss": 0.0471,
      "step": 6561
    },
    {
      "epoch": 0.509947155735157,
      "grad_norm": 1.0648669004440308,
      "learning_rate": 7.450264221324216e-06,
      "loss": 0.7044,
      "step": 6562
    },
    {
      "epoch": 0.5100248678893379,
      "grad_norm": 0.17856921255588531,
      "learning_rate": 7.4498756605533105e-06,
      "loss": 0.1447,
      "step": 6563
    },
    {
      "epoch": 0.5101025800435188,
      "grad_norm": 0.3582308888435364,
      "learning_rate": 7.449487099782406e-06,
      "loss": 0.1489,
      "step": 6564
    },
    {
      "epoch": 0.5101802921976997,
      "grad_norm": 0.593994140625,
      "learning_rate": 7.449098539011502e-06,
      "loss": 0.2041,
      "step": 6565
    },
    {
      "epoch": 0.5102580043518806,
      "grad_norm": 0.2497049868106842,
      "learning_rate": 7.448709978240597e-06,
      "loss": 0.0434,
      "step": 6566
    },
    {
      "epoch": 0.5103357165060616,
      "grad_norm": 0.298492431640625,
      "learning_rate": 7.448321417469693e-06,
      "loss": 0.1117,
      "step": 6567
    },
    {
      "epoch": 0.5104134286602424,
      "grad_norm": 0.36504673957824707,
      "learning_rate": 7.447932856698789e-06,
      "loss": 0.1646,
      "step": 6568
    },
    {
      "epoch": 0.5104911408144234,
      "grad_norm": 0.533458948135376,
      "learning_rate": 7.447544295927883e-06,
      "loss": 0.6274,
      "step": 6569
    },
    {
      "epoch": 0.5105688529686043,
      "grad_norm": 0.05660143122076988,
      "learning_rate": 7.447155735156979e-06,
      "loss": 0.0121,
      "step": 6570
    },
    {
      "epoch": 0.5106465651227852,
      "grad_norm": 0.2495112121105194,
      "learning_rate": 7.446767174386074e-06,
      "loss": 0.0966,
      "step": 6571
    },
    {
      "epoch": 0.5107242772769661,
      "grad_norm": 0.46303582191467285,
      "learning_rate": 7.44637861361517e-06,
      "loss": 0.4699,
      "step": 6572
    },
    {
      "epoch": 0.5108019894311471,
      "grad_norm": 0.2598631978034973,
      "learning_rate": 7.445990052844265e-06,
      "loss": 0.3727,
      "step": 6573
    },
    {
      "epoch": 0.5108797015853279,
      "grad_norm": 0.4911995530128479,
      "learning_rate": 7.445601492073361e-06,
      "loss": 0.1939,
      "step": 6574
    },
    {
      "epoch": 0.5109574137395089,
      "grad_norm": 0.05675536021590233,
      "learning_rate": 7.445212931302457e-06,
      "loss": 0.0118,
      "step": 6575
    },
    {
      "epoch": 0.5110351258936898,
      "grad_norm": 0.34811490774154663,
      "learning_rate": 7.444824370531552e-06,
      "loss": 0.3581,
      "step": 6576
    },
    {
      "epoch": 0.5111128380478707,
      "grad_norm": 0.9762978553771973,
      "learning_rate": 7.4444358097606475e-06,
      "loss": 0.2735,
      "step": 6577
    },
    {
      "epoch": 0.5111905502020516,
      "grad_norm": 0.2320420891046524,
      "learning_rate": 7.444047248989743e-06,
      "loss": 0.1108,
      "step": 6578
    },
    {
      "epoch": 0.5112682623562325,
      "grad_norm": 1.103143334388733,
      "learning_rate": 7.443658688218837e-06,
      "loss": 0.6274,
      "step": 6579
    },
    {
      "epoch": 0.5113459745104134,
      "grad_norm": 0.5220238566398621,
      "learning_rate": 7.443270127447933e-06,
      "loss": 0.0479,
      "step": 6580
    },
    {
      "epoch": 0.5114236866645944,
      "grad_norm": 0.3227730393409729,
      "learning_rate": 7.442881566677029e-06,
      "loss": 0.5077,
      "step": 6581
    },
    {
      "epoch": 0.5115013988187752,
      "grad_norm": 0.2392839640378952,
      "learning_rate": 7.442493005906124e-06,
      "loss": 0.087,
      "step": 6582
    },
    {
      "epoch": 0.5115791109729562,
      "grad_norm": 0.2254866510629654,
      "learning_rate": 7.44210444513522e-06,
      "loss": 0.0402,
      "step": 6583
    },
    {
      "epoch": 0.5116568231271371,
      "grad_norm": 0.3397409915924072,
      "learning_rate": 7.4417158843643155e-06,
      "loss": 0.1186,
      "step": 6584
    },
    {
      "epoch": 0.511734535281318,
      "grad_norm": 0.12626484036445618,
      "learning_rate": 7.4413273235934105e-06,
      "loss": 0.0347,
      "step": 6585
    },
    {
      "epoch": 0.5118122474354989,
      "grad_norm": 0.2833932638168335,
      "learning_rate": 7.440938762822506e-06,
      "loss": 0.1502,
      "step": 6586
    },
    {
      "epoch": 0.5118899595896799,
      "grad_norm": 0.29363805055618286,
      "learning_rate": 7.440550202051602e-06,
      "loss": 0.0979,
      "step": 6587
    },
    {
      "epoch": 0.5119676717438607,
      "grad_norm": 0.25949838757514954,
      "learning_rate": 7.440161641280696e-06,
      "loss": 0.1258,
      "step": 6588
    },
    {
      "epoch": 0.5120453838980417,
      "grad_norm": 0.6214572191238403,
      "learning_rate": 7.439773080509792e-06,
      "loss": 0.295,
      "step": 6589
    },
    {
      "epoch": 0.5121230960522226,
      "grad_norm": 0.19846348464488983,
      "learning_rate": 7.439384519738888e-06,
      "loss": 0.1058,
      "step": 6590
    },
    {
      "epoch": 0.5122008082064035,
      "grad_norm": 0.16825184226036072,
      "learning_rate": 7.438995958967983e-06,
      "loss": 0.114,
      "step": 6591
    },
    {
      "epoch": 0.5122785203605844,
      "grad_norm": 0.4204633831977844,
      "learning_rate": 7.4386073981970785e-06,
      "loss": 0.4039,
      "step": 6592
    },
    {
      "epoch": 0.5123562325147654,
      "grad_norm": 0.2804533541202545,
      "learning_rate": 7.438218837426174e-06,
      "loss": 0.0772,
      "step": 6593
    },
    {
      "epoch": 0.5124339446689462,
      "grad_norm": 0.5287327766418457,
      "learning_rate": 7.437830276655269e-06,
      "loss": 0.544,
      "step": 6594
    },
    {
      "epoch": 0.5125116568231272,
      "grad_norm": 0.6522288918495178,
      "learning_rate": 7.437441715884365e-06,
      "loss": 0.2416,
      "step": 6595
    },
    {
      "epoch": 0.512589368977308,
      "grad_norm": 0.5639222860336304,
      "learning_rate": 7.437053155113461e-06,
      "loss": 0.2284,
      "step": 6596
    },
    {
      "epoch": 0.512667081131489,
      "grad_norm": 0.5050150156021118,
      "learning_rate": 7.436664594342555e-06,
      "loss": 0.3715,
      "step": 6597
    },
    {
      "epoch": 0.5127447932856699,
      "grad_norm": 0.5122460126876831,
      "learning_rate": 7.436276033571651e-06,
      "loss": 0.3574,
      "step": 6598
    },
    {
      "epoch": 0.5128225054398508,
      "grad_norm": 0.0662599578499794,
      "learning_rate": 7.4358874728007465e-06,
      "loss": 0.0117,
      "step": 6599
    },
    {
      "epoch": 0.5129002175940317,
      "grad_norm": 0.3353929817676544,
      "learning_rate": 7.4354989120298415e-06,
      "loss": 0.1796,
      "step": 6600
    },
    {
      "epoch": 0.5129779297482127,
      "grad_norm": 0.5548200607299805,
      "learning_rate": 7.435110351258937e-06,
      "loss": 0.1542,
      "step": 6601
    },
    {
      "epoch": 0.5130556419023935,
      "grad_norm": 0.8620397448539734,
      "learning_rate": 7.434721790488033e-06,
      "loss": 0.533,
      "step": 6602
    },
    {
      "epoch": 0.5131333540565745,
      "grad_norm": 0.5747686624526978,
      "learning_rate": 7.434333229717129e-06,
      "loss": 0.2831,
      "step": 6603
    },
    {
      "epoch": 0.5132110662107554,
      "grad_norm": 0.04946299269795418,
      "learning_rate": 7.433944668946224e-06,
      "loss": 0.0122,
      "step": 6604
    },
    {
      "epoch": 0.5132887783649362,
      "grad_norm": 0.3511525094509125,
      "learning_rate": 7.43355610817532e-06,
      "loss": 0.3111,
      "step": 6605
    },
    {
      "epoch": 0.5133664905191172,
      "grad_norm": 0.4370034337043762,
      "learning_rate": 7.433167547404415e-06,
      "loss": 0.0917,
      "step": 6606
    },
    {
      "epoch": 0.5134442026732982,
      "grad_norm": 0.4161568582057953,
      "learning_rate": 7.4327789866335095e-06,
      "loss": 0.3086,
      "step": 6607
    },
    {
      "epoch": 0.513521914827479,
      "grad_norm": 0.5685800313949585,
      "learning_rate": 7.432390425862605e-06,
      "loss": 0.2427,
      "step": 6608
    },
    {
      "epoch": 0.51359962698166,
      "grad_norm": 0.2672927975654602,
      "learning_rate": 7.432001865091701e-06,
      "loss": 0.0759,
      "step": 6609
    },
    {
      "epoch": 0.5136773391358408,
      "grad_norm": 0.08880040794610977,
      "learning_rate": 7.431613304320796e-06,
      "loss": 0.0326,
      "step": 6610
    },
    {
      "epoch": 0.5137550512900217,
      "grad_norm": 0.43307292461395264,
      "learning_rate": 7.431224743549892e-06,
      "loss": 0.2958,
      "step": 6611
    },
    {
      "epoch": 0.5138327634442027,
      "grad_norm": 0.4887104332447052,
      "learning_rate": 7.430836182778988e-06,
      "loss": 0.1478,
      "step": 6612
    },
    {
      "epoch": 0.5139104755983835,
      "grad_norm": 0.2805984914302826,
      "learning_rate": 7.430447622008083e-06,
      "loss": 0.2451,
      "step": 6613
    },
    {
      "epoch": 0.5139881877525645,
      "grad_norm": 0.6238688826560974,
      "learning_rate": 7.430059061237178e-06,
      "loss": 0.8168,
      "step": 6614
    },
    {
      "epoch": 0.5140658999067454,
      "grad_norm": 0.5082960724830627,
      "learning_rate": 7.429670500466274e-06,
      "loss": 0.5011,
      "step": 6615
    },
    {
      "epoch": 0.5141436120609263,
      "grad_norm": 0.5362499952316284,
      "learning_rate": 7.429281939695368e-06,
      "loss": 0.3561,
      "step": 6616
    },
    {
      "epoch": 0.5142213242151072,
      "grad_norm": 0.29158979654312134,
      "learning_rate": 7.428893378924464e-06,
      "loss": 0.0991,
      "step": 6617
    },
    {
      "epoch": 0.5142990363692882,
      "grad_norm": 0.5092712640762329,
      "learning_rate": 7.42850481815356e-06,
      "loss": 0.045,
      "step": 6618
    },
    {
      "epoch": 0.514376748523469,
      "grad_norm": 0.21333548426628113,
      "learning_rate": 7.428116257382655e-06,
      "loss": 0.3487,
      "step": 6619
    },
    {
      "epoch": 0.51445446067765,
      "grad_norm": 0.5932609438896179,
      "learning_rate": 7.427727696611751e-06,
      "loss": 0.2173,
      "step": 6620
    },
    {
      "epoch": 0.514532172831831,
      "grad_norm": 0.6806671619415283,
      "learning_rate": 7.4273391358408464e-06,
      "loss": 0.9614,
      "step": 6621
    },
    {
      "epoch": 0.5146098849860118,
      "grad_norm": 0.4078724682331085,
      "learning_rate": 7.426950575069941e-06,
      "loss": 0.193,
      "step": 6622
    },
    {
      "epoch": 0.5146875971401927,
      "grad_norm": 0.3826471269130707,
      "learning_rate": 7.426562014299037e-06,
      "loss": 0.1561,
      "step": 6623
    },
    {
      "epoch": 0.5147653092943736,
      "grad_norm": 0.18995071947574615,
      "learning_rate": 7.426173453528133e-06,
      "loss": 0.0788,
      "step": 6624
    },
    {
      "epoch": 0.5148430214485545,
      "grad_norm": 0.180681511759758,
      "learning_rate": 7.425784892757227e-06,
      "loss": 0.2131,
      "step": 6625
    },
    {
      "epoch": 0.5149207336027355,
      "grad_norm": 0.5886620879173279,
      "learning_rate": 7.425396331986323e-06,
      "loss": 0.271,
      "step": 6626
    },
    {
      "epoch": 0.5149984457569163,
      "grad_norm": 0.2529029846191406,
      "learning_rate": 7.425007771215419e-06,
      "loss": 0.0442,
      "step": 6627
    },
    {
      "epoch": 0.5150761579110973,
      "grad_norm": 0.6236647367477417,
      "learning_rate": 7.424619210444514e-06,
      "loss": 0.2098,
      "step": 6628
    },
    {
      "epoch": 0.5151538700652782,
      "grad_norm": 0.18897473812103271,
      "learning_rate": 7.424230649673609e-06,
      "loss": 0.0725,
      "step": 6629
    },
    {
      "epoch": 0.5152315822194591,
      "grad_norm": 0.23177222907543182,
      "learning_rate": 7.423842088902705e-06,
      "loss": 0.0931,
      "step": 6630
    },
    {
      "epoch": 0.51530929437364,
      "grad_norm": 0.07834338396787643,
      "learning_rate": 7.4234535281318e-06,
      "loss": 0.0158,
      "step": 6631
    },
    {
      "epoch": 0.515387006527821,
      "grad_norm": 0.39324870705604553,
      "learning_rate": 7.423064967360896e-06,
      "loss": 0.1419,
      "step": 6632
    },
    {
      "epoch": 0.5154647186820018,
      "grad_norm": 0.7332420945167542,
      "learning_rate": 7.422676406589992e-06,
      "loss": 0.1089,
      "step": 6633
    },
    {
      "epoch": 0.5155424308361828,
      "grad_norm": 1.0634342432022095,
      "learning_rate": 7.4222878458190876e-06,
      "loss": 0.1929,
      "step": 6634
    },
    {
      "epoch": 0.5156201429903637,
      "grad_norm": 0.2283046990633011,
      "learning_rate": 7.421899285048182e-06,
      "loss": 0.0417,
      "step": 6635
    },
    {
      "epoch": 0.5156978551445446,
      "grad_norm": 0.3158518373966217,
      "learning_rate": 7.4215107242772775e-06,
      "loss": 0.1515,
      "step": 6636
    },
    {
      "epoch": 0.5157755672987255,
      "grad_norm": 0.22223538160324097,
      "learning_rate": 7.421122163506373e-06,
      "loss": 0.0537,
      "step": 6637
    },
    {
      "epoch": 0.5158532794529065,
      "grad_norm": 0.3056678771972656,
      "learning_rate": 7.420733602735468e-06,
      "loss": 0.1839,
      "step": 6638
    },
    {
      "epoch": 0.5159309916070873,
      "grad_norm": 0.536034107208252,
      "learning_rate": 7.420345041964564e-06,
      "loss": 0.4288,
      "step": 6639
    },
    {
      "epoch": 0.5160087037612683,
      "grad_norm": 0.5655714273452759,
      "learning_rate": 7.41995648119366e-06,
      "loss": 0.3137,
      "step": 6640
    },
    {
      "epoch": 0.5160864159154491,
      "grad_norm": 0.13675548136234283,
      "learning_rate": 7.419567920422755e-06,
      "loss": 0.061,
      "step": 6641
    },
    {
      "epoch": 0.5161641280696301,
      "grad_norm": 0.3665125370025635,
      "learning_rate": 7.4191793596518505e-06,
      "loss": 0.2213,
      "step": 6642
    },
    {
      "epoch": 0.516241840223811,
      "grad_norm": 0.6663846969604492,
      "learning_rate": 7.418790798880946e-06,
      "loss": 0.4129,
      "step": 6643
    },
    {
      "epoch": 0.5163195523779919,
      "grad_norm": 0.1643594652414322,
      "learning_rate": 7.4184022381100404e-06,
      "loss": 0.041,
      "step": 6644
    },
    {
      "epoch": 0.5163972645321728,
      "grad_norm": 0.35852527618408203,
      "learning_rate": 7.418013677339136e-06,
      "loss": 0.0666,
      "step": 6645
    },
    {
      "epoch": 0.5164749766863538,
      "grad_norm": 0.38068217039108276,
      "learning_rate": 7.417625116568232e-06,
      "loss": 0.1268,
      "step": 6646
    },
    {
      "epoch": 0.5165526888405346,
      "grad_norm": 0.08209377527236938,
      "learning_rate": 7.417236555797327e-06,
      "loss": 0.0865,
      "step": 6647
    },
    {
      "epoch": 0.5166304009947156,
      "grad_norm": 0.2352440357208252,
      "learning_rate": 7.416847995026423e-06,
      "loss": 0.0498,
      "step": 6648
    },
    {
      "epoch": 0.5167081131488965,
      "grad_norm": 0.1046285480260849,
      "learning_rate": 7.416459434255519e-06,
      "loss": 0.0237,
      "step": 6649
    },
    {
      "epoch": 0.5167858253030774,
      "grad_norm": 0.6460424065589905,
      "learning_rate": 7.4160708734846135e-06,
      "loss": 0.2822,
      "step": 6650
    },
    {
      "epoch": 0.5168635374572583,
      "grad_norm": 0.1608012616634369,
      "learning_rate": 7.415682312713709e-06,
      "loss": 0.0394,
      "step": 6651
    },
    {
      "epoch": 0.5169412496114393,
      "grad_norm": 0.5094673037528992,
      "learning_rate": 7.415293751942805e-06,
      "loss": 0.1859,
      "step": 6652
    },
    {
      "epoch": 0.5170189617656201,
      "grad_norm": 0.462651789188385,
      "learning_rate": 7.414905191171899e-06,
      "loss": 0.2019,
      "step": 6653
    },
    {
      "epoch": 0.5170966739198011,
      "grad_norm": 0.20230674743652344,
      "learning_rate": 7.414516630400995e-06,
      "loss": 0.0403,
      "step": 6654
    },
    {
      "epoch": 0.5171743860739819,
      "grad_norm": 0.7592797875404358,
      "learning_rate": 7.414128069630091e-06,
      "loss": 0.2022,
      "step": 6655
    },
    {
      "epoch": 0.5172520982281629,
      "grad_norm": 1.0093510150909424,
      "learning_rate": 7.413739508859186e-06,
      "loss": 0.1344,
      "step": 6656
    },
    {
      "epoch": 0.5173298103823438,
      "grad_norm": 0.1008094772696495,
      "learning_rate": 7.4133509480882816e-06,
      "loss": 0.0392,
      "step": 6657
    },
    {
      "epoch": 0.5174075225365247,
      "grad_norm": 0.20569176971912384,
      "learning_rate": 7.412962387317377e-06,
      "loss": 0.0984,
      "step": 6658
    },
    {
      "epoch": 0.5174852346907056,
      "grad_norm": 0.7323092222213745,
      "learning_rate": 7.412573826546472e-06,
      "loss": 0.3087,
      "step": 6659
    },
    {
      "epoch": 0.5175629468448866,
      "grad_norm": 0.3504006564617157,
      "learning_rate": 7.412185265775568e-06,
      "loss": 0.2203,
      "step": 6660
    },
    {
      "epoch": 0.5176406589990674,
      "grad_norm": 1.078556776046753,
      "learning_rate": 7.411796705004664e-06,
      "loss": 0.6587,
      "step": 6661
    },
    {
      "epoch": 0.5177183711532484,
      "grad_norm": 0.11242593824863434,
      "learning_rate": 7.41140814423376e-06,
      "loss": 0.0485,
      "step": 6662
    },
    {
      "epoch": 0.5177960833074293,
      "grad_norm": 0.5899754166603088,
      "learning_rate": 7.411019583462854e-06,
      "loss": 0.2737,
      "step": 6663
    },
    {
      "epoch": 0.5178737954616102,
      "grad_norm": 0.72768235206604,
      "learning_rate": 7.41063102269195e-06,
      "loss": 0.7168,
      "step": 6664
    },
    {
      "epoch": 0.5179515076157911,
      "grad_norm": 0.18782708048820496,
      "learning_rate": 7.410242461921045e-06,
      "loss": 0.2506,
      "step": 6665
    },
    {
      "epoch": 0.5180292197699721,
      "grad_norm": 0.4719063341617584,
      "learning_rate": 7.40985390115014e-06,
      "loss": 0.3847,
      "step": 6666
    },
    {
      "epoch": 0.5181069319241529,
      "grad_norm": 1.7763724327087402,
      "learning_rate": 7.409465340379236e-06,
      "loss": 0.8157,
      "step": 6667
    },
    {
      "epoch": 0.5181846440783339,
      "grad_norm": 0.4498867988586426,
      "learning_rate": 7.409076779608332e-06,
      "loss": 0.1878,
      "step": 6668
    },
    {
      "epoch": 0.5182623562325148,
      "grad_norm": 0.3897418975830078,
      "learning_rate": 7.408688218837427e-06,
      "loss": 0.0836,
      "step": 6669
    },
    {
      "epoch": 0.5183400683866957,
      "grad_norm": 0.4091835618019104,
      "learning_rate": 7.408299658066523e-06,
      "loss": 0.3387,
      "step": 6670
    },
    {
      "epoch": 0.5184177805408766,
      "grad_norm": 0.12540699541568756,
      "learning_rate": 7.4079110972956185e-06,
      "loss": 0.069,
      "step": 6671
    },
    {
      "epoch": 0.5184954926950575,
      "grad_norm": 0.5119237899780273,
      "learning_rate": 7.407522536524713e-06,
      "loss": 0.0601,
      "step": 6672
    },
    {
      "epoch": 0.5185732048492384,
      "grad_norm": 0.39306923747062683,
      "learning_rate": 7.407133975753808e-06,
      "loss": 0.1148,
      "step": 6673
    },
    {
      "epoch": 0.5186509170034194,
      "grad_norm": 0.33766862750053406,
      "learning_rate": 7.406745414982904e-06,
      "loss": 0.16,
      "step": 6674
    },
    {
      "epoch": 0.5187286291576002,
      "grad_norm": 0.4178289771080017,
      "learning_rate": 7.406356854211999e-06,
      "loss": 0.4215,
      "step": 6675
    },
    {
      "epoch": 0.5188063413117812,
      "grad_norm": 0.517227053642273,
      "learning_rate": 7.405968293441095e-06,
      "loss": 0.1368,
      "step": 6676
    },
    {
      "epoch": 0.5188840534659621,
      "grad_norm": 0.11852062493562698,
      "learning_rate": 7.405579732670191e-06,
      "loss": 0.0673,
      "step": 6677
    },
    {
      "epoch": 0.518961765620143,
      "grad_norm": 0.09879559278488159,
      "learning_rate": 7.405191171899286e-06,
      "loss": 0.0153,
      "step": 6678
    },
    {
      "epoch": 0.5190394777743239,
      "grad_norm": 0.18306520581245422,
      "learning_rate": 7.4048026111283815e-06,
      "loss": 0.0345,
      "step": 6679
    },
    {
      "epoch": 0.5191171899285049,
      "grad_norm": 0.7905631065368652,
      "learning_rate": 7.404414050357477e-06,
      "loss": 0.6011,
      "step": 6680
    },
    {
      "epoch": 0.5191949020826857,
      "grad_norm": 0.2738366425037384,
      "learning_rate": 7.404025489586571e-06,
      "loss": 0.1376,
      "step": 6681
    },
    {
      "epoch": 0.5192726142368667,
      "grad_norm": 0.2103942483663559,
      "learning_rate": 7.403636928815667e-06,
      "loss": 0.0694,
      "step": 6682
    },
    {
      "epoch": 0.5193503263910476,
      "grad_norm": 0.27184563875198364,
      "learning_rate": 7.403248368044763e-06,
      "loss": 0.0575,
      "step": 6683
    },
    {
      "epoch": 0.5194280385452285,
      "grad_norm": 0.2234957367181778,
      "learning_rate": 7.402859807273858e-06,
      "loss": 0.1218,
      "step": 6684
    },
    {
      "epoch": 0.5195057506994094,
      "grad_norm": 0.14536423981189728,
      "learning_rate": 7.402471246502954e-06,
      "loss": 0.0425,
      "step": 6685
    },
    {
      "epoch": 0.5195834628535902,
      "grad_norm": 0.17044642567634583,
      "learning_rate": 7.4020826857320495e-06,
      "loss": 0.0545,
      "step": 6686
    },
    {
      "epoch": 0.5196611750077712,
      "grad_norm": 0.2555197775363922,
      "learning_rate": 7.4016941249611445e-06,
      "loss": 0.1509,
      "step": 6687
    },
    {
      "epoch": 0.5197388871619522,
      "grad_norm": 0.17483501136302948,
      "learning_rate": 7.401305564190239e-06,
      "loss": 0.047,
      "step": 6688
    },
    {
      "epoch": 0.519816599316133,
      "grad_norm": 0.36593136191368103,
      "learning_rate": 7.400917003419335e-06,
      "loss": 0.0884,
      "step": 6689
    },
    {
      "epoch": 0.519894311470314,
      "grad_norm": 0.278076171875,
      "learning_rate": 7.40052844264843e-06,
      "loss": 0.1502,
      "step": 6690
    },
    {
      "epoch": 0.5199720236244949,
      "grad_norm": 0.8250371813774109,
      "learning_rate": 7.400139881877526e-06,
      "loss": 0.3771,
      "step": 6691
    },
    {
      "epoch": 0.5200497357786757,
      "grad_norm": 0.12930722534656525,
      "learning_rate": 7.399751321106622e-06,
      "loss": 0.0859,
      "step": 6692
    },
    {
      "epoch": 0.5201274479328567,
      "grad_norm": 0.30192792415618896,
      "learning_rate": 7.3993627603357175e-06,
      "loss": 0.1881,
      "step": 6693
    },
    {
      "epoch": 0.5202051600870377,
      "grad_norm": 0.22914886474609375,
      "learning_rate": 7.3989741995648125e-06,
      "loss": 0.0594,
      "step": 6694
    },
    {
      "epoch": 0.5202828722412185,
      "grad_norm": 0.2634066939353943,
      "learning_rate": 7.398585638793908e-06,
      "loss": 0.067,
      "step": 6695
    },
    {
      "epoch": 0.5203605843953995,
      "grad_norm": 0.15004846453666687,
      "learning_rate": 7.398197078023004e-06,
      "loss": 0.0565,
      "step": 6696
    },
    {
      "epoch": 0.5204382965495804,
      "grad_norm": 0.4586781859397888,
      "learning_rate": 7.397808517252098e-06,
      "loss": 0.167,
      "step": 6697
    },
    {
      "epoch": 0.5205160087037612,
      "grad_norm": 0.3976134657859802,
      "learning_rate": 7.397419956481194e-06,
      "loss": 0.1876,
      "step": 6698
    },
    {
      "epoch": 0.5205937208579422,
      "grad_norm": 0.036940719932317734,
      "learning_rate": 7.39703139571029e-06,
      "loss": 0.012,
      "step": 6699
    },
    {
      "epoch": 0.520671433012123,
      "grad_norm": 0.24141207337379456,
      "learning_rate": 7.396642834939385e-06,
      "loss": 0.1048,
      "step": 6700
    },
    {
      "epoch": 0.520749145166304,
      "grad_norm": 0.44139397144317627,
      "learning_rate": 7.3962542741684805e-06,
      "loss": 0.7888,
      "step": 6701
    },
    {
      "epoch": 0.520826857320485,
      "grad_norm": 0.36918923258781433,
      "learning_rate": 7.395865713397576e-06,
      "loss": 0.2715,
      "step": 6702
    },
    {
      "epoch": 0.5209045694746658,
      "grad_norm": 0.11927162855863571,
      "learning_rate": 7.395477152626671e-06,
      "loss": 0.0209,
      "step": 6703
    },
    {
      "epoch": 0.5209822816288467,
      "grad_norm": 0.965154230594635,
      "learning_rate": 7.395088591855767e-06,
      "loss": 0.2914,
      "step": 6704
    },
    {
      "epoch": 0.5210599937830277,
      "grad_norm": 0.1867646425962448,
      "learning_rate": 7.394700031084863e-06,
      "loss": 0.074,
      "step": 6705
    },
    {
      "epoch": 0.5211377059372085,
      "grad_norm": 0.3462647795677185,
      "learning_rate": 7.394311470313957e-06,
      "loss": 0.2485,
      "step": 6706
    },
    {
      "epoch": 0.5212154180913895,
      "grad_norm": 0.27506810426712036,
      "learning_rate": 7.393922909543053e-06,
      "loss": 0.1287,
      "step": 6707
    },
    {
      "epoch": 0.5212931302455704,
      "grad_norm": 0.22707600891590118,
      "learning_rate": 7.3935343487721486e-06,
      "loss": 0.4628,
      "step": 6708
    },
    {
      "epoch": 0.5213708423997513,
      "grad_norm": 0.2712806165218353,
      "learning_rate": 7.3931457880012435e-06,
      "loss": 0.1288,
      "step": 6709
    },
    {
      "epoch": 0.5214485545539322,
      "grad_norm": 0.38257724046707153,
      "learning_rate": 7.392757227230339e-06,
      "loss": 0.215,
      "step": 6710
    },
    {
      "epoch": 0.5215262667081132,
      "grad_norm": 0.556212842464447,
      "learning_rate": 7.392368666459435e-06,
      "loss": 0.2217,
      "step": 6711
    },
    {
      "epoch": 0.521603978862294,
      "grad_norm": 0.426686555147171,
      "learning_rate": 7.39198010568853e-06,
      "loss": 0.2966,
      "step": 6712
    },
    {
      "epoch": 0.521681691016475,
      "grad_norm": 0.9682571887969971,
      "learning_rate": 7.391591544917626e-06,
      "loss": 0.7098,
      "step": 6713
    },
    {
      "epoch": 0.5217594031706559,
      "grad_norm": 0.4381818175315857,
      "learning_rate": 7.391202984146722e-06,
      "loss": 0.5369,
      "step": 6714
    },
    {
      "epoch": 0.5218371153248368,
      "grad_norm": 0.09208240360021591,
      "learning_rate": 7.390814423375816e-06,
      "loss": 0.0493,
      "step": 6715
    },
    {
      "epoch": 0.5219148274790177,
      "grad_norm": 0.21471813321113586,
      "learning_rate": 7.3904258626049116e-06,
      "loss": 0.0464,
      "step": 6716
    },
    {
      "epoch": 0.5219925396331986,
      "grad_norm": 0.5562453866004944,
      "learning_rate": 7.390037301834007e-06,
      "loss": 0.2504,
      "step": 6717
    },
    {
      "epoch": 0.5220702517873795,
      "grad_norm": 1.0741751194000244,
      "learning_rate": 7.389648741063102e-06,
      "loss": 0.2756,
      "step": 6718
    },
    {
      "epoch": 0.5221479639415605,
      "grad_norm": 0.16057968139648438,
      "learning_rate": 7.389260180292198e-06,
      "loss": 0.0622,
      "step": 6719
    },
    {
      "epoch": 0.5222256760957413,
      "grad_norm": 0.11765556037425995,
      "learning_rate": 7.388871619521294e-06,
      "loss": 0.02,
      "step": 6720
    },
    {
      "epoch": 0.5223033882499223,
      "grad_norm": 0.16832518577575684,
      "learning_rate": 7.388483058750389e-06,
      "loss": 0.0975,
      "step": 6721
    },
    {
      "epoch": 0.5223811004041032,
      "grad_norm": 0.3837335705757141,
      "learning_rate": 7.388094497979485e-06,
      "loss": 0.7596,
      "step": 6722
    },
    {
      "epoch": 0.5224588125582841,
      "grad_norm": 0.41693639755249023,
      "learning_rate": 7.3877059372085804e-06,
      "loss": 0.1475,
      "step": 6723
    },
    {
      "epoch": 0.522536524712465,
      "grad_norm": 0.5930354595184326,
      "learning_rate": 7.387317376437676e-06,
      "loss": 0.2513,
      "step": 6724
    },
    {
      "epoch": 0.522614236866646,
      "grad_norm": 0.09015266597270966,
      "learning_rate": 7.38692881566677e-06,
      "loss": 0.0472,
      "step": 6725
    },
    {
      "epoch": 0.5226919490208268,
      "grad_norm": 0.19739706814289093,
      "learning_rate": 7.386540254895866e-06,
      "loss": 0.1095,
      "step": 6726
    },
    {
      "epoch": 0.5227696611750078,
      "grad_norm": 0.18646414577960968,
      "learning_rate": 7.386151694124962e-06,
      "loss": 0.0711,
      "step": 6727
    },
    {
      "epoch": 0.5228473733291887,
      "grad_norm": 0.14874610304832458,
      "learning_rate": 7.385763133354057e-06,
      "loss": 0.0431,
      "step": 6728
    },
    {
      "epoch": 0.5229250854833696,
      "grad_norm": 0.38804569840431213,
      "learning_rate": 7.385374572583153e-06,
      "loss": 0.1606,
      "step": 6729
    },
    {
      "epoch": 0.5230027976375505,
      "grad_norm": 0.14998705685138702,
      "learning_rate": 7.3849860118122485e-06,
      "loss": 0.0477,
      "step": 6730
    },
    {
      "epoch": 0.5230805097917314,
      "grad_norm": 0.24763239920139313,
      "learning_rate": 7.384597451041343e-06,
      "loss": 0.096,
      "step": 6731
    },
    {
      "epoch": 0.5231582219459123,
      "grad_norm": 0.32784298062324524,
      "learning_rate": 7.384208890270439e-06,
      "loss": 0.0864,
      "step": 6732
    },
    {
      "epoch": 0.5232359341000933,
      "grad_norm": 0.24093961715698242,
      "learning_rate": 7.383820329499535e-06,
      "loss": 0.104,
      "step": 6733
    },
    {
      "epoch": 0.5233136462542741,
      "grad_norm": 0.616411030292511,
      "learning_rate": 7.383431768728629e-06,
      "loss": 0.3626,
      "step": 6734
    },
    {
      "epoch": 0.5233913584084551,
      "grad_norm": 0.16059666872024536,
      "learning_rate": 7.383043207957725e-06,
      "loss": 0.0874,
      "step": 6735
    },
    {
      "epoch": 0.523469070562636,
      "grad_norm": 0.1423359215259552,
      "learning_rate": 7.382654647186821e-06,
      "loss": 0.0785,
      "step": 6736
    },
    {
      "epoch": 0.5235467827168169,
      "grad_norm": 0.31107190251350403,
      "learning_rate": 7.382266086415916e-06,
      "loss": 0.0866,
      "step": 6737
    },
    {
      "epoch": 0.5236244948709978,
      "grad_norm": 0.5494295358657837,
      "learning_rate": 7.3818775256450115e-06,
      "loss": 0.1383,
      "step": 6738
    },
    {
      "epoch": 0.5237022070251788,
      "grad_norm": 0.06468629837036133,
      "learning_rate": 7.381488964874107e-06,
      "loss": 0.0363,
      "step": 6739
    },
    {
      "epoch": 0.5237799191793596,
      "grad_norm": 0.7169492244720459,
      "learning_rate": 7.381100404103202e-06,
      "loss": 0.1271,
      "step": 6740
    },
    {
      "epoch": 0.5238576313335406,
      "grad_norm": 0.2841266691684723,
      "learning_rate": 7.380711843332298e-06,
      "loss": 0.1573,
      "step": 6741
    },
    {
      "epoch": 0.5239353434877215,
      "grad_norm": 1.1521730422973633,
      "learning_rate": 7.380323282561394e-06,
      "loss": 1.0544,
      "step": 6742
    },
    {
      "epoch": 0.5240130556419024,
      "grad_norm": 0.01663784682750702,
      "learning_rate": 7.379934721790488e-06,
      "loss": 0.0028,
      "step": 6743
    },
    {
      "epoch": 0.5240907677960833,
      "grad_norm": 0.5826734900474548,
      "learning_rate": 7.379546161019584e-06,
      "loss": 0.3537,
      "step": 6744
    },
    {
      "epoch": 0.5241684799502643,
      "grad_norm": 0.18079166114330292,
      "learning_rate": 7.3791576002486795e-06,
      "loss": 0.1801,
      "step": 6745
    },
    {
      "epoch": 0.5242461921044451,
      "grad_norm": 0.40280070900917053,
      "learning_rate": 7.3787690394777744e-06,
      "loss": 0.4384,
      "step": 6746
    },
    {
      "epoch": 0.5243239042586261,
      "grad_norm": 0.4182835817337036,
      "learning_rate": 7.37838047870687e-06,
      "loss": 0.5013,
      "step": 6747
    },
    {
      "epoch": 0.5244016164128069,
      "grad_norm": 0.45275992155075073,
      "learning_rate": 7.377991917935966e-06,
      "loss": 0.293,
      "step": 6748
    },
    {
      "epoch": 0.5244793285669879,
      "grad_norm": 0.5629181265830994,
      "learning_rate": 7.377603357165061e-06,
      "loss": 0.5964,
      "step": 6749
    },
    {
      "epoch": 0.5245570407211688,
      "grad_norm": 0.03467004746198654,
      "learning_rate": 7.377214796394157e-06,
      "loss": 0.0091,
      "step": 6750
    },
    {
      "epoch": 0.5246347528753497,
      "grad_norm": 0.5367569327354431,
      "learning_rate": 7.376826235623253e-06,
      "loss": 0.2533,
      "step": 6751
    },
    {
      "epoch": 0.5247124650295306,
      "grad_norm": 0.20485365390777588,
      "learning_rate": 7.376437674852347e-06,
      "loss": 0.0474,
      "step": 6752
    },
    {
      "epoch": 0.5247901771837116,
      "grad_norm": 0.6945174932479858,
      "learning_rate": 7.3760491140814425e-06,
      "loss": 0.2354,
      "step": 6753
    },
    {
      "epoch": 0.5248678893378924,
      "grad_norm": 0.2300204336643219,
      "learning_rate": 7.375660553310538e-06,
      "loss": 0.1672,
      "step": 6754
    },
    {
      "epoch": 0.5249456014920734,
      "grad_norm": 0.8733893036842346,
      "learning_rate": 7.375271992539634e-06,
      "loss": 0.3586,
      "step": 6755
    },
    {
      "epoch": 0.5250233136462543,
      "grad_norm": 0.2328648716211319,
      "learning_rate": 7.374883431768729e-06,
      "loss": 0.1046,
      "step": 6756
    },
    {
      "epoch": 0.5251010258004352,
      "grad_norm": 0.3687261641025543,
      "learning_rate": 7.374494870997825e-06,
      "loss": 0.0479,
      "step": 6757
    },
    {
      "epoch": 0.5251787379546161,
      "grad_norm": 0.028659511357545853,
      "learning_rate": 7.374106310226921e-06,
      "loss": 0.0073,
      "step": 6758
    },
    {
      "epoch": 0.5252564501087971,
      "grad_norm": 0.672091007232666,
      "learning_rate": 7.3737177494560156e-06,
      "loss": 0.3949,
      "step": 6759
    },
    {
      "epoch": 0.5253341622629779,
      "grad_norm": 0.31495213508605957,
      "learning_rate": 7.373329188685111e-06,
      "loss": 0.0721,
      "step": 6760
    },
    {
      "epoch": 0.5254118744171589,
      "grad_norm": 0.5089846253395081,
      "learning_rate": 7.372940627914207e-06,
      "loss": 0.1169,
      "step": 6761
    },
    {
      "epoch": 0.5254895865713397,
      "grad_norm": 0.30196985602378845,
      "learning_rate": 7.372552067143301e-06,
      "loss": 0.1271,
      "step": 6762
    },
    {
      "epoch": 0.5255672987255207,
      "grad_norm": 0.5116668939590454,
      "learning_rate": 7.372163506372397e-06,
      "loss": 0.2067,
      "step": 6763
    },
    {
      "epoch": 0.5256450108797016,
      "grad_norm": 0.08689437806606293,
      "learning_rate": 7.371774945601493e-06,
      "loss": 0.0179,
      "step": 6764
    },
    {
      "epoch": 0.5257227230338825,
      "grad_norm": 0.33043715357780457,
      "learning_rate": 7.371386384830588e-06,
      "loss": 0.393,
      "step": 6765
    },
    {
      "epoch": 0.5258004351880634,
      "grad_norm": 0.4117586612701416,
      "learning_rate": 7.370997824059684e-06,
      "loss": 0.737,
      "step": 6766
    },
    {
      "epoch": 0.5258781473422444,
      "grad_norm": 0.17043153941631317,
      "learning_rate": 7.370609263288779e-06,
      "loss": 0.0343,
      "step": 6767
    },
    {
      "epoch": 0.5259558594964252,
      "grad_norm": 0.19762152433395386,
      "learning_rate": 7.370220702517874e-06,
      "loss": 0.0977,
      "step": 6768
    },
    {
      "epoch": 0.5260335716506062,
      "grad_norm": 0.10721781849861145,
      "learning_rate": 7.36983214174697e-06,
      "loss": 0.0445,
      "step": 6769
    },
    {
      "epoch": 0.5261112838047871,
      "grad_norm": 0.5343095660209656,
      "learning_rate": 7.369443580976066e-06,
      "loss": 0.2191,
      "step": 6770
    },
    {
      "epoch": 0.526188995958968,
      "grad_norm": 0.402372807264328,
      "learning_rate": 7.36905502020516e-06,
      "loss": 0.1848,
      "step": 6771
    },
    {
      "epoch": 0.5262667081131489,
      "grad_norm": 0.19117678701877594,
      "learning_rate": 7.368666459434256e-06,
      "loss": 0.0755,
      "step": 6772
    },
    {
      "epoch": 0.5263444202673299,
      "grad_norm": 0.11166103184223175,
      "learning_rate": 7.368277898663352e-06,
      "loss": 0.039,
      "step": 6773
    },
    {
      "epoch": 0.5264221324215107,
      "grad_norm": 0.7127689719200134,
      "learning_rate": 7.367889337892447e-06,
      "loss": 0.5655,
      "step": 6774
    },
    {
      "epoch": 0.5264998445756917,
      "grad_norm": 0.2662719488143921,
      "learning_rate": 7.367500777121542e-06,
      "loss": 0.1759,
      "step": 6775
    },
    {
      "epoch": 0.5265775567298725,
      "grad_norm": 0.19440379738807678,
      "learning_rate": 7.367112216350638e-06,
      "loss": 0.1332,
      "step": 6776
    },
    {
      "epoch": 0.5266552688840535,
      "grad_norm": 0.13381463289260864,
      "learning_rate": 7.366723655579733e-06,
      "loss": 0.0441,
      "step": 6777
    },
    {
      "epoch": 0.5267329810382344,
      "grad_norm": 0.2292655110359192,
      "learning_rate": 7.366335094808829e-06,
      "loss": 0.0305,
      "step": 6778
    },
    {
      "epoch": 0.5268106931924152,
      "grad_norm": 0.2728225588798523,
      "learning_rate": 7.365946534037925e-06,
      "loss": 0.1888,
      "step": 6779
    },
    {
      "epoch": 0.5268884053465962,
      "grad_norm": 0.12274320423603058,
      "learning_rate": 7.365557973267019e-06,
      "loss": 0.0373,
      "step": 6780
    },
    {
      "epoch": 0.5269661175007772,
      "grad_norm": 0.639750063419342,
      "learning_rate": 7.365169412496115e-06,
      "loss": 0.7016,
      "step": 6781
    },
    {
      "epoch": 0.527043829654958,
      "grad_norm": 0.3780727982521057,
      "learning_rate": 7.3647808517252104e-06,
      "loss": 0.3124,
      "step": 6782
    },
    {
      "epoch": 0.527121541809139,
      "grad_norm": 0.33905425667762756,
      "learning_rate": 7.364392290954305e-06,
      "loss": 0.186,
      "step": 6783
    },
    {
      "epoch": 0.5271992539633199,
      "grad_norm": 0.10211891680955887,
      "learning_rate": 7.364003730183401e-06,
      "loss": 0.0134,
      "step": 6784
    },
    {
      "epoch": 0.5272769661175007,
      "grad_norm": 0.3898828625679016,
      "learning_rate": 7.363615169412497e-06,
      "loss": 0.2151,
      "step": 6785
    },
    {
      "epoch": 0.5273546782716817,
      "grad_norm": 0.30490759015083313,
      "learning_rate": 7.363226608641593e-06,
      "loss": 0.0329,
      "step": 6786
    },
    {
      "epoch": 0.5274323904258627,
      "grad_norm": 0.15092335641384125,
      "learning_rate": 7.362838047870688e-06,
      "loss": 0.0315,
      "step": 6787
    },
    {
      "epoch": 0.5275101025800435,
      "grad_norm": 0.2623854875564575,
      "learning_rate": 7.3624494870997835e-06,
      "loss": 0.1232,
      "step": 6788
    },
    {
      "epoch": 0.5275878147342244,
      "grad_norm": 0.20887987315654755,
      "learning_rate": 7.362060926328879e-06,
      "loss": 0.1142,
      "step": 6789
    },
    {
      "epoch": 0.5276655268884054,
      "grad_norm": 0.33283379673957825,
      "learning_rate": 7.361672365557973e-06,
      "loss": 0.2004,
      "step": 6790
    },
    {
      "epoch": 0.5277432390425862,
      "grad_norm": 0.9144144654273987,
      "learning_rate": 7.361283804787069e-06,
      "loss": 0.4503,
      "step": 6791
    },
    {
      "epoch": 0.5278209511967672,
      "grad_norm": 0.30586180090904236,
      "learning_rate": 7.360895244016165e-06,
      "loss": 0.1113,
      "step": 6792
    },
    {
      "epoch": 0.527898663350948,
      "grad_norm": 0.1983577162027359,
      "learning_rate": 7.36050668324526e-06,
      "loss": 0.0846,
      "step": 6793
    },
    {
      "epoch": 0.527976375505129,
      "grad_norm": 0.39512884616851807,
      "learning_rate": 7.360118122474356e-06,
      "loss": 0.117,
      "step": 6794
    },
    {
      "epoch": 0.52805408765931,
      "grad_norm": 0.3010712265968323,
      "learning_rate": 7.3597295617034515e-06,
      "loss": 0.198,
      "step": 6795
    },
    {
      "epoch": 0.5281317998134908,
      "grad_norm": 0.8022851347923279,
      "learning_rate": 7.3593410009325465e-06,
      "loss": 0.109,
      "step": 6796
    },
    {
      "epoch": 0.5282095119676717,
      "grad_norm": 0.38799577951431274,
      "learning_rate": 7.358952440161642e-06,
      "loss": 0.3058,
      "step": 6797
    },
    {
      "epoch": 0.5282872241218527,
      "grad_norm": 0.05829523503780365,
      "learning_rate": 7.358563879390738e-06,
      "loss": 0.0084,
      "step": 6798
    },
    {
      "epoch": 0.5283649362760335,
      "grad_norm": 0.37478315830230713,
      "learning_rate": 7.358175318619832e-06,
      "loss": 0.0861,
      "step": 6799
    },
    {
      "epoch": 0.5284426484302145,
      "grad_norm": 1.1884607076644897,
      "learning_rate": 7.357786757848928e-06,
      "loss": 0.403,
      "step": 6800
    },
    {
      "epoch": 0.5285203605843954,
      "grad_norm": 2.890658140182495,
      "learning_rate": 7.357398197078024e-06,
      "loss": 0.6601,
      "step": 6801
    },
    {
      "epoch": 0.5285980727385763,
      "grad_norm": 0.3913528025150299,
      "learning_rate": 7.357009636307119e-06,
      "loss": 0.309,
      "step": 6802
    },
    {
      "epoch": 0.5286757848927572,
      "grad_norm": 0.19494172930717468,
      "learning_rate": 7.3566210755362145e-06,
      "loss": 0.0397,
      "step": 6803
    },
    {
      "epoch": 0.5287534970469382,
      "grad_norm": 0.6617915630340576,
      "learning_rate": 7.35623251476531e-06,
      "loss": 0.3655,
      "step": 6804
    },
    {
      "epoch": 0.528831209201119,
      "grad_norm": 0.16888874769210815,
      "learning_rate": 7.355843953994405e-06,
      "loss": 0.0536,
      "step": 6805
    },
    {
      "epoch": 0.5289089213553,
      "grad_norm": 0.6350910067558289,
      "learning_rate": 7.355455393223501e-06,
      "loss": 0.1416,
      "step": 6806
    },
    {
      "epoch": 0.5289866335094808,
      "grad_norm": 0.3058050870895386,
      "learning_rate": 7.355066832452596e-06,
      "loss": 0.1111,
      "step": 6807
    },
    {
      "epoch": 0.5290643456636618,
      "grad_norm": 0.43347877264022827,
      "learning_rate": 7.354678271681691e-06,
      "loss": 0.1952,
      "step": 6808
    },
    {
      "epoch": 0.5291420578178427,
      "grad_norm": 0.3159952461719513,
      "learning_rate": 7.354289710910787e-06,
      "loss": 0.1311,
      "step": 6809
    },
    {
      "epoch": 0.5292197699720236,
      "grad_norm": 0.23663096129894257,
      "learning_rate": 7.3539011501398826e-06,
      "loss": 0.0484,
      "step": 6810
    },
    {
      "epoch": 0.5292974821262045,
      "grad_norm": 0.5544254779815674,
      "learning_rate": 7.3535125893689775e-06,
      "loss": 0.3144,
      "step": 6811
    },
    {
      "epoch": 0.5293751942803855,
      "grad_norm": 0.5106509923934937,
      "learning_rate": 7.353124028598073e-06,
      "loss": 0.1579,
      "step": 6812
    },
    {
      "epoch": 0.5294529064345663,
      "grad_norm": 0.2859833240509033,
      "learning_rate": 7.352735467827169e-06,
      "loss": 0.0748,
      "step": 6813
    },
    {
      "epoch": 0.5295306185887473,
      "grad_norm": 0.16254150867462158,
      "learning_rate": 7.352346907056265e-06,
      "loss": 0.0219,
      "step": 6814
    },
    {
      "epoch": 0.5296083307429282,
      "grad_norm": 0.12597247958183289,
      "learning_rate": 7.351958346285359e-06,
      "loss": 0.0697,
      "step": 6815
    },
    {
      "epoch": 0.5296860428971091,
      "grad_norm": 1.1456624269485474,
      "learning_rate": 7.351569785514455e-06,
      "loss": 0.2439,
      "step": 6816
    },
    {
      "epoch": 0.52976375505129,
      "grad_norm": 0.29982197284698486,
      "learning_rate": 7.351181224743551e-06,
      "loss": 0.2712,
      "step": 6817
    },
    {
      "epoch": 0.529841467205471,
      "grad_norm": 0.34621870517730713,
      "learning_rate": 7.3507926639726456e-06,
      "loss": 0.1797,
      "step": 6818
    },
    {
      "epoch": 0.5299191793596518,
      "grad_norm": 0.24842074513435364,
      "learning_rate": 7.350404103201741e-06,
      "loss": 0.1092,
      "step": 6819
    },
    {
      "epoch": 0.5299968915138328,
      "grad_norm": 0.388852059841156,
      "learning_rate": 7.350015542430837e-06,
      "loss": 0.0711,
      "step": 6820
    },
    {
      "epoch": 0.5300746036680136,
      "grad_norm": 0.6670699715614319,
      "learning_rate": 7.349626981659932e-06,
      "loss": 0.5731,
      "step": 6821
    },
    {
      "epoch": 0.5301523158221946,
      "grad_norm": 0.22096174955368042,
      "learning_rate": 7.349238420889028e-06,
      "loss": 0.1427,
      "step": 6822
    },
    {
      "epoch": 0.5302300279763755,
      "grad_norm": 0.09837803244590759,
      "learning_rate": 7.348849860118124e-06,
      "loss": 0.0176,
      "step": 6823
    },
    {
      "epoch": 0.5303077401305564,
      "grad_norm": 1.048378825187683,
      "learning_rate": 7.348461299347218e-06,
      "loss": 0.3156,
      "step": 6824
    },
    {
      "epoch": 0.5303854522847373,
      "grad_norm": 0.487244576215744,
      "learning_rate": 7.348072738576314e-06,
      "loss": 0.2716,
      "step": 6825
    },
    {
      "epoch": 0.5304631644389183,
      "grad_norm": 0.14955109357833862,
      "learning_rate": 7.347684177805409e-06,
      "loss": 0.0505,
      "step": 6826
    },
    {
      "epoch": 0.5305408765930991,
      "grad_norm": 0.29938629269599915,
      "learning_rate": 7.347295617034504e-06,
      "loss": 0.098,
      "step": 6827
    },
    {
      "epoch": 0.5306185887472801,
      "grad_norm": 0.11180918663740158,
      "learning_rate": 7.3469070562636e-06,
      "loss": 0.0723,
      "step": 6828
    },
    {
      "epoch": 0.530696300901461,
      "grad_norm": 0.5854099988937378,
      "learning_rate": 7.346518495492696e-06,
      "loss": 0.708,
      "step": 6829
    },
    {
      "epoch": 0.5307740130556419,
      "grad_norm": 0.7885770201683044,
      "learning_rate": 7.346129934721791e-06,
      "loss": 0.1943,
      "step": 6830
    },
    {
      "epoch": 0.5308517252098228,
      "grad_norm": 0.5476531982421875,
      "learning_rate": 7.345741373950887e-06,
      "loss": 0.3335,
      "step": 6831
    },
    {
      "epoch": 0.5309294373640038,
      "grad_norm": 0.15842874348163605,
      "learning_rate": 7.3453528131799825e-06,
      "loss": 0.0303,
      "step": 6832
    },
    {
      "epoch": 0.5310071495181846,
      "grad_norm": 0.24847130477428436,
      "learning_rate": 7.344964252409077e-06,
      "loss": 0.1387,
      "step": 6833
    },
    {
      "epoch": 0.5310848616723656,
      "grad_norm": 0.6365240216255188,
      "learning_rate": 7.344575691638172e-06,
      "loss": 0.5921,
      "step": 6834
    },
    {
      "epoch": 0.5311625738265465,
      "grad_norm": 0.2891096770763397,
      "learning_rate": 7.344187130867268e-06,
      "loss": 0.31,
      "step": 6835
    },
    {
      "epoch": 0.5312402859807274,
      "grad_norm": 0.21569734811782837,
      "learning_rate": 7.343798570096363e-06,
      "loss": 0.1389,
      "step": 6836
    },
    {
      "epoch": 0.5313179981349083,
      "grad_norm": 0.18937091529369354,
      "learning_rate": 7.343410009325459e-06,
      "loss": 0.1378,
      "step": 6837
    },
    {
      "epoch": 0.5313957102890892,
      "grad_norm": 0.3193379044532776,
      "learning_rate": 7.343021448554555e-06,
      "loss": 0.0737,
      "step": 6838
    },
    {
      "epoch": 0.5314734224432701,
      "grad_norm": 0.6173467040061951,
      "learning_rate": 7.34263288778365e-06,
      "loss": 0.1601,
      "step": 6839
    },
    {
      "epoch": 0.5315511345974511,
      "grad_norm": 0.19958020746707916,
      "learning_rate": 7.3422443270127455e-06,
      "loss": 0.0951,
      "step": 6840
    },
    {
      "epoch": 0.5316288467516319,
      "grad_norm": 0.2767086625099182,
      "learning_rate": 7.341855766241841e-06,
      "loss": 0.0602,
      "step": 6841
    },
    {
      "epoch": 0.5317065589058129,
      "grad_norm": 0.8252941370010376,
      "learning_rate": 7.341467205470935e-06,
      "loss": 0.1159,
      "step": 6842
    },
    {
      "epoch": 0.5317842710599938,
      "grad_norm": 0.33685362339019775,
      "learning_rate": 7.341078644700031e-06,
      "loss": 0.1435,
      "step": 6843
    },
    {
      "epoch": 0.5318619832141747,
      "grad_norm": 0.41736072301864624,
      "learning_rate": 7.340690083929127e-06,
      "loss": 0.7739,
      "step": 6844
    },
    {
      "epoch": 0.5319396953683556,
      "grad_norm": 0.32033729553222656,
      "learning_rate": 7.340301523158223e-06,
      "loss": 0.2059,
      "step": 6845
    },
    {
      "epoch": 0.5320174075225366,
      "grad_norm": 0.3668464124202728,
      "learning_rate": 7.339912962387318e-06,
      "loss": 0.506,
      "step": 6846
    },
    {
      "epoch": 0.5320951196767174,
      "grad_norm": 0.22934836149215698,
      "learning_rate": 7.3395244016164135e-06,
      "loss": 0.0641,
      "step": 6847
    },
    {
      "epoch": 0.5321728318308984,
      "grad_norm": 0.40888863801956177,
      "learning_rate": 7.339135840845509e-06,
      "loss": 0.0986,
      "step": 6848
    },
    {
      "epoch": 0.5322505439850793,
      "grad_norm": 0.2877519130706787,
      "learning_rate": 7.338747280074604e-06,
      "loss": 0.1241,
      "step": 6849
    },
    {
      "epoch": 0.5323282561392602,
      "grad_norm": 0.13342620432376862,
      "learning_rate": 7.3383587193037e-06,
      "loss": 0.0715,
      "step": 6850
    },
    {
      "epoch": 0.5324059682934411,
      "grad_norm": 0.5825364589691162,
      "learning_rate": 7.337970158532796e-06,
      "loss": 0.3384,
      "step": 6851
    },
    {
      "epoch": 0.532483680447622,
      "grad_norm": 0.4650167226791382,
      "learning_rate": 7.33758159776189e-06,
      "loss": 1.0649,
      "step": 6852
    },
    {
      "epoch": 0.5325613926018029,
      "grad_norm": 0.4705859422683716,
      "learning_rate": 7.337193036990986e-06,
      "loss": 0.2314,
      "step": 6853
    },
    {
      "epoch": 0.5326391047559839,
      "grad_norm": 0.30747514963150024,
      "learning_rate": 7.3368044762200815e-06,
      "loss": 0.1322,
      "step": 6854
    },
    {
      "epoch": 0.5327168169101647,
      "grad_norm": 0.3927130103111267,
      "learning_rate": 7.3364159154491765e-06,
      "loss": 0.1827,
      "step": 6855
    },
    {
      "epoch": 0.5327945290643457,
      "grad_norm": 0.1908159703016281,
      "learning_rate": 7.336027354678272e-06,
      "loss": 0.0618,
      "step": 6856
    },
    {
      "epoch": 0.5328722412185266,
      "grad_norm": 0.27026090025901794,
      "learning_rate": 7.335638793907368e-06,
      "loss": 0.0583,
      "step": 6857
    },
    {
      "epoch": 0.5329499533727075,
      "grad_norm": 0.07860694080591202,
      "learning_rate": 7.335250233136463e-06,
      "loss": 0.03,
      "step": 6858
    },
    {
      "epoch": 0.5330276655268884,
      "grad_norm": 0.3350231647491455,
      "learning_rate": 7.334861672365559e-06,
      "loss": 0.2197,
      "step": 6859
    },
    {
      "epoch": 0.5331053776810694,
      "grad_norm": 0.315582275390625,
      "learning_rate": 7.334473111594655e-06,
      "loss": 0.1467,
      "step": 6860
    },
    {
      "epoch": 0.5331830898352502,
      "grad_norm": 0.1348596066236496,
      "learning_rate": 7.334084550823749e-06,
      "loss": 0.0316,
      "step": 6861
    },
    {
      "epoch": 0.5332608019894312,
      "grad_norm": 0.09808898717164993,
      "learning_rate": 7.3336959900528445e-06,
      "loss": 0.0531,
      "step": 6862
    },
    {
      "epoch": 0.5333385141436121,
      "grad_norm": 0.4082317352294922,
      "learning_rate": 7.33330742928194e-06,
      "loss": 0.0972,
      "step": 6863
    },
    {
      "epoch": 0.533416226297793,
      "grad_norm": 0.31534895300865173,
      "learning_rate": 7.332918868511035e-06,
      "loss": 0.575,
      "step": 6864
    },
    {
      "epoch": 0.5334939384519739,
      "grad_norm": 0.1647072732448578,
      "learning_rate": 7.332530307740131e-06,
      "loss": 0.0531,
      "step": 6865
    },
    {
      "epoch": 0.5335716506061549,
      "grad_norm": 1.0863912105560303,
      "learning_rate": 7.332141746969227e-06,
      "loss": 0.5403,
      "step": 6866
    },
    {
      "epoch": 0.5336493627603357,
      "grad_norm": 0.5288548469543457,
      "learning_rate": 7.331753186198322e-06,
      "loss": 0.5906,
      "step": 6867
    },
    {
      "epoch": 0.5337270749145167,
      "grad_norm": 0.1249731183052063,
      "learning_rate": 7.331364625427418e-06,
      "loss": 0.0266,
      "step": 6868
    },
    {
      "epoch": 0.5338047870686975,
      "grad_norm": 0.3442288041114807,
      "learning_rate": 7.330976064656513e-06,
      "loss": 0.0861,
      "step": 6869
    },
    {
      "epoch": 0.5338824992228784,
      "grad_norm": 0.07694362848997116,
      "learning_rate": 7.3305875038856075e-06,
      "loss": 0.0126,
      "step": 6870
    },
    {
      "epoch": 0.5339602113770594,
      "grad_norm": 0.27463409304618835,
      "learning_rate": 7.330198943114703e-06,
      "loss": 0.1118,
      "step": 6871
    },
    {
      "epoch": 0.5340379235312402,
      "grad_norm": 0.29076653718948364,
      "learning_rate": 7.329810382343799e-06,
      "loss": 0.0455,
      "step": 6872
    },
    {
      "epoch": 0.5341156356854212,
      "grad_norm": 0.2503342926502228,
      "learning_rate": 7.329421821572894e-06,
      "loss": 0.1767,
      "step": 6873
    },
    {
      "epoch": 0.5341933478396022,
      "grad_norm": 0.3882130980491638,
      "learning_rate": 7.32903326080199e-06,
      "loss": 0.9592,
      "step": 6874
    },
    {
      "epoch": 0.534271059993783,
      "grad_norm": 0.1839212030172348,
      "learning_rate": 7.328644700031086e-06,
      "loss": 0.0373,
      "step": 6875
    },
    {
      "epoch": 0.534348772147964,
      "grad_norm": 0.14152036607265472,
      "learning_rate": 7.3282561392601814e-06,
      "loss": 0.0388,
      "step": 6876
    },
    {
      "epoch": 0.5344264843021449,
      "grad_norm": 0.4812428653240204,
      "learning_rate": 7.327867578489276e-06,
      "loss": 0.1153,
      "step": 6877
    },
    {
      "epoch": 0.5345041964563257,
      "grad_norm": 0.25843334197998047,
      "learning_rate": 7.327479017718372e-06,
      "loss": 0.0976,
      "step": 6878
    },
    {
      "epoch": 0.5345819086105067,
      "grad_norm": 0.48627573251724243,
      "learning_rate": 7.327090456947468e-06,
      "loss": 0.3232,
      "step": 6879
    },
    {
      "epoch": 0.5346596207646876,
      "grad_norm": 0.3822211027145386,
      "learning_rate": 7.326701896176562e-06,
      "loss": 0.26,
      "step": 6880
    },
    {
      "epoch": 0.5347373329188685,
      "grad_norm": 0.1832762062549591,
      "learning_rate": 7.326313335405658e-06,
      "loss": 0.0656,
      "step": 6881
    },
    {
      "epoch": 0.5348150450730494,
      "grad_norm": 0.41531533002853394,
      "learning_rate": 7.325924774634754e-06,
      "loss": 0.3046,
      "step": 6882
    },
    {
      "epoch": 0.5348927572272303,
      "grad_norm": 0.3851030766963959,
      "learning_rate": 7.325536213863849e-06,
      "loss": 0.1074,
      "step": 6883
    },
    {
      "epoch": 0.5349704693814112,
      "grad_norm": 0.21615587174892426,
      "learning_rate": 7.3251476530929444e-06,
      "loss": 0.0639,
      "step": 6884
    },
    {
      "epoch": 0.5350481815355922,
      "grad_norm": 0.7607672810554504,
      "learning_rate": 7.32475909232204e-06,
      "loss": 0.4373,
      "step": 6885
    },
    {
      "epoch": 0.535125893689773,
      "grad_norm": 0.09515374153852463,
      "learning_rate": 7.324370531551135e-06,
      "loss": 0.0221,
      "step": 6886
    },
    {
      "epoch": 0.535203605843954,
      "grad_norm": 0.31378790736198425,
      "learning_rate": 7.323981970780231e-06,
      "loss": 0.2298,
      "step": 6887
    },
    {
      "epoch": 0.5352813179981349,
      "grad_norm": 0.30280137062072754,
      "learning_rate": 7.323593410009327e-06,
      "loss": 0.0687,
      "step": 6888
    },
    {
      "epoch": 0.5353590301523158,
      "grad_norm": 0.8438976407051086,
      "learning_rate": 7.323204849238421e-06,
      "loss": 0.1348,
      "step": 6889
    },
    {
      "epoch": 0.5354367423064967,
      "grad_norm": 0.47080275416374207,
      "learning_rate": 7.322816288467517e-06,
      "loss": 0.168,
      "step": 6890
    },
    {
      "epoch": 0.5355144544606777,
      "grad_norm": 0.30632004141807556,
      "learning_rate": 7.3224277276966125e-06,
      "loss": 0.239,
      "step": 6891
    },
    {
      "epoch": 0.5355921666148585,
      "grad_norm": 0.19817450642585754,
      "learning_rate": 7.322039166925707e-06,
      "loss": 0.0796,
      "step": 6892
    },
    {
      "epoch": 0.5356698787690395,
      "grad_norm": 0.12840090692043304,
      "learning_rate": 7.321650606154803e-06,
      "loss": 0.044,
      "step": 6893
    },
    {
      "epoch": 0.5357475909232204,
      "grad_norm": 0.44444212317466736,
      "learning_rate": 7.321262045383899e-06,
      "loss": 0.2962,
      "step": 6894
    },
    {
      "epoch": 0.5358253030774013,
      "grad_norm": 0.23169435560703278,
      "learning_rate": 7.320873484612994e-06,
      "loss": 0.0496,
      "step": 6895
    },
    {
      "epoch": 0.5359030152315822,
      "grad_norm": 0.41264134645462036,
      "learning_rate": 7.32048492384209e-06,
      "loss": 0.1292,
      "step": 6896
    },
    {
      "epoch": 0.5359807273857631,
      "grad_norm": 0.4640308916568756,
      "learning_rate": 7.3200963630711856e-06,
      "loss": 0.404,
      "step": 6897
    },
    {
      "epoch": 0.536058439539944,
      "grad_norm": 0.24945245683193207,
      "learning_rate": 7.31970780230028e-06,
      "loss": 0.0841,
      "step": 6898
    },
    {
      "epoch": 0.536136151694125,
      "grad_norm": 0.3300190567970276,
      "learning_rate": 7.3193192415293755e-06,
      "loss": 0.0959,
      "step": 6899
    },
    {
      "epoch": 0.5362138638483058,
      "grad_norm": 0.11741258949041367,
      "learning_rate": 7.318930680758471e-06,
      "loss": 0.0632,
      "step": 6900
    },
    {
      "epoch": 0.5362915760024868,
      "grad_norm": 0.23816607892513275,
      "learning_rate": 7.318542119987566e-06,
      "loss": 0.0798,
      "step": 6901
    },
    {
      "epoch": 0.5363692881566677,
      "grad_norm": 0.5698406100273132,
      "learning_rate": 7.318153559216662e-06,
      "loss": 0.3796,
      "step": 6902
    },
    {
      "epoch": 0.5364470003108486,
      "grad_norm": 0.36941295862197876,
      "learning_rate": 7.317764998445758e-06,
      "loss": 0.1792,
      "step": 6903
    },
    {
      "epoch": 0.5365247124650295,
      "grad_norm": 0.2715763449668884,
      "learning_rate": 7.317376437674853e-06,
      "loss": 0.1182,
      "step": 6904
    },
    {
      "epoch": 0.5366024246192105,
      "grad_norm": 0.5382817983627319,
      "learning_rate": 7.3169878769039485e-06,
      "loss": 0.3012,
      "step": 6905
    },
    {
      "epoch": 0.5366801367733913,
      "grad_norm": 0.28590115904808044,
      "learning_rate": 7.316599316133044e-06,
      "loss": 0.1981,
      "step": 6906
    },
    {
      "epoch": 0.5367578489275723,
      "grad_norm": 0.8469358682632446,
      "learning_rate": 7.31621075536214e-06,
      "loss": 0.2093,
      "step": 6907
    },
    {
      "epoch": 0.5368355610817532,
      "grad_norm": 0.23466920852661133,
      "learning_rate": 7.315822194591234e-06,
      "loss": 0.1359,
      "step": 6908
    },
    {
      "epoch": 0.5369132732359341,
      "grad_norm": 0.334492564201355,
      "learning_rate": 7.31543363382033e-06,
      "loss": 0.1591,
      "step": 6909
    },
    {
      "epoch": 0.536990985390115,
      "grad_norm": 0.20129327476024628,
      "learning_rate": 7.315045073049426e-06,
      "loss": 0.2766,
      "step": 6910
    },
    {
      "epoch": 0.537068697544296,
      "grad_norm": 0.3459753394126892,
      "learning_rate": 7.314656512278521e-06,
      "loss": 0.1392,
      "step": 6911
    },
    {
      "epoch": 0.5371464096984768,
      "grad_norm": 0.5313065648078918,
      "learning_rate": 7.3142679515076166e-06,
      "loss": 0.1243,
      "step": 6912
    },
    {
      "epoch": 0.5372241218526578,
      "grad_norm": 0.16698722541332245,
      "learning_rate": 7.313879390736712e-06,
      "loss": 0.0708,
      "step": 6913
    },
    {
      "epoch": 0.5373018340068386,
      "grad_norm": 0.37241068482398987,
      "learning_rate": 7.313490829965807e-06,
      "loss": 0.1531,
      "step": 6914
    },
    {
      "epoch": 0.5373795461610196,
      "grad_norm": 0.1206611767411232,
      "learning_rate": 7.313102269194903e-06,
      "loss": 0.0352,
      "step": 6915
    },
    {
      "epoch": 0.5374572583152005,
      "grad_norm": 0.6412609815597534,
      "learning_rate": 7.312713708423999e-06,
      "loss": 0.3748,
      "step": 6916
    },
    {
      "epoch": 0.5375349704693814,
      "grad_norm": 0.24626897275447845,
      "learning_rate": 7.312325147653093e-06,
      "loss": 0.097,
      "step": 6917
    },
    {
      "epoch": 0.5376126826235623,
      "grad_norm": 0.10386665910482407,
      "learning_rate": 7.311936586882189e-06,
      "loss": 0.0305,
      "step": 6918
    },
    {
      "epoch": 0.5376903947777433,
      "grad_norm": 0.23496654629707336,
      "learning_rate": 7.311548026111285e-06,
      "loss": 0.1296,
      "step": 6919
    },
    {
      "epoch": 0.5377681069319241,
      "grad_norm": 0.24095574021339417,
      "learning_rate": 7.3111594653403796e-06,
      "loss": 0.2114,
      "step": 6920
    },
    {
      "epoch": 0.5378458190861051,
      "grad_norm": 0.33396026492118835,
      "learning_rate": 7.310770904569475e-06,
      "loss": 0.1025,
      "step": 6921
    },
    {
      "epoch": 0.537923531240286,
      "grad_norm": 0.33062875270843506,
      "learning_rate": 7.310382343798571e-06,
      "loss": 0.1498,
      "step": 6922
    },
    {
      "epoch": 0.5380012433944669,
      "grad_norm": 0.756777286529541,
      "learning_rate": 7.309993783027666e-06,
      "loss": 0.2153,
      "step": 6923
    },
    {
      "epoch": 0.5380789555486478,
      "grad_norm": 0.11673479527235031,
      "learning_rate": 7.309605222256762e-06,
      "loss": 0.0346,
      "step": 6924
    },
    {
      "epoch": 0.5381566677028288,
      "grad_norm": 0.9006819128990173,
      "learning_rate": 7.309216661485858e-06,
      "loss": 0.6343,
      "step": 6925
    },
    {
      "epoch": 0.5382343798570096,
      "grad_norm": 0.8195324540138245,
      "learning_rate": 7.308828100714952e-06,
      "loss": 0.3805,
      "step": 6926
    },
    {
      "epoch": 0.5383120920111906,
      "grad_norm": 0.3951783776283264,
      "learning_rate": 7.308439539944048e-06,
      "loss": 0.0582,
      "step": 6927
    },
    {
      "epoch": 0.5383898041653714,
      "grad_norm": 0.3567560911178589,
      "learning_rate": 7.308050979173143e-06,
      "loss": 0.2145,
      "step": 6928
    },
    {
      "epoch": 0.5384675163195524,
      "grad_norm": 0.33243992924690247,
      "learning_rate": 7.307662418402238e-06,
      "loss": 0.2367,
      "step": 6929
    },
    {
      "epoch": 0.5385452284737333,
      "grad_norm": 0.6886011958122253,
      "learning_rate": 7.307273857631334e-06,
      "loss": 0.407,
      "step": 6930
    },
    {
      "epoch": 0.5386229406279142,
      "grad_norm": 0.9317819476127625,
      "learning_rate": 7.30688529686043e-06,
      "loss": 0.2795,
      "step": 6931
    },
    {
      "epoch": 0.5387006527820951,
      "grad_norm": 0.3657633662223816,
      "learning_rate": 7.306496736089525e-06,
      "loss": 0.0979,
      "step": 6932
    },
    {
      "epoch": 0.5387783649362761,
      "grad_norm": 0.16943718492984772,
      "learning_rate": 7.306108175318621e-06,
      "loss": 0.0468,
      "step": 6933
    },
    {
      "epoch": 0.5388560770904569,
      "grad_norm": 0.21019583940505981,
      "learning_rate": 7.305719614547716e-06,
      "loss": 0.1014,
      "step": 6934
    },
    {
      "epoch": 0.5389337892446379,
      "grad_norm": 0.25108152627944946,
      "learning_rate": 7.3053310537768114e-06,
      "loss": 0.0933,
      "step": 6935
    },
    {
      "epoch": 0.5390115013988188,
      "grad_norm": 0.2666459083557129,
      "learning_rate": 7.304942493005906e-06,
      "loss": 0.1876,
      "step": 6936
    },
    {
      "epoch": 0.5390892135529997,
      "grad_norm": 0.3944658637046814,
      "learning_rate": 7.304553932235002e-06,
      "loss": 0.2371,
      "step": 6937
    },
    {
      "epoch": 0.5391669257071806,
      "grad_norm": 0.40756112337112427,
      "learning_rate": 7.304165371464098e-06,
      "loss": 0.24,
      "step": 6938
    },
    {
      "epoch": 0.5392446378613616,
      "grad_norm": 0.4886053204536438,
      "learning_rate": 7.303776810693193e-06,
      "loss": 0.9786,
      "step": 6939
    },
    {
      "epoch": 0.5393223500155424,
      "grad_norm": 0.20264850556850433,
      "learning_rate": 7.303388249922289e-06,
      "loss": 0.0909,
      "step": 6940
    },
    {
      "epoch": 0.5394000621697234,
      "grad_norm": 0.33649295568466187,
      "learning_rate": 7.3029996891513845e-06,
      "loss": 0.6803,
      "step": 6941
    },
    {
      "epoch": 0.5394777743239043,
      "grad_norm": 0.3875511586666107,
      "learning_rate": 7.302611128380479e-06,
      "loss": 0.2873,
      "step": 6942
    },
    {
      "epoch": 0.5395554864780852,
      "grad_norm": 0.6215904951095581,
      "learning_rate": 7.302222567609574e-06,
      "loss": 0.3265,
      "step": 6943
    },
    {
      "epoch": 0.5396331986322661,
      "grad_norm": 0.07686559855937958,
      "learning_rate": 7.30183400683867e-06,
      "loss": 0.0109,
      "step": 6944
    },
    {
      "epoch": 0.539710910786447,
      "grad_norm": 0.8166471123695374,
      "learning_rate": 7.301445446067765e-06,
      "loss": 0.2729,
      "step": 6945
    },
    {
      "epoch": 0.5397886229406279,
      "grad_norm": 0.3689967095851898,
      "learning_rate": 7.301056885296861e-06,
      "loss": 0.3454,
      "step": 6946
    },
    {
      "epoch": 0.5398663350948089,
      "grad_norm": 0.45174258947372437,
      "learning_rate": 7.300668324525957e-06,
      "loss": 0.2297,
      "step": 6947
    },
    {
      "epoch": 0.5399440472489897,
      "grad_norm": 0.23442251980304718,
      "learning_rate": 7.300279763755052e-06,
      "loss": 0.1401,
      "step": 6948
    },
    {
      "epoch": 0.5400217594031707,
      "grad_norm": 0.28498852252960205,
      "learning_rate": 7.2998912029841475e-06,
      "loss": 0.1521,
      "step": 6949
    },
    {
      "epoch": 0.5400994715573516,
      "grad_norm": 0.3597448468208313,
      "learning_rate": 7.299502642213243e-06,
      "loss": 0.088,
      "step": 6950
    },
    {
      "epoch": 0.5401771837115324,
      "grad_norm": 0.6255271434783936,
      "learning_rate": 7.299114081442337e-06,
      "loss": 0.6931,
      "step": 6951
    },
    {
      "epoch": 0.5402548958657134,
      "grad_norm": 0.45739421248435974,
      "learning_rate": 7.298725520671433e-06,
      "loss": 0.2915,
      "step": 6952
    },
    {
      "epoch": 0.5403326080198944,
      "grad_norm": 0.27625396847724915,
      "learning_rate": 7.298336959900529e-06,
      "loss": 0.1828,
      "step": 6953
    },
    {
      "epoch": 0.5404103201740752,
      "grad_norm": 1.4224088191986084,
      "learning_rate": 7.297948399129624e-06,
      "loss": 0.4041,
      "step": 6954
    },
    {
      "epoch": 0.5404880323282562,
      "grad_norm": 0.302962064743042,
      "learning_rate": 7.29755983835872e-06,
      "loss": 0.0701,
      "step": 6955
    },
    {
      "epoch": 0.5405657444824371,
      "grad_norm": 0.04662388563156128,
      "learning_rate": 7.2971712775878155e-06,
      "loss": 0.0067,
      "step": 6956
    },
    {
      "epoch": 0.540643456636618,
      "grad_norm": 0.7162443995475769,
      "learning_rate": 7.2967827168169105e-06,
      "loss": 0.3491,
      "step": 6957
    },
    {
      "epoch": 0.5407211687907989,
      "grad_norm": 1.7832196950912476,
      "learning_rate": 7.296394156046006e-06,
      "loss": 0.1149,
      "step": 6958
    },
    {
      "epoch": 0.5407988809449797,
      "grad_norm": 0.08949092030525208,
      "learning_rate": 7.296005595275102e-06,
      "loss": 0.0103,
      "step": 6959
    },
    {
      "epoch": 0.5408765930991607,
      "grad_norm": 0.5447167158126831,
      "learning_rate": 7.295617034504196e-06,
      "loss": 0.4382,
      "step": 6960
    },
    {
      "epoch": 0.5409543052533416,
      "grad_norm": 0.33853843808174133,
      "learning_rate": 7.295228473733292e-06,
      "loss": 0.1832,
      "step": 6961
    },
    {
      "epoch": 0.5410320174075225,
      "grad_norm": 0.09456811845302582,
      "learning_rate": 7.294839912962388e-06,
      "loss": 0.0529,
      "step": 6962
    },
    {
      "epoch": 0.5411097295617034,
      "grad_norm": 0.4154505133628845,
      "learning_rate": 7.294451352191483e-06,
      "loss": 0.0654,
      "step": 6963
    },
    {
      "epoch": 0.5411874417158844,
      "grad_norm": 0.090024434030056,
      "learning_rate": 7.2940627914205785e-06,
      "loss": 0.0104,
      "step": 6964
    },
    {
      "epoch": 0.5412651538700652,
      "grad_norm": 0.36288580298423767,
      "learning_rate": 7.293674230649674e-06,
      "loss": 0.3156,
      "step": 6965
    },
    {
      "epoch": 0.5413428660242462,
      "grad_norm": 0.5205644965171814,
      "learning_rate": 7.29328566987877e-06,
      "loss": 0.1577,
      "step": 6966
    },
    {
      "epoch": 0.5414205781784271,
      "grad_norm": 0.48556020855903625,
      "learning_rate": 7.292897109107865e-06,
      "loss": 0.1041,
      "step": 6967
    },
    {
      "epoch": 0.541498290332608,
      "grad_norm": 0.29643726348876953,
      "learning_rate": 7.292508548336961e-06,
      "loss": 0.0984,
      "step": 6968
    },
    {
      "epoch": 0.5415760024867889,
      "grad_norm": 0.23763878643512726,
      "learning_rate": 7.292119987566057e-06,
      "loss": 0.3006,
      "step": 6969
    },
    {
      "epoch": 0.5416537146409699,
      "grad_norm": 0.06282053887844086,
      "learning_rate": 7.291731426795151e-06,
      "loss": 0.0165,
      "step": 6970
    },
    {
      "epoch": 0.5417314267951507,
      "grad_norm": 0.567679226398468,
      "learning_rate": 7.2913428660242466e-06,
      "loss": 0.2521,
      "step": 6971
    },
    {
      "epoch": 0.5418091389493317,
      "grad_norm": 0.6771328449249268,
      "learning_rate": 7.290954305253342e-06,
      "loss": 0.286,
      "step": 6972
    },
    {
      "epoch": 0.5418868511035125,
      "grad_norm": 0.5855891108512878,
      "learning_rate": 7.290565744482437e-06,
      "loss": 0.2024,
      "step": 6973
    },
    {
      "epoch": 0.5419645632576935,
      "grad_norm": 1.6095787286758423,
      "learning_rate": 7.290177183711533e-06,
      "loss": 0.4632,
      "step": 6974
    },
    {
      "epoch": 0.5420422754118744,
      "grad_norm": 0.20212799310684204,
      "learning_rate": 7.289788622940629e-06,
      "loss": 0.1708,
      "step": 6975
    },
    {
      "epoch": 0.5421199875660553,
      "grad_norm": 0.084007129073143,
      "learning_rate": 7.289400062169724e-06,
      "loss": 0.0279,
      "step": 6976
    },
    {
      "epoch": 0.5421976997202362,
      "grad_norm": 0.4176363945007324,
      "learning_rate": 7.28901150139882e-06,
      "loss": 0.1741,
      "step": 6977
    },
    {
      "epoch": 0.5422754118744172,
      "grad_norm": 0.43800878524780273,
      "learning_rate": 7.2886229406279154e-06,
      "loss": 0.1697,
      "step": 6978
    },
    {
      "epoch": 0.542353124028598,
      "grad_norm": 0.10113329440355301,
      "learning_rate": 7.2882343798570096e-06,
      "loss": 0.0219,
      "step": 6979
    },
    {
      "epoch": 0.542430836182779,
      "grad_norm": 0.36718514561653137,
      "learning_rate": 7.287845819086105e-06,
      "loss": 0.0618,
      "step": 6980
    },
    {
      "epoch": 0.5425085483369599,
      "grad_norm": 0.4428597092628479,
      "learning_rate": 7.287457258315201e-06,
      "loss": 0.0718,
      "step": 6981
    },
    {
      "epoch": 0.5425862604911408,
      "grad_norm": 0.5512232184410095,
      "learning_rate": 7.287068697544296e-06,
      "loss": 0.2866,
      "step": 6982
    },
    {
      "epoch": 0.5426639726453217,
      "grad_norm": 0.06249668821692467,
      "learning_rate": 7.286680136773392e-06,
      "loss": 0.008,
      "step": 6983
    },
    {
      "epoch": 0.5427416847995027,
      "grad_norm": 0.7414673566818237,
      "learning_rate": 7.286291576002488e-06,
      "loss": 0.3924,
      "step": 6984
    },
    {
      "epoch": 0.5428193969536835,
      "grad_norm": 0.3141951262950897,
      "learning_rate": 7.285903015231583e-06,
      "loss": 0.0733,
      "step": 6985
    },
    {
      "epoch": 0.5428971091078645,
      "grad_norm": 1.3438615798950195,
      "learning_rate": 7.2855144544606784e-06,
      "loss": 0.2788,
      "step": 6986
    },
    {
      "epoch": 0.5429748212620454,
      "grad_norm": 0.304705411195755,
      "learning_rate": 7.285125893689774e-06,
      "loss": 0.0514,
      "step": 6987
    },
    {
      "epoch": 0.5430525334162263,
      "grad_norm": 0.5672087669372559,
      "learning_rate": 7.284737332918868e-06,
      "loss": 0.5859,
      "step": 6988
    },
    {
      "epoch": 0.5431302455704072,
      "grad_norm": 0.5679364204406738,
      "learning_rate": 7.284348772147964e-06,
      "loss": 0.3041,
      "step": 6989
    },
    {
      "epoch": 0.5432079577245881,
      "grad_norm": 0.30950772762298584,
      "learning_rate": 7.28396021137706e-06,
      "loss": 0.1222,
      "step": 6990
    },
    {
      "epoch": 0.543285669878769,
      "grad_norm": 0.463556170463562,
      "learning_rate": 7.283571650606155e-06,
      "loss": 0.241,
      "step": 6991
    },
    {
      "epoch": 0.54336338203295,
      "grad_norm": 0.12714707851409912,
      "learning_rate": 7.283183089835251e-06,
      "loss": 0.0154,
      "step": 6992
    },
    {
      "epoch": 0.5434410941871308,
      "grad_norm": 0.5632147192955017,
      "learning_rate": 7.2827945290643465e-06,
      "loss": 0.1381,
      "step": 6993
    },
    {
      "epoch": 0.5435188063413118,
      "grad_norm": 0.16987445950508118,
      "learning_rate": 7.282405968293441e-06,
      "loss": 0.0647,
      "step": 6994
    },
    {
      "epoch": 0.5435965184954927,
      "grad_norm": 0.43241769075393677,
      "learning_rate": 7.282017407522537e-06,
      "loss": 0.0615,
      "step": 6995
    },
    {
      "epoch": 0.5436742306496736,
      "grad_norm": 0.9083300828933716,
      "learning_rate": 7.281628846751633e-06,
      "loss": 0.372,
      "step": 6996
    },
    {
      "epoch": 0.5437519428038545,
      "grad_norm": 0.44291213154792786,
      "learning_rate": 7.281240285980729e-06,
      "loss": 0.2164,
      "step": 6997
    },
    {
      "epoch": 0.5438296549580355,
      "grad_norm": 0.1623915284872055,
      "learning_rate": 7.280851725209823e-06,
      "loss": 0.0766,
      "step": 6998
    },
    {
      "epoch": 0.5439073671122163,
      "grad_norm": 5.65028715133667,
      "learning_rate": 7.280463164438919e-06,
      "loss": 3.3319,
      "step": 6999
    },
    {
      "epoch": 0.5439850792663973,
      "grad_norm": 0.10209880769252777,
      "learning_rate": 7.2800746036680145e-06,
      "loss": 0.0354,
      "step": 7000
    },
    {
      "epoch": 0.5440627914205782,
      "grad_norm": 0.03779303655028343,
      "learning_rate": 7.2796860428971095e-06,
      "loss": 0.0032,
      "step": 7001
    },
    {
      "epoch": 0.5441405035747591,
      "grad_norm": 0.24813294410705566,
      "learning_rate": 7.279297482126205e-06,
      "loss": 0.138,
      "step": 7002
    },
    {
      "epoch": 0.54421821572894,
      "grad_norm": 0.41834017634391785,
      "learning_rate": 7.278908921355301e-06,
      "loss": 0.1997,
      "step": 7003
    },
    {
      "epoch": 0.5442959278831209,
      "grad_norm": 0.2642455995082855,
      "learning_rate": 7.278520360584396e-06,
      "loss": 0.0314,
      "step": 7004
    },
    {
      "epoch": 0.5443736400373018,
      "grad_norm": 0.3462497293949127,
      "learning_rate": 7.278131799813492e-06,
      "loss": 0.2637,
      "step": 7005
    },
    {
      "epoch": 0.5444513521914828,
      "grad_norm": 0.17843562364578247,
      "learning_rate": 7.277743239042588e-06,
      "loss": 0.0705,
      "step": 7006
    },
    {
      "epoch": 0.5445290643456636,
      "grad_norm": 0.5151287913322449,
      "learning_rate": 7.277354678271682e-06,
      "loss": 0.0787,
      "step": 7007
    },
    {
      "epoch": 0.5446067764998446,
      "grad_norm": 0.18041573464870453,
      "learning_rate": 7.2769661175007775e-06,
      "loss": 0.0715,
      "step": 7008
    },
    {
      "epoch": 0.5446844886540255,
      "grad_norm": 0.6611024737358093,
      "learning_rate": 7.276577556729873e-06,
      "loss": 0.2243,
      "step": 7009
    },
    {
      "epoch": 0.5447622008082064,
      "grad_norm": 0.12061349302530289,
      "learning_rate": 7.276188995958968e-06,
      "loss": 0.0319,
      "step": 7010
    },
    {
      "epoch": 0.5448399129623873,
      "grad_norm": 0.32226237654685974,
      "learning_rate": 7.275800435188064e-06,
      "loss": 0.1761,
      "step": 7011
    },
    {
      "epoch": 0.5449176251165683,
      "grad_norm": 0.3702034652233124,
      "learning_rate": 7.27541187441716e-06,
      "loss": 0.1352,
      "step": 7012
    },
    {
      "epoch": 0.5449953372707491,
      "grad_norm": 0.3394857943058014,
      "learning_rate": 7.275023313646255e-06,
      "loss": 0.1813,
      "step": 7013
    },
    {
      "epoch": 0.5450730494249301,
      "grad_norm": 0.5744256973266602,
      "learning_rate": 7.274634752875351e-06,
      "loss": 0.4169,
      "step": 7014
    },
    {
      "epoch": 0.545150761579111,
      "grad_norm": 0.607558012008667,
      "learning_rate": 7.274246192104446e-06,
      "loss": 0.3879,
      "step": 7015
    },
    {
      "epoch": 0.5452284737332919,
      "grad_norm": 0.0678417980670929,
      "learning_rate": 7.2738576313335405e-06,
      "loss": 0.0252,
      "step": 7016
    },
    {
      "epoch": 0.5453061858874728,
      "grad_norm": 0.5974420309066772,
      "learning_rate": 7.273469070562636e-06,
      "loss": 0.5929,
      "step": 7017
    },
    {
      "epoch": 0.5453838980416538,
      "grad_norm": 0.4252608120441437,
      "learning_rate": 7.273080509791732e-06,
      "loss": 0.1376,
      "step": 7018
    },
    {
      "epoch": 0.5454616101958346,
      "grad_norm": 0.21509544551372528,
      "learning_rate": 7.272691949020827e-06,
      "loss": 0.1911,
      "step": 7019
    },
    {
      "epoch": 0.5455393223500156,
      "grad_norm": 0.5682011842727661,
      "learning_rate": 7.272303388249923e-06,
      "loss": 0.709,
      "step": 7020
    },
    {
      "epoch": 0.5456170345041964,
      "grad_norm": 0.5449355244636536,
      "learning_rate": 7.271914827479019e-06,
      "loss": 0.3082,
      "step": 7021
    },
    {
      "epoch": 0.5456947466583774,
      "grad_norm": 0.2847883999347687,
      "learning_rate": 7.2715262667081136e-06,
      "loss": 0.1633,
      "step": 7022
    },
    {
      "epoch": 0.5457724588125583,
      "grad_norm": 0.25917676091194153,
      "learning_rate": 7.271137705937209e-06,
      "loss": 0.0643,
      "step": 7023
    },
    {
      "epoch": 0.5458501709667392,
      "grad_norm": 0.12587065994739532,
      "learning_rate": 7.270749145166305e-06,
      "loss": 0.035,
      "step": 7024
    },
    {
      "epoch": 0.5459278831209201,
      "grad_norm": 0.3965522050857544,
      "learning_rate": 7.270360584395399e-06,
      "loss": 0.0995,
      "step": 7025
    },
    {
      "epoch": 0.5460055952751011,
      "grad_norm": 0.1696159541606903,
      "learning_rate": 7.269972023624495e-06,
      "loss": 0.0456,
      "step": 7026
    },
    {
      "epoch": 0.5460833074292819,
      "grad_norm": 0.20496952533721924,
      "learning_rate": 7.269583462853591e-06,
      "loss": 0.0756,
      "step": 7027
    },
    {
      "epoch": 0.5461610195834629,
      "grad_norm": 0.19699271023273468,
      "learning_rate": 7.269194902082687e-06,
      "loss": 0.0652,
      "step": 7028
    },
    {
      "epoch": 0.5462387317376438,
      "grad_norm": 0.5060766935348511,
      "learning_rate": 7.268806341311782e-06,
      "loss": 0.1862,
      "step": 7029
    },
    {
      "epoch": 0.5463164438918247,
      "grad_norm": 0.07402795553207397,
      "learning_rate": 7.268417780540877e-06,
      "loss": 0.0129,
      "step": 7030
    },
    {
      "epoch": 0.5463941560460056,
      "grad_norm": 0.7697686553001404,
      "learning_rate": 7.268029219769973e-06,
      "loss": 0.4374,
      "step": 7031
    },
    {
      "epoch": 0.5464718682001866,
      "grad_norm": 0.6492708921432495,
      "learning_rate": 7.267640658999068e-06,
      "loss": 0.1644,
      "step": 7032
    },
    {
      "epoch": 0.5465495803543674,
      "grad_norm": 0.4426305294036865,
      "learning_rate": 7.267252098228164e-06,
      "loss": 0.3768,
      "step": 7033
    },
    {
      "epoch": 0.5466272925085484,
      "grad_norm": 0.3698439598083496,
      "learning_rate": 7.26686353745726e-06,
      "loss": 0.2038,
      "step": 7034
    },
    {
      "epoch": 0.5467050046627292,
      "grad_norm": 0.05498431622982025,
      "learning_rate": 7.266474976686354e-06,
      "loss": 0.0129,
      "step": 7035
    },
    {
      "epoch": 0.5467827168169102,
      "grad_norm": 0.23330552875995636,
      "learning_rate": 7.26608641591545e-06,
      "loss": 0.0919,
      "step": 7036
    },
    {
      "epoch": 0.5468604289710911,
      "grad_norm": 0.36392807960510254,
      "learning_rate": 7.2656978551445454e-06,
      "loss": 0.0639,
      "step": 7037
    },
    {
      "epoch": 0.546938141125272,
      "grad_norm": 0.18023133277893066,
      "learning_rate": 7.26530929437364e-06,
      "loss": 0.0182,
      "step": 7038
    },
    {
      "epoch": 0.5470158532794529,
      "grad_norm": 0.9436032772064209,
      "learning_rate": 7.264920733602736e-06,
      "loss": 0.2151,
      "step": 7039
    },
    {
      "epoch": 0.5470935654336339,
      "grad_norm": 0.20641346275806427,
      "learning_rate": 7.264532172831832e-06,
      "loss": 0.0344,
      "step": 7040
    },
    {
      "epoch": 0.5471712775878147,
      "grad_norm": 0.0865122601389885,
      "learning_rate": 7.264143612060927e-06,
      "loss": 0.029,
      "step": 7041
    },
    {
      "epoch": 0.5472489897419957,
      "grad_norm": 0.8420761227607727,
      "learning_rate": 7.263755051290023e-06,
      "loss": 0.3638,
      "step": 7042
    },
    {
      "epoch": 0.5473267018961766,
      "grad_norm": 0.4181016683578491,
      "learning_rate": 7.2633664905191185e-06,
      "loss": 0.0988,
      "step": 7043
    },
    {
      "epoch": 0.5474044140503574,
      "grad_norm": 0.4704362750053406,
      "learning_rate": 7.262977929748213e-06,
      "loss": 0.1451,
      "step": 7044
    },
    {
      "epoch": 0.5474821262045384,
      "grad_norm": 0.09454566985368729,
      "learning_rate": 7.262589368977308e-06,
      "loss": 0.0375,
      "step": 7045
    },
    {
      "epoch": 0.5475598383587194,
      "grad_norm": 0.35847949981689453,
      "learning_rate": 7.262200808206404e-06,
      "loss": 0.107,
      "step": 7046
    },
    {
      "epoch": 0.5476375505129002,
      "grad_norm": 0.7492445707321167,
      "learning_rate": 7.261812247435499e-06,
      "loss": 0.5377,
      "step": 7047
    },
    {
      "epoch": 0.5477152626670811,
      "grad_norm": 0.35638394951820374,
      "learning_rate": 7.261423686664595e-06,
      "loss": 0.2793,
      "step": 7048
    },
    {
      "epoch": 0.547792974821262,
      "grad_norm": 0.37800970673561096,
      "learning_rate": 7.261035125893691e-06,
      "loss": 0.1274,
      "step": 7049
    },
    {
      "epoch": 0.5478706869754429,
      "grad_norm": 0.08787108957767487,
      "learning_rate": 7.260646565122786e-06,
      "loss": 0.0397,
      "step": 7050
    },
    {
      "epoch": 0.5479483991296239,
      "grad_norm": 1.0300711393356323,
      "learning_rate": 7.2602580043518815e-06,
      "loss": 0.5167,
      "step": 7051
    },
    {
      "epoch": 0.5480261112838047,
      "grad_norm": 0.2827364206314087,
      "learning_rate": 7.259869443580977e-06,
      "loss": 0.0834,
      "step": 7052
    },
    {
      "epoch": 0.5481038234379857,
      "grad_norm": 0.4352019429206848,
      "learning_rate": 7.259480882810071e-06,
      "loss": 0.2622,
      "step": 7053
    },
    {
      "epoch": 0.5481815355921666,
      "grad_norm": 0.2152174860239029,
      "learning_rate": 7.259092322039167e-06,
      "loss": 0.1065,
      "step": 7054
    },
    {
      "epoch": 0.5482592477463475,
      "grad_norm": 0.13420407474040985,
      "learning_rate": 7.258703761268263e-06,
      "loss": 0.0493,
      "step": 7055
    },
    {
      "epoch": 0.5483369599005284,
      "grad_norm": 0.14944064617156982,
      "learning_rate": 7.258315200497358e-06,
      "loss": 0.0602,
      "step": 7056
    },
    {
      "epoch": 0.5484146720547094,
      "grad_norm": 0.20722195506095886,
      "learning_rate": 7.257926639726454e-06,
      "loss": 0.0698,
      "step": 7057
    },
    {
      "epoch": 0.5484923842088902,
      "grad_norm": 0.9661616086959839,
      "learning_rate": 7.2575380789555495e-06,
      "loss": 0.4333,
      "step": 7058
    },
    {
      "epoch": 0.5485700963630712,
      "grad_norm": 0.5698450803756714,
      "learning_rate": 7.257149518184645e-06,
      "loss": 0.4308,
      "step": 7059
    },
    {
      "epoch": 0.5486478085172521,
      "grad_norm": 0.2938886880874634,
      "learning_rate": 7.25676095741374e-06,
      "loss": 0.1549,
      "step": 7060
    },
    {
      "epoch": 0.548725520671433,
      "grad_norm": 0.40970778465270996,
      "learning_rate": 7.256372396642835e-06,
      "loss": 0.1631,
      "step": 7061
    },
    {
      "epoch": 0.5488032328256139,
      "grad_norm": 0.6300449967384338,
      "learning_rate": 7.255983835871931e-06,
      "loss": 0.2252,
      "step": 7062
    },
    {
      "epoch": 0.5488809449797949,
      "grad_norm": 0.15489156544208527,
      "learning_rate": 7.255595275101026e-06,
      "loss": 0.0326,
      "step": 7063
    },
    {
      "epoch": 0.5489586571339757,
      "grad_norm": 0.410880446434021,
      "learning_rate": 7.255206714330122e-06,
      "loss": 0.3511,
      "step": 7064
    },
    {
      "epoch": 0.5490363692881567,
      "grad_norm": 0.46046558022499084,
      "learning_rate": 7.254818153559218e-06,
      "loss": 0.2678,
      "step": 7065
    },
    {
      "epoch": 0.5491140814423375,
      "grad_norm": 0.7022287845611572,
      "learning_rate": 7.2544295927883125e-06,
      "loss": 0.1055,
      "step": 7066
    },
    {
      "epoch": 0.5491917935965185,
      "grad_norm": 0.5713797211647034,
      "learning_rate": 7.254041032017408e-06,
      "loss": 0.1567,
      "step": 7067
    },
    {
      "epoch": 0.5492695057506994,
      "grad_norm": 0.4423206150531769,
      "learning_rate": 7.253652471246504e-06,
      "loss": 0.1257,
      "step": 7068
    },
    {
      "epoch": 0.5493472179048803,
      "grad_norm": 0.2288631796836853,
      "learning_rate": 7.253263910475598e-06,
      "loss": 0.1161,
      "step": 7069
    },
    {
      "epoch": 0.5494249300590612,
      "grad_norm": 0.27357760071754456,
      "learning_rate": 7.252875349704694e-06,
      "loss": 0.0757,
      "step": 7070
    },
    {
      "epoch": 0.5495026422132422,
      "grad_norm": 1.128594994544983,
      "learning_rate": 7.25248678893379e-06,
      "loss": 0.6815,
      "step": 7071
    },
    {
      "epoch": 0.549580354367423,
      "grad_norm": 0.48794451355934143,
      "learning_rate": 7.252098228162885e-06,
      "loss": 0.2885,
      "step": 7072
    },
    {
      "epoch": 0.549658066521604,
      "grad_norm": 0.5446709990501404,
      "learning_rate": 7.2517096673919806e-06,
      "loss": 0.1929,
      "step": 7073
    },
    {
      "epoch": 0.5497357786757849,
      "grad_norm": 0.2135123461484909,
      "learning_rate": 7.251321106621076e-06,
      "loss": 0.0775,
      "step": 7074
    },
    {
      "epoch": 0.5498134908299658,
      "grad_norm": 0.30692532658576965,
      "learning_rate": 7.250932545850171e-06,
      "loss": 0.2207,
      "step": 7075
    },
    {
      "epoch": 0.5498912029841467,
      "grad_norm": 0.788287878036499,
      "learning_rate": 7.250543985079267e-06,
      "loss": 0.3718,
      "step": 7076
    },
    {
      "epoch": 0.5499689151383277,
      "grad_norm": 0.7899959087371826,
      "learning_rate": 7.250155424308363e-06,
      "loss": 0.2277,
      "step": 7077
    },
    {
      "epoch": 0.5500466272925085,
      "grad_norm": 0.3922528922557831,
      "learning_rate": 7.249766863537457e-06,
      "loss": 0.228,
      "step": 7078
    },
    {
      "epoch": 0.5501243394466895,
      "grad_norm": 0.2583710849285126,
      "learning_rate": 7.249378302766553e-06,
      "loss": 0.1585,
      "step": 7079
    },
    {
      "epoch": 0.5502020516008703,
      "grad_norm": 0.11628863215446472,
      "learning_rate": 7.248989741995649e-06,
      "loss": 0.0321,
      "step": 7080
    },
    {
      "epoch": 0.5502797637550513,
      "grad_norm": 0.1476331502199173,
      "learning_rate": 7.2486011812247436e-06,
      "loss": 0.1143,
      "step": 7081
    },
    {
      "epoch": 0.5503574759092322,
      "grad_norm": 0.3724815845489502,
      "learning_rate": 7.248212620453839e-06,
      "loss": 0.1284,
      "step": 7082
    },
    {
      "epoch": 0.5504351880634131,
      "grad_norm": 0.5311188101768494,
      "learning_rate": 7.247824059682935e-06,
      "loss": 0.4245,
      "step": 7083
    },
    {
      "epoch": 0.550512900217594,
      "grad_norm": 0.17346756160259247,
      "learning_rate": 7.24743549891203e-06,
      "loss": 0.0585,
      "step": 7084
    },
    {
      "epoch": 0.550590612371775,
      "grad_norm": 0.42747777700424194,
      "learning_rate": 7.247046938141126e-06,
      "loss": 0.1812,
      "step": 7085
    },
    {
      "epoch": 0.5506683245259558,
      "grad_norm": 0.2854164242744446,
      "learning_rate": 7.246658377370222e-06,
      "loss": 0.0648,
      "step": 7086
    },
    {
      "epoch": 0.5507460366801368,
      "grad_norm": 0.42556726932525635,
      "learning_rate": 7.2462698165993175e-06,
      "loss": 0.1448,
      "step": 7087
    },
    {
      "epoch": 0.5508237488343177,
      "grad_norm": 0.3059687316417694,
      "learning_rate": 7.245881255828412e-06,
      "loss": 0.1746,
      "step": 7088
    },
    {
      "epoch": 0.5509014609884986,
      "grad_norm": 0.9675037264823914,
      "learning_rate": 7.245492695057507e-06,
      "loss": 0.2176,
      "step": 7089
    },
    {
      "epoch": 0.5509791731426795,
      "grad_norm": 0.8797789216041565,
      "learning_rate": 7.245104134286603e-06,
      "loss": 0.4008,
      "step": 7090
    },
    {
      "epoch": 0.5510568852968605,
      "grad_norm": 0.6262030005455017,
      "learning_rate": 7.244715573515698e-06,
      "loss": 0.3358,
      "step": 7091
    },
    {
      "epoch": 0.5511345974510413,
      "grad_norm": 0.3009653389453888,
      "learning_rate": 7.244327012744794e-06,
      "loss": 0.0866,
      "step": 7092
    },
    {
      "epoch": 0.5512123096052223,
      "grad_norm": 0.1359880417585373,
      "learning_rate": 7.24393845197389e-06,
      "loss": 0.0554,
      "step": 7093
    },
    {
      "epoch": 0.5512900217594032,
      "grad_norm": 0.37136656045913696,
      "learning_rate": 7.243549891202985e-06,
      "loss": 0.3084,
      "step": 7094
    },
    {
      "epoch": 0.5513677339135841,
      "grad_norm": 0.1993662714958191,
      "learning_rate": 7.2431613304320805e-06,
      "loss": 0.0175,
      "step": 7095
    },
    {
      "epoch": 0.551445446067765,
      "grad_norm": 0.1737043559551239,
      "learning_rate": 7.242772769661176e-06,
      "loss": 0.0412,
      "step": 7096
    },
    {
      "epoch": 0.5515231582219459,
      "grad_norm": 0.23141880333423615,
      "learning_rate": 7.24238420889027e-06,
      "loss": 0.0994,
      "step": 7097
    },
    {
      "epoch": 0.5516008703761268,
      "grad_norm": 0.42001858353614807,
      "learning_rate": 7.241995648119366e-06,
      "loss": 0.1783,
      "step": 7098
    },
    {
      "epoch": 0.5516785825303078,
      "grad_norm": 0.7538197636604309,
      "learning_rate": 7.241607087348462e-06,
      "loss": 0.2172,
      "step": 7099
    },
    {
      "epoch": 0.5517562946844886,
      "grad_norm": 0.22124353051185608,
      "learning_rate": 7.241218526577557e-06,
      "loss": 0.1096,
      "step": 7100
    },
    {
      "epoch": 0.5518340068386696,
      "grad_norm": 0.32833385467529297,
      "learning_rate": 7.240829965806653e-06,
      "loss": 0.3659,
      "step": 7101
    },
    {
      "epoch": 0.5519117189928505,
      "grad_norm": 0.6678447127342224,
      "learning_rate": 7.2404414050357485e-06,
      "loss": 0.1056,
      "step": 7102
    },
    {
      "epoch": 0.5519894311470314,
      "grad_norm": 0.2917563319206238,
      "learning_rate": 7.2400528442648435e-06,
      "loss": 0.2502,
      "step": 7103
    },
    {
      "epoch": 0.5520671433012123,
      "grad_norm": 0.635254442691803,
      "learning_rate": 7.239664283493939e-06,
      "loss": 0.2339,
      "step": 7104
    },
    {
      "epoch": 0.5521448554553933,
      "grad_norm": 0.29995617270469666,
      "learning_rate": 7.239275722723035e-06,
      "loss": 0.1023,
      "step": 7105
    },
    {
      "epoch": 0.5522225676095741,
      "grad_norm": 0.23470258712768555,
      "learning_rate": 7.238887161952129e-06,
      "loss": 0.0812,
      "step": 7106
    },
    {
      "epoch": 0.5523002797637551,
      "grad_norm": 0.2613818049430847,
      "learning_rate": 7.238498601181225e-06,
      "loss": 0.1068,
      "step": 7107
    },
    {
      "epoch": 0.552377991917936,
      "grad_norm": 0.2688189744949341,
      "learning_rate": 7.238110040410321e-06,
      "loss": 0.1134,
      "step": 7108
    },
    {
      "epoch": 0.5524557040721169,
      "grad_norm": 0.24970832467079163,
      "learning_rate": 7.237721479639416e-06,
      "loss": 0.1557,
      "step": 7109
    },
    {
      "epoch": 0.5525334162262978,
      "grad_norm": 0.37620437145233154,
      "learning_rate": 7.2373329188685115e-06,
      "loss": 0.1736,
      "step": 7110
    },
    {
      "epoch": 0.5526111283804787,
      "grad_norm": 0.5129480957984924,
      "learning_rate": 7.236944358097607e-06,
      "loss": 0.2065,
      "step": 7111
    },
    {
      "epoch": 0.5526888405346596,
      "grad_norm": 0.08093059808015823,
      "learning_rate": 7.236555797326702e-06,
      "loss": 0.0248,
      "step": 7112
    },
    {
      "epoch": 0.5527665526888406,
      "grad_norm": 0.4410537779331207,
      "learning_rate": 7.236167236555798e-06,
      "loss": 0.0894,
      "step": 7113
    },
    {
      "epoch": 0.5528442648430214,
      "grad_norm": 0.37542077898979187,
      "learning_rate": 7.235778675784894e-06,
      "loss": 0.1044,
      "step": 7114
    },
    {
      "epoch": 0.5529219769972024,
      "grad_norm": 0.27490925788879395,
      "learning_rate": 7.235390115013988e-06,
      "loss": 0.0819,
      "step": 7115
    },
    {
      "epoch": 0.5529996891513833,
      "grad_norm": 0.2878013551235199,
      "learning_rate": 7.235001554243084e-06,
      "loss": 0.121,
      "step": 7116
    },
    {
      "epoch": 0.5530774013055642,
      "grad_norm": 1.411228895187378,
      "learning_rate": 7.2346129934721795e-06,
      "loss": 0.3198,
      "step": 7117
    },
    {
      "epoch": 0.5531551134597451,
      "grad_norm": 0.7042560577392578,
      "learning_rate": 7.234224432701275e-06,
      "loss": 0.1514,
      "step": 7118
    },
    {
      "epoch": 0.5532328256139261,
      "grad_norm": 0.11426323652267456,
      "learning_rate": 7.23383587193037e-06,
      "loss": 0.032,
      "step": 7119
    },
    {
      "epoch": 0.5533105377681069,
      "grad_norm": 0.20021232962608337,
      "learning_rate": 7.233447311159466e-06,
      "loss": 0.0689,
      "step": 7120
    },
    {
      "epoch": 0.5533882499222879,
      "grad_norm": 0.385360985994339,
      "learning_rate": 7.233058750388562e-06,
      "loss": 0.1228,
      "step": 7121
    },
    {
      "epoch": 0.5534659620764688,
      "grad_norm": 0.5680996775627136,
      "learning_rate": 7.232670189617657e-06,
      "loss": 0.2356,
      "step": 7122
    },
    {
      "epoch": 0.5535436742306497,
      "grad_norm": 0.2178570032119751,
      "learning_rate": 7.232281628846753e-06,
      "loss": 0.0474,
      "step": 7123
    },
    {
      "epoch": 0.5536213863848306,
      "grad_norm": 0.10990578681230545,
      "learning_rate": 7.231893068075848e-06,
      "loss": 0.0077,
      "step": 7124
    },
    {
      "epoch": 0.5536990985390114,
      "grad_norm": 0.18750788271427155,
      "learning_rate": 7.2315045073049425e-06,
      "loss": 0.0658,
      "step": 7125
    },
    {
      "epoch": 0.5537768106931924,
      "grad_norm": 0.3625132739543915,
      "learning_rate": 7.231115946534038e-06,
      "loss": 0.1593,
      "step": 7126
    },
    {
      "epoch": 0.5538545228473734,
      "grad_norm": 0.16308562457561493,
      "learning_rate": 7.230727385763134e-06,
      "loss": 0.047,
      "step": 7127
    },
    {
      "epoch": 0.5539322350015542,
      "grad_norm": 0.43370357155799866,
      "learning_rate": 7.230338824992229e-06,
      "loss": 0.1157,
      "step": 7128
    },
    {
      "epoch": 0.5540099471557351,
      "grad_norm": 0.4176398813724518,
      "learning_rate": 7.229950264221325e-06,
      "loss": 0.1284,
      "step": 7129
    },
    {
      "epoch": 0.5540876593099161,
      "grad_norm": 0.40019574761390686,
      "learning_rate": 7.229561703450421e-06,
      "loss": 0.1037,
      "step": 7130
    },
    {
      "epoch": 0.554165371464097,
      "grad_norm": 0.26545462012290955,
      "learning_rate": 7.229173142679516e-06,
      "loss": 0.1244,
      "step": 7131
    },
    {
      "epoch": 0.5542430836182779,
      "grad_norm": 0.11456345021724701,
      "learning_rate": 7.228784581908611e-06,
      "loss": 0.0235,
      "step": 7132
    },
    {
      "epoch": 0.5543207957724589,
      "grad_norm": 0.4389793872833252,
      "learning_rate": 7.228396021137707e-06,
      "loss": 0.224,
      "step": 7133
    },
    {
      "epoch": 0.5543985079266397,
      "grad_norm": 0.39401865005493164,
      "learning_rate": 7.228007460366801e-06,
      "loss": 0.1335,
      "step": 7134
    },
    {
      "epoch": 0.5544762200808206,
      "grad_norm": 0.0761992484331131,
      "learning_rate": 7.227618899595897e-06,
      "loss": 0.0239,
      "step": 7135
    },
    {
      "epoch": 0.5545539322350016,
      "grad_norm": 0.3111443817615509,
      "learning_rate": 7.227230338824993e-06,
      "loss": 0.1827,
      "step": 7136
    },
    {
      "epoch": 0.5546316443891824,
      "grad_norm": 0.0789460837841034,
      "learning_rate": 7.226841778054088e-06,
      "loss": 0.0183,
      "step": 7137
    },
    {
      "epoch": 0.5547093565433634,
      "grad_norm": 0.5829523205757141,
      "learning_rate": 7.226453217283184e-06,
      "loss": 0.178,
      "step": 7138
    },
    {
      "epoch": 0.5547870686975443,
      "grad_norm": 0.22985443472862244,
      "learning_rate": 7.2260646565122794e-06,
      "loss": 0.0318,
      "step": 7139
    },
    {
      "epoch": 0.5548647808517252,
      "grad_norm": 0.5737124085426331,
      "learning_rate": 7.225676095741374e-06,
      "loss": 0.1497,
      "step": 7140
    },
    {
      "epoch": 0.5549424930059061,
      "grad_norm": 0.2461218237876892,
      "learning_rate": 7.22528753497047e-06,
      "loss": 0.0943,
      "step": 7141
    },
    {
      "epoch": 0.555020205160087,
      "grad_norm": 0.2198648899793625,
      "learning_rate": 7.224898974199566e-06,
      "loss": 0.0883,
      "step": 7142
    },
    {
      "epoch": 0.5550979173142679,
      "grad_norm": 0.26161178946495056,
      "learning_rate": 7.22451041342866e-06,
      "loss": 0.0534,
      "step": 7143
    },
    {
      "epoch": 0.5551756294684489,
      "grad_norm": 0.5067847967147827,
      "learning_rate": 7.224121852657756e-06,
      "loss": 0.5222,
      "step": 7144
    },
    {
      "epoch": 0.5552533416226297,
      "grad_norm": 0.46027639508247375,
      "learning_rate": 7.223733291886852e-06,
      "loss": 0.203,
      "step": 7145
    },
    {
      "epoch": 0.5553310537768107,
      "grad_norm": 0.3657090365886688,
      "learning_rate": 7.223344731115947e-06,
      "loss": 0.3575,
      "step": 7146
    },
    {
      "epoch": 0.5554087659309916,
      "grad_norm": 0.15874850749969482,
      "learning_rate": 7.2229561703450424e-06,
      "loss": 0.0346,
      "step": 7147
    },
    {
      "epoch": 0.5554864780851725,
      "grad_norm": 0.21173863112926483,
      "learning_rate": 7.222567609574138e-06,
      "loss": 0.0318,
      "step": 7148
    },
    {
      "epoch": 0.5555641902393534,
      "grad_norm": 0.24137382209300995,
      "learning_rate": 7.222179048803234e-06,
      "loss": 0.0884,
      "step": 7149
    },
    {
      "epoch": 0.5556419023935344,
      "grad_norm": 0.7759358882904053,
      "learning_rate": 7.221790488032329e-06,
      "loss": 0.5489,
      "step": 7150
    },
    {
      "epoch": 0.5557196145477152,
      "grad_norm": 0.22249983251094818,
      "learning_rate": 7.221401927261425e-06,
      "loss": 0.1376,
      "step": 7151
    },
    {
      "epoch": 0.5557973267018962,
      "grad_norm": 0.39138489961624146,
      "learning_rate": 7.2210133664905206e-06,
      "loss": 0.3159,
      "step": 7152
    },
    {
      "epoch": 0.5558750388560771,
      "grad_norm": 0.6289116740226746,
      "learning_rate": 7.220624805719615e-06,
      "loss": 0.7104,
      "step": 7153
    },
    {
      "epoch": 0.555952751010258,
      "grad_norm": 1.3363641500473022,
      "learning_rate": 7.2202362449487105e-06,
      "loss": 0.306,
      "step": 7154
    },
    {
      "epoch": 0.5560304631644389,
      "grad_norm": 0.20785705745220184,
      "learning_rate": 7.219847684177806e-06,
      "loss": 0.0656,
      "step": 7155
    },
    {
      "epoch": 0.5561081753186198,
      "grad_norm": 0.34395861625671387,
      "learning_rate": 7.219459123406901e-06,
      "loss": 0.1149,
      "step": 7156
    },
    {
      "epoch": 0.5561858874728007,
      "grad_norm": 0.625123918056488,
      "learning_rate": 7.219070562635997e-06,
      "loss": 0.2688,
      "step": 7157
    },
    {
      "epoch": 0.5562635996269817,
      "grad_norm": 0.22317321598529816,
      "learning_rate": 7.218682001865093e-06,
      "loss": 0.0442,
      "step": 7158
    },
    {
      "epoch": 0.5563413117811625,
      "grad_norm": 0.5334790349006653,
      "learning_rate": 7.218293441094188e-06,
      "loss": 0.7014,
      "step": 7159
    },
    {
      "epoch": 0.5564190239353435,
      "grad_norm": 0.328377366065979,
      "learning_rate": 7.2179048803232836e-06,
      "loss": 0.162,
      "step": 7160
    },
    {
      "epoch": 0.5564967360895244,
      "grad_norm": 0.20603728294372559,
      "learning_rate": 7.217516319552379e-06,
      "loss": 0.1035,
      "step": 7161
    },
    {
      "epoch": 0.5565744482437053,
      "grad_norm": 0.20920966565608978,
      "learning_rate": 7.2171277587814735e-06,
      "loss": 0.0357,
      "step": 7162
    },
    {
      "epoch": 0.5566521603978862,
      "grad_norm": 0.31459498405456543,
      "learning_rate": 7.216739198010569e-06,
      "loss": 0.0905,
      "step": 7163
    },
    {
      "epoch": 0.5567298725520672,
      "grad_norm": 0.3254846930503845,
      "learning_rate": 7.216350637239665e-06,
      "loss": 0.091,
      "step": 7164
    },
    {
      "epoch": 0.556807584706248,
      "grad_norm": 0.10303539037704468,
      "learning_rate": 7.21596207646876e-06,
      "loss": 0.0376,
      "step": 7165
    },
    {
      "epoch": 0.556885296860429,
      "grad_norm": 0.254355251789093,
      "learning_rate": 7.215573515697856e-06,
      "loss": 0.101,
      "step": 7166
    },
    {
      "epoch": 0.5569630090146099,
      "grad_norm": 0.49343881011009216,
      "learning_rate": 7.215184954926952e-06,
      "loss": 0.2611,
      "step": 7167
    },
    {
      "epoch": 0.5570407211687908,
      "grad_norm": 0.31764188408851624,
      "learning_rate": 7.2147963941560465e-06,
      "loss": 0.2051,
      "step": 7168
    },
    {
      "epoch": 0.5571184333229717,
      "grad_norm": 0.3838057816028595,
      "learning_rate": 7.214407833385142e-06,
      "loss": 0.1748,
      "step": 7169
    },
    {
      "epoch": 0.5571961454771526,
      "grad_norm": 0.1997896283864975,
      "learning_rate": 7.214019272614238e-06,
      "loss": 0.0834,
      "step": 7170
    },
    {
      "epoch": 0.5572738576313335,
      "grad_norm": 0.23099303245544434,
      "learning_rate": 7.213630711843332e-06,
      "loss": 0.0169,
      "step": 7171
    },
    {
      "epoch": 0.5573515697855145,
      "grad_norm": 0.42280521988868713,
      "learning_rate": 7.213242151072428e-06,
      "loss": 0.0722,
      "step": 7172
    },
    {
      "epoch": 0.5574292819396953,
      "grad_norm": 0.1850009709596634,
      "learning_rate": 7.212853590301524e-06,
      "loss": 0.0293,
      "step": 7173
    },
    {
      "epoch": 0.5575069940938763,
      "grad_norm": 0.3284628689289093,
      "learning_rate": 7.212465029530619e-06,
      "loss": 0.1007,
      "step": 7174
    },
    {
      "epoch": 0.5575847062480572,
      "grad_norm": 0.11881164461374283,
      "learning_rate": 7.2120764687597146e-06,
      "loss": 0.0214,
      "step": 7175
    },
    {
      "epoch": 0.5576624184022381,
      "grad_norm": 0.44747689366340637,
      "learning_rate": 7.21168790798881e-06,
      "loss": 0.2195,
      "step": 7176
    },
    {
      "epoch": 0.557740130556419,
      "grad_norm": 0.3817405104637146,
      "learning_rate": 7.211299347217905e-06,
      "loss": 0.245,
      "step": 7177
    },
    {
      "epoch": 0.5578178427106,
      "grad_norm": 0.4550885558128357,
      "learning_rate": 7.210910786447001e-06,
      "loss": 0.2906,
      "step": 7178
    },
    {
      "epoch": 0.5578955548647808,
      "grad_norm": 0.42386502027511597,
      "learning_rate": 7.210522225676097e-06,
      "loss": 0.3945,
      "step": 7179
    },
    {
      "epoch": 0.5579732670189618,
      "grad_norm": 0.18203172087669373,
      "learning_rate": 7.210133664905192e-06,
      "loss": 0.0623,
      "step": 7180
    },
    {
      "epoch": 0.5580509791731427,
      "grad_norm": 0.3477751910686493,
      "learning_rate": 7.209745104134287e-06,
      "loss": 0.1212,
      "step": 7181
    },
    {
      "epoch": 0.5581286913273236,
      "grad_norm": 0.13092732429504395,
      "learning_rate": 7.209356543363383e-06,
      "loss": 0.0154,
      "step": 7182
    },
    {
      "epoch": 0.5582064034815045,
      "grad_norm": 0.09441793709993362,
      "learning_rate": 7.208967982592478e-06,
      "loss": 0.0186,
      "step": 7183
    },
    {
      "epoch": 0.5582841156356855,
      "grad_norm": 0.35217487812042236,
      "learning_rate": 7.208579421821573e-06,
      "loss": 0.3244,
      "step": 7184
    },
    {
      "epoch": 0.5583618277898663,
      "grad_norm": 0.3787034749984741,
      "learning_rate": 7.208190861050669e-06,
      "loss": 0.1375,
      "step": 7185
    },
    {
      "epoch": 0.5584395399440473,
      "grad_norm": 0.07455563545227051,
      "learning_rate": 7.207802300279765e-06,
      "loss": 0.0063,
      "step": 7186
    },
    {
      "epoch": 0.5585172520982281,
      "grad_norm": 0.3260959982872009,
      "learning_rate": 7.207413739508859e-06,
      "loss": 0.1341,
      "step": 7187
    },
    {
      "epoch": 0.5585949642524091,
      "grad_norm": 0.504746675491333,
      "learning_rate": 7.207025178737955e-06,
      "loss": 0.0648,
      "step": 7188
    },
    {
      "epoch": 0.55867267640659,
      "grad_norm": 0.4244966506958008,
      "learning_rate": 7.206636617967051e-06,
      "loss": 0.1594,
      "step": 7189
    },
    {
      "epoch": 0.5587503885607709,
      "grad_norm": 0.20600272715091705,
      "learning_rate": 7.206248057196146e-06,
      "loss": 0.3006,
      "step": 7190
    },
    {
      "epoch": 0.5588281007149518,
      "grad_norm": 0.5081924796104431,
      "learning_rate": 7.205859496425241e-06,
      "loss": 0.0966,
      "step": 7191
    },
    {
      "epoch": 0.5589058128691328,
      "grad_norm": 0.1608932912349701,
      "learning_rate": 7.205470935654337e-06,
      "loss": 0.0877,
      "step": 7192
    },
    {
      "epoch": 0.5589835250233136,
      "grad_norm": 0.3232584595680237,
      "learning_rate": 7.205082374883432e-06,
      "loss": 0.2023,
      "step": 7193
    },
    {
      "epoch": 0.5590612371774946,
      "grad_norm": 0.34934139251708984,
      "learning_rate": 7.204693814112528e-06,
      "loss": 0.2144,
      "step": 7194
    },
    {
      "epoch": 0.5591389493316755,
      "grad_norm": 0.16442035138607025,
      "learning_rate": 7.204305253341624e-06,
      "loss": 0.0283,
      "step": 7195
    },
    {
      "epoch": 0.5592166614858564,
      "grad_norm": 0.19363467395305634,
      "learning_rate": 7.203916692570718e-06,
      "loss": 0.0549,
      "step": 7196
    },
    {
      "epoch": 0.5592943736400373,
      "grad_norm": 0.28806939721107483,
      "learning_rate": 7.203528131799814e-06,
      "loss": 0.3883,
      "step": 7197
    },
    {
      "epoch": 0.5593720857942183,
      "grad_norm": 0.5009509921073914,
      "learning_rate": 7.2031395710289094e-06,
      "loss": 0.3804,
      "step": 7198
    },
    {
      "epoch": 0.5594497979483991,
      "grad_norm": 0.4232593774795532,
      "learning_rate": 7.202751010258004e-06,
      "loss": 0.1758,
      "step": 7199
    },
    {
      "epoch": 0.5595275101025801,
      "grad_norm": 0.1515694409608841,
      "learning_rate": 7.2023624494871e-06,
      "loss": 0.0267,
      "step": 7200
    },
    {
      "epoch": 0.5596052222567609,
      "grad_norm": 0.2161010503768921,
      "learning_rate": 7.201973888716196e-06,
      "loss": 0.1087,
      "step": 7201
    },
    {
      "epoch": 0.5596829344109419,
      "grad_norm": 0.24789583683013916,
      "learning_rate": 7.201585327945291e-06,
      "loss": 0.0336,
      "step": 7202
    },
    {
      "epoch": 0.5597606465651228,
      "grad_norm": 0.09272947907447815,
      "learning_rate": 7.201196767174387e-06,
      "loss": 0.0165,
      "step": 7203
    },
    {
      "epoch": 0.5598383587193037,
      "grad_norm": 0.40019679069519043,
      "learning_rate": 7.2008082064034825e-06,
      "loss": 0.3209,
      "step": 7204
    },
    {
      "epoch": 0.5599160708734846,
      "grad_norm": 0.5540245771408081,
      "learning_rate": 7.200419645632577e-06,
      "loss": 0.5093,
      "step": 7205
    },
    {
      "epoch": 0.5599937830276656,
      "grad_norm": 0.2553774118423462,
      "learning_rate": 7.200031084861672e-06,
      "loss": 0.0818,
      "step": 7206
    },
    {
      "epoch": 0.5600714951818464,
      "grad_norm": 0.16945672035217285,
      "learning_rate": 7.199642524090768e-06,
      "loss": 0.241,
      "step": 7207
    },
    {
      "epoch": 0.5601492073360274,
      "grad_norm": 0.19419224560260773,
      "learning_rate": 7.199253963319864e-06,
      "loss": 0.0679,
      "step": 7208
    },
    {
      "epoch": 0.5602269194902083,
      "grad_norm": 0.7374812960624695,
      "learning_rate": 7.198865402548959e-06,
      "loss": 0.3166,
      "step": 7209
    },
    {
      "epoch": 0.5603046316443892,
      "grad_norm": 1.062538504600525,
      "learning_rate": 7.198476841778055e-06,
      "loss": 0.5116,
      "step": 7210
    },
    {
      "epoch": 0.5603823437985701,
      "grad_norm": 0.1182800829410553,
      "learning_rate": 7.1980882810071506e-06,
      "loss": 0.0416,
      "step": 7211
    },
    {
      "epoch": 0.5604600559527511,
      "grad_norm": 0.28835931420326233,
      "learning_rate": 7.1976997202362455e-06,
      "loss": 0.1674,
      "step": 7212
    },
    {
      "epoch": 0.5605377681069319,
      "grad_norm": 0.792715311050415,
      "learning_rate": 7.197311159465341e-06,
      "loss": 0.0869,
      "step": 7213
    },
    {
      "epoch": 0.5606154802611129,
      "grad_norm": 0.6080609560012817,
      "learning_rate": 7.196922598694437e-06,
      "loss": 0.2558,
      "step": 7214
    },
    {
      "epoch": 0.5606931924152938,
      "grad_norm": 0.2918677031993866,
      "learning_rate": 7.196534037923531e-06,
      "loss": 0.1275,
      "step": 7215
    },
    {
      "epoch": 0.5607709045694746,
      "grad_norm": 0.15999026596546173,
      "learning_rate": 7.196145477152627e-06,
      "loss": 0.0389,
      "step": 7216
    },
    {
      "epoch": 0.5608486167236556,
      "grad_norm": 0.2574193775653839,
      "learning_rate": 7.195756916381723e-06,
      "loss": 0.0351,
      "step": 7217
    },
    {
      "epoch": 0.5609263288778364,
      "grad_norm": 0.4734918475151062,
      "learning_rate": 7.195368355610818e-06,
      "loss": 0.2598,
      "step": 7218
    },
    {
      "epoch": 0.5610040410320174,
      "grad_norm": 0.22220179438591003,
      "learning_rate": 7.1949797948399135e-06,
      "loss": 0.0911,
      "step": 7219
    },
    {
      "epoch": 0.5610817531861984,
      "grad_norm": 0.3580760359764099,
      "learning_rate": 7.194591234069009e-06,
      "loss": 0.1034,
      "step": 7220
    },
    {
      "epoch": 0.5611594653403792,
      "grad_norm": 0.6265295147895813,
      "learning_rate": 7.194202673298104e-06,
      "loss": 0.1789,
      "step": 7221
    },
    {
      "epoch": 0.5612371774945601,
      "grad_norm": 0.5693360567092896,
      "learning_rate": 7.1938141125272e-06,
      "loss": 0.364,
      "step": 7222
    },
    {
      "epoch": 0.5613148896487411,
      "grad_norm": 0.4652003347873688,
      "learning_rate": 7.193425551756296e-06,
      "loss": 0.2229,
      "step": 7223
    },
    {
      "epoch": 0.5613926018029219,
      "grad_norm": 0.6939723491668701,
      "learning_rate": 7.19303699098539e-06,
      "loss": 0.8182,
      "step": 7224
    },
    {
      "epoch": 0.5614703139571029,
      "grad_norm": 0.6070755124092102,
      "learning_rate": 7.192648430214486e-06,
      "loss": 0.5434,
      "step": 7225
    },
    {
      "epoch": 0.5615480261112838,
      "grad_norm": 0.28010648488998413,
      "learning_rate": 7.192259869443582e-06,
      "loss": 0.1406,
      "step": 7226
    },
    {
      "epoch": 0.5616257382654647,
      "grad_norm": 0.203372985124588,
      "learning_rate": 7.1918713086726765e-06,
      "loss": 0.1003,
      "step": 7227
    },
    {
      "epoch": 0.5617034504196456,
      "grad_norm": 0.4910001754760742,
      "learning_rate": 7.191482747901772e-06,
      "loss": 0.2327,
      "step": 7228
    },
    {
      "epoch": 0.5617811625738266,
      "grad_norm": 0.26013419032096863,
      "learning_rate": 7.191094187130868e-06,
      "loss": 0.1337,
      "step": 7229
    },
    {
      "epoch": 0.5618588747280074,
      "grad_norm": 0.339790940284729,
      "learning_rate": 7.190705626359963e-06,
      "loss": 0.1131,
      "step": 7230
    },
    {
      "epoch": 0.5619365868821884,
      "grad_norm": 0.5180672407150269,
      "learning_rate": 7.190317065589059e-06,
      "loss": 0.3522,
      "step": 7231
    },
    {
      "epoch": 0.5620142990363692,
      "grad_norm": 0.23386046290397644,
      "learning_rate": 7.189928504818155e-06,
      "loss": 0.1026,
      "step": 7232
    },
    {
      "epoch": 0.5620920111905502,
      "grad_norm": 0.4160189926624298,
      "learning_rate": 7.189539944047249e-06,
      "loss": 0.2222,
      "step": 7233
    },
    {
      "epoch": 0.5621697233447311,
      "grad_norm": 0.4551791548728943,
      "learning_rate": 7.1891513832763446e-06,
      "loss": 0.1288,
      "step": 7234
    },
    {
      "epoch": 0.562247435498912,
      "grad_norm": 0.7355037927627563,
      "learning_rate": 7.18876282250544e-06,
      "loss": 0.3023,
      "step": 7235
    },
    {
      "epoch": 0.5623251476530929,
      "grad_norm": 0.1249561533331871,
      "learning_rate": 7.188374261734535e-06,
      "loss": 0.0107,
      "step": 7236
    },
    {
      "epoch": 0.5624028598072739,
      "grad_norm": 0.2028624564409256,
      "learning_rate": 7.187985700963631e-06,
      "loss": 0.0881,
      "step": 7237
    },
    {
      "epoch": 0.5624805719614547,
      "grad_norm": 0.12678056955337524,
      "learning_rate": 7.187597140192727e-06,
      "loss": 0.026,
      "step": 7238
    },
    {
      "epoch": 0.5625582841156357,
      "grad_norm": 0.3652637004852295,
      "learning_rate": 7.187208579421823e-06,
      "loss": 0.1878,
      "step": 7239
    },
    {
      "epoch": 0.5626359962698166,
      "grad_norm": 1.0480924844741821,
      "learning_rate": 7.186820018650918e-06,
      "loss": 0.4675,
      "step": 7240
    },
    {
      "epoch": 0.5627137084239975,
      "grad_norm": 0.47261494398117065,
      "learning_rate": 7.1864314578800134e-06,
      "loss": 0.2696,
      "step": 7241
    },
    {
      "epoch": 0.5627914205781784,
      "grad_norm": 0.4976995587348938,
      "learning_rate": 7.186042897109109e-06,
      "loss": 0.2161,
      "step": 7242
    },
    {
      "epoch": 0.5628691327323594,
      "grad_norm": 0.8576078414916992,
      "learning_rate": 7.185654336338203e-06,
      "loss": 0.0862,
      "step": 7243
    },
    {
      "epoch": 0.5629468448865402,
      "grad_norm": 0.6405326724052429,
      "learning_rate": 7.185265775567299e-06,
      "loss": 0.8965,
      "step": 7244
    },
    {
      "epoch": 0.5630245570407212,
      "grad_norm": 0.13376545906066895,
      "learning_rate": 7.184877214796395e-06,
      "loss": 0.0305,
      "step": 7245
    },
    {
      "epoch": 0.563102269194902,
      "grad_norm": 0.5957381725311279,
      "learning_rate": 7.18448865402549e-06,
      "loss": 0.3103,
      "step": 7246
    },
    {
      "epoch": 0.563179981349083,
      "grad_norm": 0.14067833125591278,
      "learning_rate": 7.184100093254586e-06,
      "loss": 0.0449,
      "step": 7247
    },
    {
      "epoch": 0.5632576935032639,
      "grad_norm": 0.28252023458480835,
      "learning_rate": 7.1837115324836815e-06,
      "loss": 0.0475,
      "step": 7248
    },
    {
      "epoch": 0.5633354056574448,
      "grad_norm": 0.17103461921215057,
      "learning_rate": 7.1833229717127764e-06,
      "loss": 0.0477,
      "step": 7249
    },
    {
      "epoch": 0.5634131178116257,
      "grad_norm": 0.4980052709579468,
      "learning_rate": 7.182934410941872e-06,
      "loss": 0.1424,
      "step": 7250
    },
    {
      "epoch": 0.5634908299658067,
      "grad_norm": 0.3989109992980957,
      "learning_rate": 7.182545850170968e-06,
      "loss": 0.3065,
      "step": 7251
    },
    {
      "epoch": 0.5635685421199875,
      "grad_norm": 0.4752289950847626,
      "learning_rate": 7.182157289400062e-06,
      "loss": 0.0913,
      "step": 7252
    },
    {
      "epoch": 0.5636462542741685,
      "grad_norm": 0.16056211292743683,
      "learning_rate": 7.181768728629158e-06,
      "loss": 0.0628,
      "step": 7253
    },
    {
      "epoch": 0.5637239664283494,
      "grad_norm": 0.19455918669700623,
      "learning_rate": 7.181380167858254e-06,
      "loss": 0.056,
      "step": 7254
    },
    {
      "epoch": 0.5638016785825303,
      "grad_norm": 0.25016433000564575,
      "learning_rate": 7.180991607087349e-06,
      "loss": 0.1404,
      "step": 7255
    },
    {
      "epoch": 0.5638793907367112,
      "grad_norm": 0.6274234056472778,
      "learning_rate": 7.1806030463164445e-06,
      "loss": 0.0554,
      "step": 7256
    },
    {
      "epoch": 0.5639571028908922,
      "grad_norm": 0.22590847313404083,
      "learning_rate": 7.18021448554554e-06,
      "loss": 0.0366,
      "step": 7257
    },
    {
      "epoch": 0.564034815045073,
      "grad_norm": 0.531113862991333,
      "learning_rate": 7.179825924774635e-06,
      "loss": 0.0713,
      "step": 7258
    },
    {
      "epoch": 0.564112527199254,
      "grad_norm": 1.1803621053695679,
      "learning_rate": 7.179437364003731e-06,
      "loss": 0.7684,
      "step": 7259
    },
    {
      "epoch": 0.5641902393534349,
      "grad_norm": 0.3377968668937683,
      "learning_rate": 7.179048803232827e-06,
      "loss": 0.1557,
      "step": 7260
    },
    {
      "epoch": 0.5642679515076158,
      "grad_norm": 0.9264997243881226,
      "learning_rate": 7.178660242461921e-06,
      "loss": 1.8653,
      "step": 7261
    },
    {
      "epoch": 0.5643456636617967,
      "grad_norm": 0.5426539182662964,
      "learning_rate": 7.178271681691017e-06,
      "loss": 0.5535,
      "step": 7262
    },
    {
      "epoch": 0.5644233758159776,
      "grad_norm": 0.2862008512020111,
      "learning_rate": 7.1778831209201125e-06,
      "loss": 0.2001,
      "step": 7263
    },
    {
      "epoch": 0.5645010879701585,
      "grad_norm": 0.5235510468482971,
      "learning_rate": 7.1774945601492075e-06,
      "loss": 0.2637,
      "step": 7264
    },
    {
      "epoch": 0.5645788001243395,
      "grad_norm": 0.2747441530227661,
      "learning_rate": 7.177105999378303e-06,
      "loss": 0.0542,
      "step": 7265
    },
    {
      "epoch": 0.5646565122785203,
      "grad_norm": 0.3246309757232666,
      "learning_rate": 7.176717438607399e-06,
      "loss": 0.5005,
      "step": 7266
    },
    {
      "epoch": 0.5647342244327013,
      "grad_norm": 0.44342148303985596,
      "learning_rate": 7.176328877836494e-06,
      "loss": 0.2094,
      "step": 7267
    },
    {
      "epoch": 0.5648119365868822,
      "grad_norm": 0.40406447649002075,
      "learning_rate": 7.17594031706559e-06,
      "loss": 0.186,
      "step": 7268
    },
    {
      "epoch": 0.5648896487410631,
      "grad_norm": 0.12254974246025085,
      "learning_rate": 7.175551756294686e-06,
      "loss": 0.0465,
      "step": 7269
    },
    {
      "epoch": 0.564967360895244,
      "grad_norm": 0.19949468970298767,
      "learning_rate": 7.175163195523781e-06,
      "loss": 0.1271,
      "step": 7270
    },
    {
      "epoch": 0.565045073049425,
      "grad_norm": 0.4351854920387268,
      "learning_rate": 7.1747746347528755e-06,
      "loss": 0.163,
      "step": 7271
    },
    {
      "epoch": 0.5651227852036058,
      "grad_norm": 0.5385388135910034,
      "learning_rate": 7.174386073981971e-06,
      "loss": 0.7462,
      "step": 7272
    },
    {
      "epoch": 0.5652004973577868,
      "grad_norm": 0.18288569152355194,
      "learning_rate": 7.173997513211067e-06,
      "loss": 0.0443,
      "step": 7273
    },
    {
      "epoch": 0.5652782095119677,
      "grad_norm": 0.0991433784365654,
      "learning_rate": 7.173608952440162e-06,
      "loss": 0.0375,
      "step": 7274
    },
    {
      "epoch": 0.5653559216661486,
      "grad_norm": 0.2315884679555893,
      "learning_rate": 7.173220391669258e-06,
      "loss": 0.1925,
      "step": 7275
    },
    {
      "epoch": 0.5654336338203295,
      "grad_norm": 0.38400405645370483,
      "learning_rate": 7.172831830898354e-06,
      "loss": 0.5889,
      "step": 7276
    },
    {
      "epoch": 0.5655113459745104,
      "grad_norm": 0.5084474682807922,
      "learning_rate": 7.172443270127449e-06,
      "loss": 0.0645,
      "step": 7277
    },
    {
      "epoch": 0.5655890581286913,
      "grad_norm": 0.1247953549027443,
      "learning_rate": 7.172054709356544e-06,
      "loss": 0.049,
      "step": 7278
    },
    {
      "epoch": 0.5656667702828723,
      "grad_norm": 0.03450434282422066,
      "learning_rate": 7.17166614858564e-06,
      "loss": 0.0043,
      "step": 7279
    },
    {
      "epoch": 0.5657444824370531,
      "grad_norm": 0.5956060886383057,
      "learning_rate": 7.171277587814734e-06,
      "loss": 0.1757,
      "step": 7280
    },
    {
      "epoch": 0.5658221945912341,
      "grad_norm": 0.32718896865844727,
      "learning_rate": 7.17088902704383e-06,
      "loss": 0.1597,
      "step": 7281
    },
    {
      "epoch": 0.565899906745415,
      "grad_norm": 0.2143392115831375,
      "learning_rate": 7.170500466272926e-06,
      "loss": 0.0834,
      "step": 7282
    },
    {
      "epoch": 0.5659776188995959,
      "grad_norm": 0.2834743857383728,
      "learning_rate": 7.170111905502021e-06,
      "loss": 0.0899,
      "step": 7283
    },
    {
      "epoch": 0.5660553310537768,
      "grad_norm": 0.3554386794567108,
      "learning_rate": 7.169723344731117e-06,
      "loss": 0.2299,
      "step": 7284
    },
    {
      "epoch": 0.5661330432079578,
      "grad_norm": 0.18253426253795624,
      "learning_rate": 7.169334783960212e-06,
      "loss": 0.1495,
      "step": 7285
    },
    {
      "epoch": 0.5662107553621386,
      "grad_norm": 0.39007940888404846,
      "learning_rate": 7.168946223189307e-06,
      "loss": 0.1735,
      "step": 7286
    },
    {
      "epoch": 0.5662884675163196,
      "grad_norm": 0.7435685992240906,
      "learning_rate": 7.168557662418403e-06,
      "loss": 0.4347,
      "step": 7287
    },
    {
      "epoch": 0.5663661796705005,
      "grad_norm": 0.014971138909459114,
      "learning_rate": 7.168169101647499e-06,
      "loss": 0.002,
      "step": 7288
    },
    {
      "epoch": 0.5664438918246814,
      "grad_norm": 0.8220958113670349,
      "learning_rate": 7.167780540876593e-06,
      "loss": 0.1224,
      "step": 7289
    },
    {
      "epoch": 0.5665216039788623,
      "grad_norm": 0.14058171212673187,
      "learning_rate": 7.167391980105689e-06,
      "loss": 0.0636,
      "step": 7290
    },
    {
      "epoch": 0.5665993161330433,
      "grad_norm": 0.3658204972743988,
      "learning_rate": 7.167003419334785e-06,
      "loss": 0.422,
      "step": 7291
    },
    {
      "epoch": 0.5666770282872241,
      "grad_norm": 0.6095520257949829,
      "learning_rate": 7.16661485856388e-06,
      "loss": 0.2321,
      "step": 7292
    },
    {
      "epoch": 0.5667547404414051,
      "grad_norm": 0.5345778465270996,
      "learning_rate": 7.166226297792975e-06,
      "loss": 0.3319,
      "step": 7293
    },
    {
      "epoch": 0.5668324525955859,
      "grad_norm": 0.5198439359664917,
      "learning_rate": 7.165837737022071e-06,
      "loss": 0.6524,
      "step": 7294
    },
    {
      "epoch": 0.5669101647497669,
      "grad_norm": 0.18327486515045166,
      "learning_rate": 7.165449176251166e-06,
      "loss": 0.0705,
      "step": 7295
    },
    {
      "epoch": 0.5669878769039478,
      "grad_norm": 0.36302250623703003,
      "learning_rate": 7.165060615480262e-06,
      "loss": 0.0675,
      "step": 7296
    },
    {
      "epoch": 0.5670655890581286,
      "grad_norm": 0.2019597738981247,
      "learning_rate": 7.164672054709358e-06,
      "loss": 0.1132,
      "step": 7297
    },
    {
      "epoch": 0.5671433012123096,
      "grad_norm": 0.28628721833229065,
      "learning_rate": 7.164283493938452e-06,
      "loss": 0.2266,
      "step": 7298
    },
    {
      "epoch": 0.5672210133664906,
      "grad_norm": 0.27511274814605713,
      "learning_rate": 7.163894933167548e-06,
      "loss": 0.0531,
      "step": 7299
    },
    {
      "epoch": 0.5672987255206714,
      "grad_norm": 0.381145179271698,
      "learning_rate": 7.1635063723966434e-06,
      "loss": 0.1158,
      "step": 7300
    },
    {
      "epoch": 0.5673764376748524,
      "grad_norm": 0.1634223461151123,
      "learning_rate": 7.163117811625739e-06,
      "loss": 0.0476,
      "step": 7301
    },
    {
      "epoch": 0.5674541498290333,
      "grad_norm": 0.6749184131622314,
      "learning_rate": 7.162729250854834e-06,
      "loss": 0.0829,
      "step": 7302
    },
    {
      "epoch": 0.5675318619832141,
      "grad_norm": 0.3576931059360504,
      "learning_rate": 7.16234069008393e-06,
      "loss": 0.2616,
      "step": 7303
    },
    {
      "epoch": 0.5676095741373951,
      "grad_norm": 0.24005763232707977,
      "learning_rate": 7.161952129313026e-06,
      "loss": 0.0606,
      "step": 7304
    },
    {
      "epoch": 0.567687286291576,
      "grad_norm": 0.449203222990036,
      "learning_rate": 7.161563568542121e-06,
      "loss": 0.2326,
      "step": 7305
    },
    {
      "epoch": 0.5677649984457569,
      "grad_norm": 0.32274171710014343,
      "learning_rate": 7.1611750077712165e-06,
      "loss": 0.1297,
      "step": 7306
    },
    {
      "epoch": 0.5678427105999378,
      "grad_norm": 0.26883381605148315,
      "learning_rate": 7.1607864470003115e-06,
      "loss": 0.1032,
      "step": 7307
    },
    {
      "epoch": 0.5679204227541187,
      "grad_norm": 0.41808903217315674,
      "learning_rate": 7.160397886229406e-06,
      "loss": 0.332,
      "step": 7308
    },
    {
      "epoch": 0.5679981349082996,
      "grad_norm": 0.3604789972305298,
      "learning_rate": 7.160009325458502e-06,
      "loss": 0.1024,
      "step": 7309
    },
    {
      "epoch": 0.5680758470624806,
      "grad_norm": 0.3415614068508148,
      "learning_rate": 7.159620764687598e-06,
      "loss": 0.281,
      "step": 7310
    },
    {
      "epoch": 0.5681535592166614,
      "grad_norm": 0.17168545722961426,
      "learning_rate": 7.159232203916693e-06,
      "loss": 0.0757,
      "step": 7311
    },
    {
      "epoch": 0.5682312713708424,
      "grad_norm": 0.5469237565994263,
      "learning_rate": 7.158843643145789e-06,
      "loss": 0.1344,
      "step": 7312
    },
    {
      "epoch": 0.5683089835250233,
      "grad_norm": 0.3665354549884796,
      "learning_rate": 7.1584550823748846e-06,
      "loss": 0.1848,
      "step": 7313
    },
    {
      "epoch": 0.5683866956792042,
      "grad_norm": 0.634752631187439,
      "learning_rate": 7.158066521603979e-06,
      "loss": 0.7471,
      "step": 7314
    },
    {
      "epoch": 0.5684644078333851,
      "grad_norm": 0.07506875693798065,
      "learning_rate": 7.1576779608330745e-06,
      "loss": 0.009,
      "step": 7315
    },
    {
      "epoch": 0.5685421199875661,
      "grad_norm": 0.8470139503479004,
      "learning_rate": 7.15728940006217e-06,
      "loss": 0.3967,
      "step": 7316
    },
    {
      "epoch": 0.5686198321417469,
      "grad_norm": 0.35220155119895935,
      "learning_rate": 7.156900839291265e-06,
      "loss": 0.1622,
      "step": 7317
    },
    {
      "epoch": 0.5686975442959279,
      "grad_norm": 0.16636691987514496,
      "learning_rate": 7.156512278520361e-06,
      "loss": 0.0535,
      "step": 7318
    },
    {
      "epoch": 0.5687752564501088,
      "grad_norm": 0.15856888890266418,
      "learning_rate": 7.156123717749457e-06,
      "loss": 0.0592,
      "step": 7319
    },
    {
      "epoch": 0.5688529686042897,
      "grad_norm": 0.18561168015003204,
      "learning_rate": 7.155735156978552e-06,
      "loss": 0.132,
      "step": 7320
    },
    {
      "epoch": 0.5689306807584706,
      "grad_norm": 0.4809854030609131,
      "learning_rate": 7.1553465962076475e-06,
      "loss": 0.2699,
      "step": 7321
    },
    {
      "epoch": 0.5690083929126515,
      "grad_norm": 0.19266672432422638,
      "learning_rate": 7.154958035436743e-06,
      "loss": 0.1137,
      "step": 7322
    },
    {
      "epoch": 0.5690861050668324,
      "grad_norm": 0.1796049326658249,
      "learning_rate": 7.1545694746658374e-06,
      "loss": 0.0486,
      "step": 7323
    },
    {
      "epoch": 0.5691638172210134,
      "grad_norm": 0.5117619037628174,
      "learning_rate": 7.154180913894933e-06,
      "loss": 0.3067,
      "step": 7324
    },
    {
      "epoch": 0.5692415293751942,
      "grad_norm": 0.6582391262054443,
      "learning_rate": 7.153792353124029e-06,
      "loss": 0.2674,
      "step": 7325
    },
    {
      "epoch": 0.5693192415293752,
      "grad_norm": 0.5477553606033325,
      "learning_rate": 7.153403792353124e-06,
      "loss": 0.1154,
      "step": 7326
    },
    {
      "epoch": 0.5693969536835561,
      "grad_norm": 0.6163071393966675,
      "learning_rate": 7.15301523158222e-06,
      "loss": 0.0849,
      "step": 7327
    },
    {
      "epoch": 0.569474665837737,
      "grad_norm": 0.30099961161613464,
      "learning_rate": 7.152626670811316e-06,
      "loss": 0.4597,
      "step": 7328
    },
    {
      "epoch": 0.5695523779919179,
      "grad_norm": 0.10128068178892136,
      "learning_rate": 7.1522381100404105e-06,
      "loss": 0.0192,
      "step": 7329
    },
    {
      "epoch": 0.5696300901460989,
      "grad_norm": 1.4552226066589355,
      "learning_rate": 7.151849549269506e-06,
      "loss": 0.6243,
      "step": 7330
    },
    {
      "epoch": 0.5697078023002797,
      "grad_norm": 0.39986318349838257,
      "learning_rate": 7.151460988498602e-06,
      "loss": 0.0944,
      "step": 7331
    },
    {
      "epoch": 0.5697855144544607,
      "grad_norm": 0.4041227400302887,
      "learning_rate": 7.151072427727698e-06,
      "loss": 0.3102,
      "step": 7332
    },
    {
      "epoch": 0.5698632266086416,
      "grad_norm": 0.47831690311431885,
      "learning_rate": 7.150683866956792e-06,
      "loss": 0.3689,
      "step": 7333
    },
    {
      "epoch": 0.5699409387628225,
      "grad_norm": 0.41026049852371216,
      "learning_rate": 7.150295306185888e-06,
      "loss": 0.1977,
      "step": 7334
    },
    {
      "epoch": 0.5700186509170034,
      "grad_norm": 0.46007686853408813,
      "learning_rate": 7.149906745414984e-06,
      "loss": 0.1061,
      "step": 7335
    },
    {
      "epoch": 0.5700963630711844,
      "grad_norm": 0.460054874420166,
      "learning_rate": 7.1495181846440786e-06,
      "loss": 0.1144,
      "step": 7336
    },
    {
      "epoch": 0.5701740752253652,
      "grad_norm": 0.18656955659389496,
      "learning_rate": 7.149129623873174e-06,
      "loss": 0.0934,
      "step": 7337
    },
    {
      "epoch": 0.5702517873795462,
      "grad_norm": 0.43411025404930115,
      "learning_rate": 7.14874106310227e-06,
      "loss": 0.1531,
      "step": 7338
    },
    {
      "epoch": 0.570329499533727,
      "grad_norm": 0.22229698300361633,
      "learning_rate": 7.148352502331365e-06,
      "loss": 0.1892,
      "step": 7339
    },
    {
      "epoch": 0.570407211687908,
      "grad_norm": 0.8791012763977051,
      "learning_rate": 7.147963941560461e-06,
      "loss": 0.4632,
      "step": 7340
    },
    {
      "epoch": 0.5704849238420889,
      "grad_norm": 0.5641108751296997,
      "learning_rate": 7.147575380789557e-06,
      "loss": 0.4039,
      "step": 7341
    },
    {
      "epoch": 0.5705626359962698,
      "grad_norm": 0.6576592922210693,
      "learning_rate": 7.147186820018651e-06,
      "loss": 0.1982,
      "step": 7342
    },
    {
      "epoch": 0.5706403481504507,
      "grad_norm": 0.18054404854774475,
      "learning_rate": 7.146798259247747e-06,
      "loss": 0.1315,
      "step": 7343
    },
    {
      "epoch": 0.5707180603046317,
      "grad_norm": 0.24692267179489136,
      "learning_rate": 7.146409698476842e-06,
      "loss": 0.073,
      "step": 7344
    },
    {
      "epoch": 0.5707957724588125,
      "grad_norm": 0.3861066401004791,
      "learning_rate": 7.146021137705937e-06,
      "loss": 0.1242,
      "step": 7345
    },
    {
      "epoch": 0.5708734846129935,
      "grad_norm": 0.5176989436149597,
      "learning_rate": 7.145632576935033e-06,
      "loss": 0.2033,
      "step": 7346
    },
    {
      "epoch": 0.5709511967671744,
      "grad_norm": 0.39475390315055847,
      "learning_rate": 7.145244016164129e-06,
      "loss": 0.1511,
      "step": 7347
    },
    {
      "epoch": 0.5710289089213553,
      "grad_norm": 0.20888656377792358,
      "learning_rate": 7.144855455393224e-06,
      "loss": 0.0816,
      "step": 7348
    },
    {
      "epoch": 0.5711066210755362,
      "grad_norm": 0.2765316069126129,
      "learning_rate": 7.14446689462232e-06,
      "loss": 0.1193,
      "step": 7349
    },
    {
      "epoch": 0.5711843332297172,
      "grad_norm": 0.163143590092659,
      "learning_rate": 7.1440783338514155e-06,
      "loss": 0.0252,
      "step": 7350
    },
    {
      "epoch": 0.571262045383898,
      "grad_norm": 0.8175726532936096,
      "learning_rate": 7.14368977308051e-06,
      "loss": 0.4726,
      "step": 7351
    },
    {
      "epoch": 0.571339757538079,
      "grad_norm": 0.06248020753264427,
      "learning_rate": 7.143301212309605e-06,
      "loss": 0.0177,
      "step": 7352
    },
    {
      "epoch": 0.5714174696922598,
      "grad_norm": 0.36561548709869385,
      "learning_rate": 7.142912651538701e-06,
      "loss": 0.3181,
      "step": 7353
    },
    {
      "epoch": 0.5714951818464408,
      "grad_norm": 0.18661461770534515,
      "learning_rate": 7.142524090767796e-06,
      "loss": 0.0452,
      "step": 7354
    },
    {
      "epoch": 0.5715728940006217,
      "grad_norm": 0.3240364193916321,
      "learning_rate": 7.142135529996892e-06,
      "loss": 0.1255,
      "step": 7355
    },
    {
      "epoch": 0.5716506061548026,
      "grad_norm": 0.4587356448173523,
      "learning_rate": 7.141746969225988e-06,
      "loss": 0.1996,
      "step": 7356
    },
    {
      "epoch": 0.5717283183089835,
      "grad_norm": 0.43078017234802246,
      "learning_rate": 7.141358408455083e-06,
      "loss": 0.27,
      "step": 7357
    },
    {
      "epoch": 0.5718060304631645,
      "grad_norm": 0.5256616473197937,
      "learning_rate": 7.1409698476841785e-06,
      "loss": 0.1811,
      "step": 7358
    },
    {
      "epoch": 0.5718837426173453,
      "grad_norm": 0.23249241709709167,
      "learning_rate": 7.140581286913274e-06,
      "loss": 0.1058,
      "step": 7359
    },
    {
      "epoch": 0.5719614547715263,
      "grad_norm": 0.23217430710792542,
      "learning_rate": 7.14019272614237e-06,
      "loss": 0.0671,
      "step": 7360
    },
    {
      "epoch": 0.5720391669257072,
      "grad_norm": 0.14973823726177216,
      "learning_rate": 7.139804165371464e-06,
      "loss": 0.0727,
      "step": 7361
    },
    {
      "epoch": 0.5721168790798881,
      "grad_norm": 0.14761941134929657,
      "learning_rate": 7.13941560460056e-06,
      "loss": 0.0408,
      "step": 7362
    },
    {
      "epoch": 0.572194591234069,
      "grad_norm": 0.3294074237346649,
      "learning_rate": 7.139027043829656e-06,
      "loss": 0.1961,
      "step": 7363
    },
    {
      "epoch": 0.57227230338825,
      "grad_norm": 0.28225284814834595,
      "learning_rate": 7.138638483058751e-06,
      "loss": 0.1617,
      "step": 7364
    },
    {
      "epoch": 0.5723500155424308,
      "grad_norm": 0.258527547121048,
      "learning_rate": 7.1382499222878465e-06,
      "loss": 0.2019,
      "step": 7365
    },
    {
      "epoch": 0.5724277276966118,
      "grad_norm": 0.13818559050559998,
      "learning_rate": 7.137861361516942e-06,
      "loss": 0.0361,
      "step": 7366
    },
    {
      "epoch": 0.5725054398507927,
      "grad_norm": 0.2571033537387848,
      "learning_rate": 7.137472800746037e-06,
      "loss": 0.0852,
      "step": 7367
    },
    {
      "epoch": 0.5725831520049736,
      "grad_norm": 0.15930567681789398,
      "learning_rate": 7.137084239975133e-06,
      "loss": 0.0517,
      "step": 7368
    },
    {
      "epoch": 0.5726608641591545,
      "grad_norm": 0.11985867470502853,
      "learning_rate": 7.136695679204229e-06,
      "loss": 0.0702,
      "step": 7369
    },
    {
      "epoch": 0.5727385763133354,
      "grad_norm": 0.16480694711208344,
      "learning_rate": 7.136307118433323e-06,
      "loss": 0.0314,
      "step": 7370
    },
    {
      "epoch": 0.5728162884675163,
      "grad_norm": 0.20755548775196075,
      "learning_rate": 7.135918557662419e-06,
      "loss": 0.0222,
      "step": 7371
    },
    {
      "epoch": 0.5728940006216973,
      "grad_norm": 0.3899576663970947,
      "learning_rate": 7.1355299968915145e-06,
      "loss": 0.1191,
      "step": 7372
    },
    {
      "epoch": 0.5729717127758781,
      "grad_norm": 0.7620049118995667,
      "learning_rate": 7.1351414361206095e-06,
      "loss": 0.4172,
      "step": 7373
    },
    {
      "epoch": 0.5730494249300591,
      "grad_norm": 0.33910155296325684,
      "learning_rate": 7.134752875349705e-06,
      "loss": 0.2756,
      "step": 7374
    },
    {
      "epoch": 0.57312713708424,
      "grad_norm": 0.32865869998931885,
      "learning_rate": 7.134364314578801e-06,
      "loss": 0.1207,
      "step": 7375
    },
    {
      "epoch": 0.5732048492384209,
      "grad_norm": 0.3348398208618164,
      "learning_rate": 7.133975753807896e-06,
      "loss": 0.1672,
      "step": 7376
    },
    {
      "epoch": 0.5732825613926018,
      "grad_norm": 0.700298547744751,
      "learning_rate": 7.133587193036992e-06,
      "loss": 0.3736,
      "step": 7377
    },
    {
      "epoch": 0.5733602735467828,
      "grad_norm": 0.12278871238231659,
      "learning_rate": 7.133198632266088e-06,
      "loss": 0.0361,
      "step": 7378
    },
    {
      "epoch": 0.5734379857009636,
      "grad_norm": 0.31629678606987,
      "learning_rate": 7.132810071495182e-06,
      "loss": 0.0576,
      "step": 7379
    },
    {
      "epoch": 0.5735156978551446,
      "grad_norm": 0.5140678286552429,
      "learning_rate": 7.1324215107242775e-06,
      "loss": 0.2615,
      "step": 7380
    },
    {
      "epoch": 0.5735934100093255,
      "grad_norm": 0.38624849915504456,
      "learning_rate": 7.132032949953373e-06,
      "loss": 0.146,
      "step": 7381
    },
    {
      "epoch": 0.5736711221635064,
      "grad_norm": 0.3518713116645813,
      "learning_rate": 7.131644389182468e-06,
      "loss": 0.1055,
      "step": 7382
    },
    {
      "epoch": 0.5737488343176873,
      "grad_norm": 0.16468274593353271,
      "learning_rate": 7.131255828411564e-06,
      "loss": 0.0369,
      "step": 7383
    },
    {
      "epoch": 0.5738265464718681,
      "grad_norm": 0.20296958088874817,
      "learning_rate": 7.13086726764066e-06,
      "loss": 0.0987,
      "step": 7384
    },
    {
      "epoch": 0.5739042586260491,
      "grad_norm": 0.5230473875999451,
      "learning_rate": 7.130478706869755e-06,
      "loss": 0.1304,
      "step": 7385
    },
    {
      "epoch": 0.57398197078023,
      "grad_norm": 0.2551025152206421,
      "learning_rate": 7.130090146098851e-06,
      "loss": 0.0941,
      "step": 7386
    },
    {
      "epoch": 0.5740596829344109,
      "grad_norm": 0.5880725383758545,
      "learning_rate": 7.129701585327946e-06,
      "loss": 0.4647,
      "step": 7387
    },
    {
      "epoch": 0.5741373950885919,
      "grad_norm": 0.7394633889198303,
      "learning_rate": 7.1293130245570405e-06,
      "loss": 0.2749,
      "step": 7388
    },
    {
      "epoch": 0.5742151072427728,
      "grad_norm": 0.31025639176368713,
      "learning_rate": 7.128924463786136e-06,
      "loss": 0.0844,
      "step": 7389
    },
    {
      "epoch": 0.5742928193969536,
      "grad_norm": 0.6407774686813354,
      "learning_rate": 7.128535903015232e-06,
      "loss": 0.317,
      "step": 7390
    },
    {
      "epoch": 0.5743705315511346,
      "grad_norm": 0.3216748535633087,
      "learning_rate": 7.128147342244328e-06,
      "loss": 0.2158,
      "step": 7391
    },
    {
      "epoch": 0.5744482437053156,
      "grad_norm": 0.26014238595962524,
      "learning_rate": 7.127758781473423e-06,
      "loss": 0.0787,
      "step": 7392
    },
    {
      "epoch": 0.5745259558594964,
      "grad_norm": 0.16099709272384644,
      "learning_rate": 7.127370220702519e-06,
      "loss": 0.043,
      "step": 7393
    },
    {
      "epoch": 0.5746036680136773,
      "grad_norm": 0.7211639881134033,
      "learning_rate": 7.1269816599316145e-06,
      "loss": 0.1902,
      "step": 7394
    },
    {
      "epoch": 0.5746813801678583,
      "grad_norm": 0.5908148884773254,
      "learning_rate": 7.126593099160709e-06,
      "loss": 0.6118,
      "step": 7395
    },
    {
      "epoch": 0.5747590923220391,
      "grad_norm": 0.1914638876914978,
      "learning_rate": 7.126204538389805e-06,
      "loss": 0.0542,
      "step": 7396
    },
    {
      "epoch": 0.5748368044762201,
      "grad_norm": 0.29108479619026184,
      "learning_rate": 7.125815977618901e-06,
      "loss": 0.1237,
      "step": 7397
    },
    {
      "epoch": 0.5749145166304009,
      "grad_norm": 0.6228750348091125,
      "learning_rate": 7.125427416847995e-06,
      "loss": 0.3775,
      "step": 7398
    },
    {
      "epoch": 0.5749922287845819,
      "grad_norm": 0.4129156470298767,
      "learning_rate": 7.125038856077091e-06,
      "loss": 0.1966,
      "step": 7399
    },
    {
      "epoch": 0.5750699409387628,
      "grad_norm": 0.11072219163179398,
      "learning_rate": 7.124650295306187e-06,
      "loss": 0.0173,
      "step": 7400
    },
    {
      "epoch": 0.5751476530929437,
      "grad_norm": 0.07702138274908066,
      "learning_rate": 7.124261734535282e-06,
      "loss": 0.0135,
      "step": 7401
    },
    {
      "epoch": 0.5752253652471246,
      "grad_norm": 0.6396448612213135,
      "learning_rate": 7.1238731737643774e-06,
      "loss": 0.341,
      "step": 7402
    },
    {
      "epoch": 0.5753030774013056,
      "grad_norm": 0.16346687078475952,
      "learning_rate": 7.123484612993473e-06,
      "loss": 0.0476,
      "step": 7403
    },
    {
      "epoch": 0.5753807895554864,
      "grad_norm": 0.22669294476509094,
      "learning_rate": 7.123096052222568e-06,
      "loss": 0.1187,
      "step": 7404
    },
    {
      "epoch": 0.5754585017096674,
      "grad_norm": 0.4688975512981415,
      "learning_rate": 7.122707491451664e-06,
      "loss": 0.3781,
      "step": 7405
    },
    {
      "epoch": 0.5755362138638483,
      "grad_norm": 1.025622010231018,
      "learning_rate": 7.12231893068076e-06,
      "loss": 0.5434,
      "step": 7406
    },
    {
      "epoch": 0.5756139260180292,
      "grad_norm": 0.6292656064033508,
      "learning_rate": 7.121930369909854e-06,
      "loss": 0.7358,
      "step": 7407
    },
    {
      "epoch": 0.5756916381722101,
      "grad_norm": 0.3541508913040161,
      "learning_rate": 7.12154180913895e-06,
      "loss": 0.1341,
      "step": 7408
    },
    {
      "epoch": 0.5757693503263911,
      "grad_norm": 0.16365036368370056,
      "learning_rate": 7.1211532483680455e-06,
      "loss": 0.0703,
      "step": 7409
    },
    {
      "epoch": 0.5758470624805719,
      "grad_norm": 0.21034418046474457,
      "learning_rate": 7.1207646875971404e-06,
      "loss": 0.1679,
      "step": 7410
    },
    {
      "epoch": 0.5759247746347529,
      "grad_norm": 0.1715903878211975,
      "learning_rate": 7.120376126826236e-06,
      "loss": 0.0304,
      "step": 7411
    },
    {
      "epoch": 0.5760024867889338,
      "grad_norm": 0.24785470962524414,
      "learning_rate": 7.119987566055332e-06,
      "loss": 0.2092,
      "step": 7412
    },
    {
      "epoch": 0.5760801989431147,
      "grad_norm": 0.6935028433799744,
      "learning_rate": 7.119599005284427e-06,
      "loss": 0.3109,
      "step": 7413
    },
    {
      "epoch": 0.5761579110972956,
      "grad_norm": 0.7457337379455566,
      "learning_rate": 7.119210444513523e-06,
      "loss": 0.3903,
      "step": 7414
    },
    {
      "epoch": 0.5762356232514765,
      "grad_norm": 0.5167370438575745,
      "learning_rate": 7.1188218837426186e-06,
      "loss": 0.3073,
      "step": 7415
    },
    {
      "epoch": 0.5763133354056574,
      "grad_norm": 0.18794943392276764,
      "learning_rate": 7.118433322971713e-06,
      "loss": 0.0556,
      "step": 7416
    },
    {
      "epoch": 0.5763910475598384,
      "grad_norm": 0.3637126386165619,
      "learning_rate": 7.1180447622008085e-06,
      "loss": 0.3395,
      "step": 7417
    },
    {
      "epoch": 0.5764687597140192,
      "grad_norm": 0.45128926634788513,
      "learning_rate": 7.117656201429904e-06,
      "loss": 0.338,
      "step": 7418
    },
    {
      "epoch": 0.5765464718682002,
      "grad_norm": 0.30331119894981384,
      "learning_rate": 7.117267640658999e-06,
      "loss": 0.053,
      "step": 7419
    },
    {
      "epoch": 0.5766241840223811,
      "grad_norm": 0.5301568508148193,
      "learning_rate": 7.116879079888095e-06,
      "loss": 0.3019,
      "step": 7420
    },
    {
      "epoch": 0.576701896176562,
      "grad_norm": 0.3617917597293854,
      "learning_rate": 7.116490519117191e-06,
      "loss": 0.1869,
      "step": 7421
    },
    {
      "epoch": 0.5767796083307429,
      "grad_norm": 0.30977481603622437,
      "learning_rate": 7.116101958346287e-06,
      "loss": 0.1911,
      "step": 7422
    },
    {
      "epoch": 0.5768573204849239,
      "grad_norm": 0.24498946964740753,
      "learning_rate": 7.1157133975753816e-06,
      "loss": 0.0717,
      "step": 7423
    },
    {
      "epoch": 0.5769350326391047,
      "grad_norm": 0.5666396021842957,
      "learning_rate": 7.115324836804477e-06,
      "loss": 0.1298,
      "step": 7424
    },
    {
      "epoch": 0.5770127447932857,
      "grad_norm": 0.13420280814170837,
      "learning_rate": 7.114936276033573e-06,
      "loss": 0.0708,
      "step": 7425
    },
    {
      "epoch": 0.5770904569474666,
      "grad_norm": 0.5894359946250916,
      "learning_rate": 7.114547715262667e-06,
      "loss": 0.3106,
      "step": 7426
    },
    {
      "epoch": 0.5771681691016475,
      "grad_norm": 0.8870980143547058,
      "learning_rate": 7.114159154491763e-06,
      "loss": 0.5951,
      "step": 7427
    },
    {
      "epoch": 0.5772458812558284,
      "grad_norm": 1.451279878616333,
      "learning_rate": 7.113770593720859e-06,
      "loss": 0.7049,
      "step": 7428
    },
    {
      "epoch": 0.5773235934100093,
      "grad_norm": 0.2141580879688263,
      "learning_rate": 7.113382032949954e-06,
      "loss": 0.168,
      "step": 7429
    },
    {
      "epoch": 0.5774013055641902,
      "grad_norm": 0.5311465263366699,
      "learning_rate": 7.11299347217905e-06,
      "loss": 0.4449,
      "step": 7430
    },
    {
      "epoch": 0.5774790177183712,
      "grad_norm": 0.1986636370420456,
      "learning_rate": 7.112604911408145e-06,
      "loss": 0.4509,
      "step": 7431
    },
    {
      "epoch": 0.577556729872552,
      "grad_norm": 0.37228041887283325,
      "learning_rate": 7.11221635063724e-06,
      "loss": 0.0957,
      "step": 7432
    },
    {
      "epoch": 0.577634442026733,
      "grad_norm": 0.6080615520477295,
      "learning_rate": 7.111827789866336e-06,
      "loss": 0.4618,
      "step": 7433
    },
    {
      "epoch": 0.5777121541809139,
      "grad_norm": 0.04889926686882973,
      "learning_rate": 7.111439229095431e-06,
      "loss": 0.0061,
      "step": 7434
    },
    {
      "epoch": 0.5777898663350948,
      "grad_norm": 0.27172836661338806,
      "learning_rate": 7.111050668324526e-06,
      "loss": 0.1459,
      "step": 7435
    },
    {
      "epoch": 0.5778675784892757,
      "grad_norm": 0.5160235166549683,
      "learning_rate": 7.110662107553622e-06,
      "loss": 0.1413,
      "step": 7436
    },
    {
      "epoch": 0.5779452906434567,
      "grad_norm": 0.21511907875537872,
      "learning_rate": 7.110273546782718e-06,
      "loss": 0.0461,
      "step": 7437
    },
    {
      "epoch": 0.5780230027976375,
      "grad_norm": 0.9284922480583191,
      "learning_rate": 7.1098849860118126e-06,
      "loss": 0.6549,
      "step": 7438
    },
    {
      "epoch": 0.5781007149518185,
      "grad_norm": 0.6461878418922424,
      "learning_rate": 7.109496425240908e-06,
      "loss": 0.1457,
      "step": 7439
    },
    {
      "epoch": 0.5781784271059994,
      "grad_norm": 0.24702997505664825,
      "learning_rate": 7.109107864470004e-06,
      "loss": 0.0909,
      "step": 7440
    },
    {
      "epoch": 0.5782561392601803,
      "grad_norm": 0.3135406970977783,
      "learning_rate": 7.108719303699098e-06,
      "loss": 0.133,
      "step": 7441
    },
    {
      "epoch": 0.5783338514143612,
      "grad_norm": 0.4367370307445526,
      "learning_rate": 7.108330742928194e-06,
      "loss": 0.3794,
      "step": 7442
    },
    {
      "epoch": 0.5784115635685422,
      "grad_norm": 0.7068729400634766,
      "learning_rate": 7.10794218215729e-06,
      "loss": 0.3152,
      "step": 7443
    },
    {
      "epoch": 0.578489275722723,
      "grad_norm": 0.6980316638946533,
      "learning_rate": 7.107553621386385e-06,
      "loss": 0.2299,
      "step": 7444
    },
    {
      "epoch": 0.578566987876904,
      "grad_norm": 0.5236710906028748,
      "learning_rate": 7.107165060615481e-06,
      "loss": 0.2726,
      "step": 7445
    },
    {
      "epoch": 0.5786447000310848,
      "grad_norm": 0.17995867133140564,
      "learning_rate": 7.106776499844576e-06,
      "loss": 0.0296,
      "step": 7446
    },
    {
      "epoch": 0.5787224121852658,
      "grad_norm": 0.07000438123941422,
      "learning_rate": 7.106387939073671e-06,
      "loss": 0.0177,
      "step": 7447
    },
    {
      "epoch": 0.5788001243394467,
      "grad_norm": 0.2964667081832886,
      "learning_rate": 7.105999378302767e-06,
      "loss": 0.0997,
      "step": 7448
    },
    {
      "epoch": 0.5788778364936276,
      "grad_norm": 0.17433373630046844,
      "learning_rate": 7.105610817531863e-06,
      "loss": 0.0587,
      "step": 7449
    },
    {
      "epoch": 0.5789555486478085,
      "grad_norm": 0.5375889539718628,
      "learning_rate": 7.105222256760957e-06,
      "loss": 0.479,
      "step": 7450
    },
    {
      "epoch": 0.5790332608019895,
      "grad_norm": 0.34091171622276306,
      "learning_rate": 7.104833695990053e-06,
      "loss": 0.2287,
      "step": 7451
    },
    {
      "epoch": 0.5791109729561703,
      "grad_norm": 0.50718754529953,
      "learning_rate": 7.104445135219149e-06,
      "loss": 0.2603,
      "step": 7452
    },
    {
      "epoch": 0.5791886851103513,
      "grad_norm": 0.2573499083518982,
      "learning_rate": 7.1040565744482444e-06,
      "loss": 0.0947,
      "step": 7453
    },
    {
      "epoch": 0.5792663972645322,
      "grad_norm": 0.9242013692855835,
      "learning_rate": 7.103668013677339e-06,
      "loss": 0.826,
      "step": 7454
    },
    {
      "epoch": 0.5793441094187131,
      "grad_norm": 0.4427626430988312,
      "learning_rate": 7.103279452906435e-06,
      "loss": 0.3386,
      "step": 7455
    },
    {
      "epoch": 0.579421821572894,
      "grad_norm": 0.06183638051152229,
      "learning_rate": 7.102890892135531e-06,
      "loss": 0.0124,
      "step": 7456
    },
    {
      "epoch": 0.579499533727075,
      "grad_norm": 0.2958483397960663,
      "learning_rate": 7.102502331364626e-06,
      "loss": 0.0739,
      "step": 7457
    },
    {
      "epoch": 0.5795772458812558,
      "grad_norm": 0.35949695110321045,
      "learning_rate": 7.102113770593722e-06,
      "loss": 0.736,
      "step": 7458
    },
    {
      "epoch": 0.5796549580354368,
      "grad_norm": 0.09892487525939941,
      "learning_rate": 7.1017252098228175e-06,
      "loss": 0.0345,
      "step": 7459
    },
    {
      "epoch": 0.5797326701896176,
      "grad_norm": 0.5571110248565674,
      "learning_rate": 7.101336649051912e-06,
      "loss": 0.2683,
      "step": 7460
    },
    {
      "epoch": 0.5798103823437986,
      "grad_norm": 0.45939597487449646,
      "learning_rate": 7.1009480882810074e-06,
      "loss": 0.2129,
      "step": 7461
    },
    {
      "epoch": 0.5798880944979795,
      "grad_norm": 0.3438897132873535,
      "learning_rate": 7.100559527510103e-06,
      "loss": 0.1885,
      "step": 7462
    },
    {
      "epoch": 0.5799658066521604,
      "grad_norm": 0.37705153226852417,
      "learning_rate": 7.100170966739198e-06,
      "loss": 0.3904,
      "step": 7463
    },
    {
      "epoch": 0.5800435188063413,
      "grad_norm": 0.5840178728103638,
      "learning_rate": 7.099782405968294e-06,
      "loss": 0.5553,
      "step": 7464
    },
    {
      "epoch": 0.5801212309605223,
      "grad_norm": 0.13712705671787262,
      "learning_rate": 7.09939384519739e-06,
      "loss": 0.0445,
      "step": 7465
    },
    {
      "epoch": 0.5801989431147031,
      "grad_norm": 0.11230053752660751,
      "learning_rate": 7.099005284426485e-06,
      "loss": 0.0723,
      "step": 7466
    },
    {
      "epoch": 0.5802766552688841,
      "grad_norm": 0.1919986605644226,
      "learning_rate": 7.0986167236555805e-06,
      "loss": 0.0946,
      "step": 7467
    },
    {
      "epoch": 0.580354367423065,
      "grad_norm": 0.24593909084796906,
      "learning_rate": 7.098228162884676e-06,
      "loss": 0.13,
      "step": 7468
    },
    {
      "epoch": 0.5804320795772459,
      "grad_norm": 0.40326836705207825,
      "learning_rate": 7.09783960211377e-06,
      "loss": 0.0788,
      "step": 7469
    },
    {
      "epoch": 0.5805097917314268,
      "grad_norm": 0.6017012000083923,
      "learning_rate": 7.097451041342866e-06,
      "loss": 0.4978,
      "step": 7470
    },
    {
      "epoch": 0.5805875038856078,
      "grad_norm": 0.0603676475584507,
      "learning_rate": 7.097062480571962e-06,
      "loss": 0.0341,
      "step": 7471
    },
    {
      "epoch": 0.5806652160397886,
      "grad_norm": 0.09597956389188766,
      "learning_rate": 7.096673919801057e-06,
      "loss": 0.0124,
      "step": 7472
    },
    {
      "epoch": 0.5807429281939696,
      "grad_norm": 0.44321519136428833,
      "learning_rate": 7.096285359030153e-06,
      "loss": 0.2122,
      "step": 7473
    },
    {
      "epoch": 0.5808206403481504,
      "grad_norm": 0.6935814023017883,
      "learning_rate": 7.0958967982592486e-06,
      "loss": 0.8134,
      "step": 7474
    },
    {
      "epoch": 0.5808983525023313,
      "grad_norm": 0.6068370938301086,
      "learning_rate": 7.0955082374883435e-06,
      "loss": 0.5717,
      "step": 7475
    },
    {
      "epoch": 0.5809760646565123,
      "grad_norm": 0.5620119571685791,
      "learning_rate": 7.095119676717439e-06,
      "loss": 0.2557,
      "step": 7476
    },
    {
      "epoch": 0.5810537768106931,
      "grad_norm": 0.24365709722042084,
      "learning_rate": 7.094731115946535e-06,
      "loss": 0.0842,
      "step": 7477
    },
    {
      "epoch": 0.5811314889648741,
      "grad_norm": 0.5343989133834839,
      "learning_rate": 7.094342555175629e-06,
      "loss": 0.1856,
      "step": 7478
    },
    {
      "epoch": 0.581209201119055,
      "grad_norm": 0.6311028599739075,
      "learning_rate": 7.093953994404725e-06,
      "loss": 0.1181,
      "step": 7479
    },
    {
      "epoch": 0.5812869132732359,
      "grad_norm": 0.198011577129364,
      "learning_rate": 7.093565433633821e-06,
      "loss": 0.0529,
      "step": 7480
    },
    {
      "epoch": 0.5813646254274168,
      "grad_norm": 0.36022132635116577,
      "learning_rate": 7.093176872862916e-06,
      "loss": 0.0611,
      "step": 7481
    },
    {
      "epoch": 0.5814423375815978,
      "grad_norm": 0.332213819026947,
      "learning_rate": 7.0927883120920115e-06,
      "loss": 0.1608,
      "step": 7482
    },
    {
      "epoch": 0.5815200497357786,
      "grad_norm": 0.1791193038225174,
      "learning_rate": 7.092399751321107e-06,
      "loss": 0.0327,
      "step": 7483
    },
    {
      "epoch": 0.5815977618899596,
      "grad_norm": 0.34022629261016846,
      "learning_rate": 7.092011190550203e-06,
      "loss": 0.0581,
      "step": 7484
    },
    {
      "epoch": 0.5816754740441406,
      "grad_norm": 0.6038248538970947,
      "learning_rate": 7.091622629779298e-06,
      "loss": 0.177,
      "step": 7485
    },
    {
      "epoch": 0.5817531861983214,
      "grad_norm": 0.46254268288612366,
      "learning_rate": 7.091234069008394e-06,
      "loss": 0.0893,
      "step": 7486
    },
    {
      "epoch": 0.5818308983525023,
      "grad_norm": 0.4326397478580475,
      "learning_rate": 7.09084550823749e-06,
      "loss": 0.5578,
      "step": 7487
    },
    {
      "epoch": 0.5819086105066833,
      "grad_norm": 0.14424148201942444,
      "learning_rate": 7.090456947466584e-06,
      "loss": 0.0516,
      "step": 7488
    },
    {
      "epoch": 0.5819863226608641,
      "grad_norm": 0.2753215730190277,
      "learning_rate": 7.0900683866956796e-06,
      "loss": 0.0931,
      "step": 7489
    },
    {
      "epoch": 0.5820640348150451,
      "grad_norm": 0.269988089799881,
      "learning_rate": 7.089679825924775e-06,
      "loss": 0.0933,
      "step": 7490
    },
    {
      "epoch": 0.5821417469692259,
      "grad_norm": 0.7460063695907593,
      "learning_rate": 7.08929126515387e-06,
      "loss": 0.2041,
      "step": 7491
    },
    {
      "epoch": 0.5822194591234069,
      "grad_norm": 0.3101147711277008,
      "learning_rate": 7.088902704382966e-06,
      "loss": 0.13,
      "step": 7492
    },
    {
      "epoch": 0.5822971712775878,
      "grad_norm": 0.49560290575027466,
      "learning_rate": 7.088514143612062e-06,
      "loss": 0.4845,
      "step": 7493
    },
    {
      "epoch": 0.5823748834317687,
      "grad_norm": 0.17186227440834045,
      "learning_rate": 7.088125582841157e-06,
      "loss": 0.0547,
      "step": 7494
    },
    {
      "epoch": 0.5824525955859496,
      "grad_norm": 0.12831854820251465,
      "learning_rate": 7.087737022070253e-06,
      "loss": 0.0238,
      "step": 7495
    },
    {
      "epoch": 0.5825303077401306,
      "grad_norm": 0.3258804380893707,
      "learning_rate": 7.0873484612993485e-06,
      "loss": 0.2003,
      "step": 7496
    },
    {
      "epoch": 0.5826080198943114,
      "grad_norm": 0.622501790523529,
      "learning_rate": 7.0869599005284426e-06,
      "loss": 0.0594,
      "step": 7497
    },
    {
      "epoch": 0.5826857320484924,
      "grad_norm": 0.20107601583003998,
      "learning_rate": 7.086571339757538e-06,
      "loss": 0.0246,
      "step": 7498
    },
    {
      "epoch": 0.5827634442026733,
      "grad_norm": 0.4603798985481262,
      "learning_rate": 7.086182778986634e-06,
      "loss": 0.0971,
      "step": 7499
    },
    {
      "epoch": 0.5828411563568542,
      "grad_norm": 0.12771295011043549,
      "learning_rate": 7.085794218215729e-06,
      "loss": 0.0443,
      "step": 7500
    },
    {
      "epoch": 0.5829188685110351,
      "grad_norm": 0.35739007592201233,
      "learning_rate": 7.085405657444825e-06,
      "loss": 0.4481,
      "step": 7501
    },
    {
      "epoch": 0.5829965806652161,
      "grad_norm": 0.48156100511550903,
      "learning_rate": 7.085017096673921e-06,
      "loss": 0.2512,
      "step": 7502
    },
    {
      "epoch": 0.5830742928193969,
      "grad_norm": 0.15066827833652496,
      "learning_rate": 7.084628535903016e-06,
      "loss": 0.0438,
      "step": 7503
    },
    {
      "epoch": 0.5831520049735779,
      "grad_norm": 0.16582472622394562,
      "learning_rate": 7.0842399751321114e-06,
      "loss": 0.0597,
      "step": 7504
    },
    {
      "epoch": 0.5832297171277587,
      "grad_norm": 0.70729660987854,
      "learning_rate": 7.083851414361207e-06,
      "loss": 0.2563,
      "step": 7505
    },
    {
      "epoch": 0.5833074292819397,
      "grad_norm": 0.11096629500389099,
      "learning_rate": 7.083462853590301e-06,
      "loss": 0.0348,
      "step": 7506
    },
    {
      "epoch": 0.5833851414361206,
      "grad_norm": 0.9871102571487427,
      "learning_rate": 7.083074292819397e-06,
      "loss": 0.444,
      "step": 7507
    },
    {
      "epoch": 0.5834628535903015,
      "grad_norm": 0.46637511253356934,
      "learning_rate": 7.082685732048493e-06,
      "loss": 0.5239,
      "step": 7508
    },
    {
      "epoch": 0.5835405657444824,
      "grad_norm": 0.1494562327861786,
      "learning_rate": 7.082297171277588e-06,
      "loss": 0.044,
      "step": 7509
    },
    {
      "epoch": 0.5836182778986634,
      "grad_norm": 0.17221908271312714,
      "learning_rate": 7.081908610506684e-06,
      "loss": 0.0671,
      "step": 7510
    },
    {
      "epoch": 0.5836959900528442,
      "grad_norm": 1.1853110790252686,
      "learning_rate": 7.0815200497357795e-06,
      "loss": 0.9484,
      "step": 7511
    },
    {
      "epoch": 0.5837737022070252,
      "grad_norm": 0.2329283356666565,
      "learning_rate": 7.081131488964875e-06,
      "loss": 0.0417,
      "step": 7512
    },
    {
      "epoch": 0.5838514143612061,
      "grad_norm": 0.9137676954269409,
      "learning_rate": 7.08074292819397e-06,
      "loss": 0.4745,
      "step": 7513
    },
    {
      "epoch": 0.583929126515387,
      "grad_norm": 0.2889324426651001,
      "learning_rate": 7.080354367423066e-06,
      "loss": 0.1008,
      "step": 7514
    },
    {
      "epoch": 0.5840068386695679,
      "grad_norm": 0.5011248588562012,
      "learning_rate": 7.079965806652162e-06,
      "loss": 0.6668,
      "step": 7515
    },
    {
      "epoch": 0.5840845508237489,
      "grad_norm": 0.24688555300235748,
      "learning_rate": 7.079577245881256e-06,
      "loss": 0.0706,
      "step": 7516
    },
    {
      "epoch": 0.5841622629779297,
      "grad_norm": 0.4833237826824188,
      "learning_rate": 7.079188685110352e-06,
      "loss": 0.3769,
      "step": 7517
    },
    {
      "epoch": 0.5842399751321107,
      "grad_norm": 0.5449920296669006,
      "learning_rate": 7.0788001243394475e-06,
      "loss": 0.2743,
      "step": 7518
    },
    {
      "epoch": 0.5843176872862915,
      "grad_norm": 0.4114447236061096,
      "learning_rate": 7.0784115635685425e-06,
      "loss": 0.1737,
      "step": 7519
    },
    {
      "epoch": 0.5843953994404725,
      "grad_norm": 0.43917179107666016,
      "learning_rate": 7.078023002797638e-06,
      "loss": 0.2273,
      "step": 7520
    },
    {
      "epoch": 0.5844731115946534,
      "grad_norm": 0.37866339087486267,
      "learning_rate": 7.077634442026734e-06,
      "loss": 0.1721,
      "step": 7521
    },
    {
      "epoch": 0.5845508237488343,
      "grad_norm": 1.1239513158798218,
      "learning_rate": 7.077245881255829e-06,
      "loss": 0.3423,
      "step": 7522
    },
    {
      "epoch": 0.5846285359030152,
      "grad_norm": 0.5570576190948486,
      "learning_rate": 7.076857320484925e-06,
      "loss": 0.2807,
      "step": 7523
    },
    {
      "epoch": 0.5847062480571962,
      "grad_norm": 0.01564977876842022,
      "learning_rate": 7.076468759714021e-06,
      "loss": 0.0015,
      "step": 7524
    },
    {
      "epoch": 0.584783960211377,
      "grad_norm": 0.4328230023384094,
      "learning_rate": 7.076080198943115e-06,
      "loss": 0.353,
      "step": 7525
    },
    {
      "epoch": 0.584861672365558,
      "grad_norm": 0.10194384306669235,
      "learning_rate": 7.0756916381722105e-06,
      "loss": 0.1641,
      "step": 7526
    },
    {
      "epoch": 0.5849393845197389,
      "grad_norm": 0.4285050332546234,
      "learning_rate": 7.075303077401306e-06,
      "loss": 0.1275,
      "step": 7527
    },
    {
      "epoch": 0.5850170966739198,
      "grad_norm": 0.08417502790689468,
      "learning_rate": 7.074914516630401e-06,
      "loss": 0.0299,
      "step": 7528
    },
    {
      "epoch": 0.5850948088281007,
      "grad_norm": 0.4070090651512146,
      "learning_rate": 7.074525955859497e-06,
      "loss": 0.133,
      "step": 7529
    },
    {
      "epoch": 0.5851725209822817,
      "grad_norm": 0.16882652044296265,
      "learning_rate": 7.074137395088593e-06,
      "loss": 0.0594,
      "step": 7530
    },
    {
      "epoch": 0.5852502331364625,
      "grad_norm": 0.45516112446784973,
      "learning_rate": 7.073748834317688e-06,
      "loss": 0.4778,
      "step": 7531
    },
    {
      "epoch": 0.5853279452906435,
      "grad_norm": 0.4897182583808899,
      "learning_rate": 7.073360273546784e-06,
      "loss": 0.2639,
      "step": 7532
    },
    {
      "epoch": 0.5854056574448244,
      "grad_norm": 0.3358844816684723,
      "learning_rate": 7.072971712775879e-06,
      "loss": 0.2163,
      "step": 7533
    },
    {
      "epoch": 0.5854833695990053,
      "grad_norm": 1.0061956644058228,
      "learning_rate": 7.0725831520049735e-06,
      "loss": 0.9893,
      "step": 7534
    },
    {
      "epoch": 0.5855610817531862,
      "grad_norm": 0.32667675614356995,
      "learning_rate": 7.072194591234069e-06,
      "loss": 0.093,
      "step": 7535
    },
    {
      "epoch": 0.5856387939073671,
      "grad_norm": 0.5605327486991882,
      "learning_rate": 7.071806030463165e-06,
      "loss": 0.1785,
      "step": 7536
    },
    {
      "epoch": 0.585716506061548,
      "grad_norm": 0.5762791037559509,
      "learning_rate": 7.07141746969226e-06,
      "loss": 0.3091,
      "step": 7537
    },
    {
      "epoch": 0.585794218215729,
      "grad_norm": 0.21106117963790894,
      "learning_rate": 7.071028908921356e-06,
      "loss": 0.0763,
      "step": 7538
    },
    {
      "epoch": 0.5858719303699098,
      "grad_norm": 0.22599732875823975,
      "learning_rate": 7.070640348150452e-06,
      "loss": 0.1807,
      "step": 7539
    },
    {
      "epoch": 0.5859496425240908,
      "grad_norm": 0.07305143028497696,
      "learning_rate": 7.070251787379547e-06,
      "loss": 0.0106,
      "step": 7540
    },
    {
      "epoch": 0.5860273546782717,
      "grad_norm": 0.8709781169891357,
      "learning_rate": 7.069863226608642e-06,
      "loss": 0.3193,
      "step": 7541
    },
    {
      "epoch": 0.5861050668324526,
      "grad_norm": 0.4195297062397003,
      "learning_rate": 7.069474665837738e-06,
      "loss": 0.2525,
      "step": 7542
    },
    {
      "epoch": 0.5861827789866335,
      "grad_norm": 0.15862233936786652,
      "learning_rate": 7.069086105066834e-06,
      "loss": 0.0325,
      "step": 7543
    },
    {
      "epoch": 0.5862604911408145,
      "grad_norm": 0.4879022240638733,
      "learning_rate": 7.068697544295928e-06,
      "loss": 0.4558,
      "step": 7544
    },
    {
      "epoch": 0.5863382032949953,
      "grad_norm": 0.6529334187507629,
      "learning_rate": 7.068308983525024e-06,
      "loss": 0.2215,
      "step": 7545
    },
    {
      "epoch": 0.5864159154491763,
      "grad_norm": 0.33393144607543945,
      "learning_rate": 7.06792042275412e-06,
      "loss": 0.2503,
      "step": 7546
    },
    {
      "epoch": 0.5864936276033572,
      "grad_norm": 0.5436006188392639,
      "learning_rate": 7.067531861983215e-06,
      "loss": 0.1041,
      "step": 7547
    },
    {
      "epoch": 0.5865713397575381,
      "grad_norm": 0.3087303638458252,
      "learning_rate": 7.06714330121231e-06,
      "loss": 0.0605,
      "step": 7548
    },
    {
      "epoch": 0.586649051911719,
      "grad_norm": 0.15391728281974792,
      "learning_rate": 7.066754740441406e-06,
      "loss": 0.044,
      "step": 7549
    },
    {
      "epoch": 0.5867267640658999,
      "grad_norm": 0.19419166445732117,
      "learning_rate": 7.066366179670501e-06,
      "loss": 0.1242,
      "step": 7550
    },
    {
      "epoch": 0.5868044762200808,
      "grad_norm": 0.7186827659606934,
      "learning_rate": 7.065977618899597e-06,
      "loss": 0.4715,
      "step": 7551
    },
    {
      "epoch": 0.5868821883742618,
      "grad_norm": 0.6180292963981628,
      "learning_rate": 7.065589058128693e-06,
      "loss": 0.5451,
      "step": 7552
    },
    {
      "epoch": 0.5869599005284426,
      "grad_norm": 0.7858127355575562,
      "learning_rate": 7.065200497357787e-06,
      "loss": 0.3857,
      "step": 7553
    },
    {
      "epoch": 0.5870376126826236,
      "grad_norm": 0.35088175535202026,
      "learning_rate": 7.064811936586883e-06,
      "loss": 0.1146,
      "step": 7554
    },
    {
      "epoch": 0.5871153248368045,
      "grad_norm": 0.12659892439842224,
      "learning_rate": 7.0644233758159784e-06,
      "loss": 0.0172,
      "step": 7555
    },
    {
      "epoch": 0.5871930369909854,
      "grad_norm": 0.39932066202163696,
      "learning_rate": 7.064034815045073e-06,
      "loss": 0.163,
      "step": 7556
    },
    {
      "epoch": 0.5872707491451663,
      "grad_norm": 0.4062567949295044,
      "learning_rate": 7.063646254274169e-06,
      "loss": 0.2764,
      "step": 7557
    },
    {
      "epoch": 0.5873484612993473,
      "grad_norm": 0.49469542503356934,
      "learning_rate": 7.063257693503265e-06,
      "loss": 0.2984,
      "step": 7558
    },
    {
      "epoch": 0.5874261734535281,
      "grad_norm": 0.23127001523971558,
      "learning_rate": 7.06286913273236e-06,
      "loss": 0.09,
      "step": 7559
    },
    {
      "epoch": 0.587503885607709,
      "grad_norm": 0.37485405802726746,
      "learning_rate": 7.062480571961455e-06,
      "loss": 0.1076,
      "step": 7560
    },
    {
      "epoch": 0.58758159776189,
      "grad_norm": 0.260996013879776,
      "learning_rate": 7.062092011190551e-06,
      "loss": 0.1163,
      "step": 7561
    },
    {
      "epoch": 0.5876593099160708,
      "grad_norm": 0.41491320729255676,
      "learning_rate": 7.061703450419646e-06,
      "loss": 0.1362,
      "step": 7562
    },
    {
      "epoch": 0.5877370220702518,
      "grad_norm": 0.11061112582683563,
      "learning_rate": 7.0613148896487414e-06,
      "loss": 0.0475,
      "step": 7563
    },
    {
      "epoch": 0.5878147342244328,
      "grad_norm": 0.21830135583877563,
      "learning_rate": 7.060926328877837e-06,
      "loss": 0.0658,
      "step": 7564
    },
    {
      "epoch": 0.5878924463786136,
      "grad_norm": 0.2769813537597656,
      "learning_rate": 7.060537768106932e-06,
      "loss": 0.2475,
      "step": 7565
    },
    {
      "epoch": 0.5879701585327946,
      "grad_norm": 0.3541744351387024,
      "learning_rate": 7.060149207336028e-06,
      "loss": 0.3232,
      "step": 7566
    },
    {
      "epoch": 0.5880478706869754,
      "grad_norm": 0.3053854703903198,
      "learning_rate": 7.059760646565124e-06,
      "loss": 0.101,
      "step": 7567
    },
    {
      "epoch": 0.5881255828411563,
      "grad_norm": 0.31418612599372864,
      "learning_rate": 7.059372085794218e-06,
      "loss": 0.1166,
      "step": 7568
    },
    {
      "epoch": 0.5882032949953373,
      "grad_norm": 0.43335407972335815,
      "learning_rate": 7.058983525023314e-06,
      "loss": 0.773,
      "step": 7569
    },
    {
      "epoch": 0.5882810071495181,
      "grad_norm": 0.37025243043899536,
      "learning_rate": 7.0585949642524095e-06,
      "loss": 0.0965,
      "step": 7570
    },
    {
      "epoch": 0.5883587193036991,
      "grad_norm": 0.19914911687374115,
      "learning_rate": 7.058206403481504e-06,
      "loss": 0.1001,
      "step": 7571
    },
    {
      "epoch": 0.58843643145788,
      "grad_norm": 0.24410440027713776,
      "learning_rate": 7.0578178427106e-06,
      "loss": 0.0508,
      "step": 7572
    },
    {
      "epoch": 0.5885141436120609,
      "grad_norm": 0.4042949080467224,
      "learning_rate": 7.057429281939696e-06,
      "loss": 0.1313,
      "step": 7573
    },
    {
      "epoch": 0.5885918557662418,
      "grad_norm": 0.15421393513679504,
      "learning_rate": 7.057040721168792e-06,
      "loss": 0.0729,
      "step": 7574
    },
    {
      "epoch": 0.5886695679204228,
      "grad_norm": 0.11831468343734741,
      "learning_rate": 7.056652160397887e-06,
      "loss": 0.0254,
      "step": 7575
    },
    {
      "epoch": 0.5887472800746036,
      "grad_norm": 0.4475204646587372,
      "learning_rate": 7.0562635996269826e-06,
      "loss": 0.157,
      "step": 7576
    },
    {
      "epoch": 0.5888249922287846,
      "grad_norm": 0.28554415702819824,
      "learning_rate": 7.055875038856078e-06,
      "loss": 0.0898,
      "step": 7577
    },
    {
      "epoch": 0.5889027043829655,
      "grad_norm": 0.27498307824134827,
      "learning_rate": 7.0554864780851725e-06,
      "loss": 0.0592,
      "step": 7578
    },
    {
      "epoch": 0.5889804165371464,
      "grad_norm": 0.07125025987625122,
      "learning_rate": 7.055097917314268e-06,
      "loss": 0.0155,
      "step": 7579
    },
    {
      "epoch": 0.5890581286913273,
      "grad_norm": 0.6509348750114441,
      "learning_rate": 7.054709356543364e-06,
      "loss": 0.706,
      "step": 7580
    },
    {
      "epoch": 0.5891358408455082,
      "grad_norm": 0.3313741683959961,
      "learning_rate": 7.054320795772459e-06,
      "loss": 0.167,
      "step": 7581
    },
    {
      "epoch": 0.5892135529996891,
      "grad_norm": 0.30934369564056396,
      "learning_rate": 7.053932235001555e-06,
      "loss": 0.0769,
      "step": 7582
    },
    {
      "epoch": 0.5892912651538701,
      "grad_norm": 0.9548863172531128,
      "learning_rate": 7.053543674230651e-06,
      "loss": 0.3662,
      "step": 7583
    },
    {
      "epoch": 0.5893689773080509,
      "grad_norm": 0.32834354043006897,
      "learning_rate": 7.0531551134597455e-06,
      "loss": 0.0888,
      "step": 7584
    },
    {
      "epoch": 0.5894466894622319,
      "grad_norm": 0.18505926430225372,
      "learning_rate": 7.052766552688841e-06,
      "loss": 0.0412,
      "step": 7585
    },
    {
      "epoch": 0.5895244016164128,
      "grad_norm": 0.2762557864189148,
      "learning_rate": 7.052377991917937e-06,
      "loss": 0.1154,
      "step": 7586
    },
    {
      "epoch": 0.5896021137705937,
      "grad_norm": 0.21040940284729004,
      "learning_rate": 7.051989431147031e-06,
      "loss": 0.0429,
      "step": 7587
    },
    {
      "epoch": 0.5896798259247746,
      "grad_norm": 0.5137932896614075,
      "learning_rate": 7.051600870376127e-06,
      "loss": 0.211,
      "step": 7588
    },
    {
      "epoch": 0.5897575380789556,
      "grad_norm": 1.083964467048645,
      "learning_rate": 7.051212309605223e-06,
      "loss": 0.3993,
      "step": 7589
    },
    {
      "epoch": 0.5898352502331364,
      "grad_norm": 0.6768204569816589,
      "learning_rate": 7.050823748834318e-06,
      "loss": 0.3303,
      "step": 7590
    },
    {
      "epoch": 0.5899129623873174,
      "grad_norm": 0.19111183285713196,
      "learning_rate": 7.050435188063414e-06,
      "loss": 0.0737,
      "step": 7591
    },
    {
      "epoch": 0.5899906745414983,
      "grad_norm": 0.16684986650943756,
      "learning_rate": 7.050046627292509e-06,
      "loss": 0.088,
      "step": 7592
    },
    {
      "epoch": 0.5900683866956792,
      "grad_norm": 0.8167971968650818,
      "learning_rate": 7.049658066521604e-06,
      "loss": 0.7099,
      "step": 7593
    },
    {
      "epoch": 0.5901460988498601,
      "grad_norm": 0.32818129658699036,
      "learning_rate": 7.0492695057507e-06,
      "loss": 0.4769,
      "step": 7594
    },
    {
      "epoch": 0.590223811004041,
      "grad_norm": 0.30057889223098755,
      "learning_rate": 7.048880944979796e-06,
      "loss": 0.1128,
      "step": 7595
    },
    {
      "epoch": 0.5903015231582219,
      "grad_norm": 0.4622868299484253,
      "learning_rate": 7.04849238420889e-06,
      "loss": 0.3045,
      "step": 7596
    },
    {
      "epoch": 0.5903792353124029,
      "grad_norm": 0.15592195093631744,
      "learning_rate": 7.048103823437986e-06,
      "loss": 0.0303,
      "step": 7597
    },
    {
      "epoch": 0.5904569474665837,
      "grad_norm": 0.4312571585178375,
      "learning_rate": 7.047715262667082e-06,
      "loss": 0.1185,
      "step": 7598
    },
    {
      "epoch": 0.5905346596207647,
      "grad_norm": 0.6655487418174744,
      "learning_rate": 7.0473267018961766e-06,
      "loss": 0.3216,
      "step": 7599
    },
    {
      "epoch": 0.5906123717749456,
      "grad_norm": 0.5251752734184265,
      "learning_rate": 7.046938141125272e-06,
      "loss": 0.3146,
      "step": 7600
    },
    {
      "epoch": 0.5906900839291265,
      "grad_norm": 0.3900584578514099,
      "learning_rate": 7.046549580354368e-06,
      "loss": 0.253,
      "step": 7601
    },
    {
      "epoch": 0.5907677960833074,
      "grad_norm": 0.4145088791847229,
      "learning_rate": 7.046161019583463e-06,
      "loss": 0.2207,
      "step": 7602
    },
    {
      "epoch": 0.5908455082374884,
      "grad_norm": 0.7034107446670532,
      "learning_rate": 7.045772458812559e-06,
      "loss": 0.3532,
      "step": 7603
    },
    {
      "epoch": 0.5909232203916692,
      "grad_norm": 0.465932160615921,
      "learning_rate": 7.045383898041655e-06,
      "loss": 0.4421,
      "step": 7604
    },
    {
      "epoch": 0.5910009325458502,
      "grad_norm": 0.39806246757507324,
      "learning_rate": 7.0449953372707505e-06,
      "loss": 0.0729,
      "step": 7605
    },
    {
      "epoch": 0.5910786447000311,
      "grad_norm": 0.39948394894599915,
      "learning_rate": 7.044606776499845e-06,
      "loss": 0.09,
      "step": 7606
    },
    {
      "epoch": 0.591156356854212,
      "grad_norm": 0.1954817771911621,
      "learning_rate": 7.04421821572894e-06,
      "loss": 0.0886,
      "step": 7607
    },
    {
      "epoch": 0.5912340690083929,
      "grad_norm": 0.4969186782836914,
      "learning_rate": 7.043829654958036e-06,
      "loss": 0.0781,
      "step": 7608
    },
    {
      "epoch": 0.5913117811625739,
      "grad_norm": 0.5017286539077759,
      "learning_rate": 7.043441094187131e-06,
      "loss": 0.5419,
      "step": 7609
    },
    {
      "epoch": 0.5913894933167547,
      "grad_norm": 0.440684050321579,
      "learning_rate": 7.043052533416227e-06,
      "loss": 0.0861,
      "step": 7610
    },
    {
      "epoch": 0.5914672054709357,
      "grad_norm": 0.45332100987434387,
      "learning_rate": 7.042663972645323e-06,
      "loss": 0.1568,
      "step": 7611
    },
    {
      "epoch": 0.5915449176251165,
      "grad_norm": 0.30178752541542053,
      "learning_rate": 7.042275411874418e-06,
      "loss": 0.1555,
      "step": 7612
    },
    {
      "epoch": 0.5916226297792975,
      "grad_norm": 0.2581969201564789,
      "learning_rate": 7.0418868511035135e-06,
      "loss": 0.0492,
      "step": 7613
    },
    {
      "epoch": 0.5917003419334784,
      "grad_norm": 0.28549614548683167,
      "learning_rate": 7.041498290332609e-06,
      "loss": 0.0491,
      "step": 7614
    },
    {
      "epoch": 0.5917780540876593,
      "grad_norm": 0.3771209418773651,
      "learning_rate": 7.041109729561703e-06,
      "loss": 0.199,
      "step": 7615
    },
    {
      "epoch": 0.5918557662418402,
      "grad_norm": 0.496676504611969,
      "learning_rate": 7.040721168790799e-06,
      "loss": 0.1036,
      "step": 7616
    },
    {
      "epoch": 0.5919334783960212,
      "grad_norm": 0.20094868540763855,
      "learning_rate": 7.040332608019895e-06,
      "loss": 0.0468,
      "step": 7617
    },
    {
      "epoch": 0.592011190550202,
      "grad_norm": 0.8026643991470337,
      "learning_rate": 7.03994404724899e-06,
      "loss": 0.2203,
      "step": 7618
    },
    {
      "epoch": 0.592088902704383,
      "grad_norm": 0.15628209710121155,
      "learning_rate": 7.039555486478086e-06,
      "loss": 0.0999,
      "step": 7619
    },
    {
      "epoch": 0.5921666148585639,
      "grad_norm": 0.2805584967136383,
      "learning_rate": 7.0391669257071815e-06,
      "loss": 0.0542,
      "step": 7620
    },
    {
      "epoch": 0.5922443270127448,
      "grad_norm": 0.38929182291030884,
      "learning_rate": 7.0387783649362765e-06,
      "loss": 0.0858,
      "step": 7621
    },
    {
      "epoch": 0.5923220391669257,
      "grad_norm": 0.48900431394577026,
      "learning_rate": 7.038389804165372e-06,
      "loss": 0.2004,
      "step": 7622
    },
    {
      "epoch": 0.5923997513211067,
      "grad_norm": 0.6908445954322815,
      "learning_rate": 7.038001243394468e-06,
      "loss": 0.3777,
      "step": 7623
    },
    {
      "epoch": 0.5924774634752875,
      "grad_norm": 0.10691192746162415,
      "learning_rate": 7.037612682623562e-06,
      "loss": 0.0533,
      "step": 7624
    },
    {
      "epoch": 0.5925551756294685,
      "grad_norm": 0.6114780902862549,
      "learning_rate": 7.037224121852658e-06,
      "loss": 0.3786,
      "step": 7625
    },
    {
      "epoch": 0.5926328877836493,
      "grad_norm": 0.6448121666908264,
      "learning_rate": 7.036835561081754e-06,
      "loss": 0.2673,
      "step": 7626
    },
    {
      "epoch": 0.5927105999378303,
      "grad_norm": 0.2502340078353882,
      "learning_rate": 7.036447000310849e-06,
      "loss": 0.2374,
      "step": 7627
    },
    {
      "epoch": 0.5927883120920112,
      "grad_norm": 0.5362331867218018,
      "learning_rate": 7.0360584395399445e-06,
      "loss": 0.1709,
      "step": 7628
    },
    {
      "epoch": 0.5928660242461921,
      "grad_norm": 0.2742405831813812,
      "learning_rate": 7.03566987876904e-06,
      "loss": 0.0634,
      "step": 7629
    },
    {
      "epoch": 0.592943736400373,
      "grad_norm": 0.5021845102310181,
      "learning_rate": 7.035281317998135e-06,
      "loss": 0.4163,
      "step": 7630
    },
    {
      "epoch": 0.593021448554554,
      "grad_norm": 0.12688779830932617,
      "learning_rate": 7.034892757227231e-06,
      "loss": 0.0286,
      "step": 7631
    },
    {
      "epoch": 0.5930991607087348,
      "grad_norm": 0.07890475541353226,
      "learning_rate": 7.034504196456327e-06,
      "loss": 0.0231,
      "step": 7632
    },
    {
      "epoch": 0.5931768728629158,
      "grad_norm": 0.2736741304397583,
      "learning_rate": 7.034115635685423e-06,
      "loss": 0.0516,
      "step": 7633
    },
    {
      "epoch": 0.5932545850170967,
      "grad_norm": 0.4415680468082428,
      "learning_rate": 7.033727074914517e-06,
      "loss": 0.4099,
      "step": 7634
    },
    {
      "epoch": 0.5933322971712776,
      "grad_norm": 0.7089345455169678,
      "learning_rate": 7.0333385141436125e-06,
      "loss": 0.2887,
      "step": 7635
    },
    {
      "epoch": 0.5934100093254585,
      "grad_norm": 0.4210244417190552,
      "learning_rate": 7.032949953372708e-06,
      "loss": 0.259,
      "step": 7636
    },
    {
      "epoch": 0.5934877214796395,
      "grad_norm": 0.1790260225534439,
      "learning_rate": 7.032561392601803e-06,
      "loss": 0.0654,
      "step": 7637
    },
    {
      "epoch": 0.5935654336338203,
      "grad_norm": 0.2047354280948639,
      "learning_rate": 7.032172831830899e-06,
      "loss": 0.1325,
      "step": 7638
    },
    {
      "epoch": 0.5936431457880013,
      "grad_norm": 0.24534323811531067,
      "learning_rate": 7.031784271059995e-06,
      "loss": 0.0873,
      "step": 7639
    },
    {
      "epoch": 0.5937208579421822,
      "grad_norm": 0.35071060061454773,
      "learning_rate": 7.03139571028909e-06,
      "loss": 0.2222,
      "step": 7640
    },
    {
      "epoch": 0.593798570096363,
      "grad_norm": 0.23328588902950287,
      "learning_rate": 7.031007149518186e-06,
      "loss": 0.0349,
      "step": 7641
    },
    {
      "epoch": 0.593876282250544,
      "grad_norm": 0.039206042885780334,
      "learning_rate": 7.0306185887472814e-06,
      "loss": 0.0039,
      "step": 7642
    },
    {
      "epoch": 0.5939539944047248,
      "grad_norm": 0.574036717414856,
      "learning_rate": 7.0302300279763755e-06,
      "loss": 0.3054,
      "step": 7643
    },
    {
      "epoch": 0.5940317065589058,
      "grad_norm": 0.17956598103046417,
      "learning_rate": 7.029841467205471e-06,
      "loss": 0.0313,
      "step": 7644
    },
    {
      "epoch": 0.5941094187130868,
      "grad_norm": 0.11403860151767731,
      "learning_rate": 7.029452906434567e-06,
      "loss": 0.0243,
      "step": 7645
    },
    {
      "epoch": 0.5941871308672676,
      "grad_norm": 1.2218420505523682,
      "learning_rate": 7.029064345663662e-06,
      "loss": 0.8126,
      "step": 7646
    },
    {
      "epoch": 0.5942648430214486,
      "grad_norm": 0.4104749262332916,
      "learning_rate": 7.028675784892758e-06,
      "loss": 0.1683,
      "step": 7647
    },
    {
      "epoch": 0.5943425551756295,
      "grad_norm": 0.2104121893644333,
      "learning_rate": 7.028287224121854e-06,
      "loss": 0.1117,
      "step": 7648
    },
    {
      "epoch": 0.5944202673298103,
      "grad_norm": 0.07938756048679352,
      "learning_rate": 7.027898663350949e-06,
      "loss": 0.0235,
      "step": 7649
    },
    {
      "epoch": 0.5944979794839913,
      "grad_norm": 0.5157926082611084,
      "learning_rate": 7.027510102580044e-06,
      "loss": 0.1268,
      "step": 7650
    },
    {
      "epoch": 0.5945756916381723,
      "grad_norm": 0.42898231744766235,
      "learning_rate": 7.02712154180914e-06,
      "loss": 0.2129,
      "step": 7651
    },
    {
      "epoch": 0.5946534037923531,
      "grad_norm": 0.5559858083724976,
      "learning_rate": 7.026732981038234e-06,
      "loss": 0.3448,
      "step": 7652
    },
    {
      "epoch": 0.594731115946534,
      "grad_norm": 0.6873824596405029,
      "learning_rate": 7.02634442026733e-06,
      "loss": 0.7988,
      "step": 7653
    },
    {
      "epoch": 0.594808828100715,
      "grad_norm": 0.6164431571960449,
      "learning_rate": 7.025955859496426e-06,
      "loss": 0.4706,
      "step": 7654
    },
    {
      "epoch": 0.5948865402548958,
      "grad_norm": 0.29513227939605713,
      "learning_rate": 7.025567298725521e-06,
      "loss": 0.0968,
      "step": 7655
    },
    {
      "epoch": 0.5949642524090768,
      "grad_norm": 0.31067323684692383,
      "learning_rate": 7.025178737954617e-06,
      "loss": 0.0123,
      "step": 7656
    },
    {
      "epoch": 0.5950419645632576,
      "grad_norm": 0.4478258788585663,
      "learning_rate": 7.0247901771837125e-06,
      "loss": 0.4305,
      "step": 7657
    },
    {
      "epoch": 0.5951196767174386,
      "grad_norm": 0.5420200228691101,
      "learning_rate": 7.024401616412807e-06,
      "loss": 0.9933,
      "step": 7658
    },
    {
      "epoch": 0.5951973888716195,
      "grad_norm": 0.6927140355110168,
      "learning_rate": 7.024013055641903e-06,
      "loss": 0.3521,
      "step": 7659
    },
    {
      "epoch": 0.5952751010258004,
      "grad_norm": 0.2636372148990631,
      "learning_rate": 7.023624494870999e-06,
      "loss": 0.0475,
      "step": 7660
    },
    {
      "epoch": 0.5953528131799813,
      "grad_norm": 0.4178749620914459,
      "learning_rate": 7.023235934100093e-06,
      "loss": 0.1512,
      "step": 7661
    },
    {
      "epoch": 0.5954305253341623,
      "grad_norm": 0.09803098440170288,
      "learning_rate": 7.022847373329189e-06,
      "loss": 0.0361,
      "step": 7662
    },
    {
      "epoch": 0.5955082374883431,
      "grad_norm": 0.2298036515712738,
      "learning_rate": 7.022458812558285e-06,
      "loss": 0.1123,
      "step": 7663
    },
    {
      "epoch": 0.5955859496425241,
      "grad_norm": 0.6024230718612671,
      "learning_rate": 7.0220702517873805e-06,
      "loss": 0.4637,
      "step": 7664
    },
    {
      "epoch": 0.595663661796705,
      "grad_norm": 0.3012263774871826,
      "learning_rate": 7.0216816910164754e-06,
      "loss": 0.2591,
      "step": 7665
    },
    {
      "epoch": 0.5957413739508859,
      "grad_norm": 0.42673638463020325,
      "learning_rate": 7.021293130245571e-06,
      "loss": 0.3098,
      "step": 7666
    },
    {
      "epoch": 0.5958190861050668,
      "grad_norm": 0.3942693769931793,
      "learning_rate": 7.020904569474667e-06,
      "loss": 0.356,
      "step": 7667
    },
    {
      "epoch": 0.5958967982592478,
      "grad_norm": 0.42814570665359497,
      "learning_rate": 7.020516008703762e-06,
      "loss": 0.1801,
      "step": 7668
    },
    {
      "epoch": 0.5959745104134286,
      "grad_norm": 0.8101379871368408,
      "learning_rate": 7.020127447932858e-06,
      "loss": 0.2142,
      "step": 7669
    },
    {
      "epoch": 0.5960522225676096,
      "grad_norm": 1.24962317943573,
      "learning_rate": 7.019738887161954e-06,
      "loss": 0.761,
      "step": 7670
    },
    {
      "epoch": 0.5961299347217904,
      "grad_norm": 0.20835354924201965,
      "learning_rate": 7.019350326391048e-06,
      "loss": 0.0949,
      "step": 7671
    },
    {
      "epoch": 0.5962076468759714,
      "grad_norm": 0.6052783131599426,
      "learning_rate": 7.0189617656201435e-06,
      "loss": 0.2748,
      "step": 7672
    },
    {
      "epoch": 0.5962853590301523,
      "grad_norm": 0.1480357050895691,
      "learning_rate": 7.018573204849239e-06,
      "loss": 0.0453,
      "step": 7673
    },
    {
      "epoch": 0.5963630711843332,
      "grad_norm": 0.33021536469459534,
      "learning_rate": 7.018184644078334e-06,
      "loss": 0.2249,
      "step": 7674
    },
    {
      "epoch": 0.5964407833385141,
      "grad_norm": 0.4626917243003845,
      "learning_rate": 7.01779608330743e-06,
      "loss": 0.4814,
      "step": 7675
    },
    {
      "epoch": 0.5965184954926951,
      "grad_norm": 0.5722681879997253,
      "learning_rate": 7.017407522536526e-06,
      "loss": 0.2592,
      "step": 7676
    },
    {
      "epoch": 0.5965962076468759,
      "grad_norm": 0.1117958128452301,
      "learning_rate": 7.017018961765621e-06,
      "loss": 0.0561,
      "step": 7677
    },
    {
      "epoch": 0.5966739198010569,
      "grad_norm": 0.21194137632846832,
      "learning_rate": 7.0166304009947166e-06,
      "loss": 0.1195,
      "step": 7678
    },
    {
      "epoch": 0.5967516319552378,
      "grad_norm": 0.3255866765975952,
      "learning_rate": 7.016241840223812e-06,
      "loss": 0.1384,
      "step": 7679
    },
    {
      "epoch": 0.5968293441094187,
      "grad_norm": 0.41855278611183167,
      "learning_rate": 7.0158532794529065e-06,
      "loss": 0.1557,
      "step": 7680
    },
    {
      "epoch": 0.5969070562635996,
      "grad_norm": 0.4887985289096832,
      "learning_rate": 7.015464718682002e-06,
      "loss": 0.1506,
      "step": 7681
    },
    {
      "epoch": 0.5969847684177806,
      "grad_norm": 0.5727244019508362,
      "learning_rate": 7.015076157911098e-06,
      "loss": 0.2519,
      "step": 7682
    },
    {
      "epoch": 0.5970624805719614,
      "grad_norm": 1.0765472650527954,
      "learning_rate": 7.014687597140193e-06,
      "loss": 0.5783,
      "step": 7683
    },
    {
      "epoch": 0.5971401927261424,
      "grad_norm": 0.23552417755126953,
      "learning_rate": 7.014299036369289e-06,
      "loss": 0.0772,
      "step": 7684
    },
    {
      "epoch": 0.5972179048803233,
      "grad_norm": 0.31163567304611206,
      "learning_rate": 7.013910475598385e-06,
      "loss": 0.1388,
      "step": 7685
    },
    {
      "epoch": 0.5972956170345042,
      "grad_norm": 0.35313260555267334,
      "learning_rate": 7.0135219148274795e-06,
      "loss": 0.1816,
      "step": 7686
    },
    {
      "epoch": 0.5973733291886851,
      "grad_norm": 0.4386555254459381,
      "learning_rate": 7.0131333540565745e-06,
      "loss": 0.2053,
      "step": 7687
    },
    {
      "epoch": 0.597451041342866,
      "grad_norm": 0.22312742471694946,
      "learning_rate": 7.01274479328567e-06,
      "loss": 0.0803,
      "step": 7688
    },
    {
      "epoch": 0.5975287534970469,
      "grad_norm": 0.28914546966552734,
      "learning_rate": 7.012356232514765e-06,
      "loss": 0.1529,
      "step": 7689
    },
    {
      "epoch": 0.5976064656512279,
      "grad_norm": 0.3965957462787628,
      "learning_rate": 7.011967671743861e-06,
      "loss": 0.1797,
      "step": 7690
    },
    {
      "epoch": 0.5976841778054087,
      "grad_norm": 1.1136236190795898,
      "learning_rate": 7.011579110972957e-06,
      "loss": 0.2456,
      "step": 7691
    },
    {
      "epoch": 0.5977618899595897,
      "grad_norm": 0.39110440015792847,
      "learning_rate": 7.011190550202052e-06,
      "loss": 0.1049,
      "step": 7692
    },
    {
      "epoch": 0.5978396021137706,
      "grad_norm": 0.5962867140769958,
      "learning_rate": 7.010801989431148e-06,
      "loss": 0.464,
      "step": 7693
    },
    {
      "epoch": 0.5979173142679515,
      "grad_norm": 0.4610554873943329,
      "learning_rate": 7.010413428660243e-06,
      "loss": 0.1326,
      "step": 7694
    },
    {
      "epoch": 0.5979950264221324,
      "grad_norm": 0.09320791810750961,
      "learning_rate": 7.010024867889339e-06,
      "loss": 0.0224,
      "step": 7695
    },
    {
      "epoch": 0.5980727385763134,
      "grad_norm": 0.14970538020133972,
      "learning_rate": 7.009636307118433e-06,
      "loss": 0.0344,
      "step": 7696
    },
    {
      "epoch": 0.5981504507304942,
      "grad_norm": 0.40233224630355835,
      "learning_rate": 7.009247746347529e-06,
      "loss": 0.1422,
      "step": 7697
    },
    {
      "epoch": 0.5982281628846752,
      "grad_norm": 1.191349983215332,
      "learning_rate": 7.008859185576625e-06,
      "loss": 1.5155,
      "step": 7698
    },
    {
      "epoch": 0.5983058750388561,
      "grad_norm": 0.5101439356803894,
      "learning_rate": 7.00847062480572e-06,
      "loss": 0.0952,
      "step": 7699
    },
    {
      "epoch": 0.598383587193037,
      "grad_norm": 0.5072318911552429,
      "learning_rate": 7.008082064034816e-06,
      "loss": 0.1131,
      "step": 7700
    },
    {
      "epoch": 0.5984612993472179,
      "grad_norm": 0.6413260698318481,
      "learning_rate": 7.007693503263911e-06,
      "loss": 0.1413,
      "step": 7701
    },
    {
      "epoch": 0.5985390115013988,
      "grad_norm": 0.2362375259399414,
      "learning_rate": 7.007304942493006e-06,
      "loss": 0.0666,
      "step": 7702
    },
    {
      "epoch": 0.5986167236555797,
      "grad_norm": 0.7041454315185547,
      "learning_rate": 7.006916381722102e-06,
      "loss": 0.5154,
      "step": 7703
    },
    {
      "epoch": 0.5986944358097607,
      "grad_norm": 0.3224240839481354,
      "learning_rate": 7.006527820951198e-06,
      "loss": 0.1507,
      "step": 7704
    },
    {
      "epoch": 0.5987721479639415,
      "grad_norm": 0.8580989241600037,
      "learning_rate": 7.006139260180292e-06,
      "loss": 0.1733,
      "step": 7705
    },
    {
      "epoch": 0.5988498601181225,
      "grad_norm": 0.9354609251022339,
      "learning_rate": 7.005750699409388e-06,
      "loss": 0.2944,
      "step": 7706
    },
    {
      "epoch": 0.5989275722723034,
      "grad_norm": 0.336575448513031,
      "learning_rate": 7.005362138638484e-06,
      "loss": 0.1013,
      "step": 7707
    },
    {
      "epoch": 0.5990052844264843,
      "grad_norm": 0.2818085551261902,
      "learning_rate": 7.004973577867579e-06,
      "loss": 0.2637,
      "step": 7708
    },
    {
      "epoch": 0.5990829965806652,
      "grad_norm": 0.7055681347846985,
      "learning_rate": 7.004585017096674e-06,
      "loss": 0.2956,
      "step": 7709
    },
    {
      "epoch": 0.5991607087348462,
      "grad_norm": 0.8232301473617554,
      "learning_rate": 7.00419645632577e-06,
      "loss": 0.4269,
      "step": 7710
    },
    {
      "epoch": 0.599238420889027,
      "grad_norm": 0.9017685651779175,
      "learning_rate": 7.003807895554865e-06,
      "loss": 0.5505,
      "step": 7711
    },
    {
      "epoch": 0.599316133043208,
      "grad_norm": 0.3048924207687378,
      "learning_rate": 7.003419334783961e-06,
      "loss": 0.0912,
      "step": 7712
    },
    {
      "epoch": 0.5993938451973889,
      "grad_norm": 0.10552497208118439,
      "learning_rate": 7.003030774013057e-06,
      "loss": 0.0209,
      "step": 7713
    },
    {
      "epoch": 0.5994715573515698,
      "grad_norm": 0.3945668339729309,
      "learning_rate": 7.002642213242151e-06,
      "loss": 0.2623,
      "step": 7714
    },
    {
      "epoch": 0.5995492695057507,
      "grad_norm": 0.7955232858657837,
      "learning_rate": 7.002253652471247e-06,
      "loss": 0.3162,
      "step": 7715
    },
    {
      "epoch": 0.5996269816599317,
      "grad_norm": 0.2518932819366455,
      "learning_rate": 7.0018650917003424e-06,
      "loss": 0.1409,
      "step": 7716
    },
    {
      "epoch": 0.5997046938141125,
      "grad_norm": 0.6555611491203308,
      "learning_rate": 7.001476530929437e-06,
      "loss": 0.4213,
      "step": 7717
    },
    {
      "epoch": 0.5997824059682935,
      "grad_norm": 0.22779038548469543,
      "learning_rate": 7.001087970158533e-06,
      "loss": 0.0869,
      "step": 7718
    },
    {
      "epoch": 0.5998601181224743,
      "grad_norm": 0.28358277678489685,
      "learning_rate": 7.000699409387629e-06,
      "loss": 0.3338,
      "step": 7719
    },
    {
      "epoch": 0.5999378302766553,
      "grad_norm": 0.6189860701560974,
      "learning_rate": 7.000310848616724e-06,
      "loss": 0.2946,
      "step": 7720
    },
    {
      "epoch": 0.6000155424308362,
      "grad_norm": 0.4153595566749573,
      "learning_rate": 6.99992228784582e-06,
      "loss": 0.2434,
      "step": 7721
    },
    {
      "epoch": 0.600093254585017,
      "grad_norm": 1.9418941736221313,
      "learning_rate": 6.9995337270749155e-06,
      "loss": 0.3894,
      "step": 7722
    },
    {
      "epoch": 0.600170966739198,
      "grad_norm": 0.12020409852266312,
      "learning_rate": 6.99914516630401e-06,
      "loss": 0.0131,
      "step": 7723
    },
    {
      "epoch": 0.600248678893379,
      "grad_norm": 0.24570687115192413,
      "learning_rate": 6.9987566055331054e-06,
      "loss": 0.0578,
      "step": 7724
    },
    {
      "epoch": 0.6003263910475598,
      "grad_norm": 0.2847144603729248,
      "learning_rate": 6.998368044762201e-06,
      "loss": 0.0599,
      "step": 7725
    },
    {
      "epoch": 0.6004041032017408,
      "grad_norm": 0.11487027257680893,
      "learning_rate": 6.997979483991297e-06,
      "loss": 0.0212,
      "step": 7726
    },
    {
      "epoch": 0.6004818153559217,
      "grad_norm": 0.2223082035779953,
      "learning_rate": 6.997590923220392e-06,
      "loss": 0.0541,
      "step": 7727
    },
    {
      "epoch": 0.6005595275101026,
      "grad_norm": 0.3367334306240082,
      "learning_rate": 6.997202362449488e-06,
      "loss": 0.0913,
      "step": 7728
    },
    {
      "epoch": 0.6006372396642835,
      "grad_norm": 0.2643873989582062,
      "learning_rate": 6.9968138016785836e-06,
      "loss": 0.2122,
      "step": 7729
    },
    {
      "epoch": 0.6007149518184645,
      "grad_norm": 0.15646623075008392,
      "learning_rate": 6.9964252409076785e-06,
      "loss": 0.1154,
      "step": 7730
    },
    {
      "epoch": 0.6007926639726453,
      "grad_norm": 0.2816087603569031,
      "learning_rate": 6.996036680136774e-06,
      "loss": 0.0529,
      "step": 7731
    },
    {
      "epoch": 0.6008703761268263,
      "grad_norm": 0.16446012258529663,
      "learning_rate": 6.99564811936587e-06,
      "loss": 0.0614,
      "step": 7732
    },
    {
      "epoch": 0.6009480882810071,
      "grad_norm": 0.3190912902355194,
      "learning_rate": 6.995259558594964e-06,
      "loss": 0.1062,
      "step": 7733
    },
    {
      "epoch": 0.601025800435188,
      "grad_norm": 0.38442549109458923,
      "learning_rate": 6.99487099782406e-06,
      "loss": 0.198,
      "step": 7734
    },
    {
      "epoch": 0.601103512589369,
      "grad_norm": 0.2342846840620041,
      "learning_rate": 6.994482437053156e-06,
      "loss": 0.0893,
      "step": 7735
    },
    {
      "epoch": 0.6011812247435498,
      "grad_norm": 0.49421852827072144,
      "learning_rate": 6.994093876282251e-06,
      "loss": 0.2782,
      "step": 7736
    },
    {
      "epoch": 0.6012589368977308,
      "grad_norm": 0.12396535277366638,
      "learning_rate": 6.9937053155113466e-06,
      "loss": 0.0242,
      "step": 7737
    },
    {
      "epoch": 0.6013366490519118,
      "grad_norm": 0.48849421739578247,
      "learning_rate": 6.993316754740442e-06,
      "loss": 0.2473,
      "step": 7738
    },
    {
      "epoch": 0.6014143612060926,
      "grad_norm": 0.44016724824905396,
      "learning_rate": 6.992928193969537e-06,
      "loss": 0.0533,
      "step": 7739
    },
    {
      "epoch": 0.6014920733602735,
      "grad_norm": 0.46470147371292114,
      "learning_rate": 6.992539633198633e-06,
      "loss": 0.6442,
      "step": 7740
    },
    {
      "epoch": 0.6015697855144545,
      "grad_norm": 0.21787571907043457,
      "learning_rate": 6.992151072427729e-06,
      "loss": 0.1732,
      "step": 7741
    },
    {
      "epoch": 0.6016474976686353,
      "grad_norm": 0.30814969539642334,
      "learning_rate": 6.991762511656823e-06,
      "loss": 0.2283,
      "step": 7742
    },
    {
      "epoch": 0.6017252098228163,
      "grad_norm": 0.15475675463676453,
      "learning_rate": 6.991373950885919e-06,
      "loss": 0.1194,
      "step": 7743
    },
    {
      "epoch": 0.6018029219769973,
      "grad_norm": 0.486246258020401,
      "learning_rate": 6.990985390115015e-06,
      "loss": 0.349,
      "step": 7744
    },
    {
      "epoch": 0.6018806341311781,
      "grad_norm": 0.27781474590301514,
      "learning_rate": 6.9905968293441095e-06,
      "loss": 0.1782,
      "step": 7745
    },
    {
      "epoch": 0.601958346285359,
      "grad_norm": 0.184611514210701,
      "learning_rate": 6.990208268573205e-06,
      "loss": 0.0758,
      "step": 7746
    },
    {
      "epoch": 0.6020360584395399,
      "grad_norm": 0.2742587924003601,
      "learning_rate": 6.989819707802301e-06,
      "loss": 0.1053,
      "step": 7747
    },
    {
      "epoch": 0.6021137705937208,
      "grad_norm": 0.22372843325138092,
      "learning_rate": 6.989431147031396e-06,
      "loss": 0.0878,
      "step": 7748
    },
    {
      "epoch": 0.6021914827479018,
      "grad_norm": 0.11477875709533691,
      "learning_rate": 6.989042586260492e-06,
      "loss": 0.018,
      "step": 7749
    },
    {
      "epoch": 0.6022691949020826,
      "grad_norm": 0.6500675678253174,
      "learning_rate": 6.988654025489588e-06,
      "loss": 0.2801,
      "step": 7750
    },
    {
      "epoch": 0.6023469070562636,
      "grad_norm": 0.412030428647995,
      "learning_rate": 6.988265464718682e-06,
      "loss": 0.1795,
      "step": 7751
    },
    {
      "epoch": 0.6024246192104445,
      "grad_norm": 0.431629478931427,
      "learning_rate": 6.9878769039477776e-06,
      "loss": 0.3046,
      "step": 7752
    },
    {
      "epoch": 0.6025023313646254,
      "grad_norm": 0.6392512321472168,
      "learning_rate": 6.987488343176873e-06,
      "loss": 0.2584,
      "step": 7753
    },
    {
      "epoch": 0.6025800435188063,
      "grad_norm": 0.10099592059850693,
      "learning_rate": 6.987099782405968e-06,
      "loss": 0.0102,
      "step": 7754
    },
    {
      "epoch": 0.6026577556729873,
      "grad_norm": 0.2810603380203247,
      "learning_rate": 6.986711221635064e-06,
      "loss": 0.0706,
      "step": 7755
    },
    {
      "epoch": 0.6027354678271681,
      "grad_norm": 0.4028412699699402,
      "learning_rate": 6.98632266086416e-06,
      "loss": 0.1339,
      "step": 7756
    },
    {
      "epoch": 0.6028131799813491,
      "grad_norm": 0.3270927369594574,
      "learning_rate": 6.985934100093256e-06,
      "loss": 0.2253,
      "step": 7757
    },
    {
      "epoch": 0.60289089213553,
      "grad_norm": 0.1946820318698883,
      "learning_rate": 6.985545539322351e-06,
      "loss": 0.0961,
      "step": 7758
    },
    {
      "epoch": 0.6029686042897109,
      "grad_norm": 0.21537569165229797,
      "learning_rate": 6.9851569785514465e-06,
      "loss": 0.0188,
      "step": 7759
    },
    {
      "epoch": 0.6030463164438918,
      "grad_norm": 0.11944117397069931,
      "learning_rate": 6.984768417780542e-06,
      "loss": 0.0179,
      "step": 7760
    },
    {
      "epoch": 0.6031240285980728,
      "grad_norm": 0.43823617696762085,
      "learning_rate": 6.984379857009636e-06,
      "loss": 0.5481,
      "step": 7761
    },
    {
      "epoch": 0.6032017407522536,
      "grad_norm": 0.3513718843460083,
      "learning_rate": 6.983991296238732e-06,
      "loss": 0.0896,
      "step": 7762
    },
    {
      "epoch": 0.6032794529064346,
      "grad_norm": 0.030889317393302917,
      "learning_rate": 6.983602735467828e-06,
      "loss": 0.0031,
      "step": 7763
    },
    {
      "epoch": 0.6033571650606154,
      "grad_norm": 0.9971172213554382,
      "learning_rate": 6.983214174696923e-06,
      "loss": 0.8194,
      "step": 7764
    },
    {
      "epoch": 0.6034348772147964,
      "grad_norm": 0.22311246395111084,
      "learning_rate": 6.982825613926019e-06,
      "loss": 0.0372,
      "step": 7765
    },
    {
      "epoch": 0.6035125893689773,
      "grad_norm": 0.3166572153568268,
      "learning_rate": 6.9824370531551145e-06,
      "loss": 0.2216,
      "step": 7766
    },
    {
      "epoch": 0.6035903015231582,
      "grad_norm": 0.0773172453045845,
      "learning_rate": 6.9820484923842094e-06,
      "loss": 0.0626,
      "step": 7767
    },
    {
      "epoch": 0.6036680136773391,
      "grad_norm": 0.0747121199965477,
      "learning_rate": 6.981659931613305e-06,
      "loss": 0.0335,
      "step": 7768
    },
    {
      "epoch": 0.6037457258315201,
      "grad_norm": 0.8391537070274353,
      "learning_rate": 6.981271370842401e-06,
      "loss": 0.4629,
      "step": 7769
    },
    {
      "epoch": 0.6038234379857009,
      "grad_norm": 0.29630613327026367,
      "learning_rate": 6.980882810071495e-06,
      "loss": 0.0983,
      "step": 7770
    },
    {
      "epoch": 0.6039011501398819,
      "grad_norm": 0.3464549779891968,
      "learning_rate": 6.980494249300591e-06,
      "loss": 0.1621,
      "step": 7771
    },
    {
      "epoch": 0.6039788622940628,
      "grad_norm": 0.26418018341064453,
      "learning_rate": 6.980105688529687e-06,
      "loss": 0.1035,
      "step": 7772
    },
    {
      "epoch": 0.6040565744482437,
      "grad_norm": 0.4021710455417633,
      "learning_rate": 6.979717127758782e-06,
      "loss": 0.2473,
      "step": 7773
    },
    {
      "epoch": 0.6041342866024246,
      "grad_norm": 0.10633065551519394,
      "learning_rate": 6.9793285669878775e-06,
      "loss": 0.0402,
      "step": 7774
    },
    {
      "epoch": 0.6042119987566056,
      "grad_norm": 0.28165197372436523,
      "learning_rate": 6.978940006216973e-06,
      "loss": 0.1326,
      "step": 7775
    },
    {
      "epoch": 0.6042897109107864,
      "grad_norm": 0.47415053844451904,
      "learning_rate": 6.978551445446068e-06,
      "loss": 0.2101,
      "step": 7776
    },
    {
      "epoch": 0.6043674230649674,
      "grad_norm": 0.19142384827136993,
      "learning_rate": 6.978162884675164e-06,
      "loss": 0.051,
      "step": 7777
    },
    {
      "epoch": 0.6044451352191482,
      "grad_norm": 0.4310964345932007,
      "learning_rate": 6.97777432390426e-06,
      "loss": 0.2017,
      "step": 7778
    },
    {
      "epoch": 0.6045228473733292,
      "grad_norm": 0.16579581797122955,
      "learning_rate": 6.977385763133354e-06,
      "loss": 0.0527,
      "step": 7779
    },
    {
      "epoch": 0.6046005595275101,
      "grad_norm": 0.08191376179456711,
      "learning_rate": 6.97699720236245e-06,
      "loss": 0.0181,
      "step": 7780
    },
    {
      "epoch": 0.604678271681691,
      "grad_norm": 0.1953570544719696,
      "learning_rate": 6.9766086415915455e-06,
      "loss": 0.0957,
      "step": 7781
    },
    {
      "epoch": 0.6047559838358719,
      "grad_norm": 0.32536977529525757,
      "learning_rate": 6.9762200808206405e-06,
      "loss": 0.0797,
      "step": 7782
    },
    {
      "epoch": 0.6048336959900529,
      "grad_norm": 0.5193600058555603,
      "learning_rate": 6.975831520049736e-06,
      "loss": 0.4799,
      "step": 7783
    },
    {
      "epoch": 0.6049114081442337,
      "grad_norm": 0.4037782847881317,
      "learning_rate": 6.975442959278832e-06,
      "loss": 0.2671,
      "step": 7784
    },
    {
      "epoch": 0.6049891202984147,
      "grad_norm": 0.3198879659175873,
      "learning_rate": 6.975054398507928e-06,
      "loss": 0.1031,
      "step": 7785
    },
    {
      "epoch": 0.6050668324525956,
      "grad_norm": 0.4149854779243469,
      "learning_rate": 6.974665837737023e-06,
      "loss": 0.2249,
      "step": 7786
    },
    {
      "epoch": 0.6051445446067765,
      "grad_norm": 0.6339626908302307,
      "learning_rate": 6.974277276966119e-06,
      "loss": 0.3363,
      "step": 7787
    },
    {
      "epoch": 0.6052222567609574,
      "grad_norm": 0.22426389157772064,
      "learning_rate": 6.973888716195214e-06,
      "loss": 0.1255,
      "step": 7788
    },
    {
      "epoch": 0.6052999689151384,
      "grad_norm": 0.15503355860710144,
      "learning_rate": 6.9735001554243085e-06,
      "loss": 0.0623,
      "step": 7789
    },
    {
      "epoch": 0.6053776810693192,
      "grad_norm": 0.3892005681991577,
      "learning_rate": 6.973111594653404e-06,
      "loss": 0.2883,
      "step": 7790
    },
    {
      "epoch": 0.6054553932235002,
      "grad_norm": 0.5324338674545288,
      "learning_rate": 6.9727230338825e-06,
      "loss": 0.2004,
      "step": 7791
    },
    {
      "epoch": 0.6055331053776811,
      "grad_norm": 0.30981484055519104,
      "learning_rate": 6.972334473111595e-06,
      "loss": 0.0273,
      "step": 7792
    },
    {
      "epoch": 0.605610817531862,
      "grad_norm": 0.3172522783279419,
      "learning_rate": 6.971945912340691e-06,
      "loss": 0.1319,
      "step": 7793
    },
    {
      "epoch": 0.6056885296860429,
      "grad_norm": 0.2300805300474167,
      "learning_rate": 6.971557351569787e-06,
      "loss": 0.0695,
      "step": 7794
    },
    {
      "epoch": 0.6057662418402238,
      "grad_norm": 0.45863163471221924,
      "learning_rate": 6.971168790798882e-06,
      "loss": 0.3333,
      "step": 7795
    },
    {
      "epoch": 0.6058439539944047,
      "grad_norm": 0.214852973818779,
      "learning_rate": 6.970780230027977e-06,
      "loss": 0.0783,
      "step": 7796
    },
    {
      "epoch": 0.6059216661485857,
      "grad_norm": 0.5167219042778015,
      "learning_rate": 6.970391669257073e-06,
      "loss": 0.1886,
      "step": 7797
    },
    {
      "epoch": 0.6059993783027665,
      "grad_norm": 0.33822596073150635,
      "learning_rate": 6.970003108486167e-06,
      "loss": 0.1676,
      "step": 7798
    },
    {
      "epoch": 0.6060770904569475,
      "grad_norm": 0.41156595945358276,
      "learning_rate": 6.969614547715263e-06,
      "loss": 0.2627,
      "step": 7799
    },
    {
      "epoch": 0.6061548026111284,
      "grad_norm": 0.5715368986129761,
      "learning_rate": 6.969225986944359e-06,
      "loss": 0.6267,
      "step": 7800
    },
    {
      "epoch": 0.6062325147653093,
      "grad_norm": 0.5177537798881531,
      "learning_rate": 6.968837426173454e-06,
      "loss": 0.6069,
      "step": 7801
    },
    {
      "epoch": 0.6063102269194902,
      "grad_norm": 0.5248385071754456,
      "learning_rate": 6.96844886540255e-06,
      "loss": 0.149,
      "step": 7802
    },
    {
      "epoch": 0.6063879390736712,
      "grad_norm": 0.19251157343387604,
      "learning_rate": 6.9680603046316454e-06,
      "loss": 0.0463,
      "step": 7803
    },
    {
      "epoch": 0.606465651227852,
      "grad_norm": 1.2488404512405396,
      "learning_rate": 6.96767174386074e-06,
      "loss": 0.2129,
      "step": 7804
    },
    {
      "epoch": 0.606543363382033,
      "grad_norm": 0.42837759852409363,
      "learning_rate": 6.967283183089836e-06,
      "loss": 0.145,
      "step": 7805
    },
    {
      "epoch": 0.6066210755362139,
      "grad_norm": 0.9563665390014648,
      "learning_rate": 6.966894622318932e-06,
      "loss": 0.2446,
      "step": 7806
    },
    {
      "epoch": 0.6066987876903948,
      "grad_norm": 0.2297266274690628,
      "learning_rate": 6.966506061548026e-06,
      "loss": 0.0897,
      "step": 7807
    },
    {
      "epoch": 0.6067764998445757,
      "grad_norm": 0.320640504360199,
      "learning_rate": 6.966117500777122e-06,
      "loss": 0.1359,
      "step": 7808
    },
    {
      "epoch": 0.6068542119987566,
      "grad_norm": 0.4797309339046478,
      "learning_rate": 6.965728940006218e-06,
      "loss": 0.1954,
      "step": 7809
    },
    {
      "epoch": 0.6069319241529375,
      "grad_norm": 0.40772268176078796,
      "learning_rate": 6.965340379235313e-06,
      "loss": 0.2634,
      "step": 7810
    },
    {
      "epoch": 0.6070096363071185,
      "grad_norm": 0.7637167572975159,
      "learning_rate": 6.964951818464408e-06,
      "loss": 0.52,
      "step": 7811
    },
    {
      "epoch": 0.6070873484612993,
      "grad_norm": 0.6020265221595764,
      "learning_rate": 6.964563257693504e-06,
      "loss": 0.2642,
      "step": 7812
    },
    {
      "epoch": 0.6071650606154803,
      "grad_norm": 0.7511947751045227,
      "learning_rate": 6.964174696922598e-06,
      "loss": 0.5488,
      "step": 7813
    },
    {
      "epoch": 0.6072427727696612,
      "grad_norm": 0.6925600171089172,
      "learning_rate": 6.963786136151694e-06,
      "loss": 0.2233,
      "step": 7814
    },
    {
      "epoch": 0.607320484923842,
      "grad_norm": 0.7432065606117249,
      "learning_rate": 6.96339757538079e-06,
      "loss": 0.7226,
      "step": 7815
    },
    {
      "epoch": 0.607398197078023,
      "grad_norm": 0.34666210412979126,
      "learning_rate": 6.963009014609886e-06,
      "loss": 0.1153,
      "step": 7816
    },
    {
      "epoch": 0.607475909232204,
      "grad_norm": 0.23604193329811096,
      "learning_rate": 6.962620453838981e-06,
      "loss": 0.1462,
      "step": 7817
    },
    {
      "epoch": 0.6075536213863848,
      "grad_norm": 0.38960379362106323,
      "learning_rate": 6.9622318930680764e-06,
      "loss": 0.1181,
      "step": 7818
    },
    {
      "epoch": 0.6076313335405658,
      "grad_norm": 0.3843914866447449,
      "learning_rate": 6.961843332297172e-06,
      "loss": 0.2366,
      "step": 7819
    },
    {
      "epoch": 0.6077090456947467,
      "grad_norm": 0.287232905626297,
      "learning_rate": 6.961454771526267e-06,
      "loss": 0.1065,
      "step": 7820
    },
    {
      "epoch": 0.6077867578489276,
      "grad_norm": 0.5204861760139465,
      "learning_rate": 6.961066210755363e-06,
      "loss": 0.1714,
      "step": 7821
    },
    {
      "epoch": 0.6078644700031085,
      "grad_norm": 0.5459835529327393,
      "learning_rate": 6.960677649984459e-06,
      "loss": 0.1501,
      "step": 7822
    },
    {
      "epoch": 0.6079421821572893,
      "grad_norm": 0.06646710634231567,
      "learning_rate": 6.960289089213553e-06,
      "loss": 0.037,
      "step": 7823
    },
    {
      "epoch": 0.6080198943114703,
      "grad_norm": 0.2218462973833084,
      "learning_rate": 6.959900528442649e-06,
      "loss": 0.1131,
      "step": 7824
    },
    {
      "epoch": 0.6080976064656513,
      "grad_norm": 0.23222406208515167,
      "learning_rate": 6.9595119676717445e-06,
      "loss": 0.1084,
      "step": 7825
    },
    {
      "epoch": 0.6081753186198321,
      "grad_norm": 0.44043704867362976,
      "learning_rate": 6.9591234069008394e-06,
      "loss": 0.2935,
      "step": 7826
    },
    {
      "epoch": 0.608253030774013,
      "grad_norm": 0.611029863357544,
      "learning_rate": 6.958734846129935e-06,
      "loss": 0.3495,
      "step": 7827
    },
    {
      "epoch": 0.608330742928194,
      "grad_norm": 1.2472286224365234,
      "learning_rate": 6.958346285359031e-06,
      "loss": 2.4318,
      "step": 7828
    },
    {
      "epoch": 0.6084084550823748,
      "grad_norm": 0.8841066360473633,
      "learning_rate": 6.957957724588126e-06,
      "loss": 0.1888,
      "step": 7829
    },
    {
      "epoch": 0.6084861672365558,
      "grad_norm": 0.14535890519618988,
      "learning_rate": 6.957569163817222e-06,
      "loss": 0.0672,
      "step": 7830
    },
    {
      "epoch": 0.6085638793907368,
      "grad_norm": 0.4831940829753876,
      "learning_rate": 6.9571806030463176e-06,
      "loss": 0.0994,
      "step": 7831
    },
    {
      "epoch": 0.6086415915449176,
      "grad_norm": 0.5517588257789612,
      "learning_rate": 6.956792042275412e-06,
      "loss": 0.4875,
      "step": 7832
    },
    {
      "epoch": 0.6087193036990985,
      "grad_norm": 0.6546921730041504,
      "learning_rate": 6.9564034815045075e-06,
      "loss": 0.3553,
      "step": 7833
    },
    {
      "epoch": 0.6087970158532795,
      "grad_norm": 0.7584652304649353,
      "learning_rate": 6.956014920733603e-06,
      "loss": 0.5286,
      "step": 7834
    },
    {
      "epoch": 0.6088747280074603,
      "grad_norm": 0.3481883704662323,
      "learning_rate": 6.955626359962698e-06,
      "loss": 0.0547,
      "step": 7835
    },
    {
      "epoch": 0.6089524401616413,
      "grad_norm": 0.3412189483642578,
      "learning_rate": 6.955237799191794e-06,
      "loss": 0.1468,
      "step": 7836
    },
    {
      "epoch": 0.6090301523158222,
      "grad_norm": 0.1347750574350357,
      "learning_rate": 6.95484923842089e-06,
      "loss": 0.0422,
      "step": 7837
    },
    {
      "epoch": 0.6091078644700031,
      "grad_norm": 0.1761961579322815,
      "learning_rate": 6.954460677649985e-06,
      "loss": 0.0301,
      "step": 7838
    },
    {
      "epoch": 0.609185576624184,
      "grad_norm": 0.6697134375572205,
      "learning_rate": 6.9540721168790806e-06,
      "loss": 0.363,
      "step": 7839
    },
    {
      "epoch": 0.6092632887783649,
      "grad_norm": 0.4034324586391449,
      "learning_rate": 6.953683556108176e-06,
      "loss": 0.2378,
      "step": 7840
    },
    {
      "epoch": 0.6093410009325458,
      "grad_norm": 0.7953391671180725,
      "learning_rate": 6.9532949953372705e-06,
      "loss": 0.1266,
      "step": 7841
    },
    {
      "epoch": 0.6094187130867268,
      "grad_norm": 0.6324636340141296,
      "learning_rate": 6.952906434566366e-06,
      "loss": 0.2296,
      "step": 7842
    },
    {
      "epoch": 0.6094964252409076,
      "grad_norm": 0.3276963531970978,
      "learning_rate": 6.952517873795462e-06,
      "loss": 0.3371,
      "step": 7843
    },
    {
      "epoch": 0.6095741373950886,
      "grad_norm": 0.041987836360931396,
      "learning_rate": 6.952129313024557e-06,
      "loss": 0.0056,
      "step": 7844
    },
    {
      "epoch": 0.6096518495492695,
      "grad_norm": 0.29320573806762695,
      "learning_rate": 6.951740752253653e-06,
      "loss": 0.0748,
      "step": 7845
    },
    {
      "epoch": 0.6097295617034504,
      "grad_norm": 0.15129336714744568,
      "learning_rate": 6.951352191482749e-06,
      "loss": 0.0908,
      "step": 7846
    },
    {
      "epoch": 0.6098072738576313,
      "grad_norm": 1.1202160120010376,
      "learning_rate": 6.950963630711844e-06,
      "loss": 0.2878,
      "step": 7847
    },
    {
      "epoch": 0.6098849860118123,
      "grad_norm": 0.17020058631896973,
      "learning_rate": 6.950575069940939e-06,
      "loss": 0.0152,
      "step": 7848
    },
    {
      "epoch": 0.6099626981659931,
      "grad_norm": 0.25759071111679077,
      "learning_rate": 6.950186509170035e-06,
      "loss": 0.1638,
      "step": 7849
    },
    {
      "epoch": 0.6100404103201741,
      "grad_norm": 0.257712185382843,
      "learning_rate": 6.949797948399131e-06,
      "loss": 0.1935,
      "step": 7850
    },
    {
      "epoch": 0.610118122474355,
      "grad_norm": 0.08103590458631516,
      "learning_rate": 6.949409387628225e-06,
      "loss": 0.0282,
      "step": 7851
    },
    {
      "epoch": 0.6101958346285359,
      "grad_norm": 0.7415699362754822,
      "learning_rate": 6.949020826857321e-06,
      "loss": 0.3618,
      "step": 7852
    },
    {
      "epoch": 0.6102735467827168,
      "grad_norm": 0.32734158635139465,
      "learning_rate": 6.948632266086417e-06,
      "loss": 0.1883,
      "step": 7853
    },
    {
      "epoch": 0.6103512589368977,
      "grad_norm": 0.31014758348464966,
      "learning_rate": 6.948243705315512e-06,
      "loss": 0.2548,
      "step": 7854
    },
    {
      "epoch": 0.6104289710910786,
      "grad_norm": 0.5371838212013245,
      "learning_rate": 6.947855144544607e-06,
      "loss": 0.8103,
      "step": 7855
    },
    {
      "epoch": 0.6105066832452596,
      "grad_norm": 0.34698981046676636,
      "learning_rate": 6.947466583773703e-06,
      "loss": 0.1462,
      "step": 7856
    },
    {
      "epoch": 0.6105843953994404,
      "grad_norm": 0.3510916531085968,
      "learning_rate": 6.947078023002798e-06,
      "loss": 0.1055,
      "step": 7857
    },
    {
      "epoch": 0.6106621075536214,
      "grad_norm": 0.5699587464332581,
      "learning_rate": 6.946689462231894e-06,
      "loss": 0.3087,
      "step": 7858
    },
    {
      "epoch": 0.6107398197078023,
      "grad_norm": 0.2758176028728485,
      "learning_rate": 6.94630090146099e-06,
      "loss": 0.1089,
      "step": 7859
    },
    {
      "epoch": 0.6108175318619832,
      "grad_norm": 0.7070013284683228,
      "learning_rate": 6.945912340690084e-06,
      "loss": 0.4419,
      "step": 7860
    },
    {
      "epoch": 0.6108952440161641,
      "grad_norm": 0.22331447899341583,
      "learning_rate": 6.94552377991918e-06,
      "loss": 0.0626,
      "step": 7861
    },
    {
      "epoch": 0.6109729561703451,
      "grad_norm": 0.12640883028507233,
      "learning_rate": 6.945135219148275e-06,
      "loss": 0.0264,
      "step": 7862
    },
    {
      "epoch": 0.6110506683245259,
      "grad_norm": 0.29756075143814087,
      "learning_rate": 6.94474665837737e-06,
      "loss": 0.0757,
      "step": 7863
    },
    {
      "epoch": 0.6111283804787069,
      "grad_norm": 0.3645961880683899,
      "learning_rate": 6.944358097606466e-06,
      "loss": 0.1112,
      "step": 7864
    },
    {
      "epoch": 0.6112060926328878,
      "grad_norm": 1.3868452310562134,
      "learning_rate": 6.943969536835562e-06,
      "loss": 0.3224,
      "step": 7865
    },
    {
      "epoch": 0.6112838047870687,
      "grad_norm": 0.5504392981529236,
      "learning_rate": 6.943580976064657e-06,
      "loss": 0.3855,
      "step": 7866
    },
    {
      "epoch": 0.6113615169412496,
      "grad_norm": 0.43973127007484436,
      "learning_rate": 6.943192415293753e-06,
      "loss": 0.366,
      "step": 7867
    },
    {
      "epoch": 0.6114392290954305,
      "grad_norm": 0.5335230827331543,
      "learning_rate": 6.9428038545228485e-06,
      "loss": 0.155,
      "step": 7868
    },
    {
      "epoch": 0.6115169412496114,
      "grad_norm": 8.123120307922363,
      "learning_rate": 6.942415293751943e-06,
      "loss": 0.4499,
      "step": 7869
    },
    {
      "epoch": 0.6115946534037924,
      "grad_norm": 0.3722376525402069,
      "learning_rate": 6.942026732981038e-06,
      "loss": 0.2345,
      "step": 7870
    },
    {
      "epoch": 0.6116723655579732,
      "grad_norm": 1.1581196784973145,
      "learning_rate": 6.941638172210134e-06,
      "loss": 0.2876,
      "step": 7871
    },
    {
      "epoch": 0.6117500777121542,
      "grad_norm": 0.5530251860618591,
      "learning_rate": 6.941249611439229e-06,
      "loss": 0.1134,
      "step": 7872
    },
    {
      "epoch": 0.6118277898663351,
      "grad_norm": 0.1824631690979004,
      "learning_rate": 6.940861050668325e-06,
      "loss": 0.1073,
      "step": 7873
    },
    {
      "epoch": 0.611905502020516,
      "grad_norm": 0.5969368815422058,
      "learning_rate": 6.940472489897421e-06,
      "loss": 0.1628,
      "step": 7874
    },
    {
      "epoch": 0.6119832141746969,
      "grad_norm": 0.24995315074920654,
      "learning_rate": 6.940083929126516e-06,
      "loss": 0.0376,
      "step": 7875
    },
    {
      "epoch": 0.6120609263288779,
      "grad_norm": 0.86856609582901,
      "learning_rate": 6.9396953683556115e-06,
      "loss": 0.3455,
      "step": 7876
    },
    {
      "epoch": 0.6121386384830587,
      "grad_norm": 0.17682401835918427,
      "learning_rate": 6.939306807584707e-06,
      "loss": 0.0423,
      "step": 7877
    },
    {
      "epoch": 0.6122163506372397,
      "grad_norm": 0.4700332581996918,
      "learning_rate": 6.938918246813803e-06,
      "loss": 0.248,
      "step": 7878
    },
    {
      "epoch": 0.6122940627914206,
      "grad_norm": 0.3561007082462311,
      "learning_rate": 6.938529686042897e-06,
      "loss": 0.1627,
      "step": 7879
    },
    {
      "epoch": 0.6123717749456015,
      "grad_norm": 0.8195615410804749,
      "learning_rate": 6.938141125271993e-06,
      "loss": 0.2155,
      "step": 7880
    },
    {
      "epoch": 0.6124494870997824,
      "grad_norm": 0.4454798996448517,
      "learning_rate": 6.937752564501089e-06,
      "loss": 0.2374,
      "step": 7881
    },
    {
      "epoch": 0.6125271992539634,
      "grad_norm": 0.810670793056488,
      "learning_rate": 6.937364003730184e-06,
      "loss": 0.4674,
      "step": 7882
    },
    {
      "epoch": 0.6126049114081442,
      "grad_norm": 0.1413133293390274,
      "learning_rate": 6.9369754429592795e-06,
      "loss": 0.0326,
      "step": 7883
    },
    {
      "epoch": 0.6126826235623252,
      "grad_norm": 0.31426021456718445,
      "learning_rate": 6.936586882188375e-06,
      "loss": 0.173,
      "step": 7884
    },
    {
      "epoch": 0.612760335716506,
      "grad_norm": 0.6037274599075317,
      "learning_rate": 6.93619832141747e-06,
      "loss": 0.1366,
      "step": 7885
    },
    {
      "epoch": 0.612838047870687,
      "grad_norm": 0.24182699620723724,
      "learning_rate": 6.935809760646566e-06,
      "loss": 0.0964,
      "step": 7886
    },
    {
      "epoch": 0.6129157600248679,
      "grad_norm": 0.1916741281747818,
      "learning_rate": 6.935421199875662e-06,
      "loss": 0.0376,
      "step": 7887
    },
    {
      "epoch": 0.6129934721790488,
      "grad_norm": 0.5516655445098877,
      "learning_rate": 6.935032639104756e-06,
      "loss": 0.3489,
      "step": 7888
    },
    {
      "epoch": 0.6130711843332297,
      "grad_norm": 0.3175024092197418,
      "learning_rate": 6.934644078333852e-06,
      "loss": 0.1147,
      "step": 7889
    },
    {
      "epoch": 0.6131488964874107,
      "grad_norm": 0.13576768338680267,
      "learning_rate": 6.9342555175629476e-06,
      "loss": 0.0782,
      "step": 7890
    },
    {
      "epoch": 0.6132266086415915,
      "grad_norm": 0.11673329025506973,
      "learning_rate": 6.9338669567920425e-06,
      "loss": 0.0361,
      "step": 7891
    },
    {
      "epoch": 0.6133043207957725,
      "grad_norm": 0.2496037632226944,
      "learning_rate": 6.933478396021138e-06,
      "loss": 0.1007,
      "step": 7892
    },
    {
      "epoch": 0.6133820329499534,
      "grad_norm": 0.1606794148683548,
      "learning_rate": 6.933089835250234e-06,
      "loss": 0.0388,
      "step": 7893
    },
    {
      "epoch": 0.6134597451041343,
      "grad_norm": 0.12805525958538055,
      "learning_rate": 6.932701274479329e-06,
      "loss": 0.0526,
      "step": 7894
    },
    {
      "epoch": 0.6135374572583152,
      "grad_norm": 0.14670388400554657,
      "learning_rate": 6.932312713708425e-06,
      "loss": 0.0392,
      "step": 7895
    },
    {
      "epoch": 0.6136151694124962,
      "grad_norm": 0.29649245738983154,
      "learning_rate": 6.931924152937521e-06,
      "loss": 0.1961,
      "step": 7896
    },
    {
      "epoch": 0.613692881566677,
      "grad_norm": 0.3220747411251068,
      "learning_rate": 6.931535592166615e-06,
      "loss": 0.1433,
      "step": 7897
    },
    {
      "epoch": 0.613770593720858,
      "grad_norm": 0.16727367043495178,
      "learning_rate": 6.9311470313957105e-06,
      "loss": 0.0608,
      "step": 7898
    },
    {
      "epoch": 0.6138483058750388,
      "grad_norm": 0.3350463807582855,
      "learning_rate": 6.930758470624806e-06,
      "loss": 0.4663,
      "step": 7899
    },
    {
      "epoch": 0.6139260180292198,
      "grad_norm": 0.12310479581356049,
      "learning_rate": 6.930369909853901e-06,
      "loss": 0.0584,
      "step": 7900
    },
    {
      "epoch": 0.6140037301834007,
      "grad_norm": 0.3213755786418915,
      "learning_rate": 6.929981349082997e-06,
      "loss": 0.172,
      "step": 7901
    },
    {
      "epoch": 0.6140814423375816,
      "grad_norm": 0.4313497543334961,
      "learning_rate": 6.929592788312093e-06,
      "loss": 0.1609,
      "step": 7902
    },
    {
      "epoch": 0.6141591544917625,
      "grad_norm": 0.24268467724323273,
      "learning_rate": 6.929204227541188e-06,
      "loss": 0.0356,
      "step": 7903
    },
    {
      "epoch": 0.6142368666459435,
      "grad_norm": 0.5005010962486267,
      "learning_rate": 6.928815666770284e-06,
      "loss": 0.2334,
      "step": 7904
    },
    {
      "epoch": 0.6143145788001243,
      "grad_norm": 0.1276828646659851,
      "learning_rate": 6.9284271059993794e-06,
      "loss": 0.0577,
      "step": 7905
    },
    {
      "epoch": 0.6143922909543053,
      "grad_norm": 0.8227999210357666,
      "learning_rate": 6.928038545228475e-06,
      "loss": 0.2069,
      "step": 7906
    },
    {
      "epoch": 0.6144700031084862,
      "grad_norm": 0.034207750111818314,
      "learning_rate": 6.927649984457569e-06,
      "loss": 0.0049,
      "step": 7907
    },
    {
      "epoch": 0.614547715262667,
      "grad_norm": 0.6951204538345337,
      "learning_rate": 6.927261423686665e-06,
      "loss": 0.3751,
      "step": 7908
    },
    {
      "epoch": 0.614625427416848,
      "grad_norm": 0.32423827052116394,
      "learning_rate": 6.926872862915761e-06,
      "loss": 0.2304,
      "step": 7909
    },
    {
      "epoch": 0.614703139571029,
      "grad_norm": 0.5138026475906372,
      "learning_rate": 6.926484302144856e-06,
      "loss": 0.3906,
      "step": 7910
    },
    {
      "epoch": 0.6147808517252098,
      "grad_norm": 0.4864175021648407,
      "learning_rate": 6.926095741373952e-06,
      "loss": 0.2729,
      "step": 7911
    },
    {
      "epoch": 0.6148585638793908,
      "grad_norm": 0.2315300703048706,
      "learning_rate": 6.9257071806030475e-06,
      "loss": 0.1082,
      "step": 7912
    },
    {
      "epoch": 0.6149362760335717,
      "grad_norm": 0.47781243920326233,
      "learning_rate": 6.925318619832142e-06,
      "loss": 0.1569,
      "step": 7913
    },
    {
      "epoch": 0.6150139881877525,
      "grad_norm": 0.10895030200481415,
      "learning_rate": 6.924930059061238e-06,
      "loss": 0.0385,
      "step": 7914
    },
    {
      "epoch": 0.6150917003419335,
      "grad_norm": 0.19734777510166168,
      "learning_rate": 6.924541498290334e-06,
      "loss": 0.024,
      "step": 7915
    },
    {
      "epoch": 0.6151694124961143,
      "grad_norm": 0.5865945816040039,
      "learning_rate": 6.924152937519428e-06,
      "loss": 0.1535,
      "step": 7916
    },
    {
      "epoch": 0.6152471246502953,
      "grad_norm": 0.08029845356941223,
      "learning_rate": 6.923764376748524e-06,
      "loss": 0.034,
      "step": 7917
    },
    {
      "epoch": 0.6153248368044762,
      "grad_norm": 0.4594275653362274,
      "learning_rate": 6.92337581597762e-06,
      "loss": 0.1168,
      "step": 7918
    },
    {
      "epoch": 0.6154025489586571,
      "grad_norm": 0.32274895906448364,
      "learning_rate": 6.922987255206715e-06,
      "loss": 0.1333,
      "step": 7919
    },
    {
      "epoch": 0.615480261112838,
      "grad_norm": 0.18760892748832703,
      "learning_rate": 6.9225986944358105e-06,
      "loss": 0.0478,
      "step": 7920
    },
    {
      "epoch": 0.615557973267019,
      "grad_norm": 0.15737329423427582,
      "learning_rate": 6.922210133664906e-06,
      "loss": 0.052,
      "step": 7921
    },
    {
      "epoch": 0.6156356854211998,
      "grad_norm": 0.7734670042991638,
      "learning_rate": 6.921821572894001e-06,
      "loss": 0.5335,
      "step": 7922
    },
    {
      "epoch": 0.6157133975753808,
      "grad_norm": 0.285022109746933,
      "learning_rate": 6.921433012123097e-06,
      "loss": 0.1474,
      "step": 7923
    },
    {
      "epoch": 0.6157911097295617,
      "grad_norm": 0.8818963170051575,
      "learning_rate": 6.921044451352193e-06,
      "loss": 0.2854,
      "step": 7924
    },
    {
      "epoch": 0.6158688218837426,
      "grad_norm": 0.40416985750198364,
      "learning_rate": 6.920655890581287e-06,
      "loss": 0.3245,
      "step": 7925
    },
    {
      "epoch": 0.6159465340379235,
      "grad_norm": 0.30636778473854065,
      "learning_rate": 6.920267329810383e-06,
      "loss": 0.213,
      "step": 7926
    },
    {
      "epoch": 0.6160242461921045,
      "grad_norm": 0.22073012590408325,
      "learning_rate": 6.9198787690394785e-06,
      "loss": 0.1601,
      "step": 7927
    },
    {
      "epoch": 0.6161019583462853,
      "grad_norm": 0.6107240915298462,
      "learning_rate": 6.9194902082685734e-06,
      "loss": 0.4709,
      "step": 7928
    },
    {
      "epoch": 0.6161796705004663,
      "grad_norm": 0.30205661058425903,
      "learning_rate": 6.919101647497669e-06,
      "loss": 0.1586,
      "step": 7929
    },
    {
      "epoch": 0.6162573826546471,
      "grad_norm": 0.7004977464675903,
      "learning_rate": 6.918713086726765e-06,
      "loss": 0.4575,
      "step": 7930
    },
    {
      "epoch": 0.6163350948088281,
      "grad_norm": 0.4167695939540863,
      "learning_rate": 6.91832452595586e-06,
      "loss": 0.191,
      "step": 7931
    },
    {
      "epoch": 0.616412806963009,
      "grad_norm": 0.09575111418962479,
      "learning_rate": 6.917935965184956e-06,
      "loss": 0.0279,
      "step": 7932
    },
    {
      "epoch": 0.6164905191171899,
      "grad_norm": 0.28913792967796326,
      "learning_rate": 6.917547404414051e-06,
      "loss": 0.0567,
      "step": 7933
    },
    {
      "epoch": 0.6165682312713708,
      "grad_norm": 0.382743775844574,
      "learning_rate": 6.917158843643146e-06,
      "loss": 0.2522,
      "step": 7934
    },
    {
      "epoch": 0.6166459434255518,
      "grad_norm": 0.30872952938079834,
      "learning_rate": 6.9167702828722415e-06,
      "loss": 0.1182,
      "step": 7935
    },
    {
      "epoch": 0.6167236555797326,
      "grad_norm": 0.5275007486343384,
      "learning_rate": 6.916381722101337e-06,
      "loss": 0.0877,
      "step": 7936
    },
    {
      "epoch": 0.6168013677339136,
      "grad_norm": 0.3596054017543793,
      "learning_rate": 6.915993161330433e-06,
      "loss": 0.1296,
      "step": 7937
    },
    {
      "epoch": 0.6168790798880945,
      "grad_norm": 0.39132243394851685,
      "learning_rate": 6.915604600559528e-06,
      "loss": 0.0781,
      "step": 7938
    },
    {
      "epoch": 0.6169567920422754,
      "grad_norm": 0.7458985447883606,
      "learning_rate": 6.915216039788624e-06,
      "loss": 0.7392,
      "step": 7939
    },
    {
      "epoch": 0.6170345041964563,
      "grad_norm": 0.373676061630249,
      "learning_rate": 6.91482747901772e-06,
      "loss": 0.2405,
      "step": 7940
    },
    {
      "epoch": 0.6171122163506373,
      "grad_norm": 0.2606737017631531,
      "learning_rate": 6.914438918246814e-06,
      "loss": 0.0625,
      "step": 7941
    },
    {
      "epoch": 0.6171899285048181,
      "grad_norm": 0.5156263113021851,
      "learning_rate": 6.9140503574759095e-06,
      "loss": 0.4471,
      "step": 7942
    },
    {
      "epoch": 0.6172676406589991,
      "grad_norm": 0.36624622344970703,
      "learning_rate": 6.913661796705005e-06,
      "loss": 0.1466,
      "step": 7943
    },
    {
      "epoch": 0.6173453528131799,
      "grad_norm": 0.2878422737121582,
      "learning_rate": 6.9132732359341e-06,
      "loss": 0.1502,
      "step": 7944
    },
    {
      "epoch": 0.6174230649673609,
      "grad_norm": 0.061584845185279846,
      "learning_rate": 6.912884675163196e-06,
      "loss": 0.0571,
      "step": 7945
    },
    {
      "epoch": 0.6175007771215418,
      "grad_norm": 0.4326474964618683,
      "learning_rate": 6.912496114392292e-06,
      "loss": 0.1349,
      "step": 7946
    },
    {
      "epoch": 0.6175784892757227,
      "grad_norm": 0.7718772888183594,
      "learning_rate": 6.912107553621387e-06,
      "loss": 0.4681,
      "step": 7947
    },
    {
      "epoch": 0.6176562014299036,
      "grad_norm": 0.4554677903652191,
      "learning_rate": 6.911718992850483e-06,
      "loss": 0.1904,
      "step": 7948
    },
    {
      "epoch": 0.6177339135840846,
      "grad_norm": 0.5780704617500305,
      "learning_rate": 6.911330432079578e-06,
      "loss": 0.2553,
      "step": 7949
    },
    {
      "epoch": 0.6178116257382654,
      "grad_norm": 0.23248977959156036,
      "learning_rate": 6.9109418713086725e-06,
      "loss": 0.1393,
      "step": 7950
    },
    {
      "epoch": 0.6178893378924464,
      "grad_norm": 1.3379191160202026,
      "learning_rate": 6.910553310537768e-06,
      "loss": 0.708,
      "step": 7951
    },
    {
      "epoch": 0.6179670500466273,
      "grad_norm": 0.8121230602264404,
      "learning_rate": 6.910164749766864e-06,
      "loss": 0.3485,
      "step": 7952
    },
    {
      "epoch": 0.6180447622008082,
      "grad_norm": 0.2048446089029312,
      "learning_rate": 6.909776188995959e-06,
      "loss": 0.2189,
      "step": 7953
    },
    {
      "epoch": 0.6181224743549891,
      "grad_norm": 1.1763592958450317,
      "learning_rate": 6.909387628225055e-06,
      "loss": 0.3672,
      "step": 7954
    },
    {
      "epoch": 0.6182001865091701,
      "grad_norm": 0.21654674410820007,
      "learning_rate": 6.908999067454151e-06,
      "loss": 0.1133,
      "step": 7955
    },
    {
      "epoch": 0.6182778986633509,
      "grad_norm": 0.21264876425266266,
      "learning_rate": 6.908610506683246e-06,
      "loss": 0.1726,
      "step": 7956
    },
    {
      "epoch": 0.6183556108175319,
      "grad_norm": 0.2030874341726303,
      "learning_rate": 6.908221945912341e-06,
      "loss": 0.1486,
      "step": 7957
    },
    {
      "epoch": 0.6184333229717128,
      "grad_norm": 0.6249318718910217,
      "learning_rate": 6.907833385141437e-06,
      "loss": 0.4469,
      "step": 7958
    },
    {
      "epoch": 0.6185110351258937,
      "grad_norm": 0.24117408692836761,
      "learning_rate": 6.907444824370531e-06,
      "loss": 0.061,
      "step": 7959
    },
    {
      "epoch": 0.6185887472800746,
      "grad_norm": 0.2210179567337036,
      "learning_rate": 6.907056263599627e-06,
      "loss": 0.0864,
      "step": 7960
    },
    {
      "epoch": 0.6186664594342555,
      "grad_norm": 0.4529935419559479,
      "learning_rate": 6.906667702828723e-06,
      "loss": 0.1307,
      "step": 7961
    },
    {
      "epoch": 0.6187441715884364,
      "grad_norm": 0.8355799913406372,
      "learning_rate": 6.906279142057818e-06,
      "loss": 0.5165,
      "step": 7962
    },
    {
      "epoch": 0.6188218837426174,
      "grad_norm": 0.2985202372074127,
      "learning_rate": 6.905890581286914e-06,
      "loss": 0.1231,
      "step": 7963
    },
    {
      "epoch": 0.6188995958967982,
      "grad_norm": 1.2084957361221313,
      "learning_rate": 6.905502020516009e-06,
      "loss": 0.4119,
      "step": 7964
    },
    {
      "epoch": 0.6189773080509792,
      "grad_norm": 0.5281904935836792,
      "learning_rate": 6.905113459745104e-06,
      "loss": 0.1958,
      "step": 7965
    },
    {
      "epoch": 0.6190550202051601,
      "grad_norm": 0.3217593729496002,
      "learning_rate": 6.9047248989742e-06,
      "loss": 0.1793,
      "step": 7966
    },
    {
      "epoch": 0.619132732359341,
      "grad_norm": 0.20132657885551453,
      "learning_rate": 6.904336338203296e-06,
      "loss": 0.1281,
      "step": 7967
    },
    {
      "epoch": 0.6192104445135219,
      "grad_norm": 0.6365290284156799,
      "learning_rate": 6.903947777432392e-06,
      "loss": 0.388,
      "step": 7968
    },
    {
      "epoch": 0.6192881566677029,
      "grad_norm": 0.3144417703151703,
      "learning_rate": 6.903559216661486e-06,
      "loss": 0.2743,
      "step": 7969
    },
    {
      "epoch": 0.6193658688218837,
      "grad_norm": 0.5032966136932373,
      "learning_rate": 6.903170655890582e-06,
      "loss": 0.4081,
      "step": 7970
    },
    {
      "epoch": 0.6194435809760647,
      "grad_norm": 0.6695296764373779,
      "learning_rate": 6.9027820951196775e-06,
      "loss": 0.5804,
      "step": 7971
    },
    {
      "epoch": 0.6195212931302456,
      "grad_norm": 0.6602448225021362,
      "learning_rate": 6.902393534348772e-06,
      "loss": 0.4234,
      "step": 7972
    },
    {
      "epoch": 0.6195990052844265,
      "grad_norm": 0.1598089188337326,
      "learning_rate": 6.902004973577868e-06,
      "loss": 0.0401,
      "step": 7973
    },
    {
      "epoch": 0.6196767174386074,
      "grad_norm": 0.4510651230812073,
      "learning_rate": 6.901616412806964e-06,
      "loss": 0.2538,
      "step": 7974
    },
    {
      "epoch": 0.6197544295927883,
      "grad_norm": 0.28777164220809937,
      "learning_rate": 6.901227852036059e-06,
      "loss": 0.0529,
      "step": 7975
    },
    {
      "epoch": 0.6198321417469692,
      "grad_norm": 0.30619847774505615,
      "learning_rate": 6.900839291265155e-06,
      "loss": 0.1307,
      "step": 7976
    },
    {
      "epoch": 0.6199098539011502,
      "grad_norm": 0.1307099461555481,
      "learning_rate": 6.9004507304942505e-06,
      "loss": 0.0158,
      "step": 7977
    },
    {
      "epoch": 0.619987566055331,
      "grad_norm": 0.48893609642982483,
      "learning_rate": 6.900062169723345e-06,
      "loss": 0.3793,
      "step": 7978
    },
    {
      "epoch": 0.620065278209512,
      "grad_norm": 0.3044881224632263,
      "learning_rate": 6.8996736089524404e-06,
      "loss": 0.0951,
      "step": 7979
    },
    {
      "epoch": 0.6201429903636929,
      "grad_norm": 0.29748454689979553,
      "learning_rate": 6.899285048181536e-06,
      "loss": 0.1738,
      "step": 7980
    },
    {
      "epoch": 0.6202207025178738,
      "grad_norm": 0.40991684794425964,
      "learning_rate": 6.898896487410631e-06,
      "loss": 0.2493,
      "step": 7981
    },
    {
      "epoch": 0.6202984146720547,
      "grad_norm": 0.5422543287277222,
      "learning_rate": 6.898507926639727e-06,
      "loss": 0.3843,
      "step": 7982
    },
    {
      "epoch": 0.6203761268262357,
      "grad_norm": 0.464738130569458,
      "learning_rate": 6.898119365868823e-06,
      "loss": 0.1245,
      "step": 7983
    },
    {
      "epoch": 0.6204538389804165,
      "grad_norm": 0.47394129633903503,
      "learning_rate": 6.897730805097918e-06,
      "loss": 0.241,
      "step": 7984
    },
    {
      "epoch": 0.6205315511345975,
      "grad_norm": 0.12219730764627457,
      "learning_rate": 6.8973422443270135e-06,
      "loss": 0.0491,
      "step": 7985
    },
    {
      "epoch": 0.6206092632887784,
      "grad_norm": 0.2854754328727722,
      "learning_rate": 6.896953683556109e-06,
      "loss": 0.1566,
      "step": 7986
    },
    {
      "epoch": 0.6206869754429593,
      "grad_norm": 0.2644743025302887,
      "learning_rate": 6.8965651227852034e-06,
      "loss": 0.0976,
      "step": 7987
    },
    {
      "epoch": 0.6207646875971402,
      "grad_norm": 0.4271593689918518,
      "learning_rate": 6.896176562014299e-06,
      "loss": 0.3679,
      "step": 7988
    },
    {
      "epoch": 0.6208423997513212,
      "grad_norm": 0.3189959228038788,
      "learning_rate": 6.895788001243395e-06,
      "loss": 0.1049,
      "step": 7989
    },
    {
      "epoch": 0.620920111905502,
      "grad_norm": 0.4461856782436371,
      "learning_rate": 6.89539944047249e-06,
      "loss": 0.1254,
      "step": 7990
    },
    {
      "epoch": 0.620997824059683,
      "grad_norm": 0.37198302149772644,
      "learning_rate": 6.895010879701586e-06,
      "loss": 0.561,
      "step": 7991
    },
    {
      "epoch": 0.6210755362138638,
      "grad_norm": 0.4375380873680115,
      "learning_rate": 6.8946223189306816e-06,
      "loss": 0.1023,
      "step": 7992
    },
    {
      "epoch": 0.6211532483680448,
      "grad_norm": 0.042463768273591995,
      "learning_rate": 6.8942337581597765e-06,
      "loss": 0.0056,
      "step": 7993
    },
    {
      "epoch": 0.6212309605222257,
      "grad_norm": 0.33498504757881165,
      "learning_rate": 6.893845197388872e-06,
      "loss": 0.3302,
      "step": 7994
    },
    {
      "epoch": 0.6213086726764065,
      "grad_norm": 0.4870308041572571,
      "learning_rate": 6.893456636617968e-06,
      "loss": 0.2371,
      "step": 7995
    },
    {
      "epoch": 0.6213863848305875,
      "grad_norm": 0.29640746116638184,
      "learning_rate": 6.893068075847062e-06,
      "loss": 0.0741,
      "step": 7996
    },
    {
      "epoch": 0.6214640969847685,
      "grad_norm": 0.3809586465358734,
      "learning_rate": 6.892679515076158e-06,
      "loss": 0.8391,
      "step": 7997
    },
    {
      "epoch": 0.6215418091389493,
      "grad_norm": 0.2826228737831116,
      "learning_rate": 6.892290954305254e-06,
      "loss": 0.1893,
      "step": 7998
    },
    {
      "epoch": 0.6216195212931303,
      "grad_norm": 0.7807154655456543,
      "learning_rate": 6.89190239353435e-06,
      "loss": 0.4473,
      "step": 7999
    },
    {
      "epoch": 0.6216972334473112,
      "grad_norm": 0.21385371685028076,
      "learning_rate": 6.8915138327634446e-06,
      "loss": 0.1297,
      "step": 8000
    },
    {
      "epoch": 0.621774945601492,
      "grad_norm": 0.14453062415122986,
      "learning_rate": 6.89112527199254e-06,
      "loss": 0.0445,
      "step": 8001
    },
    {
      "epoch": 0.621852657755673,
      "grad_norm": 0.1840858906507492,
      "learning_rate": 6.890736711221636e-06,
      "loss": 0.0607,
      "step": 8002
    },
    {
      "epoch": 0.621930369909854,
      "grad_norm": 0.24936528503894806,
      "learning_rate": 6.890348150450731e-06,
      "loss": 0.0941,
      "step": 8003
    },
    {
      "epoch": 0.6220080820640348,
      "grad_norm": 0.17137368023395538,
      "learning_rate": 6.889959589679827e-06,
      "loss": 0.0442,
      "step": 8004
    },
    {
      "epoch": 0.6220857942182157,
      "grad_norm": 0.4063761234283447,
      "learning_rate": 6.889571028908923e-06,
      "loss": 0.0446,
      "step": 8005
    },
    {
      "epoch": 0.6221635063723966,
      "grad_norm": 0.4010109007358551,
      "learning_rate": 6.889182468138017e-06,
      "loss": 0.3603,
      "step": 8006
    },
    {
      "epoch": 0.6222412185265775,
      "grad_norm": 0.47992387413978577,
      "learning_rate": 6.888793907367113e-06,
      "loss": 0.0425,
      "step": 8007
    },
    {
      "epoch": 0.6223189306807585,
      "grad_norm": 0.7440114617347717,
      "learning_rate": 6.888405346596208e-06,
      "loss": 0.157,
      "step": 8008
    },
    {
      "epoch": 0.6223966428349393,
      "grad_norm": 0.3251834213733673,
      "learning_rate": 6.888016785825303e-06,
      "loss": 0.034,
      "step": 8009
    },
    {
      "epoch": 0.6224743549891203,
      "grad_norm": 0.04830978065729141,
      "learning_rate": 6.887628225054399e-06,
      "loss": 0.013,
      "step": 8010
    },
    {
      "epoch": 0.6225520671433012,
      "grad_norm": 0.5313992500305176,
      "learning_rate": 6.887239664283495e-06,
      "loss": 0.1816,
      "step": 8011
    },
    {
      "epoch": 0.6226297792974821,
      "grad_norm": 0.5526052713394165,
      "learning_rate": 6.88685110351259e-06,
      "loss": 0.1854,
      "step": 8012
    },
    {
      "epoch": 0.622707491451663,
      "grad_norm": 0.21865223348140717,
      "learning_rate": 6.886462542741686e-06,
      "loss": 0.2218,
      "step": 8013
    },
    {
      "epoch": 0.622785203605844,
      "grad_norm": 0.18792413175106049,
      "learning_rate": 6.8860739819707815e-06,
      "loss": 0.0665,
      "step": 8014
    },
    {
      "epoch": 0.6228629157600248,
      "grad_norm": 0.2117658257484436,
      "learning_rate": 6.8856854211998756e-06,
      "loss": 0.0304,
      "step": 8015
    },
    {
      "epoch": 0.6229406279142058,
      "grad_norm": 0.22633694112300873,
      "learning_rate": 6.885296860428971e-06,
      "loss": 0.0818,
      "step": 8016
    },
    {
      "epoch": 0.6230183400683867,
      "grad_norm": 0.33624792098999023,
      "learning_rate": 6.884908299658067e-06,
      "loss": 0.0999,
      "step": 8017
    },
    {
      "epoch": 0.6230960522225676,
      "grad_norm": 0.6180820465087891,
      "learning_rate": 6.884519738887162e-06,
      "loss": 0.5329,
      "step": 8018
    },
    {
      "epoch": 0.6231737643767485,
      "grad_norm": 0.47087809443473816,
      "learning_rate": 6.884131178116258e-06,
      "loss": 0.2937,
      "step": 8019
    },
    {
      "epoch": 0.6232514765309294,
      "grad_norm": 0.5407052636146545,
      "learning_rate": 6.883742617345354e-06,
      "loss": 0.1478,
      "step": 8020
    },
    {
      "epoch": 0.6233291886851103,
      "grad_norm": 0.7607986927032471,
      "learning_rate": 6.883354056574449e-06,
      "loss": 0.1324,
      "step": 8021
    },
    {
      "epoch": 0.6234069008392913,
      "grad_norm": 0.6153647899627686,
      "learning_rate": 6.8829654958035445e-06,
      "loss": 0.2386,
      "step": 8022
    },
    {
      "epoch": 0.6234846129934721,
      "grad_norm": 0.2013670802116394,
      "learning_rate": 6.88257693503264e-06,
      "loss": 0.0865,
      "step": 8023
    },
    {
      "epoch": 0.6235623251476531,
      "grad_norm": 0.1158892884850502,
      "learning_rate": 6.882188374261734e-06,
      "loss": 0.0623,
      "step": 8024
    },
    {
      "epoch": 0.623640037301834,
      "grad_norm": 0.48020631074905396,
      "learning_rate": 6.88179981349083e-06,
      "loss": 0.1814,
      "step": 8025
    },
    {
      "epoch": 0.6237177494560149,
      "grad_norm": 0.18415489792823792,
      "learning_rate": 6.881411252719926e-06,
      "loss": 0.0762,
      "step": 8026
    },
    {
      "epoch": 0.6237954616101958,
      "grad_norm": 0.4951516389846802,
      "learning_rate": 6.881022691949021e-06,
      "loss": 0.0528,
      "step": 8027
    },
    {
      "epoch": 0.6238731737643768,
      "grad_norm": 0.6727681159973145,
      "learning_rate": 6.880634131178117e-06,
      "loss": 0.3841,
      "step": 8028
    },
    {
      "epoch": 0.6239508859185576,
      "grad_norm": 0.44673478603363037,
      "learning_rate": 6.8802455704072125e-06,
      "loss": 0.0863,
      "step": 8029
    },
    {
      "epoch": 0.6240285980727386,
      "grad_norm": 0.9406100511550903,
      "learning_rate": 6.879857009636308e-06,
      "loss": 0.181,
      "step": 8030
    },
    {
      "epoch": 0.6241063102269195,
      "grad_norm": 0.6931767463684082,
      "learning_rate": 6.879468448865403e-06,
      "loss": 0.3373,
      "step": 8031
    },
    {
      "epoch": 0.6241840223811004,
      "grad_norm": 0.15982364118099213,
      "learning_rate": 6.879079888094499e-06,
      "loss": 0.088,
      "step": 8032
    },
    {
      "epoch": 0.6242617345352813,
      "grad_norm": 0.31050118803977966,
      "learning_rate": 6.878691327323595e-06,
      "loss": 0.2132,
      "step": 8033
    },
    {
      "epoch": 0.6243394466894623,
      "grad_norm": 0.5624769926071167,
      "learning_rate": 6.878302766552689e-06,
      "loss": 0.1857,
      "step": 8034
    },
    {
      "epoch": 0.6244171588436431,
      "grad_norm": 0.4179261326789856,
      "learning_rate": 6.877914205781785e-06,
      "loss": 0.1257,
      "step": 8035
    },
    {
      "epoch": 0.6244948709978241,
      "grad_norm": 0.08825574070215225,
      "learning_rate": 6.8775256450108805e-06,
      "loss": 0.0248,
      "step": 8036
    },
    {
      "epoch": 0.6245725831520049,
      "grad_norm": 0.13734029233455658,
      "learning_rate": 6.8771370842399755e-06,
      "loss": 0.0356,
      "step": 8037
    },
    {
      "epoch": 0.6246502953061859,
      "grad_norm": 0.246944859623909,
      "learning_rate": 6.876748523469071e-06,
      "loss": 0.085,
      "step": 8038
    },
    {
      "epoch": 0.6247280074603668,
      "grad_norm": 0.13167130947113037,
      "learning_rate": 6.876359962698167e-06,
      "loss": 0.0195,
      "step": 8039
    },
    {
      "epoch": 0.6248057196145477,
      "grad_norm": 0.90585857629776,
      "learning_rate": 6.875971401927262e-06,
      "loss": 0.2141,
      "step": 8040
    },
    {
      "epoch": 0.6248834317687286,
      "grad_norm": 0.5007878541946411,
      "learning_rate": 6.875582841156358e-06,
      "loss": 0.1232,
      "step": 8041
    },
    {
      "epoch": 0.6249611439229096,
      "grad_norm": 1.0901707410812378,
      "learning_rate": 6.875194280385454e-06,
      "loss": 0.46,
      "step": 8042
    },
    {
      "epoch": 0.6250388560770904,
      "grad_norm": 0.24656443297863007,
      "learning_rate": 6.874805719614548e-06,
      "loss": 0.1443,
      "step": 8043
    },
    {
      "epoch": 0.6251165682312714,
      "grad_norm": 0.15308751165866852,
      "learning_rate": 6.8744171588436435e-06,
      "loss": 0.0423,
      "step": 8044
    },
    {
      "epoch": 0.6251942803854523,
      "grad_norm": 0.5284943580627441,
      "learning_rate": 6.874028598072739e-06,
      "loss": 0.2734,
      "step": 8045
    },
    {
      "epoch": 0.6252719925396332,
      "grad_norm": 0.18349263072013855,
      "learning_rate": 6.873640037301834e-06,
      "loss": 0.0188,
      "step": 8046
    },
    {
      "epoch": 0.6253497046938141,
      "grad_norm": 0.47173407673835754,
      "learning_rate": 6.87325147653093e-06,
      "loss": 0.481,
      "step": 8047
    },
    {
      "epoch": 0.6254274168479951,
      "grad_norm": 0.20272956788539886,
      "learning_rate": 6.872862915760026e-06,
      "loss": 0.0648,
      "step": 8048
    },
    {
      "epoch": 0.6255051290021759,
      "grad_norm": 0.24363861978054047,
      "learning_rate": 6.872474354989121e-06,
      "loss": 0.1127,
      "step": 8049
    },
    {
      "epoch": 0.6255828411563569,
      "grad_norm": 0.4355124533176422,
      "learning_rate": 6.872085794218217e-06,
      "loss": 0.1324,
      "step": 8050
    },
    {
      "epoch": 0.6256605533105377,
      "grad_norm": 0.40379250049591064,
      "learning_rate": 6.871697233447312e-06,
      "loss": 0.1847,
      "step": 8051
    },
    {
      "epoch": 0.6257382654647187,
      "grad_norm": 0.39290332794189453,
      "learning_rate": 6.8713086726764065e-06,
      "loss": 0.132,
      "step": 8052
    },
    {
      "epoch": 0.6258159776188996,
      "grad_norm": 0.45446687936782837,
      "learning_rate": 6.870920111905502e-06,
      "loss": 0.1786,
      "step": 8053
    },
    {
      "epoch": 0.6258936897730805,
      "grad_norm": 0.39586225152015686,
      "learning_rate": 6.870531551134598e-06,
      "loss": 0.1488,
      "step": 8054
    },
    {
      "epoch": 0.6259714019272614,
      "grad_norm": 0.1692977249622345,
      "learning_rate": 6.870142990363693e-06,
      "loss": 0.0894,
      "step": 8055
    },
    {
      "epoch": 0.6260491140814424,
      "grad_norm": 0.3350664973258972,
      "learning_rate": 6.869754429592789e-06,
      "loss": 0.1504,
      "step": 8056
    },
    {
      "epoch": 0.6261268262356232,
      "grad_norm": 0.5477752089500427,
      "learning_rate": 6.869365868821885e-06,
      "loss": 0.2565,
      "step": 8057
    },
    {
      "epoch": 0.6262045383898042,
      "grad_norm": 0.43976259231567383,
      "learning_rate": 6.8689773080509804e-06,
      "loss": 0.0635,
      "step": 8058
    },
    {
      "epoch": 0.6262822505439851,
      "grad_norm": 1.5741881132125854,
      "learning_rate": 6.868588747280075e-06,
      "loss": 0.3279,
      "step": 8059
    },
    {
      "epoch": 0.626359962698166,
      "grad_norm": 0.1370549350976944,
      "learning_rate": 6.86820018650917e-06,
      "loss": 0.0349,
      "step": 8060
    },
    {
      "epoch": 0.6264376748523469,
      "grad_norm": 0.42441868782043457,
      "learning_rate": 6.867811625738266e-06,
      "loss": 0.3481,
      "step": 8061
    },
    {
      "epoch": 0.6265153870065279,
      "grad_norm": 0.5459789037704468,
      "learning_rate": 6.867423064967361e-06,
      "loss": 0.1847,
      "step": 8062
    },
    {
      "epoch": 0.6265930991607087,
      "grad_norm": 0.38346949219703674,
      "learning_rate": 6.867034504196457e-06,
      "loss": 0.4541,
      "step": 8063
    },
    {
      "epoch": 0.6266708113148897,
      "grad_norm": 0.2866988480091095,
      "learning_rate": 6.866645943425553e-06,
      "loss": 0.1445,
      "step": 8064
    },
    {
      "epoch": 0.6267485234690706,
      "grad_norm": 0.29925277829170227,
      "learning_rate": 6.866257382654648e-06,
      "loss": 0.0995,
      "step": 8065
    },
    {
      "epoch": 0.6268262356232515,
      "grad_norm": 0.1076042652130127,
      "learning_rate": 6.865868821883743e-06,
      "loss": 0.0402,
      "step": 8066
    },
    {
      "epoch": 0.6269039477774324,
      "grad_norm": 0.22351562976837158,
      "learning_rate": 6.865480261112839e-06,
      "loss": 0.0905,
      "step": 8067
    },
    {
      "epoch": 0.6269816599316133,
      "grad_norm": 0.5502939820289612,
      "learning_rate": 6.865091700341933e-06,
      "loss": 0.0811,
      "step": 8068
    },
    {
      "epoch": 0.6270593720857942,
      "grad_norm": 0.16940586268901825,
      "learning_rate": 6.864703139571029e-06,
      "loss": 0.0481,
      "step": 8069
    },
    {
      "epoch": 0.6271370842399752,
      "grad_norm": 0.09717705845832825,
      "learning_rate": 6.864314578800125e-06,
      "loss": 0.0197,
      "step": 8070
    },
    {
      "epoch": 0.627214796394156,
      "grad_norm": 0.4852049648761749,
      "learning_rate": 6.86392601802922e-06,
      "loss": 0.6062,
      "step": 8071
    },
    {
      "epoch": 0.627292508548337,
      "grad_norm": 0.34166523814201355,
      "learning_rate": 6.863537457258316e-06,
      "loss": 0.3713,
      "step": 8072
    },
    {
      "epoch": 0.6273702207025179,
      "grad_norm": 0.3008907437324524,
      "learning_rate": 6.8631488964874115e-06,
      "loss": 0.0282,
      "step": 8073
    },
    {
      "epoch": 0.6274479328566988,
      "grad_norm": 0.4121682047843933,
      "learning_rate": 6.862760335716506e-06,
      "loss": 0.2308,
      "step": 8074
    },
    {
      "epoch": 0.6275256450108797,
      "grad_norm": 0.4092276394367218,
      "learning_rate": 6.862371774945602e-06,
      "loss": 0.3988,
      "step": 8075
    },
    {
      "epoch": 0.6276033571650607,
      "grad_norm": 0.42437514662742615,
      "learning_rate": 6.861983214174698e-06,
      "loss": 0.4877,
      "step": 8076
    },
    {
      "epoch": 0.6276810693192415,
      "grad_norm": 0.28713321685791016,
      "learning_rate": 6.861594653403792e-06,
      "loss": 0.2128,
      "step": 8077
    },
    {
      "epoch": 0.6277587814734225,
      "grad_norm": 0.2630797326564789,
      "learning_rate": 6.861206092632888e-06,
      "loss": 0.1648,
      "step": 8078
    },
    {
      "epoch": 0.6278364936276034,
      "grad_norm": 0.2842654585838318,
      "learning_rate": 6.860817531861984e-06,
      "loss": 0.1074,
      "step": 8079
    },
    {
      "epoch": 0.6279142057817843,
      "grad_norm": 0.33316075801849365,
      "learning_rate": 6.860428971091079e-06,
      "loss": 0.0906,
      "step": 8080
    },
    {
      "epoch": 0.6279919179359652,
      "grad_norm": 0.14821980893611908,
      "learning_rate": 6.8600404103201744e-06,
      "loss": 0.0668,
      "step": 8081
    },
    {
      "epoch": 0.628069630090146,
      "grad_norm": 0.22029592096805573,
      "learning_rate": 6.85965184954927e-06,
      "loss": 0.0991,
      "step": 8082
    },
    {
      "epoch": 0.628147342244327,
      "grad_norm": 0.3729797601699829,
      "learning_rate": 6.859263288778365e-06,
      "loss": 0.1037,
      "step": 8083
    },
    {
      "epoch": 0.628225054398508,
      "grad_norm": 0.16013242304325104,
      "learning_rate": 6.858874728007461e-06,
      "loss": 0.082,
      "step": 8084
    },
    {
      "epoch": 0.6283027665526888,
      "grad_norm": 0.455886572599411,
      "learning_rate": 6.858486167236557e-06,
      "loss": 0.1087,
      "step": 8085
    },
    {
      "epoch": 0.6283804787068697,
      "grad_norm": 0.4953717887401581,
      "learning_rate": 6.858097606465651e-06,
      "loss": 0.0918,
      "step": 8086
    },
    {
      "epoch": 0.6284581908610507,
      "grad_norm": 0.21592053771018982,
      "learning_rate": 6.857709045694747e-06,
      "loss": 0.0821,
      "step": 8087
    },
    {
      "epoch": 0.6285359030152315,
      "grad_norm": 0.22193244099617004,
      "learning_rate": 6.8573204849238425e-06,
      "loss": 0.2444,
      "step": 8088
    },
    {
      "epoch": 0.6286136151694125,
      "grad_norm": 0.12593962252140045,
      "learning_rate": 6.856931924152938e-06,
      "loss": 0.0714,
      "step": 8089
    },
    {
      "epoch": 0.6286913273235935,
      "grad_norm": 0.5813689827919006,
      "learning_rate": 6.856543363382033e-06,
      "loss": 0.6768,
      "step": 8090
    },
    {
      "epoch": 0.6287690394777743,
      "grad_norm": 0.26859018206596375,
      "learning_rate": 6.856154802611129e-06,
      "loss": 0.0665,
      "step": 8091
    },
    {
      "epoch": 0.6288467516319552,
      "grad_norm": 0.10214931517839432,
      "learning_rate": 6.855766241840225e-06,
      "loss": 0.0888,
      "step": 8092
    },
    {
      "epoch": 0.6289244637861362,
      "grad_norm": 0.426229864358902,
      "learning_rate": 6.85537768106932e-06,
      "loss": 0.3327,
      "step": 8093
    },
    {
      "epoch": 0.629002175940317,
      "grad_norm": 0.7703458666801453,
      "learning_rate": 6.8549891202984156e-06,
      "loss": 0.3692,
      "step": 8094
    },
    {
      "epoch": 0.629079888094498,
      "grad_norm": 0.29361605644226074,
      "learning_rate": 6.854600559527511e-06,
      "loss": 0.1381,
      "step": 8095
    },
    {
      "epoch": 0.6291576002486788,
      "grad_norm": 0.8535390496253967,
      "learning_rate": 6.8542119987566055e-06,
      "loss": 0.3105,
      "step": 8096
    },
    {
      "epoch": 0.6292353124028598,
      "grad_norm": 0.33957719802856445,
      "learning_rate": 6.853823437985701e-06,
      "loss": 0.1298,
      "step": 8097
    },
    {
      "epoch": 0.6293130245570407,
      "grad_norm": 0.4688704013824463,
      "learning_rate": 6.853434877214797e-06,
      "loss": 0.1892,
      "step": 8098
    },
    {
      "epoch": 0.6293907367112216,
      "grad_norm": 0.5103939771652222,
      "learning_rate": 6.853046316443892e-06,
      "loss": 0.5849,
      "step": 8099
    },
    {
      "epoch": 0.6294684488654025,
      "grad_norm": 0.2735626995563507,
      "learning_rate": 6.852657755672988e-06,
      "loss": 0.1659,
      "step": 8100
    },
    {
      "epoch": 0.6295461610195835,
      "grad_norm": 0.5621991157531738,
      "learning_rate": 6.852269194902084e-06,
      "loss": 0.1971,
      "step": 8101
    },
    {
      "epoch": 0.6296238731737643,
      "grad_norm": 0.4651581048965454,
      "learning_rate": 6.8518806341311786e-06,
      "loss": 0.3979,
      "step": 8102
    },
    {
      "epoch": 0.6297015853279453,
      "grad_norm": 0.420341432094574,
      "learning_rate": 6.851492073360274e-06,
      "loss": 0.279,
      "step": 8103
    },
    {
      "epoch": 0.6297792974821262,
      "grad_norm": 0.315762996673584,
      "learning_rate": 6.85110351258937e-06,
      "loss": 0.137,
      "step": 8104
    },
    {
      "epoch": 0.6298570096363071,
      "grad_norm": 0.33112967014312744,
      "learning_rate": 6.850714951818464e-06,
      "loss": 0.0466,
      "step": 8105
    },
    {
      "epoch": 0.629934721790488,
      "grad_norm": 0.2414301335811615,
      "learning_rate": 6.85032639104756e-06,
      "loss": 0.1637,
      "step": 8106
    },
    {
      "epoch": 0.630012433944669,
      "grad_norm": 0.16659694910049438,
      "learning_rate": 6.849937830276656e-06,
      "loss": 0.0286,
      "step": 8107
    },
    {
      "epoch": 0.6300901460988498,
      "grad_norm": 0.0922403410077095,
      "learning_rate": 6.849549269505751e-06,
      "loss": 0.0314,
      "step": 8108
    },
    {
      "epoch": 0.6301678582530308,
      "grad_norm": 0.13475431501865387,
      "learning_rate": 6.849160708734847e-06,
      "loss": 0.0461,
      "step": 8109
    },
    {
      "epoch": 0.6302455704072117,
      "grad_norm": 0.2272673100233078,
      "learning_rate": 6.848772147963942e-06,
      "loss": 0.1063,
      "step": 8110
    },
    {
      "epoch": 0.6303232825613926,
      "grad_norm": 0.2771155536174774,
      "learning_rate": 6.848383587193037e-06,
      "loss": 0.0519,
      "step": 8111
    },
    {
      "epoch": 0.6304009947155735,
      "grad_norm": 0.43721455335617065,
      "learning_rate": 6.847995026422133e-06,
      "loss": 0.2152,
      "step": 8112
    },
    {
      "epoch": 0.6304787068697544,
      "grad_norm": 0.4380464255809784,
      "learning_rate": 6.847606465651229e-06,
      "loss": 0.1264,
      "step": 8113
    },
    {
      "epoch": 0.6305564190239353,
      "grad_norm": 0.2750730514526367,
      "learning_rate": 6.847217904880323e-06,
      "loss": 0.2539,
      "step": 8114
    },
    {
      "epoch": 0.6306341311781163,
      "grad_norm": 0.08784975856542587,
      "learning_rate": 6.846829344109419e-06,
      "loss": 0.023,
      "step": 8115
    },
    {
      "epoch": 0.6307118433322971,
      "grad_norm": 0.2106064260005951,
      "learning_rate": 6.846440783338515e-06,
      "loss": 0.0543,
      "step": 8116
    },
    {
      "epoch": 0.6307895554864781,
      "grad_norm": 0.13567902147769928,
      "learning_rate": 6.84605222256761e-06,
      "loss": 0.0258,
      "step": 8117
    },
    {
      "epoch": 0.630867267640659,
      "grad_norm": 0.1290816366672516,
      "learning_rate": 6.845663661796705e-06,
      "loss": 0.0284,
      "step": 8118
    },
    {
      "epoch": 0.6309449797948399,
      "grad_norm": 0.37317728996276855,
      "learning_rate": 6.845275101025801e-06,
      "loss": 0.1858,
      "step": 8119
    },
    {
      "epoch": 0.6310226919490208,
      "grad_norm": 0.280098557472229,
      "learning_rate": 6.844886540254897e-06,
      "loss": 0.1242,
      "step": 8120
    },
    {
      "epoch": 0.6311004041032018,
      "grad_norm": 0.9786351919174194,
      "learning_rate": 6.844497979483992e-06,
      "loss": 0.3405,
      "step": 8121
    },
    {
      "epoch": 0.6311781162573826,
      "grad_norm": 0.11790578067302704,
      "learning_rate": 6.844109418713088e-06,
      "loss": 0.0772,
      "step": 8122
    },
    {
      "epoch": 0.6312558284115636,
      "grad_norm": 0.16941048204898834,
      "learning_rate": 6.8437208579421835e-06,
      "loss": 0.0666,
      "step": 8123
    },
    {
      "epoch": 0.6313335405657445,
      "grad_norm": 0.10189168900251389,
      "learning_rate": 6.843332297171278e-06,
      "loss": 0.0221,
      "step": 8124
    },
    {
      "epoch": 0.6314112527199254,
      "grad_norm": 0.16153478622436523,
      "learning_rate": 6.842943736400373e-06,
      "loss": 0.1365,
      "step": 8125
    },
    {
      "epoch": 0.6314889648741063,
      "grad_norm": 0.10996033251285553,
      "learning_rate": 6.842555175629469e-06,
      "loss": 0.064,
      "step": 8126
    },
    {
      "epoch": 0.6315666770282872,
      "grad_norm": 0.25751858949661255,
      "learning_rate": 6.842166614858564e-06,
      "loss": 0.1168,
      "step": 8127
    },
    {
      "epoch": 0.6316443891824681,
      "grad_norm": 0.42552635073661804,
      "learning_rate": 6.84177805408766e-06,
      "loss": 0.0827,
      "step": 8128
    },
    {
      "epoch": 0.6317221013366491,
      "grad_norm": 0.25030502676963806,
      "learning_rate": 6.841389493316756e-06,
      "loss": 0.0614,
      "step": 8129
    },
    {
      "epoch": 0.6317998134908299,
      "grad_norm": 0.3461381196975708,
      "learning_rate": 6.841000932545851e-06,
      "loss": 0.3532,
      "step": 8130
    },
    {
      "epoch": 0.6318775256450109,
      "grad_norm": 0.5691120028495789,
      "learning_rate": 6.8406123717749465e-06,
      "loss": 0.3396,
      "step": 8131
    },
    {
      "epoch": 0.6319552377991918,
      "grad_norm": 0.4578981101512909,
      "learning_rate": 6.840223811004042e-06,
      "loss": 0.235,
      "step": 8132
    },
    {
      "epoch": 0.6320329499533727,
      "grad_norm": 0.2831038236618042,
      "learning_rate": 6.839835250233136e-06,
      "loss": 0.0866,
      "step": 8133
    },
    {
      "epoch": 0.6321106621075536,
      "grad_norm": 0.19263799488544464,
      "learning_rate": 6.839446689462232e-06,
      "loss": 0.0537,
      "step": 8134
    },
    {
      "epoch": 0.6321883742617346,
      "grad_norm": 0.36236995458602905,
      "learning_rate": 6.839058128691328e-06,
      "loss": 0.1383,
      "step": 8135
    },
    {
      "epoch": 0.6322660864159154,
      "grad_norm": 0.6994431018829346,
      "learning_rate": 6.838669567920423e-06,
      "loss": 0.3221,
      "step": 8136
    },
    {
      "epoch": 0.6323437985700964,
      "grad_norm": 0.31951451301574707,
      "learning_rate": 6.838281007149519e-06,
      "loss": 0.1609,
      "step": 8137
    },
    {
      "epoch": 0.6324215107242773,
      "grad_norm": 0.5155263543128967,
      "learning_rate": 6.8378924463786145e-06,
      "loss": 0.2929,
      "step": 8138
    },
    {
      "epoch": 0.6324992228784582,
      "grad_norm": 0.3016098737716675,
      "learning_rate": 6.8375038856077095e-06,
      "loss": 0.0974,
      "step": 8139
    },
    {
      "epoch": 0.6325769350326391,
      "grad_norm": 0.3162769675254822,
      "learning_rate": 6.837115324836805e-06,
      "loss": 0.1256,
      "step": 8140
    },
    {
      "epoch": 0.6326546471868201,
      "grad_norm": 0.631725013256073,
      "learning_rate": 6.836726764065901e-06,
      "loss": 0.5005,
      "step": 8141
    },
    {
      "epoch": 0.6327323593410009,
      "grad_norm": 0.5293146371841431,
      "learning_rate": 6.836338203294995e-06,
      "loss": 0.1111,
      "step": 8142
    },
    {
      "epoch": 0.6328100714951819,
      "grad_norm": 0.373820424079895,
      "learning_rate": 6.835949642524091e-06,
      "loss": 0.3647,
      "step": 8143
    },
    {
      "epoch": 0.6328877836493627,
      "grad_norm": 0.45503130555152893,
      "learning_rate": 6.835561081753187e-06,
      "loss": 0.3092,
      "step": 8144
    },
    {
      "epoch": 0.6329654958035437,
      "grad_norm": 0.6052321791648865,
      "learning_rate": 6.835172520982282e-06,
      "loss": 0.4926,
      "step": 8145
    },
    {
      "epoch": 0.6330432079577246,
      "grad_norm": 0.11656685173511505,
      "learning_rate": 6.8347839602113775e-06,
      "loss": 0.0546,
      "step": 8146
    },
    {
      "epoch": 0.6331209201119055,
      "grad_norm": 0.6231552958488464,
      "learning_rate": 6.834395399440473e-06,
      "loss": 0.4232,
      "step": 8147
    },
    {
      "epoch": 0.6331986322660864,
      "grad_norm": 0.6233327388763428,
      "learning_rate": 6.834006838669568e-06,
      "loss": 0.251,
      "step": 8148
    },
    {
      "epoch": 0.6332763444202674,
      "grad_norm": 0.7122248411178589,
      "learning_rate": 6.833618277898664e-06,
      "loss": 0.3898,
      "step": 8149
    },
    {
      "epoch": 0.6333540565744482,
      "grad_norm": 0.2999494969844818,
      "learning_rate": 6.83322971712776e-06,
      "loss": 0.085,
      "step": 8150
    },
    {
      "epoch": 0.6334317687286292,
      "grad_norm": 0.3443205952644348,
      "learning_rate": 6.832841156356856e-06,
      "loss": 0.0842,
      "step": 8151
    },
    {
      "epoch": 0.6335094808828101,
      "grad_norm": 0.6474670767784119,
      "learning_rate": 6.83245259558595e-06,
      "loss": 1.1168,
      "step": 8152
    },
    {
      "epoch": 0.633587193036991,
      "grad_norm": 0.215067520737648,
      "learning_rate": 6.8320640348150456e-06,
      "loss": 0.0516,
      "step": 8153
    },
    {
      "epoch": 0.6336649051911719,
      "grad_norm": 0.5133432149887085,
      "learning_rate": 6.831675474044141e-06,
      "loss": 0.321,
      "step": 8154
    },
    {
      "epoch": 0.6337426173453529,
      "grad_norm": 0.11915026605129242,
      "learning_rate": 6.831286913273236e-06,
      "loss": 0.0187,
      "step": 8155
    },
    {
      "epoch": 0.6338203294995337,
      "grad_norm": 0.27488818764686584,
      "learning_rate": 6.830898352502332e-06,
      "loss": 0.2103,
      "step": 8156
    },
    {
      "epoch": 0.6338980416537147,
      "grad_norm": 0.4966694414615631,
      "learning_rate": 6.830509791731428e-06,
      "loss": 0.2424,
      "step": 8157
    },
    {
      "epoch": 0.6339757538078955,
      "grad_norm": 0.7304612994194031,
      "learning_rate": 6.830121230960523e-06,
      "loss": 0.2997,
      "step": 8158
    },
    {
      "epoch": 0.6340534659620765,
      "grad_norm": 0.3400779068470001,
      "learning_rate": 6.829732670189619e-06,
      "loss": 0.1759,
      "step": 8159
    },
    {
      "epoch": 0.6341311781162574,
      "grad_norm": 0.5232450366020203,
      "learning_rate": 6.8293441094187144e-06,
      "loss": 0.3698,
      "step": 8160
    },
    {
      "epoch": 0.6342088902704383,
      "grad_norm": 0.4093082547187805,
      "learning_rate": 6.8289555486478085e-06,
      "loss": 0.2456,
      "step": 8161
    },
    {
      "epoch": 0.6342866024246192,
      "grad_norm": 0.21436820924282074,
      "learning_rate": 6.828566987876904e-06,
      "loss": 0.0176,
      "step": 8162
    },
    {
      "epoch": 0.6343643145788002,
      "grad_norm": 0.2975926995277405,
      "learning_rate": 6.828178427106e-06,
      "loss": 0.0962,
      "step": 8163
    },
    {
      "epoch": 0.634442026732981,
      "grad_norm": 0.14536570012569427,
      "learning_rate": 6.827789866335095e-06,
      "loss": 0.0386,
      "step": 8164
    },
    {
      "epoch": 0.634519738887162,
      "grad_norm": 0.38858020305633545,
      "learning_rate": 6.827401305564191e-06,
      "loss": 0.2244,
      "step": 8165
    },
    {
      "epoch": 0.6345974510413429,
      "grad_norm": 0.8419873714447021,
      "learning_rate": 6.827012744793287e-06,
      "loss": 0.4947,
      "step": 8166
    },
    {
      "epoch": 0.6346751631955238,
      "grad_norm": 0.3291082978248596,
      "learning_rate": 6.826624184022382e-06,
      "loss": 0.0565,
      "step": 8167
    },
    {
      "epoch": 0.6347528753497047,
      "grad_norm": 0.23401561379432678,
      "learning_rate": 6.8262356232514774e-06,
      "loss": 0.0722,
      "step": 8168
    },
    {
      "epoch": 0.6348305875038857,
      "grad_norm": 0.4848812222480774,
      "learning_rate": 6.825847062480573e-06,
      "loss": 0.133,
      "step": 8169
    },
    {
      "epoch": 0.6349082996580665,
      "grad_norm": 0.32770419120788574,
      "learning_rate": 6.825458501709667e-06,
      "loss": 0.173,
      "step": 8170
    },
    {
      "epoch": 0.6349860118122475,
      "grad_norm": 0.42236679792404175,
      "learning_rate": 6.825069940938763e-06,
      "loss": 0.4027,
      "step": 8171
    },
    {
      "epoch": 0.6350637239664283,
      "grad_norm": 0.58482426404953,
      "learning_rate": 6.824681380167859e-06,
      "loss": 0.5326,
      "step": 8172
    },
    {
      "epoch": 0.6351414361206092,
      "grad_norm": 0.2696816921234131,
      "learning_rate": 6.824292819396954e-06,
      "loss": 0.194,
      "step": 8173
    },
    {
      "epoch": 0.6352191482747902,
      "grad_norm": 0.3209216892719269,
      "learning_rate": 6.82390425862605e-06,
      "loss": 0.2157,
      "step": 8174
    },
    {
      "epoch": 0.635296860428971,
      "grad_norm": 0.17945313453674316,
      "learning_rate": 6.8235156978551455e-06,
      "loss": 0.0608,
      "step": 8175
    },
    {
      "epoch": 0.635374572583152,
      "grad_norm": 0.083102747797966,
      "learning_rate": 6.82312713708424e-06,
      "loss": 0.0241,
      "step": 8176
    },
    {
      "epoch": 0.635452284737333,
      "grad_norm": 0.4595063030719757,
      "learning_rate": 6.822738576313336e-06,
      "loss": 0.1846,
      "step": 8177
    },
    {
      "epoch": 0.6355299968915138,
      "grad_norm": 0.5688199400901794,
      "learning_rate": 6.822350015542432e-06,
      "loss": 0.193,
      "step": 8178
    },
    {
      "epoch": 0.6356077090456947,
      "grad_norm": 0.08025798201560974,
      "learning_rate": 6.821961454771526e-06,
      "loss": 0.0179,
      "step": 8179
    },
    {
      "epoch": 0.6356854211998757,
      "grad_norm": 0.5903366208076477,
      "learning_rate": 6.821572894000622e-06,
      "loss": 0.246,
      "step": 8180
    },
    {
      "epoch": 0.6357631333540565,
      "grad_norm": 0.27143269777297974,
      "learning_rate": 6.821184333229718e-06,
      "loss": 0.1794,
      "step": 8181
    },
    {
      "epoch": 0.6358408455082375,
      "grad_norm": 0.2832929790019989,
      "learning_rate": 6.8207957724588135e-06,
      "loss": 0.1376,
      "step": 8182
    },
    {
      "epoch": 0.6359185576624184,
      "grad_norm": 0.09488286823034286,
      "learning_rate": 6.8204072116879085e-06,
      "loss": 0.0365,
      "step": 8183
    },
    {
      "epoch": 0.6359962698165993,
      "grad_norm": 0.3404251039028168,
      "learning_rate": 6.820018650917004e-06,
      "loss": 0.1465,
      "step": 8184
    },
    {
      "epoch": 0.6360739819707802,
      "grad_norm": 0.46524330973625183,
      "learning_rate": 6.8196300901461e-06,
      "loss": 0.2786,
      "step": 8185
    },
    {
      "epoch": 0.6361516941249612,
      "grad_norm": 0.9947360754013062,
      "learning_rate": 6.819241529375194e-06,
      "loss": 0.4199,
      "step": 8186
    },
    {
      "epoch": 0.636229406279142,
      "grad_norm": 0.33479321002960205,
      "learning_rate": 6.81885296860429e-06,
      "loss": 0.1106,
      "step": 8187
    },
    {
      "epoch": 0.636307118433323,
      "grad_norm": 0.18589511513710022,
      "learning_rate": 6.818464407833386e-06,
      "loss": 0.1071,
      "step": 8188
    },
    {
      "epoch": 0.6363848305875038,
      "grad_norm": 0.9534345269203186,
      "learning_rate": 6.818075847062481e-06,
      "loss": 0.5329,
      "step": 8189
    },
    {
      "epoch": 0.6364625427416848,
      "grad_norm": 0.6491418480873108,
      "learning_rate": 6.8176872862915765e-06,
      "loss": 0.2105,
      "step": 8190
    },
    {
      "epoch": 0.6365402548958657,
      "grad_norm": 0.2435401976108551,
      "learning_rate": 6.817298725520672e-06,
      "loss": 0.1608,
      "step": 8191
    },
    {
      "epoch": 0.6366179670500466,
      "grad_norm": 0.3721122145652771,
      "learning_rate": 6.816910164749767e-06,
      "loss": 0.1526,
      "step": 8192
    },
    {
      "epoch": 0.6366956792042275,
      "grad_norm": 0.13141806423664093,
      "learning_rate": 6.816521603978863e-06,
      "loss": 0.0217,
      "step": 8193
    },
    {
      "epoch": 0.6367733913584085,
      "grad_norm": 0.35410815477371216,
      "learning_rate": 6.816133043207959e-06,
      "loss": 0.1173,
      "step": 8194
    },
    {
      "epoch": 0.6368511035125893,
      "grad_norm": 0.1657269448041916,
      "learning_rate": 6.815744482437053e-06,
      "loss": 0.0738,
      "step": 8195
    },
    {
      "epoch": 0.6369288156667703,
      "grad_norm": 0.20914137363433838,
      "learning_rate": 6.815355921666149e-06,
      "loss": 0.0655,
      "step": 8196
    },
    {
      "epoch": 0.6370065278209512,
      "grad_norm": 0.5836530923843384,
      "learning_rate": 6.8149673608952445e-06,
      "loss": 0.0898,
      "step": 8197
    },
    {
      "epoch": 0.6370842399751321,
      "grad_norm": 0.056814759969711304,
      "learning_rate": 6.8145788001243395e-06,
      "loss": 0.0044,
      "step": 8198
    },
    {
      "epoch": 0.637161952129313,
      "grad_norm": 0.5309560894966125,
      "learning_rate": 6.814190239353435e-06,
      "loss": 0.236,
      "step": 8199
    },
    {
      "epoch": 0.637239664283494,
      "grad_norm": 0.2583715319633484,
      "learning_rate": 6.813801678582531e-06,
      "loss": 0.1557,
      "step": 8200
    },
    {
      "epoch": 0.6373173764376748,
      "grad_norm": 0.2905140221118927,
      "learning_rate": 6.813413117811626e-06,
      "loss": 0.0673,
      "step": 8201
    },
    {
      "epoch": 0.6373950885918558,
      "grad_norm": 0.7236936688423157,
      "learning_rate": 6.813024557040722e-06,
      "loss": 0.1116,
      "step": 8202
    },
    {
      "epoch": 0.6374728007460366,
      "grad_norm": 0.14793023467063904,
      "learning_rate": 6.812635996269818e-06,
      "loss": 0.1093,
      "step": 8203
    },
    {
      "epoch": 0.6375505129002176,
      "grad_norm": 0.574137806892395,
      "learning_rate": 6.812247435498912e-06,
      "loss": 0.23,
      "step": 8204
    },
    {
      "epoch": 0.6376282250543985,
      "grad_norm": 0.1603526473045349,
      "learning_rate": 6.8118588747280075e-06,
      "loss": 0.1134,
      "step": 8205
    },
    {
      "epoch": 0.6377059372085794,
      "grad_norm": 0.8534824252128601,
      "learning_rate": 6.811470313957103e-06,
      "loss": 0.1671,
      "step": 8206
    },
    {
      "epoch": 0.6377836493627603,
      "grad_norm": 2.3048336505889893,
      "learning_rate": 6.811081753186198e-06,
      "loss": 0.6232,
      "step": 8207
    },
    {
      "epoch": 0.6378613615169413,
      "grad_norm": 0.856950581073761,
      "learning_rate": 6.810693192415294e-06,
      "loss": 0.33,
      "step": 8208
    },
    {
      "epoch": 0.6379390736711221,
      "grad_norm": 0.07276159524917603,
      "learning_rate": 6.81030463164439e-06,
      "loss": 0.0165,
      "step": 8209
    },
    {
      "epoch": 0.6380167858253031,
      "grad_norm": 0.38263407349586487,
      "learning_rate": 6.809916070873486e-06,
      "loss": 0.1915,
      "step": 8210
    },
    {
      "epoch": 0.638094497979484,
      "grad_norm": 0.2764328420162201,
      "learning_rate": 6.809527510102581e-06,
      "loss": 0.0252,
      "step": 8211
    },
    {
      "epoch": 0.6381722101336649,
      "grad_norm": 0.48546698689460754,
      "learning_rate": 6.809138949331676e-06,
      "loss": 0.2268,
      "step": 8212
    },
    {
      "epoch": 0.6382499222878458,
      "grad_norm": 0.3617914021015167,
      "learning_rate": 6.808750388560772e-06,
      "loss": 0.5473,
      "step": 8213
    },
    {
      "epoch": 0.6383276344420268,
      "grad_norm": 0.15602616965770721,
      "learning_rate": 6.808361827789866e-06,
      "loss": 0.0362,
      "step": 8214
    },
    {
      "epoch": 0.6384053465962076,
      "grad_norm": 0.7765107154846191,
      "learning_rate": 6.807973267018962e-06,
      "loss": 0.2929,
      "step": 8215
    },
    {
      "epoch": 0.6384830587503886,
      "grad_norm": 0.4952906668186188,
      "learning_rate": 6.807584706248058e-06,
      "loss": 0.2935,
      "step": 8216
    },
    {
      "epoch": 0.6385607709045695,
      "grad_norm": 0.105675108730793,
      "learning_rate": 6.807196145477153e-06,
      "loss": 0.0675,
      "step": 8217
    },
    {
      "epoch": 0.6386384830587504,
      "grad_norm": 0.5628660917282104,
      "learning_rate": 6.806807584706249e-06,
      "loss": 0.3043,
      "step": 8218
    },
    {
      "epoch": 0.6387161952129313,
      "grad_norm": 0.28921517729759216,
      "learning_rate": 6.8064190239353444e-06,
      "loss": 0.0437,
      "step": 8219
    },
    {
      "epoch": 0.6387939073671122,
      "grad_norm": 0.6065170764923096,
      "learning_rate": 6.806030463164439e-06,
      "loss": 0.2868,
      "step": 8220
    },
    {
      "epoch": 0.6388716195212931,
      "grad_norm": 1.0554462671279907,
      "learning_rate": 6.805641902393535e-06,
      "loss": 0.8104,
      "step": 8221
    },
    {
      "epoch": 0.6389493316754741,
      "grad_norm": 0.21033412218093872,
      "learning_rate": 6.805253341622631e-06,
      "loss": 0.1173,
      "step": 8222
    },
    {
      "epoch": 0.6390270438296549,
      "grad_norm": 0.16462744772434235,
      "learning_rate": 6.804864780851725e-06,
      "loss": 0.0397,
      "step": 8223
    },
    {
      "epoch": 0.6391047559838359,
      "grad_norm": 0.5673933029174805,
      "learning_rate": 6.804476220080821e-06,
      "loss": 0.5628,
      "step": 8224
    },
    {
      "epoch": 0.6391824681380168,
      "grad_norm": 0.6223277449607849,
      "learning_rate": 6.804087659309917e-06,
      "loss": 0.5191,
      "step": 8225
    },
    {
      "epoch": 0.6392601802921977,
      "grad_norm": 0.27060776948928833,
      "learning_rate": 6.803699098539012e-06,
      "loss": 0.1751,
      "step": 8226
    },
    {
      "epoch": 0.6393378924463786,
      "grad_norm": 0.10380759835243225,
      "learning_rate": 6.803310537768107e-06,
      "loss": 0.0239,
      "step": 8227
    },
    {
      "epoch": 0.6394156046005596,
      "grad_norm": 0.11439243704080582,
      "learning_rate": 6.802921976997203e-06,
      "loss": 0.021,
      "step": 8228
    },
    {
      "epoch": 0.6394933167547404,
      "grad_norm": 0.21256078779697418,
      "learning_rate": 6.802533416226298e-06,
      "loss": 0.0883,
      "step": 8229
    },
    {
      "epoch": 0.6395710289089214,
      "grad_norm": 0.2912846803665161,
      "learning_rate": 6.802144855455394e-06,
      "loss": 0.3581,
      "step": 8230
    },
    {
      "epoch": 0.6396487410631023,
      "grad_norm": 0.6991808414459229,
      "learning_rate": 6.80175629468449e-06,
      "loss": 0.1439,
      "step": 8231
    },
    {
      "epoch": 0.6397264532172832,
      "grad_norm": 0.23628529906272888,
      "learning_rate": 6.801367733913584e-06,
      "loss": 0.1346,
      "step": 8232
    },
    {
      "epoch": 0.6398041653714641,
      "grad_norm": 0.3178115785121918,
      "learning_rate": 6.80097917314268e-06,
      "loss": 0.267,
      "step": 8233
    },
    {
      "epoch": 0.639881877525645,
      "grad_norm": 0.12968270480632782,
      "learning_rate": 6.8005906123717755e-06,
      "loss": 0.02,
      "step": 8234
    },
    {
      "epoch": 0.6399595896798259,
      "grad_norm": 0.5848005414009094,
      "learning_rate": 6.80020205160087e-06,
      "loss": 0.1664,
      "step": 8235
    },
    {
      "epoch": 0.6400373018340069,
      "grad_norm": 0.5000823736190796,
      "learning_rate": 6.799813490829966e-06,
      "loss": 0.0356,
      "step": 8236
    },
    {
      "epoch": 0.6401150139881877,
      "grad_norm": 0.6393483877182007,
      "learning_rate": 6.799424930059062e-06,
      "loss": 0.2878,
      "step": 8237
    },
    {
      "epoch": 0.6401927261423687,
      "grad_norm": 0.30914241075515747,
      "learning_rate": 6.799036369288157e-06,
      "loss": 0.1069,
      "step": 8238
    },
    {
      "epoch": 0.6402704382965496,
      "grad_norm": 0.1617969423532486,
      "learning_rate": 6.798647808517253e-06,
      "loss": 0.0719,
      "step": 8239
    },
    {
      "epoch": 0.6403481504507305,
      "grad_norm": 0.09730391949415207,
      "learning_rate": 6.7982592477463485e-06,
      "loss": 0.0112,
      "step": 8240
    },
    {
      "epoch": 0.6404258626049114,
      "grad_norm": 0.11730111390352249,
      "learning_rate": 6.797870686975444e-06,
      "loss": 0.0321,
      "step": 8241
    },
    {
      "epoch": 0.6405035747590924,
      "grad_norm": 0.2853148877620697,
      "learning_rate": 6.7974821262045384e-06,
      "loss": 0.2503,
      "step": 8242
    },
    {
      "epoch": 0.6405812869132732,
      "grad_norm": 0.1460484266281128,
      "learning_rate": 6.797093565433634e-06,
      "loss": 0.0576,
      "step": 8243
    },
    {
      "epoch": 0.6406589990674542,
      "grad_norm": 0.4080682694911957,
      "learning_rate": 6.79670500466273e-06,
      "loss": 0.1358,
      "step": 8244
    },
    {
      "epoch": 0.6407367112216351,
      "grad_norm": 0.2189202904701233,
      "learning_rate": 6.796316443891825e-06,
      "loss": 0.0259,
      "step": 8245
    },
    {
      "epoch": 0.640814423375816,
      "grad_norm": 0.7338063716888428,
      "learning_rate": 6.795927883120921e-06,
      "loss": 0.2662,
      "step": 8246
    },
    {
      "epoch": 0.6408921355299969,
      "grad_norm": 0.2971448600292206,
      "learning_rate": 6.795539322350017e-06,
      "loss": 0.2249,
      "step": 8247
    },
    {
      "epoch": 0.6409698476841778,
      "grad_norm": 0.3092885911464691,
      "learning_rate": 6.7951507615791115e-06,
      "loss": 0.1869,
      "step": 8248
    },
    {
      "epoch": 0.6410475598383587,
      "grad_norm": 0.09565669298171997,
      "learning_rate": 6.794762200808207e-06,
      "loss": 0.0265,
      "step": 8249
    },
    {
      "epoch": 0.6411252719925397,
      "grad_norm": 0.6264451742172241,
      "learning_rate": 6.794373640037303e-06,
      "loss": 0.2073,
      "step": 8250
    },
    {
      "epoch": 0.6412029841467205,
      "grad_norm": 0.5199618935585022,
      "learning_rate": 6.793985079266397e-06,
      "loss": 0.2301,
      "step": 8251
    },
    {
      "epoch": 0.6412806963009015,
      "grad_norm": 0.1627349704504013,
      "learning_rate": 6.793596518495493e-06,
      "loss": 0.0408,
      "step": 8252
    },
    {
      "epoch": 0.6413584084550824,
      "grad_norm": 0.23087622225284576,
      "learning_rate": 6.793207957724589e-06,
      "loss": 0.0781,
      "step": 8253
    },
    {
      "epoch": 0.6414361206092632,
      "grad_norm": 0.13344140350818634,
      "learning_rate": 6.792819396953684e-06,
      "loss": 0.0891,
      "step": 8254
    },
    {
      "epoch": 0.6415138327634442,
      "grad_norm": 0.25923430919647217,
      "learning_rate": 6.7924308361827796e-06,
      "loss": 0.1382,
      "step": 8255
    },
    {
      "epoch": 0.6415915449176252,
      "grad_norm": 0.49924615025520325,
      "learning_rate": 6.792042275411875e-06,
      "loss": 0.1888,
      "step": 8256
    },
    {
      "epoch": 0.641669257071806,
      "grad_norm": 0.6745517253875732,
      "learning_rate": 6.79165371464097e-06,
      "loss": 0.1664,
      "step": 8257
    },
    {
      "epoch": 0.641746969225987,
      "grad_norm": 0.2077568620443344,
      "learning_rate": 6.791265153870066e-06,
      "loss": 0.0985,
      "step": 8258
    },
    {
      "epoch": 0.6418246813801679,
      "grad_norm": 0.4139646589756012,
      "learning_rate": 6.790876593099162e-06,
      "loss": 0.3308,
      "step": 8259
    },
    {
      "epoch": 0.6419023935343487,
      "grad_norm": 0.6267724633216858,
      "learning_rate": 6.790488032328256e-06,
      "loss": 0.3536,
      "step": 8260
    },
    {
      "epoch": 0.6419801056885297,
      "grad_norm": 0.19914722442626953,
      "learning_rate": 6.790099471557352e-06,
      "loss": 0.0722,
      "step": 8261
    },
    {
      "epoch": 0.6420578178427107,
      "grad_norm": 0.22875474393367767,
      "learning_rate": 6.789710910786448e-06,
      "loss": 0.1538,
      "step": 8262
    },
    {
      "epoch": 0.6421355299968915,
      "grad_norm": 0.6432526111602783,
      "learning_rate": 6.7893223500155425e-06,
      "loss": 0.1789,
      "step": 8263
    },
    {
      "epoch": 0.6422132421510724,
      "grad_norm": 0.42208755016326904,
      "learning_rate": 6.788933789244638e-06,
      "loss": 0.2025,
      "step": 8264
    },
    {
      "epoch": 0.6422909543052533,
      "grad_norm": 0.5593858361244202,
      "learning_rate": 6.788545228473734e-06,
      "loss": 0.213,
      "step": 8265
    },
    {
      "epoch": 0.6423686664594342,
      "grad_norm": 0.4655908942222595,
      "learning_rate": 6.788156667702829e-06,
      "loss": 0.2948,
      "step": 8266
    },
    {
      "epoch": 0.6424463786136152,
      "grad_norm": 0.537858247756958,
      "learning_rate": 6.787768106931925e-06,
      "loss": 0.5086,
      "step": 8267
    },
    {
      "epoch": 0.642524090767796,
      "grad_norm": 0.18801145255565643,
      "learning_rate": 6.787379546161021e-06,
      "loss": 0.108,
      "step": 8268
    },
    {
      "epoch": 0.642601802921977,
      "grad_norm": 0.13837873935699463,
      "learning_rate": 6.786990985390115e-06,
      "loss": 0.0259,
      "step": 8269
    },
    {
      "epoch": 0.642679515076158,
      "grad_norm": 0.35626763105392456,
      "learning_rate": 6.786602424619211e-06,
      "loss": 0.4606,
      "step": 8270
    },
    {
      "epoch": 0.6427572272303388,
      "grad_norm": 0.19657763838768005,
      "learning_rate": 6.786213863848306e-06,
      "loss": 0.0397,
      "step": 8271
    },
    {
      "epoch": 0.6428349393845197,
      "grad_norm": 0.5774336457252502,
      "learning_rate": 6.785825303077402e-06,
      "loss": 0.1072,
      "step": 8272
    },
    {
      "epoch": 0.6429126515387007,
      "grad_norm": 0.5532751679420471,
      "learning_rate": 6.785436742306497e-06,
      "loss": 0.1893,
      "step": 8273
    },
    {
      "epoch": 0.6429903636928815,
      "grad_norm": 0.11852683126926422,
      "learning_rate": 6.785048181535593e-06,
      "loss": 0.0143,
      "step": 8274
    },
    {
      "epoch": 0.6430680758470625,
      "grad_norm": 0.21022818982601166,
      "learning_rate": 6.784659620764689e-06,
      "loss": 0.0277,
      "step": 8275
    },
    {
      "epoch": 0.6431457880012434,
      "grad_norm": 0.5870544910430908,
      "learning_rate": 6.784271059993784e-06,
      "loss": 0.2761,
      "step": 8276
    },
    {
      "epoch": 0.6432235001554243,
      "grad_norm": 1.2452086210250854,
      "learning_rate": 6.7838824992228795e-06,
      "loss": 0.6825,
      "step": 8277
    },
    {
      "epoch": 0.6433012123096052,
      "grad_norm": 0.3800922930240631,
      "learning_rate": 6.783493938451975e-06,
      "loss": 0.3108,
      "step": 8278
    },
    {
      "epoch": 0.6433789244637861,
      "grad_norm": 0.44653213024139404,
      "learning_rate": 6.783105377681069e-06,
      "loss": 0.2055,
      "step": 8279
    },
    {
      "epoch": 0.643456636617967,
      "grad_norm": 0.37490975856781006,
      "learning_rate": 6.782716816910165e-06,
      "loss": 0.2195,
      "step": 8280
    },
    {
      "epoch": 0.643534348772148,
      "grad_norm": 0.8710036277770996,
      "learning_rate": 6.782328256139261e-06,
      "loss": 0.3139,
      "step": 8281
    },
    {
      "epoch": 0.6436120609263288,
      "grad_norm": 0.6405338048934937,
      "learning_rate": 6.781939695368356e-06,
      "loss": 0.4565,
      "step": 8282
    },
    {
      "epoch": 0.6436897730805098,
      "grad_norm": 0.1334928423166275,
      "learning_rate": 6.781551134597452e-06,
      "loss": 0.0656,
      "step": 8283
    },
    {
      "epoch": 0.6437674852346907,
      "grad_norm": 0.16863389313220978,
      "learning_rate": 6.7811625738265475e-06,
      "loss": 0.1679,
      "step": 8284
    },
    {
      "epoch": 0.6438451973888716,
      "grad_norm": 0.34687626361846924,
      "learning_rate": 6.7807740130556425e-06,
      "loss": 0.083,
      "step": 8285
    },
    {
      "epoch": 0.6439229095430525,
      "grad_norm": 0.23249702155590057,
      "learning_rate": 6.780385452284738e-06,
      "loss": 0.1817,
      "step": 8286
    },
    {
      "epoch": 0.6440006216972335,
      "grad_norm": 0.5042385458946228,
      "learning_rate": 6.779996891513834e-06,
      "loss": 0.2611,
      "step": 8287
    },
    {
      "epoch": 0.6440783338514143,
      "grad_norm": 0.3331410884857178,
      "learning_rate": 6.779608330742928e-06,
      "loss": 0.2237,
      "step": 8288
    },
    {
      "epoch": 0.6441560460055953,
      "grad_norm": 0.1096607893705368,
      "learning_rate": 6.779219769972024e-06,
      "loss": 0.0152,
      "step": 8289
    },
    {
      "epoch": 0.6442337581597762,
      "grad_norm": 0.27916279435157776,
      "learning_rate": 6.77883120920112e-06,
      "loss": 0.3049,
      "step": 8290
    },
    {
      "epoch": 0.6443114703139571,
      "grad_norm": 0.2112460881471634,
      "learning_rate": 6.778442648430215e-06,
      "loss": 0.0955,
      "step": 8291
    },
    {
      "epoch": 0.644389182468138,
      "grad_norm": 0.5861762762069702,
      "learning_rate": 6.7780540876593105e-06,
      "loss": 0.3261,
      "step": 8292
    },
    {
      "epoch": 0.6444668946223189,
      "grad_norm": 0.3574507534503937,
      "learning_rate": 6.777665526888406e-06,
      "loss": 0.095,
      "step": 8293
    },
    {
      "epoch": 0.6445446067764998,
      "grad_norm": 0.36147162318229675,
      "learning_rate": 6.777276966117501e-06,
      "loss": 0.2141,
      "step": 8294
    },
    {
      "epoch": 0.6446223189306808,
      "grad_norm": 0.17814002931118011,
      "learning_rate": 6.776888405346597e-06,
      "loss": 0.083,
      "step": 8295
    },
    {
      "epoch": 0.6447000310848616,
      "grad_norm": 0.06672199070453644,
      "learning_rate": 6.776499844575693e-06,
      "loss": 0.0209,
      "step": 8296
    },
    {
      "epoch": 0.6447777432390426,
      "grad_norm": 0.5608132481575012,
      "learning_rate": 6.776111283804787e-06,
      "loss": 0.2131,
      "step": 8297
    },
    {
      "epoch": 0.6448554553932235,
      "grad_norm": 0.5684788227081299,
      "learning_rate": 6.775722723033883e-06,
      "loss": 0.1844,
      "step": 8298
    },
    {
      "epoch": 0.6449331675474044,
      "grad_norm": 0.6412315368652344,
      "learning_rate": 6.7753341622629785e-06,
      "loss": 0.1827,
      "step": 8299
    },
    {
      "epoch": 0.6450108797015853,
      "grad_norm": 0.5019077658653259,
      "learning_rate": 6.7749456014920735e-06,
      "loss": 0.1021,
      "step": 8300
    },
    {
      "epoch": 0.6450885918557663,
      "grad_norm": 0.39701661467552185,
      "learning_rate": 6.774557040721169e-06,
      "loss": 0.1012,
      "step": 8301
    },
    {
      "epoch": 0.6451663040099471,
      "grad_norm": 0.4946311116218567,
      "learning_rate": 6.774168479950265e-06,
      "loss": 0.3256,
      "step": 8302
    },
    {
      "epoch": 0.6452440161641281,
      "grad_norm": 0.37506335973739624,
      "learning_rate": 6.773779919179361e-06,
      "loss": 0.1667,
      "step": 8303
    },
    {
      "epoch": 0.645321728318309,
      "grad_norm": 0.14646437764167786,
      "learning_rate": 6.773391358408456e-06,
      "loss": 0.0601,
      "step": 8304
    },
    {
      "epoch": 0.6453994404724899,
      "grad_norm": 0.4153401553630829,
      "learning_rate": 6.773002797637552e-06,
      "loss": 0.1103,
      "step": 8305
    },
    {
      "epoch": 0.6454771526266708,
      "grad_norm": 0.3267606794834137,
      "learning_rate": 6.7726142368666466e-06,
      "loss": 0.1712,
      "step": 8306
    },
    {
      "epoch": 0.6455548647808518,
      "grad_norm": 0.18563906848430634,
      "learning_rate": 6.7722256760957415e-06,
      "loss": 0.0874,
      "step": 8307
    },
    {
      "epoch": 0.6456325769350326,
      "grad_norm": 0.18116851150989532,
      "learning_rate": 6.771837115324837e-06,
      "loss": 0.08,
      "step": 8308
    },
    {
      "epoch": 0.6457102890892136,
      "grad_norm": 0.14551785588264465,
      "learning_rate": 6.771448554553933e-06,
      "loss": 0.0879,
      "step": 8309
    },
    {
      "epoch": 0.6457880012433944,
      "grad_norm": 1.3102730512619019,
      "learning_rate": 6.771059993783028e-06,
      "loss": 0.4207,
      "step": 8310
    },
    {
      "epoch": 0.6458657133975754,
      "grad_norm": 0.17143502831459045,
      "learning_rate": 6.770671433012124e-06,
      "loss": 0.049,
      "step": 8311
    },
    {
      "epoch": 0.6459434255517563,
      "grad_norm": 0.20022068917751312,
      "learning_rate": 6.77028287224122e-06,
      "loss": 0.0501,
      "step": 8312
    },
    {
      "epoch": 0.6460211377059372,
      "grad_norm": 0.28646498918533325,
      "learning_rate": 6.769894311470314e-06,
      "loss": 0.0359,
      "step": 8313
    },
    {
      "epoch": 0.6460988498601181,
      "grad_norm": 0.8559104204177856,
      "learning_rate": 6.7695057506994096e-06,
      "loss": 0.3348,
      "step": 8314
    },
    {
      "epoch": 0.6461765620142991,
      "grad_norm": 0.26310908794403076,
      "learning_rate": 6.769117189928505e-06,
      "loss": 0.1147,
      "step": 8315
    },
    {
      "epoch": 0.6462542741684799,
      "grad_norm": 0.6636956930160522,
      "learning_rate": 6.7687286291576e-06,
      "loss": 0.2602,
      "step": 8316
    },
    {
      "epoch": 0.6463319863226609,
      "grad_norm": 1.0207585096359253,
      "learning_rate": 6.768340068386696e-06,
      "loss": 0.2011,
      "step": 8317
    },
    {
      "epoch": 0.6464096984768418,
      "grad_norm": 0.23090557754039764,
      "learning_rate": 6.767951507615792e-06,
      "loss": 0.0751,
      "step": 8318
    },
    {
      "epoch": 0.6464874106310227,
      "grad_norm": 0.8327046036720276,
      "learning_rate": 6.767562946844887e-06,
      "loss": 0.4835,
      "step": 8319
    },
    {
      "epoch": 0.6465651227852036,
      "grad_norm": 0.9210362434387207,
      "learning_rate": 6.767174386073983e-06,
      "loss": 0.3931,
      "step": 8320
    },
    {
      "epoch": 0.6466428349393846,
      "grad_norm": 0.02897607907652855,
      "learning_rate": 6.7667858253030784e-06,
      "loss": 0.0025,
      "step": 8321
    },
    {
      "epoch": 0.6467205470935654,
      "grad_norm": 0.30410587787628174,
      "learning_rate": 6.7663972645321725e-06,
      "loss": 0.1156,
      "step": 8322
    },
    {
      "epoch": 0.6467982592477464,
      "grad_norm": 0.14621587097644806,
      "learning_rate": 6.766008703761268e-06,
      "loss": 0.0487,
      "step": 8323
    },
    {
      "epoch": 0.6468759714019272,
      "grad_norm": 0.4357892572879791,
      "learning_rate": 6.765620142990364e-06,
      "loss": 0.2094,
      "step": 8324
    },
    {
      "epoch": 0.6469536835561082,
      "grad_norm": 0.2880233824253082,
      "learning_rate": 6.765231582219459e-06,
      "loss": 0.1178,
      "step": 8325
    },
    {
      "epoch": 0.6470313957102891,
      "grad_norm": 0.2916104793548584,
      "learning_rate": 6.764843021448555e-06,
      "loss": 0.1309,
      "step": 8326
    },
    {
      "epoch": 0.64710910786447,
      "grad_norm": 0.7185860276222229,
      "learning_rate": 6.764454460677651e-06,
      "loss": 0.2719,
      "step": 8327
    },
    {
      "epoch": 0.6471868200186509,
      "grad_norm": 0.21469056606292725,
      "learning_rate": 6.764065899906746e-06,
      "loss": 0.112,
      "step": 8328
    },
    {
      "epoch": 0.6472645321728319,
      "grad_norm": 0.255720853805542,
      "learning_rate": 6.763677339135841e-06,
      "loss": 0.1247,
      "step": 8329
    },
    {
      "epoch": 0.6473422443270127,
      "grad_norm": 0.13977083563804626,
      "learning_rate": 6.763288778364937e-06,
      "loss": 0.0298,
      "step": 8330
    },
    {
      "epoch": 0.6474199564811937,
      "grad_norm": 0.33476999402046204,
      "learning_rate": 6.762900217594033e-06,
      "loss": 0.1557,
      "step": 8331
    },
    {
      "epoch": 0.6474976686353746,
      "grad_norm": 0.153519868850708,
      "learning_rate": 6.762511656823127e-06,
      "loss": 0.0509,
      "step": 8332
    },
    {
      "epoch": 0.6475753807895555,
      "grad_norm": 0.1888766586780548,
      "learning_rate": 6.762123096052223e-06,
      "loss": 0.0409,
      "step": 8333
    },
    {
      "epoch": 0.6476530929437364,
      "grad_norm": 0.43147462606430054,
      "learning_rate": 6.761734535281319e-06,
      "loss": 0.1457,
      "step": 8334
    },
    {
      "epoch": 0.6477308050979174,
      "grad_norm": 0.41588374972343445,
      "learning_rate": 6.761345974510414e-06,
      "loss": 0.2448,
      "step": 8335
    },
    {
      "epoch": 0.6478085172520982,
      "grad_norm": 0.17920374870300293,
      "learning_rate": 6.7609574137395095e-06,
      "loss": 0.0374,
      "step": 8336
    },
    {
      "epoch": 0.6478862294062792,
      "grad_norm": 0.45021429657936096,
      "learning_rate": 6.760568852968605e-06,
      "loss": 0.3866,
      "step": 8337
    },
    {
      "epoch": 0.6479639415604601,
      "grad_norm": 0.25878670811653137,
      "learning_rate": 6.7601802921977e-06,
      "loss": 0.1168,
      "step": 8338
    },
    {
      "epoch": 0.648041653714641,
      "grad_norm": 0.1604640781879425,
      "learning_rate": 6.759791731426796e-06,
      "loss": 0.056,
      "step": 8339
    },
    {
      "epoch": 0.6481193658688219,
      "grad_norm": 0.31896302103996277,
      "learning_rate": 6.759403170655892e-06,
      "loss": 0.5416,
      "step": 8340
    },
    {
      "epoch": 0.6481970780230027,
      "grad_norm": 0.4365377128124237,
      "learning_rate": 6.759014609884986e-06,
      "loss": 0.0884,
      "step": 8341
    },
    {
      "epoch": 0.6482747901771837,
      "grad_norm": 0.36226871609687805,
      "learning_rate": 6.758626049114082e-06,
      "loss": 0.1042,
      "step": 8342
    },
    {
      "epoch": 0.6483525023313647,
      "grad_norm": 0.21967847645282745,
      "learning_rate": 6.7582374883431775e-06,
      "loss": 0.0919,
      "step": 8343
    },
    {
      "epoch": 0.6484302144855455,
      "grad_norm": 0.16195513308048248,
      "learning_rate": 6.7578489275722724e-06,
      "loss": 0.0443,
      "step": 8344
    },
    {
      "epoch": 0.6485079266397265,
      "grad_norm": 0.12223165482282639,
      "learning_rate": 6.757460366801368e-06,
      "loss": 0.0296,
      "step": 8345
    },
    {
      "epoch": 0.6485856387939074,
      "grad_norm": 0.5471470355987549,
      "learning_rate": 6.757071806030464e-06,
      "loss": 0.1373,
      "step": 8346
    },
    {
      "epoch": 0.6486633509480882,
      "grad_norm": 0.3393189311027527,
      "learning_rate": 6.756683245259559e-06,
      "loss": 0.237,
      "step": 8347
    },
    {
      "epoch": 0.6487410631022692,
      "grad_norm": 0.31381291151046753,
      "learning_rate": 6.756294684488655e-06,
      "loss": 0.0996,
      "step": 8348
    },
    {
      "epoch": 0.6488187752564502,
      "grad_norm": 1.0505695343017578,
      "learning_rate": 6.755906123717751e-06,
      "loss": 0.2708,
      "step": 8349
    },
    {
      "epoch": 0.648896487410631,
      "grad_norm": 0.3838154971599579,
      "learning_rate": 6.755517562946845e-06,
      "loss": 0.094,
      "step": 8350
    },
    {
      "epoch": 0.648974199564812,
      "grad_norm": 2.0329301357269287,
      "learning_rate": 6.7551290021759405e-06,
      "loss": 0.6716,
      "step": 8351
    },
    {
      "epoch": 0.6490519117189929,
      "grad_norm": 0.6572142839431763,
      "learning_rate": 6.754740441405036e-06,
      "loss": 0.2983,
      "step": 8352
    },
    {
      "epoch": 0.6491296238731737,
      "grad_norm": 0.09588268399238586,
      "learning_rate": 6.754351880634131e-06,
      "loss": 0.0284,
      "step": 8353
    },
    {
      "epoch": 0.6492073360273547,
      "grad_norm": 0.3325420022010803,
      "learning_rate": 6.753963319863227e-06,
      "loss": 0.1927,
      "step": 8354
    },
    {
      "epoch": 0.6492850481815355,
      "grad_norm": 0.5361099243164062,
      "learning_rate": 6.753574759092323e-06,
      "loss": 0.3356,
      "step": 8355
    },
    {
      "epoch": 0.6493627603357165,
      "grad_norm": 0.3531656861305237,
      "learning_rate": 6.753186198321418e-06,
      "loss": 0.2337,
      "step": 8356
    },
    {
      "epoch": 0.6494404724898974,
      "grad_norm": 0.7577845454216003,
      "learning_rate": 6.7527976375505136e-06,
      "loss": 0.2297,
      "step": 8357
    },
    {
      "epoch": 0.6495181846440783,
      "grad_norm": 0.5410721302032471,
      "learning_rate": 6.752409076779609e-06,
      "loss": 0.1235,
      "step": 8358
    },
    {
      "epoch": 0.6495958967982592,
      "grad_norm": 0.19249440729618073,
      "learning_rate": 6.7520205160087035e-06,
      "loss": 0.0409,
      "step": 8359
    },
    {
      "epoch": 0.6496736089524402,
      "grad_norm": 0.8502791523933411,
      "learning_rate": 6.751631955237799e-06,
      "loss": 0.4126,
      "step": 8360
    },
    {
      "epoch": 0.649751321106621,
      "grad_norm": 0.373963862657547,
      "learning_rate": 6.751243394466895e-06,
      "loss": 0.5394,
      "step": 8361
    },
    {
      "epoch": 0.649829033260802,
      "grad_norm": 0.25622686743736267,
      "learning_rate": 6.750854833695991e-06,
      "loss": 0.1491,
      "step": 8362
    },
    {
      "epoch": 0.649906745414983,
      "grad_norm": 0.4346385598182678,
      "learning_rate": 6.750466272925086e-06,
      "loss": 0.1834,
      "step": 8363
    },
    {
      "epoch": 0.6499844575691638,
      "grad_norm": 1.7715628147125244,
      "learning_rate": 6.750077712154182e-06,
      "loss": 0.3763,
      "step": 8364
    },
    {
      "epoch": 0.6500621697233447,
      "grad_norm": 0.2208007425069809,
      "learning_rate": 6.749689151383277e-06,
      "loss": 0.0678,
      "step": 8365
    },
    {
      "epoch": 0.6501398818775257,
      "grad_norm": 0.2055829018354416,
      "learning_rate": 6.749300590612372e-06,
      "loss": 0.083,
      "step": 8366
    },
    {
      "epoch": 0.6502175940317065,
      "grad_norm": 0.2392108142375946,
      "learning_rate": 6.748912029841468e-06,
      "loss": 0.0829,
      "step": 8367
    },
    {
      "epoch": 0.6502953061858875,
      "grad_norm": 0.28675007820129395,
      "learning_rate": 6.748523469070564e-06,
      "loss": 0.057,
      "step": 8368
    },
    {
      "epoch": 0.6503730183400683,
      "grad_norm": 1.2617554664611816,
      "learning_rate": 6.748134908299658e-06,
      "loss": 0.5942,
      "step": 8369
    },
    {
      "epoch": 0.6504507304942493,
      "grad_norm": 1.4360870122909546,
      "learning_rate": 6.747746347528754e-06,
      "loss": 0.3319,
      "step": 8370
    },
    {
      "epoch": 0.6505284426484302,
      "grad_norm": 0.16848993301391602,
      "learning_rate": 6.74735778675785e-06,
      "loss": 0.136,
      "step": 8371
    },
    {
      "epoch": 0.6506061548026111,
      "grad_norm": 0.500346302986145,
      "learning_rate": 6.746969225986945e-06,
      "loss": 0.3655,
      "step": 8372
    },
    {
      "epoch": 0.650683866956792,
      "grad_norm": 0.89686518907547,
      "learning_rate": 6.74658066521604e-06,
      "loss": 0.5379,
      "step": 8373
    },
    {
      "epoch": 0.650761579110973,
      "grad_norm": 0.29146048426628113,
      "learning_rate": 6.746192104445136e-06,
      "loss": 0.1337,
      "step": 8374
    },
    {
      "epoch": 0.6508392912651538,
      "grad_norm": 1.8374873399734497,
      "learning_rate": 6.745803543674231e-06,
      "loss": 0.3743,
      "step": 8375
    },
    {
      "epoch": 0.6509170034193348,
      "grad_norm": 0.48546063899993896,
      "learning_rate": 6.745414982903327e-06,
      "loss": 0.187,
      "step": 8376
    },
    {
      "epoch": 0.6509947155735157,
      "grad_norm": 0.4228585362434387,
      "learning_rate": 6.745026422132423e-06,
      "loss": 0.2435,
      "step": 8377
    },
    {
      "epoch": 0.6510724277276966,
      "grad_norm": 0.2361723780632019,
      "learning_rate": 6.744637861361517e-06,
      "loss": 0.1179,
      "step": 8378
    },
    {
      "epoch": 0.6511501398818775,
      "grad_norm": 0.2707630395889282,
      "learning_rate": 6.744249300590613e-06,
      "loss": 0.0621,
      "step": 8379
    },
    {
      "epoch": 0.6512278520360585,
      "grad_norm": 0.2830730080604553,
      "learning_rate": 6.7438607398197084e-06,
      "loss": 0.18,
      "step": 8380
    },
    {
      "epoch": 0.6513055641902393,
      "grad_norm": 0.5294950604438782,
      "learning_rate": 6.743472179048803e-06,
      "loss": 0.0956,
      "step": 8381
    },
    {
      "epoch": 0.6513832763444203,
      "grad_norm": 0.988620936870575,
      "learning_rate": 6.743083618277899e-06,
      "loss": 0.2433,
      "step": 8382
    },
    {
      "epoch": 0.6514609884986012,
      "grad_norm": 0.5385313630104065,
      "learning_rate": 6.742695057506995e-06,
      "loss": 0.2717,
      "step": 8383
    },
    {
      "epoch": 0.6515387006527821,
      "grad_norm": 0.17813703417778015,
      "learning_rate": 6.74230649673609e-06,
      "loss": 0.0606,
      "step": 8384
    },
    {
      "epoch": 0.651616412806963,
      "grad_norm": 0.20849932730197906,
      "learning_rate": 6.741917935965186e-06,
      "loss": 0.0915,
      "step": 8385
    },
    {
      "epoch": 0.6516941249611439,
      "grad_norm": 0.09358277916908264,
      "learning_rate": 6.7415293751942815e-06,
      "loss": 0.0595,
      "step": 8386
    },
    {
      "epoch": 0.6517718371153248,
      "grad_norm": 0.3007424771785736,
      "learning_rate": 6.741140814423376e-06,
      "loss": 0.2538,
      "step": 8387
    },
    {
      "epoch": 0.6518495492695058,
      "grad_norm": 0.44812995195388794,
      "learning_rate": 6.740752253652471e-06,
      "loss": 0.1064,
      "step": 8388
    },
    {
      "epoch": 0.6519272614236866,
      "grad_norm": 0.11564610153436661,
      "learning_rate": 6.740363692881567e-06,
      "loss": 0.0559,
      "step": 8389
    },
    {
      "epoch": 0.6520049735778676,
      "grad_norm": 0.2891867458820343,
      "learning_rate": 6.739975132110662e-06,
      "loss": 0.1893,
      "step": 8390
    },
    {
      "epoch": 0.6520826857320485,
      "grad_norm": 0.2983219027519226,
      "learning_rate": 6.739586571339758e-06,
      "loss": 0.0848,
      "step": 8391
    },
    {
      "epoch": 0.6521603978862294,
      "grad_norm": 0.1973293125629425,
      "learning_rate": 6.739198010568854e-06,
      "loss": 0.1805,
      "step": 8392
    },
    {
      "epoch": 0.6522381100404103,
      "grad_norm": 0.2720204293727875,
      "learning_rate": 6.7388094497979495e-06,
      "loss": 0.0826,
      "step": 8393
    },
    {
      "epoch": 0.6523158221945913,
      "grad_norm": 0.33466726541519165,
      "learning_rate": 6.7384208890270445e-06,
      "loss": 0.2798,
      "step": 8394
    },
    {
      "epoch": 0.6523935343487721,
      "grad_norm": 0.3708769977092743,
      "learning_rate": 6.73803232825614e-06,
      "loss": 0.2501,
      "step": 8395
    },
    {
      "epoch": 0.6524712465029531,
      "grad_norm": 1.4131896495819092,
      "learning_rate": 6.737643767485236e-06,
      "loss": 0.665,
      "step": 8396
    },
    {
      "epoch": 0.652548958657134,
      "grad_norm": 0.4262850880622864,
      "learning_rate": 6.73725520671433e-06,
      "loss": 0.2412,
      "step": 8397
    },
    {
      "epoch": 0.6526266708113149,
      "grad_norm": 0.6692748069763184,
      "learning_rate": 6.736866645943426e-06,
      "loss": 0.2944,
      "step": 8398
    },
    {
      "epoch": 0.6527043829654958,
      "grad_norm": 0.5156620740890503,
      "learning_rate": 6.736478085172522e-06,
      "loss": 0.1982,
      "step": 8399
    },
    {
      "epoch": 0.6527820951196767,
      "grad_norm": 0.40482351183891296,
      "learning_rate": 6.736089524401617e-06,
      "loss": 0.1479,
      "step": 8400
    },
    {
      "epoch": 0.6528598072738576,
      "grad_norm": 0.44498056173324585,
      "learning_rate": 6.7357009636307125e-06,
      "loss": 0.2528,
      "step": 8401
    },
    {
      "epoch": 0.6529375194280386,
      "grad_norm": 0.38112881779670715,
      "learning_rate": 6.735312402859808e-06,
      "loss": 0.2304,
      "step": 8402
    },
    {
      "epoch": 0.6530152315822194,
      "grad_norm": 0.12396321445703506,
      "learning_rate": 6.734923842088903e-06,
      "loss": 0.072,
      "step": 8403
    },
    {
      "epoch": 0.6530929437364004,
      "grad_norm": 0.7569522261619568,
      "learning_rate": 6.734535281317999e-06,
      "loss": 0.2423,
      "step": 8404
    },
    {
      "epoch": 0.6531706558905813,
      "grad_norm": 0.3882688879966736,
      "learning_rate": 6.734146720547095e-06,
      "loss": 0.1394,
      "step": 8405
    },
    {
      "epoch": 0.6532483680447622,
      "grad_norm": 0.4502975642681122,
      "learning_rate": 6.733758159776189e-06,
      "loss": 0.2207,
      "step": 8406
    },
    {
      "epoch": 0.6533260801989431,
      "grad_norm": 0.28364691138267517,
      "learning_rate": 6.733369599005285e-06,
      "loss": 0.041,
      "step": 8407
    },
    {
      "epoch": 0.6534037923531241,
      "grad_norm": 0.2782858610153198,
      "learning_rate": 6.7329810382343806e-06,
      "loss": 0.0862,
      "step": 8408
    },
    {
      "epoch": 0.6534815045073049,
      "grad_norm": 0.4368230104446411,
      "learning_rate": 6.7325924774634755e-06,
      "loss": 0.3563,
      "step": 8409
    },
    {
      "epoch": 0.6535592166614859,
      "grad_norm": 0.45985808968544006,
      "learning_rate": 6.732203916692571e-06,
      "loss": 0.2931,
      "step": 8410
    },
    {
      "epoch": 0.6536369288156668,
      "grad_norm": 0.13384437561035156,
      "learning_rate": 6.731815355921667e-06,
      "loss": 0.0274,
      "step": 8411
    },
    {
      "epoch": 0.6537146409698477,
      "grad_norm": 0.44472286105155945,
      "learning_rate": 6.731426795150762e-06,
      "loss": 0.083,
      "step": 8412
    },
    {
      "epoch": 0.6537923531240286,
      "grad_norm": 0.13870690762996674,
      "learning_rate": 6.731038234379858e-06,
      "loss": 0.0385,
      "step": 8413
    },
    {
      "epoch": 0.6538700652782096,
      "grad_norm": 0.3640977740287781,
      "learning_rate": 6.730649673608954e-06,
      "loss": 0.0718,
      "step": 8414
    },
    {
      "epoch": 0.6539477774323904,
      "grad_norm": 0.37487223744392395,
      "learning_rate": 6.730261112838048e-06,
      "loss": 0.2302,
      "step": 8415
    },
    {
      "epoch": 0.6540254895865714,
      "grad_norm": 0.16304725408554077,
      "learning_rate": 6.7298725520671436e-06,
      "loss": 0.0616,
      "step": 8416
    },
    {
      "epoch": 0.6541032017407522,
      "grad_norm": 0.4944838583469391,
      "learning_rate": 6.729483991296239e-06,
      "loss": 0.537,
      "step": 8417
    },
    {
      "epoch": 0.6541809138949332,
      "grad_norm": 0.28837093710899353,
      "learning_rate": 6.729095430525334e-06,
      "loss": 0.0545,
      "step": 8418
    },
    {
      "epoch": 0.6542586260491141,
      "grad_norm": 0.9908074140548706,
      "learning_rate": 6.72870686975443e-06,
      "loss": 0.3568,
      "step": 8419
    },
    {
      "epoch": 0.654336338203295,
      "grad_norm": 0.9028184413909912,
      "learning_rate": 6.728318308983526e-06,
      "loss": 0.9939,
      "step": 8420
    },
    {
      "epoch": 0.6544140503574759,
      "grad_norm": 0.3412407636642456,
      "learning_rate": 6.727929748212621e-06,
      "loss": 0.3233,
      "step": 8421
    },
    {
      "epoch": 0.6544917625116569,
      "grad_norm": 1.1127784252166748,
      "learning_rate": 6.727541187441717e-06,
      "loss": 0.153,
      "step": 8422
    },
    {
      "epoch": 0.6545694746658377,
      "grad_norm": 0.1461331993341446,
      "learning_rate": 6.7271526266708124e-06,
      "loss": 0.0247,
      "step": 8423
    },
    {
      "epoch": 0.6546471868200187,
      "grad_norm": 0.4554762542247772,
      "learning_rate": 6.726764065899908e-06,
      "loss": 0.1419,
      "step": 8424
    },
    {
      "epoch": 0.6547248989741996,
      "grad_norm": 0.5111348628997803,
      "learning_rate": 6.726375505129002e-06,
      "loss": 0.2511,
      "step": 8425
    },
    {
      "epoch": 0.6548026111283805,
      "grad_norm": 0.6961393356323242,
      "learning_rate": 6.725986944358098e-06,
      "loss": 0.3217,
      "step": 8426
    },
    {
      "epoch": 0.6548803232825614,
      "grad_norm": 0.2034188061952591,
      "learning_rate": 6.725598383587194e-06,
      "loss": 0.0267,
      "step": 8427
    },
    {
      "epoch": 0.6549580354367424,
      "grad_norm": 0.3932039141654968,
      "learning_rate": 6.725209822816289e-06,
      "loss": 0.1266,
      "step": 8428
    },
    {
      "epoch": 0.6550357475909232,
      "grad_norm": 0.46339288353919983,
      "learning_rate": 6.724821262045385e-06,
      "loss": 0.5298,
      "step": 8429
    },
    {
      "epoch": 0.6551134597451042,
      "grad_norm": 0.06115814670920372,
      "learning_rate": 6.7244327012744805e-06,
      "loss": 0.015,
      "step": 8430
    },
    {
      "epoch": 0.655191171899285,
      "grad_norm": 0.24854186177253723,
      "learning_rate": 6.7240441405035754e-06,
      "loss": 0.3473,
      "step": 8431
    },
    {
      "epoch": 0.655268884053466,
      "grad_norm": 0.29552170634269714,
      "learning_rate": 6.723655579732671e-06,
      "loss": 0.332,
      "step": 8432
    },
    {
      "epoch": 0.6553465962076469,
      "grad_norm": 0.12449148297309875,
      "learning_rate": 6.723267018961766e-06,
      "loss": 0.053,
      "step": 8433
    },
    {
      "epoch": 0.6554243083618277,
      "grad_norm": 0.20607666671276093,
      "learning_rate": 6.722878458190861e-06,
      "loss": 0.0678,
      "step": 8434
    },
    {
      "epoch": 0.6555020205160087,
      "grad_norm": 0.6509159207344055,
      "learning_rate": 6.722489897419957e-06,
      "loss": 0.2509,
      "step": 8435
    },
    {
      "epoch": 0.6555797326701897,
      "grad_norm": 0.5063977837562561,
      "learning_rate": 6.722101336649053e-06,
      "loss": 0.232,
      "step": 8436
    },
    {
      "epoch": 0.6556574448243705,
      "grad_norm": 0.8504931330680847,
      "learning_rate": 6.721712775878148e-06,
      "loss": 0.23,
      "step": 8437
    },
    {
      "epoch": 0.6557351569785514,
      "grad_norm": 0.2684851884841919,
      "learning_rate": 6.7213242151072435e-06,
      "loss": 0.0627,
      "step": 8438
    },
    {
      "epoch": 0.6558128691327324,
      "grad_norm": 0.2189171463251114,
      "learning_rate": 6.720935654336339e-06,
      "loss": 0.0998,
      "step": 8439
    },
    {
      "epoch": 0.6558905812869132,
      "grad_norm": 0.5516647100448608,
      "learning_rate": 6.720547093565433e-06,
      "loss": 0.2718,
      "step": 8440
    },
    {
      "epoch": 0.6559682934410942,
      "grad_norm": 0.5893736481666565,
      "learning_rate": 6.720158532794529e-06,
      "loss": 0.1456,
      "step": 8441
    },
    {
      "epoch": 0.6560460055952752,
      "grad_norm": 0.3728133738040924,
      "learning_rate": 6.719769972023625e-06,
      "loss": 0.413,
      "step": 8442
    },
    {
      "epoch": 0.656123717749456,
      "grad_norm": 1.1892054080963135,
      "learning_rate": 6.71938141125272e-06,
      "loss": 0.3135,
      "step": 8443
    },
    {
      "epoch": 0.656201429903637,
      "grad_norm": 0.390697181224823,
      "learning_rate": 6.718992850481816e-06,
      "loss": 0.2336,
      "step": 8444
    },
    {
      "epoch": 0.6562791420578178,
      "grad_norm": 1.4125384092330933,
      "learning_rate": 6.7186042897109115e-06,
      "loss": 0.3923,
      "step": 8445
    },
    {
      "epoch": 0.6563568542119987,
      "grad_norm": 0.23870152235031128,
      "learning_rate": 6.7182157289400064e-06,
      "loss": 0.1299,
      "step": 8446
    },
    {
      "epoch": 0.6564345663661797,
      "grad_norm": 0.17766420543193817,
      "learning_rate": 6.717827168169102e-06,
      "loss": 0.0781,
      "step": 8447
    },
    {
      "epoch": 0.6565122785203605,
      "grad_norm": 0.7221782207489014,
      "learning_rate": 6.717438607398198e-06,
      "loss": 0.5204,
      "step": 8448
    },
    {
      "epoch": 0.6565899906745415,
      "grad_norm": 0.3577917814254761,
      "learning_rate": 6.717050046627292e-06,
      "loss": 0.5325,
      "step": 8449
    },
    {
      "epoch": 0.6566677028287224,
      "grad_norm": 0.2079237997531891,
      "learning_rate": 6.716661485856388e-06,
      "loss": 0.064,
      "step": 8450
    },
    {
      "epoch": 0.6567454149829033,
      "grad_norm": 0.15025076270103455,
      "learning_rate": 6.716272925085484e-06,
      "loss": 0.0473,
      "step": 8451
    },
    {
      "epoch": 0.6568231271370842,
      "grad_norm": 0.3240734338760376,
      "learning_rate": 6.715884364314579e-06,
      "loss": 0.1198,
      "step": 8452
    },
    {
      "epoch": 0.6569008392912652,
      "grad_norm": 0.2374289482831955,
      "learning_rate": 6.7154958035436745e-06,
      "loss": 0.0895,
      "step": 8453
    },
    {
      "epoch": 0.656978551445446,
      "grad_norm": 0.48937034606933594,
      "learning_rate": 6.71510724277277e-06,
      "loss": 0.3104,
      "step": 8454
    },
    {
      "epoch": 0.657056263599627,
      "grad_norm": 0.28894415497779846,
      "learning_rate": 6.714718682001866e-06,
      "loss": 0.0223,
      "step": 8455
    },
    {
      "epoch": 0.6571339757538079,
      "grad_norm": 0.6119074821472168,
      "learning_rate": 6.714330121230961e-06,
      "loss": 0.2868,
      "step": 8456
    },
    {
      "epoch": 0.6572116879079888,
      "grad_norm": 0.4510851800441742,
      "learning_rate": 6.713941560460057e-06,
      "loss": 0.3087,
      "step": 8457
    },
    {
      "epoch": 0.6572894000621697,
      "grad_norm": 0.1528996229171753,
      "learning_rate": 6.713552999689153e-06,
      "loss": 0.0636,
      "step": 8458
    },
    {
      "epoch": 0.6573671122163507,
      "grad_norm": 0.798274040222168,
      "learning_rate": 6.713164438918247e-06,
      "loss": 0.5512,
      "step": 8459
    },
    {
      "epoch": 0.6574448243705315,
      "grad_norm": 0.6349182724952698,
      "learning_rate": 6.7127758781473425e-06,
      "loss": 0.8088,
      "step": 8460
    },
    {
      "epoch": 0.6575225365247125,
      "grad_norm": 0.6072515845298767,
      "learning_rate": 6.712387317376438e-06,
      "loss": 0.4559,
      "step": 8461
    },
    {
      "epoch": 0.6576002486788933,
      "grad_norm": 0.5394991636276245,
      "learning_rate": 6.711998756605533e-06,
      "loss": 0.5544,
      "step": 8462
    },
    {
      "epoch": 0.6576779608330743,
      "grad_norm": 0.2703033685684204,
      "learning_rate": 6.711610195834629e-06,
      "loss": 0.0487,
      "step": 8463
    },
    {
      "epoch": 0.6577556729872552,
      "grad_norm": 0.34655988216400146,
      "learning_rate": 6.711221635063725e-06,
      "loss": 0.0659,
      "step": 8464
    },
    {
      "epoch": 0.6578333851414361,
      "grad_norm": 0.18791857361793518,
      "learning_rate": 6.71083307429282e-06,
      "loss": 0.0237,
      "step": 8465
    },
    {
      "epoch": 0.657911097295617,
      "grad_norm": 0.5226200819015503,
      "learning_rate": 6.710444513521916e-06,
      "loss": 0.2086,
      "step": 8466
    },
    {
      "epoch": 0.657988809449798,
      "grad_norm": 0.23053722083568573,
      "learning_rate": 6.710055952751011e-06,
      "loss": 0.0366,
      "step": 8467
    },
    {
      "epoch": 0.6580665216039788,
      "grad_norm": 0.3769541382789612,
      "learning_rate": 6.7096673919801055e-06,
      "loss": 0.2862,
      "step": 8468
    },
    {
      "epoch": 0.6581442337581598,
      "grad_norm": 0.5667997598648071,
      "learning_rate": 6.709278831209201e-06,
      "loss": 0.2308,
      "step": 8469
    },
    {
      "epoch": 0.6582219459123407,
      "grad_norm": 0.1490623652935028,
      "learning_rate": 6.708890270438297e-06,
      "loss": 0.0396,
      "step": 8470
    },
    {
      "epoch": 0.6582996580665216,
      "grad_norm": 0.2993822693824768,
      "learning_rate": 6.708501709667392e-06,
      "loss": 0.1331,
      "step": 8471
    },
    {
      "epoch": 0.6583773702207025,
      "grad_norm": 0.4024132490158081,
      "learning_rate": 6.708113148896488e-06,
      "loss": 0.0987,
      "step": 8472
    },
    {
      "epoch": 0.6584550823748835,
      "grad_norm": 0.6402744650840759,
      "learning_rate": 6.707724588125584e-06,
      "loss": 0.4552,
      "step": 8473
    },
    {
      "epoch": 0.6585327945290643,
      "grad_norm": 0.21117530763149261,
      "learning_rate": 6.707336027354679e-06,
      "loss": 0.0875,
      "step": 8474
    },
    {
      "epoch": 0.6586105066832453,
      "grad_norm": 0.49744099378585815,
      "learning_rate": 6.706947466583774e-06,
      "loss": 0.3107,
      "step": 8475
    },
    {
      "epoch": 0.6586882188374261,
      "grad_norm": 0.21524158120155334,
      "learning_rate": 6.70655890581287e-06,
      "loss": 0.0299,
      "step": 8476
    },
    {
      "epoch": 0.6587659309916071,
      "grad_norm": 0.6132307648658752,
      "learning_rate": 6.706170345041964e-06,
      "loss": 0.3246,
      "step": 8477
    },
    {
      "epoch": 0.658843643145788,
      "grad_norm": 0.09896270185709,
      "learning_rate": 6.70578178427106e-06,
      "loss": 0.0258,
      "step": 8478
    },
    {
      "epoch": 0.6589213552999689,
      "grad_norm": 1.4159945249557495,
      "learning_rate": 6.705393223500156e-06,
      "loss": 0.6736,
      "step": 8479
    },
    {
      "epoch": 0.6589990674541498,
      "grad_norm": 0.20635442435741425,
      "learning_rate": 6.705004662729251e-06,
      "loss": 0.0661,
      "step": 8480
    },
    {
      "epoch": 0.6590767796083308,
      "grad_norm": 0.2703026235103607,
      "learning_rate": 6.704616101958347e-06,
      "loss": 0.121,
      "step": 8481
    },
    {
      "epoch": 0.6591544917625116,
      "grad_norm": 0.44920626282691956,
      "learning_rate": 6.7042275411874424e-06,
      "loss": 0.1772,
      "step": 8482
    },
    {
      "epoch": 0.6592322039166926,
      "grad_norm": 0.19594359397888184,
      "learning_rate": 6.703838980416538e-06,
      "loss": 0.1428,
      "step": 8483
    },
    {
      "epoch": 0.6593099160708735,
      "grad_norm": 0.20213823020458221,
      "learning_rate": 6.703450419645633e-06,
      "loss": 0.0256,
      "step": 8484
    },
    {
      "epoch": 0.6593876282250544,
      "grad_norm": 0.2895689904689789,
      "learning_rate": 6.703061858874729e-06,
      "loss": 0.1035,
      "step": 8485
    },
    {
      "epoch": 0.6594653403792353,
      "grad_norm": 0.4477364122867584,
      "learning_rate": 6.702673298103825e-06,
      "loss": 0.2676,
      "step": 8486
    },
    {
      "epoch": 0.6595430525334163,
      "grad_norm": 0.37587276101112366,
      "learning_rate": 6.702284737332919e-06,
      "loss": 0.1951,
      "step": 8487
    },
    {
      "epoch": 0.6596207646875971,
      "grad_norm": 0.23167820274829865,
      "learning_rate": 6.701896176562015e-06,
      "loss": 0.0148,
      "step": 8488
    },
    {
      "epoch": 0.6596984768417781,
      "grad_norm": 0.4147947132587433,
      "learning_rate": 6.7015076157911105e-06,
      "loss": 0.0917,
      "step": 8489
    },
    {
      "epoch": 0.659776188995959,
      "grad_norm": 0.1597760170698166,
      "learning_rate": 6.701119055020205e-06,
      "loss": 0.0982,
      "step": 8490
    },
    {
      "epoch": 0.6598539011501399,
      "grad_norm": 0.8462361097335815,
      "learning_rate": 6.700730494249301e-06,
      "loss": 0.429,
      "step": 8491
    },
    {
      "epoch": 0.6599316133043208,
      "grad_norm": 0.43096062541007996,
      "learning_rate": 6.700341933478397e-06,
      "loss": 0.1274,
      "step": 8492
    },
    {
      "epoch": 0.6600093254585017,
      "grad_norm": 0.33324235677719116,
      "learning_rate": 6.699953372707492e-06,
      "loss": 0.0458,
      "step": 8493
    },
    {
      "epoch": 0.6600870376126826,
      "grad_norm": 0.4108831584453583,
      "learning_rate": 6.699564811936588e-06,
      "loss": 0.3371,
      "step": 8494
    },
    {
      "epoch": 0.6601647497668636,
      "grad_norm": 0.2905310392379761,
      "learning_rate": 6.6991762511656836e-06,
      "loss": 0.035,
      "step": 8495
    },
    {
      "epoch": 0.6602424619210444,
      "grad_norm": 0.3546546697616577,
      "learning_rate": 6.698787690394778e-06,
      "loss": 0.1043,
      "step": 8496
    },
    {
      "epoch": 0.6603201740752254,
      "grad_norm": 0.4963058829307556,
      "learning_rate": 6.6983991296238735e-06,
      "loss": 0.0517,
      "step": 8497
    },
    {
      "epoch": 0.6603978862294063,
      "grad_norm": 0.5917105674743652,
      "learning_rate": 6.698010568852969e-06,
      "loss": 0.1572,
      "step": 8498
    },
    {
      "epoch": 0.6604755983835872,
      "grad_norm": 0.5605719685554504,
      "learning_rate": 6.697622008082064e-06,
      "loss": 0.2745,
      "step": 8499
    },
    {
      "epoch": 0.6605533105377681,
      "grad_norm": 0.19041503965854645,
      "learning_rate": 6.69723344731116e-06,
      "loss": 0.0795,
      "step": 8500
    },
    {
      "epoch": 0.6606310226919491,
      "grad_norm": 0.165242999792099,
      "learning_rate": 6.696844886540256e-06,
      "loss": 0.0653,
      "step": 8501
    },
    {
      "epoch": 0.6607087348461299,
      "grad_norm": 0.15202587842941284,
      "learning_rate": 6.696456325769351e-06,
      "loss": 0.101,
      "step": 8502
    },
    {
      "epoch": 0.6607864470003109,
      "grad_norm": 1.704970359802246,
      "learning_rate": 6.6960677649984465e-06,
      "loss": 0.2944,
      "step": 8503
    },
    {
      "epoch": 0.6608641591544918,
      "grad_norm": 0.7400572299957275,
      "learning_rate": 6.695679204227542e-06,
      "loss": 0.2273,
      "step": 8504
    },
    {
      "epoch": 0.6609418713086727,
      "grad_norm": 0.35993877053260803,
      "learning_rate": 6.6952906434566364e-06,
      "loss": 0.108,
      "step": 8505
    },
    {
      "epoch": 0.6610195834628536,
      "grad_norm": 0.7413418292999268,
      "learning_rate": 6.694902082685732e-06,
      "loss": 0.8611,
      "step": 8506
    },
    {
      "epoch": 0.6610972956170345,
      "grad_norm": 0.3529401123523712,
      "learning_rate": 6.694513521914828e-06,
      "loss": 0.2069,
      "step": 8507
    },
    {
      "epoch": 0.6611750077712154,
      "grad_norm": 0.05825286731123924,
      "learning_rate": 6.694124961143923e-06,
      "loss": 0.0161,
      "step": 8508
    },
    {
      "epoch": 0.6612527199253964,
      "grad_norm": 0.21046356856822968,
      "learning_rate": 6.693736400373019e-06,
      "loss": 0.0998,
      "step": 8509
    },
    {
      "epoch": 0.6613304320795772,
      "grad_norm": 0.46867668628692627,
      "learning_rate": 6.6933478396021146e-06,
      "loss": 0.2633,
      "step": 8510
    },
    {
      "epoch": 0.6614081442337582,
      "grad_norm": 0.8248688578605652,
      "learning_rate": 6.6929592788312095e-06,
      "loss": 0.9797,
      "step": 8511
    },
    {
      "epoch": 0.6614858563879391,
      "grad_norm": 0.1968010514974594,
      "learning_rate": 6.692570718060305e-06,
      "loss": 0.0689,
      "step": 8512
    },
    {
      "epoch": 0.66156356854212,
      "grad_norm": 0.046438802033662796,
      "learning_rate": 6.692182157289401e-06,
      "loss": 0.0077,
      "step": 8513
    },
    {
      "epoch": 0.6616412806963009,
      "grad_norm": 0.337048202753067,
      "learning_rate": 6.691793596518497e-06,
      "loss": 0.1029,
      "step": 8514
    },
    {
      "epoch": 0.6617189928504819,
      "grad_norm": 0.17828136682510376,
      "learning_rate": 6.691405035747591e-06,
      "loss": 0.0849,
      "step": 8515
    },
    {
      "epoch": 0.6617967050046627,
      "grad_norm": 0.5860591530799866,
      "learning_rate": 6.691016474976687e-06,
      "loss": 0.7166,
      "step": 8516
    },
    {
      "epoch": 0.6618744171588437,
      "grad_norm": 0.384976327419281,
      "learning_rate": 6.690627914205783e-06,
      "loss": 0.1865,
      "step": 8517
    },
    {
      "epoch": 0.6619521293130246,
      "grad_norm": 0.488230437040329,
      "learning_rate": 6.6902393534348776e-06,
      "loss": 0.9664,
      "step": 8518
    },
    {
      "epoch": 0.6620298414672054,
      "grad_norm": 0.06801719963550568,
      "learning_rate": 6.689850792663973e-06,
      "loss": 0.0161,
      "step": 8519
    },
    {
      "epoch": 0.6621075536213864,
      "grad_norm": 0.6754150986671448,
      "learning_rate": 6.689462231893069e-06,
      "loss": 0.1327,
      "step": 8520
    },
    {
      "epoch": 0.6621852657755672,
      "grad_norm": 0.23341645300388336,
      "learning_rate": 6.689073671122164e-06,
      "loss": 0.1161,
      "step": 8521
    },
    {
      "epoch": 0.6622629779297482,
      "grad_norm": 0.5607475638389587,
      "learning_rate": 6.68868511035126e-06,
      "loss": 0.0964,
      "step": 8522
    },
    {
      "epoch": 0.6623406900839292,
      "grad_norm": 0.33479344844818115,
      "learning_rate": 6.688296549580356e-06,
      "loss": 0.0695,
      "step": 8523
    },
    {
      "epoch": 0.66241840223811,
      "grad_norm": 0.5109893679618835,
      "learning_rate": 6.68790798880945e-06,
      "loss": 0.1628,
      "step": 8524
    },
    {
      "epoch": 0.662496114392291,
      "grad_norm": 0.5240286588668823,
      "learning_rate": 6.687519428038546e-06,
      "loss": 0.1452,
      "step": 8525
    },
    {
      "epoch": 0.6625738265464719,
      "grad_norm": 0.402281790971756,
      "learning_rate": 6.687130867267641e-06,
      "loss": 0.0906,
      "step": 8526
    },
    {
      "epoch": 0.6626515387006527,
      "grad_norm": 0.5609902739524841,
      "learning_rate": 6.686742306496736e-06,
      "loss": 0.7034,
      "step": 8527
    },
    {
      "epoch": 0.6627292508548337,
      "grad_norm": 0.45656004548072815,
      "learning_rate": 6.686353745725832e-06,
      "loss": 0.1144,
      "step": 8528
    },
    {
      "epoch": 0.6628069630090146,
      "grad_norm": 0.54449862241745,
      "learning_rate": 6.685965184954928e-06,
      "loss": 0.1524,
      "step": 8529
    },
    {
      "epoch": 0.6628846751631955,
      "grad_norm": 0.20179016888141632,
      "learning_rate": 6.685576624184023e-06,
      "loss": 0.0536,
      "step": 8530
    },
    {
      "epoch": 0.6629623873173764,
      "grad_norm": 0.24644644558429718,
      "learning_rate": 6.685188063413119e-06,
      "loss": 0.0668,
      "step": 8531
    },
    {
      "epoch": 0.6630400994715574,
      "grad_norm": 0.2366083860397339,
      "learning_rate": 6.6847995026422145e-06,
      "loss": 0.1922,
      "step": 8532
    },
    {
      "epoch": 0.6631178116257382,
      "grad_norm": 1.4308393001556396,
      "learning_rate": 6.684410941871309e-06,
      "loss": 0.5398,
      "step": 8533
    },
    {
      "epoch": 0.6631955237799192,
      "grad_norm": 0.6049496531486511,
      "learning_rate": 6.684022381100404e-06,
      "loss": 0.1603,
      "step": 8534
    },
    {
      "epoch": 0.6632732359341001,
      "grad_norm": 0.2155931293964386,
      "learning_rate": 6.6836338203295e-06,
      "loss": 0.1126,
      "step": 8535
    },
    {
      "epoch": 0.663350948088281,
      "grad_norm": 0.7438396215438843,
      "learning_rate": 6.683245259558595e-06,
      "loss": 0.2524,
      "step": 8536
    },
    {
      "epoch": 0.6634286602424619,
      "grad_norm": 0.5867747068405151,
      "learning_rate": 6.682856698787691e-06,
      "loss": 0.2633,
      "step": 8537
    },
    {
      "epoch": 0.6635063723966428,
      "grad_norm": 0.29091110825538635,
      "learning_rate": 6.682468138016787e-06,
      "loss": 0.1309,
      "step": 8538
    },
    {
      "epoch": 0.6635840845508237,
      "grad_norm": 1.5760490894317627,
      "learning_rate": 6.682079577245882e-06,
      "loss": 0.3407,
      "step": 8539
    },
    {
      "epoch": 0.6636617967050047,
      "grad_norm": 0.16777303814888,
      "learning_rate": 6.6816910164749775e-06,
      "loss": 0.0545,
      "step": 8540
    },
    {
      "epoch": 0.6637395088591855,
      "grad_norm": 0.29650697112083435,
      "learning_rate": 6.681302455704073e-06,
      "loss": 0.0233,
      "step": 8541
    },
    {
      "epoch": 0.6638172210133665,
      "grad_norm": 0.5041741728782654,
      "learning_rate": 6.680913894933167e-06,
      "loss": 0.1043,
      "step": 8542
    },
    {
      "epoch": 0.6638949331675474,
      "grad_norm": 0.23338676989078522,
      "learning_rate": 6.680525334162263e-06,
      "loss": 0.0134,
      "step": 8543
    },
    {
      "epoch": 0.6639726453217283,
      "grad_norm": 0.40262648463249207,
      "learning_rate": 6.680136773391359e-06,
      "loss": 0.148,
      "step": 8544
    },
    {
      "epoch": 0.6640503574759092,
      "grad_norm": 0.49000996351242065,
      "learning_rate": 6.679748212620455e-06,
      "loss": 0.1735,
      "step": 8545
    },
    {
      "epoch": 0.6641280696300902,
      "grad_norm": 0.5753723382949829,
      "learning_rate": 6.67935965184955e-06,
      "loss": 0.2267,
      "step": 8546
    },
    {
      "epoch": 0.664205781784271,
      "grad_norm": 0.45770782232284546,
      "learning_rate": 6.6789710910786455e-06,
      "loss": 0.1032,
      "step": 8547
    },
    {
      "epoch": 0.664283493938452,
      "grad_norm": 0.7324761748313904,
      "learning_rate": 6.678582530307741e-06,
      "loss": 0.2863,
      "step": 8548
    },
    {
      "epoch": 0.6643612060926329,
      "grad_norm": 0.21336044371128082,
      "learning_rate": 6.678193969536836e-06,
      "loss": 0.0908,
      "step": 8549
    },
    {
      "epoch": 0.6644389182468138,
      "grad_norm": 0.4035011827945709,
      "learning_rate": 6.677805408765932e-06,
      "loss": 0.2075,
      "step": 8550
    },
    {
      "epoch": 0.6645166304009947,
      "grad_norm": 0.05700848624110222,
      "learning_rate": 6.677416847995028e-06,
      "loss": 0.0071,
      "step": 8551
    },
    {
      "epoch": 0.6645943425551756,
      "grad_norm": 0.3931941092014313,
      "learning_rate": 6.677028287224122e-06,
      "loss": 0.1033,
      "step": 8552
    },
    {
      "epoch": 0.6646720547093565,
      "grad_norm": 0.4759640097618103,
      "learning_rate": 6.676639726453218e-06,
      "loss": 0.0988,
      "step": 8553
    },
    {
      "epoch": 0.6647497668635375,
      "grad_norm": 0.3460395932197571,
      "learning_rate": 6.6762511656823135e-06,
      "loss": 0.0697,
      "step": 8554
    },
    {
      "epoch": 0.6648274790177183,
      "grad_norm": 0.8892078995704651,
      "learning_rate": 6.6758626049114085e-06,
      "loss": 0.3884,
      "step": 8555
    },
    {
      "epoch": 0.6649051911718993,
      "grad_norm": 0.38519325852394104,
      "learning_rate": 6.675474044140504e-06,
      "loss": 0.1211,
      "step": 8556
    },
    {
      "epoch": 0.6649829033260802,
      "grad_norm": 0.36411142349243164,
      "learning_rate": 6.6750854833696e-06,
      "loss": 0.2891,
      "step": 8557
    },
    {
      "epoch": 0.6650606154802611,
      "grad_norm": 0.3763251006603241,
      "learning_rate": 6.674696922598695e-06,
      "loss": 0.0598,
      "step": 8558
    },
    {
      "epoch": 0.665138327634442,
      "grad_norm": 0.7448155879974365,
      "learning_rate": 6.67430836182779e-06,
      "loss": 0.1294,
      "step": 8559
    },
    {
      "epoch": 0.665216039788623,
      "grad_norm": 0.37321674823760986,
      "learning_rate": 6.673919801056886e-06,
      "loss": 0.2397,
      "step": 8560
    },
    {
      "epoch": 0.6652937519428038,
      "grad_norm": 0.3451182246208191,
      "learning_rate": 6.673531240285981e-06,
      "loss": 0.1462,
      "step": 8561
    },
    {
      "epoch": 0.6653714640969848,
      "grad_norm": 0.4907148778438568,
      "learning_rate": 6.6731426795150765e-06,
      "loss": 0.2466,
      "step": 8562
    },
    {
      "epoch": 0.6654491762511657,
      "grad_norm": 0.6267277598381042,
      "learning_rate": 6.672754118744172e-06,
      "loss": 0.6934,
      "step": 8563
    },
    {
      "epoch": 0.6655268884053466,
      "grad_norm": 0.2340271919965744,
      "learning_rate": 6.672365557973267e-06,
      "loss": 0.0442,
      "step": 8564
    },
    {
      "epoch": 0.6656046005595275,
      "grad_norm": 0.47815626859664917,
      "learning_rate": 6.671976997202363e-06,
      "loss": 0.286,
      "step": 8565
    },
    {
      "epoch": 0.6656823127137085,
      "grad_norm": 0.22917059063911438,
      "learning_rate": 6.671588436431459e-06,
      "loss": 0.0537,
      "step": 8566
    },
    {
      "epoch": 0.6657600248678893,
      "grad_norm": 0.17437930405139923,
      "learning_rate": 6.671199875660553e-06,
      "loss": 0.0632,
      "step": 8567
    },
    {
      "epoch": 0.6658377370220703,
      "grad_norm": 0.5250449776649475,
      "learning_rate": 6.670811314889649e-06,
      "loss": 0.3217,
      "step": 8568
    },
    {
      "epoch": 0.6659154491762511,
      "grad_norm": 0.5285605788230896,
      "learning_rate": 6.6704227541187446e-06,
      "loss": 0.2475,
      "step": 8569
    },
    {
      "epoch": 0.6659931613304321,
      "grad_norm": 0.3642747700214386,
      "learning_rate": 6.6700341933478395e-06,
      "loss": 0.1234,
      "step": 8570
    },
    {
      "epoch": 0.666070873484613,
      "grad_norm": 0.755668580532074,
      "learning_rate": 6.669645632576935e-06,
      "loss": 0.2862,
      "step": 8571
    },
    {
      "epoch": 0.6661485856387939,
      "grad_norm": 0.5545519590377808,
      "learning_rate": 6.669257071806031e-06,
      "loss": 0.3706,
      "step": 8572
    },
    {
      "epoch": 0.6662262977929748,
      "grad_norm": 0.19212545454502106,
      "learning_rate": 6.668868511035126e-06,
      "loss": 0.0399,
      "step": 8573
    },
    {
      "epoch": 0.6663040099471558,
      "grad_norm": 0.8244327306747437,
      "learning_rate": 6.668479950264222e-06,
      "loss": 0.2577,
      "step": 8574
    },
    {
      "epoch": 0.6663817221013366,
      "grad_norm": 0.4312945306301117,
      "learning_rate": 6.668091389493318e-06,
      "loss": 0.0544,
      "step": 8575
    },
    {
      "epoch": 0.6664594342555176,
      "grad_norm": 0.4193304777145386,
      "learning_rate": 6.6677028287224134e-06,
      "loss": 0.2916,
      "step": 8576
    },
    {
      "epoch": 0.6665371464096985,
      "grad_norm": 0.3433742821216583,
      "learning_rate": 6.6673142679515076e-06,
      "loss": 0.1148,
      "step": 8577
    },
    {
      "epoch": 0.6666148585638794,
      "grad_norm": 0.41431522369384766,
      "learning_rate": 6.666925707180603e-06,
      "loss": 0.2225,
      "step": 8578
    },
    {
      "epoch": 0.6666925707180603,
      "grad_norm": 0.445772647857666,
      "learning_rate": 6.666537146409699e-06,
      "loss": 0.1272,
      "step": 8579
    },
    {
      "epoch": 0.6667702828722413,
      "grad_norm": 0.7777922749519348,
      "learning_rate": 6.666148585638794e-06,
      "loss": 0.5344,
      "step": 8580
    },
    {
      "epoch": 0.6668479950264221,
      "grad_norm": 0.24037989974021912,
      "learning_rate": 6.66576002486789e-06,
      "loss": 0.0978,
      "step": 8581
    },
    {
      "epoch": 0.6669257071806031,
      "grad_norm": 0.36791232228279114,
      "learning_rate": 6.665371464096986e-06,
      "loss": 0.0743,
      "step": 8582
    },
    {
      "epoch": 0.6670034193347839,
      "grad_norm": 0.5506294965744019,
      "learning_rate": 6.664982903326081e-06,
      "loss": 0.6506,
      "step": 8583
    },
    {
      "epoch": 0.6670811314889649,
      "grad_norm": 0.2993450164794922,
      "learning_rate": 6.6645943425551764e-06,
      "loss": 0.1144,
      "step": 8584
    },
    {
      "epoch": 0.6671588436431458,
      "grad_norm": 0.12212710827589035,
      "learning_rate": 6.664205781784272e-06,
      "loss": 0.0275,
      "step": 8585
    },
    {
      "epoch": 0.6672365557973267,
      "grad_norm": 0.45346006751060486,
      "learning_rate": 6.663817221013366e-06,
      "loss": 0.2523,
      "step": 8586
    },
    {
      "epoch": 0.6673142679515076,
      "grad_norm": 0.5320519804954529,
      "learning_rate": 6.663428660242462e-06,
      "loss": 0.1781,
      "step": 8587
    },
    {
      "epoch": 0.6673919801056886,
      "grad_norm": 0.39168626070022583,
      "learning_rate": 6.663040099471558e-06,
      "loss": 0.1356,
      "step": 8588
    },
    {
      "epoch": 0.6674696922598694,
      "grad_norm": 0.2944878339767456,
      "learning_rate": 6.662651538700653e-06,
      "loss": 0.1862,
      "step": 8589
    },
    {
      "epoch": 0.6675474044140504,
      "grad_norm": 0.26172760128974915,
      "learning_rate": 6.662262977929749e-06,
      "loss": 0.0693,
      "step": 8590
    },
    {
      "epoch": 0.6676251165682313,
      "grad_norm": 0.6595794558525085,
      "learning_rate": 6.6618744171588445e-06,
      "loss": 0.2402,
      "step": 8591
    },
    {
      "epoch": 0.6677028287224122,
      "grad_norm": 0.45807304978370667,
      "learning_rate": 6.661485856387939e-06,
      "loss": 0.3884,
      "step": 8592
    },
    {
      "epoch": 0.6677805408765931,
      "grad_norm": 0.5578268766403198,
      "learning_rate": 6.661097295617035e-06,
      "loss": 0.1816,
      "step": 8593
    },
    {
      "epoch": 0.6678582530307741,
      "grad_norm": 0.20803266763687134,
      "learning_rate": 6.660708734846131e-06,
      "loss": 0.0719,
      "step": 8594
    },
    {
      "epoch": 0.6679359651849549,
      "grad_norm": 0.27761879563331604,
      "learning_rate": 6.660320174075225e-06,
      "loss": 0.1028,
      "step": 8595
    },
    {
      "epoch": 0.6680136773391359,
      "grad_norm": 2.3933582305908203,
      "learning_rate": 6.659931613304321e-06,
      "loss": 0.6471,
      "step": 8596
    },
    {
      "epoch": 0.6680913894933167,
      "grad_norm": 0.18624837696552277,
      "learning_rate": 6.659543052533417e-06,
      "loss": 0.0991,
      "step": 8597
    },
    {
      "epoch": 0.6681691016474977,
      "grad_norm": 0.31665900349617004,
      "learning_rate": 6.659154491762512e-06,
      "loss": 0.605,
      "step": 8598
    },
    {
      "epoch": 0.6682468138016786,
      "grad_norm": 0.6013637781143188,
      "learning_rate": 6.6587659309916075e-06,
      "loss": 0.3659,
      "step": 8599
    },
    {
      "epoch": 0.6683245259558594,
      "grad_norm": 0.22993935644626617,
      "learning_rate": 6.658377370220703e-06,
      "loss": 0.0632,
      "step": 8600
    },
    {
      "epoch": 0.6684022381100404,
      "grad_norm": 0.3689322769641876,
      "learning_rate": 6.657988809449798e-06,
      "loss": 0.1683,
      "step": 8601
    },
    {
      "epoch": 0.6684799502642214,
      "grad_norm": 0.29378542304039,
      "learning_rate": 6.657600248678894e-06,
      "loss": 0.1313,
      "step": 8602
    },
    {
      "epoch": 0.6685576624184022,
      "grad_norm": 0.7596105933189392,
      "learning_rate": 6.65721168790799e-06,
      "loss": 0.1261,
      "step": 8603
    },
    {
      "epoch": 0.6686353745725832,
      "grad_norm": 0.1720263659954071,
      "learning_rate": 6.656823127137086e-06,
      "loss": 0.0461,
      "step": 8604
    },
    {
      "epoch": 0.6687130867267641,
      "grad_norm": 0.6229261159896851,
      "learning_rate": 6.65643456636618e-06,
      "loss": 0.1742,
      "step": 8605
    },
    {
      "epoch": 0.668790798880945,
      "grad_norm": 0.9141741394996643,
      "learning_rate": 6.6560460055952755e-06,
      "loss": 0.1296,
      "step": 8606
    },
    {
      "epoch": 0.6688685110351259,
      "grad_norm": 0.33002543449401855,
      "learning_rate": 6.655657444824371e-06,
      "loss": 0.1481,
      "step": 8607
    },
    {
      "epoch": 0.6689462231893069,
      "grad_norm": 0.30300676822662354,
      "learning_rate": 6.655268884053466e-06,
      "loss": 0.0781,
      "step": 8608
    },
    {
      "epoch": 0.6690239353434877,
      "grad_norm": 0.3392607867717743,
      "learning_rate": 6.654880323282562e-06,
      "loss": 0.1054,
      "step": 8609
    },
    {
      "epoch": 0.6691016474976687,
      "grad_norm": 0.16021308302879333,
      "learning_rate": 6.654491762511658e-06,
      "loss": 0.0628,
      "step": 8610
    },
    {
      "epoch": 0.6691793596518496,
      "grad_norm": 0.19306105375289917,
      "learning_rate": 6.654103201740753e-06,
      "loss": 0.0736,
      "step": 8611
    },
    {
      "epoch": 0.6692570718060304,
      "grad_norm": 0.1372365951538086,
      "learning_rate": 6.653714640969849e-06,
      "loss": 0.0443,
      "step": 8612
    },
    {
      "epoch": 0.6693347839602114,
      "grad_norm": 0.9167267084121704,
      "learning_rate": 6.653326080198944e-06,
      "loss": 1.1678,
      "step": 8613
    },
    {
      "epoch": 0.6694124961143922,
      "grad_norm": 0.21676893532276154,
      "learning_rate": 6.6529375194280385e-06,
      "loss": 0.0238,
      "step": 8614
    },
    {
      "epoch": 0.6694902082685732,
      "grad_norm": 0.08097857981920242,
      "learning_rate": 6.652548958657134e-06,
      "loss": 0.0199,
      "step": 8615
    },
    {
      "epoch": 0.6695679204227541,
      "grad_norm": 0.4233073890209198,
      "learning_rate": 6.65216039788623e-06,
      "loss": 0.4844,
      "step": 8616
    },
    {
      "epoch": 0.669645632576935,
      "grad_norm": 0.7509973645210266,
      "learning_rate": 6.651771837115325e-06,
      "loss": 0.2253,
      "step": 8617
    },
    {
      "epoch": 0.6697233447311159,
      "grad_norm": 0.4774684011936188,
      "learning_rate": 6.651383276344421e-06,
      "loss": 0.3423,
      "step": 8618
    },
    {
      "epoch": 0.6698010568852969,
      "grad_norm": 0.4684094190597534,
      "learning_rate": 6.650994715573517e-06,
      "loss": 0.3554,
      "step": 8619
    },
    {
      "epoch": 0.6698787690394777,
      "grad_norm": 1.0165575742721558,
      "learning_rate": 6.6506061548026116e-06,
      "loss": 0.3393,
      "step": 8620
    },
    {
      "epoch": 0.6699564811936587,
      "grad_norm": 0.6334206461906433,
      "learning_rate": 6.650217594031707e-06,
      "loss": 0.4729,
      "step": 8621
    },
    {
      "epoch": 0.6700341933478396,
      "grad_norm": 0.99448561668396,
      "learning_rate": 6.649829033260803e-06,
      "loss": 0.2029,
      "step": 8622
    },
    {
      "epoch": 0.6701119055020205,
      "grad_norm": 0.3452102541923523,
      "learning_rate": 6.649440472489897e-06,
      "loss": 0.209,
      "step": 8623
    },
    {
      "epoch": 0.6701896176562014,
      "grad_norm": 0.5836358070373535,
      "learning_rate": 6.649051911718993e-06,
      "loss": 0.3275,
      "step": 8624
    },
    {
      "epoch": 0.6702673298103824,
      "grad_norm": 0.27848565578460693,
      "learning_rate": 6.648663350948089e-06,
      "loss": 0.2067,
      "step": 8625
    },
    {
      "epoch": 0.6703450419645632,
      "grad_norm": 0.577427864074707,
      "learning_rate": 6.648274790177184e-06,
      "loss": 0.2844,
      "step": 8626
    },
    {
      "epoch": 0.6704227541187442,
      "grad_norm": 0.2299208790063858,
      "learning_rate": 6.64788622940628e-06,
      "loss": 0.1501,
      "step": 8627
    },
    {
      "epoch": 0.670500466272925,
      "grad_norm": 0.25126731395721436,
      "learning_rate": 6.647497668635375e-06,
      "loss": 0.1368,
      "step": 8628
    },
    {
      "epoch": 0.670578178427106,
      "grad_norm": 0.5379416942596436,
      "learning_rate": 6.64710910786447e-06,
      "loss": 0.123,
      "step": 8629
    },
    {
      "epoch": 0.6706558905812869,
      "grad_norm": 0.1522531807422638,
      "learning_rate": 6.646720547093566e-06,
      "loss": 0.0465,
      "step": 8630
    },
    {
      "epoch": 0.6707336027354678,
      "grad_norm": 0.263115793466568,
      "learning_rate": 6.646331986322662e-06,
      "loss": 0.0769,
      "step": 8631
    },
    {
      "epoch": 0.6708113148896487,
      "grad_norm": 0.34996992349624634,
      "learning_rate": 6.645943425551756e-06,
      "loss": 0.2284,
      "step": 8632
    },
    {
      "epoch": 0.6708890270438297,
      "grad_norm": 0.19185763597488403,
      "learning_rate": 6.645554864780852e-06,
      "loss": 0.0695,
      "step": 8633
    },
    {
      "epoch": 0.6709667391980105,
      "grad_norm": 0.20414766669273376,
      "learning_rate": 6.645166304009948e-06,
      "loss": 0.1185,
      "step": 8634
    },
    {
      "epoch": 0.6710444513521915,
      "grad_norm": 0.2553451359272003,
      "learning_rate": 6.6447777432390434e-06,
      "loss": 0.0924,
      "step": 8635
    },
    {
      "epoch": 0.6711221635063724,
      "grad_norm": 0.3571516275405884,
      "learning_rate": 6.644389182468138e-06,
      "loss": 0.1501,
      "step": 8636
    },
    {
      "epoch": 0.6711998756605533,
      "grad_norm": 0.6310135722160339,
      "learning_rate": 6.644000621697234e-06,
      "loss": 0.0623,
      "step": 8637
    },
    {
      "epoch": 0.6712775878147342,
      "grad_norm": 0.7671428322792053,
      "learning_rate": 6.64361206092633e-06,
      "loss": 0.1524,
      "step": 8638
    },
    {
      "epoch": 0.6713552999689152,
      "grad_norm": 0.27284494042396545,
      "learning_rate": 6.643223500155425e-06,
      "loss": 0.0439,
      "step": 8639
    },
    {
      "epoch": 0.671433012123096,
      "grad_norm": 0.13851793110370636,
      "learning_rate": 6.642834939384521e-06,
      "loss": 0.1764,
      "step": 8640
    },
    {
      "epoch": 0.671510724277277,
      "grad_norm": 0.43067216873168945,
      "learning_rate": 6.6424463786136165e-06,
      "loss": 0.3073,
      "step": 8641
    },
    {
      "epoch": 0.6715884364314578,
      "grad_norm": 0.13827504217624664,
      "learning_rate": 6.642057817842711e-06,
      "loss": 0.0196,
      "step": 8642
    },
    {
      "epoch": 0.6716661485856388,
      "grad_norm": 0.34279876947402954,
      "learning_rate": 6.641669257071806e-06,
      "loss": 0.183,
      "step": 8643
    },
    {
      "epoch": 0.6717438607398197,
      "grad_norm": 0.3725026845932007,
      "learning_rate": 6.641280696300902e-06,
      "loss": 0.1344,
      "step": 8644
    },
    {
      "epoch": 0.6718215728940006,
      "grad_norm": 0.24674294888973236,
      "learning_rate": 6.640892135529997e-06,
      "loss": 0.0666,
      "step": 8645
    },
    {
      "epoch": 0.6718992850481815,
      "grad_norm": 0.6159960627555847,
      "learning_rate": 6.640503574759093e-06,
      "loss": 0.0851,
      "step": 8646
    },
    {
      "epoch": 0.6719769972023625,
      "grad_norm": 0.6081605553627014,
      "learning_rate": 6.640115013988189e-06,
      "loss": 0.1755,
      "step": 8647
    },
    {
      "epoch": 0.6720547093565433,
      "grad_norm": 0.45789283514022827,
      "learning_rate": 6.639726453217284e-06,
      "loss": 0.196,
      "step": 8648
    },
    {
      "epoch": 0.6721324215107243,
      "grad_norm": 0.3545853793621063,
      "learning_rate": 6.6393378924463795e-06,
      "loss": 0.1277,
      "step": 8649
    },
    {
      "epoch": 0.6722101336649052,
      "grad_norm": 0.9479762315750122,
      "learning_rate": 6.638949331675475e-06,
      "loss": 0.1245,
      "step": 8650
    },
    {
      "epoch": 0.6722878458190861,
      "grad_norm": 0.44231927394866943,
      "learning_rate": 6.638560770904569e-06,
      "loss": 0.0531,
      "step": 8651
    },
    {
      "epoch": 0.672365557973267,
      "grad_norm": 0.8100659251213074,
      "learning_rate": 6.638172210133665e-06,
      "loss": 0.6694,
      "step": 8652
    },
    {
      "epoch": 0.672443270127448,
      "grad_norm": 0.17137068510055542,
      "learning_rate": 6.637783649362761e-06,
      "loss": 0.0316,
      "step": 8653
    },
    {
      "epoch": 0.6725209822816288,
      "grad_norm": 0.41737881302833557,
      "learning_rate": 6.637395088591856e-06,
      "loss": 0.1075,
      "step": 8654
    },
    {
      "epoch": 0.6725986944358098,
      "grad_norm": 0.35299158096313477,
      "learning_rate": 6.637006527820952e-06,
      "loss": 0.0389,
      "step": 8655
    },
    {
      "epoch": 0.6726764065899907,
      "grad_norm": 0.20282666385173798,
      "learning_rate": 6.6366179670500475e-06,
      "loss": 0.0598,
      "step": 8656
    },
    {
      "epoch": 0.6727541187441716,
      "grad_norm": 0.5201209187507629,
      "learning_rate": 6.6362294062791425e-06,
      "loss": 0.1583,
      "step": 8657
    },
    {
      "epoch": 0.6728318308983525,
      "grad_norm": 0.17356079816818237,
      "learning_rate": 6.635840845508238e-06,
      "loss": 0.0422,
      "step": 8658
    },
    {
      "epoch": 0.6729095430525334,
      "grad_norm": 0.5105652809143066,
      "learning_rate": 6.635452284737334e-06,
      "loss": 0.1317,
      "step": 8659
    },
    {
      "epoch": 0.6729872552067143,
      "grad_norm": 0.4612239897251129,
      "learning_rate": 6.635063723966428e-06,
      "loss": 0.0932,
      "step": 8660
    },
    {
      "epoch": 0.6730649673608953,
      "grad_norm": 0.19616198539733887,
      "learning_rate": 6.634675163195524e-06,
      "loss": 0.1802,
      "step": 8661
    },
    {
      "epoch": 0.6731426795150761,
      "grad_norm": 1.2357596158981323,
      "learning_rate": 6.63428660242462e-06,
      "loss": 0.2411,
      "step": 8662
    },
    {
      "epoch": 0.6732203916692571,
      "grad_norm": 0.4872703552246094,
      "learning_rate": 6.633898041653715e-06,
      "loss": 0.2548,
      "step": 8663
    },
    {
      "epoch": 0.673298103823438,
      "grad_norm": 0.6169801950454712,
      "learning_rate": 6.6335094808828105e-06,
      "loss": 0.3198,
      "step": 8664
    },
    {
      "epoch": 0.6733758159776189,
      "grad_norm": 0.29198703169822693,
      "learning_rate": 6.633120920111906e-06,
      "loss": 0.055,
      "step": 8665
    },
    {
      "epoch": 0.6734535281317998,
      "grad_norm": 0.24487443268299103,
      "learning_rate": 6.632732359341002e-06,
      "loss": 0.0217,
      "step": 8666
    },
    {
      "epoch": 0.6735312402859808,
      "grad_norm": 0.12287718802690506,
      "learning_rate": 6.632343798570097e-06,
      "loss": 0.0282,
      "step": 8667
    },
    {
      "epoch": 0.6736089524401616,
      "grad_norm": 0.36512625217437744,
      "learning_rate": 6.631955237799193e-06,
      "loss": 0.2092,
      "step": 8668
    },
    {
      "epoch": 0.6736866645943426,
      "grad_norm": 0.4959144592285156,
      "learning_rate": 6.631566677028289e-06,
      "loss": 0.4425,
      "step": 8669
    },
    {
      "epoch": 0.6737643767485235,
      "grad_norm": 0.5716636180877686,
      "learning_rate": 6.631178116257383e-06,
      "loss": 0.4444,
      "step": 8670
    },
    {
      "epoch": 0.6738420889027044,
      "grad_norm": 0.46942630410194397,
      "learning_rate": 6.6307895554864786e-06,
      "loss": 0.2839,
      "step": 8671
    },
    {
      "epoch": 0.6739198010568853,
      "grad_norm": 0.15042784810066223,
      "learning_rate": 6.630400994715574e-06,
      "loss": 0.098,
      "step": 8672
    },
    {
      "epoch": 0.6739975132110662,
      "grad_norm": 0.6824290156364441,
      "learning_rate": 6.630012433944669e-06,
      "loss": 0.3272,
      "step": 8673
    },
    {
      "epoch": 0.6740752253652471,
      "grad_norm": 0.3049360513687134,
      "learning_rate": 6.629623873173765e-06,
      "loss": 0.0587,
      "step": 8674
    },
    {
      "epoch": 0.6741529375194281,
      "grad_norm": 0.38731423020362854,
      "learning_rate": 6.629235312402861e-06,
      "loss": 0.1703,
      "step": 8675
    },
    {
      "epoch": 0.6742306496736089,
      "grad_norm": 0.2645178735256195,
      "learning_rate": 6.628846751631956e-06,
      "loss": 0.1482,
      "step": 8676
    },
    {
      "epoch": 0.6743083618277899,
      "grad_norm": 0.2128526270389557,
      "learning_rate": 6.628458190861052e-06,
      "loss": 0.033,
      "step": 8677
    },
    {
      "epoch": 0.6743860739819708,
      "grad_norm": 0.15245215594768524,
      "learning_rate": 6.6280696300901475e-06,
      "loss": 0.0789,
      "step": 8678
    },
    {
      "epoch": 0.6744637861361517,
      "grad_norm": 0.5895475149154663,
      "learning_rate": 6.6276810693192416e-06,
      "loss": 0.1157,
      "step": 8679
    },
    {
      "epoch": 0.6745414982903326,
      "grad_norm": 0.275899738073349,
      "learning_rate": 6.627292508548337e-06,
      "loss": 0.1786,
      "step": 8680
    },
    {
      "epoch": 0.6746192104445136,
      "grad_norm": 0.6160717010498047,
      "learning_rate": 6.626903947777433e-06,
      "loss": 0.4293,
      "step": 8681
    },
    {
      "epoch": 0.6746969225986944,
      "grad_norm": 0.8570403456687927,
      "learning_rate": 6.626515387006528e-06,
      "loss": 0.4472,
      "step": 8682
    },
    {
      "epoch": 0.6747746347528754,
      "grad_norm": 0.3513864576816559,
      "learning_rate": 6.626126826235624e-06,
      "loss": 0.2083,
      "step": 8683
    },
    {
      "epoch": 0.6748523469070563,
      "grad_norm": 0.20383517444133759,
      "learning_rate": 6.62573826546472e-06,
      "loss": 0.2053,
      "step": 8684
    },
    {
      "epoch": 0.6749300590612372,
      "grad_norm": 0.37581777572631836,
      "learning_rate": 6.625349704693815e-06,
      "loss": 0.1231,
      "step": 8685
    },
    {
      "epoch": 0.6750077712154181,
      "grad_norm": 0.3054101765155792,
      "learning_rate": 6.62496114392291e-06,
      "loss": 0.0809,
      "step": 8686
    },
    {
      "epoch": 0.6750854833695991,
      "grad_norm": 0.402252197265625,
      "learning_rate": 6.624572583152005e-06,
      "loss": 0.1184,
      "step": 8687
    },
    {
      "epoch": 0.6751631955237799,
      "grad_norm": 0.4311560392379761,
      "learning_rate": 6.6241840223811e-06,
      "loss": 0.18,
      "step": 8688
    },
    {
      "epoch": 0.6752409076779609,
      "grad_norm": 0.34345743060112,
      "learning_rate": 6.623795461610196e-06,
      "loss": 0.2395,
      "step": 8689
    },
    {
      "epoch": 0.6753186198321417,
      "grad_norm": 0.24251848459243774,
      "learning_rate": 6.623406900839292e-06,
      "loss": 0.0398,
      "step": 8690
    },
    {
      "epoch": 0.6753963319863227,
      "grad_norm": 0.6820895075798035,
      "learning_rate": 6.623018340068387e-06,
      "loss": 0.2601,
      "step": 8691
    },
    {
      "epoch": 0.6754740441405036,
      "grad_norm": 0.6163561940193176,
      "learning_rate": 6.622629779297483e-06,
      "loss": 0.2899,
      "step": 8692
    },
    {
      "epoch": 0.6755517562946844,
      "grad_norm": 0.2859705090522766,
      "learning_rate": 6.6222412185265785e-06,
      "loss": 1.0041,
      "step": 8693
    },
    {
      "epoch": 0.6756294684488654,
      "grad_norm": 0.7360695600509644,
      "learning_rate": 6.621852657755673e-06,
      "loss": 0.6641,
      "step": 8694
    },
    {
      "epoch": 0.6757071806030464,
      "grad_norm": 0.47895458340644836,
      "learning_rate": 6.621464096984768e-06,
      "loss": 0.3169,
      "step": 8695
    },
    {
      "epoch": 0.6757848927572272,
      "grad_norm": 0.08313123136758804,
      "learning_rate": 6.621075536213864e-06,
      "loss": 0.0379,
      "step": 8696
    },
    {
      "epoch": 0.6758626049114081,
      "grad_norm": 0.3679264485836029,
      "learning_rate": 6.62068697544296e-06,
      "loss": 0.1811,
      "step": 8697
    },
    {
      "epoch": 0.6759403170655891,
      "grad_norm": 0.18763025104999542,
      "learning_rate": 6.620298414672055e-06,
      "loss": 0.0904,
      "step": 8698
    },
    {
      "epoch": 0.67601802921977,
      "grad_norm": 0.5660814046859741,
      "learning_rate": 6.619909853901151e-06,
      "loss": 0.3723,
      "step": 8699
    },
    {
      "epoch": 0.6760957413739509,
      "grad_norm": 0.039140112698078156,
      "learning_rate": 6.6195212931302465e-06,
      "loss": 0.0336,
      "step": 8700
    },
    {
      "epoch": 0.6761734535281319,
      "grad_norm": 1.1141557693481445,
      "learning_rate": 6.6191327323593415e-06,
      "loss": 0.3356,
      "step": 8701
    },
    {
      "epoch": 0.6762511656823127,
      "grad_norm": 0.18658778071403503,
      "learning_rate": 6.618744171588437e-06,
      "loss": 0.0152,
      "step": 8702
    },
    {
      "epoch": 0.6763288778364936,
      "grad_norm": 0.14096026122570038,
      "learning_rate": 6.618355610817533e-06,
      "loss": 0.1135,
      "step": 8703
    },
    {
      "epoch": 0.6764065899906745,
      "grad_norm": 0.4768494963645935,
      "learning_rate": 6.617967050046627e-06,
      "loss": 0.2662,
      "step": 8704
    },
    {
      "epoch": 0.6764843021448554,
      "grad_norm": 0.0270790196955204,
      "learning_rate": 6.617578489275723e-06,
      "loss": 0.0027,
      "step": 8705
    },
    {
      "epoch": 0.6765620142990364,
      "grad_norm": 0.5150861144065857,
      "learning_rate": 6.617189928504819e-06,
      "loss": 0.2726,
      "step": 8706
    },
    {
      "epoch": 0.6766397264532172,
      "grad_norm": 0.2684077024459839,
      "learning_rate": 6.616801367733914e-06,
      "loss": 0.0488,
      "step": 8707
    },
    {
      "epoch": 0.6767174386073982,
      "grad_norm": 0.5989211201667786,
      "learning_rate": 6.6164128069630095e-06,
      "loss": 0.3462,
      "step": 8708
    },
    {
      "epoch": 0.6767951507615791,
      "grad_norm": 0.6243364214897156,
      "learning_rate": 6.616024246192105e-06,
      "loss": 0.1835,
      "step": 8709
    },
    {
      "epoch": 0.67687286291576,
      "grad_norm": 0.6021313667297363,
      "learning_rate": 6.6156356854212e-06,
      "loss": 0.2313,
      "step": 8710
    },
    {
      "epoch": 0.6769505750699409,
      "grad_norm": 0.16522355377674103,
      "learning_rate": 6.615247124650296e-06,
      "loss": 0.0393,
      "step": 8711
    },
    {
      "epoch": 0.6770282872241219,
      "grad_norm": 0.3907441794872284,
      "learning_rate": 6.614858563879392e-06,
      "loss": 0.2734,
      "step": 8712
    },
    {
      "epoch": 0.6771059993783027,
      "grad_norm": 0.1607336699962616,
      "learning_rate": 6.614470003108486e-06,
      "loss": 0.0395,
      "step": 8713
    },
    {
      "epoch": 0.6771837115324837,
      "grad_norm": 0.6069073677062988,
      "learning_rate": 6.614081442337582e-06,
      "loss": 0.1588,
      "step": 8714
    },
    {
      "epoch": 0.6772614236866646,
      "grad_norm": 0.3664924204349518,
      "learning_rate": 6.6136928815666775e-06,
      "loss": 0.0415,
      "step": 8715
    },
    {
      "epoch": 0.6773391358408455,
      "grad_norm": 0.5597965121269226,
      "learning_rate": 6.6133043207957725e-06,
      "loss": 0.3922,
      "step": 8716
    },
    {
      "epoch": 0.6774168479950264,
      "grad_norm": 0.3973667323589325,
      "learning_rate": 6.612915760024868e-06,
      "loss": 0.3355,
      "step": 8717
    },
    {
      "epoch": 0.6774945601492073,
      "grad_norm": 0.45685678720474243,
      "learning_rate": 6.612527199253964e-06,
      "loss": 0.3858,
      "step": 8718
    },
    {
      "epoch": 0.6775722723033882,
      "grad_norm": 1.8675137758255005,
      "learning_rate": 6.612138638483059e-06,
      "loss": 0.6327,
      "step": 8719
    },
    {
      "epoch": 0.6776499844575692,
      "grad_norm": 0.23318105936050415,
      "learning_rate": 6.611750077712155e-06,
      "loss": 0.0643,
      "step": 8720
    },
    {
      "epoch": 0.67772769661175,
      "grad_norm": 0.26260101795196533,
      "learning_rate": 6.611361516941251e-06,
      "loss": 0.1443,
      "step": 8721
    },
    {
      "epoch": 0.677805408765931,
      "grad_norm": 0.07981744408607483,
      "learning_rate": 6.610972956170345e-06,
      "loss": 0.0061,
      "step": 8722
    },
    {
      "epoch": 0.6778831209201119,
      "grad_norm": 0.49951305985450745,
      "learning_rate": 6.6105843953994405e-06,
      "loss": 0.4183,
      "step": 8723
    },
    {
      "epoch": 0.6779608330742928,
      "grad_norm": 0.21035803854465485,
      "learning_rate": 6.610195834628536e-06,
      "loss": 0.0391,
      "step": 8724
    },
    {
      "epoch": 0.6780385452284737,
      "grad_norm": 0.2290169596672058,
      "learning_rate": 6.609807273857631e-06,
      "loss": 0.1381,
      "step": 8725
    },
    {
      "epoch": 0.6781162573826547,
      "grad_norm": 0.579870343208313,
      "learning_rate": 6.609418713086727e-06,
      "loss": 0.5147,
      "step": 8726
    },
    {
      "epoch": 0.6781939695368355,
      "grad_norm": 0.38609611988067627,
      "learning_rate": 6.609030152315823e-06,
      "loss": 0.0739,
      "step": 8727
    },
    {
      "epoch": 0.6782716816910165,
      "grad_norm": 0.3544537127017975,
      "learning_rate": 6.608641591544919e-06,
      "loss": 0.1256,
      "step": 8728
    },
    {
      "epoch": 0.6783493938451974,
      "grad_norm": 0.33972272276878357,
      "learning_rate": 6.608253030774014e-06,
      "loss": 0.264,
      "step": 8729
    },
    {
      "epoch": 0.6784271059993783,
      "grad_norm": 0.247079536318779,
      "learning_rate": 6.607864470003109e-06,
      "loss": 0.0525,
      "step": 8730
    },
    {
      "epoch": 0.6785048181535592,
      "grad_norm": 0.34918490052223206,
      "learning_rate": 6.607475909232205e-06,
      "loss": 0.0714,
      "step": 8731
    },
    {
      "epoch": 0.6785825303077402,
      "grad_norm": 0.1360759288072586,
      "learning_rate": 6.607087348461299e-06,
      "loss": 0.0306,
      "step": 8732
    },
    {
      "epoch": 0.678660242461921,
      "grad_norm": 0.3510873317718506,
      "learning_rate": 6.606698787690395e-06,
      "loss": 0.4631,
      "step": 8733
    },
    {
      "epoch": 0.678737954616102,
      "grad_norm": 0.2832674980163574,
      "learning_rate": 6.606310226919491e-06,
      "loss": 0.3435,
      "step": 8734
    },
    {
      "epoch": 0.6788156667702828,
      "grad_norm": 0.1806105226278305,
      "learning_rate": 6.605921666148586e-06,
      "loss": 0.0852,
      "step": 8735
    },
    {
      "epoch": 0.6788933789244638,
      "grad_norm": 0.10552587360143661,
      "learning_rate": 6.605533105377682e-06,
      "loss": 0.0186,
      "step": 8736
    },
    {
      "epoch": 0.6789710910786447,
      "grad_norm": 0.21753601729869843,
      "learning_rate": 6.6051445446067774e-06,
      "loss": 0.0509,
      "step": 8737
    },
    {
      "epoch": 0.6790488032328256,
      "grad_norm": 0.7648979425430298,
      "learning_rate": 6.604755983835872e-06,
      "loss": 0.2871,
      "step": 8738
    },
    {
      "epoch": 0.6791265153870065,
      "grad_norm": 0.20278401672840118,
      "learning_rate": 6.604367423064968e-06,
      "loss": 0.0447,
      "step": 8739
    },
    {
      "epoch": 0.6792042275411875,
      "grad_norm": 0.573919415473938,
      "learning_rate": 6.603978862294064e-06,
      "loss": 0.3043,
      "step": 8740
    },
    {
      "epoch": 0.6792819396953683,
      "grad_norm": 0.3627612888813019,
      "learning_rate": 6.603590301523158e-06,
      "loss": 0.139,
      "step": 8741
    },
    {
      "epoch": 0.6793596518495493,
      "grad_norm": 0.3643135130405426,
      "learning_rate": 6.603201740752254e-06,
      "loss": 0.1653,
      "step": 8742
    },
    {
      "epoch": 0.6794373640037302,
      "grad_norm": 0.46950939297676086,
      "learning_rate": 6.60281317998135e-06,
      "loss": 0.2574,
      "step": 8743
    },
    {
      "epoch": 0.6795150761579111,
      "grad_norm": 0.15813764929771423,
      "learning_rate": 6.602424619210445e-06,
      "loss": 0.3218,
      "step": 8744
    },
    {
      "epoch": 0.679592788312092,
      "grad_norm": 0.32978498935699463,
      "learning_rate": 6.6020360584395404e-06,
      "loss": 0.2417,
      "step": 8745
    },
    {
      "epoch": 0.679670500466273,
      "grad_norm": 0.7313450574874878,
      "learning_rate": 6.601647497668636e-06,
      "loss": 0.5046,
      "step": 8746
    },
    {
      "epoch": 0.6797482126204538,
      "grad_norm": 0.3629789352416992,
      "learning_rate": 6.601258936897731e-06,
      "loss": 0.0736,
      "step": 8747
    },
    {
      "epoch": 0.6798259247746348,
      "grad_norm": 0.3433696925640106,
      "learning_rate": 6.600870376126827e-06,
      "loss": 0.0925,
      "step": 8748
    },
    {
      "epoch": 0.6799036369288156,
      "grad_norm": 0.1400693655014038,
      "learning_rate": 6.600481815355923e-06,
      "loss": 0.0443,
      "step": 8749
    },
    {
      "epoch": 0.6799813490829966,
      "grad_norm": 0.1269451528787613,
      "learning_rate": 6.600093254585017e-06,
      "loss": 0.0825,
      "step": 8750
    },
    {
      "epoch": 0.6800590612371775,
      "grad_norm": 0.5611715316772461,
      "learning_rate": 6.599704693814113e-06,
      "loss": 0.2971,
      "step": 8751
    },
    {
      "epoch": 0.6801367733913584,
      "grad_norm": 0.29670411348342896,
      "learning_rate": 6.5993161330432085e-06,
      "loss": 0.1306,
      "step": 8752
    },
    {
      "epoch": 0.6802144855455393,
      "grad_norm": 1.0626381635665894,
      "learning_rate": 6.598927572272303e-06,
      "loss": 0.6612,
      "step": 8753
    },
    {
      "epoch": 0.6802921976997203,
      "grad_norm": 0.3745117485523224,
      "learning_rate": 6.598539011501399e-06,
      "loss": 0.176,
      "step": 8754
    },
    {
      "epoch": 0.6803699098539011,
      "grad_norm": 0.48183685541152954,
      "learning_rate": 6.598150450730495e-06,
      "loss": 0.7313,
      "step": 8755
    },
    {
      "epoch": 0.6804476220080821,
      "grad_norm": 0.09093368053436279,
      "learning_rate": 6.597761889959591e-06,
      "loss": 0.0169,
      "step": 8756
    },
    {
      "epoch": 0.680525334162263,
      "grad_norm": 0.3716789186000824,
      "learning_rate": 6.597373329188686e-06,
      "loss": 0.1538,
      "step": 8757
    },
    {
      "epoch": 0.6806030463164439,
      "grad_norm": 1.1747413873672485,
      "learning_rate": 6.5969847684177816e-06,
      "loss": 0.3944,
      "step": 8758
    },
    {
      "epoch": 0.6806807584706248,
      "grad_norm": 0.30006691813468933,
      "learning_rate": 6.596596207646877e-06,
      "loss": 0.1034,
      "step": 8759
    },
    {
      "epoch": 0.6807584706248058,
      "grad_norm": 0.43835434317588806,
      "learning_rate": 6.5962076468759715e-06,
      "loss": 0.1946,
      "step": 8760
    },
    {
      "epoch": 0.6808361827789866,
      "grad_norm": 0.24105481803417206,
      "learning_rate": 6.595819086105067e-06,
      "loss": 0.0664,
      "step": 8761
    },
    {
      "epoch": 0.6809138949331676,
      "grad_norm": 0.1261577159166336,
      "learning_rate": 6.595430525334163e-06,
      "loss": 0.0886,
      "step": 8762
    },
    {
      "epoch": 0.6809916070873485,
      "grad_norm": 0.8299633860588074,
      "learning_rate": 6.595041964563258e-06,
      "loss": 0.2593,
      "step": 8763
    },
    {
      "epoch": 0.6810693192415294,
      "grad_norm": 0.2134762704372406,
      "learning_rate": 6.594653403792354e-06,
      "loss": 0.0476,
      "step": 8764
    },
    {
      "epoch": 0.6811470313957103,
      "grad_norm": 0.13403114676475525,
      "learning_rate": 6.59426484302145e-06,
      "loss": 0.024,
      "step": 8765
    },
    {
      "epoch": 0.6812247435498912,
      "grad_norm": 1.2828885316848755,
      "learning_rate": 6.5938762822505445e-06,
      "loss": 0.7343,
      "step": 8766
    },
    {
      "epoch": 0.6813024557040721,
      "grad_norm": 0.8374665379524231,
      "learning_rate": 6.59348772147964e-06,
      "loss": 0.3046,
      "step": 8767
    },
    {
      "epoch": 0.6813801678582531,
      "grad_norm": 0.14224810898303986,
      "learning_rate": 6.593099160708736e-06,
      "loss": 0.0521,
      "step": 8768
    },
    {
      "epoch": 0.6814578800124339,
      "grad_norm": 0.6686403751373291,
      "learning_rate": 6.59271059993783e-06,
      "loss": 0.7345,
      "step": 8769
    },
    {
      "epoch": 0.6815355921666149,
      "grad_norm": 0.38545793294906616,
      "learning_rate": 6.592322039166926e-06,
      "loss": 0.1402,
      "step": 8770
    },
    {
      "epoch": 0.6816133043207958,
      "grad_norm": 1.1934431791305542,
      "learning_rate": 6.591933478396022e-06,
      "loss": 0.4096,
      "step": 8771
    },
    {
      "epoch": 0.6816910164749767,
      "grad_norm": 1.9912934303283691,
      "learning_rate": 6.591544917625117e-06,
      "loss": 0.8668,
      "step": 8772
    },
    {
      "epoch": 0.6817687286291576,
      "grad_norm": 0.4544554650783539,
      "learning_rate": 6.5911563568542126e-06,
      "loss": 0.2015,
      "step": 8773
    },
    {
      "epoch": 0.6818464407833386,
      "grad_norm": 0.8282092809677124,
      "learning_rate": 6.590767796083308e-06,
      "loss": 0.3818,
      "step": 8774
    },
    {
      "epoch": 0.6819241529375194,
      "grad_norm": 0.6713985204696655,
      "learning_rate": 6.590379235312403e-06,
      "loss": 0.4566,
      "step": 8775
    },
    {
      "epoch": 0.6820018650917004,
      "grad_norm": 0.2159106731414795,
      "learning_rate": 6.589990674541499e-06,
      "loss": 0.0658,
      "step": 8776
    },
    {
      "epoch": 0.6820795772458813,
      "grad_norm": 0.19188660383224487,
      "learning_rate": 6.589602113770595e-06,
      "loss": 0.1097,
      "step": 8777
    },
    {
      "epoch": 0.6821572894000622,
      "grad_norm": 1.2382310628890991,
      "learning_rate": 6.589213552999689e-06,
      "loss": 0.4076,
      "step": 8778
    },
    {
      "epoch": 0.6822350015542431,
      "grad_norm": 0.6362093091011047,
      "learning_rate": 6.588824992228785e-06,
      "loss": 0.3688,
      "step": 8779
    },
    {
      "epoch": 0.682312713708424,
      "grad_norm": 0.15931910276412964,
      "learning_rate": 6.588436431457881e-06,
      "loss": 0.0579,
      "step": 8780
    },
    {
      "epoch": 0.6823904258626049,
      "grad_norm": 0.1847277134656906,
      "learning_rate": 6.5880478706869756e-06,
      "loss": 0.1029,
      "step": 8781
    },
    {
      "epoch": 0.6824681380167859,
      "grad_norm": 0.23956981301307678,
      "learning_rate": 6.587659309916071e-06,
      "loss": 0.1803,
      "step": 8782
    },
    {
      "epoch": 0.6825458501709667,
      "grad_norm": 0.8616998791694641,
      "learning_rate": 6.587270749145167e-06,
      "loss": 0.226,
      "step": 8783
    },
    {
      "epoch": 0.6826235623251476,
      "grad_norm": 0.2247752845287323,
      "learning_rate": 6.586882188374262e-06,
      "loss": 0.0634,
      "step": 8784
    },
    {
      "epoch": 0.6827012744793286,
      "grad_norm": 0.7869512438774109,
      "learning_rate": 6.586493627603358e-06,
      "loss": 0.2589,
      "step": 8785
    },
    {
      "epoch": 0.6827789866335094,
      "grad_norm": 0.49586033821105957,
      "learning_rate": 6.586105066832454e-06,
      "loss": 0.1652,
      "step": 8786
    },
    {
      "epoch": 0.6828566987876904,
      "grad_norm": 0.7556073665618896,
      "learning_rate": 6.5857165060615495e-06,
      "loss": 0.3166,
      "step": 8787
    },
    {
      "epoch": 0.6829344109418714,
      "grad_norm": 0.4683530926704407,
      "learning_rate": 6.585327945290644e-06,
      "loss": 0.2917,
      "step": 8788
    },
    {
      "epoch": 0.6830121230960522,
      "grad_norm": 0.41021594405174255,
      "learning_rate": 6.584939384519739e-06,
      "loss": 0.1791,
      "step": 8789
    },
    {
      "epoch": 0.6830898352502331,
      "grad_norm": 0.28186798095703125,
      "learning_rate": 6.584550823748835e-06,
      "loss": 0.122,
      "step": 8790
    },
    {
      "epoch": 0.6831675474044141,
      "grad_norm": 0.7661469578742981,
      "learning_rate": 6.58416226297793e-06,
      "loss": 0.3972,
      "step": 8791
    },
    {
      "epoch": 0.6832452595585949,
      "grad_norm": 0.6767887473106384,
      "learning_rate": 6.583773702207026e-06,
      "loss": 0.1686,
      "step": 8792
    },
    {
      "epoch": 0.6833229717127759,
      "grad_norm": 0.31708043813705444,
      "learning_rate": 6.583385141436122e-06,
      "loss": 0.1215,
      "step": 8793
    },
    {
      "epoch": 0.6834006838669567,
      "grad_norm": 0.21133577823638916,
      "learning_rate": 6.582996580665217e-06,
      "loss": 0.1044,
      "step": 8794
    },
    {
      "epoch": 0.6834783960211377,
      "grad_norm": 0.5882697701454163,
      "learning_rate": 6.5826080198943125e-06,
      "loss": 0.2646,
      "step": 8795
    },
    {
      "epoch": 0.6835561081753186,
      "grad_norm": 0.2890307307243347,
      "learning_rate": 6.582219459123408e-06,
      "loss": 0.162,
      "step": 8796
    },
    {
      "epoch": 0.6836338203294995,
      "grad_norm": 0.6383262276649475,
      "learning_rate": 6.581830898352502e-06,
      "loss": 1.4676,
      "step": 8797
    },
    {
      "epoch": 0.6837115324836804,
      "grad_norm": 0.20150329172611237,
      "learning_rate": 6.581442337581598e-06,
      "loss": 0.0423,
      "step": 8798
    },
    {
      "epoch": 0.6837892446378614,
      "grad_norm": 0.8992252349853516,
      "learning_rate": 6.581053776810694e-06,
      "loss": 0.0895,
      "step": 8799
    },
    {
      "epoch": 0.6838669567920422,
      "grad_norm": 0.22486187517642975,
      "learning_rate": 6.580665216039789e-06,
      "loss": 0.0983,
      "step": 8800
    },
    {
      "epoch": 0.6839446689462232,
      "grad_norm": 1.1312872171401978,
      "learning_rate": 6.580276655268885e-06,
      "loss": 0.3498,
      "step": 8801
    },
    {
      "epoch": 0.6840223811004041,
      "grad_norm": 0.3444242477416992,
      "learning_rate": 6.5798880944979805e-06,
      "loss": 0.0426,
      "step": 8802
    },
    {
      "epoch": 0.684100093254585,
      "grad_norm": 0.05225048214197159,
      "learning_rate": 6.5794995337270755e-06,
      "loss": 0.0104,
      "step": 8803
    },
    {
      "epoch": 0.6841778054087659,
      "grad_norm": 0.21456582844257355,
      "learning_rate": 6.579110972956171e-06,
      "loss": 0.1053,
      "step": 8804
    },
    {
      "epoch": 0.6842555175629469,
      "grad_norm": 0.4887799322605133,
      "learning_rate": 6.578722412185267e-06,
      "loss": 0.4017,
      "step": 8805
    },
    {
      "epoch": 0.6843332297171277,
      "grad_norm": 0.6736348867416382,
      "learning_rate": 6.578333851414361e-06,
      "loss": 0.4483,
      "step": 8806
    },
    {
      "epoch": 0.6844109418713087,
      "grad_norm": 0.4192206561565399,
      "learning_rate": 6.577945290643457e-06,
      "loss": 0.3729,
      "step": 8807
    },
    {
      "epoch": 0.6844886540254896,
      "grad_norm": 0.24176663160324097,
      "learning_rate": 6.577556729872553e-06,
      "loss": 0.065,
      "step": 8808
    },
    {
      "epoch": 0.6845663661796705,
      "grad_norm": 0.2725326716899872,
      "learning_rate": 6.577168169101648e-06,
      "loss": 0.2523,
      "step": 8809
    },
    {
      "epoch": 0.6846440783338514,
      "grad_norm": 0.3175467848777771,
      "learning_rate": 6.5767796083307435e-06,
      "loss": 0.0459,
      "step": 8810
    },
    {
      "epoch": 0.6847217904880323,
      "grad_norm": 0.41659441590309143,
      "learning_rate": 6.576391047559839e-06,
      "loss": 0.1454,
      "step": 8811
    },
    {
      "epoch": 0.6847995026422132,
      "grad_norm": 0.49012699723243713,
      "learning_rate": 6.576002486788933e-06,
      "loss": 0.1336,
      "step": 8812
    },
    {
      "epoch": 0.6848772147963942,
      "grad_norm": 0.9350881576538086,
      "learning_rate": 6.575613926018029e-06,
      "loss": 0.6683,
      "step": 8813
    },
    {
      "epoch": 0.684954926950575,
      "grad_norm": 0.24695567786693573,
      "learning_rate": 6.575225365247125e-06,
      "loss": 0.1246,
      "step": 8814
    },
    {
      "epoch": 0.685032639104756,
      "grad_norm": 0.3013632595539093,
      "learning_rate": 6.57483680447622e-06,
      "loss": 0.5857,
      "step": 8815
    },
    {
      "epoch": 0.6851103512589369,
      "grad_norm": 1.0783973932266235,
      "learning_rate": 6.574448243705316e-06,
      "loss": 0.3969,
      "step": 8816
    },
    {
      "epoch": 0.6851880634131178,
      "grad_norm": 0.44769638776779175,
      "learning_rate": 6.5740596829344115e-06,
      "loss": 0.0948,
      "step": 8817
    },
    {
      "epoch": 0.6852657755672987,
      "grad_norm": 0.22058816254138947,
      "learning_rate": 6.573671122163507e-06,
      "loss": 0.052,
      "step": 8818
    },
    {
      "epoch": 0.6853434877214797,
      "grad_norm": 0.7653341889381409,
      "learning_rate": 6.573282561392602e-06,
      "loss": 0.0691,
      "step": 8819
    },
    {
      "epoch": 0.6854211998756605,
      "grad_norm": 0.38391244411468506,
      "learning_rate": 6.572894000621698e-06,
      "loss": 0.2089,
      "step": 8820
    },
    {
      "epoch": 0.6854989120298415,
      "grad_norm": 0.5265660881996155,
      "learning_rate": 6.572505439850794e-06,
      "loss": 0.2313,
      "step": 8821
    },
    {
      "epoch": 0.6855766241840224,
      "grad_norm": 0.32159343361854553,
      "learning_rate": 6.572116879079888e-06,
      "loss": 0.1932,
      "step": 8822
    },
    {
      "epoch": 0.6856543363382033,
      "grad_norm": 0.3292803466320038,
      "learning_rate": 6.571728318308984e-06,
      "loss": 0.1771,
      "step": 8823
    },
    {
      "epoch": 0.6857320484923842,
      "grad_norm": 0.28421512246131897,
      "learning_rate": 6.57133975753808e-06,
      "loss": 0.1619,
      "step": 8824
    },
    {
      "epoch": 0.6858097606465651,
      "grad_norm": 0.49873799085617065,
      "learning_rate": 6.5709511967671745e-06,
      "loss": 0.1621,
      "step": 8825
    },
    {
      "epoch": 0.685887472800746,
      "grad_norm": 0.5393561124801636,
      "learning_rate": 6.57056263599627e-06,
      "loss": 0.1817,
      "step": 8826
    },
    {
      "epoch": 0.685965184954927,
      "grad_norm": 0.3267759680747986,
      "learning_rate": 6.570174075225366e-06,
      "loss": 0.5697,
      "step": 8827
    },
    {
      "epoch": 0.6860428971091078,
      "grad_norm": 0.8048359751701355,
      "learning_rate": 6.569785514454461e-06,
      "loss": 0.1423,
      "step": 8828
    },
    {
      "epoch": 0.6861206092632888,
      "grad_norm": 0.3560897409915924,
      "learning_rate": 6.569396953683557e-06,
      "loss": 0.1651,
      "step": 8829
    },
    {
      "epoch": 0.6861983214174697,
      "grad_norm": 0.32056570053100586,
      "learning_rate": 6.569008392912653e-06,
      "loss": 0.1148,
      "step": 8830
    },
    {
      "epoch": 0.6862760335716506,
      "grad_norm": 0.38744738698005676,
      "learning_rate": 6.568619832141747e-06,
      "loss": 0.0243,
      "step": 8831
    },
    {
      "epoch": 0.6863537457258315,
      "grad_norm": 0.24330642819404602,
      "learning_rate": 6.5682312713708426e-06,
      "loss": 0.1394,
      "step": 8832
    },
    {
      "epoch": 0.6864314578800125,
      "grad_norm": 0.29021793603897095,
      "learning_rate": 6.567842710599938e-06,
      "loss": 0.0803,
      "step": 8833
    },
    {
      "epoch": 0.6865091700341933,
      "grad_norm": 0.49307936429977417,
      "learning_rate": 6.567454149829033e-06,
      "loss": 0.3048,
      "step": 8834
    },
    {
      "epoch": 0.6865868821883743,
      "grad_norm": 0.3069915473461151,
      "learning_rate": 6.567065589058129e-06,
      "loss": 0.0889,
      "step": 8835
    },
    {
      "epoch": 0.6866645943425552,
      "grad_norm": 0.5616492629051208,
      "learning_rate": 6.566677028287225e-06,
      "loss": 0.3443,
      "step": 8836
    },
    {
      "epoch": 0.6867423064967361,
      "grad_norm": 0.48895642161369324,
      "learning_rate": 6.56628846751632e-06,
      "loss": 0.0717,
      "step": 8837
    },
    {
      "epoch": 0.686820018650917,
      "grad_norm": 0.6392238140106201,
      "learning_rate": 6.565899906745416e-06,
      "loss": 0.6005,
      "step": 8838
    },
    {
      "epoch": 0.686897730805098,
      "grad_norm": 0.2655833065509796,
      "learning_rate": 6.5655113459745114e-06,
      "loss": 0.1628,
      "step": 8839
    },
    {
      "epoch": 0.6869754429592788,
      "grad_norm": 0.19497936964035034,
      "learning_rate": 6.5651227852036055e-06,
      "loss": 0.0944,
      "step": 8840
    },
    {
      "epoch": 0.6870531551134598,
      "grad_norm": 0.616308331489563,
      "learning_rate": 6.564734224432701e-06,
      "loss": 0.4122,
      "step": 8841
    },
    {
      "epoch": 0.6871308672676406,
      "grad_norm": 0.18225938081741333,
      "learning_rate": 6.564345663661797e-06,
      "loss": 0.027,
      "step": 8842
    },
    {
      "epoch": 0.6872085794218216,
      "grad_norm": 0.1034620925784111,
      "learning_rate": 6.563957102890892e-06,
      "loss": 0.0229,
      "step": 8843
    },
    {
      "epoch": 0.6872862915760025,
      "grad_norm": 0.7480934262275696,
      "learning_rate": 6.563568542119988e-06,
      "loss": 0.2714,
      "step": 8844
    },
    {
      "epoch": 0.6873640037301834,
      "grad_norm": 0.2491568922996521,
      "learning_rate": 6.563179981349084e-06,
      "loss": 0.0891,
      "step": 8845
    },
    {
      "epoch": 0.6874417158843643,
      "grad_norm": 0.19502198696136475,
      "learning_rate": 6.562791420578179e-06,
      "loss": 0.0063,
      "step": 8846
    },
    {
      "epoch": 0.6875194280385453,
      "grad_norm": 0.414331316947937,
      "learning_rate": 6.5624028598072744e-06,
      "loss": 0.6354,
      "step": 8847
    },
    {
      "epoch": 0.6875971401927261,
      "grad_norm": 0.174555703997612,
      "learning_rate": 6.56201429903637e-06,
      "loss": 0.0719,
      "step": 8848
    },
    {
      "epoch": 0.6876748523469071,
      "grad_norm": 0.3570862114429474,
      "learning_rate": 6.561625738265466e-06,
      "loss": 0.0813,
      "step": 8849
    },
    {
      "epoch": 0.687752564501088,
      "grad_norm": 0.5431459546089172,
      "learning_rate": 6.56123717749456e-06,
      "loss": 0.4816,
      "step": 8850
    },
    {
      "epoch": 0.6878302766552689,
      "grad_norm": 0.30810391902923584,
      "learning_rate": 6.560848616723656e-06,
      "loss": 0.0989,
      "step": 8851
    },
    {
      "epoch": 0.6879079888094498,
      "grad_norm": 1.1904600858688354,
      "learning_rate": 6.560460055952752e-06,
      "loss": 0.3954,
      "step": 8852
    },
    {
      "epoch": 0.6879857009636308,
      "grad_norm": 0.4577496349811554,
      "learning_rate": 6.560071495181847e-06,
      "loss": 0.3933,
      "step": 8853
    },
    {
      "epoch": 0.6880634131178116,
      "grad_norm": 0.7427164912223816,
      "learning_rate": 6.5596829344109425e-06,
      "loss": 0.122,
      "step": 8854
    },
    {
      "epoch": 0.6881411252719926,
      "grad_norm": 0.6740557551383972,
      "learning_rate": 6.559294373640038e-06,
      "loss": 0.4107,
      "step": 8855
    },
    {
      "epoch": 0.6882188374261734,
      "grad_norm": 0.4536590278148651,
      "learning_rate": 6.558905812869133e-06,
      "loss": 0.0947,
      "step": 8856
    },
    {
      "epoch": 0.6882965495803544,
      "grad_norm": 0.07092607766389847,
      "learning_rate": 6.558517252098229e-06,
      "loss": 0.0074,
      "step": 8857
    },
    {
      "epoch": 0.6883742617345353,
      "grad_norm": 0.22777479887008667,
      "learning_rate": 6.558128691327325e-06,
      "loss": 0.0805,
      "step": 8858
    },
    {
      "epoch": 0.6884519738887162,
      "grad_norm": 0.6696509718894958,
      "learning_rate": 6.557740130556419e-06,
      "loss": 0.1458,
      "step": 8859
    },
    {
      "epoch": 0.6885296860428971,
      "grad_norm": 0.09226587414741516,
      "learning_rate": 6.557351569785515e-06,
      "loss": 0.0264,
      "step": 8860
    },
    {
      "epoch": 0.6886073981970781,
      "grad_norm": 0.14865073561668396,
      "learning_rate": 6.5569630090146105e-06,
      "loss": 0.1275,
      "step": 8861
    },
    {
      "epoch": 0.6886851103512589,
      "grad_norm": 0.3702983558177948,
      "learning_rate": 6.5565744482437055e-06,
      "loss": 0.2206,
      "step": 8862
    },
    {
      "epoch": 0.6887628225054399,
      "grad_norm": 0.15894025564193726,
      "learning_rate": 6.556185887472801e-06,
      "loss": 0.0489,
      "step": 8863
    },
    {
      "epoch": 0.6888405346596208,
      "grad_norm": 0.5732749700546265,
      "learning_rate": 6.555797326701897e-06,
      "loss": 0.0447,
      "step": 8864
    },
    {
      "epoch": 0.6889182468138016,
      "grad_norm": 0.40181097388267517,
      "learning_rate": 6.555408765930992e-06,
      "loss": 0.4983,
      "step": 8865
    },
    {
      "epoch": 0.6889959589679826,
      "grad_norm": 0.3851180970668793,
      "learning_rate": 6.555020205160088e-06,
      "loss": 0.0849,
      "step": 8866
    },
    {
      "epoch": 0.6890736711221636,
      "grad_norm": 0.24050353467464447,
      "learning_rate": 6.554631644389184e-06,
      "loss": 0.1458,
      "step": 8867
    },
    {
      "epoch": 0.6891513832763444,
      "grad_norm": 0.5588659644126892,
      "learning_rate": 6.554243083618278e-06,
      "loss": 0.9736,
      "step": 8868
    },
    {
      "epoch": 0.6892290954305254,
      "grad_norm": 0.2932495176792145,
      "learning_rate": 6.5538545228473735e-06,
      "loss": 0.1525,
      "step": 8869
    },
    {
      "epoch": 0.6893068075847062,
      "grad_norm": 0.20386630296707153,
      "learning_rate": 6.553465962076469e-06,
      "loss": 0.0458,
      "step": 8870
    },
    {
      "epoch": 0.6893845197388871,
      "grad_norm": 0.058660585433244705,
      "learning_rate": 6.553077401305564e-06,
      "loss": 0.0131,
      "step": 8871
    },
    {
      "epoch": 0.6894622318930681,
      "grad_norm": 0.42668822407722473,
      "learning_rate": 6.55268884053466e-06,
      "loss": 0.0828,
      "step": 8872
    },
    {
      "epoch": 0.6895399440472489,
      "grad_norm": 0.37161949276924133,
      "learning_rate": 6.552300279763756e-06,
      "loss": 0.1403,
      "step": 8873
    },
    {
      "epoch": 0.6896176562014299,
      "grad_norm": 0.3011918365955353,
      "learning_rate": 6.551911718992851e-06,
      "loss": 0.1238,
      "step": 8874
    },
    {
      "epoch": 0.6896953683556108,
      "grad_norm": 0.32810401916503906,
      "learning_rate": 6.551523158221947e-06,
      "loss": 0.1245,
      "step": 8875
    },
    {
      "epoch": 0.6897730805097917,
      "grad_norm": 0.2868918776512146,
      "learning_rate": 6.551134597451042e-06,
      "loss": 0.0635,
      "step": 8876
    },
    {
      "epoch": 0.6898507926639726,
      "grad_norm": 0.3549686670303345,
      "learning_rate": 6.5507460366801365e-06,
      "loss": 0.1306,
      "step": 8877
    },
    {
      "epoch": 0.6899285048181536,
      "grad_norm": 0.33203285932540894,
      "learning_rate": 6.550357475909232e-06,
      "loss": 0.2719,
      "step": 8878
    },
    {
      "epoch": 0.6900062169723344,
      "grad_norm": 0.9596408009529114,
      "learning_rate": 6.549968915138328e-06,
      "loss": 0.4823,
      "step": 8879
    },
    {
      "epoch": 0.6900839291265154,
      "grad_norm": 0.11524076759815216,
      "learning_rate": 6.549580354367424e-06,
      "loss": 0.0304,
      "step": 8880
    },
    {
      "epoch": 0.6901616412806963,
      "grad_norm": 0.6248058080673218,
      "learning_rate": 6.549191793596519e-06,
      "loss": 0.1975,
      "step": 8881
    },
    {
      "epoch": 0.6902393534348772,
      "grad_norm": 0.4489060044288635,
      "learning_rate": 6.548803232825615e-06,
      "loss": 0.3357,
      "step": 8882
    },
    {
      "epoch": 0.6903170655890581,
      "grad_norm": 0.4227389395236969,
      "learning_rate": 6.54841467205471e-06,
      "loss": 0.1832,
      "step": 8883
    },
    {
      "epoch": 0.6903947777432391,
      "grad_norm": 0.7311251759529114,
      "learning_rate": 6.548026111283805e-06,
      "loss": 0.2286,
      "step": 8884
    },
    {
      "epoch": 0.6904724898974199,
      "grad_norm": 0.2856210172176361,
      "learning_rate": 6.547637550512901e-06,
      "loss": 0.2852,
      "step": 8885
    },
    {
      "epoch": 0.6905502020516009,
      "grad_norm": 0.29048988223075867,
      "learning_rate": 6.547248989741997e-06,
      "loss": 0.2706,
      "step": 8886
    },
    {
      "epoch": 0.6906279142057817,
      "grad_norm": 0.5591618418693542,
      "learning_rate": 6.546860428971091e-06,
      "loss": 0.6427,
      "step": 8887
    },
    {
      "epoch": 0.6907056263599627,
      "grad_norm": 0.16567060351371765,
      "learning_rate": 6.546471868200187e-06,
      "loss": 0.0617,
      "step": 8888
    },
    {
      "epoch": 0.6907833385141436,
      "grad_norm": 0.5686455368995667,
      "learning_rate": 6.546083307429283e-06,
      "loss": 0.1475,
      "step": 8889
    },
    {
      "epoch": 0.6908610506683245,
      "grad_norm": 0.10620749741792679,
      "learning_rate": 6.545694746658378e-06,
      "loss": 0.0156,
      "step": 8890
    },
    {
      "epoch": 0.6909387628225054,
      "grad_norm": 0.501184344291687,
      "learning_rate": 6.545306185887473e-06,
      "loss": 0.0959,
      "step": 8891
    },
    {
      "epoch": 0.6910164749766864,
      "grad_norm": 0.6103346347808838,
      "learning_rate": 6.544917625116569e-06,
      "loss": 0.1977,
      "step": 8892
    },
    {
      "epoch": 0.6910941871308672,
      "grad_norm": 0.036371588706970215,
      "learning_rate": 6.544529064345664e-06,
      "loss": 0.0147,
      "step": 8893
    },
    {
      "epoch": 0.6911718992850482,
      "grad_norm": 0.44062548875808716,
      "learning_rate": 6.54414050357476e-06,
      "loss": 0.2242,
      "step": 8894
    },
    {
      "epoch": 0.6912496114392291,
      "grad_norm": 0.3771819770336151,
      "learning_rate": 6.543751942803856e-06,
      "loss": 0.5078,
      "step": 8895
    },
    {
      "epoch": 0.69132732359341,
      "grad_norm": 0.38993972539901733,
      "learning_rate": 6.54336338203295e-06,
      "loss": 0.2679,
      "step": 8896
    },
    {
      "epoch": 0.6914050357475909,
      "grad_norm": 0.35209178924560547,
      "learning_rate": 6.542974821262046e-06,
      "loss": 0.0807,
      "step": 8897
    },
    {
      "epoch": 0.6914827479017719,
      "grad_norm": 0.2857613265514374,
      "learning_rate": 6.5425862604911414e-06,
      "loss": 0.1564,
      "step": 8898
    },
    {
      "epoch": 0.6915604600559527,
      "grad_norm": 0.6026773452758789,
      "learning_rate": 6.542197699720236e-06,
      "loss": 0.2236,
      "step": 8899
    },
    {
      "epoch": 0.6916381722101337,
      "grad_norm": 0.37349820137023926,
      "learning_rate": 6.541809138949332e-06,
      "loss": 0.102,
      "step": 8900
    },
    {
      "epoch": 0.6917158843643145,
      "grad_norm": 0.11595946550369263,
      "learning_rate": 6.541420578178428e-06,
      "loss": 0.0386,
      "step": 8901
    },
    {
      "epoch": 0.6917935965184955,
      "grad_norm": 0.2625123858451843,
      "learning_rate": 6.541032017407523e-06,
      "loss": 0.0931,
      "step": 8902
    },
    {
      "epoch": 0.6918713086726764,
      "grad_norm": 0.15370136499404907,
      "learning_rate": 6.540643456636619e-06,
      "loss": 0.1063,
      "step": 8903
    },
    {
      "epoch": 0.6919490208268573,
      "grad_norm": 0.2878384292125702,
      "learning_rate": 6.5402548958657145e-06,
      "loss": 0.1036,
      "step": 8904
    },
    {
      "epoch": 0.6920267329810382,
      "grad_norm": 0.2866138517856598,
      "learning_rate": 6.539866335094809e-06,
      "loss": 0.17,
      "step": 8905
    },
    {
      "epoch": 0.6921044451352192,
      "grad_norm": 0.32415077090263367,
      "learning_rate": 6.539477774323904e-06,
      "loss": 0.0844,
      "step": 8906
    },
    {
      "epoch": 0.6921821572894,
      "grad_norm": 0.44239336252212524,
      "learning_rate": 6.539089213553e-06,
      "loss": 0.4767,
      "step": 8907
    },
    {
      "epoch": 0.692259869443581,
      "grad_norm": 0.28239181637763977,
      "learning_rate": 6.538700652782096e-06,
      "loss": 0.0597,
      "step": 8908
    },
    {
      "epoch": 0.6923375815977619,
      "grad_norm": 0.8797467350959778,
      "learning_rate": 6.538312092011191e-06,
      "loss": 0.5104,
      "step": 8909
    },
    {
      "epoch": 0.6924152937519428,
      "grad_norm": 0.5240907669067383,
      "learning_rate": 6.537923531240287e-06,
      "loss": 0.2655,
      "step": 8910
    },
    {
      "epoch": 0.6924930059061237,
      "grad_norm": 0.5939412117004395,
      "learning_rate": 6.5375349704693826e-06,
      "loss": 0.2147,
      "step": 8911
    },
    {
      "epoch": 0.6925707180603047,
      "grad_norm": 0.20785744488239288,
      "learning_rate": 6.5371464096984775e-06,
      "loss": 0.1145,
      "step": 8912
    },
    {
      "epoch": 0.6926484302144855,
      "grad_norm": 0.18096014857292175,
      "learning_rate": 6.536757848927573e-06,
      "loss": 0.0759,
      "step": 8913
    },
    {
      "epoch": 0.6927261423686665,
      "grad_norm": 0.8355162739753723,
      "learning_rate": 6.536369288156669e-06,
      "loss": 0.3188,
      "step": 8914
    },
    {
      "epoch": 0.6928038545228474,
      "grad_norm": 1.3275467157363892,
      "learning_rate": 6.535980727385763e-06,
      "loss": 0.3323,
      "step": 8915
    },
    {
      "epoch": 0.6928815666770283,
      "grad_norm": 0.22831743955612183,
      "learning_rate": 6.535592166614859e-06,
      "loss": 0.0594,
      "step": 8916
    },
    {
      "epoch": 0.6929592788312092,
      "grad_norm": 0.3252299427986145,
      "learning_rate": 6.535203605843955e-06,
      "loss": 0.1093,
      "step": 8917
    },
    {
      "epoch": 0.6930369909853901,
      "grad_norm": 0.5587537288665771,
      "learning_rate": 6.53481504507305e-06,
      "loss": 0.2388,
      "step": 8918
    },
    {
      "epoch": 0.693114703139571,
      "grad_norm": 0.06844550371170044,
      "learning_rate": 6.5344264843021455e-06,
      "loss": 0.0144,
      "step": 8919
    },
    {
      "epoch": 0.693192415293752,
      "grad_norm": 0.3365388512611389,
      "learning_rate": 6.534037923531241e-06,
      "loss": 0.1902,
      "step": 8920
    },
    {
      "epoch": 0.6932701274479328,
      "grad_norm": 0.4090500771999359,
      "learning_rate": 6.533649362760336e-06,
      "loss": 0.2824,
      "step": 8921
    },
    {
      "epoch": 0.6933478396021138,
      "grad_norm": 0.4043755829334259,
      "learning_rate": 6.533260801989432e-06,
      "loss": 0.0865,
      "step": 8922
    },
    {
      "epoch": 0.6934255517562947,
      "grad_norm": 0.3068282902240753,
      "learning_rate": 6.532872241218528e-06,
      "loss": 0.0694,
      "step": 8923
    },
    {
      "epoch": 0.6935032639104756,
      "grad_norm": 0.2830961048603058,
      "learning_rate": 6.532483680447622e-06,
      "loss": 0.1971,
      "step": 8924
    },
    {
      "epoch": 0.6935809760646565,
      "grad_norm": 0.3029167950153351,
      "learning_rate": 6.532095119676718e-06,
      "loss": 0.2418,
      "step": 8925
    },
    {
      "epoch": 0.6936586882188375,
      "grad_norm": 0.025997593998908997,
      "learning_rate": 6.531706558905814e-06,
      "loss": 0.0039,
      "step": 8926
    },
    {
      "epoch": 0.6937364003730183,
      "grad_norm": 0.3498612940311432,
      "learning_rate": 6.5313179981349085e-06,
      "loss": 0.1563,
      "step": 8927
    },
    {
      "epoch": 0.6938141125271993,
      "grad_norm": 0.3013472259044647,
      "learning_rate": 6.530929437364004e-06,
      "loss": 0.1329,
      "step": 8928
    },
    {
      "epoch": 0.6938918246813802,
      "grad_norm": 0.3164326250553131,
      "learning_rate": 6.5305408765931e-06,
      "loss": 0.099,
      "step": 8929
    },
    {
      "epoch": 0.6939695368355611,
      "grad_norm": 0.20695236325263977,
      "learning_rate": 6.530152315822195e-06,
      "loss": 0.0501,
      "step": 8930
    },
    {
      "epoch": 0.694047248989742,
      "grad_norm": 0.5485718250274658,
      "learning_rate": 6.529763755051291e-06,
      "loss": 0.3951,
      "step": 8931
    },
    {
      "epoch": 0.6941249611439229,
      "grad_norm": 0.1952078938484192,
      "learning_rate": 6.529375194280386e-06,
      "loss": 0.0944,
      "step": 8932
    },
    {
      "epoch": 0.6942026732981038,
      "grad_norm": 0.47547560930252075,
      "learning_rate": 6.528986633509481e-06,
      "loss": 0.2804,
      "step": 8933
    },
    {
      "epoch": 0.6942803854522848,
      "grad_norm": 0.2941899597644806,
      "learning_rate": 6.5285980727385766e-06,
      "loss": 0.2132,
      "step": 8934
    },
    {
      "epoch": 0.6943580976064656,
      "grad_norm": 0.49129989743232727,
      "learning_rate": 6.528209511967672e-06,
      "loss": 0.1339,
      "step": 8935
    },
    {
      "epoch": 0.6944358097606466,
      "grad_norm": 0.8909105658531189,
      "learning_rate": 6.527820951196767e-06,
      "loss": 0.3226,
      "step": 8936
    },
    {
      "epoch": 0.6945135219148275,
      "grad_norm": 0.19561804831027985,
      "learning_rate": 6.527432390425863e-06,
      "loss": 0.1398,
      "step": 8937
    },
    {
      "epoch": 0.6945912340690084,
      "grad_norm": 0.28777480125427246,
      "learning_rate": 6.527043829654959e-06,
      "loss": 0.1989,
      "step": 8938
    },
    {
      "epoch": 0.6946689462231893,
      "grad_norm": 0.5806780457496643,
      "learning_rate": 6.526655268884055e-06,
      "loss": 0.3937,
      "step": 8939
    },
    {
      "epoch": 0.6947466583773703,
      "grad_norm": 0.4562702178955078,
      "learning_rate": 6.526266708113149e-06,
      "loss": 0.2492,
      "step": 8940
    },
    {
      "epoch": 0.6948243705315511,
      "grad_norm": 0.20833146572113037,
      "learning_rate": 6.525878147342245e-06,
      "loss": 0.139,
      "step": 8941
    },
    {
      "epoch": 0.6949020826857321,
      "grad_norm": 0.1970571130514145,
      "learning_rate": 6.52548958657134e-06,
      "loss": 0.1106,
      "step": 8942
    },
    {
      "epoch": 0.694979794839913,
      "grad_norm": 0.6239151954650879,
      "learning_rate": 6.525101025800435e-06,
      "loss": 0.2586,
      "step": 8943
    },
    {
      "epoch": 0.6950575069940939,
      "grad_norm": 0.3777054250240326,
      "learning_rate": 6.524712465029531e-06,
      "loss": 0.1959,
      "step": 8944
    },
    {
      "epoch": 0.6951352191482748,
      "grad_norm": 0.3247683048248291,
      "learning_rate": 6.524323904258627e-06,
      "loss": 0.1043,
      "step": 8945
    },
    {
      "epoch": 0.6952129313024557,
      "grad_norm": 1.4458259344100952,
      "learning_rate": 6.523935343487722e-06,
      "loss": 0.7025,
      "step": 8946
    },
    {
      "epoch": 0.6952906434566366,
      "grad_norm": 0.3684687614440918,
      "learning_rate": 6.523546782716818e-06,
      "loss": 0.2331,
      "step": 8947
    },
    {
      "epoch": 0.6953683556108176,
      "grad_norm": 0.5006905198097229,
      "learning_rate": 6.5231582219459135e-06,
      "loss": 0.1563,
      "step": 8948
    },
    {
      "epoch": 0.6954460677649984,
      "grad_norm": 0.5046784281730652,
      "learning_rate": 6.522769661175008e-06,
      "loss": 0.3568,
      "step": 8949
    },
    {
      "epoch": 0.6955237799191794,
      "grad_norm": 0.3740144968032837,
      "learning_rate": 6.522381100404103e-06,
      "loss": 0.1458,
      "step": 8950
    },
    {
      "epoch": 0.6956014920733603,
      "grad_norm": 0.5231555104255676,
      "learning_rate": 6.521992539633199e-06,
      "loss": 0.1147,
      "step": 8951
    },
    {
      "epoch": 0.6956792042275411,
      "grad_norm": 0.21766997873783112,
      "learning_rate": 6.521603978862294e-06,
      "loss": 0.0779,
      "step": 8952
    },
    {
      "epoch": 0.6957569163817221,
      "grad_norm": 0.8288713693618774,
      "learning_rate": 6.52121541809139e-06,
      "loss": 0.2318,
      "step": 8953
    },
    {
      "epoch": 0.695834628535903,
      "grad_norm": 0.3254689574241638,
      "learning_rate": 6.520826857320486e-06,
      "loss": 0.131,
      "step": 8954
    },
    {
      "epoch": 0.6959123406900839,
      "grad_norm": 0.3542357087135315,
      "learning_rate": 6.520438296549581e-06,
      "loss": 0.1329,
      "step": 8955
    },
    {
      "epoch": 0.6959900528442649,
      "grad_norm": 0.32862141728401184,
      "learning_rate": 6.5200497357786765e-06,
      "loss": 0.3311,
      "step": 8956
    },
    {
      "epoch": 0.6960677649984458,
      "grad_norm": 0.46731188893318176,
      "learning_rate": 6.519661175007772e-06,
      "loss": 0.2241,
      "step": 8957
    },
    {
      "epoch": 0.6961454771526266,
      "grad_norm": 0.3474076986312866,
      "learning_rate": 6.519272614236866e-06,
      "loss": 0.147,
      "step": 8958
    },
    {
      "epoch": 0.6962231893068076,
      "grad_norm": 0.9550470113754272,
      "learning_rate": 6.518884053465962e-06,
      "loss": 0.2652,
      "step": 8959
    },
    {
      "epoch": 0.6963009014609886,
      "grad_norm": 0.3063863515853882,
      "learning_rate": 6.518495492695058e-06,
      "loss": 0.1032,
      "step": 8960
    },
    {
      "epoch": 0.6963786136151694,
      "grad_norm": 0.29307159781455994,
      "learning_rate": 6.518106931924153e-06,
      "loss": 0.192,
      "step": 8961
    },
    {
      "epoch": 0.6964563257693503,
      "grad_norm": 0.36701148748397827,
      "learning_rate": 6.517718371153249e-06,
      "loss": 0.1545,
      "step": 8962
    },
    {
      "epoch": 0.6965340379235312,
      "grad_norm": 0.19962731003761292,
      "learning_rate": 6.5173298103823445e-06,
      "loss": 0.1525,
      "step": 8963
    },
    {
      "epoch": 0.6966117500777121,
      "grad_norm": 0.4802618622779846,
      "learning_rate": 6.5169412496114395e-06,
      "loss": 0.2394,
      "step": 8964
    },
    {
      "epoch": 0.6966894622318931,
      "grad_norm": 0.1328406184911728,
      "learning_rate": 6.516552688840535e-06,
      "loss": 0.0728,
      "step": 8965
    },
    {
      "epoch": 0.6967671743860739,
      "grad_norm": 0.35887378454208374,
      "learning_rate": 6.516164128069631e-06,
      "loss": 0.1248,
      "step": 8966
    },
    {
      "epoch": 0.6968448865402549,
      "grad_norm": 0.5543833374977112,
      "learning_rate": 6.515775567298725e-06,
      "loss": 0.2234,
      "step": 8967
    },
    {
      "epoch": 0.6969225986944358,
      "grad_norm": 0.27439141273498535,
      "learning_rate": 6.515387006527821e-06,
      "loss": 0.0626,
      "step": 8968
    },
    {
      "epoch": 0.6970003108486167,
      "grad_norm": 0.3475908935070038,
      "learning_rate": 6.514998445756917e-06,
      "loss": 0.3181,
      "step": 8969
    },
    {
      "epoch": 0.6970780230027976,
      "grad_norm": 0.3604920506477356,
      "learning_rate": 6.5146098849860125e-06,
      "loss": 0.2574,
      "step": 8970
    },
    {
      "epoch": 0.6971557351569786,
      "grad_norm": 0.21724244952201843,
      "learning_rate": 6.5142213242151075e-06,
      "loss": 0.0545,
      "step": 8971
    },
    {
      "epoch": 0.6972334473111594,
      "grad_norm": 1.3713874816894531,
      "learning_rate": 6.513832763444203e-06,
      "loss": 0.1966,
      "step": 8972
    },
    {
      "epoch": 0.6973111594653404,
      "grad_norm": 0.6758919954299927,
      "learning_rate": 6.513444202673299e-06,
      "loss": 0.1895,
      "step": 8973
    },
    {
      "epoch": 0.6973888716195213,
      "grad_norm": 0.7479397654533386,
      "learning_rate": 6.513055641902394e-06,
      "loss": 0.4582,
      "step": 8974
    },
    {
      "epoch": 0.6974665837737022,
      "grad_norm": 0.3846904933452606,
      "learning_rate": 6.51266708113149e-06,
      "loss": 0.3654,
      "step": 8975
    },
    {
      "epoch": 0.6975442959278831,
      "grad_norm": 0.501406729221344,
      "learning_rate": 6.512278520360586e-06,
      "loss": 0.1311,
      "step": 8976
    },
    {
      "epoch": 0.697622008082064,
      "grad_norm": 1.244860053062439,
      "learning_rate": 6.51188995958968e-06,
      "loss": 0.4595,
      "step": 8977
    },
    {
      "epoch": 0.6976997202362449,
      "grad_norm": 0.38150352239608765,
      "learning_rate": 6.5115013988187755e-06,
      "loss": 0.2216,
      "step": 8978
    },
    {
      "epoch": 0.6977774323904259,
      "grad_norm": 0.07872665673494339,
      "learning_rate": 6.511112838047871e-06,
      "loss": 0.0133,
      "step": 8979
    },
    {
      "epoch": 0.6978551445446067,
      "grad_norm": 0.6380438804626465,
      "learning_rate": 6.510724277276966e-06,
      "loss": 0.4054,
      "step": 8980
    },
    {
      "epoch": 0.6979328566987877,
      "grad_norm": 0.7386038899421692,
      "learning_rate": 6.510335716506062e-06,
      "loss": 0.274,
      "step": 8981
    },
    {
      "epoch": 0.6980105688529686,
      "grad_norm": 0.06382904201745987,
      "learning_rate": 6.509947155735158e-06,
      "loss": 0.009,
      "step": 8982
    },
    {
      "epoch": 0.6980882810071495,
      "grad_norm": 0.14515157043933868,
      "learning_rate": 6.509558594964253e-06,
      "loss": 0.0288,
      "step": 8983
    },
    {
      "epoch": 0.6981659931613304,
      "grad_norm": 0.7288029193878174,
      "learning_rate": 6.509170034193349e-06,
      "loss": 0.4827,
      "step": 8984
    },
    {
      "epoch": 0.6982437053155114,
      "grad_norm": 0.3085695803165436,
      "learning_rate": 6.508781473422444e-06,
      "loss": 0.1792,
      "step": 8985
    },
    {
      "epoch": 0.6983214174696922,
      "grad_norm": 0.3380044400691986,
      "learning_rate": 6.5083929126515385e-06,
      "loss": 0.1684,
      "step": 8986
    },
    {
      "epoch": 0.6983991296238732,
      "grad_norm": 0.2105288803577423,
      "learning_rate": 6.508004351880634e-06,
      "loss": 0.0278,
      "step": 8987
    },
    {
      "epoch": 0.6984768417780541,
      "grad_norm": 0.34445446729660034,
      "learning_rate": 6.50761579110973e-06,
      "loss": 0.132,
      "step": 8988
    },
    {
      "epoch": 0.698554553932235,
      "grad_norm": 0.4208880066871643,
      "learning_rate": 6.507227230338825e-06,
      "loss": 0.2512,
      "step": 8989
    },
    {
      "epoch": 0.6986322660864159,
      "grad_norm": 0.6944780349731445,
      "learning_rate": 6.506838669567921e-06,
      "loss": 0.1948,
      "step": 8990
    },
    {
      "epoch": 0.6987099782405968,
      "grad_norm": 0.5434215068817139,
      "learning_rate": 6.506450108797017e-06,
      "loss": 0.3223,
      "step": 8991
    },
    {
      "epoch": 0.6987876903947777,
      "grad_norm": 0.45156270265579224,
      "learning_rate": 6.506061548026112e-06,
      "loss": 0.0976,
      "step": 8992
    },
    {
      "epoch": 0.6988654025489587,
      "grad_norm": 0.13805243372917175,
      "learning_rate": 6.505672987255207e-06,
      "loss": 0.02,
      "step": 8993
    },
    {
      "epoch": 0.6989431147031395,
      "grad_norm": 0.5128412246704102,
      "learning_rate": 6.505284426484303e-06,
      "loss": 0.3728,
      "step": 8994
    },
    {
      "epoch": 0.6990208268573205,
      "grad_norm": 0.5526968240737915,
      "learning_rate": 6.504895865713397e-06,
      "loss": 0.1029,
      "step": 8995
    },
    {
      "epoch": 0.6990985390115014,
      "grad_norm": 0.7243157029151917,
      "learning_rate": 6.504507304942493e-06,
      "loss": 0.1662,
      "step": 8996
    },
    {
      "epoch": 0.6991762511656823,
      "grad_norm": 0.1283111274242401,
      "learning_rate": 6.504118744171589e-06,
      "loss": 0.0735,
      "step": 8997
    },
    {
      "epoch": 0.6992539633198632,
      "grad_norm": 0.15362125635147095,
      "learning_rate": 6.503730183400684e-06,
      "loss": 0.0904,
      "step": 8998
    },
    {
      "epoch": 0.6993316754740442,
      "grad_norm": 0.28150758147239685,
      "learning_rate": 6.50334162262978e-06,
      "loss": 0.1291,
      "step": 8999
    },
    {
      "epoch": 0.699409387628225,
      "grad_norm": 0.33597737550735474,
      "learning_rate": 6.5029530618588754e-06,
      "loss": 0.0415,
      "step": 9000
    },
    {
      "epoch": 0.699487099782406,
      "grad_norm": 0.36488279700279236,
      "learning_rate": 6.502564501087971e-06,
      "loss": 0.5807,
      "step": 9001
    },
    {
      "epoch": 0.6995648119365869,
      "grad_norm": 0.2584059238433838,
      "learning_rate": 6.502175940317066e-06,
      "loss": 0.1589,
      "step": 9002
    },
    {
      "epoch": 0.6996425240907678,
      "grad_norm": 0.14201577007770538,
      "learning_rate": 6.501787379546162e-06,
      "loss": 0.0478,
      "step": 9003
    },
    {
      "epoch": 0.6997202362449487,
      "grad_norm": 0.23529799282550812,
      "learning_rate": 6.501398818775258e-06,
      "loss": 0.0392,
      "step": 9004
    },
    {
      "epoch": 0.6997979483991297,
      "grad_norm": 0.503034234046936,
      "learning_rate": 6.501010258004352e-06,
      "loss": 0.1511,
      "step": 9005
    },
    {
      "epoch": 0.6998756605533105,
      "grad_norm": 0.03362620994448662,
      "learning_rate": 6.500621697233448e-06,
      "loss": 0.0033,
      "step": 9006
    },
    {
      "epoch": 0.6999533727074915,
      "grad_norm": 0.5868703722953796,
      "learning_rate": 6.5002331364625435e-06,
      "loss": 0.2401,
      "step": 9007
    },
    {
      "epoch": 0.7000310848616723,
      "grad_norm": 0.4787524938583374,
      "learning_rate": 6.4998445756916384e-06,
      "loss": 0.6108,
      "step": 9008
    },
    {
      "epoch": 0.7001087970158533,
      "grad_norm": 0.76264488697052,
      "learning_rate": 6.499456014920734e-06,
      "loss": 0.374,
      "step": 9009
    },
    {
      "epoch": 0.7001865091700342,
      "grad_norm": 0.1091107651591301,
      "learning_rate": 6.49906745414983e-06,
      "loss": 0.0426,
      "step": 9010
    },
    {
      "epoch": 0.7002642213242151,
      "grad_norm": 0.08134670555591583,
      "learning_rate": 6.498678893378925e-06,
      "loss": 0.0108,
      "step": 9011
    },
    {
      "epoch": 0.700341933478396,
      "grad_norm": 0.2890060245990753,
      "learning_rate": 6.498290332608021e-06,
      "loss": 0.1097,
      "step": 9012
    },
    {
      "epoch": 0.700419645632577,
      "grad_norm": 0.726491391658783,
      "learning_rate": 6.4979017718371166e-06,
      "loss": 0.3893,
      "step": 9013
    },
    {
      "epoch": 0.7004973577867578,
      "grad_norm": 0.24732640385627747,
      "learning_rate": 6.497513211066211e-06,
      "loss": 0.0998,
      "step": 9014
    },
    {
      "epoch": 0.7005750699409388,
      "grad_norm": 0.22199764847755432,
      "learning_rate": 6.4971246502953065e-06,
      "loss": 0.0618,
      "step": 9015
    },
    {
      "epoch": 0.7006527820951197,
      "grad_norm": 0.5656129717826843,
      "learning_rate": 6.496736089524402e-06,
      "loss": 0.5433,
      "step": 9016
    },
    {
      "epoch": 0.7007304942493006,
      "grad_norm": 0.13199099898338318,
      "learning_rate": 6.496347528753497e-06,
      "loss": 0.0528,
      "step": 9017
    },
    {
      "epoch": 0.7008082064034815,
      "grad_norm": 0.22207432985305786,
      "learning_rate": 6.495958967982593e-06,
      "loss": 0.0828,
      "step": 9018
    },
    {
      "epoch": 0.7008859185576625,
      "grad_norm": 0.8058146238327026,
      "learning_rate": 6.495570407211689e-06,
      "loss": 0.2663,
      "step": 9019
    },
    {
      "epoch": 0.7009636307118433,
      "grad_norm": 0.032290488481521606,
      "learning_rate": 6.495181846440784e-06,
      "loss": 0.0141,
      "step": 9020
    },
    {
      "epoch": 0.7010413428660243,
      "grad_norm": 0.4472505748271942,
      "learning_rate": 6.4947932856698796e-06,
      "loss": 0.4437,
      "step": 9021
    },
    {
      "epoch": 0.7011190550202051,
      "grad_norm": 0.4106238782405853,
      "learning_rate": 6.494404724898975e-06,
      "loss": 0.3863,
      "step": 9022
    },
    {
      "epoch": 0.7011967671743861,
      "grad_norm": 0.24318906664848328,
      "learning_rate": 6.4940161641280694e-06,
      "loss": 0.0462,
      "step": 9023
    },
    {
      "epoch": 0.701274479328567,
      "grad_norm": 0.1561947911977768,
      "learning_rate": 6.493627603357165e-06,
      "loss": 0.0383,
      "step": 9024
    },
    {
      "epoch": 0.7013521914827479,
      "grad_norm": 0.6064570546150208,
      "learning_rate": 6.493239042586261e-06,
      "loss": 0.1497,
      "step": 9025
    },
    {
      "epoch": 0.7014299036369288,
      "grad_norm": 0.2763828635215759,
      "learning_rate": 6.492850481815356e-06,
      "loss": 0.0915,
      "step": 9026
    },
    {
      "epoch": 0.7015076157911098,
      "grad_norm": 0.1036391630768776,
      "learning_rate": 6.492461921044452e-06,
      "loss": 0.0573,
      "step": 9027
    },
    {
      "epoch": 0.7015853279452906,
      "grad_norm": 0.6327958703041077,
      "learning_rate": 6.492073360273548e-06,
      "loss": 0.1059,
      "step": 9028
    },
    {
      "epoch": 0.7016630400994716,
      "grad_norm": 0.12260280549526215,
      "learning_rate": 6.491684799502643e-06,
      "loss": 0.0334,
      "step": 9029
    },
    {
      "epoch": 0.7017407522536525,
      "grad_norm": 0.4905236065387726,
      "learning_rate": 6.491296238731738e-06,
      "loss": 0.3073,
      "step": 9030
    },
    {
      "epoch": 0.7018184644078334,
      "grad_norm": 0.3736186921596527,
      "learning_rate": 6.490907677960834e-06,
      "loss": 0.0767,
      "step": 9031
    },
    {
      "epoch": 0.7018961765620143,
      "grad_norm": 0.24229392409324646,
      "learning_rate": 6.49051911718993e-06,
      "loss": 0.1346,
      "step": 9032
    },
    {
      "epoch": 0.7019738887161953,
      "grad_norm": 0.2607622742652893,
      "learning_rate": 6.490130556419024e-06,
      "loss": 0.1884,
      "step": 9033
    },
    {
      "epoch": 0.7020516008703761,
      "grad_norm": 1.297323226928711,
      "learning_rate": 6.48974199564812e-06,
      "loss": 0.4917,
      "step": 9034
    },
    {
      "epoch": 0.7021293130245571,
      "grad_norm": 0.5696485638618469,
      "learning_rate": 6.489353434877216e-06,
      "loss": 0.1672,
      "step": 9035
    },
    {
      "epoch": 0.702207025178738,
      "grad_norm": 0.08703126758337021,
      "learning_rate": 6.4889648741063106e-06,
      "loss": 0.0203,
      "step": 9036
    },
    {
      "epoch": 0.7022847373329189,
      "grad_norm": 0.1758357137441635,
      "learning_rate": 6.488576313335406e-06,
      "loss": 0.0296,
      "step": 9037
    },
    {
      "epoch": 0.7023624494870998,
      "grad_norm": 0.3820842206478119,
      "learning_rate": 6.488187752564502e-06,
      "loss": 0.2752,
      "step": 9038
    },
    {
      "epoch": 0.7024401616412806,
      "grad_norm": 0.06613068282604218,
      "learning_rate": 6.487799191793597e-06,
      "loss": 0.0152,
      "step": 9039
    },
    {
      "epoch": 0.7025178737954616,
      "grad_norm": 0.17603766918182373,
      "learning_rate": 6.487410631022693e-06,
      "loss": 0.0384,
      "step": 9040
    },
    {
      "epoch": 0.7025955859496426,
      "grad_norm": 0.3668345510959625,
      "learning_rate": 6.487022070251789e-06,
      "loss": 0.2639,
      "step": 9041
    },
    {
      "epoch": 0.7026732981038234,
      "grad_norm": 0.962863564491272,
      "learning_rate": 6.486633509480883e-06,
      "loss": 0.8597,
      "step": 9042
    },
    {
      "epoch": 0.7027510102580043,
      "grad_norm": 0.5453013777732849,
      "learning_rate": 6.486244948709979e-06,
      "loss": 0.261,
      "step": 9043
    },
    {
      "epoch": 0.7028287224121853,
      "grad_norm": 0.20096589624881744,
      "learning_rate": 6.485856387939074e-06,
      "loss": 0.0307,
      "step": 9044
    },
    {
      "epoch": 0.7029064345663661,
      "grad_norm": 0.7109890580177307,
      "learning_rate": 6.485467827168169e-06,
      "loss": 0.8736,
      "step": 9045
    },
    {
      "epoch": 0.7029841467205471,
      "grad_norm": 0.29499512910842896,
      "learning_rate": 6.485079266397265e-06,
      "loss": 0.2694,
      "step": 9046
    },
    {
      "epoch": 0.703061858874728,
      "grad_norm": 0.3263031840324402,
      "learning_rate": 6.484690705626361e-06,
      "loss": 0.223,
      "step": 9047
    },
    {
      "epoch": 0.7031395710289089,
      "grad_norm": 0.39868247509002686,
      "learning_rate": 6.484302144855456e-06,
      "loss": 0.1373,
      "step": 9048
    },
    {
      "epoch": 0.7032172831830898,
      "grad_norm": 0.4174307882785797,
      "learning_rate": 6.483913584084552e-06,
      "loss": 0.1856,
      "step": 9049
    },
    {
      "epoch": 0.7032949953372708,
      "grad_norm": 0.38911381363868713,
      "learning_rate": 6.4835250233136475e-06,
      "loss": 0.1904,
      "step": 9050
    },
    {
      "epoch": 0.7033727074914516,
      "grad_norm": 0.710059642791748,
      "learning_rate": 6.483136462542742e-06,
      "loss": 0.1859,
      "step": 9051
    },
    {
      "epoch": 0.7034504196456326,
      "grad_norm": 0.5837097764015198,
      "learning_rate": 6.482747901771837e-06,
      "loss": 0.1287,
      "step": 9052
    },
    {
      "epoch": 0.7035281317998134,
      "grad_norm": 0.22330419719219208,
      "learning_rate": 6.482359341000933e-06,
      "loss": 0.1144,
      "step": 9053
    },
    {
      "epoch": 0.7036058439539944,
      "grad_norm": 0.4527314603328705,
      "learning_rate": 6.481970780230028e-06,
      "loss": 0.2814,
      "step": 9054
    },
    {
      "epoch": 0.7036835561081753,
      "grad_norm": 0.21414059400558472,
      "learning_rate": 6.481582219459124e-06,
      "loss": 0.2379,
      "step": 9055
    },
    {
      "epoch": 0.7037612682623562,
      "grad_norm": 0.48007574677467346,
      "learning_rate": 6.48119365868822e-06,
      "loss": 0.2938,
      "step": 9056
    },
    {
      "epoch": 0.7038389804165371,
      "grad_norm": 0.08953489363193512,
      "learning_rate": 6.480805097917315e-06,
      "loss": 0.0217,
      "step": 9057
    },
    {
      "epoch": 0.7039166925707181,
      "grad_norm": 0.5581997036933899,
      "learning_rate": 6.4804165371464105e-06,
      "loss": 0.3925,
      "step": 9058
    },
    {
      "epoch": 0.7039944047248989,
      "grad_norm": 0.1783318817615509,
      "learning_rate": 6.4800279763755054e-06,
      "loss": 0.0669,
      "step": 9059
    },
    {
      "epoch": 0.7040721168790799,
      "grad_norm": 0.12671996653079987,
      "learning_rate": 6.479639415604601e-06,
      "loss": 0.0219,
      "step": 9060
    },
    {
      "epoch": 0.7041498290332608,
      "grad_norm": 0.25495654344558716,
      "learning_rate": 6.479250854833696e-06,
      "loss": 0.045,
      "step": 9061
    },
    {
      "epoch": 0.7042275411874417,
      "grad_norm": 0.26717156171798706,
      "learning_rate": 6.478862294062792e-06,
      "loss": 0.2095,
      "step": 9062
    },
    {
      "epoch": 0.7043052533416226,
      "grad_norm": 0.09426505118608475,
      "learning_rate": 6.478473733291888e-06,
      "loss": 0.0455,
      "step": 9063
    },
    {
      "epoch": 0.7043829654958036,
      "grad_norm": 0.39023858308792114,
      "learning_rate": 6.478085172520983e-06,
      "loss": 0.1574,
      "step": 9064
    },
    {
      "epoch": 0.7044606776499844,
      "grad_norm": 0.3963751494884491,
      "learning_rate": 6.4776966117500785e-06,
      "loss": 0.0988,
      "step": 9065
    },
    {
      "epoch": 0.7045383898041654,
      "grad_norm": 0.40765300393104553,
      "learning_rate": 6.477308050979174e-06,
      "loss": 0.2286,
      "step": 9066
    },
    {
      "epoch": 0.7046161019583462,
      "grad_norm": 0.7022320032119751,
      "learning_rate": 6.476919490208268e-06,
      "loss": 0.4785,
      "step": 9067
    },
    {
      "epoch": 0.7046938141125272,
      "grad_norm": 0.27451983094215393,
      "learning_rate": 6.476530929437364e-06,
      "loss": 0.0912,
      "step": 9068
    },
    {
      "epoch": 0.7047715262667081,
      "grad_norm": 0.24207918345928192,
      "learning_rate": 6.47614236866646e-06,
      "loss": 0.0608,
      "step": 9069
    },
    {
      "epoch": 0.704849238420889,
      "grad_norm": 0.31998804211616516,
      "learning_rate": 6.475753807895555e-06,
      "loss": 0.1665,
      "step": 9070
    },
    {
      "epoch": 0.7049269505750699,
      "grad_norm": 0.47251299023628235,
      "learning_rate": 6.475365247124651e-06,
      "loss": 0.1733,
      "step": 9071
    },
    {
      "epoch": 0.7050046627292509,
      "grad_norm": 0.3323753774166107,
      "learning_rate": 6.4749766863537466e-06,
      "loss": 0.1331,
      "step": 9072
    },
    {
      "epoch": 0.7050823748834317,
      "grad_norm": 0.3065641522407532,
      "learning_rate": 6.4745881255828415e-06,
      "loss": 0.1507,
      "step": 9073
    },
    {
      "epoch": 0.7051600870376127,
      "grad_norm": 0.5829104781150818,
      "learning_rate": 6.474199564811937e-06,
      "loss": 0.254,
      "step": 9074
    },
    {
      "epoch": 0.7052377991917936,
      "grad_norm": 0.06827632337808609,
      "learning_rate": 6.473811004041033e-06,
      "loss": 0.0036,
      "step": 9075
    },
    {
      "epoch": 0.7053155113459745,
      "grad_norm": 0.09092966467142105,
      "learning_rate": 6.473422443270127e-06,
      "loss": 0.0249,
      "step": 9076
    },
    {
      "epoch": 0.7053932235001554,
      "grad_norm": 0.5130257606506348,
      "learning_rate": 6.473033882499223e-06,
      "loss": 0.2776,
      "step": 9077
    },
    {
      "epoch": 0.7054709356543364,
      "grad_norm": 0.32275697588920593,
      "learning_rate": 6.472645321728319e-06,
      "loss": 0.1997,
      "step": 9078
    },
    {
      "epoch": 0.7055486478085172,
      "grad_norm": 0.16583116352558136,
      "learning_rate": 6.472256760957414e-06,
      "loss": 0.0437,
      "step": 9079
    },
    {
      "epoch": 0.7056263599626982,
      "grad_norm": 0.6813598275184631,
      "learning_rate": 6.4718682001865095e-06,
      "loss": 0.4499,
      "step": 9080
    },
    {
      "epoch": 0.7057040721168791,
      "grad_norm": 0.5417726039886475,
      "learning_rate": 6.471479639415605e-06,
      "loss": 0.4201,
      "step": 9081
    },
    {
      "epoch": 0.70578178427106,
      "grad_norm": 0.3973937928676605,
      "learning_rate": 6.4710910786447e-06,
      "loss": 0.2472,
      "step": 9082
    },
    {
      "epoch": 0.7058594964252409,
      "grad_norm": 0.12317456305027008,
      "learning_rate": 6.470702517873796e-06,
      "loss": 0.0958,
      "step": 9083
    },
    {
      "epoch": 0.7059372085794218,
      "grad_norm": 0.47816333174705505,
      "learning_rate": 6.470313957102892e-06,
      "loss": 0.1957,
      "step": 9084
    },
    {
      "epoch": 0.7060149207336027,
      "grad_norm": 0.17765839397907257,
      "learning_rate": 6.469925396331986e-06,
      "loss": 0.0497,
      "step": 9085
    },
    {
      "epoch": 0.7060926328877837,
      "grad_norm": 0.7161638140678406,
      "learning_rate": 6.469536835561082e-06,
      "loss": 0.182,
      "step": 9086
    },
    {
      "epoch": 0.7061703450419645,
      "grad_norm": 0.1332271546125412,
      "learning_rate": 6.4691482747901776e-06,
      "loss": 0.0599,
      "step": 9087
    },
    {
      "epoch": 0.7062480571961455,
      "grad_norm": 0.2956225872039795,
      "learning_rate": 6.4687597140192725e-06,
      "loss": 0.1031,
      "step": 9088
    },
    {
      "epoch": 0.7063257693503264,
      "grad_norm": 0.19517584145069122,
      "learning_rate": 6.468371153248368e-06,
      "loss": 0.0401,
      "step": 9089
    },
    {
      "epoch": 0.7064034815045073,
      "grad_norm": 0.22198033332824707,
      "learning_rate": 6.467982592477464e-06,
      "loss": 0.0793,
      "step": 9090
    },
    {
      "epoch": 0.7064811936586882,
      "grad_norm": 0.2093142420053482,
      "learning_rate": 6.46759403170656e-06,
      "loss": 0.1054,
      "step": 9091
    },
    {
      "epoch": 0.7065589058128692,
      "grad_norm": 0.09318490326404572,
      "learning_rate": 6.467205470935655e-06,
      "loss": 0.043,
      "step": 9092
    },
    {
      "epoch": 0.70663661796705,
      "grad_norm": 0.4755590558052063,
      "learning_rate": 6.466816910164751e-06,
      "loss": 0.1278,
      "step": 9093
    },
    {
      "epoch": 0.706714330121231,
      "grad_norm": 0.40264374017715454,
      "learning_rate": 6.4664283493938465e-06,
      "loss": 0.3038,
      "step": 9094
    },
    {
      "epoch": 0.7067920422754119,
      "grad_norm": 0.7306391596794128,
      "learning_rate": 6.4660397886229406e-06,
      "loss": 0.0839,
      "step": 9095
    },
    {
      "epoch": 0.7068697544295928,
      "grad_norm": 0.2999635934829712,
      "learning_rate": 6.465651227852036e-06,
      "loss": 0.0807,
      "step": 9096
    },
    {
      "epoch": 0.7069474665837737,
      "grad_norm": 0.4750116467475891,
      "learning_rate": 6.465262667081132e-06,
      "loss": 0.2581,
      "step": 9097
    },
    {
      "epoch": 0.7070251787379546,
      "grad_norm": 0.3467879891395569,
      "learning_rate": 6.464874106310227e-06,
      "loss": 0.2287,
      "step": 9098
    },
    {
      "epoch": 0.7071028908921355,
      "grad_norm": 0.1896616369485855,
      "learning_rate": 6.464485545539323e-06,
      "loss": 0.0839,
      "step": 9099
    },
    {
      "epoch": 0.7071806030463165,
      "grad_norm": 0.481565922498703,
      "learning_rate": 6.464096984768419e-06,
      "loss": 0.0945,
      "step": 9100
    },
    {
      "epoch": 0.7072583152004973,
      "grad_norm": 0.2612563669681549,
      "learning_rate": 6.463708423997514e-06,
      "loss": 0.1782,
      "step": 9101
    },
    {
      "epoch": 0.7073360273546783,
      "grad_norm": 0.5800377130508423,
      "learning_rate": 6.4633198632266094e-06,
      "loss": 0.0891,
      "step": 9102
    },
    {
      "epoch": 0.7074137395088592,
      "grad_norm": 0.3644218146800995,
      "learning_rate": 6.462931302455705e-06,
      "loss": 0.0368,
      "step": 9103
    },
    {
      "epoch": 0.7074914516630401,
      "grad_norm": 0.1897997409105301,
      "learning_rate": 6.462542741684799e-06,
      "loss": 0.0952,
      "step": 9104
    },
    {
      "epoch": 0.707569163817221,
      "grad_norm": 0.38448411226272583,
      "learning_rate": 6.462154180913895e-06,
      "loss": 0.1008,
      "step": 9105
    },
    {
      "epoch": 0.707646875971402,
      "grad_norm": 0.2641686797142029,
      "learning_rate": 6.461765620142991e-06,
      "loss": 0.1066,
      "step": 9106
    },
    {
      "epoch": 0.7077245881255828,
      "grad_norm": 0.5941731333732605,
      "learning_rate": 6.461377059372086e-06,
      "loss": 0.2882,
      "step": 9107
    },
    {
      "epoch": 0.7078023002797638,
      "grad_norm": 0.303330659866333,
      "learning_rate": 6.460988498601182e-06,
      "loss": 0.3065,
      "step": 9108
    },
    {
      "epoch": 0.7078800124339447,
      "grad_norm": 0.5891902446746826,
      "learning_rate": 6.4605999378302775e-06,
      "loss": 0.3398,
      "step": 9109
    },
    {
      "epoch": 0.7079577245881256,
      "grad_norm": 0.10208668559789658,
      "learning_rate": 6.4602113770593724e-06,
      "loss": 0.0069,
      "step": 9110
    },
    {
      "epoch": 0.7080354367423065,
      "grad_norm": 0.25519704818725586,
      "learning_rate": 6.459822816288468e-06,
      "loss": 0.087,
      "step": 9111
    },
    {
      "epoch": 0.7081131488964875,
      "grad_norm": 0.40202978253364563,
      "learning_rate": 6.459434255517564e-06,
      "loss": 0.4343,
      "step": 9112
    },
    {
      "epoch": 0.7081908610506683,
      "grad_norm": 0.5010877847671509,
      "learning_rate": 6.459045694746658e-06,
      "loss": 0.251,
      "step": 9113
    },
    {
      "epoch": 0.7082685732048493,
      "grad_norm": 0.6972230672836304,
      "learning_rate": 6.458657133975754e-06,
      "loss": 0.0917,
      "step": 9114
    },
    {
      "epoch": 0.7083462853590301,
      "grad_norm": 0.19986948370933533,
      "learning_rate": 6.45826857320485e-06,
      "loss": 0.151,
      "step": 9115
    },
    {
      "epoch": 0.7084239975132111,
      "grad_norm": 0.343914657831192,
      "learning_rate": 6.457880012433945e-06,
      "loss": 0.4369,
      "step": 9116
    },
    {
      "epoch": 0.708501709667392,
      "grad_norm": 0.1419014185667038,
      "learning_rate": 6.4574914516630405e-06,
      "loss": 0.0369,
      "step": 9117
    },
    {
      "epoch": 0.7085794218215729,
      "grad_norm": 0.8020851612091064,
      "learning_rate": 6.457102890892136e-06,
      "loss": 0.5095,
      "step": 9118
    },
    {
      "epoch": 0.7086571339757538,
      "grad_norm": 0.1520562469959259,
      "learning_rate": 6.456714330121231e-06,
      "loss": 0.0874,
      "step": 9119
    },
    {
      "epoch": 0.7087348461299348,
      "grad_norm": 0.4290810525417328,
      "learning_rate": 6.456325769350327e-06,
      "loss": 0.1685,
      "step": 9120
    },
    {
      "epoch": 0.7088125582841156,
      "grad_norm": 0.06036140024662018,
      "learning_rate": 6.455937208579423e-06,
      "loss": 0.01,
      "step": 9121
    },
    {
      "epoch": 0.7088902704382966,
      "grad_norm": 0.30856865644454956,
      "learning_rate": 6.455548647808519e-06,
      "loss": 0.1649,
      "step": 9122
    },
    {
      "epoch": 0.7089679825924775,
      "grad_norm": 0.6653785705566406,
      "learning_rate": 6.455160087037613e-06,
      "loss": 0.0592,
      "step": 9123
    },
    {
      "epoch": 0.7090456947466584,
      "grad_norm": 0.4213942885398865,
      "learning_rate": 6.4547715262667085e-06,
      "loss": 0.1518,
      "step": 9124
    },
    {
      "epoch": 0.7091234069008393,
      "grad_norm": 0.6226230263710022,
      "learning_rate": 6.454382965495804e-06,
      "loss": 0.4257,
      "step": 9125
    },
    {
      "epoch": 0.7092011190550203,
      "grad_norm": 0.4337562322616577,
      "learning_rate": 6.453994404724899e-06,
      "loss": 0.0868,
      "step": 9126
    },
    {
      "epoch": 0.7092788312092011,
      "grad_norm": 0.3486676812171936,
      "learning_rate": 6.453605843953995e-06,
      "loss": 0.0609,
      "step": 9127
    },
    {
      "epoch": 0.709356543363382,
      "grad_norm": 0.182813361287117,
      "learning_rate": 6.453217283183091e-06,
      "loss": 0.0219,
      "step": 9128
    },
    {
      "epoch": 0.7094342555175629,
      "grad_norm": 1.0197577476501465,
      "learning_rate": 6.452828722412186e-06,
      "loss": 0.41,
      "step": 9129
    },
    {
      "epoch": 0.7095119676717438,
      "grad_norm": 0.35256415605545044,
      "learning_rate": 6.452440161641282e-06,
      "loss": 0.0677,
      "step": 9130
    },
    {
      "epoch": 0.7095896798259248,
      "grad_norm": 0.11091099679470062,
      "learning_rate": 6.452051600870377e-06,
      "loss": 0.0238,
      "step": 9131
    },
    {
      "epoch": 0.7096673919801056,
      "grad_norm": 0.16689617931842804,
      "learning_rate": 6.4516630400994715e-06,
      "loss": 0.0506,
      "step": 9132
    },
    {
      "epoch": 0.7097451041342866,
      "grad_norm": 0.15436312556266785,
      "learning_rate": 6.451274479328567e-06,
      "loss": 0.0478,
      "step": 9133
    },
    {
      "epoch": 0.7098228162884676,
      "grad_norm": 0.4474184513092041,
      "learning_rate": 6.450885918557663e-06,
      "loss": 0.1869,
      "step": 9134
    },
    {
      "epoch": 0.7099005284426484,
      "grad_norm": 0.5913756489753723,
      "learning_rate": 6.450497357786758e-06,
      "loss": 0.2635,
      "step": 9135
    },
    {
      "epoch": 0.7099782405968293,
      "grad_norm": 0.7531731724739075,
      "learning_rate": 6.450108797015854e-06,
      "loss": 0.2069,
      "step": 9136
    },
    {
      "epoch": 0.7100559527510103,
      "grad_norm": 0.3221485912799835,
      "learning_rate": 6.44972023624495e-06,
      "loss": 0.0912,
      "step": 9137
    },
    {
      "epoch": 0.7101336649051911,
      "grad_norm": 0.19899427890777588,
      "learning_rate": 6.449331675474045e-06,
      "loss": 0.0413,
      "step": 9138
    },
    {
      "epoch": 0.7102113770593721,
      "grad_norm": 0.5007355809211731,
      "learning_rate": 6.44894311470314e-06,
      "loss": 0.9153,
      "step": 9139
    },
    {
      "epoch": 0.710289089213553,
      "grad_norm": 0.38600191473960876,
      "learning_rate": 6.448554553932236e-06,
      "loss": 0.06,
      "step": 9140
    },
    {
      "epoch": 0.7103668013677339,
      "grad_norm": 0.4294167160987854,
      "learning_rate": 6.44816599316133e-06,
      "loss": 0.0931,
      "step": 9141
    },
    {
      "epoch": 0.7104445135219148,
      "grad_norm": 0.32531940937042236,
      "learning_rate": 6.447777432390426e-06,
      "loss": 0.1172,
      "step": 9142
    },
    {
      "epoch": 0.7105222256760957,
      "grad_norm": 0.40507620573043823,
      "learning_rate": 6.447388871619522e-06,
      "loss": 0.3757,
      "step": 9143
    },
    {
      "epoch": 0.7105999378302766,
      "grad_norm": 0.28752246499061584,
      "learning_rate": 6.447000310848617e-06,
      "loss": 0.1109,
      "step": 9144
    },
    {
      "epoch": 0.7106776499844576,
      "grad_norm": 0.07888040691614151,
      "learning_rate": 6.446611750077713e-06,
      "loss": 0.0335,
      "step": 9145
    },
    {
      "epoch": 0.7107553621386384,
      "grad_norm": 0.19615377485752106,
      "learning_rate": 6.446223189306808e-06,
      "loss": 0.0612,
      "step": 9146
    },
    {
      "epoch": 0.7108330742928194,
      "grad_norm": 0.7125004529953003,
      "learning_rate": 6.445834628535903e-06,
      "loss": 0.2138,
      "step": 9147
    },
    {
      "epoch": 0.7109107864470003,
      "grad_norm": 0.2481493055820465,
      "learning_rate": 6.445446067764999e-06,
      "loss": 0.1259,
      "step": 9148
    },
    {
      "epoch": 0.7109884986011812,
      "grad_norm": 0.1765667349100113,
      "learning_rate": 6.445057506994095e-06,
      "loss": 0.0705,
      "step": 9149
    },
    {
      "epoch": 0.7110662107553621,
      "grad_norm": 0.3851664066314697,
      "learning_rate": 6.444668946223189e-06,
      "loss": 0.0596,
      "step": 9150
    },
    {
      "epoch": 0.7111439229095431,
      "grad_norm": 0.364145427942276,
      "learning_rate": 6.444280385452285e-06,
      "loss": 0.1248,
      "step": 9151
    },
    {
      "epoch": 0.7112216350637239,
      "grad_norm": 0.07878939807415009,
      "learning_rate": 6.443891824681381e-06,
      "loss": 0.0159,
      "step": 9152
    },
    {
      "epoch": 0.7112993472179049,
      "grad_norm": 0.5799891948699951,
      "learning_rate": 6.4435032639104764e-06,
      "loss": 0.3043,
      "step": 9153
    },
    {
      "epoch": 0.7113770593720858,
      "grad_norm": 0.616610050201416,
      "learning_rate": 6.443114703139571e-06,
      "loss": 0.4335,
      "step": 9154
    },
    {
      "epoch": 0.7114547715262667,
      "grad_norm": 0.30921638011932373,
      "learning_rate": 6.442726142368667e-06,
      "loss": 0.1023,
      "step": 9155
    },
    {
      "epoch": 0.7115324836804476,
      "grad_norm": 0.44670817255973816,
      "learning_rate": 6.442337581597763e-06,
      "loss": 0.1178,
      "step": 9156
    },
    {
      "epoch": 0.7116101958346286,
      "grad_norm": 0.35205671191215515,
      "learning_rate": 6.441949020826858e-06,
      "loss": 0.0959,
      "step": 9157
    },
    {
      "epoch": 0.7116879079888094,
      "grad_norm": 0.41627177596092224,
      "learning_rate": 6.441560460055954e-06,
      "loss": 0.3529,
      "step": 9158
    },
    {
      "epoch": 0.7117656201429904,
      "grad_norm": 1.0737519264221191,
      "learning_rate": 6.4411718992850495e-06,
      "loss": 0.4373,
      "step": 9159
    },
    {
      "epoch": 0.7118433322971712,
      "grad_norm": 1.8622993230819702,
      "learning_rate": 6.440783338514144e-06,
      "loss": 0.2458,
      "step": 9160
    },
    {
      "epoch": 0.7119210444513522,
      "grad_norm": 0.9161126017570496,
      "learning_rate": 6.4403947777432394e-06,
      "loss": 0.2089,
      "step": 9161
    },
    {
      "epoch": 0.7119987566055331,
      "grad_norm": 0.2902635931968689,
      "learning_rate": 6.440006216972335e-06,
      "loss": 0.1098,
      "step": 9162
    },
    {
      "epoch": 0.712076468759714,
      "grad_norm": 0.29008713364601135,
      "learning_rate": 6.43961765620143e-06,
      "loss": 0.1219,
      "step": 9163
    },
    {
      "epoch": 0.7121541809138949,
      "grad_norm": 0.5389124751091003,
      "learning_rate": 6.439229095430526e-06,
      "loss": 0.2863,
      "step": 9164
    },
    {
      "epoch": 0.7122318930680759,
      "grad_norm": 0.3327699601650238,
      "learning_rate": 6.438840534659622e-06,
      "loss": 0.1231,
      "step": 9165
    },
    {
      "epoch": 0.7123096052222567,
      "grad_norm": 0.46736940741539,
      "learning_rate": 6.438451973888717e-06,
      "loss": 0.1806,
      "step": 9166
    },
    {
      "epoch": 0.7123873173764377,
      "grad_norm": 0.30568966269493103,
      "learning_rate": 6.4380634131178125e-06,
      "loss": 0.1679,
      "step": 9167
    },
    {
      "epoch": 0.7124650295306186,
      "grad_norm": 0.2341775745153427,
      "learning_rate": 6.437674852346908e-06,
      "loss": 0.1156,
      "step": 9168
    },
    {
      "epoch": 0.7125427416847995,
      "grad_norm": 0.1765265315771103,
      "learning_rate": 6.437286291576002e-06,
      "loss": 0.0479,
      "step": 9169
    },
    {
      "epoch": 0.7126204538389804,
      "grad_norm": 0.3168044090270996,
      "learning_rate": 6.436897730805098e-06,
      "loss": 0.1639,
      "step": 9170
    },
    {
      "epoch": 0.7126981659931614,
      "grad_norm": 0.36896631121635437,
      "learning_rate": 6.436509170034194e-06,
      "loss": 0.1655,
      "step": 9171
    },
    {
      "epoch": 0.7127758781473422,
      "grad_norm": 0.17584389448165894,
      "learning_rate": 6.436120609263289e-06,
      "loss": 0.1297,
      "step": 9172
    },
    {
      "epoch": 0.7128535903015232,
      "grad_norm": 0.1064726710319519,
      "learning_rate": 6.435732048492385e-06,
      "loss": 0.0159,
      "step": 9173
    },
    {
      "epoch": 0.712931302455704,
      "grad_norm": 0.5337567329406738,
      "learning_rate": 6.4353434877214806e-06,
      "loss": 0.5342,
      "step": 9174
    },
    {
      "epoch": 0.713009014609885,
      "grad_norm": 0.4844302237033844,
      "learning_rate": 6.4349549269505755e-06,
      "loss": 0.2272,
      "step": 9175
    },
    {
      "epoch": 0.7130867267640659,
      "grad_norm": 0.2381022423505783,
      "learning_rate": 6.434566366179671e-06,
      "loss": 0.0948,
      "step": 9176
    },
    {
      "epoch": 0.7131644389182468,
      "grad_norm": 0.38304615020751953,
      "learning_rate": 6.434177805408767e-06,
      "loss": 0.4327,
      "step": 9177
    },
    {
      "epoch": 0.7132421510724277,
      "grad_norm": 0.5016589760780334,
      "learning_rate": 6.433789244637861e-06,
      "loss": 0.3118,
      "step": 9178
    },
    {
      "epoch": 0.7133198632266087,
      "grad_norm": 0.46673300862312317,
      "learning_rate": 6.433400683866957e-06,
      "loss": 0.3484,
      "step": 9179
    },
    {
      "epoch": 0.7133975753807895,
      "grad_norm": 1.1114189624786377,
      "learning_rate": 6.433012123096053e-06,
      "loss": 0.097,
      "step": 9180
    },
    {
      "epoch": 0.7134752875349705,
      "grad_norm": 0.1882772296667099,
      "learning_rate": 6.432623562325149e-06,
      "loss": 0.0435,
      "step": 9181
    },
    {
      "epoch": 0.7135529996891514,
      "grad_norm": 0.3917831480503082,
      "learning_rate": 6.4322350015542435e-06,
      "loss": 0.3277,
      "step": 9182
    },
    {
      "epoch": 0.7136307118433323,
      "grad_norm": 0.315126895904541,
      "learning_rate": 6.431846440783339e-06,
      "loss": 0.0969,
      "step": 9183
    },
    {
      "epoch": 0.7137084239975132,
      "grad_norm": 0.23607385158538818,
      "learning_rate": 6.431457880012435e-06,
      "loss": 0.1459,
      "step": 9184
    },
    {
      "epoch": 0.7137861361516942,
      "grad_norm": 0.449033260345459,
      "learning_rate": 6.431069319241529e-06,
      "loss": 0.2043,
      "step": 9185
    },
    {
      "epoch": 0.713863848305875,
      "grad_norm": 0.4107237458229065,
      "learning_rate": 6.430680758470625e-06,
      "loss": 0.2521,
      "step": 9186
    },
    {
      "epoch": 0.713941560460056,
      "grad_norm": 0.44187772274017334,
      "learning_rate": 6.430292197699721e-06,
      "loss": 0.212,
      "step": 9187
    },
    {
      "epoch": 0.7140192726142369,
      "grad_norm": 0.20612704753875732,
      "learning_rate": 6.429903636928816e-06,
      "loss": 0.0339,
      "step": 9188
    },
    {
      "epoch": 0.7140969847684178,
      "grad_norm": 0.4694828689098358,
      "learning_rate": 6.429515076157912e-06,
      "loss": 0.3277,
      "step": 9189
    },
    {
      "epoch": 0.7141746969225987,
      "grad_norm": 1.6282298564910889,
      "learning_rate": 6.429126515387007e-06,
      "loss": 0.7153,
      "step": 9190
    },
    {
      "epoch": 0.7142524090767796,
      "grad_norm": 0.5925331711769104,
      "learning_rate": 6.428737954616102e-06,
      "loss": 0.3761,
      "step": 9191
    },
    {
      "epoch": 0.7143301212309605,
      "grad_norm": 0.538412868976593,
      "learning_rate": 6.428349393845198e-06,
      "loss": 0.6547,
      "step": 9192
    },
    {
      "epoch": 0.7144078333851415,
      "grad_norm": 0.2597061097621918,
      "learning_rate": 6.427960833074294e-06,
      "loss": 0.0656,
      "step": 9193
    },
    {
      "epoch": 0.7144855455393223,
      "grad_norm": 0.6144047379493713,
      "learning_rate": 6.427572272303388e-06,
      "loss": 0.7056,
      "step": 9194
    },
    {
      "epoch": 0.7145632576935033,
      "grad_norm": 0.2696804404258728,
      "learning_rate": 6.427183711532484e-06,
      "loss": 0.1111,
      "step": 9195
    },
    {
      "epoch": 0.7146409698476842,
      "grad_norm": 0.6316996216773987,
      "learning_rate": 6.42679515076158e-06,
      "loss": 0.617,
      "step": 9196
    },
    {
      "epoch": 0.7147186820018651,
      "grad_norm": 0.4081341624259949,
      "learning_rate": 6.4264065899906746e-06,
      "loss": 0.0857,
      "step": 9197
    },
    {
      "epoch": 0.714796394156046,
      "grad_norm": 0.5480274558067322,
      "learning_rate": 6.42601802921977e-06,
      "loss": 0.2299,
      "step": 9198
    },
    {
      "epoch": 0.714874106310227,
      "grad_norm": 0.34397637844085693,
      "learning_rate": 6.425629468448866e-06,
      "loss": 0.1613,
      "step": 9199
    },
    {
      "epoch": 0.7149518184644078,
      "grad_norm": 0.6175308227539062,
      "learning_rate": 6.425240907677961e-06,
      "loss": 0.0421,
      "step": 9200
    },
    {
      "epoch": 0.7150295306185888,
      "grad_norm": 0.030677367001771927,
      "learning_rate": 6.424852346907057e-06,
      "loss": 0.0046,
      "step": 9201
    },
    {
      "epoch": 0.7151072427727697,
      "grad_norm": 0.4692745506763458,
      "learning_rate": 6.424463786136153e-06,
      "loss": 0.1509,
      "step": 9202
    },
    {
      "epoch": 0.7151849549269506,
      "grad_norm": 0.460761159658432,
      "learning_rate": 6.424075225365247e-06,
      "loss": 0.0426,
      "step": 9203
    },
    {
      "epoch": 0.7152626670811315,
      "grad_norm": 1.07296884059906,
      "learning_rate": 6.423686664594343e-06,
      "loss": 0.4668,
      "step": 9204
    },
    {
      "epoch": 0.7153403792353124,
      "grad_norm": 0.13665823638439178,
      "learning_rate": 6.423298103823438e-06,
      "loss": 0.0447,
      "step": 9205
    },
    {
      "epoch": 0.7154180913894933,
      "grad_norm": 0.42313915491104126,
      "learning_rate": 6.422909543052533e-06,
      "loss": 0.1465,
      "step": 9206
    },
    {
      "epoch": 0.7154958035436743,
      "grad_norm": 0.20703375339508057,
      "learning_rate": 6.422520982281629e-06,
      "loss": 0.2442,
      "step": 9207
    },
    {
      "epoch": 0.7155735156978551,
      "grad_norm": 0.1534310132265091,
      "learning_rate": 6.422132421510725e-06,
      "loss": 0.0391,
      "step": 9208
    },
    {
      "epoch": 0.715651227852036,
      "grad_norm": 0.26680830121040344,
      "learning_rate": 6.42174386073982e-06,
      "loss": 0.0261,
      "step": 9209
    },
    {
      "epoch": 0.715728940006217,
      "grad_norm": 0.19801901280879974,
      "learning_rate": 6.421355299968916e-06,
      "loss": 0.0624,
      "step": 9210
    },
    {
      "epoch": 0.7158066521603978,
      "grad_norm": 0.5533384680747986,
      "learning_rate": 6.4209667391980115e-06,
      "loss": 0.0965,
      "step": 9211
    },
    {
      "epoch": 0.7158843643145788,
      "grad_norm": 0.29301953315734863,
      "learning_rate": 6.420578178427107e-06,
      "loss": 0.0681,
      "step": 9212
    },
    {
      "epoch": 0.7159620764687598,
      "grad_norm": 0.2710164487361908,
      "learning_rate": 6.420189617656201e-06,
      "loss": 0.0806,
      "step": 9213
    },
    {
      "epoch": 0.7160397886229406,
      "grad_norm": 0.4961026608943939,
      "learning_rate": 6.419801056885297e-06,
      "loss": 0.3272,
      "step": 9214
    },
    {
      "epoch": 0.7161175007771216,
      "grad_norm": 0.5441402196884155,
      "learning_rate": 6.419412496114393e-06,
      "loss": 0.3542,
      "step": 9215
    },
    {
      "epoch": 0.7161952129313025,
      "grad_norm": 0.2603145241737366,
      "learning_rate": 6.419023935343488e-06,
      "loss": 0.1293,
      "step": 9216
    },
    {
      "epoch": 0.7162729250854833,
      "grad_norm": 0.30521589517593384,
      "learning_rate": 6.418635374572584e-06,
      "loss": 0.0529,
      "step": 9217
    },
    {
      "epoch": 0.7163506372396643,
      "grad_norm": 0.8651229739189148,
      "learning_rate": 6.4182468138016795e-06,
      "loss": 0.4422,
      "step": 9218
    },
    {
      "epoch": 0.7164283493938451,
      "grad_norm": 0.5575742721557617,
      "learning_rate": 6.4178582530307745e-06,
      "loss": 0.2221,
      "step": 9219
    },
    {
      "epoch": 0.7165060615480261,
      "grad_norm": 0.713954746723175,
      "learning_rate": 6.41746969225987e-06,
      "loss": 0.134,
      "step": 9220
    },
    {
      "epoch": 0.716583773702207,
      "grad_norm": 0.3105071783065796,
      "learning_rate": 6.417081131488966e-06,
      "loss": 0.3688,
      "step": 9221
    },
    {
      "epoch": 0.7166614858563879,
      "grad_norm": 0.16311994194984436,
      "learning_rate": 6.41669257071806e-06,
      "loss": 0.0606,
      "step": 9222
    },
    {
      "epoch": 0.7167391980105688,
      "grad_norm": 0.26374760270118713,
      "learning_rate": 6.416304009947156e-06,
      "loss": 0.22,
      "step": 9223
    },
    {
      "epoch": 0.7168169101647498,
      "grad_norm": 0.25519928336143494,
      "learning_rate": 6.415915449176252e-06,
      "loss": 0.0272,
      "step": 9224
    },
    {
      "epoch": 0.7168946223189306,
      "grad_norm": 0.4116423428058624,
      "learning_rate": 6.415526888405347e-06,
      "loss": 0.2646,
      "step": 9225
    },
    {
      "epoch": 0.7169723344731116,
      "grad_norm": 0.4083043336868286,
      "learning_rate": 6.4151383276344425e-06,
      "loss": 0.2083,
      "step": 9226
    },
    {
      "epoch": 0.7170500466272925,
      "grad_norm": 0.6158797144889832,
      "learning_rate": 6.414749766863538e-06,
      "loss": 0.1787,
      "step": 9227
    },
    {
      "epoch": 0.7171277587814734,
      "grad_norm": 0.7187532186508179,
      "learning_rate": 6.414361206092633e-06,
      "loss": 0.2354,
      "step": 9228
    },
    {
      "epoch": 0.7172054709356543,
      "grad_norm": 0.6292282938957214,
      "learning_rate": 6.413972645321729e-06,
      "loss": 0.1348,
      "step": 9229
    },
    {
      "epoch": 0.7172831830898353,
      "grad_norm": 0.6826763153076172,
      "learning_rate": 6.413584084550825e-06,
      "loss": 0.252,
      "step": 9230
    },
    {
      "epoch": 0.7173608952440161,
      "grad_norm": 0.5794870853424072,
      "learning_rate": 6.413195523779919e-06,
      "loss": 0.2497,
      "step": 9231
    },
    {
      "epoch": 0.7174386073981971,
      "grad_norm": 0.48046445846557617,
      "learning_rate": 6.412806963009015e-06,
      "loss": 0.2989,
      "step": 9232
    },
    {
      "epoch": 0.717516319552378,
      "grad_norm": 0.36757516860961914,
      "learning_rate": 6.4124184022381105e-06,
      "loss": 0.1537,
      "step": 9233
    },
    {
      "epoch": 0.7175940317065589,
      "grad_norm": 0.5448726415634155,
      "learning_rate": 6.4120298414672055e-06,
      "loss": 0.2381,
      "step": 9234
    },
    {
      "epoch": 0.7176717438607398,
      "grad_norm": 0.3751591444015503,
      "learning_rate": 6.411641280696301e-06,
      "loss": 0.069,
      "step": 9235
    },
    {
      "epoch": 0.7177494560149207,
      "grad_norm": 0.1909884214401245,
      "learning_rate": 6.411252719925397e-06,
      "loss": 0.1283,
      "step": 9236
    },
    {
      "epoch": 0.7178271681691016,
      "grad_norm": 0.5270954370498657,
      "learning_rate": 6.410864159154492e-06,
      "loss": 0.5224,
      "step": 9237
    },
    {
      "epoch": 0.7179048803232826,
      "grad_norm": 0.4739324152469635,
      "learning_rate": 6.410475598383588e-06,
      "loss": 0.2073,
      "step": 9238
    },
    {
      "epoch": 0.7179825924774634,
      "grad_norm": 0.19512873888015747,
      "learning_rate": 6.410087037612684e-06,
      "loss": 0.0744,
      "step": 9239
    },
    {
      "epoch": 0.7180603046316444,
      "grad_norm": 0.20091520249843597,
      "learning_rate": 6.409698476841778e-06,
      "loss": 0.052,
      "step": 9240
    },
    {
      "epoch": 0.7181380167858253,
      "grad_norm": 0.3274540305137634,
      "learning_rate": 6.4093099160708735e-06,
      "loss": 0.1156,
      "step": 9241
    },
    {
      "epoch": 0.7182157289400062,
      "grad_norm": 0.46559154987335205,
      "learning_rate": 6.408921355299969e-06,
      "loss": 0.1554,
      "step": 9242
    },
    {
      "epoch": 0.7182934410941871,
      "grad_norm": 0.3293936848640442,
      "learning_rate": 6.408532794529065e-06,
      "loss": 0.1215,
      "step": 9243
    },
    {
      "epoch": 0.7183711532483681,
      "grad_norm": 0.3416482210159302,
      "learning_rate": 6.40814423375816e-06,
      "loss": 0.1017,
      "step": 9244
    },
    {
      "epoch": 0.7184488654025489,
      "grad_norm": 0.3256933093070984,
      "learning_rate": 6.407755672987256e-06,
      "loss": 0.162,
      "step": 9245
    },
    {
      "epoch": 0.7185265775567299,
      "grad_norm": 0.5753457546234131,
      "learning_rate": 6.407367112216352e-06,
      "loss": 0.3092,
      "step": 9246
    },
    {
      "epoch": 0.7186042897109108,
      "grad_norm": 0.3470522165298462,
      "learning_rate": 6.406978551445447e-06,
      "loss": 0.1998,
      "step": 9247
    },
    {
      "epoch": 0.7186820018650917,
      "grad_norm": 0.49283212423324585,
      "learning_rate": 6.406589990674542e-06,
      "loss": 0.1242,
      "step": 9248
    },
    {
      "epoch": 0.7187597140192726,
      "grad_norm": 0.4837401211261749,
      "learning_rate": 6.406201429903638e-06,
      "loss": 0.3054,
      "step": 9249
    },
    {
      "epoch": 0.7188374261734535,
      "grad_norm": 1.5204097032546997,
      "learning_rate": 6.405812869132732e-06,
      "loss": 0.0906,
      "step": 9250
    },
    {
      "epoch": 0.7189151383276344,
      "grad_norm": 0.511172890663147,
      "learning_rate": 6.405424308361828e-06,
      "loss": 0.0633,
      "step": 9251
    },
    {
      "epoch": 0.7189928504818154,
      "grad_norm": 0.44204986095428467,
      "learning_rate": 6.405035747590924e-06,
      "loss": 0.1376,
      "step": 9252
    },
    {
      "epoch": 0.7190705626359962,
      "grad_norm": 0.6721327900886536,
      "learning_rate": 6.404647186820019e-06,
      "loss": 0.2093,
      "step": 9253
    },
    {
      "epoch": 0.7191482747901772,
      "grad_norm": 0.3602766990661621,
      "learning_rate": 6.404258626049115e-06,
      "loss": 0.0891,
      "step": 9254
    },
    {
      "epoch": 0.7192259869443581,
      "grad_norm": 0.2113366574048996,
      "learning_rate": 6.4038700652782105e-06,
      "loss": 0.0831,
      "step": 9255
    },
    {
      "epoch": 0.719303699098539,
      "grad_norm": 0.3038579821586609,
      "learning_rate": 6.403481504507305e-06,
      "loss": 0.0971,
      "step": 9256
    },
    {
      "epoch": 0.7193814112527199,
      "grad_norm": 0.38625600934028625,
      "learning_rate": 6.403092943736401e-06,
      "loss": 0.0875,
      "step": 9257
    },
    {
      "epoch": 0.7194591234069009,
      "grad_norm": 0.2577105164527893,
      "learning_rate": 6.402704382965497e-06,
      "loss": 0.1393,
      "step": 9258
    },
    {
      "epoch": 0.7195368355610817,
      "grad_norm": 0.25087791681289673,
      "learning_rate": 6.402315822194591e-06,
      "loss": 0.0879,
      "step": 9259
    },
    {
      "epoch": 0.7196145477152627,
      "grad_norm": 0.6042596101760864,
      "learning_rate": 6.401927261423687e-06,
      "loss": 0.6963,
      "step": 9260
    },
    {
      "epoch": 0.7196922598694436,
      "grad_norm": 0.4649706482887268,
      "learning_rate": 6.401538700652783e-06,
      "loss": 0.2097,
      "step": 9261
    },
    {
      "epoch": 0.7197699720236245,
      "grad_norm": 0.33744239807128906,
      "learning_rate": 6.401150139881878e-06,
      "loss": 0.1732,
      "step": 9262
    },
    {
      "epoch": 0.7198476841778054,
      "grad_norm": 0.5878356695175171,
      "learning_rate": 6.4007615791109734e-06,
      "loss": 0.4004,
      "step": 9263
    },
    {
      "epoch": 0.7199253963319864,
      "grad_norm": 0.32708796858787537,
      "learning_rate": 6.400373018340069e-06,
      "loss": 0.0913,
      "step": 9264
    },
    {
      "epoch": 0.7200031084861672,
      "grad_norm": 0.11401144415140152,
      "learning_rate": 6.399984457569164e-06,
      "loss": 0.038,
      "step": 9265
    },
    {
      "epoch": 0.7200808206403482,
      "grad_norm": 0.29865652322769165,
      "learning_rate": 6.39959589679826e-06,
      "loss": 0.0596,
      "step": 9266
    },
    {
      "epoch": 0.720158532794529,
      "grad_norm": 0.05041207745671272,
      "learning_rate": 6.399207336027356e-06,
      "loss": 0.0201,
      "step": 9267
    },
    {
      "epoch": 0.72023624494871,
      "grad_norm": 0.3814220428466797,
      "learning_rate": 6.39881877525645e-06,
      "loss": 0.068,
      "step": 9268
    },
    {
      "epoch": 0.7203139571028909,
      "grad_norm": 0.7774017453193665,
      "learning_rate": 6.398430214485546e-06,
      "loss": 0.1522,
      "step": 9269
    },
    {
      "epoch": 0.7203916692570718,
      "grad_norm": 0.5075650811195374,
      "learning_rate": 6.3980416537146415e-06,
      "loss": 0.2006,
      "step": 9270
    },
    {
      "epoch": 0.7204693814112527,
      "grad_norm": 0.016949066892266273,
      "learning_rate": 6.3976530929437364e-06,
      "loss": 0.0015,
      "step": 9271
    },
    {
      "epoch": 0.7205470935654337,
      "grad_norm": 0.113042913377285,
      "learning_rate": 6.397264532172832e-06,
      "loss": 0.0295,
      "step": 9272
    },
    {
      "epoch": 0.7206248057196145,
      "grad_norm": 0.08198549598455429,
      "learning_rate": 6.396875971401928e-06,
      "loss": 0.0257,
      "step": 9273
    },
    {
      "epoch": 0.7207025178737955,
      "grad_norm": 0.16199548542499542,
      "learning_rate": 6.396487410631024e-06,
      "loss": 0.0238,
      "step": 9274
    },
    {
      "epoch": 0.7207802300279764,
      "grad_norm": 0.2196868658065796,
      "learning_rate": 6.396098849860119e-06,
      "loss": 0.0526,
      "step": 9275
    },
    {
      "epoch": 0.7208579421821573,
      "grad_norm": 0.1782405525445938,
      "learning_rate": 6.3957102890892146e-06,
      "loss": 0.0526,
      "step": 9276
    },
    {
      "epoch": 0.7209356543363382,
      "grad_norm": 0.36251217126846313,
      "learning_rate": 6.39532172831831e-06,
      "loss": 0.2089,
      "step": 9277
    },
    {
      "epoch": 0.7210133664905192,
      "grad_norm": 0.19085793197155,
      "learning_rate": 6.3949331675474045e-06,
      "loss": 0.1291,
      "step": 9278
    },
    {
      "epoch": 0.7210910786447,
      "grad_norm": 0.09957756102085114,
      "learning_rate": 6.3945446067765e-06,
      "loss": 0.0254,
      "step": 9279
    },
    {
      "epoch": 0.721168790798881,
      "grad_norm": 0.11685451120138168,
      "learning_rate": 6.394156046005596e-06,
      "loss": 0.0374,
      "step": 9280
    },
    {
      "epoch": 0.7212465029530618,
      "grad_norm": 0.31809309124946594,
      "learning_rate": 6.393767485234691e-06,
      "loss": 0.2263,
      "step": 9281
    },
    {
      "epoch": 0.7213242151072428,
      "grad_norm": 0.13541996479034424,
      "learning_rate": 6.393378924463787e-06,
      "loss": 0.0213,
      "step": 9282
    },
    {
      "epoch": 0.7214019272614237,
      "grad_norm": 0.6193782091140747,
      "learning_rate": 6.392990363692883e-06,
      "loss": 0.5151,
      "step": 9283
    },
    {
      "epoch": 0.7214796394156046,
      "grad_norm": 0.46246805787086487,
      "learning_rate": 6.3926018029219775e-06,
      "loss": 0.5378,
      "step": 9284
    },
    {
      "epoch": 0.7215573515697855,
      "grad_norm": 0.4556540250778198,
      "learning_rate": 6.392213242151073e-06,
      "loss": 0.1598,
      "step": 9285
    },
    {
      "epoch": 0.7216350637239665,
      "grad_norm": 0.48458927869796753,
      "learning_rate": 6.391824681380169e-06,
      "loss": 0.0831,
      "step": 9286
    },
    {
      "epoch": 0.7217127758781473,
      "grad_norm": 0.7486373782157898,
      "learning_rate": 6.391436120609263e-06,
      "loss": 0.2417,
      "step": 9287
    },
    {
      "epoch": 0.7217904880323283,
      "grad_norm": 0.809614360332489,
      "learning_rate": 6.391047559838359e-06,
      "loss": 0.5902,
      "step": 9288
    },
    {
      "epoch": 0.7218682001865092,
      "grad_norm": 0.37215790152549744,
      "learning_rate": 6.390658999067455e-06,
      "loss": 0.2527,
      "step": 9289
    },
    {
      "epoch": 0.72194591234069,
      "grad_norm": 0.16704817116260529,
      "learning_rate": 6.39027043829655e-06,
      "loss": 0.0418,
      "step": 9290
    },
    {
      "epoch": 0.722023624494871,
      "grad_norm": 0.47037896513938904,
      "learning_rate": 6.389881877525646e-06,
      "loss": 0.3586,
      "step": 9291
    },
    {
      "epoch": 0.722101336649052,
      "grad_norm": 0.44592979550361633,
      "learning_rate": 6.389493316754741e-06,
      "loss": 0.2617,
      "step": 9292
    },
    {
      "epoch": 0.7221790488032328,
      "grad_norm": 0.10530481487512589,
      "learning_rate": 6.389104755983836e-06,
      "loss": 0.0824,
      "step": 9293
    },
    {
      "epoch": 0.7222567609574138,
      "grad_norm": 0.16551125049591064,
      "learning_rate": 6.388716195212932e-06,
      "loss": 0.0523,
      "step": 9294
    },
    {
      "epoch": 0.7223344731115946,
      "grad_norm": 0.22269093990325928,
      "learning_rate": 6.388327634442028e-06,
      "loss": 0.0449,
      "step": 9295
    },
    {
      "epoch": 0.7224121852657756,
      "grad_norm": 0.8415801525115967,
      "learning_rate": 6.387939073671122e-06,
      "loss": 0.5353,
      "step": 9296
    },
    {
      "epoch": 0.7224898974199565,
      "grad_norm": 0.7198399901390076,
      "learning_rate": 6.387550512900218e-06,
      "loss": 0.5876,
      "step": 9297
    },
    {
      "epoch": 0.7225676095741373,
      "grad_norm": 0.2273285984992981,
      "learning_rate": 6.387161952129314e-06,
      "loss": 0.0627,
      "step": 9298
    },
    {
      "epoch": 0.7226453217283183,
      "grad_norm": 0.24764949083328247,
      "learning_rate": 6.3867733913584086e-06,
      "loss": 0.1323,
      "step": 9299
    },
    {
      "epoch": 0.7227230338824993,
      "grad_norm": 0.11654191464185715,
      "learning_rate": 6.386384830587504e-06,
      "loss": 0.0177,
      "step": 9300
    },
    {
      "epoch": 0.7228007460366801,
      "grad_norm": 0.09812045097351074,
      "learning_rate": 6.3859962698166e-06,
      "loss": 0.0495,
      "step": 9301
    },
    {
      "epoch": 0.722878458190861,
      "grad_norm": 0.8833188414573669,
      "learning_rate": 6.385607709045696e-06,
      "loss": 0.4715,
      "step": 9302
    },
    {
      "epoch": 0.722956170345042,
      "grad_norm": 0.3585314452648163,
      "learning_rate": 6.385219148274791e-06,
      "loss": 0.1762,
      "step": 9303
    },
    {
      "epoch": 0.7230338824992228,
      "grad_norm": 0.26012101769447327,
      "learning_rate": 6.384830587503887e-06,
      "loss": 0.124,
      "step": 9304
    },
    {
      "epoch": 0.7231115946534038,
      "grad_norm": 0.32712194323539734,
      "learning_rate": 6.384442026732982e-06,
      "loss": 0.1253,
      "step": 9305
    },
    {
      "epoch": 0.7231893068075848,
      "grad_norm": 0.26649919152259827,
      "learning_rate": 6.384053465962077e-06,
      "loss": 0.1528,
      "step": 9306
    },
    {
      "epoch": 0.7232670189617656,
      "grad_norm": 0.4382365047931671,
      "learning_rate": 6.383664905191172e-06,
      "loss": 0.2665,
      "step": 9307
    },
    {
      "epoch": 0.7233447311159465,
      "grad_norm": 0.11471716314554214,
      "learning_rate": 6.383276344420268e-06,
      "loss": 0.0712,
      "step": 9308
    },
    {
      "epoch": 0.7234224432701275,
      "grad_norm": 0.34214577078819275,
      "learning_rate": 6.382887783649363e-06,
      "loss": 0.1655,
      "step": 9309
    },
    {
      "epoch": 0.7235001554243083,
      "grad_norm": 0.7822505831718445,
      "learning_rate": 6.382499222878459e-06,
      "loss": 0.3265,
      "step": 9310
    },
    {
      "epoch": 0.7235778675784893,
      "grad_norm": 0.39965522289276123,
      "learning_rate": 6.382110662107555e-06,
      "loss": 0.0619,
      "step": 9311
    },
    {
      "epoch": 0.7236555797326701,
      "grad_norm": 0.22047245502471924,
      "learning_rate": 6.381722101336649e-06,
      "loss": 0.0942,
      "step": 9312
    },
    {
      "epoch": 0.7237332918868511,
      "grad_norm": 0.3098160922527313,
      "learning_rate": 6.381333540565745e-06,
      "loss": 0.1373,
      "step": 9313
    },
    {
      "epoch": 0.723811004041032,
      "grad_norm": 0.23198950290679932,
      "learning_rate": 6.3809449797948404e-06,
      "loss": 0.1404,
      "step": 9314
    },
    {
      "epoch": 0.7238887161952129,
      "grad_norm": 0.2413424253463745,
      "learning_rate": 6.380556419023935e-06,
      "loss": 0.0709,
      "step": 9315
    },
    {
      "epoch": 0.7239664283493938,
      "grad_norm": 0.3323928117752075,
      "learning_rate": 6.380167858253031e-06,
      "loss": 0.3228,
      "step": 9316
    },
    {
      "epoch": 0.7240441405035748,
      "grad_norm": 0.14643898606300354,
      "learning_rate": 6.379779297482127e-06,
      "loss": 0.0244,
      "step": 9317
    },
    {
      "epoch": 0.7241218526577556,
      "grad_norm": 0.11357004940509796,
      "learning_rate": 6.379390736711222e-06,
      "loss": 0.0217,
      "step": 9318
    },
    {
      "epoch": 0.7241995648119366,
      "grad_norm": 0.08922266960144043,
      "learning_rate": 6.379002175940318e-06,
      "loss": 0.043,
      "step": 9319
    },
    {
      "epoch": 0.7242772769661175,
      "grad_norm": 0.27186527848243713,
      "learning_rate": 6.3786136151694135e-06,
      "loss": 0.0578,
      "step": 9320
    },
    {
      "epoch": 0.7243549891202984,
      "grad_norm": 0.6141354441642761,
      "learning_rate": 6.378225054398508e-06,
      "loss": 0.1961,
      "step": 9321
    },
    {
      "epoch": 0.7244327012744793,
      "grad_norm": 0.31315210461616516,
      "learning_rate": 6.3778364936276034e-06,
      "loss": 0.0945,
      "step": 9322
    },
    {
      "epoch": 0.7245104134286603,
      "grad_norm": 0.27532848715782166,
      "learning_rate": 6.377447932856699e-06,
      "loss": 0.1962,
      "step": 9323
    },
    {
      "epoch": 0.7245881255828411,
      "grad_norm": 0.17332132160663605,
      "learning_rate": 6.377059372085794e-06,
      "loss": 0.0355,
      "step": 9324
    },
    {
      "epoch": 0.7246658377370221,
      "grad_norm": 0.663307249546051,
      "learning_rate": 6.37667081131489e-06,
      "loss": 0.2519,
      "step": 9325
    },
    {
      "epoch": 0.7247435498912029,
      "grad_norm": 0.5079185962677002,
      "learning_rate": 6.376282250543986e-06,
      "loss": 0.5217,
      "step": 9326
    },
    {
      "epoch": 0.7248212620453839,
      "grad_norm": 0.39871731400489807,
      "learning_rate": 6.375893689773081e-06,
      "loss": 0.2819,
      "step": 9327
    },
    {
      "epoch": 0.7248989741995648,
      "grad_norm": 0.37106627225875854,
      "learning_rate": 6.3755051290021765e-06,
      "loss": 0.1908,
      "step": 9328
    },
    {
      "epoch": 0.7249766863537457,
      "grad_norm": 0.7782737016677856,
      "learning_rate": 6.375116568231272e-06,
      "loss": 0.2708,
      "step": 9329
    },
    {
      "epoch": 0.7250543985079266,
      "grad_norm": 0.09297884255647659,
      "learning_rate": 6.374728007460366e-06,
      "loss": 0.0221,
      "step": 9330
    },
    {
      "epoch": 0.7251321106621076,
      "grad_norm": 0.6136407852172852,
      "learning_rate": 6.374339446689462e-06,
      "loss": 0.1448,
      "step": 9331
    },
    {
      "epoch": 0.7252098228162884,
      "grad_norm": 0.09817945212125778,
      "learning_rate": 6.373950885918558e-06,
      "loss": 0.0301,
      "step": 9332
    },
    {
      "epoch": 0.7252875349704694,
      "grad_norm": 0.7954661846160889,
      "learning_rate": 6.373562325147654e-06,
      "loss": 0.9505,
      "step": 9333
    },
    {
      "epoch": 0.7253652471246503,
      "grad_norm": 0.31495949625968933,
      "learning_rate": 6.373173764376749e-06,
      "loss": 0.2458,
      "step": 9334
    },
    {
      "epoch": 0.7254429592788312,
      "grad_norm": 0.47460752725601196,
      "learning_rate": 6.3727852036058446e-06,
      "loss": 0.2771,
      "step": 9335
    },
    {
      "epoch": 0.7255206714330121,
      "grad_norm": 0.3673475384712219,
      "learning_rate": 6.37239664283494e-06,
      "loss": 0.3368,
      "step": 9336
    },
    {
      "epoch": 0.7255983835871931,
      "grad_norm": 0.339735746383667,
      "learning_rate": 6.372008082064035e-06,
      "loss": 0.0814,
      "step": 9337
    },
    {
      "epoch": 0.7256760957413739,
      "grad_norm": 0.5043866634368896,
      "learning_rate": 6.371619521293131e-06,
      "loss": 0.1457,
      "step": 9338
    },
    {
      "epoch": 0.7257538078955549,
      "grad_norm": 0.5484844446182251,
      "learning_rate": 6.371230960522227e-06,
      "loss": 0.4333,
      "step": 9339
    },
    {
      "epoch": 0.7258315200497357,
      "grad_norm": 0.2981368601322174,
      "learning_rate": 6.370842399751321e-06,
      "loss": 0.1739,
      "step": 9340
    },
    {
      "epoch": 0.7259092322039167,
      "grad_norm": 0.2465665489435196,
      "learning_rate": 6.370453838980417e-06,
      "loss": 0.1159,
      "step": 9341
    },
    {
      "epoch": 0.7259869443580976,
      "grad_norm": 0.27927646040916443,
      "learning_rate": 6.370065278209513e-06,
      "loss": 0.0502,
      "step": 9342
    },
    {
      "epoch": 0.7260646565122785,
      "grad_norm": 0.013500122353434563,
      "learning_rate": 6.3696767174386075e-06,
      "loss": 0.001,
      "step": 9343
    },
    {
      "epoch": 0.7261423686664594,
      "grad_norm": 0.3900493383407593,
      "learning_rate": 6.369288156667703e-06,
      "loss": 0.4598,
      "step": 9344
    },
    {
      "epoch": 0.7262200808206404,
      "grad_norm": 0.5073949694633484,
      "learning_rate": 6.368899595896799e-06,
      "loss": 0.3095,
      "step": 9345
    },
    {
      "epoch": 0.7262977929748212,
      "grad_norm": 0.5056535601615906,
      "learning_rate": 6.368511035125894e-06,
      "loss": 0.9665,
      "step": 9346
    },
    {
      "epoch": 0.7263755051290022,
      "grad_norm": 0.44310158491134644,
      "learning_rate": 6.36812247435499e-06,
      "loss": 0.2963,
      "step": 9347
    },
    {
      "epoch": 0.7264532172831831,
      "grad_norm": 0.5675112009048462,
      "learning_rate": 6.367733913584086e-06,
      "loss": 0.2068,
      "step": 9348
    },
    {
      "epoch": 0.726530929437364,
      "grad_norm": 0.10521941632032394,
      "learning_rate": 6.36734535281318e-06,
      "loss": 0.0187,
      "step": 9349
    },
    {
      "epoch": 0.7266086415915449,
      "grad_norm": 0.20471617579460144,
      "learning_rate": 6.3669567920422756e-06,
      "loss": 0.0622,
      "step": 9350
    },
    {
      "epoch": 0.7266863537457259,
      "grad_norm": 0.4269197881221771,
      "learning_rate": 6.366568231271371e-06,
      "loss": 0.1938,
      "step": 9351
    },
    {
      "epoch": 0.7267640658999067,
      "grad_norm": 0.23531071841716766,
      "learning_rate": 6.366179670500466e-06,
      "loss": 0.071,
      "step": 9352
    },
    {
      "epoch": 0.7268417780540877,
      "grad_norm": 0.5365087985992432,
      "learning_rate": 6.365791109729562e-06,
      "loss": 0.2,
      "step": 9353
    },
    {
      "epoch": 0.7269194902082686,
      "grad_norm": 0.5767698884010315,
      "learning_rate": 6.365402548958658e-06,
      "loss": 0.288,
      "step": 9354
    },
    {
      "epoch": 0.7269972023624495,
      "grad_norm": 0.8079546093940735,
      "learning_rate": 6.365013988187753e-06,
      "loss": 0.5603,
      "step": 9355
    },
    {
      "epoch": 0.7270749145166304,
      "grad_norm": 0.24217277765274048,
      "learning_rate": 6.364625427416849e-06,
      "loss": 0.1829,
      "step": 9356
    },
    {
      "epoch": 0.7271526266708113,
      "grad_norm": 0.22848063707351685,
      "learning_rate": 6.3642368666459445e-06,
      "loss": 0.12,
      "step": 9357
    },
    {
      "epoch": 0.7272303388249922,
      "grad_norm": 0.07818193733692169,
      "learning_rate": 6.3638483058750386e-06,
      "loss": 0.0094,
      "step": 9358
    },
    {
      "epoch": 0.7273080509791732,
      "grad_norm": 0.19276222586631775,
      "learning_rate": 6.363459745104134e-06,
      "loss": 0.0574,
      "step": 9359
    },
    {
      "epoch": 0.727385763133354,
      "grad_norm": 0.3999217748641968,
      "learning_rate": 6.36307118433323e-06,
      "loss": 0.1352,
      "step": 9360
    },
    {
      "epoch": 0.727463475287535,
      "grad_norm": 0.774151086807251,
      "learning_rate": 6.362682623562325e-06,
      "loss": 0.6085,
      "step": 9361
    },
    {
      "epoch": 0.7275411874417159,
      "grad_norm": 0.22940295934677124,
      "learning_rate": 6.362294062791421e-06,
      "loss": 0.1059,
      "step": 9362
    },
    {
      "epoch": 0.7276188995958968,
      "grad_norm": 0.6181452870368958,
      "learning_rate": 6.361905502020517e-06,
      "loss": 0.3676,
      "step": 9363
    },
    {
      "epoch": 0.7276966117500777,
      "grad_norm": 0.4341946840286255,
      "learning_rate": 6.3615169412496125e-06,
      "loss": 0.1878,
      "step": 9364
    },
    {
      "epoch": 0.7277743239042587,
      "grad_norm": 0.2099849283695221,
      "learning_rate": 6.3611283804787074e-06,
      "loss": 0.0665,
      "step": 9365
    },
    {
      "epoch": 0.7278520360584395,
      "grad_norm": 0.2820607125759125,
      "learning_rate": 6.360739819707803e-06,
      "loss": 0.0679,
      "step": 9366
    },
    {
      "epoch": 0.7279297482126205,
      "grad_norm": 0.25523507595062256,
      "learning_rate": 6.360351258936899e-06,
      "loss": 0.1125,
      "step": 9367
    },
    {
      "epoch": 0.7280074603668014,
      "grad_norm": 0.590411365032196,
      "learning_rate": 6.359962698165993e-06,
      "loss": 0.4729,
      "step": 9368
    },
    {
      "epoch": 0.7280851725209823,
      "grad_norm": 0.166794091463089,
      "learning_rate": 6.359574137395089e-06,
      "loss": 0.0647,
      "step": 9369
    },
    {
      "epoch": 0.7281628846751632,
      "grad_norm": 0.3001183271408081,
      "learning_rate": 6.359185576624185e-06,
      "loss": 0.225,
      "step": 9370
    },
    {
      "epoch": 0.7282405968293441,
      "grad_norm": 0.31755638122558594,
      "learning_rate": 6.35879701585328e-06,
      "loss": 0.4351,
      "step": 9371
    },
    {
      "epoch": 0.728318308983525,
      "grad_norm": 0.2682448923587799,
      "learning_rate": 6.3584084550823755e-06,
      "loss": 0.0976,
      "step": 9372
    },
    {
      "epoch": 0.728396021137706,
      "grad_norm": 0.3442012369632721,
      "learning_rate": 6.358019894311471e-06,
      "loss": 0.1584,
      "step": 9373
    },
    {
      "epoch": 0.7284737332918868,
      "grad_norm": 0.08130670338869095,
      "learning_rate": 6.357631333540566e-06,
      "loss": 0.0146,
      "step": 9374
    },
    {
      "epoch": 0.7285514454460678,
      "grad_norm": 0.11580844223499298,
      "learning_rate": 6.357242772769662e-06,
      "loss": 0.0295,
      "step": 9375
    },
    {
      "epoch": 0.7286291576002487,
      "grad_norm": 0.30312177538871765,
      "learning_rate": 6.356854211998758e-06,
      "loss": 0.0562,
      "step": 9376
    },
    {
      "epoch": 0.7287068697544296,
      "grad_norm": 0.34931260347366333,
      "learning_rate": 6.356465651227852e-06,
      "loss": 0.1961,
      "step": 9377
    },
    {
      "epoch": 0.7287845819086105,
      "grad_norm": 0.3952127695083618,
      "learning_rate": 6.356077090456948e-06,
      "loss": 0.104,
      "step": 9378
    },
    {
      "epoch": 0.7288622940627915,
      "grad_norm": 0.3261202573776245,
      "learning_rate": 6.3556885296860435e-06,
      "loss": 0.1745,
      "step": 9379
    },
    {
      "epoch": 0.7289400062169723,
      "grad_norm": 0.22495342791080475,
      "learning_rate": 6.3552999689151385e-06,
      "loss": 0.0293,
      "step": 9380
    },
    {
      "epoch": 0.7290177183711533,
      "grad_norm": 0.42815470695495605,
      "learning_rate": 6.354911408144234e-06,
      "loss": 0.2772,
      "step": 9381
    },
    {
      "epoch": 0.7290954305253342,
      "grad_norm": 0.17754366993904114,
      "learning_rate": 6.35452284737333e-06,
      "loss": 0.0487,
      "step": 9382
    },
    {
      "epoch": 0.729173142679515,
      "grad_norm": 0.1889573484659195,
      "learning_rate": 6.354134286602425e-06,
      "loss": 0.0884,
      "step": 9383
    },
    {
      "epoch": 0.729250854833696,
      "grad_norm": 0.24418996274471283,
      "learning_rate": 6.353745725831521e-06,
      "loss": 0.1567,
      "step": 9384
    },
    {
      "epoch": 0.729328566987877,
      "grad_norm": 0.6099909543991089,
      "learning_rate": 6.353357165060617e-06,
      "loss": 0.253,
      "step": 9385
    },
    {
      "epoch": 0.7294062791420578,
      "grad_norm": 0.15461832284927368,
      "learning_rate": 6.352968604289711e-06,
      "loss": 0.0554,
      "step": 9386
    },
    {
      "epoch": 0.7294839912962388,
      "grad_norm": 0.2118372619152069,
      "learning_rate": 6.3525800435188065e-06,
      "loss": 0.025,
      "step": 9387
    },
    {
      "epoch": 0.7295617034504196,
      "grad_norm": 0.23096351325511932,
      "learning_rate": 6.352191482747902e-06,
      "loss": 0.0597,
      "step": 9388
    },
    {
      "epoch": 0.7296394156046005,
      "grad_norm": 0.4853539764881134,
      "learning_rate": 6.351802921976997e-06,
      "loss": 0.3885,
      "step": 9389
    },
    {
      "epoch": 0.7297171277587815,
      "grad_norm": 0.21267354488372803,
      "learning_rate": 6.351414361206093e-06,
      "loss": 0.0705,
      "step": 9390
    },
    {
      "epoch": 0.7297948399129623,
      "grad_norm": 0.8507888317108154,
      "learning_rate": 6.351025800435189e-06,
      "loss": 0.5771,
      "step": 9391
    },
    {
      "epoch": 0.7298725520671433,
      "grad_norm": 0.21779395639896393,
      "learning_rate": 6.350637239664284e-06,
      "loss": 0.0698,
      "step": 9392
    },
    {
      "epoch": 0.7299502642213243,
      "grad_norm": 0.43537697196006775,
      "learning_rate": 6.35024867889338e-06,
      "loss": 0.2196,
      "step": 9393
    },
    {
      "epoch": 0.7300279763755051,
      "grad_norm": 0.4887353181838989,
      "learning_rate": 6.349860118122475e-06,
      "loss": 0.1482,
      "step": 9394
    },
    {
      "epoch": 0.730105688529686,
      "grad_norm": 0.7444263696670532,
      "learning_rate": 6.349471557351571e-06,
      "loss": 1.1195,
      "step": 9395
    },
    {
      "epoch": 0.730183400683867,
      "grad_norm": 0.35288766026496887,
      "learning_rate": 6.349082996580665e-06,
      "loss": 0.3729,
      "step": 9396
    },
    {
      "epoch": 0.7302611128380478,
      "grad_norm": 0.36010104417800903,
      "learning_rate": 6.348694435809761e-06,
      "loss": 0.0271,
      "step": 9397
    },
    {
      "epoch": 0.7303388249922288,
      "grad_norm": 0.585501492023468,
      "learning_rate": 6.348305875038857e-06,
      "loss": 0.524,
      "step": 9398
    },
    {
      "epoch": 0.7304165371464098,
      "grad_norm": 0.6823042035102844,
      "learning_rate": 6.347917314267952e-06,
      "loss": 0.6492,
      "step": 9399
    },
    {
      "epoch": 0.7304942493005906,
      "grad_norm": 0.6030614376068115,
      "learning_rate": 6.347528753497048e-06,
      "loss": 0.263,
      "step": 9400
    },
    {
      "epoch": 0.7305719614547715,
      "grad_norm": 0.8098104596138,
      "learning_rate": 6.3471401927261434e-06,
      "loss": 0.4316,
      "step": 9401
    },
    {
      "epoch": 0.7306496736089524,
      "grad_norm": 0.20345932245254517,
      "learning_rate": 6.346751631955238e-06,
      "loss": 0.0441,
      "step": 9402
    },
    {
      "epoch": 0.7307273857631333,
      "grad_norm": 0.06834468990564346,
      "learning_rate": 6.346363071184334e-06,
      "loss": 0.0189,
      "step": 9403
    },
    {
      "epoch": 0.7308050979173143,
      "grad_norm": 1.3118137121200562,
      "learning_rate": 6.34597451041343e-06,
      "loss": 0.5913,
      "step": 9404
    },
    {
      "epoch": 0.7308828100714951,
      "grad_norm": 0.27688655257225037,
      "learning_rate": 6.345585949642524e-06,
      "loss": 0.1834,
      "step": 9405
    },
    {
      "epoch": 0.7309605222256761,
      "grad_norm": 0.16690629720687866,
      "learning_rate": 6.34519738887162e-06,
      "loss": 0.0456,
      "step": 9406
    },
    {
      "epoch": 0.731038234379857,
      "grad_norm": 0.1977728009223938,
      "learning_rate": 6.344808828100716e-06,
      "loss": 0.0527,
      "step": 9407
    },
    {
      "epoch": 0.7311159465340379,
      "grad_norm": 0.3135935366153717,
      "learning_rate": 6.344420267329811e-06,
      "loss": 0.1628,
      "step": 9408
    },
    {
      "epoch": 0.7311936586882188,
      "grad_norm": 0.5826968550682068,
      "learning_rate": 6.344031706558906e-06,
      "loss": 0.1597,
      "step": 9409
    },
    {
      "epoch": 0.7312713708423998,
      "grad_norm": 0.09834003448486328,
      "learning_rate": 6.343643145788002e-06,
      "loss": 0.0149,
      "step": 9410
    },
    {
      "epoch": 0.7313490829965806,
      "grad_norm": 0.12852321565151215,
      "learning_rate": 6.343254585017097e-06,
      "loss": 0.0484,
      "step": 9411
    },
    {
      "epoch": 0.7314267951507616,
      "grad_norm": 0.29755207896232605,
      "learning_rate": 6.342866024246193e-06,
      "loss": 0.0515,
      "step": 9412
    },
    {
      "epoch": 0.7315045073049425,
      "grad_norm": 0.20423762500286102,
      "learning_rate": 6.342477463475289e-06,
      "loss": 0.0485,
      "step": 9413
    },
    {
      "epoch": 0.7315822194591234,
      "grad_norm": 0.2814704477787018,
      "learning_rate": 6.342088902704383e-06,
      "loss": 0.2044,
      "step": 9414
    },
    {
      "epoch": 0.7316599316133043,
      "grad_norm": 0.2741870582103729,
      "learning_rate": 6.341700341933479e-06,
      "loss": 0.0522,
      "step": 9415
    },
    {
      "epoch": 0.7317376437674852,
      "grad_norm": 0.750478208065033,
      "learning_rate": 6.3413117811625744e-06,
      "loss": 0.4638,
      "step": 9416
    },
    {
      "epoch": 0.7318153559216661,
      "grad_norm": 0.2629527151584625,
      "learning_rate": 6.340923220391669e-06,
      "loss": 0.2058,
      "step": 9417
    },
    {
      "epoch": 0.7318930680758471,
      "grad_norm": 0.3929104208946228,
      "learning_rate": 6.340534659620765e-06,
      "loss": 0.1735,
      "step": 9418
    },
    {
      "epoch": 0.7319707802300279,
      "grad_norm": 0.7434266209602356,
      "learning_rate": 6.340146098849861e-06,
      "loss": 0.495,
      "step": 9419
    },
    {
      "epoch": 0.7320484923842089,
      "grad_norm": 1.7423292398452759,
      "learning_rate": 6.339757538078956e-06,
      "loss": 0.4082,
      "step": 9420
    },
    {
      "epoch": 0.7321262045383898,
      "grad_norm": 0.38803166151046753,
      "learning_rate": 6.339368977308052e-06,
      "loss": 0.2282,
      "step": 9421
    },
    {
      "epoch": 0.7322039166925707,
      "grad_norm": 0.21096189320087433,
      "learning_rate": 6.3389804165371475e-06,
      "loss": 0.1562,
      "step": 9422
    },
    {
      "epoch": 0.7322816288467516,
      "grad_norm": 0.09059617668390274,
      "learning_rate": 6.338591855766242e-06,
      "loss": 0.0479,
      "step": 9423
    },
    {
      "epoch": 0.7323593410009326,
      "grad_norm": 0.39347824454307556,
      "learning_rate": 6.3382032949953374e-06,
      "loss": 0.3674,
      "step": 9424
    },
    {
      "epoch": 0.7324370531551134,
      "grad_norm": 0.16958896815776825,
      "learning_rate": 6.337814734224433e-06,
      "loss": 0.0325,
      "step": 9425
    },
    {
      "epoch": 0.7325147653092944,
      "grad_norm": 0.20002028346061707,
      "learning_rate": 6.337426173453529e-06,
      "loss": 0.0556,
      "step": 9426
    },
    {
      "epoch": 0.7325924774634753,
      "grad_norm": 0.4841836392879486,
      "learning_rate": 6.337037612682624e-06,
      "loss": 0.2326,
      "step": 9427
    },
    {
      "epoch": 0.7326701896176562,
      "grad_norm": 0.1132848784327507,
      "learning_rate": 6.33664905191172e-06,
      "loss": 0.0391,
      "step": 9428
    },
    {
      "epoch": 0.7327479017718371,
      "grad_norm": 0.32205304503440857,
      "learning_rate": 6.3362604911408156e-06,
      "loss": 0.1162,
      "step": 9429
    },
    {
      "epoch": 0.7328256139260181,
      "grad_norm": 0.07038603723049164,
      "learning_rate": 6.3358719303699105e-06,
      "loss": 0.0114,
      "step": 9430
    },
    {
      "epoch": 0.7329033260801989,
      "grad_norm": 0.5939540266990662,
      "learning_rate": 6.335483369599006e-06,
      "loss": 0.1463,
      "step": 9431
    },
    {
      "epoch": 0.7329810382343799,
      "grad_norm": 0.700639545917511,
      "learning_rate": 6.335094808828101e-06,
      "loss": 0.4074,
      "step": 9432
    },
    {
      "epoch": 0.7330587503885607,
      "grad_norm": 0.5623716711997986,
      "learning_rate": 6.334706248057196e-06,
      "loss": 0.2851,
      "step": 9433
    },
    {
      "epoch": 0.7331364625427417,
      "grad_norm": 0.3140455484390259,
      "learning_rate": 6.334317687286292e-06,
      "loss": 0.1343,
      "step": 9434
    },
    {
      "epoch": 0.7332141746969226,
      "grad_norm": 0.44951942563056946,
      "learning_rate": 6.333929126515388e-06,
      "loss": 0.2393,
      "step": 9435
    },
    {
      "epoch": 0.7332918868511035,
      "grad_norm": 0.3167326748371124,
      "learning_rate": 6.333540565744483e-06,
      "loss": 0.1598,
      "step": 9436
    },
    {
      "epoch": 0.7333695990052844,
      "grad_norm": 0.4634277820587158,
      "learning_rate": 6.3331520049735786e-06,
      "loss": 0.1559,
      "step": 9437
    },
    {
      "epoch": 0.7334473111594654,
      "grad_norm": 0.9474496245384216,
      "learning_rate": 6.332763444202674e-06,
      "loss": 1.1654,
      "step": 9438
    },
    {
      "epoch": 0.7335250233136462,
      "grad_norm": 0.5872187614440918,
      "learning_rate": 6.3323748834317685e-06,
      "loss": 0.2062,
      "step": 9439
    },
    {
      "epoch": 0.7336027354678272,
      "grad_norm": 0.23584584891796112,
      "learning_rate": 6.331986322660864e-06,
      "loss": 0.1642,
      "step": 9440
    },
    {
      "epoch": 0.7336804476220081,
      "grad_norm": 0.4980463981628418,
      "learning_rate": 6.33159776188996e-06,
      "loss": 0.1561,
      "step": 9441
    },
    {
      "epoch": 0.733758159776189,
      "grad_norm": 0.11676077544689178,
      "learning_rate": 6.331209201119055e-06,
      "loss": 0.0064,
      "step": 9442
    },
    {
      "epoch": 0.7338358719303699,
      "grad_norm": 0.3561374843120575,
      "learning_rate": 6.330820640348151e-06,
      "loss": 0.1664,
      "step": 9443
    },
    {
      "epoch": 0.7339135840845509,
      "grad_norm": 0.6704502701759338,
      "learning_rate": 6.330432079577247e-06,
      "loss": 0.9394,
      "step": 9444
    },
    {
      "epoch": 0.7339912962387317,
      "grad_norm": 0.4188297688961029,
      "learning_rate": 6.3300435188063415e-06,
      "loss": 0.3795,
      "step": 9445
    },
    {
      "epoch": 0.7340690083929127,
      "grad_norm": 0.1692536324262619,
      "learning_rate": 6.329654958035437e-06,
      "loss": 0.1126,
      "step": 9446
    },
    {
      "epoch": 0.7341467205470935,
      "grad_norm": 0.07291290163993835,
      "learning_rate": 6.329266397264533e-06,
      "loss": 0.02,
      "step": 9447
    },
    {
      "epoch": 0.7342244327012745,
      "grad_norm": 0.21819841861724854,
      "learning_rate": 6.328877836493627e-06,
      "loss": 0.1623,
      "step": 9448
    },
    {
      "epoch": 0.7343021448554554,
      "grad_norm": 1.2235097885131836,
      "learning_rate": 6.328489275722723e-06,
      "loss": 0.6819,
      "step": 9449
    },
    {
      "epoch": 0.7343798570096363,
      "grad_norm": 0.5098469257354736,
      "learning_rate": 6.328100714951819e-06,
      "loss": 0.3068,
      "step": 9450
    },
    {
      "epoch": 0.7344575691638172,
      "grad_norm": 0.21376456320285797,
      "learning_rate": 6.327712154180914e-06,
      "loss": 0.1115,
      "step": 9451
    },
    {
      "epoch": 0.7345352813179982,
      "grad_norm": 0.6218850016593933,
      "learning_rate": 6.32732359341001e-06,
      "loss": 0.1563,
      "step": 9452
    },
    {
      "epoch": 0.734612993472179,
      "grad_norm": 1.1035025119781494,
      "learning_rate": 6.326935032639105e-06,
      "loss": 0.3471,
      "step": 9453
    },
    {
      "epoch": 0.73469070562636,
      "grad_norm": 0.413622111082077,
      "learning_rate": 6.326546471868201e-06,
      "loss": 0.1179,
      "step": 9454
    },
    {
      "epoch": 0.7347684177805409,
      "grad_norm": 0.12897999584674835,
      "learning_rate": 6.326157911097296e-06,
      "loss": 0.0264,
      "step": 9455
    },
    {
      "epoch": 0.7348461299347218,
      "grad_norm": 0.31889069080352783,
      "learning_rate": 6.325769350326392e-06,
      "loss": 0.109,
      "step": 9456
    },
    {
      "epoch": 0.7349238420889027,
      "grad_norm": 0.09997084736824036,
      "learning_rate": 6.325380789555488e-06,
      "loss": 0.0497,
      "step": 9457
    },
    {
      "epoch": 0.7350015542430837,
      "grad_norm": 0.20196844637393951,
      "learning_rate": 6.324992228784582e-06,
      "loss": 0.0449,
      "step": 9458
    },
    {
      "epoch": 0.7350792663972645,
      "grad_norm": 0.4055446982383728,
      "learning_rate": 6.324603668013678e-06,
      "loss": 0.1548,
      "step": 9459
    },
    {
      "epoch": 0.7351569785514455,
      "grad_norm": 0.6454036831855774,
      "learning_rate": 6.324215107242773e-06,
      "loss": 0.2692,
      "step": 9460
    },
    {
      "epoch": 0.7352346907056264,
      "grad_norm": 0.8605245351791382,
      "learning_rate": 6.323826546471868e-06,
      "loss": 0.4549,
      "step": 9461
    },
    {
      "epoch": 0.7353124028598073,
      "grad_norm": 0.16795656085014343,
      "learning_rate": 6.323437985700964e-06,
      "loss": 0.0586,
      "step": 9462
    },
    {
      "epoch": 0.7353901150139882,
      "grad_norm": 0.3949059844017029,
      "learning_rate": 6.32304942493006e-06,
      "loss": 0.2102,
      "step": 9463
    },
    {
      "epoch": 0.735467827168169,
      "grad_norm": 1.4179143905639648,
      "learning_rate": 6.322660864159155e-06,
      "loss": 0.167,
      "step": 9464
    },
    {
      "epoch": 0.73554553932235,
      "grad_norm": 1.026891827583313,
      "learning_rate": 6.322272303388251e-06,
      "loss": 0.6979,
      "step": 9465
    },
    {
      "epoch": 0.735623251476531,
      "grad_norm": 0.32037192583084106,
      "learning_rate": 6.3218837426173465e-06,
      "loss": 0.144,
      "step": 9466
    },
    {
      "epoch": 0.7357009636307118,
      "grad_norm": 0.22931401431560516,
      "learning_rate": 6.321495181846441e-06,
      "loss": 0.0439,
      "step": 9467
    },
    {
      "epoch": 0.7357786757848928,
      "grad_norm": 0.9637518525123596,
      "learning_rate": 6.321106621075536e-06,
      "loss": 0.3346,
      "step": 9468
    },
    {
      "epoch": 0.7358563879390737,
      "grad_norm": 1.2755730152130127,
      "learning_rate": 6.320718060304632e-06,
      "loss": 0.3663,
      "step": 9469
    },
    {
      "epoch": 0.7359341000932546,
      "grad_norm": 0.3919222950935364,
      "learning_rate": 6.320329499533727e-06,
      "loss": 0.1194,
      "step": 9470
    },
    {
      "epoch": 0.7360118122474355,
      "grad_norm": 0.1606338620185852,
      "learning_rate": 6.319940938762823e-06,
      "loss": 0.0156,
      "step": 9471
    },
    {
      "epoch": 0.7360895244016165,
      "grad_norm": 0.5992616415023804,
      "learning_rate": 6.319552377991919e-06,
      "loss": 0.5811,
      "step": 9472
    },
    {
      "epoch": 0.7361672365557973,
      "grad_norm": 0.8167959451675415,
      "learning_rate": 6.319163817221014e-06,
      "loss": 0.4979,
      "step": 9473
    },
    {
      "epoch": 0.7362449487099783,
      "grad_norm": 0.6413429379463196,
      "learning_rate": 6.3187752564501095e-06,
      "loss": 0.1111,
      "step": 9474
    },
    {
      "epoch": 0.7363226608641592,
      "grad_norm": 0.5162666440010071,
      "learning_rate": 6.318386695679205e-06,
      "loss": 0.3138,
      "step": 9475
    },
    {
      "epoch": 0.73640037301834,
      "grad_norm": 0.38827845454216003,
      "learning_rate": 6.317998134908299e-06,
      "loss": 0.1087,
      "step": 9476
    },
    {
      "epoch": 0.736478085172521,
      "grad_norm": 0.28324899077415466,
      "learning_rate": 6.317609574137395e-06,
      "loss": 0.0911,
      "step": 9477
    },
    {
      "epoch": 0.7365557973267018,
      "grad_norm": 0.3034546375274658,
      "learning_rate": 6.317221013366491e-06,
      "loss": 0.1322,
      "step": 9478
    },
    {
      "epoch": 0.7366335094808828,
      "grad_norm": 0.23170873522758484,
      "learning_rate": 6.316832452595586e-06,
      "loss": 0.0496,
      "step": 9479
    },
    {
      "epoch": 0.7367112216350638,
      "grad_norm": 0.42674365639686584,
      "learning_rate": 6.316443891824682e-06,
      "loss": 0.1313,
      "step": 9480
    },
    {
      "epoch": 0.7367889337892446,
      "grad_norm": 0.497383177280426,
      "learning_rate": 6.3160553310537775e-06,
      "loss": 0.0604,
      "step": 9481
    },
    {
      "epoch": 0.7368666459434255,
      "grad_norm": 0.8107370138168335,
      "learning_rate": 6.3156667702828725e-06,
      "loss": 0.1398,
      "step": 9482
    },
    {
      "epoch": 0.7369443580976065,
      "grad_norm": 0.13483691215515137,
      "learning_rate": 6.315278209511968e-06,
      "loss": 0.0263,
      "step": 9483
    },
    {
      "epoch": 0.7370220702517873,
      "grad_norm": 0.21870861947536469,
      "learning_rate": 6.314889648741064e-06,
      "loss": 0.0628,
      "step": 9484
    },
    {
      "epoch": 0.7370997824059683,
      "grad_norm": 0.6018611192703247,
      "learning_rate": 6.31450108797016e-06,
      "loss": 0.3024,
      "step": 9485
    },
    {
      "epoch": 0.7371774945601492,
      "grad_norm": 0.4531461298465729,
      "learning_rate": 6.314112527199254e-06,
      "loss": 0.1628,
      "step": 9486
    },
    {
      "epoch": 0.7372552067143301,
      "grad_norm": 0.8167621493339539,
      "learning_rate": 6.31372396642835e-06,
      "loss": 0.4476,
      "step": 9487
    },
    {
      "epoch": 0.737332918868511,
      "grad_norm": 0.7271184325218201,
      "learning_rate": 6.3133354056574456e-06,
      "loss": 0.7306,
      "step": 9488
    },
    {
      "epoch": 0.737410631022692,
      "grad_norm": 0.9229701161384583,
      "learning_rate": 6.3129468448865405e-06,
      "loss": 0.1241,
      "step": 9489
    },
    {
      "epoch": 0.7374883431768728,
      "grad_norm": 1.2124640941619873,
      "learning_rate": 6.312558284115636e-06,
      "loss": 0.6064,
      "step": 9490
    },
    {
      "epoch": 0.7375660553310538,
      "grad_norm": 0.26516416668891907,
      "learning_rate": 6.312169723344732e-06,
      "loss": 0.061,
      "step": 9491
    },
    {
      "epoch": 0.7376437674852346,
      "grad_norm": 0.43550050258636475,
      "learning_rate": 6.311781162573827e-06,
      "loss": 0.3404,
      "step": 9492
    },
    {
      "epoch": 0.7377214796394156,
      "grad_norm": 0.45325276255607605,
      "learning_rate": 6.311392601802923e-06,
      "loss": 0.6408,
      "step": 9493
    },
    {
      "epoch": 0.7377991917935965,
      "grad_norm": 0.44354483485221863,
      "learning_rate": 6.311004041032019e-06,
      "loss": 0.1328,
      "step": 9494
    },
    {
      "epoch": 0.7378769039477774,
      "grad_norm": 0.6028764247894287,
      "learning_rate": 6.310615480261113e-06,
      "loss": 0.3562,
      "step": 9495
    },
    {
      "epoch": 0.7379546161019583,
      "grad_norm": 0.2780090868473053,
      "learning_rate": 6.3102269194902085e-06,
      "loss": 0.115,
      "step": 9496
    },
    {
      "epoch": 0.7380323282561393,
      "grad_norm": 0.4635671079158783,
      "learning_rate": 6.309838358719304e-06,
      "loss": 0.2042,
      "step": 9497
    },
    {
      "epoch": 0.7381100404103201,
      "grad_norm": 0.2946094572544098,
      "learning_rate": 6.309449797948399e-06,
      "loss": 0.0911,
      "step": 9498
    },
    {
      "epoch": 0.7381877525645011,
      "grad_norm": 0.23520591855049133,
      "learning_rate": 6.309061237177495e-06,
      "loss": 0.0852,
      "step": 9499
    },
    {
      "epoch": 0.738265464718682,
      "grad_norm": 0.2035246193408966,
      "learning_rate": 6.308672676406591e-06,
      "loss": 0.1132,
      "step": 9500
    },
    {
      "epoch": 0.7383431768728629,
      "grad_norm": 0.24167537689208984,
      "learning_rate": 6.308284115635686e-06,
      "loss": 0.0897,
      "step": 9501
    },
    {
      "epoch": 0.7384208890270438,
      "grad_norm": 0.2675844430923462,
      "learning_rate": 6.307895554864782e-06,
      "loss": 0.1462,
      "step": 9502
    },
    {
      "epoch": 0.7384986011812248,
      "grad_norm": 0.19523227214813232,
      "learning_rate": 6.3075069940938774e-06,
      "loss": 0.0877,
      "step": 9503
    },
    {
      "epoch": 0.7385763133354056,
      "grad_norm": 0.06130805239081383,
      "learning_rate": 6.3071184333229715e-06,
      "loss": 0.0193,
      "step": 9504
    },
    {
      "epoch": 0.7386540254895866,
      "grad_norm": 0.21979175508022308,
      "learning_rate": 6.306729872552067e-06,
      "loss": 0.2013,
      "step": 9505
    },
    {
      "epoch": 0.7387317376437675,
      "grad_norm": 0.29052528738975525,
      "learning_rate": 6.306341311781163e-06,
      "loss": 0.1321,
      "step": 9506
    },
    {
      "epoch": 0.7388094497979484,
      "grad_norm": 0.8359785079956055,
      "learning_rate": 6.305952751010258e-06,
      "loss": 0.4208,
      "step": 9507
    },
    {
      "epoch": 0.7388871619521293,
      "grad_norm": 0.2602595388889313,
      "learning_rate": 6.305564190239354e-06,
      "loss": 0.066,
      "step": 9508
    },
    {
      "epoch": 0.7389648741063102,
      "grad_norm": 0.05653649568557739,
      "learning_rate": 6.30517562946845e-06,
      "loss": 0.0119,
      "step": 9509
    },
    {
      "epoch": 0.7390425862604911,
      "grad_norm": 0.11359487473964691,
      "learning_rate": 6.304787068697545e-06,
      "loss": 0.0771,
      "step": 9510
    },
    {
      "epoch": 0.7391202984146721,
      "grad_norm": 0.4206623435020447,
      "learning_rate": 6.30439850792664e-06,
      "loss": 0.2434,
      "step": 9511
    },
    {
      "epoch": 0.7391980105688529,
      "grad_norm": 0.5288529992103577,
      "learning_rate": 6.304009947155736e-06,
      "loss": 0.1814,
      "step": 9512
    },
    {
      "epoch": 0.7392757227230339,
      "grad_norm": 0.05991778522729874,
      "learning_rate": 6.30362138638483e-06,
      "loss": 0.0064,
      "step": 9513
    },
    {
      "epoch": 0.7393534348772148,
      "grad_norm": 0.4864424765110016,
      "learning_rate": 6.303232825613926e-06,
      "loss": 0.1922,
      "step": 9514
    },
    {
      "epoch": 0.7394311470313957,
      "grad_norm": 0.5781259536743164,
      "learning_rate": 6.302844264843022e-06,
      "loss": 0.4406,
      "step": 9515
    },
    {
      "epoch": 0.7395088591855766,
      "grad_norm": 0.1332097351551056,
      "learning_rate": 6.302455704072118e-06,
      "loss": 0.0238,
      "step": 9516
    },
    {
      "epoch": 0.7395865713397576,
      "grad_norm": 0.4004949927330017,
      "learning_rate": 6.302067143301213e-06,
      "loss": 0.2522,
      "step": 9517
    },
    {
      "epoch": 0.7396642834939384,
      "grad_norm": 1.028490662574768,
      "learning_rate": 6.3016785825303085e-06,
      "loss": 0.6657,
      "step": 9518
    },
    {
      "epoch": 0.7397419956481194,
      "grad_norm": 0.5541740655899048,
      "learning_rate": 6.301290021759404e-06,
      "loss": 0.3135,
      "step": 9519
    },
    {
      "epoch": 0.7398197078023003,
      "grad_norm": 0.6755937933921814,
      "learning_rate": 6.300901460988499e-06,
      "loss": 0.6762,
      "step": 9520
    },
    {
      "epoch": 0.7398974199564812,
      "grad_norm": 0.20696420967578888,
      "learning_rate": 6.300512900217595e-06,
      "loss": 0.0925,
      "step": 9521
    },
    {
      "epoch": 0.7399751321106621,
      "grad_norm": 0.16844645142555237,
      "learning_rate": 6.300124339446691e-06,
      "loss": 0.0651,
      "step": 9522
    },
    {
      "epoch": 0.740052844264843,
      "grad_norm": 0.22489449381828308,
      "learning_rate": 6.299735778675785e-06,
      "loss": 0.1256,
      "step": 9523
    },
    {
      "epoch": 0.7401305564190239,
      "grad_norm": 0.4335392415523529,
      "learning_rate": 6.299347217904881e-06,
      "loss": 0.2835,
      "step": 9524
    },
    {
      "epoch": 0.7402082685732049,
      "grad_norm": 0.38244593143463135,
      "learning_rate": 6.2989586571339765e-06,
      "loss": 0.2945,
      "step": 9525
    },
    {
      "epoch": 0.7402859807273857,
      "grad_norm": 0.16752280294895172,
      "learning_rate": 6.2985700963630714e-06,
      "loss": 0.0371,
      "step": 9526
    },
    {
      "epoch": 0.7403636928815667,
      "grad_norm": 0.33217015862464905,
      "learning_rate": 6.298181535592167e-06,
      "loss": 0.0553,
      "step": 9527
    },
    {
      "epoch": 0.7404414050357476,
      "grad_norm": 0.11890891194343567,
      "learning_rate": 6.297792974821263e-06,
      "loss": 0.0819,
      "step": 9528
    },
    {
      "epoch": 0.7405191171899285,
      "grad_norm": 0.8048269152641296,
      "learning_rate": 6.297404414050358e-06,
      "loss": 0.5108,
      "step": 9529
    },
    {
      "epoch": 0.7405968293441094,
      "grad_norm": 0.1526738405227661,
      "learning_rate": 6.297015853279454e-06,
      "loss": 0.0328,
      "step": 9530
    },
    {
      "epoch": 0.7406745414982904,
      "grad_norm": 0.43793198466300964,
      "learning_rate": 6.2966272925085496e-06,
      "loss": 0.1113,
      "step": 9531
    },
    {
      "epoch": 0.7407522536524712,
      "grad_norm": 0.33657869696617126,
      "learning_rate": 6.296238731737644e-06,
      "loss": 0.1462,
      "step": 9532
    },
    {
      "epoch": 0.7408299658066522,
      "grad_norm": 1.6299866437911987,
      "learning_rate": 6.2958501709667395e-06,
      "loss": 0.7206,
      "step": 9533
    },
    {
      "epoch": 0.7409076779608331,
      "grad_norm": 0.4949595332145691,
      "learning_rate": 6.295461610195835e-06,
      "loss": 0.2544,
      "step": 9534
    },
    {
      "epoch": 0.740985390115014,
      "grad_norm": 0.09490900486707687,
      "learning_rate": 6.29507304942493e-06,
      "loss": 0.0121,
      "step": 9535
    },
    {
      "epoch": 0.7410631022691949,
      "grad_norm": 0.7983739972114563,
      "learning_rate": 6.294684488654026e-06,
      "loss": 0.4182,
      "step": 9536
    },
    {
      "epoch": 0.7411408144233759,
      "grad_norm": 0.2293778657913208,
      "learning_rate": 6.294295927883122e-06,
      "loss": 0.088,
      "step": 9537
    },
    {
      "epoch": 0.7412185265775567,
      "grad_norm": 0.2575339376926422,
      "learning_rate": 6.293907367112217e-06,
      "loss": 0.0682,
      "step": 9538
    },
    {
      "epoch": 0.7412962387317377,
      "grad_norm": 0.28153195977211,
      "learning_rate": 6.2935188063413126e-06,
      "loss": 0.1665,
      "step": 9539
    },
    {
      "epoch": 0.7413739508859185,
      "grad_norm": 0.295634001493454,
      "learning_rate": 6.293130245570408e-06,
      "loss": 0.1244,
      "step": 9540
    },
    {
      "epoch": 0.7414516630400995,
      "grad_norm": 0.15302234888076782,
      "learning_rate": 6.2927416847995025e-06,
      "loss": 0.0392,
      "step": 9541
    },
    {
      "epoch": 0.7415293751942804,
      "grad_norm": 0.592488706111908,
      "learning_rate": 6.292353124028598e-06,
      "loss": 0.541,
      "step": 9542
    },
    {
      "epoch": 0.7416070873484613,
      "grad_norm": 0.3124680519104004,
      "learning_rate": 6.291964563257694e-06,
      "loss": 0.1228,
      "step": 9543
    },
    {
      "epoch": 0.7416847995026422,
      "grad_norm": 0.1253156065940857,
      "learning_rate": 6.291576002486789e-06,
      "loss": 0.04,
      "step": 9544
    },
    {
      "epoch": 0.7417625116568232,
      "grad_norm": 0.31308993697166443,
      "learning_rate": 6.291187441715885e-06,
      "loss": 0.2028,
      "step": 9545
    },
    {
      "epoch": 0.741840223811004,
      "grad_norm": 0.9180815815925598,
      "learning_rate": 6.290798880944981e-06,
      "loss": 0.2626,
      "step": 9546
    },
    {
      "epoch": 0.741917935965185,
      "grad_norm": 0.8454011082649231,
      "learning_rate": 6.290410320174076e-06,
      "loss": 0.8885,
      "step": 9547
    },
    {
      "epoch": 0.7419956481193659,
      "grad_norm": 0.6387682557106018,
      "learning_rate": 6.290021759403171e-06,
      "loss": 0.6432,
      "step": 9548
    },
    {
      "epoch": 0.7420733602735468,
      "grad_norm": 0.5267034769058228,
      "learning_rate": 6.289633198632267e-06,
      "loss": 0.3953,
      "step": 9549
    },
    {
      "epoch": 0.7421510724277277,
      "grad_norm": 0.6602770686149597,
      "learning_rate": 6.289244637861363e-06,
      "loss": 0.3503,
      "step": 9550
    },
    {
      "epoch": 0.7422287845819087,
      "grad_norm": 0.6077340841293335,
      "learning_rate": 6.288856077090457e-06,
      "loss": 0.1496,
      "step": 9551
    },
    {
      "epoch": 0.7423064967360895,
      "grad_norm": 0.2694939374923706,
      "learning_rate": 6.288467516319553e-06,
      "loss": 0.1389,
      "step": 9552
    },
    {
      "epoch": 0.7423842088902705,
      "grad_norm": 0.514105498790741,
      "learning_rate": 6.288078955548649e-06,
      "loss": 0.2734,
      "step": 9553
    },
    {
      "epoch": 0.7424619210444513,
      "grad_norm": 0.3305545449256897,
      "learning_rate": 6.287690394777744e-06,
      "loss": 0.093,
      "step": 9554
    },
    {
      "epoch": 0.7425396331986323,
      "grad_norm": 0.48475635051727295,
      "learning_rate": 6.287301834006839e-06,
      "loss": 0.2935,
      "step": 9555
    },
    {
      "epoch": 0.7426173453528132,
      "grad_norm": 0.07230403274297714,
      "learning_rate": 6.286913273235935e-06,
      "loss": 0.0142,
      "step": 9556
    },
    {
      "epoch": 0.742695057506994,
      "grad_norm": 0.5113726854324341,
      "learning_rate": 6.28652471246503e-06,
      "loss": 0.1363,
      "step": 9557
    },
    {
      "epoch": 0.742772769661175,
      "grad_norm": 0.31895577907562256,
      "learning_rate": 6.286136151694125e-06,
      "loss": 0.131,
      "step": 9558
    },
    {
      "epoch": 0.742850481815356,
      "grad_norm": 0.3267918825149536,
      "learning_rate": 6.285747590923221e-06,
      "loss": 0.1504,
      "step": 9559
    },
    {
      "epoch": 0.7429281939695368,
      "grad_norm": 0.17361941933631897,
      "learning_rate": 6.285359030152316e-06,
      "loss": 0.0313,
      "step": 9560
    },
    {
      "epoch": 0.7430059061237178,
      "grad_norm": 0.552908182144165,
      "learning_rate": 6.284970469381412e-06,
      "loss": 0.2131,
      "step": 9561
    },
    {
      "epoch": 0.7430836182778987,
      "grad_norm": 0.36734989285469055,
      "learning_rate": 6.284581908610507e-06,
      "loss": 0.1535,
      "step": 9562
    },
    {
      "epoch": 0.7431613304320795,
      "grad_norm": 0.16976840794086456,
      "learning_rate": 6.284193347839602e-06,
      "loss": 0.0806,
      "step": 9563
    },
    {
      "epoch": 0.7432390425862605,
      "grad_norm": 0.42125511169433594,
      "learning_rate": 6.283804787068698e-06,
      "loss": 0.2993,
      "step": 9564
    },
    {
      "epoch": 0.7433167547404415,
      "grad_norm": 0.27952006459236145,
      "learning_rate": 6.283416226297794e-06,
      "loss": 0.0892,
      "step": 9565
    },
    {
      "epoch": 0.7433944668946223,
      "grad_norm": 0.37682434916496277,
      "learning_rate": 6.283027665526888e-06,
      "loss": 0.1389,
      "step": 9566
    },
    {
      "epoch": 0.7434721790488033,
      "grad_norm": 0.36140263080596924,
      "learning_rate": 6.282639104755984e-06,
      "loss": 0.0891,
      "step": 9567
    },
    {
      "epoch": 0.7435498912029841,
      "grad_norm": 0.36380040645599365,
      "learning_rate": 6.28225054398508e-06,
      "loss": 0.0992,
      "step": 9568
    },
    {
      "epoch": 0.743627603357165,
      "grad_norm": 0.3701314628124237,
      "learning_rate": 6.281861983214175e-06,
      "loss": 0.1653,
      "step": 9569
    },
    {
      "epoch": 0.743705315511346,
      "grad_norm": 0.21471205353736877,
      "learning_rate": 6.28147342244327e-06,
      "loss": 0.1044,
      "step": 9570
    },
    {
      "epoch": 0.7437830276655268,
      "grad_norm": 0.20784592628479004,
      "learning_rate": 6.281084861672366e-06,
      "loss": 0.1055,
      "step": 9571
    },
    {
      "epoch": 0.7438607398197078,
      "grad_norm": 0.13231027126312256,
      "learning_rate": 6.280696300901461e-06,
      "loss": 0.0461,
      "step": 9572
    },
    {
      "epoch": 0.7439384519738887,
      "grad_norm": 0.31512555480003357,
      "learning_rate": 6.280307740130557e-06,
      "loss": 0.1746,
      "step": 9573
    },
    {
      "epoch": 0.7440161641280696,
      "grad_norm": 0.1342865526676178,
      "learning_rate": 6.279919179359653e-06,
      "loss": 0.0331,
      "step": 9574
    },
    {
      "epoch": 0.7440938762822505,
      "grad_norm": 0.517657458782196,
      "learning_rate": 6.279530618588747e-06,
      "loss": 0.2906,
      "step": 9575
    },
    {
      "epoch": 0.7441715884364315,
      "grad_norm": 0.14938171207904816,
      "learning_rate": 6.279142057817843e-06,
      "loss": 0.0256,
      "step": 9576
    },
    {
      "epoch": 0.7442493005906123,
      "grad_norm": 0.17362380027770996,
      "learning_rate": 6.2787534970469384e-06,
      "loss": 0.0671,
      "step": 9577
    },
    {
      "epoch": 0.7443270127447933,
      "grad_norm": 0.4156543016433716,
      "learning_rate": 6.278364936276034e-06,
      "loss": 0.1391,
      "step": 9578
    },
    {
      "epoch": 0.7444047248989742,
      "grad_norm": 0.2140892893075943,
      "learning_rate": 6.277976375505129e-06,
      "loss": 0.0882,
      "step": 9579
    },
    {
      "epoch": 0.7444824370531551,
      "grad_norm": 0.47169026732444763,
      "learning_rate": 6.277587814734225e-06,
      "loss": 0.4798,
      "step": 9580
    },
    {
      "epoch": 0.744560149207336,
      "grad_norm": 0.7737600803375244,
      "learning_rate": 6.277199253963321e-06,
      "loss": 0.2723,
      "step": 9581
    },
    {
      "epoch": 0.744637861361517,
      "grad_norm": 0.17810359597206116,
      "learning_rate": 6.276810693192416e-06,
      "loss": 0.079,
      "step": 9582
    },
    {
      "epoch": 0.7447155735156978,
      "grad_norm": 0.6671358346939087,
      "learning_rate": 6.2764221324215115e-06,
      "loss": 0.2868,
      "step": 9583
    },
    {
      "epoch": 0.7447932856698788,
      "grad_norm": 0.30707865953445435,
      "learning_rate": 6.276033571650607e-06,
      "loss": 0.0844,
      "step": 9584
    },
    {
      "epoch": 0.7448709978240596,
      "grad_norm": 0.3363092541694641,
      "learning_rate": 6.2756450108797014e-06,
      "loss": 0.0621,
      "step": 9585
    },
    {
      "epoch": 0.7449487099782406,
      "grad_norm": 0.48418623208999634,
      "learning_rate": 6.275256450108797e-06,
      "loss": 0.0519,
      "step": 9586
    },
    {
      "epoch": 0.7450264221324215,
      "grad_norm": 0.15404680371284485,
      "learning_rate": 6.274867889337893e-06,
      "loss": 0.0597,
      "step": 9587
    },
    {
      "epoch": 0.7451041342866024,
      "grad_norm": 0.8359521627426147,
      "learning_rate": 6.274479328566988e-06,
      "loss": 0.6172,
      "step": 9588
    },
    {
      "epoch": 0.7451818464407833,
      "grad_norm": 0.27255427837371826,
      "learning_rate": 6.274090767796084e-06,
      "loss": 0.409,
      "step": 9589
    },
    {
      "epoch": 0.7452595585949643,
      "grad_norm": 0.5131583213806152,
      "learning_rate": 6.2737022070251796e-06,
      "loss": 0.1068,
      "step": 9590
    },
    {
      "epoch": 0.7453372707491451,
      "grad_norm": 0.7435267567634583,
      "learning_rate": 6.2733136462542745e-06,
      "loss": 0.1657,
      "step": 9591
    },
    {
      "epoch": 0.7454149829033261,
      "grad_norm": 0.47720664739608765,
      "learning_rate": 6.27292508548337e-06,
      "loss": 0.2491,
      "step": 9592
    },
    {
      "epoch": 0.745492695057507,
      "grad_norm": 0.08051855862140656,
      "learning_rate": 6.272536524712466e-06,
      "loss": 0.0473,
      "step": 9593
    },
    {
      "epoch": 0.7455704072116879,
      "grad_norm": 0.35320529341697693,
      "learning_rate": 6.27214796394156e-06,
      "loss": 0.1955,
      "step": 9594
    },
    {
      "epoch": 0.7456481193658688,
      "grad_norm": 0.608851969242096,
      "learning_rate": 6.271759403170656e-06,
      "loss": 0.3285,
      "step": 9595
    },
    {
      "epoch": 0.7457258315200498,
      "grad_norm": 0.6657785177230835,
      "learning_rate": 6.271370842399752e-06,
      "loss": 0.1376,
      "step": 9596
    },
    {
      "epoch": 0.7458035436742306,
      "grad_norm": 0.1969166249036789,
      "learning_rate": 6.270982281628847e-06,
      "loss": 0.0924,
      "step": 9597
    },
    {
      "epoch": 0.7458812558284116,
      "grad_norm": 0.10714453458786011,
      "learning_rate": 6.2705937208579426e-06,
      "loss": 0.0337,
      "step": 9598
    },
    {
      "epoch": 0.7459589679825924,
      "grad_norm": 0.3880767226219177,
      "learning_rate": 6.270205160087038e-06,
      "loss": 0.582,
      "step": 9599
    },
    {
      "epoch": 0.7460366801367734,
      "grad_norm": 0.3233720064163208,
      "learning_rate": 6.269816599316133e-06,
      "loss": 0.2739,
      "step": 9600
    },
    {
      "epoch": 0.7461143922909543,
      "grad_norm": 0.22614097595214844,
      "learning_rate": 6.269428038545229e-06,
      "loss": 0.1375,
      "step": 9601
    },
    {
      "epoch": 0.7461921044451352,
      "grad_norm": 0.23824049532413483,
      "learning_rate": 6.269039477774325e-06,
      "loss": 0.1067,
      "step": 9602
    },
    {
      "epoch": 0.7462698165993161,
      "grad_norm": 0.6503025889396667,
      "learning_rate": 6.268650917003419e-06,
      "loss": 0.1702,
      "step": 9603
    },
    {
      "epoch": 0.7463475287534971,
      "grad_norm": 0.17637965083122253,
      "learning_rate": 6.268262356232515e-06,
      "loss": 0.0424,
      "step": 9604
    },
    {
      "epoch": 0.7464252409076779,
      "grad_norm": 0.5421866774559021,
      "learning_rate": 6.267873795461611e-06,
      "loss": 0.5235,
      "step": 9605
    },
    {
      "epoch": 0.7465029530618589,
      "grad_norm": 0.41095203161239624,
      "learning_rate": 6.267485234690706e-06,
      "loss": 0.1458,
      "step": 9606
    },
    {
      "epoch": 0.7465806652160398,
      "grad_norm": 0.24330414831638336,
      "learning_rate": 6.267096673919801e-06,
      "loss": 0.1011,
      "step": 9607
    },
    {
      "epoch": 0.7466583773702207,
      "grad_norm": 0.2733047902584076,
      "learning_rate": 6.266708113148897e-06,
      "loss": 0.0643,
      "step": 9608
    },
    {
      "epoch": 0.7467360895244016,
      "grad_norm": 0.2332746684551239,
      "learning_rate": 6.266319552377993e-06,
      "loss": 0.0277,
      "step": 9609
    },
    {
      "epoch": 0.7468138016785826,
      "grad_norm": 0.5081865787506104,
      "learning_rate": 6.265930991607088e-06,
      "loss": 0.1558,
      "step": 9610
    },
    {
      "epoch": 0.7468915138327634,
      "grad_norm": 0.38875284790992737,
      "learning_rate": 6.265542430836184e-06,
      "loss": 0.0496,
      "step": 9611
    },
    {
      "epoch": 0.7469692259869444,
      "grad_norm": 0.4803680181503296,
      "learning_rate": 6.2651538700652795e-06,
      "loss": 0.2335,
      "step": 9612
    },
    {
      "epoch": 0.7470469381411253,
      "grad_norm": 0.22315271198749542,
      "learning_rate": 6.2647653092943736e-06,
      "loss": 0.05,
      "step": 9613
    },
    {
      "epoch": 0.7471246502953062,
      "grad_norm": 0.4325036406517029,
      "learning_rate": 6.264376748523469e-06,
      "loss": 0.1375,
      "step": 9614
    },
    {
      "epoch": 0.7472023624494871,
      "grad_norm": 0.15309645235538483,
      "learning_rate": 6.263988187752565e-06,
      "loss": 0.0688,
      "step": 9615
    },
    {
      "epoch": 0.747280074603668,
      "grad_norm": 0.22475899755954742,
      "learning_rate": 6.26359962698166e-06,
      "loss": 0.0957,
      "step": 9616
    },
    {
      "epoch": 0.7473577867578489,
      "grad_norm": 0.5725080370903015,
      "learning_rate": 6.263211066210756e-06,
      "loss": 0.3053,
      "step": 9617
    },
    {
      "epoch": 0.7474354989120299,
      "grad_norm": 0.5900141000747681,
      "learning_rate": 6.262822505439852e-06,
      "loss": 0.0886,
      "step": 9618
    },
    {
      "epoch": 0.7475132110662107,
      "grad_norm": 0.11077432334423065,
      "learning_rate": 6.262433944668947e-06,
      "loss": 0.0131,
      "step": 9619
    },
    {
      "epoch": 0.7475909232203917,
      "grad_norm": 0.3142118453979492,
      "learning_rate": 6.2620453838980425e-06,
      "loss": 0.4812,
      "step": 9620
    },
    {
      "epoch": 0.7476686353745726,
      "grad_norm": 0.32611802220344543,
      "learning_rate": 6.261656823127138e-06,
      "loss": 0.1627,
      "step": 9621
    },
    {
      "epoch": 0.7477463475287535,
      "grad_norm": 0.3161340355873108,
      "learning_rate": 6.261268262356232e-06,
      "loss": 0.133,
      "step": 9622
    },
    {
      "epoch": 0.7478240596829344,
      "grad_norm": 0.14787767827510834,
      "learning_rate": 6.260879701585328e-06,
      "loss": 0.0567,
      "step": 9623
    },
    {
      "epoch": 0.7479017718371154,
      "grad_norm": 0.3784210979938507,
      "learning_rate": 6.260491140814424e-06,
      "loss": 0.1213,
      "step": 9624
    },
    {
      "epoch": 0.7479794839912962,
      "grad_norm": 0.31516122817993164,
      "learning_rate": 6.260102580043519e-06,
      "loss": 0.1226,
      "step": 9625
    },
    {
      "epoch": 0.7480571961454772,
      "grad_norm": 0.06434004753828049,
      "learning_rate": 6.259714019272615e-06,
      "loss": 0.0105,
      "step": 9626
    },
    {
      "epoch": 0.7481349082996581,
      "grad_norm": 0.14804184436798096,
      "learning_rate": 6.2593254585017105e-06,
      "loss": 0.0393,
      "step": 9627
    },
    {
      "epoch": 0.748212620453839,
      "grad_norm": 0.19487926363945007,
      "learning_rate": 6.2589368977308054e-06,
      "loss": 0.0613,
      "step": 9628
    },
    {
      "epoch": 0.7482903326080199,
      "grad_norm": 0.2609430253505707,
      "learning_rate": 6.258548336959901e-06,
      "loss": 0.1378,
      "step": 9629
    },
    {
      "epoch": 0.7483680447622008,
      "grad_norm": 0.8387916684150696,
      "learning_rate": 6.258159776188997e-06,
      "loss": 0.3822,
      "step": 9630
    },
    {
      "epoch": 0.7484457569163817,
      "grad_norm": 0.21355988085269928,
      "learning_rate": 6.257771215418091e-06,
      "loss": 0.0511,
      "step": 9631
    },
    {
      "epoch": 0.7485234690705627,
      "grad_norm": 0.7858293056488037,
      "learning_rate": 6.257382654647187e-06,
      "loss": 0.7191,
      "step": 9632
    },
    {
      "epoch": 0.7486011812247435,
      "grad_norm": 0.2327311933040619,
      "learning_rate": 6.256994093876283e-06,
      "loss": 0.0878,
      "step": 9633
    },
    {
      "epoch": 0.7486788933789245,
      "grad_norm": 0.3537049889564514,
      "learning_rate": 6.256605533105378e-06,
      "loss": 0.0992,
      "step": 9634
    },
    {
      "epoch": 0.7487566055331054,
      "grad_norm": 0.5590578317642212,
      "learning_rate": 6.2562169723344735e-06,
      "loss": 0.185,
      "step": 9635
    },
    {
      "epoch": 0.7488343176872863,
      "grad_norm": 0.9735933542251587,
      "learning_rate": 6.255828411563569e-06,
      "loss": 0.3385,
      "step": 9636
    },
    {
      "epoch": 0.7489120298414672,
      "grad_norm": 0.6457675099372864,
      "learning_rate": 6.255439850792665e-06,
      "loss": 0.3573,
      "step": 9637
    },
    {
      "epoch": 0.7489897419956482,
      "grad_norm": 0.5686675310134888,
      "learning_rate": 6.25505129002176e-06,
      "loss": 0.2741,
      "step": 9638
    },
    {
      "epoch": 0.749067454149829,
      "grad_norm": 0.17377939820289612,
      "learning_rate": 6.254662729250856e-06,
      "loss": 0.0801,
      "step": 9639
    },
    {
      "epoch": 0.74914516630401,
      "grad_norm": 0.4414513409137726,
      "learning_rate": 6.254274168479952e-06,
      "loss": 0.1193,
      "step": 9640
    },
    {
      "epoch": 0.7492228784581909,
      "grad_norm": 0.7632251977920532,
      "learning_rate": 6.253885607709046e-06,
      "loss": 0.4288,
      "step": 9641
    },
    {
      "epoch": 0.7493005906123718,
      "grad_norm": 0.24553504586219788,
      "learning_rate": 6.2534970469381415e-06,
      "loss": 0.0486,
      "step": 9642
    },
    {
      "epoch": 0.7493783027665527,
      "grad_norm": 0.1455463021993637,
      "learning_rate": 6.253108486167237e-06,
      "loss": 0.0366,
      "step": 9643
    },
    {
      "epoch": 0.7494560149207335,
      "grad_norm": 0.336818128824234,
      "learning_rate": 6.252719925396332e-06,
      "loss": 0.1657,
      "step": 9644
    },
    {
      "epoch": 0.7495337270749145,
      "grad_norm": 0.43561574816703796,
      "learning_rate": 6.252331364625428e-06,
      "loss": 0.188,
      "step": 9645
    },
    {
      "epoch": 0.7496114392290955,
      "grad_norm": 0.175770103931427,
      "learning_rate": 6.251942803854524e-06,
      "loss": 0.0701,
      "step": 9646
    },
    {
      "epoch": 0.7496891513832763,
      "grad_norm": 0.22594307363033295,
      "learning_rate": 6.251554243083619e-06,
      "loss": 0.0427,
      "step": 9647
    },
    {
      "epoch": 0.7497668635374573,
      "grad_norm": 0.2327282875776291,
      "learning_rate": 6.251165682312715e-06,
      "loss": 0.1034,
      "step": 9648
    },
    {
      "epoch": 0.7498445756916382,
      "grad_norm": 0.21900111436843872,
      "learning_rate": 6.25077712154181e-06,
      "loss": 0.2111,
      "step": 9649
    },
    {
      "epoch": 0.749922287845819,
      "grad_norm": 0.29889434576034546,
      "learning_rate": 6.2503885607709045e-06,
      "loss": 0.0515,
      "step": 9650
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.2428969293832779,
      "learning_rate": 6.25e-06,
      "loss": 0.0368,
      "step": 9651
    },
    {
      "epoch": 0.750077712154181,
      "grad_norm": 0.3010861575603485,
      "learning_rate": 6.249611439229096e-06,
      "loss": 0.17,
      "step": 9652
    },
    {
      "epoch": 0.7501554243083618,
      "grad_norm": 0.15328578650951385,
      "learning_rate": 6.249222878458191e-06,
      "loss": 0.0533,
      "step": 9653
    },
    {
      "epoch": 0.7502331364625427,
      "grad_norm": 0.24336589872837067,
      "learning_rate": 6.248834317687287e-06,
      "loss": 0.159,
      "step": 9654
    },
    {
      "epoch": 0.7503108486167237,
      "grad_norm": 0.12204301357269287,
      "learning_rate": 6.248445756916383e-06,
      "loss": 0.0552,
      "step": 9655
    },
    {
      "epoch": 0.7503885607709045,
      "grad_norm": 0.5068897008895874,
      "learning_rate": 6.248057196145478e-06,
      "loss": 0.5412,
      "step": 9656
    },
    {
      "epoch": 0.7504662729250855,
      "grad_norm": 0.6203166246414185,
      "learning_rate": 6.247668635374573e-06,
      "loss": 0.0811,
      "step": 9657
    },
    {
      "epoch": 0.7505439850792665,
      "grad_norm": 0.40772882103919983,
      "learning_rate": 6.247280074603669e-06,
      "loss": 0.1476,
      "step": 9658
    },
    {
      "epoch": 0.7506216972334473,
      "grad_norm": 0.4291817843914032,
      "learning_rate": 6.246891513832763e-06,
      "loss": 0.1906,
      "step": 9659
    },
    {
      "epoch": 0.7506994093876282,
      "grad_norm": 0.24264004826545715,
      "learning_rate": 6.246502953061859e-06,
      "loss": 0.052,
      "step": 9660
    },
    {
      "epoch": 0.7507771215418091,
      "grad_norm": 1.1875091791152954,
      "learning_rate": 6.246114392290955e-06,
      "loss": 0.7144,
      "step": 9661
    },
    {
      "epoch": 0.75085483369599,
      "grad_norm": 0.47971802949905396,
      "learning_rate": 6.24572583152005e-06,
      "loss": 0.3334,
      "step": 9662
    },
    {
      "epoch": 0.750932545850171,
      "grad_norm": 0.4173450469970703,
      "learning_rate": 6.245337270749146e-06,
      "loss": 0.0729,
      "step": 9663
    },
    {
      "epoch": 0.7510102580043518,
      "grad_norm": 0.5508922338485718,
      "learning_rate": 6.244948709978241e-06,
      "loss": 0.2862,
      "step": 9664
    },
    {
      "epoch": 0.7510879701585328,
      "grad_norm": 0.3784453570842743,
      "learning_rate": 6.244560149207336e-06,
      "loss": 0.3418,
      "step": 9665
    },
    {
      "epoch": 0.7511656823127137,
      "grad_norm": 0.22440436482429504,
      "learning_rate": 6.244171588436432e-06,
      "loss": 0.0956,
      "step": 9666
    },
    {
      "epoch": 0.7512433944668946,
      "grad_norm": 0.2305096834897995,
      "learning_rate": 6.243783027665528e-06,
      "loss": 0.2096,
      "step": 9667
    },
    {
      "epoch": 0.7513211066210755,
      "grad_norm": 0.6508302688598633,
      "learning_rate": 6.243394466894624e-06,
      "loss": 0.5503,
      "step": 9668
    },
    {
      "epoch": 0.7513988187752565,
      "grad_norm": 0.3577042520046234,
      "learning_rate": 6.243005906123718e-06,
      "loss": 0.1028,
      "step": 9669
    },
    {
      "epoch": 0.7514765309294373,
      "grad_norm": 0.28776785731315613,
      "learning_rate": 6.242617345352814e-06,
      "loss": 0.1451,
      "step": 9670
    },
    {
      "epoch": 0.7515542430836183,
      "grad_norm": 0.620743989944458,
      "learning_rate": 6.2422287845819095e-06,
      "loss": 0.179,
      "step": 9671
    },
    {
      "epoch": 0.7516319552377992,
      "grad_norm": 0.24622732400894165,
      "learning_rate": 6.241840223811004e-06,
      "loss": 0.0676,
      "step": 9672
    },
    {
      "epoch": 0.7517096673919801,
      "grad_norm": 0.19708706438541412,
      "learning_rate": 6.2414516630401e-06,
      "loss": 0.0419,
      "step": 9673
    },
    {
      "epoch": 0.751787379546161,
      "grad_norm": 0.028091173619031906,
      "learning_rate": 6.241063102269196e-06,
      "loss": 0.011,
      "step": 9674
    },
    {
      "epoch": 0.7518650917003419,
      "grad_norm": 0.3394460380077362,
      "learning_rate": 6.240674541498291e-06,
      "loss": 0.0371,
      "step": 9675
    },
    {
      "epoch": 0.7519428038545228,
      "grad_norm": 0.32497933506965637,
      "learning_rate": 6.240285980727387e-06,
      "loss": 0.1741,
      "step": 9676
    },
    {
      "epoch": 0.7520205160087038,
      "grad_norm": 0.5835596323013306,
      "learning_rate": 6.2398974199564825e-06,
      "loss": 0.14,
      "step": 9677
    },
    {
      "epoch": 0.7520982281628846,
      "grad_norm": 0.25693777203559875,
      "learning_rate": 6.239508859185577e-06,
      "loss": 0.0626,
      "step": 9678
    },
    {
      "epoch": 0.7521759403170656,
      "grad_norm": 0.2924472987651825,
      "learning_rate": 6.2391202984146724e-06,
      "loss": 0.2553,
      "step": 9679
    },
    {
      "epoch": 0.7522536524712465,
      "grad_norm": 0.27610543370246887,
      "learning_rate": 6.238731737643768e-06,
      "loss": 0.0929,
      "step": 9680
    },
    {
      "epoch": 0.7523313646254274,
      "grad_norm": 0.1762172430753708,
      "learning_rate": 6.238343176872863e-06,
      "loss": 0.0475,
      "step": 9681
    },
    {
      "epoch": 0.7524090767796083,
      "grad_norm": 0.08685192465782166,
      "learning_rate": 6.237954616101959e-06,
      "loss": 0.0573,
      "step": 9682
    },
    {
      "epoch": 0.7524867889337893,
      "grad_norm": 1.4847509860992432,
      "learning_rate": 6.237566055331055e-06,
      "loss": 0.3784,
      "step": 9683
    },
    {
      "epoch": 0.7525645010879701,
      "grad_norm": 3.3305580615997314,
      "learning_rate": 6.23717749456015e-06,
      "loss": 0.7053,
      "step": 9684
    },
    {
      "epoch": 0.7526422132421511,
      "grad_norm": 0.4025964140892029,
      "learning_rate": 6.236788933789245e-06,
      "loss": 0.069,
      "step": 9685
    },
    {
      "epoch": 0.752719925396332,
      "grad_norm": 0.9098169803619385,
      "learning_rate": 6.2364003730183405e-06,
      "loss": 0.8047,
      "step": 9686
    },
    {
      "epoch": 0.7527976375505129,
      "grad_norm": 0.084477998316288,
      "learning_rate": 6.2360118122474354e-06,
      "loss": 0.0322,
      "step": 9687
    },
    {
      "epoch": 0.7528753497046938,
      "grad_norm": 0.2274809181690216,
      "learning_rate": 6.235623251476531e-06,
      "loss": 0.085,
      "step": 9688
    },
    {
      "epoch": 0.7529530618588747,
      "grad_norm": 0.9496597051620483,
      "learning_rate": 6.235234690705627e-06,
      "loss": 0.5323,
      "step": 9689
    },
    {
      "epoch": 0.7530307740130556,
      "grad_norm": 1.0599777698516846,
      "learning_rate": 6.234846129934722e-06,
      "loss": 0.4178,
      "step": 9690
    },
    {
      "epoch": 0.7531084861672366,
      "grad_norm": 0.439797967672348,
      "learning_rate": 6.234457569163818e-06,
      "loss": 0.2654,
      "step": 9691
    },
    {
      "epoch": 0.7531861983214174,
      "grad_norm": 0.20717753469944,
      "learning_rate": 6.2340690083929136e-06,
      "loss": 0.0763,
      "step": 9692
    },
    {
      "epoch": 0.7532639104755984,
      "grad_norm": 0.11214342713356018,
      "learning_rate": 6.233680447622008e-06,
      "loss": 0.0234,
      "step": 9693
    },
    {
      "epoch": 0.7533416226297793,
      "grad_norm": 0.16538327932357788,
      "learning_rate": 6.2332918868511035e-06,
      "loss": 0.0291,
      "step": 9694
    },
    {
      "epoch": 0.7534193347839602,
      "grad_norm": 0.2002219706773758,
      "learning_rate": 6.232903326080199e-06,
      "loss": 0.0466,
      "step": 9695
    },
    {
      "epoch": 0.7534970469381411,
      "grad_norm": 0.6110411286354065,
      "learning_rate": 6.232514765309294e-06,
      "loss": 0.7359,
      "step": 9696
    },
    {
      "epoch": 0.7535747590923221,
      "grad_norm": 0.7054957747459412,
      "learning_rate": 6.23212620453839e-06,
      "loss": 0.1569,
      "step": 9697
    },
    {
      "epoch": 0.7536524712465029,
      "grad_norm": 0.1284344643354416,
      "learning_rate": 6.231737643767486e-06,
      "loss": 0.0252,
      "step": 9698
    },
    {
      "epoch": 0.7537301834006839,
      "grad_norm": 0.2975548505783081,
      "learning_rate": 6.231349082996582e-06,
      "loss": 0.1862,
      "step": 9699
    },
    {
      "epoch": 0.7538078955548648,
      "grad_norm": 0.7806007862091064,
      "learning_rate": 6.2309605222256766e-06,
      "loss": 0.7726,
      "step": 9700
    },
    {
      "epoch": 0.7538856077090457,
      "grad_norm": 1.0136890411376953,
      "learning_rate": 6.230571961454772e-06,
      "loss": 0.2327,
      "step": 9701
    },
    {
      "epoch": 0.7539633198632266,
      "grad_norm": 0.42888209223747253,
      "learning_rate": 6.230183400683868e-06,
      "loss": 0.2236,
      "step": 9702
    },
    {
      "epoch": 0.7540410320174076,
      "grad_norm": 0.29497405886650085,
      "learning_rate": 6.229794839912962e-06,
      "loss": 0.1823,
      "step": 9703
    },
    {
      "epoch": 0.7541187441715884,
      "grad_norm": 0.3818705677986145,
      "learning_rate": 6.229406279142058e-06,
      "loss": 0.1862,
      "step": 9704
    },
    {
      "epoch": 0.7541964563257694,
      "grad_norm": 0.7467488646507263,
      "learning_rate": 6.229017718371154e-06,
      "loss": 0.2731,
      "step": 9705
    },
    {
      "epoch": 0.7542741684799502,
      "grad_norm": 1.1752854585647583,
      "learning_rate": 6.228629157600249e-06,
      "loss": 0.2403,
      "step": 9706
    },
    {
      "epoch": 0.7543518806341312,
      "grad_norm": 0.2954389452934265,
      "learning_rate": 6.228240596829345e-06,
      "loss": 0.0872,
      "step": 9707
    },
    {
      "epoch": 0.7544295927883121,
      "grad_norm": 0.6340541243553162,
      "learning_rate": 6.22785203605844e-06,
      "loss": 0.1515,
      "step": 9708
    },
    {
      "epoch": 0.754507304942493,
      "grad_norm": 0.2624635100364685,
      "learning_rate": 6.227463475287535e-06,
      "loss": 0.1024,
      "step": 9709
    },
    {
      "epoch": 0.7545850170966739,
      "grad_norm": 0.5199684500694275,
      "learning_rate": 6.227074914516631e-06,
      "loss": 0.0967,
      "step": 9710
    },
    {
      "epoch": 0.7546627292508549,
      "grad_norm": 0.4574873149394989,
      "learning_rate": 6.226686353745727e-06,
      "loss": 0.6666,
      "step": 9711
    },
    {
      "epoch": 0.7547404414050357,
      "grad_norm": 0.08584572374820709,
      "learning_rate": 6.226297792974821e-06,
      "loss": 0.0269,
      "step": 9712
    },
    {
      "epoch": 0.7548181535592167,
      "grad_norm": 0.19645807147026062,
      "learning_rate": 6.225909232203917e-06,
      "loss": 0.0466,
      "step": 9713
    },
    {
      "epoch": 0.7548958657133976,
      "grad_norm": 0.22948923707008362,
      "learning_rate": 6.225520671433013e-06,
      "loss": 0.0301,
      "step": 9714
    },
    {
      "epoch": 0.7549735778675785,
      "grad_norm": 0.36869126558303833,
      "learning_rate": 6.225132110662108e-06,
      "loss": 0.1263,
      "step": 9715
    },
    {
      "epoch": 0.7550512900217594,
      "grad_norm": 0.5683587193489075,
      "learning_rate": 6.224743549891203e-06,
      "loss": 0.3653,
      "step": 9716
    },
    {
      "epoch": 0.7551290021759404,
      "grad_norm": 0.4672756791114807,
      "learning_rate": 6.224354989120299e-06,
      "loss": 0.3054,
      "step": 9717
    },
    {
      "epoch": 0.7552067143301212,
      "grad_norm": 0.5100484490394592,
      "learning_rate": 6.223966428349394e-06,
      "loss": 0.07,
      "step": 9718
    },
    {
      "epoch": 0.7552844264843022,
      "grad_norm": 0.12323366105556488,
      "learning_rate": 6.22357786757849e-06,
      "loss": 0.0846,
      "step": 9719
    },
    {
      "epoch": 0.755362138638483,
      "grad_norm": 0.41067931056022644,
      "learning_rate": 6.223189306807586e-06,
      "loss": 0.2677,
      "step": 9720
    },
    {
      "epoch": 0.755439850792664,
      "grad_norm": 0.4797130227088928,
      "learning_rate": 6.22280074603668e-06,
      "loss": 0.1335,
      "step": 9721
    },
    {
      "epoch": 0.7555175629468449,
      "grad_norm": 1.0112279653549194,
      "learning_rate": 6.222412185265776e-06,
      "loss": 0.2866,
      "step": 9722
    },
    {
      "epoch": 0.7555952751010258,
      "grad_norm": 0.07940809428691864,
      "learning_rate": 6.222023624494871e-06,
      "loss": 0.0175,
      "step": 9723
    },
    {
      "epoch": 0.7556729872552067,
      "grad_norm": 1.2000341415405273,
      "learning_rate": 6.221635063723966e-06,
      "loss": 0.4327,
      "step": 9724
    },
    {
      "epoch": 0.7557506994093877,
      "grad_norm": 0.5165931582450867,
      "learning_rate": 6.221246502953062e-06,
      "loss": 0.3598,
      "step": 9725
    },
    {
      "epoch": 0.7558284115635685,
      "grad_norm": 0.1414135843515396,
      "learning_rate": 6.220857942182158e-06,
      "loss": 0.0257,
      "step": 9726
    },
    {
      "epoch": 0.7559061237177495,
      "grad_norm": 0.29564404487609863,
      "learning_rate": 6.220469381411254e-06,
      "loss": 0.1107,
      "step": 9727
    },
    {
      "epoch": 0.7559838358719304,
      "grad_norm": 0.47835230827331543,
      "learning_rate": 6.220080820640349e-06,
      "loss": 0.2178,
      "step": 9728
    },
    {
      "epoch": 0.7560615480261113,
      "grad_norm": 0.4179871380329132,
      "learning_rate": 6.2196922598694445e-06,
      "loss": 0.1576,
      "step": 9729
    },
    {
      "epoch": 0.7561392601802922,
      "grad_norm": 0.208018958568573,
      "learning_rate": 6.21930369909854e-06,
      "loss": 0.0949,
      "step": 9730
    },
    {
      "epoch": 0.7562169723344732,
      "grad_norm": 0.23269331455230713,
      "learning_rate": 6.218915138327634e-06,
      "loss": 0.2041,
      "step": 9731
    },
    {
      "epoch": 0.756294684488654,
      "grad_norm": 0.43065938353538513,
      "learning_rate": 6.21852657755673e-06,
      "loss": 0.2449,
      "step": 9732
    },
    {
      "epoch": 0.756372396642835,
      "grad_norm": 0.15037693083286285,
      "learning_rate": 6.218138016785826e-06,
      "loss": 0.068,
      "step": 9733
    },
    {
      "epoch": 0.7564501087970159,
      "grad_norm": 0.3623899817466736,
      "learning_rate": 6.217749456014921e-06,
      "loss": 0.1588,
      "step": 9734
    },
    {
      "epoch": 0.7565278209511967,
      "grad_norm": 0.1038777306675911,
      "learning_rate": 6.217360895244017e-06,
      "loss": 0.0666,
      "step": 9735
    },
    {
      "epoch": 0.7566055331053777,
      "grad_norm": 0.46000489592552185,
      "learning_rate": 6.2169723344731125e-06,
      "loss": 0.214,
      "step": 9736
    },
    {
      "epoch": 0.7566832452595585,
      "grad_norm": 0.6100439429283142,
      "learning_rate": 6.2165837737022075e-06,
      "loss": 0.1251,
      "step": 9737
    },
    {
      "epoch": 0.7567609574137395,
      "grad_norm": 0.5671730041503906,
      "learning_rate": 6.216195212931303e-06,
      "loss": 0.7916,
      "step": 9738
    },
    {
      "epoch": 0.7568386695679205,
      "grad_norm": 0.25164586305618286,
      "learning_rate": 6.215806652160399e-06,
      "loss": 0.1244,
      "step": 9739
    },
    {
      "epoch": 0.7569163817221013,
      "grad_norm": 0.16262464225292206,
      "learning_rate": 6.215418091389493e-06,
      "loss": 0.06,
      "step": 9740
    },
    {
      "epoch": 0.7569940938762822,
      "grad_norm": 0.8136019110679626,
      "learning_rate": 6.215029530618589e-06,
      "loss": 0.5419,
      "step": 9741
    },
    {
      "epoch": 0.7570718060304632,
      "grad_norm": 0.8315140008926392,
      "learning_rate": 6.214640969847685e-06,
      "loss": 0.7734,
      "step": 9742
    },
    {
      "epoch": 0.757149518184644,
      "grad_norm": 1.1378173828125,
      "learning_rate": 6.21425240907678e-06,
      "loss": 0.5058,
      "step": 9743
    },
    {
      "epoch": 0.757227230338825,
      "grad_norm": 0.19754207134246826,
      "learning_rate": 6.2138638483058755e-06,
      "loss": 0.099,
      "step": 9744
    },
    {
      "epoch": 0.757304942493006,
      "grad_norm": 0.3220736086368561,
      "learning_rate": 6.213475287534971e-06,
      "loss": 0.1066,
      "step": 9745
    },
    {
      "epoch": 0.7573826546471868,
      "grad_norm": 8.811224937438965,
      "learning_rate": 6.213086726764066e-06,
      "loss": 3.0602,
      "step": 9746
    },
    {
      "epoch": 0.7574603668013677,
      "grad_norm": 0.22961106896400452,
      "learning_rate": 6.212698165993162e-06,
      "loss": 0.1116,
      "step": 9747
    },
    {
      "epoch": 0.7575380789555487,
      "grad_norm": 0.11755594611167908,
      "learning_rate": 6.212309605222258e-06,
      "loss": 0.3598,
      "step": 9748
    },
    {
      "epoch": 0.7576157911097295,
      "grad_norm": 0.5856717824935913,
      "learning_rate": 6.211921044451352e-06,
      "loss": 0.2302,
      "step": 9749
    },
    {
      "epoch": 0.7576935032639105,
      "grad_norm": 0.5261949300765991,
      "learning_rate": 6.211532483680448e-06,
      "loss": 0.2513,
      "step": 9750
    },
    {
      "epoch": 0.7577712154180913,
      "grad_norm": 0.21009120345115662,
      "learning_rate": 6.2111439229095436e-06,
      "loss": 0.0495,
      "step": 9751
    },
    {
      "epoch": 0.7578489275722723,
      "grad_norm": 0.7884668707847595,
      "learning_rate": 6.2107553621386385e-06,
      "loss": 0.2579,
      "step": 9752
    },
    {
      "epoch": 0.7579266397264532,
      "grad_norm": 0.4019503891468048,
      "learning_rate": 6.210366801367734e-06,
      "loss": 0.1518,
      "step": 9753
    },
    {
      "epoch": 0.7580043518806341,
      "grad_norm": 0.5569010972976685,
      "learning_rate": 6.20997824059683e-06,
      "loss": 0.3443,
      "step": 9754
    },
    {
      "epoch": 0.758082064034815,
      "grad_norm": 0.34846511483192444,
      "learning_rate": 6.209589679825925e-06,
      "loss": 0.0796,
      "step": 9755
    },
    {
      "epoch": 0.758159776188996,
      "grad_norm": 0.4327085018157959,
      "learning_rate": 6.209201119055021e-06,
      "loss": 0.2099,
      "step": 9756
    },
    {
      "epoch": 0.7582374883431768,
      "grad_norm": 0.07327872514724731,
      "learning_rate": 6.208812558284117e-06,
      "loss": 0.0147,
      "step": 9757
    },
    {
      "epoch": 0.7583152004973578,
      "grad_norm": 0.3696885108947754,
      "learning_rate": 6.2084239975132124e-06,
      "loss": 0.1074,
      "step": 9758
    },
    {
      "epoch": 0.7583929126515387,
      "grad_norm": 0.5512406229972839,
      "learning_rate": 6.2080354367423065e-06,
      "loss": 0.5253,
      "step": 9759
    },
    {
      "epoch": 0.7584706248057196,
      "grad_norm": 0.4596499800682068,
      "learning_rate": 6.207646875971402e-06,
      "loss": 0.1822,
      "step": 9760
    },
    {
      "epoch": 0.7585483369599005,
      "grad_norm": 0.2973122000694275,
      "learning_rate": 6.207258315200498e-06,
      "loss": 0.1444,
      "step": 9761
    },
    {
      "epoch": 0.7586260491140815,
      "grad_norm": 0.0034170320723205805,
      "learning_rate": 6.206869754429593e-06,
      "loss": 0.0002,
      "step": 9762
    },
    {
      "epoch": 0.7587037612682623,
      "grad_norm": 0.24052608013153076,
      "learning_rate": 6.206481193658689e-06,
      "loss": 0.0625,
      "step": 9763
    },
    {
      "epoch": 0.7587814734224433,
      "grad_norm": 0.43875908851623535,
      "learning_rate": 6.206092632887785e-06,
      "loss": 0.4241,
      "step": 9764
    },
    {
      "epoch": 0.7588591855766241,
      "grad_norm": 0.4580762982368469,
      "learning_rate": 6.20570407211688e-06,
      "loss": 0.2462,
      "step": 9765
    },
    {
      "epoch": 0.7589368977308051,
      "grad_norm": 0.3461390733718872,
      "learning_rate": 6.2053155113459754e-06,
      "loss": 0.1197,
      "step": 9766
    },
    {
      "epoch": 0.759014609884986,
      "grad_norm": 0.3031083941459656,
      "learning_rate": 6.204926950575071e-06,
      "loss": 0.1275,
      "step": 9767
    },
    {
      "epoch": 0.7590923220391669,
      "grad_norm": 0.1805441528558731,
      "learning_rate": 6.204538389804165e-06,
      "loss": 0.0458,
      "step": 9768
    },
    {
      "epoch": 0.7591700341933478,
      "grad_norm": 0.31377875804901123,
      "learning_rate": 6.204149829033261e-06,
      "loss": 0.0646,
      "step": 9769
    },
    {
      "epoch": 0.7592477463475288,
      "grad_norm": 0.3647797703742981,
      "learning_rate": 6.203761268262357e-06,
      "loss": 0.2545,
      "step": 9770
    },
    {
      "epoch": 0.7593254585017096,
      "grad_norm": 0.06278152018785477,
      "learning_rate": 6.203372707491452e-06,
      "loss": 0.0334,
      "step": 9771
    },
    {
      "epoch": 0.7594031706558906,
      "grad_norm": 0.24759890139102936,
      "learning_rate": 6.202984146720548e-06,
      "loss": 0.0962,
      "step": 9772
    },
    {
      "epoch": 0.7594808828100715,
      "grad_norm": 0.2287963181734085,
      "learning_rate": 6.2025955859496435e-06,
      "loss": 0.1222,
      "step": 9773
    },
    {
      "epoch": 0.7595585949642524,
      "grad_norm": 0.5816222429275513,
      "learning_rate": 6.202207025178738e-06,
      "loss": 0.4005,
      "step": 9774
    },
    {
      "epoch": 0.7596363071184333,
      "grad_norm": 0.22745493054389954,
      "learning_rate": 6.201818464407834e-06,
      "loss": 0.0418,
      "step": 9775
    },
    {
      "epoch": 0.7597140192726143,
      "grad_norm": 0.21251602470874786,
      "learning_rate": 6.20142990363693e-06,
      "loss": 0.1138,
      "step": 9776
    },
    {
      "epoch": 0.7597917314267951,
      "grad_norm": 0.24921384453773499,
      "learning_rate": 6.201041342866024e-06,
      "loss": 0.0986,
      "step": 9777
    },
    {
      "epoch": 0.7598694435809761,
      "grad_norm": 0.3082484006881714,
      "learning_rate": 6.20065278209512e-06,
      "loss": 0.0821,
      "step": 9778
    },
    {
      "epoch": 0.759947155735157,
      "grad_norm": 0.6634477376937866,
      "learning_rate": 6.200264221324216e-06,
      "loss": 0.3522,
      "step": 9779
    },
    {
      "epoch": 0.7600248678893379,
      "grad_norm": 0.2717632055282593,
      "learning_rate": 6.199875660553311e-06,
      "loss": 0.0845,
      "step": 9780
    },
    {
      "epoch": 0.7601025800435188,
      "grad_norm": 0.5868081450462341,
      "learning_rate": 6.1994870997824065e-06,
      "loss": 0.2511,
      "step": 9781
    },
    {
      "epoch": 0.7601802921976997,
      "grad_norm": 0.5041119456291199,
      "learning_rate": 6.199098539011502e-06,
      "loss": 0.1625,
      "step": 9782
    },
    {
      "epoch": 0.7602580043518806,
      "grad_norm": 0.5256944298744202,
      "learning_rate": 6.198709978240597e-06,
      "loss": 0.4667,
      "step": 9783
    },
    {
      "epoch": 0.7603357165060616,
      "grad_norm": 0.1653665453195572,
      "learning_rate": 6.198321417469693e-06,
      "loss": 0.0215,
      "step": 9784
    },
    {
      "epoch": 0.7604134286602424,
      "grad_norm": 0.3659491240978241,
      "learning_rate": 6.197932856698789e-06,
      "loss": 0.2937,
      "step": 9785
    },
    {
      "epoch": 0.7604911408144234,
      "grad_norm": 0.1541675627231598,
      "learning_rate": 6.197544295927883e-06,
      "loss": 0.0937,
      "step": 9786
    },
    {
      "epoch": 0.7605688529686043,
      "grad_norm": 0.08909625560045242,
      "learning_rate": 6.197155735156979e-06,
      "loss": 0.0117,
      "step": 9787
    },
    {
      "epoch": 0.7606465651227852,
      "grad_norm": 0.24534016847610474,
      "learning_rate": 6.1967671743860745e-06,
      "loss": 0.415,
      "step": 9788
    },
    {
      "epoch": 0.7607242772769661,
      "grad_norm": 0.4025653302669525,
      "learning_rate": 6.19637861361517e-06,
      "loss": 0.16,
      "step": 9789
    },
    {
      "epoch": 0.7608019894311471,
      "grad_norm": 0.5171073079109192,
      "learning_rate": 6.195990052844265e-06,
      "loss": 0.1053,
      "step": 9790
    },
    {
      "epoch": 0.7608797015853279,
      "grad_norm": 0.5530803203582764,
      "learning_rate": 6.195601492073361e-06,
      "loss": 0.1943,
      "step": 9791
    },
    {
      "epoch": 0.7609574137395089,
      "grad_norm": 0.30331626534461975,
      "learning_rate": 6.195212931302457e-06,
      "loss": 0.0991,
      "step": 9792
    },
    {
      "epoch": 0.7610351258936898,
      "grad_norm": 0.5445823669433594,
      "learning_rate": 6.194824370531552e-06,
      "loss": 0.2113,
      "step": 9793
    },
    {
      "epoch": 0.7611128380478707,
      "grad_norm": 0.49006983637809753,
      "learning_rate": 6.1944358097606476e-06,
      "loss": 0.1813,
      "step": 9794
    },
    {
      "epoch": 0.7611905502020516,
      "grad_norm": 0.2655077576637268,
      "learning_rate": 6.194047248989743e-06,
      "loss": 0.0161,
      "step": 9795
    },
    {
      "epoch": 0.7612682623562325,
      "grad_norm": 0.21146593987941742,
      "learning_rate": 6.1936586882188375e-06,
      "loss": 0.1395,
      "step": 9796
    },
    {
      "epoch": 0.7613459745104134,
      "grad_norm": 0.525596022605896,
      "learning_rate": 6.193270127447933e-06,
      "loss": 0.6959,
      "step": 9797
    },
    {
      "epoch": 0.7614236866645944,
      "grad_norm": 0.6718057990074158,
      "learning_rate": 6.192881566677029e-06,
      "loss": 0.4861,
      "step": 9798
    },
    {
      "epoch": 0.7615013988187752,
      "grad_norm": 0.7015610337257385,
      "learning_rate": 6.192493005906124e-06,
      "loss": 0.3293,
      "step": 9799
    },
    {
      "epoch": 0.7615791109729562,
      "grad_norm": 0.3647081255912781,
      "learning_rate": 6.19210444513522e-06,
      "loss": 0.1248,
      "step": 9800
    },
    {
      "epoch": 0.7616568231271371,
      "grad_norm": 0.4113152325153351,
      "learning_rate": 6.191715884364316e-06,
      "loss": 0.3768,
      "step": 9801
    },
    {
      "epoch": 0.761734535281318,
      "grad_norm": 1.4339208602905273,
      "learning_rate": 6.1913273235934106e-06,
      "loss": 0.2996,
      "step": 9802
    },
    {
      "epoch": 0.7618122474354989,
      "grad_norm": 0.6270542740821838,
      "learning_rate": 6.190938762822506e-06,
      "loss": 0.2055,
      "step": 9803
    },
    {
      "epoch": 0.7618899595896799,
      "grad_norm": 0.10110518336296082,
      "learning_rate": 6.190550202051602e-06,
      "loss": 0.0378,
      "step": 9804
    },
    {
      "epoch": 0.7619676717438607,
      "grad_norm": 0.15083114802837372,
      "learning_rate": 6.190161641280696e-06,
      "loss": 0.0104,
      "step": 9805
    },
    {
      "epoch": 0.7620453838980417,
      "grad_norm": 0.5213402509689331,
      "learning_rate": 6.189773080509792e-06,
      "loss": 0.2234,
      "step": 9806
    },
    {
      "epoch": 0.7621230960522226,
      "grad_norm": 0.3907281458377838,
      "learning_rate": 6.189384519738888e-06,
      "loss": 0.3593,
      "step": 9807
    },
    {
      "epoch": 0.7622008082064035,
      "grad_norm": 0.4845482409000397,
      "learning_rate": 6.188995958967983e-06,
      "loss": 0.1801,
      "step": 9808
    },
    {
      "epoch": 0.7622785203605844,
      "grad_norm": 0.30412083864212036,
      "learning_rate": 6.188607398197079e-06,
      "loss": 0.1335,
      "step": 9809
    },
    {
      "epoch": 0.7623562325147654,
      "grad_norm": 0.2551381587982178,
      "learning_rate": 6.188218837426174e-06,
      "loss": 0.1403,
      "step": 9810
    },
    {
      "epoch": 0.7624339446689462,
      "grad_norm": 0.15223346650600433,
      "learning_rate": 6.1878302766552685e-06,
      "loss": 0.1116,
      "step": 9811
    },
    {
      "epoch": 0.7625116568231272,
      "grad_norm": 0.16800038516521454,
      "learning_rate": 6.187441715884364e-06,
      "loss": 0.0216,
      "step": 9812
    },
    {
      "epoch": 0.762589368977308,
      "grad_norm": 0.17484426498413086,
      "learning_rate": 6.18705315511346e-06,
      "loss": 0.1181,
      "step": 9813
    },
    {
      "epoch": 0.762667081131489,
      "grad_norm": 0.26053255796432495,
      "learning_rate": 6.186664594342555e-06,
      "loss": 0.0377,
      "step": 9814
    },
    {
      "epoch": 0.7627447932856699,
      "grad_norm": 0.5139129161834717,
      "learning_rate": 6.186276033571651e-06,
      "loss": 0.1659,
      "step": 9815
    },
    {
      "epoch": 0.7628225054398508,
      "grad_norm": 0.3907630443572998,
      "learning_rate": 6.185887472800747e-06,
      "loss": 0.2989,
      "step": 9816
    },
    {
      "epoch": 0.7629002175940317,
      "grad_norm": 0.6694589853286743,
      "learning_rate": 6.185498912029842e-06,
      "loss": 0.2932,
      "step": 9817
    },
    {
      "epoch": 0.7629779297482127,
      "grad_norm": 0.465486079454422,
      "learning_rate": 6.185110351258937e-06,
      "loss": 0.1137,
      "step": 9818
    },
    {
      "epoch": 0.7630556419023935,
      "grad_norm": 0.19815708696842194,
      "learning_rate": 6.184721790488033e-06,
      "loss": 0.118,
      "step": 9819
    },
    {
      "epoch": 0.7631333540565745,
      "grad_norm": 0.32935112714767456,
      "learning_rate": 6.184333229717129e-06,
      "loss": 0.2507,
      "step": 9820
    },
    {
      "epoch": 0.7632110662107554,
      "grad_norm": 0.20984913408756256,
      "learning_rate": 6.183944668946223e-06,
      "loss": 0.1687,
      "step": 9821
    },
    {
      "epoch": 0.7632887783649362,
      "grad_norm": 0.4172383248806,
      "learning_rate": 6.183556108175319e-06,
      "loss": 0.1675,
      "step": 9822
    },
    {
      "epoch": 0.7633664905191172,
      "grad_norm": 0.3193334639072418,
      "learning_rate": 6.183167547404415e-06,
      "loss": 0.1605,
      "step": 9823
    },
    {
      "epoch": 0.7634442026732982,
      "grad_norm": 0.7669640183448792,
      "learning_rate": 6.18277898663351e-06,
      "loss": 0.7955,
      "step": 9824
    },
    {
      "epoch": 0.763521914827479,
      "grad_norm": 0.037151072174310684,
      "learning_rate": 6.182390425862605e-06,
      "loss": 0.0079,
      "step": 9825
    },
    {
      "epoch": 0.76359962698166,
      "grad_norm": 0.3716298043727875,
      "learning_rate": 6.182001865091701e-06,
      "loss": 0.2963,
      "step": 9826
    },
    {
      "epoch": 0.7636773391358408,
      "grad_norm": 0.16667109727859497,
      "learning_rate": 6.181613304320796e-06,
      "loss": 0.052,
      "step": 9827
    },
    {
      "epoch": 0.7637550512900217,
      "grad_norm": 0.16217853128910065,
      "learning_rate": 6.181224743549892e-06,
      "loss": 0.0976,
      "step": 9828
    },
    {
      "epoch": 0.7638327634442027,
      "grad_norm": 0.5034480690956116,
      "learning_rate": 6.180836182778988e-06,
      "loss": 0.3272,
      "step": 9829
    },
    {
      "epoch": 0.7639104755983835,
      "grad_norm": 0.30738338828086853,
      "learning_rate": 6.180447622008082e-06,
      "loss": 0.1955,
      "step": 9830
    },
    {
      "epoch": 0.7639881877525645,
      "grad_norm": 0.3277333676815033,
      "learning_rate": 6.180059061237178e-06,
      "loss": 0.1989,
      "step": 9831
    },
    {
      "epoch": 0.7640658999067454,
      "grad_norm": 0.4234452247619629,
      "learning_rate": 6.1796705004662735e-06,
      "loss": 0.2184,
      "step": 9832
    },
    {
      "epoch": 0.7641436120609263,
      "grad_norm": 0.26789364218711853,
      "learning_rate": 6.179281939695368e-06,
      "loss": 0.097,
      "step": 9833
    },
    {
      "epoch": 0.7642213242151072,
      "grad_norm": 0.2282755970954895,
      "learning_rate": 6.178893378924464e-06,
      "loss": 0.0723,
      "step": 9834
    },
    {
      "epoch": 0.7642990363692882,
      "grad_norm": 0.5586677193641663,
      "learning_rate": 6.17850481815356e-06,
      "loss": 0.2438,
      "step": 9835
    },
    {
      "epoch": 0.764376748523469,
      "grad_norm": 0.4240688681602478,
      "learning_rate": 6.178116257382655e-06,
      "loss": 0.5244,
      "step": 9836
    },
    {
      "epoch": 0.76445446067765,
      "grad_norm": 0.15469145774841309,
      "learning_rate": 6.177727696611751e-06,
      "loss": 0.192,
      "step": 9837
    },
    {
      "epoch": 0.764532172831831,
      "grad_norm": 0.5589159727096558,
      "learning_rate": 6.1773391358408465e-06,
      "loss": 0.3327,
      "step": 9838
    },
    {
      "epoch": 0.7646098849860118,
      "grad_norm": 0.5187126398086548,
      "learning_rate": 6.176950575069941e-06,
      "loss": 0.4922,
      "step": 9839
    },
    {
      "epoch": 0.7646875971401927,
      "grad_norm": 0.03951018676161766,
      "learning_rate": 6.1765620142990364e-06,
      "loss": 0.0091,
      "step": 9840
    },
    {
      "epoch": 0.7647653092943736,
      "grad_norm": 0.48533812165260315,
      "learning_rate": 6.176173453528132e-06,
      "loss": 0.2306,
      "step": 9841
    },
    {
      "epoch": 0.7648430214485545,
      "grad_norm": 0.36382484436035156,
      "learning_rate": 6.175784892757227e-06,
      "loss": 0.2299,
      "step": 9842
    },
    {
      "epoch": 0.7649207336027355,
      "grad_norm": 0.3063971996307373,
      "learning_rate": 6.175396331986323e-06,
      "loss": 0.1501,
      "step": 9843
    },
    {
      "epoch": 0.7649984457569163,
      "grad_norm": 0.3144893944263458,
      "learning_rate": 6.175007771215419e-06,
      "loss": 0.1271,
      "step": 9844
    },
    {
      "epoch": 0.7650761579110973,
      "grad_norm": 0.3553449809551239,
      "learning_rate": 6.174619210444514e-06,
      "loss": 0.1258,
      "step": 9845
    },
    {
      "epoch": 0.7651538700652782,
      "grad_norm": 0.2128422111272812,
      "learning_rate": 6.1742306496736095e-06,
      "loss": 0.0783,
      "step": 9846
    },
    {
      "epoch": 0.7652315822194591,
      "grad_norm": 0.9609646201133728,
      "learning_rate": 6.173842088902705e-06,
      "loss": 0.9177,
      "step": 9847
    },
    {
      "epoch": 0.76530929437364,
      "grad_norm": 0.7416816353797913,
      "learning_rate": 6.1734535281317994e-06,
      "loss": 0.3904,
      "step": 9848
    },
    {
      "epoch": 0.765387006527821,
      "grad_norm": 0.1675727367401123,
      "learning_rate": 6.173064967360895e-06,
      "loss": 0.084,
      "step": 9849
    },
    {
      "epoch": 0.7654647186820018,
      "grad_norm": 0.2867663502693176,
      "learning_rate": 6.172676406589991e-06,
      "loss": 0.1616,
      "step": 9850
    },
    {
      "epoch": 0.7655424308361828,
      "grad_norm": 0.2662132978439331,
      "learning_rate": 6.172287845819087e-06,
      "loss": 0.269,
      "step": 9851
    },
    {
      "epoch": 0.7656201429903637,
      "grad_norm": 0.897462010383606,
      "learning_rate": 6.171899285048182e-06,
      "loss": 0.2853,
      "step": 9852
    },
    {
      "epoch": 0.7656978551445446,
      "grad_norm": 0.28404244780540466,
      "learning_rate": 6.1715107242772776e-06,
      "loss": 0.0601,
      "step": 9853
    },
    {
      "epoch": 0.7657755672987255,
      "grad_norm": 0.37016400694847107,
      "learning_rate": 6.171122163506373e-06,
      "loss": 0.2557,
      "step": 9854
    },
    {
      "epoch": 0.7658532794529065,
      "grad_norm": 0.4211127460002899,
      "learning_rate": 6.170733602735468e-06,
      "loss": 0.17,
      "step": 9855
    },
    {
      "epoch": 0.7659309916070873,
      "grad_norm": 0.09245249629020691,
      "learning_rate": 6.170345041964564e-06,
      "loss": 0.1827,
      "step": 9856
    },
    {
      "epoch": 0.7660087037612683,
      "grad_norm": 0.17389996349811554,
      "learning_rate": 6.16995648119366e-06,
      "loss": 0.0663,
      "step": 9857
    },
    {
      "epoch": 0.7660864159154491,
      "grad_norm": 0.3479177951812744,
      "learning_rate": 6.169567920422754e-06,
      "loss": 0.1255,
      "step": 9858
    },
    {
      "epoch": 0.7661641280696301,
      "grad_norm": 0.0833846777677536,
      "learning_rate": 6.16917935965185e-06,
      "loss": 0.0523,
      "step": 9859
    },
    {
      "epoch": 0.766241840223811,
      "grad_norm": 0.5360109210014343,
      "learning_rate": 6.168790798880946e-06,
      "loss": 0.2842,
      "step": 9860
    },
    {
      "epoch": 0.7663195523779919,
      "grad_norm": 0.32286444306373596,
      "learning_rate": 6.1684022381100405e-06,
      "loss": 0.4653,
      "step": 9861
    },
    {
      "epoch": 0.7663972645321728,
      "grad_norm": 0.5085211396217346,
      "learning_rate": 6.168013677339136e-06,
      "loss": 0.2148,
      "step": 9862
    },
    {
      "epoch": 0.7664749766863538,
      "grad_norm": 0.09559427946805954,
      "learning_rate": 6.167625116568232e-06,
      "loss": 0.018,
      "step": 9863
    },
    {
      "epoch": 0.7665526888405346,
      "grad_norm": 0.16857892274856567,
      "learning_rate": 6.167236555797327e-06,
      "loss": 0.0714,
      "step": 9864
    },
    {
      "epoch": 0.7666304009947156,
      "grad_norm": 0.2241077870130539,
      "learning_rate": 6.166847995026423e-06,
      "loss": 0.1247,
      "step": 9865
    },
    {
      "epoch": 0.7667081131488965,
      "grad_norm": 0.7114509344100952,
      "learning_rate": 6.166459434255519e-06,
      "loss": 0.393,
      "step": 9866
    },
    {
      "epoch": 0.7667858253030774,
      "grad_norm": 0.6330536603927612,
      "learning_rate": 6.166070873484613e-06,
      "loss": 0.2025,
      "step": 9867
    },
    {
      "epoch": 0.7668635374572583,
      "grad_norm": 0.13478563725948334,
      "learning_rate": 6.165682312713709e-06,
      "loss": 0.0224,
      "step": 9868
    },
    {
      "epoch": 0.7669412496114393,
      "grad_norm": 0.5372985601425171,
      "learning_rate": 6.165293751942804e-06,
      "loss": 0.1372,
      "step": 9869
    },
    {
      "epoch": 0.7670189617656201,
      "grad_norm": 0.19596324861049652,
      "learning_rate": 6.164905191171899e-06,
      "loss": 0.0795,
      "step": 9870
    },
    {
      "epoch": 0.7670966739198011,
      "grad_norm": 0.41918155550956726,
      "learning_rate": 6.164516630400995e-06,
      "loss": 0.1836,
      "step": 9871
    },
    {
      "epoch": 0.7671743860739819,
      "grad_norm": 0.322108656167984,
      "learning_rate": 6.164128069630091e-06,
      "loss": 0.2468,
      "step": 9872
    },
    {
      "epoch": 0.7672520982281629,
      "grad_norm": 0.3013375699520111,
      "learning_rate": 6.163739508859186e-06,
      "loss": 0.0835,
      "step": 9873
    },
    {
      "epoch": 0.7673298103823438,
      "grad_norm": 0.48650166392326355,
      "learning_rate": 6.163350948088282e-06,
      "loss": 0.1735,
      "step": 9874
    },
    {
      "epoch": 0.7674075225365247,
      "grad_norm": 0.5289751887321472,
      "learning_rate": 6.1629623873173775e-06,
      "loss": 0.1751,
      "step": 9875
    },
    {
      "epoch": 0.7674852346907056,
      "grad_norm": 0.36783367395401,
      "learning_rate": 6.1625738265464716e-06,
      "loss": 0.1528,
      "step": 9876
    },
    {
      "epoch": 0.7675629468448866,
      "grad_norm": 0.9921346306800842,
      "learning_rate": 6.162185265775567e-06,
      "loss": 0.2558,
      "step": 9877
    },
    {
      "epoch": 0.7676406589990674,
      "grad_norm": 0.6208308339118958,
      "learning_rate": 6.161796705004663e-06,
      "loss": 0.0802,
      "step": 9878
    },
    {
      "epoch": 0.7677183711532484,
      "grad_norm": 0.5415660738945007,
      "learning_rate": 6.161408144233759e-06,
      "loss": 0.8478,
      "step": 9879
    },
    {
      "epoch": 0.7677960833074293,
      "grad_norm": 0.7228766679763794,
      "learning_rate": 6.161019583462854e-06,
      "loss": 0.4271,
      "step": 9880
    },
    {
      "epoch": 0.7678737954616102,
      "grad_norm": 0.05408831685781479,
      "learning_rate": 6.16063102269195e-06,
      "loss": 0.0198,
      "step": 9881
    },
    {
      "epoch": 0.7679515076157911,
      "grad_norm": 0.12826141715049744,
      "learning_rate": 6.1602424619210455e-06,
      "loss": 0.0205,
      "step": 9882
    },
    {
      "epoch": 0.7680292197699721,
      "grad_norm": 0.6152331829071045,
      "learning_rate": 6.1598539011501405e-06,
      "loss": 0.2647,
      "step": 9883
    },
    {
      "epoch": 0.7681069319241529,
      "grad_norm": 0.543217122554779,
      "learning_rate": 6.159465340379236e-06,
      "loss": 0.2396,
      "step": 9884
    },
    {
      "epoch": 0.7681846440783339,
      "grad_norm": 0.07927931845188141,
      "learning_rate": 6.159076779608332e-06,
      "loss": 0.0269,
      "step": 9885
    },
    {
      "epoch": 0.7682623562325148,
      "grad_norm": 0.49613362550735474,
      "learning_rate": 6.158688218837426e-06,
      "loss": 0.1966,
      "step": 9886
    },
    {
      "epoch": 0.7683400683866957,
      "grad_norm": 0.40607750415802,
      "learning_rate": 6.158299658066522e-06,
      "loss": 0.1967,
      "step": 9887
    },
    {
      "epoch": 0.7684177805408766,
      "grad_norm": 0.5777968168258667,
      "learning_rate": 6.157911097295618e-06,
      "loss": 0.4449,
      "step": 9888
    },
    {
      "epoch": 0.7684954926950575,
      "grad_norm": 0.7420596480369568,
      "learning_rate": 6.157522536524713e-06,
      "loss": 0.2721,
      "step": 9889
    },
    {
      "epoch": 0.7685732048492384,
      "grad_norm": 0.269130676984787,
      "learning_rate": 6.1571339757538085e-06,
      "loss": 0.0726,
      "step": 9890
    },
    {
      "epoch": 0.7686509170034194,
      "grad_norm": 0.06518443673849106,
      "learning_rate": 6.156745414982904e-06,
      "loss": 0.0295,
      "step": 9891
    },
    {
      "epoch": 0.7687286291576002,
      "grad_norm": 0.1792456954717636,
      "learning_rate": 6.156356854211999e-06,
      "loss": 0.1131,
      "step": 9892
    },
    {
      "epoch": 0.7688063413117812,
      "grad_norm": 0.17983181774616241,
      "learning_rate": 6.155968293441095e-06,
      "loss": 0.0468,
      "step": 9893
    },
    {
      "epoch": 0.7688840534659621,
      "grad_norm": 0.45928794145584106,
      "learning_rate": 6.155579732670191e-06,
      "loss": 0.1185,
      "step": 9894
    },
    {
      "epoch": 0.768961765620143,
      "grad_norm": 0.15516620874404907,
      "learning_rate": 6.155191171899285e-06,
      "loss": 0.0476,
      "step": 9895
    },
    {
      "epoch": 0.7690394777743239,
      "grad_norm": 0.4475342631340027,
      "learning_rate": 6.154802611128381e-06,
      "loss": 0.2496,
      "step": 9896
    },
    {
      "epoch": 0.7691171899285049,
      "grad_norm": 0.48991259932518005,
      "learning_rate": 6.1544140503574765e-06,
      "loss": 0.2245,
      "step": 9897
    },
    {
      "epoch": 0.7691949020826857,
      "grad_norm": 0.3514789938926697,
      "learning_rate": 6.1540254895865715e-06,
      "loss": 0.1678,
      "step": 9898
    },
    {
      "epoch": 0.7692726142368667,
      "grad_norm": 0.1599634736776352,
      "learning_rate": 6.153636928815667e-06,
      "loss": 0.1403,
      "step": 9899
    },
    {
      "epoch": 0.7693503263910476,
      "grad_norm": 0.583683431148529,
      "learning_rate": 6.153248368044763e-06,
      "loss": 0.3288,
      "step": 9900
    },
    {
      "epoch": 0.7694280385452285,
      "grad_norm": 0.5125074982643127,
      "learning_rate": 6.152859807273858e-06,
      "loss": 0.378,
      "step": 9901
    },
    {
      "epoch": 0.7695057506994094,
      "grad_norm": 0.6139487624168396,
      "learning_rate": 6.152471246502954e-06,
      "loss": 0.5873,
      "step": 9902
    },
    {
      "epoch": 0.7695834628535902,
      "grad_norm": 0.47135329246520996,
      "learning_rate": 6.15208268573205e-06,
      "loss": 0.2185,
      "step": 9903
    },
    {
      "epoch": 0.7696611750077712,
      "grad_norm": 0.8806114792823792,
      "learning_rate": 6.151694124961144e-06,
      "loss": 0.571,
      "step": 9904
    },
    {
      "epoch": 0.7697388871619522,
      "grad_norm": 0.5455019474029541,
      "learning_rate": 6.1513055641902395e-06,
      "loss": 0.2615,
      "step": 9905
    },
    {
      "epoch": 0.769816599316133,
      "grad_norm": 0.43698325753211975,
      "learning_rate": 6.150917003419335e-06,
      "loss": 0.1548,
      "step": 9906
    },
    {
      "epoch": 0.769894311470314,
      "grad_norm": 0.5988690853118896,
      "learning_rate": 6.15052844264843e-06,
      "loss": 0.5116,
      "step": 9907
    },
    {
      "epoch": 0.7699720236244949,
      "grad_norm": 0.6229397058486938,
      "learning_rate": 6.150139881877526e-06,
      "loss": 0.2328,
      "step": 9908
    },
    {
      "epoch": 0.7700497357786757,
      "grad_norm": 0.5731216669082642,
      "learning_rate": 6.149751321106622e-06,
      "loss": 0.114,
      "step": 9909
    },
    {
      "epoch": 0.7701274479328567,
      "grad_norm": 1.445824146270752,
      "learning_rate": 6.149362760335718e-06,
      "loss": 0.5726,
      "step": 9910
    },
    {
      "epoch": 0.7702051600870377,
      "grad_norm": 0.4699871242046356,
      "learning_rate": 6.148974199564813e-06,
      "loss": 0.1811,
      "step": 9911
    },
    {
      "epoch": 0.7702828722412185,
      "grad_norm": 0.5140647888183594,
      "learning_rate": 6.148585638793908e-06,
      "loss": 0.4598,
      "step": 9912
    },
    {
      "epoch": 0.7703605843953995,
      "grad_norm": 0.3435814082622528,
      "learning_rate": 6.148197078023004e-06,
      "loss": 0.3096,
      "step": 9913
    },
    {
      "epoch": 0.7704382965495804,
      "grad_norm": 0.6769190430641174,
      "learning_rate": 6.147808517252098e-06,
      "loss": 0.284,
      "step": 9914
    },
    {
      "epoch": 0.7705160087037612,
      "grad_norm": 0.5039507150650024,
      "learning_rate": 6.147419956481194e-06,
      "loss": 0.4237,
      "step": 9915
    },
    {
      "epoch": 0.7705937208579422,
      "grad_norm": 0.2917407155036926,
      "learning_rate": 6.14703139571029e-06,
      "loss": 0.1195,
      "step": 9916
    },
    {
      "epoch": 0.770671433012123,
      "grad_norm": 0.16597701609134674,
      "learning_rate": 6.146642834939385e-06,
      "loss": 0.0484,
      "step": 9917
    },
    {
      "epoch": 0.770749145166304,
      "grad_norm": 0.3089151680469513,
      "learning_rate": 6.146254274168481e-06,
      "loss": 0.4455,
      "step": 9918
    },
    {
      "epoch": 0.770826857320485,
      "grad_norm": 0.3720223605632782,
      "learning_rate": 6.1458657133975764e-06,
      "loss": 0.5664,
      "step": 9919
    },
    {
      "epoch": 0.7709045694746658,
      "grad_norm": 0.3029153048992157,
      "learning_rate": 6.145477152626671e-06,
      "loss": 0.1078,
      "step": 9920
    },
    {
      "epoch": 0.7709822816288467,
      "grad_norm": 0.0902336984872818,
      "learning_rate": 6.145088591855767e-06,
      "loss": 0.0267,
      "step": 9921
    },
    {
      "epoch": 0.7710599937830277,
      "grad_norm": 0.04418591782450676,
      "learning_rate": 6.144700031084863e-06,
      "loss": 0.0129,
      "step": 9922
    },
    {
      "epoch": 0.7711377059372085,
      "grad_norm": 0.547080397605896,
      "learning_rate": 6.144311470313957e-06,
      "loss": 0.1506,
      "step": 9923
    },
    {
      "epoch": 0.7712154180913895,
      "grad_norm": 0.27016836404800415,
      "learning_rate": 6.143922909543053e-06,
      "loss": 0.1628,
      "step": 9924
    },
    {
      "epoch": 0.7712931302455704,
      "grad_norm": 0.49061551690101624,
      "learning_rate": 6.143534348772149e-06,
      "loss": 0.4267,
      "step": 9925
    },
    {
      "epoch": 0.7713708423997513,
      "grad_norm": 0.5120593905448914,
      "learning_rate": 6.143145788001244e-06,
      "loss": 0.2949,
      "step": 9926
    },
    {
      "epoch": 0.7714485545539322,
      "grad_norm": 0.20185323059558868,
      "learning_rate": 6.142757227230339e-06,
      "loss": 0.0739,
      "step": 9927
    },
    {
      "epoch": 0.7715262667081132,
      "grad_norm": 0.5580629706382751,
      "learning_rate": 6.142368666459435e-06,
      "loss": 0.3504,
      "step": 9928
    },
    {
      "epoch": 0.771603978862294,
      "grad_norm": 0.5179423093795776,
      "learning_rate": 6.14198010568853e-06,
      "loss": 0.6985,
      "step": 9929
    },
    {
      "epoch": 0.771681691016475,
      "grad_norm": 0.47577935457229614,
      "learning_rate": 6.141591544917626e-06,
      "loss": 0.1203,
      "step": 9930
    },
    {
      "epoch": 0.7717594031706559,
      "grad_norm": 0.19256076216697693,
      "learning_rate": 6.141202984146721e-06,
      "loss": 0.0478,
      "step": 9931
    },
    {
      "epoch": 0.7718371153248368,
      "grad_norm": 0.3441421389579773,
      "learning_rate": 6.140814423375816e-06,
      "loss": 0.1512,
      "step": 9932
    },
    {
      "epoch": 0.7719148274790177,
      "grad_norm": 0.09619026631116867,
      "learning_rate": 6.140425862604912e-06,
      "loss": 0.0151,
      "step": 9933
    },
    {
      "epoch": 0.7719925396331986,
      "grad_norm": 0.3225681781768799,
      "learning_rate": 6.1400373018340075e-06,
      "loss": 0.1172,
      "step": 9934
    },
    {
      "epoch": 0.7720702517873795,
      "grad_norm": 0.2889392375946045,
      "learning_rate": 6.139648741063102e-06,
      "loss": 0.1461,
      "step": 9935
    },
    {
      "epoch": 0.7721479639415605,
      "grad_norm": 0.4054872393608093,
      "learning_rate": 6.139260180292198e-06,
      "loss": 0.1342,
      "step": 9936
    },
    {
      "epoch": 0.7722256760957413,
      "grad_norm": 0.318177729845047,
      "learning_rate": 6.138871619521294e-06,
      "loss": 0.1938,
      "step": 9937
    },
    {
      "epoch": 0.7723033882499223,
      "grad_norm": 0.37373337149620056,
      "learning_rate": 6.138483058750388e-06,
      "loss": 0.1576,
      "step": 9938
    },
    {
      "epoch": 0.7723811004041032,
      "grad_norm": 0.3158607482910156,
      "learning_rate": 6.138094497979484e-06,
      "loss": 0.177,
      "step": 9939
    },
    {
      "epoch": 0.7724588125582841,
      "grad_norm": 0.2857041656970978,
      "learning_rate": 6.13770593720858e-06,
      "loss": 0.0587,
      "step": 9940
    },
    {
      "epoch": 0.772536524712465,
      "grad_norm": 0.6835955381393433,
      "learning_rate": 6.1373173764376755e-06,
      "loss": 0.395,
      "step": 9941
    },
    {
      "epoch": 0.772614236866646,
      "grad_norm": 0.5322921276092529,
      "learning_rate": 6.1369288156667704e-06,
      "loss": 0.4617,
      "step": 9942
    },
    {
      "epoch": 0.7726919490208268,
      "grad_norm": 1.2870299816131592,
      "learning_rate": 6.136540254895866e-06,
      "loss": 0.235,
      "step": 9943
    },
    {
      "epoch": 0.7727696611750078,
      "grad_norm": 0.984150767326355,
      "learning_rate": 6.136151694124962e-06,
      "loss": 0.5684,
      "step": 9944
    },
    {
      "epoch": 0.7728473733291887,
      "grad_norm": 0.2431003600358963,
      "learning_rate": 6.135763133354057e-06,
      "loss": 0.1442,
      "step": 9945
    },
    {
      "epoch": 0.7729250854833696,
      "grad_norm": 0.2781786322593689,
      "learning_rate": 6.135374572583153e-06,
      "loss": 0.1801,
      "step": 9946
    },
    {
      "epoch": 0.7730027976375505,
      "grad_norm": 0.47933557629585266,
      "learning_rate": 6.134986011812249e-06,
      "loss": 0.3059,
      "step": 9947
    },
    {
      "epoch": 0.7730805097917314,
      "grad_norm": 0.7624344825744629,
      "learning_rate": 6.134597451041343e-06,
      "loss": 0.0689,
      "step": 9948
    },
    {
      "epoch": 0.7731582219459123,
      "grad_norm": 0.27332040667533875,
      "learning_rate": 6.1342088902704385e-06,
      "loss": 0.1157,
      "step": 9949
    },
    {
      "epoch": 0.7732359341000933,
      "grad_norm": 0.33400529623031616,
      "learning_rate": 6.133820329499534e-06,
      "loss": 0.1695,
      "step": 9950
    },
    {
      "epoch": 0.7733136462542741,
      "grad_norm": 0.3150028586387634,
      "learning_rate": 6.133431768728629e-06,
      "loss": 0.0632,
      "step": 9951
    },
    {
      "epoch": 0.7733913584084551,
      "grad_norm": 0.02678738161921501,
      "learning_rate": 6.133043207957725e-06,
      "loss": 0.0064,
      "step": 9952
    },
    {
      "epoch": 0.773469070562636,
      "grad_norm": 0.5154533386230469,
      "learning_rate": 6.132654647186821e-06,
      "loss": 0.1879,
      "step": 9953
    },
    {
      "epoch": 0.7735467827168169,
      "grad_norm": 0.3833705484867096,
      "learning_rate": 6.132266086415916e-06,
      "loss": 0.1101,
      "step": 9954
    },
    {
      "epoch": 0.7736244948709978,
      "grad_norm": 0.1805797517299652,
      "learning_rate": 6.1318775256450116e-06,
      "loss": 0.0212,
      "step": 9955
    },
    {
      "epoch": 0.7737022070251788,
      "grad_norm": 1.2021763324737549,
      "learning_rate": 6.131488964874107e-06,
      "loss": 0.4116,
      "step": 9956
    },
    {
      "epoch": 0.7737799191793596,
      "grad_norm": 0.06079649552702904,
      "learning_rate": 6.1311004041032015e-06,
      "loss": 0.0225,
      "step": 9957
    },
    {
      "epoch": 0.7738576313335406,
      "grad_norm": 0.3965153992176056,
      "learning_rate": 6.130711843332297e-06,
      "loss": 0.0623,
      "step": 9958
    },
    {
      "epoch": 0.7739353434877215,
      "grad_norm": 0.34622281789779663,
      "learning_rate": 6.130323282561393e-06,
      "loss": 0.1608,
      "step": 9959
    },
    {
      "epoch": 0.7740130556419024,
      "grad_norm": 0.2833993434906006,
      "learning_rate": 6.129934721790488e-06,
      "loss": 0.1258,
      "step": 9960
    },
    {
      "epoch": 0.7740907677960833,
      "grad_norm": 0.16860049962997437,
      "learning_rate": 6.129546161019584e-06,
      "loss": 0.1072,
      "step": 9961
    },
    {
      "epoch": 0.7741684799502643,
      "grad_norm": 0.19387027621269226,
      "learning_rate": 6.12915760024868e-06,
      "loss": 0.0693,
      "step": 9962
    },
    {
      "epoch": 0.7742461921044451,
      "grad_norm": 0.05153191089630127,
      "learning_rate": 6.1287690394777746e-06,
      "loss": 0.0121,
      "step": 9963
    },
    {
      "epoch": 0.7743239042586261,
      "grad_norm": 0.19045913219451904,
      "learning_rate": 6.12838047870687e-06,
      "loss": 0.0926,
      "step": 9964
    },
    {
      "epoch": 0.7744016164128069,
      "grad_norm": 0.349979430437088,
      "learning_rate": 6.127991917935966e-06,
      "loss": 0.1429,
      "step": 9965
    },
    {
      "epoch": 0.7744793285669879,
      "grad_norm": 0.477872759103775,
      "learning_rate": 6.12760335716506e-06,
      "loss": 0.2812,
      "step": 9966
    },
    {
      "epoch": 0.7745570407211688,
      "grad_norm": 0.6071822047233582,
      "learning_rate": 6.127214796394156e-06,
      "loss": 0.499,
      "step": 9967
    },
    {
      "epoch": 0.7746347528753497,
      "grad_norm": 0.18007095158100128,
      "learning_rate": 6.126826235623252e-06,
      "loss": 0.0637,
      "step": 9968
    },
    {
      "epoch": 0.7747124650295306,
      "grad_norm": 0.18573828041553497,
      "learning_rate": 6.126437674852347e-06,
      "loss": 0.0201,
      "step": 9969
    },
    {
      "epoch": 0.7747901771837116,
      "grad_norm": 0.568230152130127,
      "learning_rate": 6.126049114081443e-06,
      "loss": 0.0803,
      "step": 9970
    },
    {
      "epoch": 0.7748678893378924,
      "grad_norm": 0.3302776515483856,
      "learning_rate": 6.125660553310538e-06,
      "loss": 0.3645,
      "step": 9971
    },
    {
      "epoch": 0.7749456014920734,
      "grad_norm": 0.13444198668003082,
      "learning_rate": 6.125271992539634e-06,
      "loss": 0.034,
      "step": 9972
    },
    {
      "epoch": 0.7750233136462543,
      "grad_norm": 0.22748108208179474,
      "learning_rate": 6.124883431768729e-06,
      "loss": 0.0514,
      "step": 9973
    },
    {
      "epoch": 0.7751010258004352,
      "grad_norm": 0.16824376583099365,
      "learning_rate": 6.124494870997825e-06,
      "loss": 0.0308,
      "step": 9974
    },
    {
      "epoch": 0.7751787379546161,
      "grad_norm": 0.6758188009262085,
      "learning_rate": 6.124106310226921e-06,
      "loss": 0.4256,
      "step": 9975
    },
    {
      "epoch": 0.7752564501087971,
      "grad_norm": 0.2073763608932495,
      "learning_rate": 6.123717749456015e-06,
      "loss": 0.0487,
      "step": 9976
    },
    {
      "epoch": 0.7753341622629779,
      "grad_norm": 0.23385439813137054,
      "learning_rate": 6.123329188685111e-06,
      "loss": 0.0474,
      "step": 9977
    },
    {
      "epoch": 0.7754118744171589,
      "grad_norm": 0.08860302716493607,
      "learning_rate": 6.1229406279142064e-06,
      "loss": 0.0402,
      "step": 9978
    },
    {
      "epoch": 0.7754895865713397,
      "grad_norm": 0.3774886131286621,
      "learning_rate": 6.122552067143301e-06,
      "loss": 0.1243,
      "step": 9979
    },
    {
      "epoch": 0.7755672987255207,
      "grad_norm": 0.2189732789993286,
      "learning_rate": 6.122163506372397e-06,
      "loss": 0.1561,
      "step": 9980
    },
    {
      "epoch": 0.7756450108797016,
      "grad_norm": 0.4621480703353882,
      "learning_rate": 6.121774945601493e-06,
      "loss": 0.2456,
      "step": 9981
    },
    {
      "epoch": 0.7757227230338825,
      "grad_norm": 0.5232741832733154,
      "learning_rate": 6.121386384830588e-06,
      "loss": 0.0798,
      "step": 9982
    },
    {
      "epoch": 0.7758004351880634,
      "grad_norm": 0.3072409927845001,
      "learning_rate": 6.120997824059684e-06,
      "loss": 0.0664,
      "step": 9983
    },
    {
      "epoch": 0.7758781473422444,
      "grad_norm": 0.4023606479167938,
      "learning_rate": 6.1206092632887795e-06,
      "loss": 0.1112,
      "step": 9984
    },
    {
      "epoch": 0.7759558594964252,
      "grad_norm": 0.368389368057251,
      "learning_rate": 6.120220702517874e-06,
      "loss": 0.2358,
      "step": 9985
    },
    {
      "epoch": 0.7760335716506062,
      "grad_norm": 0.2041987031698227,
      "learning_rate": 6.119832141746969e-06,
      "loss": 0.1477,
      "step": 9986
    },
    {
      "epoch": 0.7761112838047871,
      "grad_norm": 0.45252570509910583,
      "learning_rate": 6.119443580976065e-06,
      "loss": 0.102,
      "step": 9987
    },
    {
      "epoch": 0.776188995958968,
      "grad_norm": 0.30545809864997864,
      "learning_rate": 6.11905502020516e-06,
      "loss": 0.0543,
      "step": 9988
    },
    {
      "epoch": 0.7762667081131489,
      "grad_norm": 0.09264355897903442,
      "learning_rate": 6.118666459434256e-06,
      "loss": 0.0219,
      "step": 9989
    },
    {
      "epoch": 0.7763444202673299,
      "grad_norm": 0.23269829154014587,
      "learning_rate": 6.118277898663352e-06,
      "loss": 0.0919,
      "step": 9990
    },
    {
      "epoch": 0.7764221324215107,
      "grad_norm": 0.2766501307487488,
      "learning_rate": 6.117889337892447e-06,
      "loss": 0.1928,
      "step": 9991
    },
    {
      "epoch": 0.7764998445756917,
      "grad_norm": 0.0485641248524189,
      "learning_rate": 6.1175007771215425e-06,
      "loss": 0.0141,
      "step": 9992
    },
    {
      "epoch": 0.7765775567298725,
      "grad_norm": 0.1464722454547882,
      "learning_rate": 6.117112216350638e-06,
      "loss": 0.0233,
      "step": 9993
    },
    {
      "epoch": 0.7766552688840535,
      "grad_norm": 0.7737910747528076,
      "learning_rate": 6.116723655579732e-06,
      "loss": 0.1642,
      "step": 9994
    },
    {
      "epoch": 0.7767329810382344,
      "grad_norm": 0.1747787892818451,
      "learning_rate": 6.116335094808828e-06,
      "loss": 0.0484,
      "step": 9995
    },
    {
      "epoch": 0.7768106931924152,
      "grad_norm": 0.3433472812175751,
      "learning_rate": 6.115946534037924e-06,
      "loss": 0.17,
      "step": 9996
    },
    {
      "epoch": 0.7768884053465962,
      "grad_norm": 0.3597218692302704,
      "learning_rate": 6.115557973267019e-06,
      "loss": 0.1391,
      "step": 9997
    },
    {
      "epoch": 0.7769661175007772,
      "grad_norm": 0.5662817358970642,
      "learning_rate": 6.115169412496115e-06,
      "loss": 0.3479,
      "step": 9998
    },
    {
      "epoch": 0.777043829654958,
      "grad_norm": 0.13496725261211395,
      "learning_rate": 6.1147808517252105e-06,
      "loss": 0.0171,
      "step": 9999
    },
    {
      "epoch": 0.777121541809139,
      "grad_norm": 0.5780426263809204,
      "learning_rate": 6.1143922909543055e-06,
      "loss": 0.1915,
      "step": 10000
    },
    {
      "epoch": 0.7771992539633199,
      "grad_norm": 0.3101113438606262,
      "learning_rate": 6.114003730183401e-06,
      "loss": 0.1789,
      "step": 10001
    },
    {
      "epoch": 0.7772769661175007,
      "grad_norm": 0.45223599672317505,
      "learning_rate": 6.113615169412497e-06,
      "loss": 0.164,
      "step": 10002
    },
    {
      "epoch": 0.7773546782716817,
      "grad_norm": 0.4394250810146332,
      "learning_rate": 6.113226608641593e-06,
      "loss": 0.2519,
      "step": 10003
    },
    {
      "epoch": 0.7774323904258627,
      "grad_norm": 0.36164796352386475,
      "learning_rate": 6.112838047870687e-06,
      "loss": 0.2767,
      "step": 10004
    },
    {
      "epoch": 0.7775101025800435,
      "grad_norm": 0.8436589241027832,
      "learning_rate": 6.112449487099783e-06,
      "loss": 0.5178,
      "step": 10005
    },
    {
      "epoch": 0.7775878147342244,
      "grad_norm": 0.1344144344329834,
      "learning_rate": 6.1120609263288786e-06,
      "loss": 0.0309,
      "step": 10006
    },
    {
      "epoch": 0.7776655268884054,
      "grad_norm": 0.17730845510959625,
      "learning_rate": 6.1116723655579735e-06,
      "loss": 0.0575,
      "step": 10007
    },
    {
      "epoch": 0.7777432390425862,
      "grad_norm": 0.5173770189285278,
      "learning_rate": 6.111283804787069e-06,
      "loss": 0.0453,
      "step": 10008
    },
    {
      "epoch": 0.7778209511967672,
      "grad_norm": 0.022247647866606712,
      "learning_rate": 6.110895244016165e-06,
      "loss": 0.0024,
      "step": 10009
    },
    {
      "epoch": 0.777898663350948,
      "grad_norm": 0.790076732635498,
      "learning_rate": 6.11050668324526e-06,
      "loss": 0.209,
      "step": 10010
    },
    {
      "epoch": 0.777976375505129,
      "grad_norm": 0.5082750916481018,
      "learning_rate": 6.110118122474356e-06,
      "loss": 0.2601,
      "step": 10011
    },
    {
      "epoch": 0.77805408765931,
      "grad_norm": 1.6329617500305176,
      "learning_rate": 6.109729561703452e-06,
      "loss": 0.3475,
      "step": 10012
    },
    {
      "epoch": 0.7781317998134908,
      "grad_norm": 0.09794981777667999,
      "learning_rate": 6.109341000932546e-06,
      "loss": 0.0166,
      "step": 10013
    },
    {
      "epoch": 0.7782095119676717,
      "grad_norm": 0.12057141214609146,
      "learning_rate": 6.1089524401616416e-06,
      "loss": 0.0455,
      "step": 10014
    },
    {
      "epoch": 0.7782872241218527,
      "grad_norm": 0.08542483299970627,
      "learning_rate": 6.108563879390737e-06,
      "loss": 0.0532,
      "step": 10015
    },
    {
      "epoch": 0.7783649362760335,
      "grad_norm": 0.4458090364933014,
      "learning_rate": 6.108175318619832e-06,
      "loss": 0.2917,
      "step": 10016
    },
    {
      "epoch": 0.7784426484302145,
      "grad_norm": 0.1983063966035843,
      "learning_rate": 6.107786757848928e-06,
      "loss": 0.0927,
      "step": 10017
    },
    {
      "epoch": 0.7785203605843954,
      "grad_norm": 0.25259333848953247,
      "learning_rate": 6.107398197078024e-06,
      "loss": 0.1413,
      "step": 10018
    },
    {
      "epoch": 0.7785980727385763,
      "grad_norm": 0.21642890572547913,
      "learning_rate": 6.107009636307119e-06,
      "loss": 0.1193,
      "step": 10019
    },
    {
      "epoch": 0.7786757848927572,
      "grad_norm": 0.397085040807724,
      "learning_rate": 6.106621075536215e-06,
      "loss": 0.2368,
      "step": 10020
    },
    {
      "epoch": 0.7787534970469382,
      "grad_norm": 0.4007759690284729,
      "learning_rate": 6.1062325147653104e-06,
      "loss": 0.5159,
      "step": 10021
    },
    {
      "epoch": 0.778831209201119,
      "grad_norm": 0.6416237950325012,
      "learning_rate": 6.1058439539944045e-06,
      "loss": 0.3833,
      "step": 10022
    },
    {
      "epoch": 0.7789089213553,
      "grad_norm": 0.5458231568336487,
      "learning_rate": 6.1054553932235e-06,
      "loss": 0.2781,
      "step": 10023
    },
    {
      "epoch": 0.7789866335094808,
      "grad_norm": 0.5862765312194824,
      "learning_rate": 6.105066832452596e-06,
      "loss": 0.3499,
      "step": 10024
    },
    {
      "epoch": 0.7790643456636618,
      "grad_norm": 0.3691270351409912,
      "learning_rate": 6.104678271681691e-06,
      "loss": 0.2255,
      "step": 10025
    },
    {
      "epoch": 0.7791420578178427,
      "grad_norm": 0.5892708897590637,
      "learning_rate": 6.104289710910787e-06,
      "loss": 0.3498,
      "step": 10026
    },
    {
      "epoch": 0.7792197699720236,
      "grad_norm": 1.0718451738357544,
      "learning_rate": 6.103901150139883e-06,
      "loss": 0.3337,
      "step": 10027
    },
    {
      "epoch": 0.7792974821262045,
      "grad_norm": 0.36900749802589417,
      "learning_rate": 6.103512589368978e-06,
      "loss": 0.3785,
      "step": 10028
    },
    {
      "epoch": 0.7793751942803855,
      "grad_norm": 0.5370480418205261,
      "learning_rate": 6.1031240285980734e-06,
      "loss": 0.7292,
      "step": 10029
    },
    {
      "epoch": 0.7794529064345663,
      "grad_norm": 0.2649962902069092,
      "learning_rate": 6.102735467827169e-06,
      "loss": 0.1691,
      "step": 10030
    },
    {
      "epoch": 0.7795306185887473,
      "grad_norm": 0.20011021196842194,
      "learning_rate": 6.102346907056265e-06,
      "loss": 0.0769,
      "step": 10031
    },
    {
      "epoch": 0.7796083307429282,
      "grad_norm": 0.6290999054908752,
      "learning_rate": 6.101958346285359e-06,
      "loss": 0.5767,
      "step": 10032
    },
    {
      "epoch": 0.7796860428971091,
      "grad_norm": 0.27160537242889404,
      "learning_rate": 6.101569785514455e-06,
      "loss": 0.1129,
      "step": 10033
    },
    {
      "epoch": 0.77976375505129,
      "grad_norm": 0.23720254004001617,
      "learning_rate": 6.101181224743551e-06,
      "loss": 0.1215,
      "step": 10034
    },
    {
      "epoch": 0.779841467205471,
      "grad_norm": 0.3727778196334839,
      "learning_rate": 6.100792663972646e-06,
      "loss": 0.1992,
      "step": 10035
    },
    {
      "epoch": 0.7799191793596518,
      "grad_norm": 0.409235417842865,
      "learning_rate": 6.1004041032017415e-06,
      "loss": 0.243,
      "step": 10036
    },
    {
      "epoch": 0.7799968915138328,
      "grad_norm": 0.3494841158390045,
      "learning_rate": 6.100015542430837e-06,
      "loss": 0.1449,
      "step": 10037
    },
    {
      "epoch": 0.7800746036680136,
      "grad_norm": 0.1436992883682251,
      "learning_rate": 6.099626981659932e-06,
      "loss": 0.0485,
      "step": 10038
    },
    {
      "epoch": 0.7801523158221946,
      "grad_norm": 0.24049782752990723,
      "learning_rate": 6.099238420889028e-06,
      "loss": 0.1822,
      "step": 10039
    },
    {
      "epoch": 0.7802300279763755,
      "grad_norm": 0.3832876682281494,
      "learning_rate": 6.098849860118124e-06,
      "loss": 0.1238,
      "step": 10040
    },
    {
      "epoch": 0.7803077401305564,
      "grad_norm": 0.5436640381813049,
      "learning_rate": 6.098461299347218e-06,
      "loss": 0.1243,
      "step": 10041
    },
    {
      "epoch": 0.7803854522847373,
      "grad_norm": 0.28665292263031006,
      "learning_rate": 6.098072738576314e-06,
      "loss": 0.0401,
      "step": 10042
    },
    {
      "epoch": 0.7804631644389183,
      "grad_norm": 0.4815478026866913,
      "learning_rate": 6.0976841778054095e-06,
      "loss": 0.1912,
      "step": 10043
    },
    {
      "epoch": 0.7805408765930991,
      "grad_norm": 0.7702454328536987,
      "learning_rate": 6.0972956170345044e-06,
      "loss": 0.6989,
      "step": 10044
    },
    {
      "epoch": 0.7806185887472801,
      "grad_norm": 0.45533251762390137,
      "learning_rate": 6.0969070562636e-06,
      "loss": 0.1817,
      "step": 10045
    },
    {
      "epoch": 0.780696300901461,
      "grad_norm": 0.4226594865322113,
      "learning_rate": 6.096518495492696e-06,
      "loss": 0.2494,
      "step": 10046
    },
    {
      "epoch": 0.7807740130556419,
      "grad_norm": 0.6199240684509277,
      "learning_rate": 6.096129934721791e-06,
      "loss": 0.1649,
      "step": 10047
    },
    {
      "epoch": 0.7808517252098228,
      "grad_norm": 0.398721843957901,
      "learning_rate": 6.095741373950887e-06,
      "loss": 0.0921,
      "step": 10048
    },
    {
      "epoch": 0.7809294373640038,
      "grad_norm": 0.7750232815742493,
      "learning_rate": 6.095352813179983e-06,
      "loss": 0.187,
      "step": 10049
    },
    {
      "epoch": 0.7810071495181846,
      "grad_norm": 0.7535561919212341,
      "learning_rate": 6.094964252409077e-06,
      "loss": 0.3024,
      "step": 10050
    },
    {
      "epoch": 0.7810848616723656,
      "grad_norm": 0.2656760513782501,
      "learning_rate": 6.0945756916381725e-06,
      "loss": 0.1779,
      "step": 10051
    },
    {
      "epoch": 0.7811625738265465,
      "grad_norm": 0.4825591444969177,
      "learning_rate": 6.094187130867268e-06,
      "loss": 0.0541,
      "step": 10052
    },
    {
      "epoch": 0.7812402859807274,
      "grad_norm": 0.3267687261104584,
      "learning_rate": 6.093798570096363e-06,
      "loss": 0.0887,
      "step": 10053
    },
    {
      "epoch": 0.7813179981349083,
      "grad_norm": 0.22585226595401764,
      "learning_rate": 6.093410009325459e-06,
      "loss": 0.1614,
      "step": 10054
    },
    {
      "epoch": 0.7813957102890892,
      "grad_norm": 0.32659149169921875,
      "learning_rate": 6.093021448554555e-06,
      "loss": 0.1481,
      "step": 10055
    },
    {
      "epoch": 0.7814734224432701,
      "grad_norm": 1.39397394657135,
      "learning_rate": 6.09263288778365e-06,
      "loss": 0.8703,
      "step": 10056
    },
    {
      "epoch": 0.7815511345974511,
      "grad_norm": 0.26767852902412415,
      "learning_rate": 6.0922443270127456e-06,
      "loss": 0.1124,
      "step": 10057
    },
    {
      "epoch": 0.7816288467516319,
      "grad_norm": 0.22443605959415436,
      "learning_rate": 6.0918557662418405e-06,
      "loss": 0.0849,
      "step": 10058
    },
    {
      "epoch": 0.7817065589058129,
      "grad_norm": 0.7239276170730591,
      "learning_rate": 6.0914672054709355e-06,
      "loss": 0.1664,
      "step": 10059
    },
    {
      "epoch": 0.7817842710599938,
      "grad_norm": 0.13302816450595856,
      "learning_rate": 6.091078644700031e-06,
      "loss": 0.0236,
      "step": 10060
    },
    {
      "epoch": 0.7818619832141747,
      "grad_norm": 0.31772100925445557,
      "learning_rate": 6.090690083929127e-06,
      "loss": 0.0706,
      "step": 10061
    },
    {
      "epoch": 0.7819396953683556,
      "grad_norm": 0.2114778608083725,
      "learning_rate": 6.090301523158223e-06,
      "loss": 0.0522,
      "step": 10062
    },
    {
      "epoch": 0.7820174075225366,
      "grad_norm": 0.09580185264348984,
      "learning_rate": 6.089912962387318e-06,
      "loss": 0.0138,
      "step": 10063
    },
    {
      "epoch": 0.7820951196767174,
      "grad_norm": 0.4844273626804352,
      "learning_rate": 6.089524401616414e-06,
      "loss": 0.4418,
      "step": 10064
    },
    {
      "epoch": 0.7821728318308984,
      "grad_norm": 0.5097187161445618,
      "learning_rate": 6.089135840845509e-06,
      "loss": 0.1737,
      "step": 10065
    },
    {
      "epoch": 0.7822505439850793,
      "grad_norm": 0.43587133288383484,
      "learning_rate": 6.0887472800746035e-06,
      "loss": 0.2033,
      "step": 10066
    },
    {
      "epoch": 0.7823282561392602,
      "grad_norm": 0.7473120093345642,
      "learning_rate": 6.088358719303699e-06,
      "loss": 0.0997,
      "step": 10067
    },
    {
      "epoch": 0.7824059682934411,
      "grad_norm": 0.540486752986908,
      "learning_rate": 6.087970158532795e-06,
      "loss": 0.3367,
      "step": 10068
    },
    {
      "epoch": 0.782483680447622,
      "grad_norm": 0.42595648765563965,
      "learning_rate": 6.08758159776189e-06,
      "loss": 0.1128,
      "step": 10069
    },
    {
      "epoch": 0.7825613926018029,
      "grad_norm": 0.5233550071716309,
      "learning_rate": 6.087193036990986e-06,
      "loss": 0.3404,
      "step": 10070
    },
    {
      "epoch": 0.7826391047559839,
      "grad_norm": 0.22037743031978607,
      "learning_rate": 6.086804476220082e-06,
      "loss": 0.0542,
      "step": 10071
    },
    {
      "epoch": 0.7827168169101647,
      "grad_norm": 0.5386529564857483,
      "learning_rate": 6.086415915449177e-06,
      "loss": 0.2173,
      "step": 10072
    },
    {
      "epoch": 0.7827945290643457,
      "grad_norm": 0.34298402070999146,
      "learning_rate": 6.086027354678272e-06,
      "loss": 0.2322,
      "step": 10073
    },
    {
      "epoch": 0.7828722412185266,
      "grad_norm": 0.3066932260990143,
      "learning_rate": 6.085638793907368e-06,
      "loss": 0.1318,
      "step": 10074
    },
    {
      "epoch": 0.7829499533727075,
      "grad_norm": 0.06530281901359558,
      "learning_rate": 6.085250233136462e-06,
      "loss": 0.0062,
      "step": 10075
    },
    {
      "epoch": 0.7830276655268884,
      "grad_norm": 0.15148788690567017,
      "learning_rate": 6.084861672365558e-06,
      "loss": 0.0493,
      "step": 10076
    },
    {
      "epoch": 0.7831053776810694,
      "grad_norm": 0.16564905643463135,
      "learning_rate": 6.084473111594654e-06,
      "loss": 0.0987,
      "step": 10077
    },
    {
      "epoch": 0.7831830898352502,
      "grad_norm": 0.2882753610610962,
      "learning_rate": 6.084084550823749e-06,
      "loss": 0.1313,
      "step": 10078
    },
    {
      "epoch": 0.7832608019894312,
      "grad_norm": 0.5401512980461121,
      "learning_rate": 6.083695990052845e-06,
      "loss": 0.1675,
      "step": 10079
    },
    {
      "epoch": 0.7833385141436121,
      "grad_norm": 1.5018872022628784,
      "learning_rate": 6.0833074292819404e-06,
      "loss": 0.5737,
      "step": 10080
    },
    {
      "epoch": 0.783416226297793,
      "grad_norm": 0.059396062046289444,
      "learning_rate": 6.082918868511035e-06,
      "loss": 0.0092,
      "step": 10081
    },
    {
      "epoch": 0.7834939384519739,
      "grad_norm": 0.3511892259120941,
      "learning_rate": 6.082530307740131e-06,
      "loss": 0.5518,
      "step": 10082
    },
    {
      "epoch": 0.7835716506061549,
      "grad_norm": 0.6263221502304077,
      "learning_rate": 6.082141746969227e-06,
      "loss": 0.2053,
      "step": 10083
    },
    {
      "epoch": 0.7836493627603357,
      "grad_norm": 1.0940676927566528,
      "learning_rate": 6.081753186198321e-06,
      "loss": 0.118,
      "step": 10084
    },
    {
      "epoch": 0.7837270749145167,
      "grad_norm": 0.3991943299770355,
      "learning_rate": 6.081364625427417e-06,
      "loss": 0.4648,
      "step": 10085
    },
    {
      "epoch": 0.7838047870686975,
      "grad_norm": 0.24533040821552277,
      "learning_rate": 6.080976064656513e-06,
      "loss": 0.0531,
      "step": 10086
    },
    {
      "epoch": 0.7838824992228784,
      "grad_norm": 0.08645158261060715,
      "learning_rate": 6.080587503885608e-06,
      "loss": 0.0156,
      "step": 10087
    },
    {
      "epoch": 0.7839602113770594,
      "grad_norm": 0.33216115832328796,
      "learning_rate": 6.080198943114703e-06,
      "loss": 0.2316,
      "step": 10088
    },
    {
      "epoch": 0.7840379235312402,
      "grad_norm": 0.4924401044845581,
      "learning_rate": 6.079810382343799e-06,
      "loss": 0.1168,
      "step": 10089
    },
    {
      "epoch": 0.7841156356854212,
      "grad_norm": 0.15928421914577484,
      "learning_rate": 6.079421821572894e-06,
      "loss": 0.0456,
      "step": 10090
    },
    {
      "epoch": 0.7841933478396022,
      "grad_norm": 0.6888230443000793,
      "learning_rate": 6.07903326080199e-06,
      "loss": 0.2686,
      "step": 10091
    },
    {
      "epoch": 0.784271059993783,
      "grad_norm": 0.5564854145050049,
      "learning_rate": 6.078644700031086e-06,
      "loss": 0.4231,
      "step": 10092
    },
    {
      "epoch": 0.784348772147964,
      "grad_norm": 0.23865588009357452,
      "learning_rate": 6.0782561392601816e-06,
      "loss": 0.0484,
      "step": 10093
    },
    {
      "epoch": 0.7844264843021449,
      "grad_norm": 0.1286085844039917,
      "learning_rate": 6.077867578489276e-06,
      "loss": 0.0745,
      "step": 10094
    },
    {
      "epoch": 0.7845041964563257,
      "grad_norm": 0.20619714260101318,
      "learning_rate": 6.0774790177183715e-06,
      "loss": 0.0555,
      "step": 10095
    },
    {
      "epoch": 0.7845819086105067,
      "grad_norm": 0.1825917512178421,
      "learning_rate": 6.077090456947467e-06,
      "loss": 0.0419,
      "step": 10096
    },
    {
      "epoch": 0.7846596207646876,
      "grad_norm": 0.6257739663124084,
      "learning_rate": 6.076701896176562e-06,
      "loss": 0.4522,
      "step": 10097
    },
    {
      "epoch": 0.7847373329188685,
      "grad_norm": 0.7524175047874451,
      "learning_rate": 6.076313335405658e-06,
      "loss": 0.7205,
      "step": 10098
    },
    {
      "epoch": 0.7848150450730494,
      "grad_norm": 0.11413954198360443,
      "learning_rate": 6.075924774634754e-06,
      "loss": 0.0517,
      "step": 10099
    },
    {
      "epoch": 0.7848927572272303,
      "grad_norm": 0.636796236038208,
      "learning_rate": 6.075536213863849e-06,
      "loss": 0.1527,
      "step": 10100
    },
    {
      "epoch": 0.7849704693814112,
      "grad_norm": 0.8144322633743286,
      "learning_rate": 6.0751476530929445e-06,
      "loss": 0.7968,
      "step": 10101
    },
    {
      "epoch": 0.7850481815355922,
      "grad_norm": 0.4896320104598999,
      "learning_rate": 6.07475909232204e-06,
      "loss": 0.733,
      "step": 10102
    },
    {
      "epoch": 0.785125893689773,
      "grad_norm": 0.1780214160680771,
      "learning_rate": 6.0743705315511344e-06,
      "loss": 0.0976,
      "step": 10103
    },
    {
      "epoch": 0.785203605843954,
      "grad_norm": 1.3362152576446533,
      "learning_rate": 6.07398197078023e-06,
      "loss": 0.3443,
      "step": 10104
    },
    {
      "epoch": 0.7852813179981349,
      "grad_norm": 0.27871084213256836,
      "learning_rate": 6.073593410009326e-06,
      "loss": 0.0542,
      "step": 10105
    },
    {
      "epoch": 0.7853590301523158,
      "grad_norm": 0.05531848594546318,
      "learning_rate": 6.073204849238421e-06,
      "loss": 0.0029,
      "step": 10106
    },
    {
      "epoch": 0.7854367423064967,
      "grad_norm": 0.5930045247077942,
      "learning_rate": 6.072816288467517e-06,
      "loss": 0.1464,
      "step": 10107
    },
    {
      "epoch": 0.7855144544606777,
      "grad_norm": 0.2540662884712219,
      "learning_rate": 6.0724277276966126e-06,
      "loss": 0.0678,
      "step": 10108
    },
    {
      "epoch": 0.7855921666148585,
      "grad_norm": 0.5497061014175415,
      "learning_rate": 6.0720391669257075e-06,
      "loss": 0.49,
      "step": 10109
    },
    {
      "epoch": 0.7856698787690395,
      "grad_norm": 0.2025250941514969,
      "learning_rate": 6.071650606154803e-06,
      "loss": 0.0812,
      "step": 10110
    },
    {
      "epoch": 0.7857475909232204,
      "grad_norm": 0.29380837082862854,
      "learning_rate": 6.071262045383899e-06,
      "loss": 0.0883,
      "step": 10111
    },
    {
      "epoch": 0.7858253030774013,
      "grad_norm": 0.07713768631219864,
      "learning_rate": 6.070873484612993e-06,
      "loss": 0.0097,
      "step": 10112
    },
    {
      "epoch": 0.7859030152315822,
      "grad_norm": 0.4787253737449646,
      "learning_rate": 6.070484923842089e-06,
      "loss": 0.2404,
      "step": 10113
    },
    {
      "epoch": 0.7859807273857631,
      "grad_norm": 0.14354203641414642,
      "learning_rate": 6.070096363071185e-06,
      "loss": 0.0385,
      "step": 10114
    },
    {
      "epoch": 0.786058439539944,
      "grad_norm": 0.28686636686325073,
      "learning_rate": 6.06970780230028e-06,
      "loss": 0.0788,
      "step": 10115
    },
    {
      "epoch": 0.786136151694125,
      "grad_norm": 0.4832043945789337,
      "learning_rate": 6.0693192415293756e-06,
      "loss": 0.1807,
      "step": 10116
    },
    {
      "epoch": 0.7862138638483058,
      "grad_norm": 0.05824514105916023,
      "learning_rate": 6.068930680758471e-06,
      "loss": 0.0071,
      "step": 10117
    },
    {
      "epoch": 0.7862915760024868,
      "grad_norm": 0.9083471298217773,
      "learning_rate": 6.068542119987566e-06,
      "loss": 0.7547,
      "step": 10118
    },
    {
      "epoch": 0.7863692881566677,
      "grad_norm": 0.32014432549476624,
      "learning_rate": 6.068153559216662e-06,
      "loss": 0.1422,
      "step": 10119
    },
    {
      "epoch": 0.7864470003108486,
      "grad_norm": 0.2749173641204834,
      "learning_rate": 6.067764998445758e-06,
      "loss": 0.1329,
      "step": 10120
    },
    {
      "epoch": 0.7865247124650295,
      "grad_norm": 0.2917475998401642,
      "learning_rate": 6.067376437674852e-06,
      "loss": 0.069,
      "step": 10121
    },
    {
      "epoch": 0.7866024246192105,
      "grad_norm": 0.4443449378013611,
      "learning_rate": 6.066987876903948e-06,
      "loss": 0.2814,
      "step": 10122
    },
    {
      "epoch": 0.7866801367733913,
      "grad_norm": 0.83077073097229,
      "learning_rate": 6.066599316133044e-06,
      "loss": 0.8662,
      "step": 10123
    },
    {
      "epoch": 0.7867578489275723,
      "grad_norm": 0.5919342637062073,
      "learning_rate": 6.066210755362139e-06,
      "loss": 0.246,
      "step": 10124
    },
    {
      "epoch": 0.7868355610817532,
      "grad_norm": 0.1962406188249588,
      "learning_rate": 6.065822194591234e-06,
      "loss": 0.0715,
      "step": 10125
    },
    {
      "epoch": 0.7869132732359341,
      "grad_norm": 0.29146403074264526,
      "learning_rate": 6.06543363382033e-06,
      "loss": 0.0929,
      "step": 10126
    },
    {
      "epoch": 0.786990985390115,
      "grad_norm": 0.36051467061042786,
      "learning_rate": 6.065045073049426e-06,
      "loss": 0.0808,
      "step": 10127
    },
    {
      "epoch": 0.787068697544296,
      "grad_norm": 0.3773493766784668,
      "learning_rate": 6.064656512278521e-06,
      "loss": 0.1553,
      "step": 10128
    },
    {
      "epoch": 0.7871464096984768,
      "grad_norm": 0.19601403176784515,
      "learning_rate": 6.064267951507617e-06,
      "loss": 0.0611,
      "step": 10129
    },
    {
      "epoch": 0.7872241218526578,
      "grad_norm": 0.24559833109378815,
      "learning_rate": 6.0638793907367125e-06,
      "loss": 0.0467,
      "step": 10130
    },
    {
      "epoch": 0.7873018340068386,
      "grad_norm": 0.665638267993927,
      "learning_rate": 6.063490829965807e-06,
      "loss": 0.1122,
      "step": 10131
    },
    {
      "epoch": 0.7873795461610196,
      "grad_norm": 0.5560951828956604,
      "learning_rate": 6.063102269194902e-06,
      "loss": 0.5485,
      "step": 10132
    },
    {
      "epoch": 0.7874572583152005,
      "grad_norm": 0.19977807998657227,
      "learning_rate": 6.062713708423998e-06,
      "loss": 0.0747,
      "step": 10133
    },
    {
      "epoch": 0.7875349704693814,
      "grad_norm": 0.7793405652046204,
      "learning_rate": 6.062325147653093e-06,
      "loss": 0.3702,
      "step": 10134
    },
    {
      "epoch": 0.7876126826235623,
      "grad_norm": 0.8482582569122314,
      "learning_rate": 6.061936586882189e-06,
      "loss": 0.2364,
      "step": 10135
    },
    {
      "epoch": 0.7876903947777433,
      "grad_norm": 0.192386195063591,
      "learning_rate": 6.061548026111285e-06,
      "loss": 0.0212,
      "step": 10136
    },
    {
      "epoch": 0.7877681069319241,
      "grad_norm": 0.36006981134414673,
      "learning_rate": 6.06115946534038e-06,
      "loss": 0.0979,
      "step": 10137
    },
    {
      "epoch": 0.7878458190861051,
      "grad_norm": 0.3105109632015228,
      "learning_rate": 6.0607709045694755e-06,
      "loss": 0.2818,
      "step": 10138
    },
    {
      "epoch": 0.787923531240286,
      "grad_norm": 0.209437295794487,
      "learning_rate": 6.060382343798571e-06,
      "loss": 0.1502,
      "step": 10139
    },
    {
      "epoch": 0.7880012433944669,
      "grad_norm": 0.9559831023216248,
      "learning_rate": 6.059993783027665e-06,
      "loss": 0.7015,
      "step": 10140
    },
    {
      "epoch": 0.7880789555486478,
      "grad_norm": 0.8139141201972961,
      "learning_rate": 6.059605222256761e-06,
      "loss": 0.2336,
      "step": 10141
    },
    {
      "epoch": 0.7881566677028288,
      "grad_norm": 0.1079695075750351,
      "learning_rate": 6.059216661485857e-06,
      "loss": 0.0392,
      "step": 10142
    },
    {
      "epoch": 0.7882343798570096,
      "grad_norm": 0.3619202971458435,
      "learning_rate": 6.058828100714952e-06,
      "loss": 0.1903,
      "step": 10143
    },
    {
      "epoch": 0.7883120920111906,
      "grad_norm": 0.24369758367538452,
      "learning_rate": 6.058439539944048e-06,
      "loss": 0.1804,
      "step": 10144
    },
    {
      "epoch": 0.7883898041653714,
      "grad_norm": 4.081308841705322,
      "learning_rate": 6.0580509791731435e-06,
      "loss": 3.177,
      "step": 10145
    },
    {
      "epoch": 0.7884675163195524,
      "grad_norm": 0.19256217777729034,
      "learning_rate": 6.0576624184022385e-06,
      "loss": 0.0641,
      "step": 10146
    },
    {
      "epoch": 0.7885452284737333,
      "grad_norm": 0.3437851369380951,
      "learning_rate": 6.057273857631334e-06,
      "loss": 0.0811,
      "step": 10147
    },
    {
      "epoch": 0.7886229406279142,
      "grad_norm": 0.16923050582408905,
      "learning_rate": 6.05688529686043e-06,
      "loss": 0.0337,
      "step": 10148
    },
    {
      "epoch": 0.7887006527820951,
      "grad_norm": 2.184124231338501,
      "learning_rate": 6.056496736089524e-06,
      "loss": 0.6419,
      "step": 10149
    },
    {
      "epoch": 0.7887783649362761,
      "grad_norm": 0.24174030125141144,
      "learning_rate": 6.05610817531862e-06,
      "loss": 0.0549,
      "step": 10150
    },
    {
      "epoch": 0.7888560770904569,
      "grad_norm": 0.10382702946662903,
      "learning_rate": 6.055719614547716e-06,
      "loss": 0.0252,
      "step": 10151
    },
    {
      "epoch": 0.7889337892446379,
      "grad_norm": 0.14537402987480164,
      "learning_rate": 6.0553310537768115e-06,
      "loss": 0.022,
      "step": 10152
    },
    {
      "epoch": 0.7890115013988188,
      "grad_norm": 0.1327955573797226,
      "learning_rate": 6.0549424930059065e-06,
      "loss": 0.0404,
      "step": 10153
    },
    {
      "epoch": 0.7890892135529997,
      "grad_norm": 0.3282149136066437,
      "learning_rate": 6.054553932235002e-06,
      "loss": 0.0439,
      "step": 10154
    },
    {
      "epoch": 0.7891669257071806,
      "grad_norm": 0.14779767394065857,
      "learning_rate": 6.054165371464098e-06,
      "loss": 0.1134,
      "step": 10155
    },
    {
      "epoch": 0.7892446378613616,
      "grad_norm": 0.27485188841819763,
      "learning_rate": 6.053776810693193e-06,
      "loss": 0.0905,
      "step": 10156
    },
    {
      "epoch": 0.7893223500155424,
      "grad_norm": 0.38893502950668335,
      "learning_rate": 6.053388249922289e-06,
      "loss": 0.2118,
      "step": 10157
    },
    {
      "epoch": 0.7894000621697234,
      "grad_norm": 0.7871388792991638,
      "learning_rate": 6.052999689151385e-06,
      "loss": 0.2837,
      "step": 10158
    },
    {
      "epoch": 0.7894777743239043,
      "grad_norm": 0.5718713402748108,
      "learning_rate": 6.052611128380479e-06,
      "loss": 0.2372,
      "step": 10159
    },
    {
      "epoch": 0.7895554864780852,
      "grad_norm": 0.17006541788578033,
      "learning_rate": 6.0522225676095745e-06,
      "loss": 0.0529,
      "step": 10160
    },
    {
      "epoch": 0.7896331986322661,
      "grad_norm": 0.49967801570892334,
      "learning_rate": 6.05183400683867e-06,
      "loss": 0.2466,
      "step": 10161
    },
    {
      "epoch": 0.789710910786447,
      "grad_norm": 0.2804664969444275,
      "learning_rate": 6.051445446067765e-06,
      "loss": 0.0603,
      "step": 10162
    },
    {
      "epoch": 0.7897886229406279,
      "grad_norm": 0.2524251639842987,
      "learning_rate": 6.051056885296861e-06,
      "loss": 0.0534,
      "step": 10163
    },
    {
      "epoch": 0.7898663350948089,
      "grad_norm": 0.4642575979232788,
      "learning_rate": 6.050668324525957e-06,
      "loss": 0.0748,
      "step": 10164
    },
    {
      "epoch": 0.7899440472489897,
      "grad_norm": 0.4367585778236389,
      "learning_rate": 6.050279763755052e-06,
      "loss": 0.1471,
      "step": 10165
    },
    {
      "epoch": 0.7900217594031707,
      "grad_norm": 0.23677054047584534,
      "learning_rate": 6.049891202984148e-06,
      "loss": 0.1148,
      "step": 10166
    },
    {
      "epoch": 0.7900994715573516,
      "grad_norm": 0.3951444625854492,
      "learning_rate": 6.049502642213243e-06,
      "loss": 0.048,
      "step": 10167
    },
    {
      "epoch": 0.7901771837115324,
      "grad_norm": 0.14766982197761536,
      "learning_rate": 6.0491140814423375e-06,
      "loss": 0.0669,
      "step": 10168
    },
    {
      "epoch": 0.7902548958657134,
      "grad_norm": 0.8532231450080872,
      "learning_rate": 6.048725520671433e-06,
      "loss": 0.5538,
      "step": 10169
    },
    {
      "epoch": 0.7903326080198944,
      "grad_norm": 0.3022864758968353,
      "learning_rate": 6.048336959900529e-06,
      "loss": 0.106,
      "step": 10170
    },
    {
      "epoch": 0.7904103201740752,
      "grad_norm": 11.943754196166992,
      "learning_rate": 6.047948399129624e-06,
      "loss": 4.187,
      "step": 10171
    },
    {
      "epoch": 0.7904880323282562,
      "grad_norm": 0.42648452520370483,
      "learning_rate": 6.04755983835872e-06,
      "loss": 0.4029,
      "step": 10172
    },
    {
      "epoch": 0.7905657444824371,
      "grad_norm": 0.2864629328250885,
      "learning_rate": 6.047171277587816e-06,
      "loss": 0.1117,
      "step": 10173
    },
    {
      "epoch": 0.790643456636618,
      "grad_norm": 0.14941050112247467,
      "learning_rate": 6.046782716816911e-06,
      "loss": 0.0549,
      "step": 10174
    },
    {
      "epoch": 0.7907211687907989,
      "grad_norm": 0.6768375635147095,
      "learning_rate": 6.046394156046006e-06,
      "loss": 0.6909,
      "step": 10175
    },
    {
      "epoch": 0.7907988809449797,
      "grad_norm": 1.1528105735778809,
      "learning_rate": 6.046005595275102e-06,
      "loss": 0.3115,
      "step": 10176
    },
    {
      "epoch": 0.7908765930991607,
      "grad_norm": 0.2715115249156952,
      "learning_rate": 6.045617034504196e-06,
      "loss": 0.1107,
      "step": 10177
    },
    {
      "epoch": 0.7909543052533416,
      "grad_norm": 0.03716477006673813,
      "learning_rate": 6.045228473733292e-06,
      "loss": 0.0028,
      "step": 10178
    },
    {
      "epoch": 0.7910320174075225,
      "grad_norm": 0.22053106129169464,
      "learning_rate": 6.044839912962388e-06,
      "loss": 0.0452,
      "step": 10179
    },
    {
      "epoch": 0.7911097295617034,
      "grad_norm": 0.3157195448875427,
      "learning_rate": 6.044451352191483e-06,
      "loss": 0.2674,
      "step": 10180
    },
    {
      "epoch": 0.7911874417158844,
      "grad_norm": 0.43708866834640503,
      "learning_rate": 6.044062791420579e-06,
      "loss": 0.1688,
      "step": 10181
    },
    {
      "epoch": 0.7912651538700652,
      "grad_norm": 0.18443596363067627,
      "learning_rate": 6.0436742306496744e-06,
      "loss": 0.0351,
      "step": 10182
    },
    {
      "epoch": 0.7913428660242462,
      "grad_norm": 0.3299645781517029,
      "learning_rate": 6.04328566987877e-06,
      "loss": 0.2881,
      "step": 10183
    },
    {
      "epoch": 0.7914205781784271,
      "grad_norm": 0.7563648819923401,
      "learning_rate": 6.042897109107864e-06,
      "loss": 0.1241,
      "step": 10184
    },
    {
      "epoch": 0.791498290332608,
      "grad_norm": 0.7388888597488403,
      "learning_rate": 6.04250854833696e-06,
      "loss": 0.2225,
      "step": 10185
    },
    {
      "epoch": 0.7915760024867889,
      "grad_norm": 0.21940447390079498,
      "learning_rate": 6.042119987566056e-06,
      "loss": 0.11,
      "step": 10186
    },
    {
      "epoch": 0.7916537146409699,
      "grad_norm": 0.31271040439605713,
      "learning_rate": 6.041731426795151e-06,
      "loss": 0.1392,
      "step": 10187
    },
    {
      "epoch": 0.7917314267951507,
      "grad_norm": 0.23314958810806274,
      "learning_rate": 6.041342866024247e-06,
      "loss": 0.0579,
      "step": 10188
    },
    {
      "epoch": 0.7918091389493317,
      "grad_norm": 0.3235483765602112,
      "learning_rate": 6.0409543052533425e-06,
      "loss": 0.1068,
      "step": 10189
    },
    {
      "epoch": 0.7918868511035125,
      "grad_norm": 1.0044975280761719,
      "learning_rate": 6.040565744482437e-06,
      "loss": 0.4745,
      "step": 10190
    },
    {
      "epoch": 0.7919645632576935,
      "grad_norm": 0.30468231439590454,
      "learning_rate": 6.040177183711533e-06,
      "loss": 0.1777,
      "step": 10191
    },
    {
      "epoch": 0.7920422754118744,
      "grad_norm": 0.08102088421583176,
      "learning_rate": 6.039788622940629e-06,
      "loss": 0.025,
      "step": 10192
    },
    {
      "epoch": 0.7921199875660553,
      "grad_norm": 0.279441237449646,
      "learning_rate": 6.039400062169723e-06,
      "loss": 0.0954,
      "step": 10193
    },
    {
      "epoch": 0.7921976997202362,
      "grad_norm": 1.1503666639328003,
      "learning_rate": 6.039011501398819e-06,
      "loss": 0.1626,
      "step": 10194
    },
    {
      "epoch": 0.7922754118744172,
      "grad_norm": 0.5770002603530884,
      "learning_rate": 6.038622940627915e-06,
      "loss": 0.5848,
      "step": 10195
    },
    {
      "epoch": 0.792353124028598,
      "grad_norm": 0.30714526772499084,
      "learning_rate": 6.03823437985701e-06,
      "loss": 0.174,
      "step": 10196
    },
    {
      "epoch": 0.792430836182779,
      "grad_norm": 0.24447086453437805,
      "learning_rate": 6.0378458190861055e-06,
      "loss": 0.0737,
      "step": 10197
    },
    {
      "epoch": 0.7925085483369599,
      "grad_norm": 0.4318437874317169,
      "learning_rate": 6.037457258315201e-06,
      "loss": 0.3174,
      "step": 10198
    },
    {
      "epoch": 0.7925862604911408,
      "grad_norm": 0.13731864094734192,
      "learning_rate": 6.037068697544296e-06,
      "loss": 0.0224,
      "step": 10199
    },
    {
      "epoch": 0.7926639726453217,
      "grad_norm": 0.1300801932811737,
      "learning_rate": 6.036680136773392e-06,
      "loss": 0.033,
      "step": 10200
    },
    {
      "epoch": 0.7927416847995027,
      "grad_norm": 0.25130707025527954,
      "learning_rate": 6.036291576002488e-06,
      "loss": 0.0895,
      "step": 10201
    },
    {
      "epoch": 0.7928193969536835,
      "grad_norm": 0.315091997385025,
      "learning_rate": 6.035903015231582e-06,
      "loss": 0.0587,
      "step": 10202
    },
    {
      "epoch": 0.7928971091078645,
      "grad_norm": 0.40722164511680603,
      "learning_rate": 6.035514454460678e-06,
      "loss": 0.2254,
      "step": 10203
    },
    {
      "epoch": 0.7929748212620454,
      "grad_norm": 0.2926035523414612,
      "learning_rate": 6.0351258936897735e-06,
      "loss": 0.1697,
      "step": 10204
    },
    {
      "epoch": 0.7930525334162263,
      "grad_norm": 0.32451245188713074,
      "learning_rate": 6.0347373329188684e-06,
      "loss": 0.2846,
      "step": 10205
    },
    {
      "epoch": 0.7931302455704072,
      "grad_norm": 0.10534709692001343,
      "learning_rate": 6.034348772147964e-06,
      "loss": 0.0248,
      "step": 10206
    },
    {
      "epoch": 0.7932079577245881,
      "grad_norm": 0.1158013641834259,
      "learning_rate": 6.03396021137706e-06,
      "loss": 0.0419,
      "step": 10207
    },
    {
      "epoch": 0.793285669878769,
      "grad_norm": 0.2554398477077484,
      "learning_rate": 6.033571650606155e-06,
      "loss": 0.146,
      "step": 10208
    },
    {
      "epoch": 0.79336338203295,
      "grad_norm": 0.18087811768054962,
      "learning_rate": 6.033183089835251e-06,
      "loss": 0.0978,
      "step": 10209
    },
    {
      "epoch": 0.7934410941871308,
      "grad_norm": 0.14829276502132416,
      "learning_rate": 6.032794529064347e-06,
      "loss": 0.0381,
      "step": 10210
    },
    {
      "epoch": 0.7935188063413118,
      "grad_norm": 0.28637340664863586,
      "learning_rate": 6.032405968293441e-06,
      "loss": 0.1013,
      "step": 10211
    },
    {
      "epoch": 0.7935965184954927,
      "grad_norm": 0.1996682584285736,
      "learning_rate": 6.0320174075225365e-06,
      "loss": 0.1481,
      "step": 10212
    },
    {
      "epoch": 0.7936742306496736,
      "grad_norm": 0.24885840713977814,
      "learning_rate": 6.031628846751632e-06,
      "loss": 0.1532,
      "step": 10213
    },
    {
      "epoch": 0.7937519428038545,
      "grad_norm": 0.6505606174468994,
      "learning_rate": 6.031240285980728e-06,
      "loss": 0.2515,
      "step": 10214
    },
    {
      "epoch": 0.7938296549580355,
      "grad_norm": 0.15008749067783356,
      "learning_rate": 6.030851725209823e-06,
      "loss": 0.0674,
      "step": 10215
    },
    {
      "epoch": 0.7939073671122163,
      "grad_norm": 0.3268893361091614,
      "learning_rate": 6.030463164438919e-06,
      "loss": 0.3169,
      "step": 10216
    },
    {
      "epoch": 0.7939850792663973,
      "grad_norm": 0.15460294485092163,
      "learning_rate": 6.030074603668015e-06,
      "loss": 0.0455,
      "step": 10217
    },
    {
      "epoch": 0.7940627914205782,
      "grad_norm": 0.5108762383460999,
      "learning_rate": 6.0296860428971096e-06,
      "loss": 0.3761,
      "step": 10218
    },
    {
      "epoch": 0.7941405035747591,
      "grad_norm": 0.2292719930410385,
      "learning_rate": 6.029297482126205e-06,
      "loss": 0.1815,
      "step": 10219
    },
    {
      "epoch": 0.79421821572894,
      "grad_norm": 0.13057640194892883,
      "learning_rate": 6.028908921355301e-06,
      "loss": 0.0259,
      "step": 10220
    },
    {
      "epoch": 0.7942959278831209,
      "grad_norm": 0.31415823101997375,
      "learning_rate": 6.028520360584395e-06,
      "loss": 0.3765,
      "step": 10221
    },
    {
      "epoch": 0.7943736400373018,
      "grad_norm": 0.34592100977897644,
      "learning_rate": 6.028131799813491e-06,
      "loss": 0.0883,
      "step": 10222
    },
    {
      "epoch": 0.7944513521914828,
      "grad_norm": 0.41455259919166565,
      "learning_rate": 6.027743239042587e-06,
      "loss": 0.7521,
      "step": 10223
    },
    {
      "epoch": 0.7945290643456636,
      "grad_norm": 0.36554473638534546,
      "learning_rate": 6.027354678271682e-06,
      "loss": 0.2072,
      "step": 10224
    },
    {
      "epoch": 0.7946067764998446,
      "grad_norm": 0.8068683743476868,
      "learning_rate": 6.026966117500778e-06,
      "loss": 0.6617,
      "step": 10225
    },
    {
      "epoch": 0.7946844886540255,
      "grad_norm": 0.30894505977630615,
      "learning_rate": 6.026577556729873e-06,
      "loss": 0.0639,
      "step": 10226
    },
    {
      "epoch": 0.7947622008082064,
      "grad_norm": 0.6504417061805725,
      "learning_rate": 6.026188995958968e-06,
      "loss": 0.3979,
      "step": 10227
    },
    {
      "epoch": 0.7948399129623873,
      "grad_norm": 0.403931587934494,
      "learning_rate": 6.025800435188064e-06,
      "loss": 0.2654,
      "step": 10228
    },
    {
      "epoch": 0.7949176251165683,
      "grad_norm": 0.4694771468639374,
      "learning_rate": 6.02541187441716e-06,
      "loss": 0.4076,
      "step": 10229
    },
    {
      "epoch": 0.7949953372707491,
      "grad_norm": 0.25117453932762146,
      "learning_rate": 6.025023313646254e-06,
      "loss": 0.0672,
      "step": 10230
    },
    {
      "epoch": 0.7950730494249301,
      "grad_norm": 0.3326346278190613,
      "learning_rate": 6.02463475287535e-06,
      "loss": 0.2356,
      "step": 10231
    },
    {
      "epoch": 0.795150761579111,
      "grad_norm": 0.13563808798789978,
      "learning_rate": 6.024246192104446e-06,
      "loss": 0.0641,
      "step": 10232
    },
    {
      "epoch": 0.7952284737332919,
      "grad_norm": 0.32081103324890137,
      "learning_rate": 6.023857631333541e-06,
      "loss": 0.1571,
      "step": 10233
    },
    {
      "epoch": 0.7953061858874728,
      "grad_norm": 0.9621374607086182,
      "learning_rate": 6.023469070562636e-06,
      "loss": 0.3236,
      "step": 10234
    },
    {
      "epoch": 0.7953838980416538,
      "grad_norm": 0.21693463623523712,
      "learning_rate": 6.023080509791732e-06,
      "loss": 0.0502,
      "step": 10235
    },
    {
      "epoch": 0.7954616101958346,
      "grad_norm": 0.4961613416671753,
      "learning_rate": 6.022691949020827e-06,
      "loss": 0.3972,
      "step": 10236
    },
    {
      "epoch": 0.7955393223500156,
      "grad_norm": 0.3260730504989624,
      "learning_rate": 6.022303388249923e-06,
      "loss": 0.1859,
      "step": 10237
    },
    {
      "epoch": 0.7956170345041964,
      "grad_norm": 0.4969039559364319,
      "learning_rate": 6.021914827479019e-06,
      "loss": 0.1893,
      "step": 10238
    },
    {
      "epoch": 0.7956947466583774,
      "grad_norm": 0.48537272214889526,
      "learning_rate": 6.021526266708113e-06,
      "loss": 0.354,
      "step": 10239
    },
    {
      "epoch": 0.7957724588125583,
      "grad_norm": 0.3660937249660492,
      "learning_rate": 6.021137705937209e-06,
      "loss": 0.1036,
      "step": 10240
    },
    {
      "epoch": 0.7958501709667392,
      "grad_norm": 0.5244033336639404,
      "learning_rate": 6.020749145166304e-06,
      "loss": 0.235,
      "step": 10241
    },
    {
      "epoch": 0.7959278831209201,
      "grad_norm": 0.43080753087997437,
      "learning_rate": 6.020360584395399e-06,
      "loss": 0.2647,
      "step": 10242
    },
    {
      "epoch": 0.7960055952751011,
      "grad_norm": 0.5742493867874146,
      "learning_rate": 6.019972023624495e-06,
      "loss": 0.1894,
      "step": 10243
    },
    {
      "epoch": 0.7960833074292819,
      "grad_norm": 0.4236186742782593,
      "learning_rate": 6.019583462853591e-06,
      "loss": 0.3014,
      "step": 10244
    },
    {
      "epoch": 0.7961610195834629,
      "grad_norm": 0.22789792716503143,
      "learning_rate": 6.019194902082687e-06,
      "loss": 0.1072,
      "step": 10245
    },
    {
      "epoch": 0.7962387317376438,
      "grad_norm": 0.6442752480506897,
      "learning_rate": 6.018806341311782e-06,
      "loss": 0.5642,
      "step": 10246
    },
    {
      "epoch": 0.7963164438918247,
      "grad_norm": 0.3345935344696045,
      "learning_rate": 6.0184177805408775e-06,
      "loss": 0.1443,
      "step": 10247
    },
    {
      "epoch": 0.7963941560460056,
      "grad_norm": 0.5037323832511902,
      "learning_rate": 6.018029219769973e-06,
      "loss": 0.1228,
      "step": 10248
    },
    {
      "epoch": 0.7964718682001866,
      "grad_norm": 0.5036131739616394,
      "learning_rate": 6.017640658999067e-06,
      "loss": 0.3705,
      "step": 10249
    },
    {
      "epoch": 0.7965495803543674,
      "grad_norm": 0.26335400342941284,
      "learning_rate": 6.017252098228163e-06,
      "loss": 0.4298,
      "step": 10250
    },
    {
      "epoch": 0.7966272925085484,
      "grad_norm": 0.4830359220504761,
      "learning_rate": 6.016863537457259e-06,
      "loss": 0.6055,
      "step": 10251
    },
    {
      "epoch": 0.7967050046627292,
      "grad_norm": 0.3983984589576721,
      "learning_rate": 6.016474976686354e-06,
      "loss": 0.2186,
      "step": 10252
    },
    {
      "epoch": 0.7967827168169102,
      "grad_norm": 0.387321412563324,
      "learning_rate": 6.01608641591545e-06,
      "loss": 0.0893,
      "step": 10253
    },
    {
      "epoch": 0.7968604289710911,
      "grad_norm": 0.5391324162483215,
      "learning_rate": 6.0156978551445455e-06,
      "loss": 0.3295,
      "step": 10254
    },
    {
      "epoch": 0.796938141125272,
      "grad_norm": 0.3441513180732727,
      "learning_rate": 6.0153092943736405e-06,
      "loss": 0.1526,
      "step": 10255
    },
    {
      "epoch": 0.7970158532794529,
      "grad_norm": 0.339772492647171,
      "learning_rate": 6.014920733602736e-06,
      "loss": 0.2045,
      "step": 10256
    },
    {
      "epoch": 0.7970935654336339,
      "grad_norm": 0.4416343569755554,
      "learning_rate": 6.014532172831832e-06,
      "loss": 0.2752,
      "step": 10257
    },
    {
      "epoch": 0.7971712775878147,
      "grad_norm": 0.40408673882484436,
      "learning_rate": 6.014143612060926e-06,
      "loss": 0.241,
      "step": 10258
    },
    {
      "epoch": 0.7972489897419957,
      "grad_norm": 0.9947468042373657,
      "learning_rate": 6.013755051290022e-06,
      "loss": 0.5432,
      "step": 10259
    },
    {
      "epoch": 0.7973267018961766,
      "grad_norm": 0.6912014484405518,
      "learning_rate": 6.013366490519118e-06,
      "loss": 0.7042,
      "step": 10260
    },
    {
      "epoch": 0.7974044140503574,
      "grad_norm": 0.268978476524353,
      "learning_rate": 6.012977929748213e-06,
      "loss": 0.0591,
      "step": 10261
    },
    {
      "epoch": 0.7974821262045384,
      "grad_norm": 0.14048074185848236,
      "learning_rate": 6.0125893689773085e-06,
      "loss": 0.0197,
      "step": 10262
    },
    {
      "epoch": 0.7975598383587194,
      "grad_norm": 0.5775607228279114,
      "learning_rate": 6.012200808206404e-06,
      "loss": 0.1061,
      "step": 10263
    },
    {
      "epoch": 0.7976375505129002,
      "grad_norm": 0.08194223791360855,
      "learning_rate": 6.011812247435499e-06,
      "loss": 0.0199,
      "step": 10264
    },
    {
      "epoch": 0.7977152626670811,
      "grad_norm": 0.27299633622169495,
      "learning_rate": 6.011423686664595e-06,
      "loss": 0.0604,
      "step": 10265
    },
    {
      "epoch": 0.797792974821262,
      "grad_norm": 0.3479916751384735,
      "learning_rate": 6.011035125893691e-06,
      "loss": 0.097,
      "step": 10266
    },
    {
      "epoch": 0.7978706869754429,
      "grad_norm": 0.12438962608575821,
      "learning_rate": 6.010646565122785e-06,
      "loss": 0.0106,
      "step": 10267
    },
    {
      "epoch": 0.7979483991296239,
      "grad_norm": 0.48490622639656067,
      "learning_rate": 6.010258004351881e-06,
      "loss": 0.2013,
      "step": 10268
    },
    {
      "epoch": 0.7980261112838047,
      "grad_norm": 0.589480996131897,
      "learning_rate": 6.0098694435809766e-06,
      "loss": 0.4091,
      "step": 10269
    },
    {
      "epoch": 0.7981038234379857,
      "grad_norm": 0.28278669714927673,
      "learning_rate": 6.0094808828100715e-06,
      "loss": 0.1251,
      "step": 10270
    },
    {
      "epoch": 0.7981815355921666,
      "grad_norm": 0.8976886868476868,
      "learning_rate": 6.009092322039167e-06,
      "loss": 0.1157,
      "step": 10271
    },
    {
      "epoch": 0.7982592477463475,
      "grad_norm": 0.6399397253990173,
      "learning_rate": 6.008703761268263e-06,
      "loss": 0.1362,
      "step": 10272
    },
    {
      "epoch": 0.7983369599005284,
      "grad_norm": 0.15664586424827576,
      "learning_rate": 6.008315200497358e-06,
      "loss": 0.0724,
      "step": 10273
    },
    {
      "epoch": 0.7984146720547094,
      "grad_norm": 0.09721273183822632,
      "learning_rate": 6.007926639726454e-06,
      "loss": 0.02,
      "step": 10274
    },
    {
      "epoch": 0.7984923842088902,
      "grad_norm": 0.542147696018219,
      "learning_rate": 6.00753807895555e-06,
      "loss": 0.1691,
      "step": 10275
    },
    {
      "epoch": 0.7985700963630712,
      "grad_norm": 0.07269538938999176,
      "learning_rate": 6.0071495181846455e-06,
      "loss": 0.0124,
      "step": 10276
    },
    {
      "epoch": 0.7986478085172521,
      "grad_norm": 0.5188068151473999,
      "learning_rate": 6.0067609574137396e-06,
      "loss": 0.5767,
      "step": 10277
    },
    {
      "epoch": 0.798725520671433,
      "grad_norm": 0.5261967182159424,
      "learning_rate": 6.006372396642835e-06,
      "loss": 0.367,
      "step": 10278
    },
    {
      "epoch": 0.7988032328256139,
      "grad_norm": 0.37280651926994324,
      "learning_rate": 6.005983835871931e-06,
      "loss": 0.5378,
      "step": 10279
    },
    {
      "epoch": 0.7988809449797949,
      "grad_norm": 0.3508937954902649,
      "learning_rate": 6.005595275101026e-06,
      "loss": 0.0784,
      "step": 10280
    },
    {
      "epoch": 0.7989586571339757,
      "grad_norm": 1.0308371782302856,
      "learning_rate": 6.005206714330122e-06,
      "loss": 0.7015,
      "step": 10281
    },
    {
      "epoch": 0.7990363692881567,
      "grad_norm": 0.6497626900672913,
      "learning_rate": 6.004818153559218e-06,
      "loss": 0.8416,
      "step": 10282
    },
    {
      "epoch": 0.7991140814423375,
      "grad_norm": 0.31379759311676025,
      "learning_rate": 6.004429592788313e-06,
      "loss": 0.0566,
      "step": 10283
    },
    {
      "epoch": 0.7991917935965185,
      "grad_norm": 0.35590142011642456,
      "learning_rate": 6.0040410320174084e-06,
      "loss": 0.057,
      "step": 10284
    },
    {
      "epoch": 0.7992695057506994,
      "grad_norm": 0.6626421213150024,
      "learning_rate": 6.003652471246504e-06,
      "loss": 0.476,
      "step": 10285
    },
    {
      "epoch": 0.7993472179048803,
      "grad_norm": 1.0866094827651978,
      "learning_rate": 6.003263910475598e-06,
      "loss": 0.267,
      "step": 10286
    },
    {
      "epoch": 0.7994249300590612,
      "grad_norm": 0.5356491208076477,
      "learning_rate": 6.002875349704694e-06,
      "loss": 0.3453,
      "step": 10287
    },
    {
      "epoch": 0.7995026422132422,
      "grad_norm": 0.6550689339637756,
      "learning_rate": 6.00248678893379e-06,
      "loss": 0.26,
      "step": 10288
    },
    {
      "epoch": 0.799580354367423,
      "grad_norm": 0.07026093453168869,
      "learning_rate": 6.002098228162885e-06,
      "loss": 0.0214,
      "step": 10289
    },
    {
      "epoch": 0.799658066521604,
      "grad_norm": 0.6437091827392578,
      "learning_rate": 6.001709667391981e-06,
      "loss": 0.3521,
      "step": 10290
    },
    {
      "epoch": 0.7997357786757849,
      "grad_norm": 0.38738784193992615,
      "learning_rate": 6.0013211066210765e-06,
      "loss": 0.1097,
      "step": 10291
    },
    {
      "epoch": 0.7998134908299658,
      "grad_norm": 0.5983524918556213,
      "learning_rate": 6.0009325458501714e-06,
      "loss": 0.238,
      "step": 10292
    },
    {
      "epoch": 0.7998912029841467,
      "grad_norm": 0.3826179802417755,
      "learning_rate": 6.000543985079267e-06,
      "loss": 0.1055,
      "step": 10293
    },
    {
      "epoch": 0.7999689151383277,
      "grad_norm": 0.19817931950092316,
      "learning_rate": 6.000155424308363e-06,
      "loss": 0.082,
      "step": 10294
    },
    {
      "epoch": 0.8000466272925085,
      "grad_norm": 0.39040684700012207,
      "learning_rate": 5.999766863537457e-06,
      "loss": 0.0513,
      "step": 10295
    },
    {
      "epoch": 0.8001243394466895,
      "grad_norm": 0.2961655557155609,
      "learning_rate": 5.999378302766553e-06,
      "loss": 0.0561,
      "step": 10296
    },
    {
      "epoch": 0.8002020516008703,
      "grad_norm": 0.1861860752105713,
      "learning_rate": 5.998989741995649e-06,
      "loss": 0.0693,
      "step": 10297
    },
    {
      "epoch": 0.8002797637550513,
      "grad_norm": 0.4289281666278839,
      "learning_rate": 5.998601181224744e-06,
      "loss": 0.2148,
      "step": 10298
    },
    {
      "epoch": 0.8003574759092322,
      "grad_norm": 0.33776891231536865,
      "learning_rate": 5.9982126204538395e-06,
      "loss": 0.0981,
      "step": 10299
    },
    {
      "epoch": 0.8004351880634131,
      "grad_norm": 0.523749589920044,
      "learning_rate": 5.997824059682935e-06,
      "loss": 0.3859,
      "step": 10300
    },
    {
      "epoch": 0.800512900217594,
      "grad_norm": 0.4067522883415222,
      "learning_rate": 5.99743549891203e-06,
      "loss": 0.4238,
      "step": 10301
    },
    {
      "epoch": 0.800590612371775,
      "grad_norm": 0.26325270533561707,
      "learning_rate": 5.997046938141126e-06,
      "loss": 0.0627,
      "step": 10302
    },
    {
      "epoch": 0.8006683245259558,
      "grad_norm": 0.22274306416511536,
      "learning_rate": 5.996658377370222e-06,
      "loss": 0.0888,
      "step": 10303
    },
    {
      "epoch": 0.8007460366801368,
      "grad_norm": 0.6696699261665344,
      "learning_rate": 5.996269816599317e-06,
      "loss": 0.475,
      "step": 10304
    },
    {
      "epoch": 0.8008237488343177,
      "grad_norm": 0.24687261879444122,
      "learning_rate": 5.995881255828412e-06,
      "loss": 0.1293,
      "step": 10305
    },
    {
      "epoch": 0.8009014609884986,
      "grad_norm": 1.009859323501587,
      "learning_rate": 5.9954926950575075e-06,
      "loss": 0.5283,
      "step": 10306
    },
    {
      "epoch": 0.8009791731426795,
      "grad_norm": 0.6825675964355469,
      "learning_rate": 5.995104134286603e-06,
      "loss": 0.2594,
      "step": 10307
    },
    {
      "epoch": 0.8010568852968605,
      "grad_norm": 0.3996424078941345,
      "learning_rate": 5.994715573515698e-06,
      "loss": 0.3649,
      "step": 10308
    },
    {
      "epoch": 0.8011345974510413,
      "grad_norm": 0.14666631817817688,
      "learning_rate": 5.994327012744794e-06,
      "loss": 0.0557,
      "step": 10309
    },
    {
      "epoch": 0.8012123096052223,
      "grad_norm": 0.7380543947219849,
      "learning_rate": 5.99393845197389e-06,
      "loss": 0.511,
      "step": 10310
    },
    {
      "epoch": 0.8012900217594032,
      "grad_norm": 0.711513876914978,
      "learning_rate": 5.993549891202984e-06,
      "loss": 0.2115,
      "step": 10311
    },
    {
      "epoch": 0.8013677339135841,
      "grad_norm": 0.7807490229606628,
      "learning_rate": 5.99316133043208e-06,
      "loss": 0.1989,
      "step": 10312
    },
    {
      "epoch": 0.801445446067765,
      "grad_norm": 0.16586421430110931,
      "learning_rate": 5.9927727696611755e-06,
      "loss": 0.0217,
      "step": 10313
    },
    {
      "epoch": 0.8015231582219459,
      "grad_norm": 0.299805223941803,
      "learning_rate": 5.9923842088902705e-06,
      "loss": 0.095,
      "step": 10314
    },
    {
      "epoch": 0.8016008703761268,
      "grad_norm": 0.13647615909576416,
      "learning_rate": 5.991995648119366e-06,
      "loss": 0.0317,
      "step": 10315
    },
    {
      "epoch": 0.8016785825303078,
      "grad_norm": 0.15188607573509216,
      "learning_rate": 5.991607087348462e-06,
      "loss": 0.0359,
      "step": 10316
    },
    {
      "epoch": 0.8017562946844886,
      "grad_norm": 0.35715726017951965,
      "learning_rate": 5.991218526577557e-06,
      "loss": 0.1523,
      "step": 10317
    },
    {
      "epoch": 0.8018340068386696,
      "grad_norm": 0.1421840637922287,
      "learning_rate": 5.990829965806653e-06,
      "loss": 0.0474,
      "step": 10318
    },
    {
      "epoch": 0.8019117189928505,
      "grad_norm": 0.44895997643470764,
      "learning_rate": 5.990441405035749e-06,
      "loss": 0.2883,
      "step": 10319
    },
    {
      "epoch": 0.8019894311470314,
      "grad_norm": 0.10607095062732697,
      "learning_rate": 5.990052844264843e-06,
      "loss": 0.0267,
      "step": 10320
    },
    {
      "epoch": 0.8020671433012123,
      "grad_norm": 0.16921736299991608,
      "learning_rate": 5.9896642834939385e-06,
      "loss": 0.1064,
      "step": 10321
    },
    {
      "epoch": 0.8021448554553933,
      "grad_norm": 0.4799569249153137,
      "learning_rate": 5.989275722723034e-06,
      "loss": 0.131,
      "step": 10322
    },
    {
      "epoch": 0.8022225676095741,
      "grad_norm": 0.6394261121749878,
      "learning_rate": 5.988887161952129e-06,
      "loss": 0.1959,
      "step": 10323
    },
    {
      "epoch": 0.8023002797637551,
      "grad_norm": 0.4375091791152954,
      "learning_rate": 5.988498601181225e-06,
      "loss": 0.0794,
      "step": 10324
    },
    {
      "epoch": 0.802377991917936,
      "grad_norm": 0.6563718914985657,
      "learning_rate": 5.988110040410321e-06,
      "loss": 0.2079,
      "step": 10325
    },
    {
      "epoch": 0.8024557040721169,
      "grad_norm": 0.13355572521686554,
      "learning_rate": 5.987721479639416e-06,
      "loss": 0.0452,
      "step": 10326
    },
    {
      "epoch": 0.8025334162262978,
      "grad_norm": 0.48594555258750916,
      "learning_rate": 5.987332918868512e-06,
      "loss": 0.5323,
      "step": 10327
    },
    {
      "epoch": 0.8026111283804787,
      "grad_norm": 0.40792033076286316,
      "learning_rate": 5.986944358097607e-06,
      "loss": 0.2119,
      "step": 10328
    },
    {
      "epoch": 0.8026888405346596,
      "grad_norm": 0.3180444538593292,
      "learning_rate": 5.9865557973267015e-06,
      "loss": 0.0813,
      "step": 10329
    },
    {
      "epoch": 0.8027665526888406,
      "grad_norm": 0.6593169569969177,
      "learning_rate": 5.986167236555797e-06,
      "loss": 0.2735,
      "step": 10330
    },
    {
      "epoch": 0.8028442648430214,
      "grad_norm": 0.3613119125366211,
      "learning_rate": 5.985778675784893e-06,
      "loss": 0.1659,
      "step": 10331
    },
    {
      "epoch": 0.8029219769972024,
      "grad_norm": 0.181314155459404,
      "learning_rate": 5.985390115013988e-06,
      "loss": 0.0383,
      "step": 10332
    },
    {
      "epoch": 0.8029996891513833,
      "grad_norm": 0.6532098054885864,
      "learning_rate": 5.985001554243084e-06,
      "loss": 0.2715,
      "step": 10333
    },
    {
      "epoch": 0.8030774013055642,
      "grad_norm": 0.1771032065153122,
      "learning_rate": 5.98461299347218e-06,
      "loss": 0.0658,
      "step": 10334
    },
    {
      "epoch": 0.8031551134597451,
      "grad_norm": 0.14128996431827545,
      "learning_rate": 5.9842244327012754e-06,
      "loss": 0.0529,
      "step": 10335
    },
    {
      "epoch": 0.8032328256139261,
      "grad_norm": 0.49378663301467896,
      "learning_rate": 5.98383587193037e-06,
      "loss": 0.1804,
      "step": 10336
    },
    {
      "epoch": 0.8033105377681069,
      "grad_norm": 0.16986306011676788,
      "learning_rate": 5.983447311159466e-06,
      "loss": 0.0345,
      "step": 10337
    },
    {
      "epoch": 0.8033882499222879,
      "grad_norm": 0.2771412134170532,
      "learning_rate": 5.983058750388562e-06,
      "loss": 0.0334,
      "step": 10338
    },
    {
      "epoch": 0.8034659620764688,
      "grad_norm": 0.31192243099212646,
      "learning_rate": 5.982670189617656e-06,
      "loss": 0.063,
      "step": 10339
    },
    {
      "epoch": 0.8035436742306497,
      "grad_norm": 0.3419141173362732,
      "learning_rate": 5.982281628846752e-06,
      "loss": 0.2231,
      "step": 10340
    },
    {
      "epoch": 0.8036213863848306,
      "grad_norm": 0.2443302869796753,
      "learning_rate": 5.981893068075848e-06,
      "loss": 0.2245,
      "step": 10341
    },
    {
      "epoch": 0.8036990985390114,
      "grad_norm": 0.6154791116714478,
      "learning_rate": 5.981504507304943e-06,
      "loss": 0.1967,
      "step": 10342
    },
    {
      "epoch": 0.8037768106931924,
      "grad_norm": 0.29785922169685364,
      "learning_rate": 5.9811159465340384e-06,
      "loss": 0.1758,
      "step": 10343
    },
    {
      "epoch": 0.8038545228473734,
      "grad_norm": 0.49511897563934326,
      "learning_rate": 5.980727385763134e-06,
      "loss": 0.3007,
      "step": 10344
    },
    {
      "epoch": 0.8039322350015542,
      "grad_norm": 0.3448036313056946,
      "learning_rate": 5.980338824992229e-06,
      "loss": 0.0636,
      "step": 10345
    },
    {
      "epoch": 0.8040099471557351,
      "grad_norm": 0.21118953824043274,
      "learning_rate": 5.979950264221325e-06,
      "loss": 0.0621,
      "step": 10346
    },
    {
      "epoch": 0.8040876593099161,
      "grad_norm": 0.5630035996437073,
      "learning_rate": 5.979561703450421e-06,
      "loss": 0.4879,
      "step": 10347
    },
    {
      "epoch": 0.804165371464097,
      "grad_norm": 0.26614612340927124,
      "learning_rate": 5.979173142679515e-06,
      "loss": 0.1087,
      "step": 10348
    },
    {
      "epoch": 0.8042430836182779,
      "grad_norm": 0.5598430633544922,
      "learning_rate": 5.978784581908611e-06,
      "loss": 0.1342,
      "step": 10349
    },
    {
      "epoch": 0.8043207957724589,
      "grad_norm": 0.6360951662063599,
      "learning_rate": 5.9783960211377065e-06,
      "loss": 0.3449,
      "step": 10350
    },
    {
      "epoch": 0.8043985079266397,
      "grad_norm": 0.2517518401145935,
      "learning_rate": 5.978007460366801e-06,
      "loss": 0.0957,
      "step": 10351
    },
    {
      "epoch": 0.8044762200808206,
      "grad_norm": 0.6509965658187866,
      "learning_rate": 5.977618899595897e-06,
      "loss": 0.3343,
      "step": 10352
    },
    {
      "epoch": 0.8045539322350016,
      "grad_norm": 0.3918110728263855,
      "learning_rate": 5.977230338824993e-06,
      "loss": 0.2115,
      "step": 10353
    },
    {
      "epoch": 0.8046316443891824,
      "grad_norm": 0.08766844868659973,
      "learning_rate": 5.976841778054088e-06,
      "loss": 0.015,
      "step": 10354
    },
    {
      "epoch": 0.8047093565433634,
      "grad_norm": 0.06770054250955582,
      "learning_rate": 5.976453217283184e-06,
      "loss": 0.011,
      "step": 10355
    },
    {
      "epoch": 0.8047870686975443,
      "grad_norm": 0.4819481670856476,
      "learning_rate": 5.9760646565122796e-06,
      "loss": 0.1143,
      "step": 10356
    },
    {
      "epoch": 0.8048647808517252,
      "grad_norm": 0.312853068113327,
      "learning_rate": 5.975676095741374e-06,
      "loss": 0.0889,
      "step": 10357
    },
    {
      "epoch": 0.8049424930059061,
      "grad_norm": 0.3552723824977875,
      "learning_rate": 5.9752875349704695e-06,
      "loss": 0.1603,
      "step": 10358
    },
    {
      "epoch": 0.805020205160087,
      "grad_norm": 0.28886812925338745,
      "learning_rate": 5.974898974199565e-06,
      "loss": 0.0734,
      "step": 10359
    },
    {
      "epoch": 0.8050979173142679,
      "grad_norm": 0.44639796018600464,
      "learning_rate": 5.97451041342866e-06,
      "loss": 0.0854,
      "step": 10360
    },
    {
      "epoch": 0.8051756294684489,
      "grad_norm": 0.18086902797222137,
      "learning_rate": 5.974121852657756e-06,
      "loss": 0.1315,
      "step": 10361
    },
    {
      "epoch": 0.8052533416226297,
      "grad_norm": 0.7426314353942871,
      "learning_rate": 5.973733291886852e-06,
      "loss": 0.3619,
      "step": 10362
    },
    {
      "epoch": 0.8053310537768107,
      "grad_norm": 0.4248245656490326,
      "learning_rate": 5.973344731115947e-06,
      "loss": 0.1643,
      "step": 10363
    },
    {
      "epoch": 0.8054087659309916,
      "grad_norm": 0.6074399948120117,
      "learning_rate": 5.9729561703450425e-06,
      "loss": 0.176,
      "step": 10364
    },
    {
      "epoch": 0.8054864780851725,
      "grad_norm": 0.30126792192459106,
      "learning_rate": 5.972567609574138e-06,
      "loss": 0.368,
      "step": 10365
    },
    {
      "epoch": 0.8055641902393534,
      "grad_norm": 0.5207030177116394,
      "learning_rate": 5.972179048803234e-06,
      "loss": 0.1953,
      "step": 10366
    },
    {
      "epoch": 0.8056419023935344,
      "grad_norm": 0.07034037262201309,
      "learning_rate": 5.971790488032328e-06,
      "loss": 0.0172,
      "step": 10367
    },
    {
      "epoch": 0.8057196145477152,
      "grad_norm": 0.37058573961257935,
      "learning_rate": 5.971401927261424e-06,
      "loss": 0.1771,
      "step": 10368
    },
    {
      "epoch": 0.8057973267018962,
      "grad_norm": 0.29125475883483887,
      "learning_rate": 5.97101336649052e-06,
      "loss": 0.1017,
      "step": 10369
    },
    {
      "epoch": 0.8058750388560771,
      "grad_norm": 0.44651997089385986,
      "learning_rate": 5.970624805719615e-06,
      "loss": 0.1335,
      "step": 10370
    },
    {
      "epoch": 0.805952751010258,
      "grad_norm": 1.8512440919876099,
      "learning_rate": 5.9702362449487106e-06,
      "loss": 0.4586,
      "step": 10371
    },
    {
      "epoch": 0.8060304631644389,
      "grad_norm": 0.23711423575878143,
      "learning_rate": 5.969847684177806e-06,
      "loss": 0.0727,
      "step": 10372
    },
    {
      "epoch": 0.8061081753186198,
      "grad_norm": 0.4773869514465332,
      "learning_rate": 5.969459123406901e-06,
      "loss": 0.3397,
      "step": 10373
    },
    {
      "epoch": 0.8061858874728007,
      "grad_norm": 0.3416604995727539,
      "learning_rate": 5.969070562635997e-06,
      "loss": 0.2555,
      "step": 10374
    },
    {
      "epoch": 0.8062635996269817,
      "grad_norm": 0.09329868853092194,
      "learning_rate": 5.968682001865093e-06,
      "loss": 0.0218,
      "step": 10375
    },
    {
      "epoch": 0.8063413117811625,
      "grad_norm": 0.3200041651725769,
      "learning_rate": 5.968293441094187e-06,
      "loss": 0.1599,
      "step": 10376
    },
    {
      "epoch": 0.8064190239353435,
      "grad_norm": 0.3892478942871094,
      "learning_rate": 5.967904880323283e-06,
      "loss": 0.2185,
      "step": 10377
    },
    {
      "epoch": 0.8064967360895244,
      "grad_norm": 0.4172251224517822,
      "learning_rate": 5.967516319552379e-06,
      "loss": 0.2122,
      "step": 10378
    },
    {
      "epoch": 0.8065744482437053,
      "grad_norm": 0.5186040997505188,
      "learning_rate": 5.9671277587814736e-06,
      "loss": 0.3222,
      "step": 10379
    },
    {
      "epoch": 0.8066521603978862,
      "grad_norm": 0.1604214310646057,
      "learning_rate": 5.966739198010569e-06,
      "loss": 0.101,
      "step": 10380
    },
    {
      "epoch": 0.8067298725520672,
      "grad_norm": 0.1425420492887497,
      "learning_rate": 5.966350637239665e-06,
      "loss": 0.0843,
      "step": 10381
    },
    {
      "epoch": 0.806807584706248,
      "grad_norm": 0.19739694893360138,
      "learning_rate": 5.96596207646876e-06,
      "loss": 0.0581,
      "step": 10382
    },
    {
      "epoch": 0.806885296860429,
      "grad_norm": 0.3725045621395111,
      "learning_rate": 5.965573515697856e-06,
      "loss": 0.1138,
      "step": 10383
    },
    {
      "epoch": 0.8069630090146099,
      "grad_norm": 0.19970348477363586,
      "learning_rate": 5.965184954926952e-06,
      "loss": 0.0401,
      "step": 10384
    },
    {
      "epoch": 0.8070407211687908,
      "grad_norm": 0.4948600232601166,
      "learning_rate": 5.964796394156046e-06,
      "loss": 0.517,
      "step": 10385
    },
    {
      "epoch": 0.8071184333229717,
      "grad_norm": 0.2809664309024811,
      "learning_rate": 5.964407833385142e-06,
      "loss": 0.1307,
      "step": 10386
    },
    {
      "epoch": 0.8071961454771526,
      "grad_norm": 0.2889931797981262,
      "learning_rate": 5.964019272614237e-06,
      "loss": 0.0856,
      "step": 10387
    },
    {
      "epoch": 0.8072738576313335,
      "grad_norm": 0.08912641555070877,
      "learning_rate": 5.963630711843332e-06,
      "loss": 0.0141,
      "step": 10388
    },
    {
      "epoch": 0.8073515697855145,
      "grad_norm": 0.37182435393333435,
      "learning_rate": 5.963242151072428e-06,
      "loss": 0.1277,
      "step": 10389
    },
    {
      "epoch": 0.8074292819396953,
      "grad_norm": 0.14875119924545288,
      "learning_rate": 5.962853590301524e-06,
      "loss": 0.0633,
      "step": 10390
    },
    {
      "epoch": 0.8075069940938763,
      "grad_norm": 0.6948363184928894,
      "learning_rate": 5.962465029530619e-06,
      "loss": 0.3901,
      "step": 10391
    },
    {
      "epoch": 0.8075847062480572,
      "grad_norm": 0.7026575207710266,
      "learning_rate": 5.962076468759715e-06,
      "loss": 0.3149,
      "step": 10392
    },
    {
      "epoch": 0.8076624184022381,
      "grad_norm": 0.5513178706169128,
      "learning_rate": 5.9616879079888105e-06,
      "loss": 0.3487,
      "step": 10393
    },
    {
      "epoch": 0.807740130556419,
      "grad_norm": 0.11938312649726868,
      "learning_rate": 5.961299347217905e-06,
      "loss": 0.0428,
      "step": 10394
    },
    {
      "epoch": 0.8078178427106,
      "grad_norm": 0.46768665313720703,
      "learning_rate": 5.960910786447e-06,
      "loss": 0.1547,
      "step": 10395
    },
    {
      "epoch": 0.8078955548647808,
      "grad_norm": 0.3291849195957184,
      "learning_rate": 5.960522225676096e-06,
      "loss": 0.0837,
      "step": 10396
    },
    {
      "epoch": 0.8079732670189618,
      "grad_norm": 0.31694796681404114,
      "learning_rate": 5.960133664905192e-06,
      "loss": 0.113,
      "step": 10397
    },
    {
      "epoch": 0.8080509791731427,
      "grad_norm": 0.6672061681747437,
      "learning_rate": 5.959745104134287e-06,
      "loss": 0.1002,
      "step": 10398
    },
    {
      "epoch": 0.8081286913273236,
      "grad_norm": 0.3050179183483124,
      "learning_rate": 5.959356543363383e-06,
      "loss": 0.0668,
      "step": 10399
    },
    {
      "epoch": 0.8082064034815045,
      "grad_norm": 0.5856972336769104,
      "learning_rate": 5.9589679825924785e-06,
      "loss": 0.4787,
      "step": 10400
    },
    {
      "epoch": 0.8082841156356855,
      "grad_norm": 0.33437415957450867,
      "learning_rate": 5.9585794218215735e-06,
      "loss": 0.1138,
      "step": 10401
    },
    {
      "epoch": 0.8083618277898663,
      "grad_norm": 0.15202321112155914,
      "learning_rate": 5.958190861050669e-06,
      "loss": 0.065,
      "step": 10402
    },
    {
      "epoch": 0.8084395399440473,
      "grad_norm": 0.5705389380455017,
      "learning_rate": 5.957802300279765e-06,
      "loss": 0.1608,
      "step": 10403
    },
    {
      "epoch": 0.8085172520982281,
      "grad_norm": 0.7524026036262512,
      "learning_rate": 5.957413739508859e-06,
      "loss": 0.2805,
      "step": 10404
    },
    {
      "epoch": 0.8085949642524091,
      "grad_norm": 0.5601997375488281,
      "learning_rate": 5.957025178737955e-06,
      "loss": 0.444,
      "step": 10405
    },
    {
      "epoch": 0.80867267640659,
      "grad_norm": 0.2239154428243637,
      "learning_rate": 5.956636617967051e-06,
      "loss": 0.0545,
      "step": 10406
    },
    {
      "epoch": 0.8087503885607709,
      "grad_norm": 1.2982306480407715,
      "learning_rate": 5.956248057196146e-06,
      "loss": 0.436,
      "step": 10407
    },
    {
      "epoch": 0.8088281007149518,
      "grad_norm": 0.3605107069015503,
      "learning_rate": 5.9558594964252415e-06,
      "loss": 0.0935,
      "step": 10408
    },
    {
      "epoch": 0.8089058128691328,
      "grad_norm": 0.8733370900154114,
      "learning_rate": 5.955470935654337e-06,
      "loss": 0.2273,
      "step": 10409
    },
    {
      "epoch": 0.8089835250233136,
      "grad_norm": 0.24625582993030548,
      "learning_rate": 5.955082374883432e-06,
      "loss": 0.076,
      "step": 10410
    },
    {
      "epoch": 0.8090612371774946,
      "grad_norm": 0.33245110511779785,
      "learning_rate": 5.954693814112528e-06,
      "loss": 0.1837,
      "step": 10411
    },
    {
      "epoch": 0.8091389493316755,
      "grad_norm": 0.09644879400730133,
      "learning_rate": 5.954305253341624e-06,
      "loss": 0.0154,
      "step": 10412
    },
    {
      "epoch": 0.8092166614858564,
      "grad_norm": 0.45671704411506653,
      "learning_rate": 5.953916692570718e-06,
      "loss": 0.1978,
      "step": 10413
    },
    {
      "epoch": 0.8092943736400373,
      "grad_norm": 0.25287988781929016,
      "learning_rate": 5.953528131799814e-06,
      "loss": 0.1174,
      "step": 10414
    },
    {
      "epoch": 0.8093720857942183,
      "grad_norm": 0.5273740887641907,
      "learning_rate": 5.9531395710289095e-06,
      "loss": 0.1478,
      "step": 10415
    },
    {
      "epoch": 0.8094497979483991,
      "grad_norm": 0.4147641658782959,
      "learning_rate": 5.9527510102580045e-06,
      "loss": 1.0662,
      "step": 10416
    },
    {
      "epoch": 0.8095275101025801,
      "grad_norm": 0.06139380484819412,
      "learning_rate": 5.9523624494871e-06,
      "loss": 0.0152,
      "step": 10417
    },
    {
      "epoch": 0.8096052222567609,
      "grad_norm": 0.32741278409957886,
      "learning_rate": 5.951973888716196e-06,
      "loss": 0.2143,
      "step": 10418
    },
    {
      "epoch": 0.8096829344109419,
      "grad_norm": 0.11763881891965866,
      "learning_rate": 5.951585327945291e-06,
      "loss": 0.052,
      "step": 10419
    },
    {
      "epoch": 0.8097606465651228,
      "grad_norm": 0.6423501968383789,
      "learning_rate": 5.951196767174387e-06,
      "loss": 0.2748,
      "step": 10420
    },
    {
      "epoch": 0.8098383587193037,
      "grad_norm": 0.4028204381465912,
      "learning_rate": 5.950808206403483e-06,
      "loss": 0.1322,
      "step": 10421
    },
    {
      "epoch": 0.8099160708734846,
      "grad_norm": 0.5531997084617615,
      "learning_rate": 5.950419645632577e-06,
      "loss": 0.261,
      "step": 10422
    },
    {
      "epoch": 0.8099937830276656,
      "grad_norm": 0.2602343261241913,
      "learning_rate": 5.9500310848616725e-06,
      "loss": 0.0756,
      "step": 10423
    },
    {
      "epoch": 0.8100714951818464,
      "grad_norm": 0.14919577538967133,
      "learning_rate": 5.949642524090768e-06,
      "loss": 0.036,
      "step": 10424
    },
    {
      "epoch": 0.8101492073360274,
      "grad_norm": 0.22765004634857178,
      "learning_rate": 5.949253963319864e-06,
      "loss": 0.0626,
      "step": 10425
    },
    {
      "epoch": 0.8102269194902083,
      "grad_norm": 0.4820358455181122,
      "learning_rate": 5.948865402548959e-06,
      "loss": 0.2713,
      "step": 10426
    },
    {
      "epoch": 0.8103046316443892,
      "grad_norm": 0.29796963930130005,
      "learning_rate": 5.948476841778055e-06,
      "loss": 0.1528,
      "step": 10427
    },
    {
      "epoch": 0.8103823437985701,
      "grad_norm": 0.37135061621665955,
      "learning_rate": 5.948088281007151e-06,
      "loss": 0.206,
      "step": 10428
    },
    {
      "epoch": 0.8104600559527511,
      "grad_norm": 0.3011590540409088,
      "learning_rate": 5.947699720236246e-06,
      "loss": 0.0427,
      "step": 10429
    },
    {
      "epoch": 0.8105377681069319,
      "grad_norm": 0.9631245732307434,
      "learning_rate": 5.947311159465341e-06,
      "loss": 0.6619,
      "step": 10430
    },
    {
      "epoch": 0.8106154802611129,
      "grad_norm": 0.13532111048698425,
      "learning_rate": 5.946922598694436e-06,
      "loss": 0.029,
      "step": 10431
    },
    {
      "epoch": 0.8106931924152938,
      "grad_norm": 0.059510186314582825,
      "learning_rate": 5.946534037923531e-06,
      "loss": 0.0141,
      "step": 10432
    },
    {
      "epoch": 0.8107709045694746,
      "grad_norm": 0.2367607057094574,
      "learning_rate": 5.946145477152627e-06,
      "loss": 0.0673,
      "step": 10433
    },
    {
      "epoch": 0.8108486167236556,
      "grad_norm": 0.1467987447977066,
      "learning_rate": 5.945756916381723e-06,
      "loss": 0.0538,
      "step": 10434
    },
    {
      "epoch": 0.8109263288778364,
      "grad_norm": 0.317544162273407,
      "learning_rate": 5.945368355610818e-06,
      "loss": 0.1328,
      "step": 10435
    },
    {
      "epoch": 0.8110040410320174,
      "grad_norm": 0.509126603603363,
      "learning_rate": 5.944979794839914e-06,
      "loss": 0.2098,
      "step": 10436
    },
    {
      "epoch": 0.8110817531861984,
      "grad_norm": 0.06670617312192917,
      "learning_rate": 5.9445912340690094e-06,
      "loss": 0.0185,
      "step": 10437
    },
    {
      "epoch": 0.8111594653403792,
      "grad_norm": 0.15289723873138428,
      "learning_rate": 5.9442026732981035e-06,
      "loss": 0.0569,
      "step": 10438
    },
    {
      "epoch": 0.8112371774945601,
      "grad_norm": 0.4674162268638611,
      "learning_rate": 5.943814112527199e-06,
      "loss": 0.1638,
      "step": 10439
    },
    {
      "epoch": 0.8113148896487411,
      "grad_norm": 1.308132290840149,
      "learning_rate": 5.943425551756295e-06,
      "loss": 0.7733,
      "step": 10440
    },
    {
      "epoch": 0.8113926018029219,
      "grad_norm": 0.47656404972076416,
      "learning_rate": 5.94303699098539e-06,
      "loss": 0.1282,
      "step": 10441
    },
    {
      "epoch": 0.8114703139571029,
      "grad_norm": 0.4315337538719177,
      "learning_rate": 5.942648430214486e-06,
      "loss": 0.1773,
      "step": 10442
    },
    {
      "epoch": 0.8115480261112838,
      "grad_norm": 0.39268022775650024,
      "learning_rate": 5.942259869443582e-06,
      "loss": 0.2124,
      "step": 10443
    },
    {
      "epoch": 0.8116257382654647,
      "grad_norm": 0.830870509147644,
      "learning_rate": 5.941871308672677e-06,
      "loss": 0.4541,
      "step": 10444
    },
    {
      "epoch": 0.8117034504196456,
      "grad_norm": 0.29219043254852295,
      "learning_rate": 5.9414827479017724e-06,
      "loss": 0.1977,
      "step": 10445
    },
    {
      "epoch": 0.8117811625738266,
      "grad_norm": 0.38051944971084595,
      "learning_rate": 5.941094187130868e-06,
      "loss": 0.3078,
      "step": 10446
    },
    {
      "epoch": 0.8118588747280074,
      "grad_norm": 0.49363401532173157,
      "learning_rate": 5.940705626359962e-06,
      "loss": 0.1243,
      "step": 10447
    },
    {
      "epoch": 0.8119365868821884,
      "grad_norm": 0.24017487466335297,
      "learning_rate": 5.940317065589058e-06,
      "loss": 0.0585,
      "step": 10448
    },
    {
      "epoch": 0.8120142990363692,
      "grad_norm": 1.440796971321106,
      "learning_rate": 5.939928504818154e-06,
      "loss": 0.2937,
      "step": 10449
    },
    {
      "epoch": 0.8120920111905502,
      "grad_norm": 0.4474416971206665,
      "learning_rate": 5.939539944047249e-06,
      "loss": 0.0873,
      "step": 10450
    },
    {
      "epoch": 0.8121697233447311,
      "grad_norm": 0.18168124556541443,
      "learning_rate": 5.939151383276345e-06,
      "loss": 0.0505,
      "step": 10451
    },
    {
      "epoch": 0.812247435498912,
      "grad_norm": 0.19118274748325348,
      "learning_rate": 5.9387628225054405e-06,
      "loss": 0.0669,
      "step": 10452
    },
    {
      "epoch": 0.8123251476530929,
      "grad_norm": 0.1900472640991211,
      "learning_rate": 5.938374261734535e-06,
      "loss": 0.057,
      "step": 10453
    },
    {
      "epoch": 0.8124028598072739,
      "grad_norm": 2.1748363971710205,
      "learning_rate": 5.937985700963631e-06,
      "loss": 0.7865,
      "step": 10454
    },
    {
      "epoch": 0.8124805719614547,
      "grad_norm": 0.5763600468635559,
      "learning_rate": 5.937597140192727e-06,
      "loss": 0.3633,
      "step": 10455
    },
    {
      "epoch": 0.8125582841156357,
      "grad_norm": 8.388018608093262,
      "learning_rate": 5.937208579421823e-06,
      "loss": 2.9417,
      "step": 10456
    },
    {
      "epoch": 0.8126359962698166,
      "grad_norm": 0.8148070573806763,
      "learning_rate": 5.936820018650917e-06,
      "loss": 0.2877,
      "step": 10457
    },
    {
      "epoch": 0.8127137084239975,
      "grad_norm": 0.8114722967147827,
      "learning_rate": 5.936431457880013e-06,
      "loss": 0.3573,
      "step": 10458
    },
    {
      "epoch": 0.8127914205781784,
      "grad_norm": 0.06674013286828995,
      "learning_rate": 5.9360428971091085e-06,
      "loss": 0.0116,
      "step": 10459
    },
    {
      "epoch": 0.8128691327323594,
      "grad_norm": 0.2503538131713867,
      "learning_rate": 5.9356543363382035e-06,
      "loss": 0.1267,
      "step": 10460
    },
    {
      "epoch": 0.8129468448865402,
      "grad_norm": 0.5214083790779114,
      "learning_rate": 5.935265775567299e-06,
      "loss": 0.3816,
      "step": 10461
    },
    {
      "epoch": 0.8130245570407212,
      "grad_norm": 0.6711569428443909,
      "learning_rate": 5.934877214796395e-06,
      "loss": 0.3752,
      "step": 10462
    },
    {
      "epoch": 0.813102269194902,
      "grad_norm": 0.9243775606155396,
      "learning_rate": 5.93448865402549e-06,
      "loss": 0.3155,
      "step": 10463
    },
    {
      "epoch": 0.813179981349083,
      "grad_norm": 0.6720330119132996,
      "learning_rate": 5.934100093254586e-06,
      "loss": 0.081,
      "step": 10464
    },
    {
      "epoch": 0.8132576935032639,
      "grad_norm": 0.40225857496261597,
      "learning_rate": 5.933711532483682e-06,
      "loss": 0.2967,
      "step": 10465
    },
    {
      "epoch": 0.8133354056574448,
      "grad_norm": 0.17759858071804047,
      "learning_rate": 5.933322971712776e-06,
      "loss": 0.0673,
      "step": 10466
    },
    {
      "epoch": 0.8134131178116257,
      "grad_norm": 0.3609519600868225,
      "learning_rate": 5.9329344109418715e-06,
      "loss": 0.1036,
      "step": 10467
    },
    {
      "epoch": 0.8134908299658067,
      "grad_norm": 0.5686103701591492,
      "learning_rate": 5.932545850170967e-06,
      "loss": 0.3513,
      "step": 10468
    },
    {
      "epoch": 0.8135685421199875,
      "grad_norm": 0.2189272791147232,
      "learning_rate": 5.932157289400062e-06,
      "loss": 0.0178,
      "step": 10469
    },
    {
      "epoch": 0.8136462542741685,
      "grad_norm": 0.5353531837463379,
      "learning_rate": 5.931768728629158e-06,
      "loss": 0.3979,
      "step": 10470
    },
    {
      "epoch": 0.8137239664283494,
      "grad_norm": 0.33157673478126526,
      "learning_rate": 5.931380167858254e-06,
      "loss": 0.0478,
      "step": 10471
    },
    {
      "epoch": 0.8138016785825303,
      "grad_norm": 0.06949795037508011,
      "learning_rate": 5.930991607087349e-06,
      "loss": 0.0362,
      "step": 10472
    },
    {
      "epoch": 0.8138793907367112,
      "grad_norm": 0.7702179551124573,
      "learning_rate": 5.930603046316445e-06,
      "loss": 0.2722,
      "step": 10473
    },
    {
      "epoch": 0.8139571028908922,
      "grad_norm": 0.2394712269306183,
      "learning_rate": 5.93021448554554e-06,
      "loss": 0.6365,
      "step": 10474
    },
    {
      "epoch": 0.814034815045073,
      "grad_norm": 0.25622206926345825,
      "learning_rate": 5.9298259247746345e-06,
      "loss": 0.1456,
      "step": 10475
    },
    {
      "epoch": 0.814112527199254,
      "grad_norm": 0.34433436393737793,
      "learning_rate": 5.92943736400373e-06,
      "loss": 0.3613,
      "step": 10476
    },
    {
      "epoch": 0.8141902393534349,
      "grad_norm": 0.41746848821640015,
      "learning_rate": 5.929048803232826e-06,
      "loss": 0.1412,
      "step": 10477
    },
    {
      "epoch": 0.8142679515076158,
      "grad_norm": 0.08029700815677643,
      "learning_rate": 5.928660242461921e-06,
      "loss": 0.0093,
      "step": 10478
    },
    {
      "epoch": 0.8143456636617967,
      "grad_norm": 0.20958904922008514,
      "learning_rate": 5.928271681691017e-06,
      "loss": 0.0534,
      "step": 10479
    },
    {
      "epoch": 0.8144233758159776,
      "grad_norm": 0.8538199663162231,
      "learning_rate": 5.927883120920113e-06,
      "loss": 0.5167,
      "step": 10480
    },
    {
      "epoch": 0.8145010879701585,
      "grad_norm": 1.4029327630996704,
      "learning_rate": 5.9274945601492076e-06,
      "loss": 0.3697,
      "step": 10481
    },
    {
      "epoch": 0.8145788001243395,
      "grad_norm": 0.4360465407371521,
      "learning_rate": 5.927105999378303e-06,
      "loss": 0.1216,
      "step": 10482
    },
    {
      "epoch": 0.8146565122785203,
      "grad_norm": 0.08702836185693741,
      "learning_rate": 5.926717438607399e-06,
      "loss": 0.032,
      "step": 10483
    },
    {
      "epoch": 0.8147342244327013,
      "grad_norm": 0.17240917682647705,
      "learning_rate": 5.926328877836493e-06,
      "loss": 0.0435,
      "step": 10484
    },
    {
      "epoch": 0.8148119365868822,
      "grad_norm": 0.32104402780532837,
      "learning_rate": 5.925940317065589e-06,
      "loss": 0.0931,
      "step": 10485
    },
    {
      "epoch": 0.8148896487410631,
      "grad_norm": 0.43271538615226746,
      "learning_rate": 5.925551756294685e-06,
      "loss": 0.2494,
      "step": 10486
    },
    {
      "epoch": 0.814967360895244,
      "grad_norm": 0.21445916593074799,
      "learning_rate": 5.925163195523781e-06,
      "loss": 0.3444,
      "step": 10487
    },
    {
      "epoch": 0.815045073049425,
      "grad_norm": 0.43503087759017944,
      "learning_rate": 5.924774634752876e-06,
      "loss": 0.0434,
      "step": 10488
    },
    {
      "epoch": 0.8151227852036058,
      "grad_norm": 0.8932220935821533,
      "learning_rate": 5.924386073981971e-06,
      "loss": 0.4704,
      "step": 10489
    },
    {
      "epoch": 0.8152004973577868,
      "grad_norm": 0.21960555016994476,
      "learning_rate": 5.923997513211067e-06,
      "loss": 0.0742,
      "step": 10490
    },
    {
      "epoch": 0.8152782095119677,
      "grad_norm": 0.8226694464683533,
      "learning_rate": 5.923608952440162e-06,
      "loss": 0.3312,
      "step": 10491
    },
    {
      "epoch": 0.8153559216661486,
      "grad_norm": 0.38139012455940247,
      "learning_rate": 5.923220391669258e-06,
      "loss": 0.1339,
      "step": 10492
    },
    {
      "epoch": 0.8154336338203295,
      "grad_norm": 0.662453830242157,
      "learning_rate": 5.922831830898354e-06,
      "loss": 0.3629,
      "step": 10493
    },
    {
      "epoch": 0.8155113459745104,
      "grad_norm": 0.2804996371269226,
      "learning_rate": 5.922443270127448e-06,
      "loss": 0.0861,
      "step": 10494
    },
    {
      "epoch": 0.8155890581286913,
      "grad_norm": 0.13466809689998627,
      "learning_rate": 5.922054709356544e-06,
      "loss": 0.0802,
      "step": 10495
    },
    {
      "epoch": 0.8156667702828723,
      "grad_norm": 0.4773525893688202,
      "learning_rate": 5.9216661485856394e-06,
      "loss": 0.143,
      "step": 10496
    },
    {
      "epoch": 0.8157444824370531,
      "grad_norm": 0.6847912669181824,
      "learning_rate": 5.921277587814734e-06,
      "loss": 0.2688,
      "step": 10497
    },
    {
      "epoch": 0.8158221945912341,
      "grad_norm": 0.08779038488864899,
      "learning_rate": 5.92088902704383e-06,
      "loss": 0.035,
      "step": 10498
    },
    {
      "epoch": 0.815899906745415,
      "grad_norm": 0.29191693663597107,
      "learning_rate": 5.920500466272926e-06,
      "loss": 0.1467,
      "step": 10499
    },
    {
      "epoch": 0.8159776188995959,
      "grad_norm": 1.5648245811462402,
      "learning_rate": 5.920111905502021e-06,
      "loss": 0.2797,
      "step": 10500
    },
    {
      "epoch": 0.8160553310537768,
      "grad_norm": 0.26836851239204407,
      "learning_rate": 5.919723344731117e-06,
      "loss": 0.0478,
      "step": 10501
    },
    {
      "epoch": 0.8161330432079578,
      "grad_norm": 0.2112509161233902,
      "learning_rate": 5.9193347839602125e-06,
      "loss": 0.0256,
      "step": 10502
    },
    {
      "epoch": 0.8162107553621386,
      "grad_norm": 0.38184186816215515,
      "learning_rate": 5.918946223189307e-06,
      "loss": 0.1742,
      "step": 10503
    },
    {
      "epoch": 0.8162884675163196,
      "grad_norm": 0.5164027214050293,
      "learning_rate": 5.918557662418402e-06,
      "loss": 0.1266,
      "step": 10504
    },
    {
      "epoch": 0.8163661796705005,
      "grad_norm": 0.20597843825817108,
      "learning_rate": 5.918169101647498e-06,
      "loss": 0.1802,
      "step": 10505
    },
    {
      "epoch": 0.8164438918246814,
      "grad_norm": 0.11580526828765869,
      "learning_rate": 5.917780540876593e-06,
      "loss": 0.0298,
      "step": 10506
    },
    {
      "epoch": 0.8165216039788623,
      "grad_norm": 0.39831429719924927,
      "learning_rate": 5.917391980105689e-06,
      "loss": 0.517,
      "step": 10507
    },
    {
      "epoch": 0.8165993161330433,
      "grad_norm": 0.5471906661987305,
      "learning_rate": 5.917003419334785e-06,
      "loss": 0.2289,
      "step": 10508
    },
    {
      "epoch": 0.8166770282872241,
      "grad_norm": 1.2805525064468384,
      "learning_rate": 5.91661485856388e-06,
      "loss": 0.4745,
      "step": 10509
    },
    {
      "epoch": 0.8167547404414051,
      "grad_norm": 0.40183180570602417,
      "learning_rate": 5.9162262977929755e-06,
      "loss": 0.2266,
      "step": 10510
    },
    {
      "epoch": 0.8168324525955859,
      "grad_norm": 0.31620773673057556,
      "learning_rate": 5.915837737022071e-06,
      "loss": 0.1313,
      "step": 10511
    },
    {
      "epoch": 0.8169101647497669,
      "grad_norm": 0.8166068196296692,
      "learning_rate": 5.915449176251165e-06,
      "loss": 0.4064,
      "step": 10512
    },
    {
      "epoch": 0.8169878769039478,
      "grad_norm": 0.7430148720741272,
      "learning_rate": 5.915060615480261e-06,
      "loss": 0.1363,
      "step": 10513
    },
    {
      "epoch": 0.8170655890581286,
      "grad_norm": 0.8105494379997253,
      "learning_rate": 5.914672054709357e-06,
      "loss": 0.3628,
      "step": 10514
    },
    {
      "epoch": 0.8171433012123096,
      "grad_norm": 0.147955521941185,
      "learning_rate": 5.914283493938452e-06,
      "loss": 0.042,
      "step": 10515
    },
    {
      "epoch": 0.8172210133664906,
      "grad_norm": 0.5353049635887146,
      "learning_rate": 5.913894933167548e-06,
      "loss": 0.1132,
      "step": 10516
    },
    {
      "epoch": 0.8172987255206714,
      "grad_norm": 0.3396066725254059,
      "learning_rate": 5.9135063723966435e-06,
      "loss": 0.1113,
      "step": 10517
    },
    {
      "epoch": 0.8173764376748524,
      "grad_norm": 0.24789296090602875,
      "learning_rate": 5.913117811625739e-06,
      "loss": 0.1418,
      "step": 10518
    },
    {
      "epoch": 0.8174541498290333,
      "grad_norm": 0.6469389200210571,
      "learning_rate": 5.912729250854834e-06,
      "loss": 0.1885,
      "step": 10519
    },
    {
      "epoch": 0.8175318619832141,
      "grad_norm": 0.14791636168956757,
      "learning_rate": 5.91234069008393e-06,
      "loss": 0.0583,
      "step": 10520
    },
    {
      "epoch": 0.8176095741373951,
      "grad_norm": 0.23058335483074188,
      "learning_rate": 5.911952129313026e-06,
      "loss": 0.0984,
      "step": 10521
    },
    {
      "epoch": 0.817687286291576,
      "grad_norm": 0.10822988301515579,
      "learning_rate": 5.91156356854212e-06,
      "loss": 0.0404,
      "step": 10522
    },
    {
      "epoch": 0.8177649984457569,
      "grad_norm": 0.7309706211090088,
      "learning_rate": 5.911175007771216e-06,
      "loss": 0.2414,
      "step": 10523
    },
    {
      "epoch": 0.8178427105999378,
      "grad_norm": 0.28290173411369324,
      "learning_rate": 5.910786447000312e-06,
      "loss": 0.1945,
      "step": 10524
    },
    {
      "epoch": 0.8179204227541187,
      "grad_norm": 1.4612241983413696,
      "learning_rate": 5.9103978862294065e-06,
      "loss": 0.8506,
      "step": 10525
    },
    {
      "epoch": 0.8179981349082996,
      "grad_norm": 0.136930450797081,
      "learning_rate": 5.910009325458502e-06,
      "loss": 0.0259,
      "step": 10526
    },
    {
      "epoch": 0.8180758470624806,
      "grad_norm": 0.27326494455337524,
      "learning_rate": 5.909620764687598e-06,
      "loss": 0.1333,
      "step": 10527
    },
    {
      "epoch": 0.8181535592166614,
      "grad_norm": 0.6165029406547546,
      "learning_rate": 5.909232203916693e-06,
      "loss": 0.1703,
      "step": 10528
    },
    {
      "epoch": 0.8182312713708424,
      "grad_norm": 0.42867204546928406,
      "learning_rate": 5.908843643145789e-06,
      "loss": 0.0784,
      "step": 10529
    },
    {
      "epoch": 0.8183089835250233,
      "grad_norm": 0.25219592452049255,
      "learning_rate": 5.908455082374885e-06,
      "loss": 0.102,
      "step": 10530
    },
    {
      "epoch": 0.8183866956792042,
      "grad_norm": 0.47928544878959656,
      "learning_rate": 5.908066521603979e-06,
      "loss": 0.3163,
      "step": 10531
    },
    {
      "epoch": 0.8184644078333851,
      "grad_norm": 0.6278409361839294,
      "learning_rate": 5.9076779608330746e-06,
      "loss": 0.38,
      "step": 10532
    },
    {
      "epoch": 0.8185421199875661,
      "grad_norm": 0.5320143103599548,
      "learning_rate": 5.90728940006217e-06,
      "loss": 0.1967,
      "step": 10533
    },
    {
      "epoch": 0.8186198321417469,
      "grad_norm": 0.7267323136329651,
      "learning_rate": 5.906900839291265e-06,
      "loss": 0.102,
      "step": 10534
    },
    {
      "epoch": 0.8186975442959279,
      "grad_norm": 0.13267050683498383,
      "learning_rate": 5.906512278520361e-06,
      "loss": 0.0808,
      "step": 10535
    },
    {
      "epoch": 0.8187752564501088,
      "grad_norm": 0.32427021861076355,
      "learning_rate": 5.906123717749457e-06,
      "loss": 0.2367,
      "step": 10536
    },
    {
      "epoch": 0.8188529686042897,
      "grad_norm": 0.3943219482898712,
      "learning_rate": 5.905735156978552e-06,
      "loss": 0.1294,
      "step": 10537
    },
    {
      "epoch": 0.8189306807584706,
      "grad_norm": 0.321553111076355,
      "learning_rate": 5.905346596207648e-06,
      "loss": 0.5178,
      "step": 10538
    },
    {
      "epoch": 0.8190083929126515,
      "grad_norm": 0.12502776086330414,
      "learning_rate": 5.9049580354367435e-06,
      "loss": 0.0418,
      "step": 10539
    },
    {
      "epoch": 0.8190861050668324,
      "grad_norm": 0.16440251469612122,
      "learning_rate": 5.9045694746658376e-06,
      "loss": 0.0437,
      "step": 10540
    },
    {
      "epoch": 0.8191638172210134,
      "grad_norm": 0.11154306679964066,
      "learning_rate": 5.904180913894933e-06,
      "loss": 0.066,
      "step": 10541
    },
    {
      "epoch": 0.8192415293751942,
      "grad_norm": 0.242556631565094,
      "learning_rate": 5.903792353124029e-06,
      "loss": 0.1759,
      "step": 10542
    },
    {
      "epoch": 0.8193192415293752,
      "grad_norm": 0.6383062601089478,
      "learning_rate": 5.903403792353124e-06,
      "loss": 0.1342,
      "step": 10543
    },
    {
      "epoch": 0.8193969536835561,
      "grad_norm": 0.4208022654056549,
      "learning_rate": 5.90301523158222e-06,
      "loss": 0.2525,
      "step": 10544
    },
    {
      "epoch": 0.819474665837737,
      "grad_norm": 0.18653714656829834,
      "learning_rate": 5.902626670811316e-06,
      "loss": 0.0393,
      "step": 10545
    },
    {
      "epoch": 0.8195523779919179,
      "grad_norm": 0.2975237965583801,
      "learning_rate": 5.902238110040411e-06,
      "loss": 0.0814,
      "step": 10546
    },
    {
      "epoch": 0.8196300901460989,
      "grad_norm": 0.6299458742141724,
      "learning_rate": 5.9018495492695064e-06,
      "loss": 0.3216,
      "step": 10547
    },
    {
      "epoch": 0.8197078023002797,
      "grad_norm": 0.6315662860870361,
      "learning_rate": 5.901460988498602e-06,
      "loss": 0.2519,
      "step": 10548
    },
    {
      "epoch": 0.8197855144544607,
      "grad_norm": 0.12673959136009216,
      "learning_rate": 5.901072427727698e-06,
      "loss": 0.0379,
      "step": 10549
    },
    {
      "epoch": 0.8198632266086416,
      "grad_norm": 0.7538769841194153,
      "learning_rate": 5.900683866956792e-06,
      "loss": 0.2087,
      "step": 10550
    },
    {
      "epoch": 0.8199409387628225,
      "grad_norm": 0.26863059401512146,
      "learning_rate": 5.900295306185888e-06,
      "loss": 0.0878,
      "step": 10551
    },
    {
      "epoch": 0.8200186509170034,
      "grad_norm": 0.14549635350704193,
      "learning_rate": 5.899906745414984e-06,
      "loss": 0.0614,
      "step": 10552
    },
    {
      "epoch": 0.8200963630711844,
      "grad_norm": 0.20425020158290863,
      "learning_rate": 5.899518184644079e-06,
      "loss": 0.0327,
      "step": 10553
    },
    {
      "epoch": 0.8201740752253652,
      "grad_norm": 0.6224247217178345,
      "learning_rate": 5.8991296238731745e-06,
      "loss": 0.364,
      "step": 10554
    },
    {
      "epoch": 0.8202517873795462,
      "grad_norm": 0.20930485427379608,
      "learning_rate": 5.89874106310227e-06,
      "loss": 0.0586,
      "step": 10555
    },
    {
      "epoch": 0.820329499533727,
      "grad_norm": 0.10188370943069458,
      "learning_rate": 5.898352502331365e-06,
      "loss": 0.0228,
      "step": 10556
    },
    {
      "epoch": 0.820407211687908,
      "grad_norm": 0.18579338490962982,
      "learning_rate": 5.89796394156046e-06,
      "loss": 0.0216,
      "step": 10557
    },
    {
      "epoch": 0.8204849238420889,
      "grad_norm": 0.06466489285230637,
      "learning_rate": 5.897575380789556e-06,
      "loss": 0.0128,
      "step": 10558
    },
    {
      "epoch": 0.8205626359962698,
      "grad_norm": 0.4045271873474121,
      "learning_rate": 5.897186820018651e-06,
      "loss": 0.0863,
      "step": 10559
    },
    {
      "epoch": 0.8206403481504507,
      "grad_norm": 3.251037359237671,
      "learning_rate": 5.896798259247747e-06,
      "loss": 0.7059,
      "step": 10560
    },
    {
      "epoch": 0.8207180603046317,
      "grad_norm": 0.3057529926300049,
      "learning_rate": 5.8964096984768425e-06,
      "loss": 0.138,
      "step": 10561
    },
    {
      "epoch": 0.8207957724588125,
      "grad_norm": 0.46925145387649536,
      "learning_rate": 5.8960211377059375e-06,
      "loss": 0.1855,
      "step": 10562
    },
    {
      "epoch": 0.8208734846129935,
      "grad_norm": 0.5644822716712952,
      "learning_rate": 5.895632576935033e-06,
      "loss": 0.265,
      "step": 10563
    },
    {
      "epoch": 0.8209511967671744,
      "grad_norm": 0.6159933805465698,
      "learning_rate": 5.895244016164129e-06,
      "loss": 0.2982,
      "step": 10564
    },
    {
      "epoch": 0.8210289089213553,
      "grad_norm": 0.5234476923942566,
      "learning_rate": 5.894855455393223e-06,
      "loss": 0.8029,
      "step": 10565
    },
    {
      "epoch": 0.8211066210755362,
      "grad_norm": 0.28757360577583313,
      "learning_rate": 5.894466894622319e-06,
      "loss": 0.088,
      "step": 10566
    },
    {
      "epoch": 0.8211843332297172,
      "grad_norm": 0.13609002530574799,
      "learning_rate": 5.894078333851415e-06,
      "loss": 0.0269,
      "step": 10567
    },
    {
      "epoch": 0.821262045383898,
      "grad_norm": 0.21875928342342377,
      "learning_rate": 5.89368977308051e-06,
      "loss": 0.047,
      "step": 10568
    },
    {
      "epoch": 0.821339757538079,
      "grad_norm": 0.3861777186393738,
      "learning_rate": 5.8933012123096055e-06,
      "loss": 0.1466,
      "step": 10569
    },
    {
      "epoch": 0.8214174696922598,
      "grad_norm": 0.05982333794236183,
      "learning_rate": 5.892912651538701e-06,
      "loss": 0.0226,
      "step": 10570
    },
    {
      "epoch": 0.8214951818464408,
      "grad_norm": 0.42265424132347107,
      "learning_rate": 5.892524090767796e-06,
      "loss": 0.132,
      "step": 10571
    },
    {
      "epoch": 0.8215728940006217,
      "grad_norm": 0.2999795973300934,
      "learning_rate": 5.892135529996892e-06,
      "loss": 0.5839,
      "step": 10572
    },
    {
      "epoch": 0.8216506061548026,
      "grad_norm": 0.4078401029109955,
      "learning_rate": 5.891746969225988e-06,
      "loss": 0.1779,
      "step": 10573
    },
    {
      "epoch": 0.8217283183089835,
      "grad_norm": 0.334150105714798,
      "learning_rate": 5.891358408455082e-06,
      "loss": 0.1069,
      "step": 10574
    },
    {
      "epoch": 0.8218060304631645,
      "grad_norm": 0.45988035202026367,
      "learning_rate": 5.890969847684178e-06,
      "loss": 0.2788,
      "step": 10575
    },
    {
      "epoch": 0.8218837426173453,
      "grad_norm": 0.36974987387657166,
      "learning_rate": 5.8905812869132735e-06,
      "loss": 0.2257,
      "step": 10576
    },
    {
      "epoch": 0.8219614547715263,
      "grad_norm": 0.24503041803836823,
      "learning_rate": 5.890192726142369e-06,
      "loss": 0.0966,
      "step": 10577
    },
    {
      "epoch": 0.8220391669257072,
      "grad_norm": 0.4402785301208496,
      "learning_rate": 5.889804165371464e-06,
      "loss": 0.3553,
      "step": 10578
    },
    {
      "epoch": 0.8221168790798881,
      "grad_norm": 0.2599274516105652,
      "learning_rate": 5.88941560460056e-06,
      "loss": 0.0788,
      "step": 10579
    },
    {
      "epoch": 0.822194591234069,
      "grad_norm": 0.28013110160827637,
      "learning_rate": 5.889027043829656e-06,
      "loss": 0.0292,
      "step": 10580
    },
    {
      "epoch": 0.82227230338825,
      "grad_norm": 0.2534351944923401,
      "learning_rate": 5.888638483058751e-06,
      "loss": 0.0481,
      "step": 10581
    },
    {
      "epoch": 0.8223500155424308,
      "grad_norm": 0.5721897482872009,
      "learning_rate": 5.888249922287847e-06,
      "loss": 0.4492,
      "step": 10582
    },
    {
      "epoch": 0.8224277276966118,
      "grad_norm": 0.2255827784538269,
      "learning_rate": 5.887861361516942e-06,
      "loss": 0.0215,
      "step": 10583
    },
    {
      "epoch": 0.8225054398507927,
      "grad_norm": 0.28153833746910095,
      "learning_rate": 5.8874728007460365e-06,
      "loss": 0.0741,
      "step": 10584
    },
    {
      "epoch": 0.8225831520049736,
      "grad_norm": 0.37166827917099,
      "learning_rate": 5.887084239975132e-06,
      "loss": 0.0795,
      "step": 10585
    },
    {
      "epoch": 0.8226608641591545,
      "grad_norm": 0.0812825933098793,
      "learning_rate": 5.886695679204228e-06,
      "loss": 0.0212,
      "step": 10586
    },
    {
      "epoch": 0.8227385763133354,
      "grad_norm": 0.20271427929401398,
      "learning_rate": 5.886307118433323e-06,
      "loss": 0.1008,
      "step": 10587
    },
    {
      "epoch": 0.8228162884675163,
      "grad_norm": 0.8108921051025391,
      "learning_rate": 5.885918557662419e-06,
      "loss": 0.2391,
      "step": 10588
    },
    {
      "epoch": 0.8228940006216973,
      "grad_norm": 0.5732907056808472,
      "learning_rate": 5.885529996891515e-06,
      "loss": 0.2641,
      "step": 10589
    },
    {
      "epoch": 0.8229717127758781,
      "grad_norm": 0.17627041041851044,
      "learning_rate": 5.88514143612061e-06,
      "loss": 0.0356,
      "step": 10590
    },
    {
      "epoch": 0.8230494249300591,
      "grad_norm": 0.442641019821167,
      "learning_rate": 5.884752875349705e-06,
      "loss": 0.228,
      "step": 10591
    },
    {
      "epoch": 0.82312713708424,
      "grad_norm": 0.32359686493873596,
      "learning_rate": 5.884364314578801e-06,
      "loss": 0.1251,
      "step": 10592
    },
    {
      "epoch": 0.8232048492384209,
      "grad_norm": 0.12859801948070526,
      "learning_rate": 5.883975753807895e-06,
      "loss": 0.0333,
      "step": 10593
    },
    {
      "epoch": 0.8232825613926018,
      "grad_norm": 0.5762707591056824,
      "learning_rate": 5.883587193036991e-06,
      "loss": 0.3358,
      "step": 10594
    },
    {
      "epoch": 0.8233602735467828,
      "grad_norm": 0.7693049311637878,
      "learning_rate": 5.883198632266087e-06,
      "loss": 0.2514,
      "step": 10595
    },
    {
      "epoch": 0.8234379857009636,
      "grad_norm": 1.0113524198532104,
      "learning_rate": 5.882810071495182e-06,
      "loss": 0.3748,
      "step": 10596
    },
    {
      "epoch": 0.8235156978551446,
      "grad_norm": 0.3561156392097473,
      "learning_rate": 5.882421510724278e-06,
      "loss": 0.0302,
      "step": 10597
    },
    {
      "epoch": 0.8235934100093255,
      "grad_norm": 0.11222146451473236,
      "learning_rate": 5.8820329499533734e-06,
      "loss": 0.0238,
      "step": 10598
    },
    {
      "epoch": 0.8236711221635064,
      "grad_norm": 0.3471430540084839,
      "learning_rate": 5.881644389182468e-06,
      "loss": 0.2505,
      "step": 10599
    },
    {
      "epoch": 0.8237488343176873,
      "grad_norm": 0.17607256770133972,
      "learning_rate": 5.881255828411564e-06,
      "loss": 0.0778,
      "step": 10600
    },
    {
      "epoch": 0.8238265464718681,
      "grad_norm": 0.13407602906227112,
      "learning_rate": 5.88086726764066e-06,
      "loss": 0.0607,
      "step": 10601
    },
    {
      "epoch": 0.8239042586260491,
      "grad_norm": 0.27879974246025085,
      "learning_rate": 5.880478706869754e-06,
      "loss": 0.0575,
      "step": 10602
    },
    {
      "epoch": 0.82398197078023,
      "grad_norm": 0.21360911428928375,
      "learning_rate": 5.88009014609885e-06,
      "loss": 0.0199,
      "step": 10603
    },
    {
      "epoch": 0.8240596829344109,
      "grad_norm": 2.192671060562134,
      "learning_rate": 5.879701585327946e-06,
      "loss": 0.6249,
      "step": 10604
    },
    {
      "epoch": 0.8241373950885919,
      "grad_norm": 0.6915381550788879,
      "learning_rate": 5.879313024557041e-06,
      "loss": 0.5148,
      "step": 10605
    },
    {
      "epoch": 0.8242151072427728,
      "grad_norm": 0.5029304623603821,
      "learning_rate": 5.8789244637861364e-06,
      "loss": 0.2234,
      "step": 10606
    },
    {
      "epoch": 0.8242928193969536,
      "grad_norm": 0.2887093126773834,
      "learning_rate": 5.878535903015232e-06,
      "loss": 0.0845,
      "step": 10607
    },
    {
      "epoch": 0.8243705315511346,
      "grad_norm": 0.04780679568648338,
      "learning_rate": 5.878147342244328e-06,
      "loss": 0.014,
      "step": 10608
    },
    {
      "epoch": 0.8244482437053156,
      "grad_norm": 0.15442529320716858,
      "learning_rate": 5.877758781473423e-06,
      "loss": 0.0575,
      "step": 10609
    },
    {
      "epoch": 0.8245259558594964,
      "grad_norm": 0.13264493644237518,
      "learning_rate": 5.877370220702519e-06,
      "loss": 0.026,
      "step": 10610
    },
    {
      "epoch": 0.8246036680136773,
      "grad_norm": 0.3010145425796509,
      "learning_rate": 5.8769816599316146e-06,
      "loss": 0.1524,
      "step": 10611
    },
    {
      "epoch": 0.8246813801678583,
      "grad_norm": 0.3354443907737732,
      "learning_rate": 5.876593099160709e-06,
      "loss": 0.117,
      "step": 10612
    },
    {
      "epoch": 0.8247590923220391,
      "grad_norm": 0.3317051827907562,
      "learning_rate": 5.8762045383898045e-06,
      "loss": 0.204,
      "step": 10613
    },
    {
      "epoch": 0.8248368044762201,
      "grad_norm": 0.7534007430076599,
      "learning_rate": 5.8758159776189e-06,
      "loss": 0.2069,
      "step": 10614
    },
    {
      "epoch": 0.8249145166304009,
      "grad_norm": 0.08066203445196152,
      "learning_rate": 5.875427416847995e-06,
      "loss": 0.011,
      "step": 10615
    },
    {
      "epoch": 0.8249922287845819,
      "grad_norm": 0.3243246078491211,
      "learning_rate": 5.875038856077091e-06,
      "loss": 0.2034,
      "step": 10616
    },
    {
      "epoch": 0.8250699409387628,
      "grad_norm": 0.5476412177085876,
      "learning_rate": 5.874650295306187e-06,
      "loss": 0.2218,
      "step": 10617
    },
    {
      "epoch": 0.8251476530929437,
      "grad_norm": 0.4080824553966522,
      "learning_rate": 5.874261734535282e-06,
      "loss": 0.2175,
      "step": 10618
    },
    {
      "epoch": 0.8252253652471246,
      "grad_norm": 0.671485424041748,
      "learning_rate": 5.8738731737643776e-06,
      "loss": 0.2549,
      "step": 10619
    },
    {
      "epoch": 0.8253030774013056,
      "grad_norm": 1.1312493085861206,
      "learning_rate": 5.873484612993473e-06,
      "loss": 0.6986,
      "step": 10620
    },
    {
      "epoch": 0.8253807895554864,
      "grad_norm": 0.4288780093193054,
      "learning_rate": 5.8730960522225674e-06,
      "loss": 0.0997,
      "step": 10621
    },
    {
      "epoch": 0.8254585017096674,
      "grad_norm": 0.18617959320545197,
      "learning_rate": 5.872707491451663e-06,
      "loss": 0.0941,
      "step": 10622
    },
    {
      "epoch": 0.8255362138638483,
      "grad_norm": 0.4076736867427826,
      "learning_rate": 5.872318930680759e-06,
      "loss": 0.1466,
      "step": 10623
    },
    {
      "epoch": 0.8256139260180292,
      "grad_norm": 0.6522904634475708,
      "learning_rate": 5.871930369909854e-06,
      "loss": 0.2115,
      "step": 10624
    },
    {
      "epoch": 0.8256916381722101,
      "grad_norm": 0.31727269291877747,
      "learning_rate": 5.87154180913895e-06,
      "loss": 0.3305,
      "step": 10625
    },
    {
      "epoch": 0.8257693503263911,
      "grad_norm": 0.34195977449417114,
      "learning_rate": 5.871153248368046e-06,
      "loss": 0.1346,
      "step": 10626
    },
    {
      "epoch": 0.8258470624805719,
      "grad_norm": 0.17921948432922363,
      "learning_rate": 5.8707646875971405e-06,
      "loss": 0.0377,
      "step": 10627
    },
    {
      "epoch": 0.8259247746347529,
      "grad_norm": 0.23519834876060486,
      "learning_rate": 5.870376126826236e-06,
      "loss": 0.0439,
      "step": 10628
    },
    {
      "epoch": 0.8260024867889338,
      "grad_norm": 1.1243382692337036,
      "learning_rate": 5.869987566055332e-06,
      "loss": 0.6558,
      "step": 10629
    },
    {
      "epoch": 0.8260801989431147,
      "grad_norm": 0.13212649524211884,
      "learning_rate": 5.869599005284426e-06,
      "loss": 0.0658,
      "step": 10630
    },
    {
      "epoch": 0.8261579110972956,
      "grad_norm": 0.21539072692394257,
      "learning_rate": 5.869210444513522e-06,
      "loss": 0.0426,
      "step": 10631
    },
    {
      "epoch": 0.8262356232514765,
      "grad_norm": 0.4161340296268463,
      "learning_rate": 5.868821883742618e-06,
      "loss": 0.112,
      "step": 10632
    },
    {
      "epoch": 0.8263133354056574,
      "grad_norm": 0.15872061252593994,
      "learning_rate": 5.868433322971713e-06,
      "loss": 0.0917,
      "step": 10633
    },
    {
      "epoch": 0.8263910475598384,
      "grad_norm": 2.3689913749694824,
      "learning_rate": 5.8680447622008086e-06,
      "loss": 0.8523,
      "step": 10634
    },
    {
      "epoch": 0.8264687597140192,
      "grad_norm": 0.24561993777751923,
      "learning_rate": 5.867656201429904e-06,
      "loss": 0.0806,
      "step": 10635
    },
    {
      "epoch": 0.8265464718682002,
      "grad_norm": 0.2580386698246002,
      "learning_rate": 5.867267640658999e-06,
      "loss": 0.0479,
      "step": 10636
    },
    {
      "epoch": 0.8266241840223811,
      "grad_norm": 0.2078082114458084,
      "learning_rate": 5.866879079888095e-06,
      "loss": 0.0805,
      "step": 10637
    },
    {
      "epoch": 0.826701896176562,
      "grad_norm": 0.6861460208892822,
      "learning_rate": 5.866490519117191e-06,
      "loss": 0.2696,
      "step": 10638
    },
    {
      "epoch": 0.8267796083307429,
      "grad_norm": 0.3022814989089966,
      "learning_rate": 5.866101958346287e-06,
      "loss": 0.0884,
      "step": 10639
    },
    {
      "epoch": 0.8268573204849239,
      "grad_norm": 0.12418445199728012,
      "learning_rate": 5.865713397575381e-06,
      "loss": 0.0792,
      "step": 10640
    },
    {
      "epoch": 0.8269350326391047,
      "grad_norm": 0.7329878807067871,
      "learning_rate": 5.865324836804477e-06,
      "loss": 0.1658,
      "step": 10641
    },
    {
      "epoch": 0.8270127447932857,
      "grad_norm": 0.17821109294891357,
      "learning_rate": 5.864936276033572e-06,
      "loss": 0.0321,
      "step": 10642
    },
    {
      "epoch": 0.8270904569474666,
      "grad_norm": 0.35130131244659424,
      "learning_rate": 5.864547715262667e-06,
      "loss": 0.1695,
      "step": 10643
    },
    {
      "epoch": 0.8271681691016475,
      "grad_norm": 0.3594646453857422,
      "learning_rate": 5.864159154491763e-06,
      "loss": 0.1043,
      "step": 10644
    },
    {
      "epoch": 0.8272458812558284,
      "grad_norm": 0.275486558675766,
      "learning_rate": 5.863770593720859e-06,
      "loss": 0.0606,
      "step": 10645
    },
    {
      "epoch": 0.8273235934100093,
      "grad_norm": 0.8299131989479065,
      "learning_rate": 5.863382032949954e-06,
      "loss": 0.1786,
      "step": 10646
    },
    {
      "epoch": 0.8274013055641902,
      "grad_norm": 0.2742558419704437,
      "learning_rate": 5.86299347217905e-06,
      "loss": 0.1557,
      "step": 10647
    },
    {
      "epoch": 0.8274790177183712,
      "grad_norm": 0.5919039249420166,
      "learning_rate": 5.8626049114081455e-06,
      "loss": 0.2486,
      "step": 10648
    },
    {
      "epoch": 0.827556729872552,
      "grad_norm": 0.21021801233291626,
      "learning_rate": 5.86221635063724e-06,
      "loss": 0.1575,
      "step": 10649
    },
    {
      "epoch": 0.827634442026733,
      "grad_norm": 1.2778633832931519,
      "learning_rate": 5.861827789866335e-06,
      "loss": 0.1342,
      "step": 10650
    },
    {
      "epoch": 0.8277121541809139,
      "grad_norm": 0.32653582096099854,
      "learning_rate": 5.861439229095431e-06,
      "loss": 0.1151,
      "step": 10651
    },
    {
      "epoch": 0.8277898663350948,
      "grad_norm": 0.36954227089881897,
      "learning_rate": 5.861050668324526e-06,
      "loss": 0.1862,
      "step": 10652
    },
    {
      "epoch": 0.8278675784892757,
      "grad_norm": 0.7523348927497864,
      "learning_rate": 5.860662107553622e-06,
      "loss": 0.8434,
      "step": 10653
    },
    {
      "epoch": 0.8279452906434567,
      "grad_norm": 0.3583749830722809,
      "learning_rate": 5.860273546782718e-06,
      "loss": 0.1733,
      "step": 10654
    },
    {
      "epoch": 0.8280230027976375,
      "grad_norm": 0.1060684472322464,
      "learning_rate": 5.859884986011813e-06,
      "loss": 0.0262,
      "step": 10655
    },
    {
      "epoch": 0.8281007149518185,
      "grad_norm": 0.41850966215133667,
      "learning_rate": 5.8594964252409085e-06,
      "loss": 0.2514,
      "step": 10656
    },
    {
      "epoch": 0.8281784271059994,
      "grad_norm": 0.06242954730987549,
      "learning_rate": 5.859107864470004e-06,
      "loss": 0.0206,
      "step": 10657
    },
    {
      "epoch": 0.8282561392601803,
      "grad_norm": 0.38771525025367737,
      "learning_rate": 5.858719303699098e-06,
      "loss": 0.1497,
      "step": 10658
    },
    {
      "epoch": 0.8283338514143612,
      "grad_norm": 1.2498782873153687,
      "learning_rate": 5.858330742928194e-06,
      "loss": 0.4288,
      "step": 10659
    },
    {
      "epoch": 0.8284115635685422,
      "grad_norm": 0.24527674913406372,
      "learning_rate": 5.85794218215729e-06,
      "loss": 0.0678,
      "step": 10660
    },
    {
      "epoch": 0.828489275722723,
      "grad_norm": 0.70827317237854,
      "learning_rate": 5.857553621386385e-06,
      "loss": 0.3085,
      "step": 10661
    },
    {
      "epoch": 0.828566987876904,
      "grad_norm": 0.44507497549057007,
      "learning_rate": 5.857165060615481e-06,
      "loss": 0.1792,
      "step": 10662
    },
    {
      "epoch": 0.8286447000310848,
      "grad_norm": 1.2713998556137085,
      "learning_rate": 5.8567764998445765e-06,
      "loss": 0.343,
      "step": 10663
    },
    {
      "epoch": 0.8287224121852658,
      "grad_norm": 0.3593789041042328,
      "learning_rate": 5.8563879390736715e-06,
      "loss": 0.1783,
      "step": 10664
    },
    {
      "epoch": 0.8288001243394467,
      "grad_norm": 0.21284396946430206,
      "learning_rate": 5.855999378302767e-06,
      "loss": 0.0571,
      "step": 10665
    },
    {
      "epoch": 0.8288778364936276,
      "grad_norm": 0.5985674858093262,
      "learning_rate": 5.855610817531863e-06,
      "loss": 0.3555,
      "step": 10666
    },
    {
      "epoch": 0.8289555486478085,
      "grad_norm": 0.12399257719516754,
      "learning_rate": 5.855222256760957e-06,
      "loss": 0.0396,
      "step": 10667
    },
    {
      "epoch": 0.8290332608019895,
      "grad_norm": 0.27081379294395447,
      "learning_rate": 5.854833695990053e-06,
      "loss": 0.1002,
      "step": 10668
    },
    {
      "epoch": 0.8291109729561703,
      "grad_norm": 0.7351028323173523,
      "learning_rate": 5.854445135219149e-06,
      "loss": 0.2015,
      "step": 10669
    },
    {
      "epoch": 0.8291886851103513,
      "grad_norm": 0.9145236015319824,
      "learning_rate": 5.8540565744482446e-06,
      "loss": 0.3113,
      "step": 10670
    },
    {
      "epoch": 0.8292663972645322,
      "grad_norm": 0.2951011657714844,
      "learning_rate": 5.8536680136773395e-06,
      "loss": 0.1503,
      "step": 10671
    },
    {
      "epoch": 0.8293441094187131,
      "grad_norm": 0.3374808132648468,
      "learning_rate": 5.853279452906435e-06,
      "loss": 0.0994,
      "step": 10672
    },
    {
      "epoch": 0.829421821572894,
      "grad_norm": 0.21000511944293976,
      "learning_rate": 5.852890892135531e-06,
      "loss": 0.0611,
      "step": 10673
    },
    {
      "epoch": 0.829499533727075,
      "grad_norm": 0.2276630997657776,
      "learning_rate": 5.852502331364626e-06,
      "loss": 0.0655,
      "step": 10674
    },
    {
      "epoch": 0.8295772458812558,
      "grad_norm": 0.855055034160614,
      "learning_rate": 5.852113770593722e-06,
      "loss": 0.1214,
      "step": 10675
    },
    {
      "epoch": 0.8296549580354368,
      "grad_norm": 0.17910894751548767,
      "learning_rate": 5.851725209822818e-06,
      "loss": 0.0612,
      "step": 10676
    },
    {
      "epoch": 0.8297326701896176,
      "grad_norm": 0.6472070217132568,
      "learning_rate": 5.851336649051912e-06,
      "loss": 0.67,
      "step": 10677
    },
    {
      "epoch": 0.8298103823437986,
      "grad_norm": 1.2925965785980225,
      "learning_rate": 5.8509480882810075e-06,
      "loss": 0.4222,
      "step": 10678
    },
    {
      "epoch": 0.8298880944979795,
      "grad_norm": 0.6349649429321289,
      "learning_rate": 5.850559527510103e-06,
      "loss": 0.2092,
      "step": 10679
    },
    {
      "epoch": 0.8299658066521604,
      "grad_norm": 0.3942546844482422,
      "learning_rate": 5.850170966739198e-06,
      "loss": 0.1122,
      "step": 10680
    },
    {
      "epoch": 0.8300435188063413,
      "grad_norm": 1.1735458374023438,
      "learning_rate": 5.849782405968294e-06,
      "loss": 0.6485,
      "step": 10681
    },
    {
      "epoch": 0.8301212309605223,
      "grad_norm": 0.35599881410598755,
      "learning_rate": 5.84939384519739e-06,
      "loss": 0.1349,
      "step": 10682
    },
    {
      "epoch": 0.8301989431147031,
      "grad_norm": 12.729345321655273,
      "learning_rate": 5.849005284426485e-06,
      "loss": 2.517,
      "step": 10683
    },
    {
      "epoch": 0.8302766552688841,
      "grad_norm": 1.0059808492660522,
      "learning_rate": 5.84861672365558e-06,
      "loss": 0.1734,
      "step": 10684
    },
    {
      "epoch": 0.830354367423065,
      "grad_norm": 0.2857135534286499,
      "learning_rate": 5.8482281628846756e-06,
      "loss": 0.2185,
      "step": 10685
    },
    {
      "epoch": 0.8304320795772459,
      "grad_norm": 0.4191245138645172,
      "learning_rate": 5.8478396021137705e-06,
      "loss": 0.1648,
      "step": 10686
    },
    {
      "epoch": 0.8305097917314268,
      "grad_norm": 0.10349707305431366,
      "learning_rate": 5.847451041342866e-06,
      "loss": 0.0391,
      "step": 10687
    },
    {
      "epoch": 0.8305875038856078,
      "grad_norm": 0.45625919103622437,
      "learning_rate": 5.847062480571962e-06,
      "loss": 0.3177,
      "step": 10688
    },
    {
      "epoch": 0.8306652160397886,
      "grad_norm": 0.21917475759983063,
      "learning_rate": 5.846673919801057e-06,
      "loss": 0.0593,
      "step": 10689
    },
    {
      "epoch": 0.8307429281939696,
      "grad_norm": 0.1863977164030075,
      "learning_rate": 5.846285359030153e-06,
      "loss": 0.0404,
      "step": 10690
    },
    {
      "epoch": 0.8308206403481504,
      "grad_norm": 0.2709740698337555,
      "learning_rate": 5.845896798259249e-06,
      "loss": 0.1331,
      "step": 10691
    },
    {
      "epoch": 0.8308983525023313,
      "grad_norm": 0.1785714477300644,
      "learning_rate": 5.845508237488343e-06,
      "loss": 0.0671,
      "step": 10692
    },
    {
      "epoch": 0.8309760646565123,
      "grad_norm": 0.317693293094635,
      "learning_rate": 5.8451196767174386e-06,
      "loss": 0.1685,
      "step": 10693
    },
    {
      "epoch": 0.8310537768106931,
      "grad_norm": 0.5330753922462463,
      "learning_rate": 5.844731115946534e-06,
      "loss": 0.1549,
      "step": 10694
    },
    {
      "epoch": 0.8311314889648741,
      "grad_norm": 0.44350361824035645,
      "learning_rate": 5.844342555175629e-06,
      "loss": 0.1547,
      "step": 10695
    },
    {
      "epoch": 0.831209201119055,
      "grad_norm": 0.35321271419525146,
      "learning_rate": 5.843953994404725e-06,
      "loss": 0.3021,
      "step": 10696
    },
    {
      "epoch": 0.8312869132732359,
      "grad_norm": 0.3969951868057251,
      "learning_rate": 5.843565433633821e-06,
      "loss": 0.2162,
      "step": 10697
    },
    {
      "epoch": 0.8313646254274168,
      "grad_norm": 0.1296738237142563,
      "learning_rate": 5.843176872862916e-06,
      "loss": 0.0306,
      "step": 10698
    },
    {
      "epoch": 0.8314423375815978,
      "grad_norm": 0.42270565032958984,
      "learning_rate": 5.842788312092012e-06,
      "loss": 0.2162,
      "step": 10699
    },
    {
      "epoch": 0.8315200497357786,
      "grad_norm": 0.4984506666660309,
      "learning_rate": 5.8423997513211074e-06,
      "loss": 0.1988,
      "step": 10700
    },
    {
      "epoch": 0.8315977618899596,
      "grad_norm": 0.03073619306087494,
      "learning_rate": 5.842011190550203e-06,
      "loss": 0.0032,
      "step": 10701
    },
    {
      "epoch": 0.8316754740441406,
      "grad_norm": 0.44839680194854736,
      "learning_rate": 5.841622629779297e-06,
      "loss": 0.0907,
      "step": 10702
    },
    {
      "epoch": 0.8317531861983214,
      "grad_norm": 0.3789573609828949,
      "learning_rate": 5.841234069008393e-06,
      "loss": 0.1412,
      "step": 10703
    },
    {
      "epoch": 0.8318308983525023,
      "grad_norm": 0.5160437226295471,
      "learning_rate": 5.840845508237489e-06,
      "loss": 0.1713,
      "step": 10704
    },
    {
      "epoch": 0.8319086105066833,
      "grad_norm": 0.18063144385814667,
      "learning_rate": 5.840456947466584e-06,
      "loss": 0.0315,
      "step": 10705
    },
    {
      "epoch": 0.8319863226608641,
      "grad_norm": 1.6597479581832886,
      "learning_rate": 5.84006838669568e-06,
      "loss": 0.4916,
      "step": 10706
    },
    {
      "epoch": 0.8320640348150451,
      "grad_norm": 0.4944508671760559,
      "learning_rate": 5.8396798259247755e-06,
      "loss": 0.0514,
      "step": 10707
    },
    {
      "epoch": 0.8321417469692259,
      "grad_norm": 0.2753905951976776,
      "learning_rate": 5.8392912651538704e-06,
      "loss": 0.2699,
      "step": 10708
    },
    {
      "epoch": 0.8322194591234069,
      "grad_norm": 0.9839076995849609,
      "learning_rate": 5.838902704382966e-06,
      "loss": 0.4428,
      "step": 10709
    },
    {
      "epoch": 0.8322971712775878,
      "grad_norm": 0.3342646360397339,
      "learning_rate": 5.838514143612062e-06,
      "loss": 0.125,
      "step": 10710
    },
    {
      "epoch": 0.8323748834317687,
      "grad_norm": 0.17161686718463898,
      "learning_rate": 5.838125582841156e-06,
      "loss": 0.0304,
      "step": 10711
    },
    {
      "epoch": 0.8324525955859496,
      "grad_norm": 0.07896572351455688,
      "learning_rate": 5.837737022070252e-06,
      "loss": 0.0273,
      "step": 10712
    },
    {
      "epoch": 0.8325303077401306,
      "grad_norm": 0.13394483923912048,
      "learning_rate": 5.837348461299348e-06,
      "loss": 0.0544,
      "step": 10713
    },
    {
      "epoch": 0.8326080198943114,
      "grad_norm": 0.1641649305820465,
      "learning_rate": 5.836959900528443e-06,
      "loss": 0.0333,
      "step": 10714
    },
    {
      "epoch": 0.8326857320484924,
      "grad_norm": 0.6267252564430237,
      "learning_rate": 5.8365713397575385e-06,
      "loss": 0.3999,
      "step": 10715
    },
    {
      "epoch": 0.8327634442026733,
      "grad_norm": 0.28397050499916077,
      "learning_rate": 5.836182778986634e-06,
      "loss": 0.1263,
      "step": 10716
    },
    {
      "epoch": 0.8328411563568542,
      "grad_norm": 0.06973773241043091,
      "learning_rate": 5.835794218215729e-06,
      "loss": 0.0082,
      "step": 10717
    },
    {
      "epoch": 0.8329188685110351,
      "grad_norm": 0.7494623064994812,
      "learning_rate": 5.835405657444825e-06,
      "loss": 0.2804,
      "step": 10718
    },
    {
      "epoch": 0.8329965806652161,
      "grad_norm": 0.2998458445072174,
      "learning_rate": 5.835017096673921e-06,
      "loss": 0.3029,
      "step": 10719
    },
    {
      "epoch": 0.8330742928193969,
      "grad_norm": 0.23179689049720764,
      "learning_rate": 5.834628535903015e-06,
      "loss": 0.079,
      "step": 10720
    },
    {
      "epoch": 0.8331520049735779,
      "grad_norm": 0.274750292301178,
      "learning_rate": 5.834239975132111e-06,
      "loss": 0.0683,
      "step": 10721
    },
    {
      "epoch": 0.8332297171277587,
      "grad_norm": 0.3636007308959961,
      "learning_rate": 5.8338514143612065e-06,
      "loss": 0.0494,
      "step": 10722
    },
    {
      "epoch": 0.8333074292819397,
      "grad_norm": 0.06883668154478073,
      "learning_rate": 5.8334628535903015e-06,
      "loss": 0.0112,
      "step": 10723
    },
    {
      "epoch": 0.8333851414361206,
      "grad_norm": 0.6621965169906616,
      "learning_rate": 5.833074292819397e-06,
      "loss": 0.2761,
      "step": 10724
    },
    {
      "epoch": 0.8334628535903015,
      "grad_norm": 0.3162405490875244,
      "learning_rate": 5.832685732048493e-06,
      "loss": 0.1202,
      "step": 10725
    },
    {
      "epoch": 0.8335405657444824,
      "grad_norm": 0.44376975297927856,
      "learning_rate": 5.832297171277588e-06,
      "loss": 0.1774,
      "step": 10726
    },
    {
      "epoch": 0.8336182778986634,
      "grad_norm": 0.7481838464736938,
      "learning_rate": 5.831908610506684e-06,
      "loss": 0.7492,
      "step": 10727
    },
    {
      "epoch": 0.8336959900528442,
      "grad_norm": 0.3642224371433258,
      "learning_rate": 5.83152004973578e-06,
      "loss": 0.4292,
      "step": 10728
    },
    {
      "epoch": 0.8337737022070252,
      "grad_norm": 0.7826552987098694,
      "learning_rate": 5.831131488964875e-06,
      "loss": 0.5102,
      "step": 10729
    },
    {
      "epoch": 0.8338514143612061,
      "grad_norm": 0.3783532977104187,
      "learning_rate": 5.8307429281939695e-06,
      "loss": 0.2013,
      "step": 10730
    },
    {
      "epoch": 0.833929126515387,
      "grad_norm": 0.4364272356033325,
      "learning_rate": 5.830354367423065e-06,
      "loss": 0.1002,
      "step": 10731
    },
    {
      "epoch": 0.8340068386695679,
      "grad_norm": 0.5399134159088135,
      "learning_rate": 5.829965806652161e-06,
      "loss": 0.4108,
      "step": 10732
    },
    {
      "epoch": 0.8340845508237489,
      "grad_norm": 0.6037853956222534,
      "learning_rate": 5.829577245881256e-06,
      "loss": 0.1347,
      "step": 10733
    },
    {
      "epoch": 0.8341622629779297,
      "grad_norm": 0.18597248196601868,
      "learning_rate": 5.829188685110352e-06,
      "loss": 0.0493,
      "step": 10734
    },
    {
      "epoch": 0.8342399751321107,
      "grad_norm": 0.08614800125360489,
      "learning_rate": 5.828800124339448e-06,
      "loss": 0.0162,
      "step": 10735
    },
    {
      "epoch": 0.8343176872862915,
      "grad_norm": 0.1891452819108963,
      "learning_rate": 5.828411563568543e-06,
      "loss": 0.0653,
      "step": 10736
    },
    {
      "epoch": 0.8343953994404725,
      "grad_norm": 0.6627591848373413,
      "learning_rate": 5.828023002797638e-06,
      "loss": 0.2487,
      "step": 10737
    },
    {
      "epoch": 0.8344731115946534,
      "grad_norm": 0.06660979241132736,
      "learning_rate": 5.827634442026734e-06,
      "loss": 0.0063,
      "step": 10738
    },
    {
      "epoch": 0.8345508237488343,
      "grad_norm": 0.4833413064479828,
      "learning_rate": 5.827245881255828e-06,
      "loss": 0.1751,
      "step": 10739
    },
    {
      "epoch": 0.8346285359030152,
      "grad_norm": 0.37922239303588867,
      "learning_rate": 5.826857320484924e-06,
      "loss": 0.0567,
      "step": 10740
    },
    {
      "epoch": 0.8347062480571962,
      "grad_norm": 0.3105093240737915,
      "learning_rate": 5.82646875971402e-06,
      "loss": 0.3846,
      "step": 10741
    },
    {
      "epoch": 0.834783960211377,
      "grad_norm": 0.6765766143798828,
      "learning_rate": 5.826080198943115e-06,
      "loss": 0.2404,
      "step": 10742
    },
    {
      "epoch": 0.834861672365558,
      "grad_norm": 0.21500051021575928,
      "learning_rate": 5.825691638172211e-06,
      "loss": 0.0722,
      "step": 10743
    },
    {
      "epoch": 0.8349393845197389,
      "grad_norm": 0.03655378147959709,
      "learning_rate": 5.825303077401306e-06,
      "loss": 0.004,
      "step": 10744
    },
    {
      "epoch": 0.8350170966739198,
      "grad_norm": 0.30193066596984863,
      "learning_rate": 5.824914516630401e-06,
      "loss": 0.1772,
      "step": 10745
    },
    {
      "epoch": 0.8350948088281007,
      "grad_norm": 0.31021735072135925,
      "learning_rate": 5.824525955859497e-06,
      "loss": 0.0616,
      "step": 10746
    },
    {
      "epoch": 0.8351725209822817,
      "grad_norm": 0.4666300117969513,
      "learning_rate": 5.824137395088593e-06,
      "loss": 0.3022,
      "step": 10747
    },
    {
      "epoch": 0.8352502331364625,
      "grad_norm": 0.034373071044683456,
      "learning_rate": 5.823748834317687e-06,
      "loss": 0.0013,
      "step": 10748
    },
    {
      "epoch": 0.8353279452906435,
      "grad_norm": 0.3746241629123688,
      "learning_rate": 5.823360273546783e-06,
      "loss": 0.248,
      "step": 10749
    },
    {
      "epoch": 0.8354056574448244,
      "grad_norm": 0.7310852408409119,
      "learning_rate": 5.822971712775879e-06,
      "loss": 0.3654,
      "step": 10750
    },
    {
      "epoch": 0.8354833695990053,
      "grad_norm": 0.2770944833755493,
      "learning_rate": 5.822583152004974e-06,
      "loss": 0.0756,
      "step": 10751
    },
    {
      "epoch": 0.8355610817531862,
      "grad_norm": 0.35882052779197693,
      "learning_rate": 5.822194591234069e-06,
      "loss": 0.181,
      "step": 10752
    },
    {
      "epoch": 0.8356387939073671,
      "grad_norm": 0.6264572143554688,
      "learning_rate": 5.821806030463165e-06,
      "loss": 0.3001,
      "step": 10753
    },
    {
      "epoch": 0.835716506061548,
      "grad_norm": 0.15076521039009094,
      "learning_rate": 5.82141746969226e-06,
      "loss": 0.0242,
      "step": 10754
    },
    {
      "epoch": 0.835794218215729,
      "grad_norm": 0.6451253294944763,
      "learning_rate": 5.821028908921356e-06,
      "loss": 0.2362,
      "step": 10755
    },
    {
      "epoch": 0.8358719303699098,
      "grad_norm": 0.22501705586910248,
      "learning_rate": 5.820640348150452e-06,
      "loss": 0.0651,
      "step": 10756
    },
    {
      "epoch": 0.8359496425240908,
      "grad_norm": 0.1691410094499588,
      "learning_rate": 5.820251787379546e-06,
      "loss": 0.0974,
      "step": 10757
    },
    {
      "epoch": 0.8360273546782717,
      "grad_norm": 0.43815773725509644,
      "learning_rate": 5.819863226608642e-06,
      "loss": 0.134,
      "step": 10758
    },
    {
      "epoch": 0.8361050668324526,
      "grad_norm": 0.8376495838165283,
      "learning_rate": 5.8194746658377374e-06,
      "loss": 0.6734,
      "step": 10759
    },
    {
      "epoch": 0.8361827789866335,
      "grad_norm": 0.7729916572570801,
      "learning_rate": 5.819086105066833e-06,
      "loss": 0.1854,
      "step": 10760
    },
    {
      "epoch": 0.8362604911408145,
      "grad_norm": 0.15575362741947174,
      "learning_rate": 5.818697544295928e-06,
      "loss": 0.0433,
      "step": 10761
    },
    {
      "epoch": 0.8363382032949953,
      "grad_norm": 0.33886483311653137,
      "learning_rate": 5.818308983525024e-06,
      "loss": 0.1057,
      "step": 10762
    },
    {
      "epoch": 0.8364159154491763,
      "grad_norm": 0.18219693005084991,
      "learning_rate": 5.81792042275412e-06,
      "loss": 0.0392,
      "step": 10763
    },
    {
      "epoch": 0.8364936276033572,
      "grad_norm": 0.27263015508651733,
      "learning_rate": 5.817531861983215e-06,
      "loss": 0.1272,
      "step": 10764
    },
    {
      "epoch": 0.8365713397575381,
      "grad_norm": 0.19580978155136108,
      "learning_rate": 5.8171433012123105e-06,
      "loss": 0.0918,
      "step": 10765
    },
    {
      "epoch": 0.836649051911719,
      "grad_norm": 0.18572460114955902,
      "learning_rate": 5.816754740441406e-06,
      "loss": 0.095,
      "step": 10766
    },
    {
      "epoch": 0.8367267640658999,
      "grad_norm": 0.2507207989692688,
      "learning_rate": 5.8163661796705e-06,
      "loss": 0.0896,
      "step": 10767
    },
    {
      "epoch": 0.8368044762200808,
      "grad_norm": 0.3773374557495117,
      "learning_rate": 5.815977618899596e-06,
      "loss": 0.3472,
      "step": 10768
    },
    {
      "epoch": 0.8368821883742618,
      "grad_norm": 0.46157369017601013,
      "learning_rate": 5.815589058128692e-06,
      "loss": 0.2798,
      "step": 10769
    },
    {
      "epoch": 0.8369599005284426,
      "grad_norm": 0.479178786277771,
      "learning_rate": 5.815200497357787e-06,
      "loss": 0.1352,
      "step": 10770
    },
    {
      "epoch": 0.8370376126826236,
      "grad_norm": 0.5146462321281433,
      "learning_rate": 5.814811936586883e-06,
      "loss": 0.2688,
      "step": 10771
    },
    {
      "epoch": 0.8371153248368045,
      "grad_norm": 0.3738987147808075,
      "learning_rate": 5.8144233758159786e-06,
      "loss": 0.4575,
      "step": 10772
    },
    {
      "epoch": 0.8371930369909854,
      "grad_norm": 0.20639048516750336,
      "learning_rate": 5.8140348150450735e-06,
      "loss": 0.083,
      "step": 10773
    },
    {
      "epoch": 0.8372707491451663,
      "grad_norm": 0.10087095201015472,
      "learning_rate": 5.813646254274169e-06,
      "loss": 0.007,
      "step": 10774
    },
    {
      "epoch": 0.8373484612993473,
      "grad_norm": 0.48975497484207153,
      "learning_rate": 5.813257693503265e-06,
      "loss": 0.4954,
      "step": 10775
    },
    {
      "epoch": 0.8374261734535281,
      "grad_norm": 0.5416392087936401,
      "learning_rate": 5.812869132732359e-06,
      "loss": 0.2601,
      "step": 10776
    },
    {
      "epoch": 0.837503885607709,
      "grad_norm": 0.43498268723487854,
      "learning_rate": 5.812480571961455e-06,
      "loss": 0.2859,
      "step": 10777
    },
    {
      "epoch": 0.83758159776189,
      "grad_norm": 0.25003206729888916,
      "learning_rate": 5.812092011190551e-06,
      "loss": 0.1759,
      "step": 10778
    },
    {
      "epoch": 0.8376593099160708,
      "grad_norm": 0.27760767936706543,
      "learning_rate": 5.811703450419646e-06,
      "loss": 0.0571,
      "step": 10779
    },
    {
      "epoch": 0.8377370220702518,
      "grad_norm": 0.4621518552303314,
      "learning_rate": 5.8113148896487415e-06,
      "loss": 0.0404,
      "step": 10780
    },
    {
      "epoch": 0.8378147342244328,
      "grad_norm": 0.871412456035614,
      "learning_rate": 5.810926328877837e-06,
      "loss": 0.4239,
      "step": 10781
    },
    {
      "epoch": 0.8378924463786136,
      "grad_norm": 0.43329980969429016,
      "learning_rate": 5.810537768106932e-06,
      "loss": 0.1398,
      "step": 10782
    },
    {
      "epoch": 0.8379701585327946,
      "grad_norm": 0.2915237247943878,
      "learning_rate": 5.810149207336028e-06,
      "loss": 0.0842,
      "step": 10783
    },
    {
      "epoch": 0.8380478706869754,
      "grad_norm": 0.4982295334339142,
      "learning_rate": 5.809760646565124e-06,
      "loss": 0.3549,
      "step": 10784
    },
    {
      "epoch": 0.8381255828411563,
      "grad_norm": 0.7708179354667664,
      "learning_rate": 5.809372085794218e-06,
      "loss": 0.3693,
      "step": 10785
    },
    {
      "epoch": 0.8382032949953373,
      "grad_norm": 0.1332307755947113,
      "learning_rate": 5.808983525023314e-06,
      "loss": 0.0227,
      "step": 10786
    },
    {
      "epoch": 0.8382810071495181,
      "grad_norm": 0.6418635845184326,
      "learning_rate": 5.80859496425241e-06,
      "loss": 0.3083,
      "step": 10787
    },
    {
      "epoch": 0.8383587193036991,
      "grad_norm": 0.3419225811958313,
      "learning_rate": 5.8082064034815045e-06,
      "loss": 0.0859,
      "step": 10788
    },
    {
      "epoch": 0.83843643145788,
      "grad_norm": 0.3900788724422455,
      "learning_rate": 5.8078178427106e-06,
      "loss": 0.2672,
      "step": 10789
    },
    {
      "epoch": 0.8385141436120609,
      "grad_norm": 0.1626390814781189,
      "learning_rate": 5.807429281939696e-06,
      "loss": 0.0513,
      "step": 10790
    },
    {
      "epoch": 0.8385918557662418,
      "grad_norm": 0.1947031021118164,
      "learning_rate": 5.807040721168792e-06,
      "loss": 0.0623,
      "step": 10791
    },
    {
      "epoch": 0.8386695679204228,
      "grad_norm": 0.08725504577159882,
      "learning_rate": 5.806652160397887e-06,
      "loss": 0.01,
      "step": 10792
    },
    {
      "epoch": 0.8387472800746036,
      "grad_norm": 0.9236481785774231,
      "learning_rate": 5.806263599626983e-06,
      "loss": 0.3979,
      "step": 10793
    },
    {
      "epoch": 0.8388249922287846,
      "grad_norm": 0.14346958696842194,
      "learning_rate": 5.8058750388560785e-06,
      "loss": 0.0261,
      "step": 10794
    },
    {
      "epoch": 0.8389027043829655,
      "grad_norm": 0.3334571123123169,
      "learning_rate": 5.8054864780851726e-06,
      "loss": 0.1727,
      "step": 10795
    },
    {
      "epoch": 0.8389804165371464,
      "grad_norm": 0.20246173441410065,
      "learning_rate": 5.805097917314268e-06,
      "loss": 0.0547,
      "step": 10796
    },
    {
      "epoch": 0.8390581286913273,
      "grad_norm": 0.4877094626426697,
      "learning_rate": 5.804709356543364e-06,
      "loss": 0.2822,
      "step": 10797
    },
    {
      "epoch": 0.8391358408455082,
      "grad_norm": 0.4459204375743866,
      "learning_rate": 5.804320795772459e-06,
      "loss": 0.1451,
      "step": 10798
    },
    {
      "epoch": 0.8392135529996891,
      "grad_norm": 0.4642811715602875,
      "learning_rate": 5.803932235001555e-06,
      "loss": 0.1985,
      "step": 10799
    },
    {
      "epoch": 0.8392912651538701,
      "grad_norm": 0.289752721786499,
      "learning_rate": 5.803543674230651e-06,
      "loss": 0.3921,
      "step": 10800
    },
    {
      "epoch": 0.8393689773080509,
      "grad_norm": 0.10185502469539642,
      "learning_rate": 5.803155113459746e-06,
      "loss": 0.0324,
      "step": 10801
    },
    {
      "epoch": 0.8394466894622319,
      "grad_norm": 0.4123232066631317,
      "learning_rate": 5.8027665526888415e-06,
      "loss": 0.5983,
      "step": 10802
    },
    {
      "epoch": 0.8395244016164128,
      "grad_norm": 0.5848816633224487,
      "learning_rate": 5.802377991917937e-06,
      "loss": 0.341,
      "step": 10803
    },
    {
      "epoch": 0.8396021137705937,
      "grad_norm": 0.1409066617488861,
      "learning_rate": 5.801989431147031e-06,
      "loss": 0.0612,
      "step": 10804
    },
    {
      "epoch": 0.8396798259247746,
      "grad_norm": 0.470356822013855,
      "learning_rate": 5.801600870376127e-06,
      "loss": 0.1971,
      "step": 10805
    },
    {
      "epoch": 0.8397575380789556,
      "grad_norm": 0.4631817638874054,
      "learning_rate": 5.801212309605223e-06,
      "loss": 0.1306,
      "step": 10806
    },
    {
      "epoch": 0.8398352502331364,
      "grad_norm": 3.6805598735809326,
      "learning_rate": 5.800823748834318e-06,
      "loss": 0.5747,
      "step": 10807
    },
    {
      "epoch": 0.8399129623873174,
      "grad_norm": 0.24820400774478912,
      "learning_rate": 5.800435188063414e-06,
      "loss": 0.1326,
      "step": 10808
    },
    {
      "epoch": 0.8399906745414983,
      "grad_norm": 0.20099559426307678,
      "learning_rate": 5.8000466272925095e-06,
      "loss": 0.0605,
      "step": 10809
    },
    {
      "epoch": 0.8400683866956792,
      "grad_norm": 0.20555883646011353,
      "learning_rate": 5.799658066521604e-06,
      "loss": 0.0629,
      "step": 10810
    },
    {
      "epoch": 0.8401460988498601,
      "grad_norm": 0.27913257479667664,
      "learning_rate": 5.799269505750699e-06,
      "loss": 0.0335,
      "step": 10811
    },
    {
      "epoch": 0.840223811004041,
      "grad_norm": 1.0242915153503418,
      "learning_rate": 5.798880944979795e-06,
      "loss": 0.1406,
      "step": 10812
    },
    {
      "epoch": 0.8403015231582219,
      "grad_norm": 0.5246750712394714,
      "learning_rate": 5.79849238420889e-06,
      "loss": 0.1116,
      "step": 10813
    },
    {
      "epoch": 0.8403792353124029,
      "grad_norm": 0.5228047370910645,
      "learning_rate": 5.798103823437986e-06,
      "loss": 0.3186,
      "step": 10814
    },
    {
      "epoch": 0.8404569474665837,
      "grad_norm": 0.20653796195983887,
      "learning_rate": 5.797715262667082e-06,
      "loss": 0.0686,
      "step": 10815
    },
    {
      "epoch": 0.8405346596207647,
      "grad_norm": 1.8219208717346191,
      "learning_rate": 5.797326701896177e-06,
      "loss": 0.623,
      "step": 10816
    },
    {
      "epoch": 0.8406123717749456,
      "grad_norm": 0.35657840967178345,
      "learning_rate": 5.7969381411252725e-06,
      "loss": 0.1525,
      "step": 10817
    },
    {
      "epoch": 0.8406900839291265,
      "grad_norm": 0.17936848104000092,
      "learning_rate": 5.796549580354368e-06,
      "loss": 0.1051,
      "step": 10818
    },
    {
      "epoch": 0.8407677960833074,
      "grad_norm": 0.39793241024017334,
      "learning_rate": 5.796161019583462e-06,
      "loss": 0.0832,
      "step": 10819
    },
    {
      "epoch": 0.8408455082374884,
      "grad_norm": 0.4985630512237549,
      "learning_rate": 5.795772458812558e-06,
      "loss": 0.2067,
      "step": 10820
    },
    {
      "epoch": 0.8409232203916692,
      "grad_norm": 0.3060438632965088,
      "learning_rate": 5.795383898041654e-06,
      "loss": 0.1656,
      "step": 10821
    },
    {
      "epoch": 0.8410009325458502,
      "grad_norm": 0.5048294067382812,
      "learning_rate": 5.79499533727075e-06,
      "loss": 0.2188,
      "step": 10822
    },
    {
      "epoch": 0.8410786447000311,
      "grad_norm": 0.2788473963737488,
      "learning_rate": 5.794606776499845e-06,
      "loss": 0.1017,
      "step": 10823
    },
    {
      "epoch": 0.841156356854212,
      "grad_norm": 0.48582199215888977,
      "learning_rate": 5.7942182157289405e-06,
      "loss": 0.1503,
      "step": 10824
    },
    {
      "epoch": 0.8412340690083929,
      "grad_norm": 0.1728813201189041,
      "learning_rate": 5.793829654958036e-06,
      "loss": 0.0365,
      "step": 10825
    },
    {
      "epoch": 0.8413117811625739,
      "grad_norm": 0.6066631078720093,
      "learning_rate": 5.793441094187131e-06,
      "loss": 0.3142,
      "step": 10826
    },
    {
      "epoch": 0.8413894933167547,
      "grad_norm": 0.29831063747406006,
      "learning_rate": 5.793052533416227e-06,
      "loss": 0.0589,
      "step": 10827
    },
    {
      "epoch": 0.8414672054709357,
      "grad_norm": 0.1415843665599823,
      "learning_rate": 5.792663972645323e-06,
      "loss": 0.0162,
      "step": 10828
    },
    {
      "epoch": 0.8415449176251165,
      "grad_norm": 0.2212316244840622,
      "learning_rate": 5.792275411874417e-06,
      "loss": 0.0432,
      "step": 10829
    },
    {
      "epoch": 0.8416226297792975,
      "grad_norm": 0.2917497456073761,
      "learning_rate": 5.791886851103513e-06,
      "loss": 0.1209,
      "step": 10830
    },
    {
      "epoch": 0.8417003419334784,
      "grad_norm": 0.2905706465244293,
      "learning_rate": 5.7914982903326085e-06,
      "loss": 0.1493,
      "step": 10831
    },
    {
      "epoch": 0.8417780540876593,
      "grad_norm": 0.6137406826019287,
      "learning_rate": 5.7911097295617035e-06,
      "loss": 0.4194,
      "step": 10832
    },
    {
      "epoch": 0.8418557662418402,
      "grad_norm": 0.16716301441192627,
      "learning_rate": 5.790721168790799e-06,
      "loss": 0.1819,
      "step": 10833
    },
    {
      "epoch": 0.8419334783960212,
      "grad_norm": 0.282375693321228,
      "learning_rate": 5.790332608019895e-06,
      "loss": 0.1491,
      "step": 10834
    },
    {
      "epoch": 0.842011190550202,
      "grad_norm": 0.28194352984428406,
      "learning_rate": 5.78994404724899e-06,
      "loss": 0.0436,
      "step": 10835
    },
    {
      "epoch": 0.842088902704383,
      "grad_norm": 0.08403979241847992,
      "learning_rate": 5.789555486478086e-06,
      "loss": 0.0439,
      "step": 10836
    },
    {
      "epoch": 0.8421666148585639,
      "grad_norm": 0.12430209666490555,
      "learning_rate": 5.789166925707182e-06,
      "loss": 0.0238,
      "step": 10837
    },
    {
      "epoch": 0.8422443270127448,
      "grad_norm": 0.11535370349884033,
      "learning_rate": 5.788778364936276e-06,
      "loss": 0.0179,
      "step": 10838
    },
    {
      "epoch": 0.8423220391669257,
      "grad_norm": 0.1408085972070694,
      "learning_rate": 5.7883898041653715e-06,
      "loss": 0.107,
      "step": 10839
    },
    {
      "epoch": 0.8423997513211067,
      "grad_norm": 0.32048502564430237,
      "learning_rate": 5.788001243394467e-06,
      "loss": 0.0513,
      "step": 10840
    },
    {
      "epoch": 0.8424774634752875,
      "grad_norm": 0.1026882752776146,
      "learning_rate": 5.787612682623562e-06,
      "loss": 0.0143,
      "step": 10841
    },
    {
      "epoch": 0.8425551756294685,
      "grad_norm": 0.07354402542114258,
      "learning_rate": 5.787224121852658e-06,
      "loss": 0.0295,
      "step": 10842
    },
    {
      "epoch": 0.8426328877836493,
      "grad_norm": 0.5206620693206787,
      "learning_rate": 5.786835561081754e-06,
      "loss": 0.259,
      "step": 10843
    },
    {
      "epoch": 0.8427105999378303,
      "grad_norm": 0.2417251318693161,
      "learning_rate": 5.786447000310849e-06,
      "loss": 0.1499,
      "step": 10844
    },
    {
      "epoch": 0.8427883120920112,
      "grad_norm": 0.3214315176010132,
      "learning_rate": 5.786058439539945e-06,
      "loss": 0.1342,
      "step": 10845
    },
    {
      "epoch": 0.8428660242461921,
      "grad_norm": 0.08529580384492874,
      "learning_rate": 5.78566987876904e-06,
      "loss": 0.0155,
      "step": 10846
    },
    {
      "epoch": 0.842943736400373,
      "grad_norm": 0.4202132821083069,
      "learning_rate": 5.7852813179981345e-06,
      "loss": 0.2733,
      "step": 10847
    },
    {
      "epoch": 0.843021448554554,
      "grad_norm": 0.17279942333698273,
      "learning_rate": 5.78489275722723e-06,
      "loss": 0.0784,
      "step": 10848
    },
    {
      "epoch": 0.8430991607087348,
      "grad_norm": 0.42747101187705994,
      "learning_rate": 5.784504196456326e-06,
      "loss": 0.1593,
      "step": 10849
    },
    {
      "epoch": 0.8431768728629158,
      "grad_norm": 0.49706268310546875,
      "learning_rate": 5.784115635685422e-06,
      "loss": 0.2017,
      "step": 10850
    },
    {
      "epoch": 0.8432545850170967,
      "grad_norm": 0.14983925223350525,
      "learning_rate": 5.783727074914517e-06,
      "loss": 0.067,
      "step": 10851
    },
    {
      "epoch": 0.8433322971712776,
      "grad_norm": 0.4420529007911682,
      "learning_rate": 5.783338514143613e-06,
      "loss": 0.4681,
      "step": 10852
    },
    {
      "epoch": 0.8434100093254585,
      "grad_norm": 0.5459569692611694,
      "learning_rate": 5.7829499533727085e-06,
      "loss": 0.4126,
      "step": 10853
    },
    {
      "epoch": 0.8434877214796395,
      "grad_norm": 0.4923040568828583,
      "learning_rate": 5.782561392601803e-06,
      "loss": 0.1265,
      "step": 10854
    },
    {
      "epoch": 0.8435654336338203,
      "grad_norm": 0.19798161089420319,
      "learning_rate": 5.782172831830899e-06,
      "loss": 0.0998,
      "step": 10855
    },
    {
      "epoch": 0.8436431457880013,
      "grad_norm": 0.5897995233535767,
      "learning_rate": 5.781784271059995e-06,
      "loss": 0.3733,
      "step": 10856
    },
    {
      "epoch": 0.8437208579421822,
      "grad_norm": 0.5954846739768982,
      "learning_rate": 5.781395710289089e-06,
      "loss": 0.1378,
      "step": 10857
    },
    {
      "epoch": 0.843798570096363,
      "grad_norm": 0.2982175350189209,
      "learning_rate": 5.781007149518185e-06,
      "loss": 0.1849,
      "step": 10858
    },
    {
      "epoch": 0.843876282250544,
      "grad_norm": 0.5238990783691406,
      "learning_rate": 5.780618588747281e-06,
      "loss": 0.2073,
      "step": 10859
    },
    {
      "epoch": 0.8439539944047248,
      "grad_norm": 0.14693033695220947,
      "learning_rate": 5.780230027976376e-06,
      "loss": 0.0328,
      "step": 10860
    },
    {
      "epoch": 0.8440317065589058,
      "grad_norm": 0.2993431091308594,
      "learning_rate": 5.7798414672054714e-06,
      "loss": 0.2248,
      "step": 10861
    },
    {
      "epoch": 0.8441094187130868,
      "grad_norm": 0.14797911047935486,
      "learning_rate": 5.779452906434567e-06,
      "loss": 0.0398,
      "step": 10862
    },
    {
      "epoch": 0.8441871308672676,
      "grad_norm": 0.6052603721618652,
      "learning_rate": 5.779064345663662e-06,
      "loss": 0.5098,
      "step": 10863
    },
    {
      "epoch": 0.8442648430214486,
      "grad_norm": 0.03736342489719391,
      "learning_rate": 5.778675784892758e-06,
      "loss": 0.004,
      "step": 10864
    },
    {
      "epoch": 0.8443425551756295,
      "grad_norm": 0.3759067952632904,
      "learning_rate": 5.778287224121854e-06,
      "loss": 0.0489,
      "step": 10865
    },
    {
      "epoch": 0.8444202673298103,
      "grad_norm": 0.433604896068573,
      "learning_rate": 5.777898663350948e-06,
      "loss": 0.3048,
      "step": 10866
    },
    {
      "epoch": 0.8444979794839913,
      "grad_norm": 0.10280409455299377,
      "learning_rate": 5.777510102580044e-06,
      "loss": 0.0373,
      "step": 10867
    },
    {
      "epoch": 0.8445756916381723,
      "grad_norm": 0.31506702303886414,
      "learning_rate": 5.7771215418091395e-06,
      "loss": 0.0764,
      "step": 10868
    },
    {
      "epoch": 0.8446534037923531,
      "grad_norm": 0.40488526225090027,
      "learning_rate": 5.7767329810382344e-06,
      "loss": 0.4663,
      "step": 10869
    },
    {
      "epoch": 0.844731115946534,
      "grad_norm": 0.36324343085289,
      "learning_rate": 5.77634442026733e-06,
      "loss": 0.1719,
      "step": 10870
    },
    {
      "epoch": 0.844808828100715,
      "grad_norm": 0.8464100956916809,
      "learning_rate": 5.775955859496426e-06,
      "loss": 0.2638,
      "step": 10871
    },
    {
      "epoch": 0.8448865402548958,
      "grad_norm": 0.7599430084228516,
      "learning_rate": 5.775567298725521e-06,
      "loss": 0.2177,
      "step": 10872
    },
    {
      "epoch": 0.8449642524090768,
      "grad_norm": 0.13527178764343262,
      "learning_rate": 5.775178737954617e-06,
      "loss": 0.07,
      "step": 10873
    },
    {
      "epoch": 0.8450419645632576,
      "grad_norm": 0.5620293021202087,
      "learning_rate": 5.7747901771837126e-06,
      "loss": 0.3231,
      "step": 10874
    },
    {
      "epoch": 0.8451196767174386,
      "grad_norm": 0.2767219543457031,
      "learning_rate": 5.774401616412807e-06,
      "loss": 0.1658,
      "step": 10875
    },
    {
      "epoch": 0.8451973888716195,
      "grad_norm": 0.5166466236114502,
      "learning_rate": 5.7740130556419025e-06,
      "loss": 0.1571,
      "step": 10876
    },
    {
      "epoch": 0.8452751010258004,
      "grad_norm": 0.6464696526527405,
      "learning_rate": 5.773624494870998e-06,
      "loss": 0.1729,
      "step": 10877
    },
    {
      "epoch": 0.8453528131799813,
      "grad_norm": 0.9687739014625549,
      "learning_rate": 5.773235934100093e-06,
      "loss": 0.2398,
      "step": 10878
    },
    {
      "epoch": 0.8454305253341623,
      "grad_norm": 0.8005806803703308,
      "learning_rate": 5.772847373329189e-06,
      "loss": 0.4713,
      "step": 10879
    },
    {
      "epoch": 0.8455082374883431,
      "grad_norm": 0.5487144589424133,
      "learning_rate": 5.772458812558285e-06,
      "loss": 0.4383,
      "step": 10880
    },
    {
      "epoch": 0.8455859496425241,
      "grad_norm": 0.06520304828882217,
      "learning_rate": 5.772070251787381e-06,
      "loss": 0.0243,
      "step": 10881
    },
    {
      "epoch": 0.845663661796705,
      "grad_norm": 0.40115880966186523,
      "learning_rate": 5.7716816910164755e-06,
      "loss": 0.4365,
      "step": 10882
    },
    {
      "epoch": 0.8457413739508859,
      "grad_norm": 0.6127120852470398,
      "learning_rate": 5.771293130245571e-06,
      "loss": 0.2575,
      "step": 10883
    },
    {
      "epoch": 0.8458190861050668,
      "grad_norm": 0.3776634633541107,
      "learning_rate": 5.770904569474667e-06,
      "loss": 0.1517,
      "step": 10884
    },
    {
      "epoch": 0.8458967982592478,
      "grad_norm": 0.20955011248588562,
      "learning_rate": 5.770516008703761e-06,
      "loss": 0.0451,
      "step": 10885
    },
    {
      "epoch": 0.8459745104134286,
      "grad_norm": 0.8324469327926636,
      "learning_rate": 5.770127447932857e-06,
      "loss": 0.2,
      "step": 10886
    },
    {
      "epoch": 0.8460522225676096,
      "grad_norm": 1.1610260009765625,
      "learning_rate": 5.769738887161953e-06,
      "loss": 0.436,
      "step": 10887
    },
    {
      "epoch": 0.8461299347217904,
      "grad_norm": 0.22913098335266113,
      "learning_rate": 5.769350326391048e-06,
      "loss": 0.1569,
      "step": 10888
    },
    {
      "epoch": 0.8462076468759714,
      "grad_norm": 0.44494086503982544,
      "learning_rate": 5.768961765620144e-06,
      "loss": 0.2411,
      "step": 10889
    },
    {
      "epoch": 0.8462853590301523,
      "grad_norm": 0.31149986386299133,
      "learning_rate": 5.768573204849239e-06,
      "loss": 0.3052,
      "step": 10890
    },
    {
      "epoch": 0.8463630711843332,
      "grad_norm": 0.592105507850647,
      "learning_rate": 5.768184644078334e-06,
      "loss": 0.2559,
      "step": 10891
    },
    {
      "epoch": 0.8464407833385141,
      "grad_norm": 0.5228071808815002,
      "learning_rate": 5.76779608330743e-06,
      "loss": 0.5683,
      "step": 10892
    },
    {
      "epoch": 0.8465184954926951,
      "grad_norm": 0.30129894614219666,
      "learning_rate": 5.767407522536526e-06,
      "loss": 0.1526,
      "step": 10893
    },
    {
      "epoch": 0.8465962076468759,
      "grad_norm": 0.41712847352027893,
      "learning_rate": 5.76701896176562e-06,
      "loss": 0.0918,
      "step": 10894
    },
    {
      "epoch": 0.8466739198010569,
      "grad_norm": 0.30908849835395813,
      "learning_rate": 5.766630400994716e-06,
      "loss": 0.1179,
      "step": 10895
    },
    {
      "epoch": 0.8467516319552378,
      "grad_norm": 0.5751046538352966,
      "learning_rate": 5.766241840223812e-06,
      "loss": 0.462,
      "step": 10896
    },
    {
      "epoch": 0.8468293441094187,
      "grad_norm": 0.48711657524108887,
      "learning_rate": 5.7658532794529066e-06,
      "loss": 0.1615,
      "step": 10897
    },
    {
      "epoch": 0.8469070562635996,
      "grad_norm": 1.1944631338119507,
      "learning_rate": 5.765464718682002e-06,
      "loss": 0.3454,
      "step": 10898
    },
    {
      "epoch": 0.8469847684177806,
      "grad_norm": 0.22533459961414337,
      "learning_rate": 5.765076157911098e-06,
      "loss": 0.0674,
      "step": 10899
    },
    {
      "epoch": 0.8470624805719614,
      "grad_norm": 0.6336333751678467,
      "learning_rate": 5.764687597140193e-06,
      "loss": 0.2796,
      "step": 10900
    },
    {
      "epoch": 0.8471401927261424,
      "grad_norm": 0.932792067527771,
      "learning_rate": 5.764299036369289e-06,
      "loss": 0.3261,
      "step": 10901
    },
    {
      "epoch": 0.8472179048803233,
      "grad_norm": 0.05597921460866928,
      "learning_rate": 5.763910475598385e-06,
      "loss": 0.0047,
      "step": 10902
    },
    {
      "epoch": 0.8472956170345042,
      "grad_norm": 0.38473403453826904,
      "learning_rate": 5.763521914827479e-06,
      "loss": 0.364,
      "step": 10903
    },
    {
      "epoch": 0.8473733291886851,
      "grad_norm": 0.4666208028793335,
      "learning_rate": 5.763133354056575e-06,
      "loss": 0.5532,
      "step": 10904
    },
    {
      "epoch": 0.847451041342866,
      "grad_norm": 0.48277929425239563,
      "learning_rate": 5.76274479328567e-06,
      "loss": 0.0909,
      "step": 10905
    },
    {
      "epoch": 0.8475287534970469,
      "grad_norm": 0.38771021366119385,
      "learning_rate": 5.762356232514765e-06,
      "loss": 0.1285,
      "step": 10906
    },
    {
      "epoch": 0.8476064656512279,
      "grad_norm": 0.6888585090637207,
      "learning_rate": 5.761967671743861e-06,
      "loss": 0.5283,
      "step": 10907
    },
    {
      "epoch": 0.8476841778054087,
      "grad_norm": 0.44672611355781555,
      "learning_rate": 5.761579110972957e-06,
      "loss": 0.8097,
      "step": 10908
    },
    {
      "epoch": 0.8477618899595897,
      "grad_norm": 0.08805680274963379,
      "learning_rate": 5.761190550202052e-06,
      "loss": 0.0558,
      "step": 10909
    },
    {
      "epoch": 0.8478396021137706,
      "grad_norm": 0.8936880230903625,
      "learning_rate": 5.760801989431148e-06,
      "loss": 0.2099,
      "step": 10910
    },
    {
      "epoch": 0.8479173142679515,
      "grad_norm": 0.7763020992279053,
      "learning_rate": 5.7604134286602435e-06,
      "loss": 0.2809,
      "step": 10911
    },
    {
      "epoch": 0.8479950264221324,
      "grad_norm": 0.16057844460010529,
      "learning_rate": 5.760024867889339e-06,
      "loss": 0.1111,
      "step": 10912
    },
    {
      "epoch": 0.8480727385763134,
      "grad_norm": 0.48022353649139404,
      "learning_rate": 5.759636307118433e-06,
      "loss": 0.3761,
      "step": 10913
    },
    {
      "epoch": 0.8481504507304942,
      "grad_norm": 0.6711264848709106,
      "learning_rate": 5.759247746347529e-06,
      "loss": 0.1749,
      "step": 10914
    },
    {
      "epoch": 0.8482281628846752,
      "grad_norm": 0.6308661103248596,
      "learning_rate": 5.758859185576625e-06,
      "loss": 0.112,
      "step": 10915
    },
    {
      "epoch": 0.8483058750388561,
      "grad_norm": 0.3840193450450897,
      "learning_rate": 5.75847062480572e-06,
      "loss": 0.2027,
      "step": 10916
    },
    {
      "epoch": 0.848383587193037,
      "grad_norm": 0.4503345191478729,
      "learning_rate": 5.758082064034816e-06,
      "loss": 0.2608,
      "step": 10917
    },
    {
      "epoch": 0.8484612993472179,
      "grad_norm": 0.27837464213371277,
      "learning_rate": 5.7576935032639115e-06,
      "loss": 0.1554,
      "step": 10918
    },
    {
      "epoch": 0.8485390115013988,
      "grad_norm": 0.6813017725944519,
      "learning_rate": 5.7573049424930065e-06,
      "loss": 0.1356,
      "step": 10919
    },
    {
      "epoch": 0.8486167236555797,
      "grad_norm": 0.23353709280490875,
      "learning_rate": 5.756916381722102e-06,
      "loss": 0.0906,
      "step": 10920
    },
    {
      "epoch": 0.8486944358097607,
      "grad_norm": 0.4608990252017975,
      "learning_rate": 5.756527820951198e-06,
      "loss": 0.6453,
      "step": 10921
    },
    {
      "epoch": 0.8487721479639415,
      "grad_norm": 0.3151607811450958,
      "learning_rate": 5.756139260180292e-06,
      "loss": 0.1894,
      "step": 10922
    },
    {
      "epoch": 0.8488498601181225,
      "grad_norm": 0.7992590665817261,
      "learning_rate": 5.755750699409388e-06,
      "loss": 0.2735,
      "step": 10923
    },
    {
      "epoch": 0.8489275722723034,
      "grad_norm": 0.37864068150520325,
      "learning_rate": 5.755362138638484e-06,
      "loss": 0.091,
      "step": 10924
    },
    {
      "epoch": 0.8490052844264843,
      "grad_norm": 0.5477674603462219,
      "learning_rate": 5.754973577867579e-06,
      "loss": 0.1983,
      "step": 10925
    },
    {
      "epoch": 0.8490829965806652,
      "grad_norm": 0.24872274696826935,
      "learning_rate": 5.7545850170966745e-06,
      "loss": 0.068,
      "step": 10926
    },
    {
      "epoch": 0.8491607087348462,
      "grad_norm": 0.33693134784698486,
      "learning_rate": 5.75419645632577e-06,
      "loss": 0.1051,
      "step": 10927
    },
    {
      "epoch": 0.849238420889027,
      "grad_norm": 0.05999679118394852,
      "learning_rate": 5.753807895554865e-06,
      "loss": 0.0064,
      "step": 10928
    },
    {
      "epoch": 0.849316133043208,
      "grad_norm": 0.2373749166727066,
      "learning_rate": 5.753419334783961e-06,
      "loss": 0.0856,
      "step": 10929
    },
    {
      "epoch": 0.8493938451973889,
      "grad_norm": 0.6375317573547363,
      "learning_rate": 5.753030774013056e-06,
      "loss": 0.2731,
      "step": 10930
    },
    {
      "epoch": 0.8494715573515698,
      "grad_norm": 0.28918665647506714,
      "learning_rate": 5.752642213242151e-06,
      "loss": 0.099,
      "step": 10931
    },
    {
      "epoch": 0.8495492695057507,
      "grad_norm": 0.18748052418231964,
      "learning_rate": 5.752253652471247e-06,
      "loss": 0.1445,
      "step": 10932
    },
    {
      "epoch": 0.8496269816599317,
      "grad_norm": 0.2230692058801651,
      "learning_rate": 5.7518650917003426e-06,
      "loss": 0.0629,
      "step": 10933
    },
    {
      "epoch": 0.8497046938141125,
      "grad_norm": 0.7552679181098938,
      "learning_rate": 5.7514765309294375e-06,
      "loss": 0.47,
      "step": 10934
    },
    {
      "epoch": 0.8497824059682935,
      "grad_norm": 0.670407235622406,
      "learning_rate": 5.751087970158533e-06,
      "loss": 0.4778,
      "step": 10935
    },
    {
      "epoch": 0.8498601181224743,
      "grad_norm": 0.15491610765457153,
      "learning_rate": 5.750699409387629e-06,
      "loss": 0.0524,
      "step": 10936
    },
    {
      "epoch": 0.8499378302766553,
      "grad_norm": 0.538622260093689,
      "learning_rate": 5.750310848616723e-06,
      "loss": 0.0379,
      "step": 10937
    },
    {
      "epoch": 0.8500155424308362,
      "grad_norm": 0.5091274380683899,
      "learning_rate": 5.749922287845819e-06,
      "loss": 0.0702,
      "step": 10938
    },
    {
      "epoch": 0.850093254585017,
      "grad_norm": 0.1931874006986618,
      "learning_rate": 5.749533727074915e-06,
      "loss": 0.0268,
      "step": 10939
    },
    {
      "epoch": 0.850170966739198,
      "grad_norm": 0.5759174227714539,
      "learning_rate": 5.74914516630401e-06,
      "loss": 0.2344,
      "step": 10940
    },
    {
      "epoch": 0.850248678893379,
      "grad_norm": 0.26101064682006836,
      "learning_rate": 5.7487566055331055e-06,
      "loss": 0.0926,
      "step": 10941
    },
    {
      "epoch": 0.8503263910475598,
      "grad_norm": 0.1931629776954651,
      "learning_rate": 5.748368044762201e-06,
      "loss": 0.0505,
      "step": 10942
    },
    {
      "epoch": 0.8504041032017408,
      "grad_norm": 0.5470094680786133,
      "learning_rate": 5.747979483991297e-06,
      "loss": 0.4662,
      "step": 10943
    },
    {
      "epoch": 0.8504818153559217,
      "grad_norm": 0.44287407398223877,
      "learning_rate": 5.747590923220392e-06,
      "loss": 0.1685,
      "step": 10944
    },
    {
      "epoch": 0.8505595275101026,
      "grad_norm": 0.6352246999740601,
      "learning_rate": 5.747202362449488e-06,
      "loss": 0.3157,
      "step": 10945
    },
    {
      "epoch": 0.8506372396642835,
      "grad_norm": 0.4801675081253052,
      "learning_rate": 5.746813801678584e-06,
      "loss": 0.2429,
      "step": 10946
    },
    {
      "epoch": 0.8507149518184645,
      "grad_norm": 0.4334581196308136,
      "learning_rate": 5.746425240907678e-06,
      "loss": 0.1656,
      "step": 10947
    },
    {
      "epoch": 0.8507926639726453,
      "grad_norm": 0.08603442460298538,
      "learning_rate": 5.7460366801367736e-06,
      "loss": 0.0334,
      "step": 10948
    },
    {
      "epoch": 0.8508703761268263,
      "grad_norm": 0.11568757891654968,
      "learning_rate": 5.745648119365869e-06,
      "loss": 0.0277,
      "step": 10949
    },
    {
      "epoch": 0.8509480882810071,
      "grad_norm": 0.4889413118362427,
      "learning_rate": 5.745259558594964e-06,
      "loss": 0.3833,
      "step": 10950
    },
    {
      "epoch": 0.851025800435188,
      "grad_norm": 0.28819093108177185,
      "learning_rate": 5.74487099782406e-06,
      "loss": 0.1568,
      "step": 10951
    },
    {
      "epoch": 0.851103512589369,
      "grad_norm": 0.2501896619796753,
      "learning_rate": 5.744482437053156e-06,
      "loss": 0.0643,
      "step": 10952
    },
    {
      "epoch": 0.8511812247435498,
      "grad_norm": 0.5326590538024902,
      "learning_rate": 5.744093876282251e-06,
      "loss": 0.1889,
      "step": 10953
    },
    {
      "epoch": 0.8512589368977308,
      "grad_norm": 0.37040016055107117,
      "learning_rate": 5.743705315511347e-06,
      "loss": 0.0962,
      "step": 10954
    },
    {
      "epoch": 0.8513366490519118,
      "grad_norm": 0.16619305312633514,
      "learning_rate": 5.7433167547404425e-06,
      "loss": 0.0265,
      "step": 10955
    },
    {
      "epoch": 0.8514143612060926,
      "grad_norm": 0.26261821389198303,
      "learning_rate": 5.7429281939695366e-06,
      "loss": 0.1728,
      "step": 10956
    },
    {
      "epoch": 0.8514920733602735,
      "grad_norm": 0.31502145528793335,
      "learning_rate": 5.742539633198632e-06,
      "loss": 0.139,
      "step": 10957
    },
    {
      "epoch": 0.8515697855144545,
      "grad_norm": 0.20695054531097412,
      "learning_rate": 5.742151072427728e-06,
      "loss": 0.0261,
      "step": 10958
    },
    {
      "epoch": 0.8516474976686353,
      "grad_norm": 0.23135390877723694,
      "learning_rate": 5.741762511656823e-06,
      "loss": 0.065,
      "step": 10959
    },
    {
      "epoch": 0.8517252098228163,
      "grad_norm": 0.3353533446788788,
      "learning_rate": 5.741373950885919e-06,
      "loss": 0.3699,
      "step": 10960
    },
    {
      "epoch": 0.8518029219769973,
      "grad_norm": 0.7769011855125427,
      "learning_rate": 5.740985390115015e-06,
      "loss": 0.2258,
      "step": 10961
    },
    {
      "epoch": 0.8518806341311781,
      "grad_norm": 0.2997559607028961,
      "learning_rate": 5.74059682934411e-06,
      "loss": 0.1015,
      "step": 10962
    },
    {
      "epoch": 0.851958346285359,
      "grad_norm": 0.3391333520412445,
      "learning_rate": 5.7402082685732054e-06,
      "loss": 0.1557,
      "step": 10963
    },
    {
      "epoch": 0.8520360584395399,
      "grad_norm": 0.18317897617816925,
      "learning_rate": 5.739819707802301e-06,
      "loss": 0.0864,
      "step": 10964
    },
    {
      "epoch": 0.8521137705937208,
      "grad_norm": 0.3035847544670105,
      "learning_rate": 5.739431147031395e-06,
      "loss": 0.1362,
      "step": 10965
    },
    {
      "epoch": 0.8521914827479018,
      "grad_norm": 0.6116601824760437,
      "learning_rate": 5.739042586260491e-06,
      "loss": 0.32,
      "step": 10966
    },
    {
      "epoch": 0.8522691949020826,
      "grad_norm": 0.43397057056427,
      "learning_rate": 5.738654025489587e-06,
      "loss": 0.1105,
      "step": 10967
    },
    {
      "epoch": 0.8523469070562636,
      "grad_norm": 0.3561793863773346,
      "learning_rate": 5.738265464718682e-06,
      "loss": 0.1599,
      "step": 10968
    },
    {
      "epoch": 0.8524246192104445,
      "grad_norm": 0.2560561001300812,
      "learning_rate": 5.737876903947778e-06,
      "loss": 0.1405,
      "step": 10969
    },
    {
      "epoch": 0.8525023313646254,
      "grad_norm": 0.27494293451309204,
      "learning_rate": 5.7374883431768735e-06,
      "loss": 0.0897,
      "step": 10970
    },
    {
      "epoch": 0.8525800435188063,
      "grad_norm": 1.034898042678833,
      "learning_rate": 5.7370997824059684e-06,
      "loss": 0.1093,
      "step": 10971
    },
    {
      "epoch": 0.8526577556729873,
      "grad_norm": 0.3813607394695282,
      "learning_rate": 5.736711221635064e-06,
      "loss": 0.309,
      "step": 10972
    },
    {
      "epoch": 0.8527354678271681,
      "grad_norm": 0.2680160105228424,
      "learning_rate": 5.73632266086416e-06,
      "loss": 0.2467,
      "step": 10973
    },
    {
      "epoch": 0.8528131799813491,
      "grad_norm": 0.6395713090896606,
      "learning_rate": 5.735934100093256e-06,
      "loss": 0.7792,
      "step": 10974
    },
    {
      "epoch": 0.85289089213553,
      "grad_norm": 0.2929452657699585,
      "learning_rate": 5.73554553932235e-06,
      "loss": 0.083,
      "step": 10975
    },
    {
      "epoch": 0.8529686042897109,
      "grad_norm": 0.8978826403617859,
      "learning_rate": 5.735156978551446e-06,
      "loss": 0.4038,
      "step": 10976
    },
    {
      "epoch": 0.8530463164438918,
      "grad_norm": 0.5918025374412537,
      "learning_rate": 5.7347684177805415e-06,
      "loss": 0.3345,
      "step": 10977
    },
    {
      "epoch": 0.8531240285980728,
      "grad_norm": 0.38056597113609314,
      "learning_rate": 5.7343798570096365e-06,
      "loss": 0.0544,
      "step": 10978
    },
    {
      "epoch": 0.8532017407522536,
      "grad_norm": 0.6027711629867554,
      "learning_rate": 5.733991296238732e-06,
      "loss": 0.2224,
      "step": 10979
    },
    {
      "epoch": 0.8532794529064346,
      "grad_norm": 0.45394057035446167,
      "learning_rate": 5.733602735467828e-06,
      "loss": 0.1168,
      "step": 10980
    },
    {
      "epoch": 0.8533571650606154,
      "grad_norm": 0.18598441779613495,
      "learning_rate": 5.733214174696923e-06,
      "loss": 0.0619,
      "step": 10981
    },
    {
      "epoch": 0.8534348772147964,
      "grad_norm": 0.3095296323299408,
      "learning_rate": 5.732825613926019e-06,
      "loss": 0.1004,
      "step": 10982
    },
    {
      "epoch": 0.8535125893689773,
      "grad_norm": 0.09370391070842743,
      "learning_rate": 5.732437053155115e-06,
      "loss": 0.0177,
      "step": 10983
    },
    {
      "epoch": 0.8535903015231582,
      "grad_norm": 0.4339486360549927,
      "learning_rate": 5.732048492384209e-06,
      "loss": 0.2633,
      "step": 10984
    },
    {
      "epoch": 0.8536680136773391,
      "grad_norm": 0.36985018849372864,
      "learning_rate": 5.7316599316133045e-06,
      "loss": 0.141,
      "step": 10985
    },
    {
      "epoch": 0.8537457258315201,
      "grad_norm": 0.4024450182914734,
      "learning_rate": 5.7312713708424e-06,
      "loss": 0.8093,
      "step": 10986
    },
    {
      "epoch": 0.8538234379857009,
      "grad_norm": 0.25721216201782227,
      "learning_rate": 5.730882810071495e-06,
      "loss": 0.1349,
      "step": 10987
    },
    {
      "epoch": 0.8539011501398819,
      "grad_norm": 0.4647858440876007,
      "learning_rate": 5.730494249300591e-06,
      "loss": 0.161,
      "step": 10988
    },
    {
      "epoch": 0.8539788622940628,
      "grad_norm": 0.19093860685825348,
      "learning_rate": 5.730105688529687e-06,
      "loss": 0.0817,
      "step": 10989
    },
    {
      "epoch": 0.8540565744482437,
      "grad_norm": 0.20851582288742065,
      "learning_rate": 5.729717127758782e-06,
      "loss": 0.179,
      "step": 10990
    },
    {
      "epoch": 0.8541342866024246,
      "grad_norm": 0.35889819264411926,
      "learning_rate": 5.729328566987878e-06,
      "loss": 0.1561,
      "step": 10991
    },
    {
      "epoch": 0.8542119987566056,
      "grad_norm": 0.1401333212852478,
      "learning_rate": 5.728940006216973e-06,
      "loss": 0.0477,
      "step": 10992
    },
    {
      "epoch": 0.8542897109107864,
      "grad_norm": 0.5539299845695496,
      "learning_rate": 5.7285514454460675e-06,
      "loss": 0.2238,
      "step": 10993
    },
    {
      "epoch": 0.8543674230649674,
      "grad_norm": 0.16414745151996613,
      "learning_rate": 5.728162884675163e-06,
      "loss": 0.0564,
      "step": 10994
    },
    {
      "epoch": 0.8544451352191482,
      "grad_norm": 0.6449170112609863,
      "learning_rate": 5.727774323904259e-06,
      "loss": 0.2354,
      "step": 10995
    },
    {
      "epoch": 0.8545228473733292,
      "grad_norm": 0.4559893310070038,
      "learning_rate": 5.727385763133354e-06,
      "loss": 0.188,
      "step": 10996
    },
    {
      "epoch": 0.8546005595275101,
      "grad_norm": 0.330651193857193,
      "learning_rate": 5.72699720236245e-06,
      "loss": 0.2146,
      "step": 10997
    },
    {
      "epoch": 0.854678271681691,
      "grad_norm": 0.5734366178512573,
      "learning_rate": 5.726608641591546e-06,
      "loss": 0.2831,
      "step": 10998
    },
    {
      "epoch": 0.8547559838358719,
      "grad_norm": 0.6867572665214539,
      "learning_rate": 5.726220080820641e-06,
      "loss": 0.1071,
      "step": 10999
    },
    {
      "epoch": 0.8548336959900529,
      "grad_norm": 0.4475676119327545,
      "learning_rate": 5.725831520049736e-06,
      "loss": 0.1588,
      "step": 11000
    },
    {
      "epoch": 0.8549114081442337,
      "grad_norm": 0.8221963047981262,
      "learning_rate": 5.725442959278832e-06,
      "loss": 0.1552,
      "step": 11001
    },
    {
      "epoch": 0.8549891202984147,
      "grad_norm": 0.17781637609004974,
      "learning_rate": 5.725054398507928e-06,
      "loss": 0.0755,
      "step": 11002
    },
    {
      "epoch": 0.8550668324525956,
      "grad_norm": 0.4876118004322052,
      "learning_rate": 5.724665837737022e-06,
      "loss": 0.2006,
      "step": 11003
    },
    {
      "epoch": 0.8551445446067765,
      "grad_norm": 0.46015357971191406,
      "learning_rate": 5.724277276966118e-06,
      "loss": 0.2021,
      "step": 11004
    },
    {
      "epoch": 0.8552222567609574,
      "grad_norm": 0.9658452868461609,
      "learning_rate": 5.723888716195214e-06,
      "loss": 0.3691,
      "step": 11005
    },
    {
      "epoch": 0.8552999689151384,
      "grad_norm": 0.2545515298843384,
      "learning_rate": 5.723500155424309e-06,
      "loss": 0.1674,
      "step": 11006
    },
    {
      "epoch": 0.8553776810693192,
      "grad_norm": 0.8454763889312744,
      "learning_rate": 5.723111594653404e-06,
      "loss": 0.2365,
      "step": 11007
    },
    {
      "epoch": 0.8554553932235002,
      "grad_norm": 0.7155019640922546,
      "learning_rate": 5.7227230338825e-06,
      "loss": 0.2164,
      "step": 11008
    },
    {
      "epoch": 0.8555331053776811,
      "grad_norm": 0.3165624439716339,
      "learning_rate": 5.722334473111595e-06,
      "loss": 0.0516,
      "step": 11009
    },
    {
      "epoch": 0.855610817531862,
      "grad_norm": 0.2084348052740097,
      "learning_rate": 5.721945912340691e-06,
      "loss": 0.0815,
      "step": 11010
    },
    {
      "epoch": 0.8556885296860429,
      "grad_norm": 1.3000495433807373,
      "learning_rate": 5.721557351569787e-06,
      "loss": 0.3536,
      "step": 11011
    },
    {
      "epoch": 0.8557662418402238,
      "grad_norm": 0.1258937418460846,
      "learning_rate": 5.721168790798881e-06,
      "loss": 0.0204,
      "step": 11012
    },
    {
      "epoch": 0.8558439539944047,
      "grad_norm": 0.6009975671768188,
      "learning_rate": 5.720780230027977e-06,
      "loss": 0.4619,
      "step": 11013
    },
    {
      "epoch": 0.8559216661485857,
      "grad_norm": 0.6693137288093567,
      "learning_rate": 5.7203916692570724e-06,
      "loss": 0.15,
      "step": 11014
    },
    {
      "epoch": 0.8559993783027665,
      "grad_norm": 0.17314141988754272,
      "learning_rate": 5.720003108486167e-06,
      "loss": 0.0674,
      "step": 11015
    },
    {
      "epoch": 0.8560770904569475,
      "grad_norm": 0.3469668924808502,
      "learning_rate": 5.719614547715263e-06,
      "loss": 0.166,
      "step": 11016
    },
    {
      "epoch": 0.8561548026111284,
      "grad_norm": 0.4999065697193146,
      "learning_rate": 5.719225986944359e-06,
      "loss": 0.1006,
      "step": 11017
    },
    {
      "epoch": 0.8562325147653093,
      "grad_norm": 0.3152908384799957,
      "learning_rate": 5.718837426173454e-06,
      "loss": 0.1217,
      "step": 11018
    },
    {
      "epoch": 0.8563102269194902,
      "grad_norm": 0.07444609701633453,
      "learning_rate": 5.71844886540255e-06,
      "loss": 0.0272,
      "step": 11019
    },
    {
      "epoch": 0.8563879390736712,
      "grad_norm": 0.6751989722251892,
      "learning_rate": 5.7180603046316455e-06,
      "loss": 0.2441,
      "step": 11020
    },
    {
      "epoch": 0.856465651227852,
      "grad_norm": 0.7332010269165039,
      "learning_rate": 5.71767174386074e-06,
      "loss": 0.9503,
      "step": 11021
    },
    {
      "epoch": 0.856543363382033,
      "grad_norm": 0.3567599356174469,
      "learning_rate": 5.7172831830898354e-06,
      "loss": 0.1565,
      "step": 11022
    },
    {
      "epoch": 0.8566210755362139,
      "grad_norm": 0.269253671169281,
      "learning_rate": 5.716894622318931e-06,
      "loss": 0.0633,
      "step": 11023
    },
    {
      "epoch": 0.8566987876903948,
      "grad_norm": 0.43469974398612976,
      "learning_rate": 5.716506061548026e-06,
      "loss": 0.2727,
      "step": 11024
    },
    {
      "epoch": 0.8567764998445757,
      "grad_norm": 0.3284395635128021,
      "learning_rate": 5.716117500777122e-06,
      "loss": 0.0739,
      "step": 11025
    },
    {
      "epoch": 0.8568542119987566,
      "grad_norm": 0.2107846885919571,
      "learning_rate": 5.715728940006218e-06,
      "loss": 0.0411,
      "step": 11026
    },
    {
      "epoch": 0.8569319241529375,
      "grad_norm": 0.44771504402160645,
      "learning_rate": 5.715340379235313e-06,
      "loss": 0.1204,
      "step": 11027
    },
    {
      "epoch": 0.8570096363071185,
      "grad_norm": 0.17878636717796326,
      "learning_rate": 5.7149518184644085e-06,
      "loss": 0.0227,
      "step": 11028
    },
    {
      "epoch": 0.8570873484612993,
      "grad_norm": 0.13255365192890167,
      "learning_rate": 5.714563257693504e-06,
      "loss": 0.0613,
      "step": 11029
    },
    {
      "epoch": 0.8571650606154803,
      "grad_norm": 0.23316869139671326,
      "learning_rate": 5.714174696922598e-06,
      "loss": 0.1853,
      "step": 11030
    },
    {
      "epoch": 0.8572427727696612,
      "grad_norm": 0.2711070477962494,
      "learning_rate": 5.713786136151694e-06,
      "loss": 0.5051,
      "step": 11031
    },
    {
      "epoch": 0.857320484923842,
      "grad_norm": 0.21919803321361542,
      "learning_rate": 5.71339757538079e-06,
      "loss": 0.1047,
      "step": 11032
    },
    {
      "epoch": 0.857398197078023,
      "grad_norm": 0.829582929611206,
      "learning_rate": 5.713009014609886e-06,
      "loss": 0.5439,
      "step": 11033
    },
    {
      "epoch": 0.857475909232204,
      "grad_norm": 0.6642078757286072,
      "learning_rate": 5.712620453838981e-06,
      "loss": 0.4154,
      "step": 11034
    },
    {
      "epoch": 0.8575536213863848,
      "grad_norm": 0.04682276397943497,
      "learning_rate": 5.7122318930680766e-06,
      "loss": 0.0259,
      "step": 11035
    },
    {
      "epoch": 0.8576313335405658,
      "grad_norm": 0.3024384677410126,
      "learning_rate": 5.711843332297172e-06,
      "loss": 0.3318,
      "step": 11036
    },
    {
      "epoch": 0.8577090456947467,
      "grad_norm": 0.47011274099349976,
      "learning_rate": 5.711454771526267e-06,
      "loss": 0.1398,
      "step": 11037
    },
    {
      "epoch": 0.8577867578489276,
      "grad_norm": 0.08537248522043228,
      "learning_rate": 5.711066210755363e-06,
      "loss": 0.048,
      "step": 11038
    },
    {
      "epoch": 0.8578644700031085,
      "grad_norm": 0.26753419637680054,
      "learning_rate": 5.710677649984459e-06,
      "loss": 0.078,
      "step": 11039
    },
    {
      "epoch": 0.8579421821572893,
      "grad_norm": 0.24676722288131714,
      "learning_rate": 5.710289089213553e-06,
      "loss": 0.0691,
      "step": 11040
    },
    {
      "epoch": 0.8580198943114703,
      "grad_norm": 0.2782368063926697,
      "learning_rate": 5.709900528442649e-06,
      "loss": 0.0952,
      "step": 11041
    },
    {
      "epoch": 0.8580976064656513,
      "grad_norm": 0.13309884071350098,
      "learning_rate": 5.709511967671745e-06,
      "loss": 0.0581,
      "step": 11042
    },
    {
      "epoch": 0.8581753186198321,
      "grad_norm": 0.09973011910915375,
      "learning_rate": 5.7091234069008395e-06,
      "loss": 0.0332,
      "step": 11043
    },
    {
      "epoch": 0.858253030774013,
      "grad_norm": 0.7931909561157227,
      "learning_rate": 5.708734846129935e-06,
      "loss": 0.4582,
      "step": 11044
    },
    {
      "epoch": 0.858330742928194,
      "grad_norm": 0.10719455778598785,
      "learning_rate": 5.708346285359031e-06,
      "loss": 0.0127,
      "step": 11045
    },
    {
      "epoch": 0.8584084550823748,
      "grad_norm": 0.5850070118904114,
      "learning_rate": 5.707957724588126e-06,
      "loss": 0.2726,
      "step": 11046
    },
    {
      "epoch": 0.8584861672365558,
      "grad_norm": 0.21243403851985931,
      "learning_rate": 5.707569163817222e-06,
      "loss": 0.0645,
      "step": 11047
    },
    {
      "epoch": 0.8585638793907368,
      "grad_norm": 0.3796684145927429,
      "learning_rate": 5.707180603046318e-06,
      "loss": 0.0808,
      "step": 11048
    },
    {
      "epoch": 0.8586415915449176,
      "grad_norm": 0.22209253907203674,
      "learning_rate": 5.706792042275412e-06,
      "loss": 0.0659,
      "step": 11049
    },
    {
      "epoch": 0.8587193036990985,
      "grad_norm": 0.4632720947265625,
      "learning_rate": 5.706403481504508e-06,
      "loss": 0.144,
      "step": 11050
    },
    {
      "epoch": 0.8587970158532795,
      "grad_norm": 0.7040776014328003,
      "learning_rate": 5.706014920733603e-06,
      "loss": 0.5417,
      "step": 11051
    },
    {
      "epoch": 0.8588747280074603,
      "grad_norm": 0.378024160861969,
      "learning_rate": 5.705626359962698e-06,
      "loss": 0.234,
      "step": 11052
    },
    {
      "epoch": 0.8589524401616413,
      "grad_norm": 2.2052688598632812,
      "learning_rate": 5.705237799191794e-06,
      "loss": 0.6871,
      "step": 11053
    },
    {
      "epoch": 0.8590301523158222,
      "grad_norm": 0.2873488962650299,
      "learning_rate": 5.70484923842089e-06,
      "loss": 0.0447,
      "step": 11054
    },
    {
      "epoch": 0.8591078644700031,
      "grad_norm": 0.45879682898521423,
      "learning_rate": 5.704460677649985e-06,
      "loss": 0.2139,
      "step": 11055
    },
    {
      "epoch": 0.859185576624184,
      "grad_norm": 0.05975832790136337,
      "learning_rate": 5.704072116879081e-06,
      "loss": 0.0074,
      "step": 11056
    },
    {
      "epoch": 0.8592632887783649,
      "grad_norm": 0.6909738183021545,
      "learning_rate": 5.703683556108176e-06,
      "loss": 0.3362,
      "step": 11057
    },
    {
      "epoch": 0.8593410009325458,
      "grad_norm": 0.4375133514404297,
      "learning_rate": 5.7032949953372706e-06,
      "loss": 0.4226,
      "step": 11058
    },
    {
      "epoch": 0.8594187130867268,
      "grad_norm": 0.3744274079799652,
      "learning_rate": 5.702906434566366e-06,
      "loss": 0.183,
      "step": 11059
    },
    {
      "epoch": 0.8594964252409076,
      "grad_norm": 0.355952650308609,
      "learning_rate": 5.702517873795462e-06,
      "loss": 0.122,
      "step": 11060
    },
    {
      "epoch": 0.8595741373950886,
      "grad_norm": 0.08632369339466095,
      "learning_rate": 5.702129313024557e-06,
      "loss": 0.0294,
      "step": 11061
    },
    {
      "epoch": 0.8596518495492695,
      "grad_norm": 0.20697659254074097,
      "learning_rate": 5.701740752253653e-06,
      "loss": 0.0248,
      "step": 11062
    },
    {
      "epoch": 0.8597295617034504,
      "grad_norm": 0.4423708915710449,
      "learning_rate": 5.701352191482749e-06,
      "loss": 0.1074,
      "step": 11063
    },
    {
      "epoch": 0.8598072738576313,
      "grad_norm": 0.4725275933742523,
      "learning_rate": 5.7009636307118445e-06,
      "loss": 0.2162,
      "step": 11064
    },
    {
      "epoch": 0.8598849860118123,
      "grad_norm": 0.15424974262714386,
      "learning_rate": 5.700575069940939e-06,
      "loss": 0.0261,
      "step": 11065
    },
    {
      "epoch": 0.8599626981659931,
      "grad_norm": 0.4659462869167328,
      "learning_rate": 5.700186509170034e-06,
      "loss": 0.2333,
      "step": 11066
    },
    {
      "epoch": 0.8600404103201741,
      "grad_norm": 0.25613299012184143,
      "learning_rate": 5.69979794839913e-06,
      "loss": 0.0662,
      "step": 11067
    },
    {
      "epoch": 0.860118122474355,
      "grad_norm": 0.3371216356754303,
      "learning_rate": 5.699409387628225e-06,
      "loss": 0.0898,
      "step": 11068
    },
    {
      "epoch": 0.8601958346285359,
      "grad_norm": 0.6796348690986633,
      "learning_rate": 5.699020826857321e-06,
      "loss": 0.1513,
      "step": 11069
    },
    {
      "epoch": 0.8602735467827168,
      "grad_norm": 0.4670473635196686,
      "learning_rate": 5.698632266086417e-06,
      "loss": 0.0942,
      "step": 11070
    },
    {
      "epoch": 0.8603512589368977,
      "grad_norm": 0.5436268448829651,
      "learning_rate": 5.698243705315512e-06,
      "loss": 0.0868,
      "step": 11071
    },
    {
      "epoch": 0.8604289710910786,
      "grad_norm": 0.20093344151973724,
      "learning_rate": 5.6978551445446075e-06,
      "loss": 0.1753,
      "step": 11072
    },
    {
      "epoch": 0.8605066832452596,
      "grad_norm": 0.3451978266239166,
      "learning_rate": 5.697466583773703e-06,
      "loss": 0.1046,
      "step": 11073
    },
    {
      "epoch": 0.8605843953994404,
      "grad_norm": 0.26595133543014526,
      "learning_rate": 5.697078023002797e-06,
      "loss": 0.0937,
      "step": 11074
    },
    {
      "epoch": 0.8606621075536214,
      "grad_norm": 0.4021620452404022,
      "learning_rate": 5.696689462231893e-06,
      "loss": 0.2967,
      "step": 11075
    },
    {
      "epoch": 0.8607398197078023,
      "grad_norm": 0.17897994816303253,
      "learning_rate": 5.696300901460989e-06,
      "loss": 0.0767,
      "step": 11076
    },
    {
      "epoch": 0.8608175318619832,
      "grad_norm": 0.3807949721813202,
      "learning_rate": 5.695912340690084e-06,
      "loss": 0.0622,
      "step": 11077
    },
    {
      "epoch": 0.8608952440161641,
      "grad_norm": 0.14262737333774567,
      "learning_rate": 5.69552377991918e-06,
      "loss": 0.004,
      "step": 11078
    },
    {
      "epoch": 0.8609729561703451,
      "grad_norm": 1.0557397603988647,
      "learning_rate": 5.6951352191482755e-06,
      "loss": 0.3335,
      "step": 11079
    },
    {
      "epoch": 0.8610506683245259,
      "grad_norm": 0.35316115617752075,
      "learning_rate": 5.6947466583773705e-06,
      "loss": 0.1823,
      "step": 11080
    },
    {
      "epoch": 0.8611283804787069,
      "grad_norm": 0.26482054591178894,
      "learning_rate": 5.694358097606466e-06,
      "loss": 0.0563,
      "step": 11081
    },
    {
      "epoch": 0.8612060926328878,
      "grad_norm": 0.7247409820556641,
      "learning_rate": 5.693969536835562e-06,
      "loss": 0.4404,
      "step": 11082
    },
    {
      "epoch": 0.8612838047870687,
      "grad_norm": 0.4067787230014801,
      "learning_rate": 5.693580976064656e-06,
      "loss": 0.2745,
      "step": 11083
    },
    {
      "epoch": 0.8613615169412496,
      "grad_norm": 0.34914863109588623,
      "learning_rate": 5.693192415293752e-06,
      "loss": 0.0522,
      "step": 11084
    },
    {
      "epoch": 0.8614392290954305,
      "grad_norm": 0.13362205028533936,
      "learning_rate": 5.692803854522848e-06,
      "loss": 0.045,
      "step": 11085
    },
    {
      "epoch": 0.8615169412496114,
      "grad_norm": 0.5673118233680725,
      "learning_rate": 5.692415293751943e-06,
      "loss": 0.3949,
      "step": 11086
    },
    {
      "epoch": 0.8615946534037924,
      "grad_norm": 0.6168729662895203,
      "learning_rate": 5.6920267329810385e-06,
      "loss": 0.2943,
      "step": 11087
    },
    {
      "epoch": 0.8616723655579732,
      "grad_norm": 0.17784176766872406,
      "learning_rate": 5.691638172210134e-06,
      "loss": 0.1124,
      "step": 11088
    },
    {
      "epoch": 0.8617500777121542,
      "grad_norm": 0.5109856724739075,
      "learning_rate": 5.691249611439229e-06,
      "loss": 0.2328,
      "step": 11089
    },
    {
      "epoch": 0.8618277898663351,
      "grad_norm": 0.725739598274231,
      "learning_rate": 5.690861050668325e-06,
      "loss": 0.1681,
      "step": 11090
    },
    {
      "epoch": 0.861905502020516,
      "grad_norm": 0.47309544682502747,
      "learning_rate": 5.690472489897421e-06,
      "loss": 0.1424,
      "step": 11091
    },
    {
      "epoch": 0.8619832141746969,
      "grad_norm": 0.9266639351844788,
      "learning_rate": 5.690083929126515e-06,
      "loss": 0.2222,
      "step": 11092
    },
    {
      "epoch": 0.8620609263288779,
      "grad_norm": 0.14967785775661469,
      "learning_rate": 5.689695368355611e-06,
      "loss": 0.067,
      "step": 11093
    },
    {
      "epoch": 0.8621386384830587,
      "grad_norm": 0.2836982011795044,
      "learning_rate": 5.6893068075847065e-06,
      "loss": 0.0846,
      "step": 11094
    },
    {
      "epoch": 0.8622163506372397,
      "grad_norm": 0.37573400139808655,
      "learning_rate": 5.688918246813802e-06,
      "loss": 0.3681,
      "step": 11095
    },
    {
      "epoch": 0.8622940627914206,
      "grad_norm": 0.4237082600593567,
      "learning_rate": 5.688529686042897e-06,
      "loss": 0.126,
      "step": 11096
    },
    {
      "epoch": 0.8623717749456015,
      "grad_norm": 0.21580079197883606,
      "learning_rate": 5.688141125271993e-06,
      "loss": 0.0766,
      "step": 11097
    },
    {
      "epoch": 0.8624494870997824,
      "grad_norm": 1.0693515539169312,
      "learning_rate": 5.687752564501089e-06,
      "loss": 0.2571,
      "step": 11098
    },
    {
      "epoch": 0.8625271992539634,
      "grad_norm": 0.7573356032371521,
      "learning_rate": 5.687364003730184e-06,
      "loss": 0.5995,
      "step": 11099
    },
    {
      "epoch": 0.8626049114081442,
      "grad_norm": 0.1807912290096283,
      "learning_rate": 5.68697544295928e-06,
      "loss": 0.0374,
      "step": 11100
    },
    {
      "epoch": 0.8626826235623252,
      "grad_norm": 0.23242244124412537,
      "learning_rate": 5.6865868821883754e-06,
      "loss": 0.1112,
      "step": 11101
    },
    {
      "epoch": 0.862760335716506,
      "grad_norm": 0.4559902250766754,
      "learning_rate": 5.6861983214174695e-06,
      "loss": 0.2878,
      "step": 11102
    },
    {
      "epoch": 0.862838047870687,
      "grad_norm": 0.756481945514679,
      "learning_rate": 5.685809760646565e-06,
      "loss": 0.2836,
      "step": 11103
    },
    {
      "epoch": 0.8629157600248679,
      "grad_norm": 0.37081024050712585,
      "learning_rate": 5.685421199875661e-06,
      "loss": 0.1254,
      "step": 11104
    },
    {
      "epoch": 0.8629934721790488,
      "grad_norm": 1.0900541543960571,
      "learning_rate": 5.685032639104756e-06,
      "loss": 0.214,
      "step": 11105
    },
    {
      "epoch": 0.8630711843332297,
      "grad_norm": 0.9870238900184631,
      "learning_rate": 5.684644078333852e-06,
      "loss": 0.5577,
      "step": 11106
    },
    {
      "epoch": 0.8631488964874107,
      "grad_norm": 0.17879106104373932,
      "learning_rate": 5.684255517562948e-06,
      "loss": 0.0517,
      "step": 11107
    },
    {
      "epoch": 0.8632266086415915,
      "grad_norm": 0.1482507437467575,
      "learning_rate": 5.683866956792043e-06,
      "loss": 0.0311,
      "step": 11108
    },
    {
      "epoch": 0.8633043207957725,
      "grad_norm": 0.7484197020530701,
      "learning_rate": 5.683478396021138e-06,
      "loss": 0.2322,
      "step": 11109
    },
    {
      "epoch": 0.8633820329499534,
      "grad_norm": 0.4098532199859619,
      "learning_rate": 5.683089835250234e-06,
      "loss": 0.1517,
      "step": 11110
    },
    {
      "epoch": 0.8634597451041343,
      "grad_norm": 0.45472288131713867,
      "learning_rate": 5.682701274479328e-06,
      "loss": 0.24,
      "step": 11111
    },
    {
      "epoch": 0.8635374572583152,
      "grad_norm": 0.35755956172943115,
      "learning_rate": 5.682312713708424e-06,
      "loss": 0.1371,
      "step": 11112
    },
    {
      "epoch": 0.8636151694124962,
      "grad_norm": 0.23883771896362305,
      "learning_rate": 5.68192415293752e-06,
      "loss": 0.0532,
      "step": 11113
    },
    {
      "epoch": 0.863692881566677,
      "grad_norm": 0.047279149293899536,
      "learning_rate": 5.681535592166615e-06,
      "loss": 0.0227,
      "step": 11114
    },
    {
      "epoch": 0.863770593720858,
      "grad_norm": 0.3932623267173767,
      "learning_rate": 5.681147031395711e-06,
      "loss": 0.2351,
      "step": 11115
    },
    {
      "epoch": 0.8638483058750388,
      "grad_norm": 0.591547966003418,
      "learning_rate": 5.6807584706248065e-06,
      "loss": 0.2217,
      "step": 11116
    },
    {
      "epoch": 0.8639260180292198,
      "grad_norm": 0.3480401933193207,
      "learning_rate": 5.680369909853901e-06,
      "loss": 0.1484,
      "step": 11117
    },
    {
      "epoch": 0.8640037301834007,
      "grad_norm": 0.32105740904808044,
      "learning_rate": 5.679981349082997e-06,
      "loss": 0.5737,
      "step": 11118
    },
    {
      "epoch": 0.8640814423375816,
      "grad_norm": 0.2012987583875656,
      "learning_rate": 5.679592788312093e-06,
      "loss": 0.0618,
      "step": 11119
    },
    {
      "epoch": 0.8641591544917625,
      "grad_norm": 0.21804635226726532,
      "learning_rate": 5.679204227541187e-06,
      "loss": 0.0909,
      "step": 11120
    },
    {
      "epoch": 0.8642368666459435,
      "grad_norm": 0.1799122542142868,
      "learning_rate": 5.678815666770283e-06,
      "loss": 0.0999,
      "step": 11121
    },
    {
      "epoch": 0.8643145788001243,
      "grad_norm": 0.4123534560203552,
      "learning_rate": 5.678427105999379e-06,
      "loss": 0.5818,
      "step": 11122
    },
    {
      "epoch": 0.8643922909543053,
      "grad_norm": 0.23415812849998474,
      "learning_rate": 5.6780385452284745e-06,
      "loss": 0.0742,
      "step": 11123
    },
    {
      "epoch": 0.8644700031084862,
      "grad_norm": 0.40015992522239685,
      "learning_rate": 5.6776499844575694e-06,
      "loss": 0.2138,
      "step": 11124
    },
    {
      "epoch": 0.864547715262667,
      "grad_norm": 0.5346073508262634,
      "learning_rate": 5.677261423686665e-06,
      "loss": 0.8106,
      "step": 11125
    },
    {
      "epoch": 0.864625427416848,
      "grad_norm": 0.5251886248588562,
      "learning_rate": 5.676872862915761e-06,
      "loss": 0.1167,
      "step": 11126
    },
    {
      "epoch": 0.864703139571029,
      "grad_norm": 0.8174618482589722,
      "learning_rate": 5.676484302144856e-06,
      "loss": 0.4601,
      "step": 11127
    },
    {
      "epoch": 0.8647808517252098,
      "grad_norm": 0.17751434445381165,
      "learning_rate": 5.676095741373952e-06,
      "loss": 0.0973,
      "step": 11128
    },
    {
      "epoch": 0.8648585638793908,
      "grad_norm": 0.4351286292076111,
      "learning_rate": 5.6757071806030476e-06,
      "loss": 0.1818,
      "step": 11129
    },
    {
      "epoch": 0.8649362760335717,
      "grad_norm": 0.30760255455970764,
      "learning_rate": 5.675318619832142e-06,
      "loss": 0.0947,
      "step": 11130
    },
    {
      "epoch": 0.8650139881877525,
      "grad_norm": 0.3684171736240387,
      "learning_rate": 5.6749300590612375e-06,
      "loss": 0.2548,
      "step": 11131
    },
    {
      "epoch": 0.8650917003419335,
      "grad_norm": 0.34197869896888733,
      "learning_rate": 5.674541498290333e-06,
      "loss": 0.2159,
      "step": 11132
    },
    {
      "epoch": 0.8651694124961143,
      "grad_norm": 1.1792746782302856,
      "learning_rate": 5.674152937519428e-06,
      "loss": 0.5616,
      "step": 11133
    },
    {
      "epoch": 0.8652471246502953,
      "grad_norm": 0.4234256446361542,
      "learning_rate": 5.673764376748524e-06,
      "loss": 0.2452,
      "step": 11134
    },
    {
      "epoch": 0.8653248368044762,
      "grad_norm": 0.5189902186393738,
      "learning_rate": 5.67337581597762e-06,
      "loss": 0.2396,
      "step": 11135
    },
    {
      "epoch": 0.8654025489586571,
      "grad_norm": 1.3040976524353027,
      "learning_rate": 5.672987255206715e-06,
      "loss": 0.443,
      "step": 11136
    },
    {
      "epoch": 0.865480261112838,
      "grad_norm": 0.14164309203624725,
      "learning_rate": 5.6725986944358106e-06,
      "loss": 0.0708,
      "step": 11137
    },
    {
      "epoch": 0.865557973267019,
      "grad_norm": 0.34107705950737,
      "learning_rate": 5.672210133664906e-06,
      "loss": 0.2181,
      "step": 11138
    },
    {
      "epoch": 0.8656356854211998,
      "grad_norm": 0.20034220814704895,
      "learning_rate": 5.6718215728940005e-06,
      "loss": 0.0862,
      "step": 11139
    },
    {
      "epoch": 0.8657133975753808,
      "grad_norm": 0.6784162521362305,
      "learning_rate": 5.671433012123096e-06,
      "loss": 0.1967,
      "step": 11140
    },
    {
      "epoch": 0.8657911097295617,
      "grad_norm": 0.24973534047603607,
      "learning_rate": 5.671044451352192e-06,
      "loss": 0.0749,
      "step": 11141
    },
    {
      "epoch": 0.8658688218837426,
      "grad_norm": 0.13107800483703613,
      "learning_rate": 5.670655890581287e-06,
      "loss": 0.0294,
      "step": 11142
    },
    {
      "epoch": 0.8659465340379235,
      "grad_norm": 1.0154578685760498,
      "learning_rate": 5.670267329810383e-06,
      "loss": 0.2156,
      "step": 11143
    },
    {
      "epoch": 0.8660242461921045,
      "grad_norm": 0.4798464775085449,
      "learning_rate": 5.669878769039479e-06,
      "loss": 0.0939,
      "step": 11144
    },
    {
      "epoch": 0.8661019583462853,
      "grad_norm": 0.146188423037529,
      "learning_rate": 5.6694902082685735e-06,
      "loss": 0.0229,
      "step": 11145
    },
    {
      "epoch": 0.8661796705004663,
      "grad_norm": 0.18808628618717194,
      "learning_rate": 5.669101647497669e-06,
      "loss": 0.0816,
      "step": 11146
    },
    {
      "epoch": 0.8662573826546471,
      "grad_norm": 0.44678670167922974,
      "learning_rate": 5.668713086726765e-06,
      "loss": 0.1894,
      "step": 11147
    },
    {
      "epoch": 0.8663350948088281,
      "grad_norm": 0.34915396571159363,
      "learning_rate": 5.668324525955859e-06,
      "loss": 0.1231,
      "step": 11148
    },
    {
      "epoch": 0.866412806963009,
      "grad_norm": 0.1833859086036682,
      "learning_rate": 5.667935965184955e-06,
      "loss": 0.0636,
      "step": 11149
    },
    {
      "epoch": 0.8664905191171899,
      "grad_norm": 0.22534768283367157,
      "learning_rate": 5.667547404414051e-06,
      "loss": 0.2402,
      "step": 11150
    },
    {
      "epoch": 0.8665682312713708,
      "grad_norm": 1.1115180253982544,
      "learning_rate": 5.667158843643146e-06,
      "loss": 0.5358,
      "step": 11151
    },
    {
      "epoch": 0.8666459434255518,
      "grad_norm": 0.4201536476612091,
      "learning_rate": 5.666770282872242e-06,
      "loss": 0.1336,
      "step": 11152
    },
    {
      "epoch": 0.8667236555797326,
      "grad_norm": 0.9879092574119568,
      "learning_rate": 5.666381722101337e-06,
      "loss": 0.4211,
      "step": 11153
    },
    {
      "epoch": 0.8668013677339136,
      "grad_norm": 0.32968342304229736,
      "learning_rate": 5.665993161330433e-06,
      "loss": 0.2326,
      "step": 11154
    },
    {
      "epoch": 0.8668790798880945,
      "grad_norm": 0.3470515012741089,
      "learning_rate": 5.665604600559528e-06,
      "loss": 0.0556,
      "step": 11155
    },
    {
      "epoch": 0.8669567920422754,
      "grad_norm": 0.3111441135406494,
      "learning_rate": 5.665216039788624e-06,
      "loss": 0.113,
      "step": 11156
    },
    {
      "epoch": 0.8670345041964563,
      "grad_norm": 0.21689054369926453,
      "learning_rate": 5.66482747901772e-06,
      "loss": 0.0601,
      "step": 11157
    },
    {
      "epoch": 0.8671122163506373,
      "grad_norm": 0.09400446712970734,
      "learning_rate": 5.664438918246814e-06,
      "loss": 0.0247,
      "step": 11158
    },
    {
      "epoch": 0.8671899285048181,
      "grad_norm": 0.3587242066860199,
      "learning_rate": 5.66405035747591e-06,
      "loss": 0.2146,
      "step": 11159
    },
    {
      "epoch": 0.8672676406589991,
      "grad_norm": 0.3526071310043335,
      "learning_rate": 5.663661796705005e-06,
      "loss": 0.0954,
      "step": 11160
    },
    {
      "epoch": 0.8673453528131799,
      "grad_norm": 0.13241302967071533,
      "learning_rate": 5.6632732359341e-06,
      "loss": 0.0353,
      "step": 11161
    },
    {
      "epoch": 0.8674230649673609,
      "grad_norm": 0.32989978790283203,
      "learning_rate": 5.662884675163196e-06,
      "loss": 0.115,
      "step": 11162
    },
    {
      "epoch": 0.8675007771215418,
      "grad_norm": 0.3493325710296631,
      "learning_rate": 5.662496114392292e-06,
      "loss": 0.4462,
      "step": 11163
    },
    {
      "epoch": 0.8675784892757227,
      "grad_norm": 0.6626729369163513,
      "learning_rate": 5.662107553621387e-06,
      "loss": 0.4639,
      "step": 11164
    },
    {
      "epoch": 0.8676562014299036,
      "grad_norm": 0.014713672921061516,
      "learning_rate": 5.661718992850483e-06,
      "loss": 0.0017,
      "step": 11165
    },
    {
      "epoch": 0.8677339135840846,
      "grad_norm": 0.14666014909744263,
      "learning_rate": 5.6613304320795785e-06,
      "loss": 0.006,
      "step": 11166
    },
    {
      "epoch": 0.8678116257382654,
      "grad_norm": 0.4078407287597656,
      "learning_rate": 5.660941871308673e-06,
      "loss": 0.2353,
      "step": 11167
    },
    {
      "epoch": 0.8678893378924464,
      "grad_norm": 0.13753236830234528,
      "learning_rate": 5.660553310537768e-06,
      "loss": 0.0402,
      "step": 11168
    },
    {
      "epoch": 0.8679670500466273,
      "grad_norm": 0.5988572835922241,
      "learning_rate": 5.660164749766864e-06,
      "loss": 0.527,
      "step": 11169
    },
    {
      "epoch": 0.8680447622008082,
      "grad_norm": 0.4717748463153839,
      "learning_rate": 5.659776188995959e-06,
      "loss": 0.4978,
      "step": 11170
    },
    {
      "epoch": 0.8681224743549891,
      "grad_norm": 0.3648560047149658,
      "learning_rate": 5.659387628225055e-06,
      "loss": 0.129,
      "step": 11171
    },
    {
      "epoch": 0.8682001865091701,
      "grad_norm": 0.2619992196559906,
      "learning_rate": 5.658999067454151e-06,
      "loss": 0.1086,
      "step": 11172
    },
    {
      "epoch": 0.8682778986633509,
      "grad_norm": 0.2322533130645752,
      "learning_rate": 5.658610506683246e-06,
      "loss": 0.0784,
      "step": 11173
    },
    {
      "epoch": 0.8683556108175319,
      "grad_norm": 0.38480523228645325,
      "learning_rate": 5.6582219459123415e-06,
      "loss": 0.2124,
      "step": 11174
    },
    {
      "epoch": 0.8684333229717128,
      "grad_norm": 0.21388943493366241,
      "learning_rate": 5.657833385141437e-06,
      "loss": 0.1362,
      "step": 11175
    },
    {
      "epoch": 0.8685110351258937,
      "grad_norm": 0.5714823603630066,
      "learning_rate": 5.657444824370531e-06,
      "loss": 0.4183,
      "step": 11176
    },
    {
      "epoch": 0.8685887472800746,
      "grad_norm": 0.3912942111492157,
      "learning_rate": 5.657056263599627e-06,
      "loss": 0.2033,
      "step": 11177
    },
    {
      "epoch": 0.8686664594342555,
      "grad_norm": 1.3091579675674438,
      "learning_rate": 5.656667702828723e-06,
      "loss": 0.2479,
      "step": 11178
    },
    {
      "epoch": 0.8687441715884364,
      "grad_norm": 0.24477143585681915,
      "learning_rate": 5.656279142057818e-06,
      "loss": 0.1133,
      "step": 11179
    },
    {
      "epoch": 0.8688218837426174,
      "grad_norm": 0.7595606446266174,
      "learning_rate": 5.655890581286914e-06,
      "loss": 0.1625,
      "step": 11180
    },
    {
      "epoch": 0.8688995958967982,
      "grad_norm": 0.4553466737270355,
      "learning_rate": 5.6555020205160095e-06,
      "loss": 0.0476,
      "step": 11181
    },
    {
      "epoch": 0.8689773080509792,
      "grad_norm": 1.1206046342849731,
      "learning_rate": 5.6551134597451045e-06,
      "loss": 0.5541,
      "step": 11182
    },
    {
      "epoch": 0.8690550202051601,
      "grad_norm": 0.38982871174812317,
      "learning_rate": 5.6547248989741994e-06,
      "loss": 0.1558,
      "step": 11183
    },
    {
      "epoch": 0.869132732359341,
      "grad_norm": 0.4413721263408661,
      "learning_rate": 5.654336338203295e-06,
      "loss": 0.274,
      "step": 11184
    },
    {
      "epoch": 0.8692104445135219,
      "grad_norm": 0.41753292083740234,
      "learning_rate": 5.653947777432391e-06,
      "loss": 0.0984,
      "step": 11185
    },
    {
      "epoch": 0.8692881566677029,
      "grad_norm": 0.22828474640846252,
      "learning_rate": 5.653559216661486e-06,
      "loss": 0.054,
      "step": 11186
    },
    {
      "epoch": 0.8693658688218837,
      "grad_norm": 1.255075216293335,
      "learning_rate": 5.653170655890582e-06,
      "loss": 0.2234,
      "step": 11187
    },
    {
      "epoch": 0.8694435809760647,
      "grad_norm": 0.19664056599140167,
      "learning_rate": 5.6527820951196776e-06,
      "loss": 0.0748,
      "step": 11188
    },
    {
      "epoch": 0.8695212931302456,
      "grad_norm": 0.4223206043243408,
      "learning_rate": 5.6523935343487725e-06,
      "loss": 0.28,
      "step": 11189
    },
    {
      "epoch": 0.8695990052844265,
      "grad_norm": 0.11844731122255325,
      "learning_rate": 5.652004973577868e-06,
      "loss": 0.0094,
      "step": 11190
    },
    {
      "epoch": 0.8696767174386074,
      "grad_norm": 10.22101879119873,
      "learning_rate": 5.651616412806964e-06,
      "loss": 0.399,
      "step": 11191
    },
    {
      "epoch": 0.8697544295927883,
      "grad_norm": 0.5793225169181824,
      "learning_rate": 5.651227852036058e-06,
      "loss": 0.1779,
      "step": 11192
    },
    {
      "epoch": 0.8698321417469692,
      "grad_norm": 0.5389056205749512,
      "learning_rate": 5.650839291265154e-06,
      "loss": 0.1322,
      "step": 11193
    },
    {
      "epoch": 0.8699098539011502,
      "grad_norm": 0.8267577886581421,
      "learning_rate": 5.65045073049425e-06,
      "loss": 0.2941,
      "step": 11194
    },
    {
      "epoch": 0.869987566055331,
      "grad_norm": 0.2172742486000061,
      "learning_rate": 5.650062169723345e-06,
      "loss": 0.0887,
      "step": 11195
    },
    {
      "epoch": 0.870065278209512,
      "grad_norm": 0.2720659077167511,
      "learning_rate": 5.6496736089524406e-06,
      "loss": 0.2297,
      "step": 11196
    },
    {
      "epoch": 0.8701429903636929,
      "grad_norm": 0.3077147305011749,
      "learning_rate": 5.649285048181536e-06,
      "loss": 0.0779,
      "step": 11197
    },
    {
      "epoch": 0.8702207025178738,
      "grad_norm": 0.621441125869751,
      "learning_rate": 5.648896487410631e-06,
      "loss": 0.1093,
      "step": 11198
    },
    {
      "epoch": 0.8702984146720547,
      "grad_norm": 0.18662391602993011,
      "learning_rate": 5.648507926639727e-06,
      "loss": 0.0361,
      "step": 11199
    },
    {
      "epoch": 0.8703761268262357,
      "grad_norm": 0.3855198919773102,
      "learning_rate": 5.648119365868823e-06,
      "loss": 0.2918,
      "step": 11200
    },
    {
      "epoch": 0.8704538389804165,
      "grad_norm": 0.30818745493888855,
      "learning_rate": 5.647730805097917e-06,
      "loss": 0.2654,
      "step": 11201
    },
    {
      "epoch": 0.8705315511345975,
      "grad_norm": 0.45997002720832825,
      "learning_rate": 5.647342244327013e-06,
      "loss": 0.1609,
      "step": 11202
    },
    {
      "epoch": 0.8706092632887784,
      "grad_norm": 0.3451493978500366,
      "learning_rate": 5.646953683556109e-06,
      "loss": 0.1778,
      "step": 11203
    },
    {
      "epoch": 0.8706869754429593,
      "grad_norm": 0.5774033665657043,
      "learning_rate": 5.6465651227852035e-06,
      "loss": 0.3017,
      "step": 11204
    },
    {
      "epoch": 0.8707646875971402,
      "grad_norm": 0.5454576015472412,
      "learning_rate": 5.646176562014299e-06,
      "loss": 0.1332,
      "step": 11205
    },
    {
      "epoch": 0.8708423997513212,
      "grad_norm": 0.5674028992652893,
      "learning_rate": 5.645788001243395e-06,
      "loss": 0.2923,
      "step": 11206
    },
    {
      "epoch": 0.870920111905502,
      "grad_norm": 0.27063608169555664,
      "learning_rate": 5.64539944047249e-06,
      "loss": 0.1149,
      "step": 11207
    },
    {
      "epoch": 0.870997824059683,
      "grad_norm": 0.36682721972465515,
      "learning_rate": 5.645010879701586e-06,
      "loss": 0.556,
      "step": 11208
    },
    {
      "epoch": 0.8710755362138638,
      "grad_norm": 0.19604705274105072,
      "learning_rate": 5.644622318930682e-06,
      "loss": 0.0704,
      "step": 11209
    },
    {
      "epoch": 0.8711532483680448,
      "grad_norm": 0.44789400696754456,
      "learning_rate": 5.644233758159776e-06,
      "loss": 0.2075,
      "step": 11210
    },
    {
      "epoch": 0.8712309605222257,
      "grad_norm": 0.38475021719932556,
      "learning_rate": 5.6438451973888716e-06,
      "loss": 0.1012,
      "step": 11211
    },
    {
      "epoch": 0.8713086726764065,
      "grad_norm": 0.28018996119499207,
      "learning_rate": 5.643456636617967e-06,
      "loss": 0.055,
      "step": 11212
    },
    {
      "epoch": 0.8713863848305875,
      "grad_norm": 0.2691672444343567,
      "learning_rate": 5.643068075847062e-06,
      "loss": 0.1072,
      "step": 11213
    },
    {
      "epoch": 0.8714640969847685,
      "grad_norm": 0.2389453798532486,
      "learning_rate": 5.642679515076158e-06,
      "loss": 0.1174,
      "step": 11214
    },
    {
      "epoch": 0.8715418091389493,
      "grad_norm": 0.5901842713356018,
      "learning_rate": 5.642290954305254e-06,
      "loss": 0.3458,
      "step": 11215
    },
    {
      "epoch": 0.8716195212931303,
      "grad_norm": 0.39143434166908264,
      "learning_rate": 5.64190239353435e-06,
      "loss": 0.0726,
      "step": 11216
    },
    {
      "epoch": 0.8716972334473112,
      "grad_norm": 0.23173291981220245,
      "learning_rate": 5.641513832763445e-06,
      "loss": 0.0622,
      "step": 11217
    },
    {
      "epoch": 0.871774945601492,
      "grad_norm": 0.30956876277923584,
      "learning_rate": 5.6411252719925405e-06,
      "loss": 0.089,
      "step": 11218
    },
    {
      "epoch": 0.871852657755673,
      "grad_norm": 0.12539559602737427,
      "learning_rate": 5.640736711221636e-06,
      "loss": 0.0622,
      "step": 11219
    },
    {
      "epoch": 0.871930369909854,
      "grad_norm": 0.24735619127750397,
      "learning_rate": 5.64034815045073e-06,
      "loss": 0.053,
      "step": 11220
    },
    {
      "epoch": 0.8720080820640348,
      "grad_norm": 0.21181215345859528,
      "learning_rate": 5.639959589679826e-06,
      "loss": 0.1001,
      "step": 11221
    },
    {
      "epoch": 0.8720857942182157,
      "grad_norm": 0.4074651300907135,
      "learning_rate": 5.639571028908922e-06,
      "loss": 0.2006,
      "step": 11222
    },
    {
      "epoch": 0.8721635063723966,
      "grad_norm": 0.6326560974121094,
      "learning_rate": 5.639182468138017e-06,
      "loss": 0.5276,
      "step": 11223
    },
    {
      "epoch": 0.8722412185265775,
      "grad_norm": 0.37639525532722473,
      "learning_rate": 5.638793907367113e-06,
      "loss": 0.3765,
      "step": 11224
    },
    {
      "epoch": 0.8723189306807585,
      "grad_norm": 0.11807087063789368,
      "learning_rate": 5.6384053465962085e-06,
      "loss": 0.0725,
      "step": 11225
    },
    {
      "epoch": 0.8723966428349393,
      "grad_norm": 0.15198251605033875,
      "learning_rate": 5.6380167858253034e-06,
      "loss": 0.0249,
      "step": 11226
    },
    {
      "epoch": 0.8724743549891203,
      "grad_norm": 0.4090835750102997,
      "learning_rate": 5.637628225054399e-06,
      "loss": 0.2169,
      "step": 11227
    },
    {
      "epoch": 0.8725520671433012,
      "grad_norm": 0.35047709941864014,
      "learning_rate": 5.637239664283495e-06,
      "loss": 0.1219,
      "step": 11228
    },
    {
      "epoch": 0.8726297792974821,
      "grad_norm": 0.6482918858528137,
      "learning_rate": 5.636851103512589e-06,
      "loss": 0.4469,
      "step": 11229
    },
    {
      "epoch": 0.872707491451663,
      "grad_norm": 0.28357377648353577,
      "learning_rate": 5.636462542741685e-06,
      "loss": 0.1061,
      "step": 11230
    },
    {
      "epoch": 0.872785203605844,
      "grad_norm": 0.18836838006973267,
      "learning_rate": 5.636073981970781e-06,
      "loss": 0.1579,
      "step": 11231
    },
    {
      "epoch": 0.8728629157600248,
      "grad_norm": 0.923770546913147,
      "learning_rate": 5.635685421199876e-06,
      "loss": 0.4704,
      "step": 11232
    },
    {
      "epoch": 0.8729406279142058,
      "grad_norm": 2.012860059738159,
      "learning_rate": 5.6352968604289715e-06,
      "loss": 0.6402,
      "step": 11233
    },
    {
      "epoch": 0.8730183400683867,
      "grad_norm": 0.2998500168323517,
      "learning_rate": 5.634908299658067e-06,
      "loss": 0.0644,
      "step": 11234
    },
    {
      "epoch": 0.8730960522225676,
      "grad_norm": 0.4330357313156128,
      "learning_rate": 5.634519738887162e-06,
      "loss": 0.1826,
      "step": 11235
    },
    {
      "epoch": 0.8731737643767485,
      "grad_norm": 0.44566911458969116,
      "learning_rate": 5.634131178116258e-06,
      "loss": 0.1766,
      "step": 11236
    },
    {
      "epoch": 0.8732514765309294,
      "grad_norm": 0.38749444484710693,
      "learning_rate": 5.633742617345354e-06,
      "loss": 0.0601,
      "step": 11237
    },
    {
      "epoch": 0.8733291886851103,
      "grad_norm": 0.6178296804428101,
      "learning_rate": 5.633354056574448e-06,
      "loss": 0.3012,
      "step": 11238
    },
    {
      "epoch": 0.8734069008392913,
      "grad_norm": 0.08774197846651077,
      "learning_rate": 5.632965495803544e-06,
      "loss": 0.0294,
      "step": 11239
    },
    {
      "epoch": 0.8734846129934721,
      "grad_norm": 0.5795894861221313,
      "learning_rate": 5.6325769350326395e-06,
      "loss": 0.272,
      "step": 11240
    },
    {
      "epoch": 0.8735623251476531,
      "grad_norm": 0.7480976581573486,
      "learning_rate": 5.6321883742617345e-06,
      "loss": 0.7683,
      "step": 11241
    },
    {
      "epoch": 0.873640037301834,
      "grad_norm": 0.46948620676994324,
      "learning_rate": 5.63179981349083e-06,
      "loss": 0.41,
      "step": 11242
    },
    {
      "epoch": 0.8737177494560149,
      "grad_norm": 0.25803783535957336,
      "learning_rate": 5.631411252719926e-06,
      "loss": 0.0487,
      "step": 11243
    },
    {
      "epoch": 0.8737954616101958,
      "grad_norm": 0.16514939069747925,
      "learning_rate": 5.631022691949021e-06,
      "loss": 0.1714,
      "step": 11244
    },
    {
      "epoch": 0.8738731737643768,
      "grad_norm": 0.39333221316337585,
      "learning_rate": 5.630634131178117e-06,
      "loss": 0.1188,
      "step": 11245
    },
    {
      "epoch": 0.8739508859185576,
      "grad_norm": 0.2918005883693695,
      "learning_rate": 5.630245570407213e-06,
      "loss": 0.1039,
      "step": 11246
    },
    {
      "epoch": 0.8740285980727386,
      "grad_norm": 0.5688733458518982,
      "learning_rate": 5.629857009636308e-06,
      "loss": 0.1705,
      "step": 11247
    },
    {
      "epoch": 0.8741063102269195,
      "grad_norm": 0.1552278846502304,
      "learning_rate": 5.6294684488654025e-06,
      "loss": 0.0356,
      "step": 11248
    },
    {
      "epoch": 0.8741840223811004,
      "grad_norm": 0.24412110447883606,
      "learning_rate": 5.629079888094498e-06,
      "loss": 0.1297,
      "step": 11249
    },
    {
      "epoch": 0.8742617345352813,
      "grad_norm": 0.253339022397995,
      "learning_rate": 5.628691327323594e-06,
      "loss": 0.0898,
      "step": 11250
    },
    {
      "epoch": 0.8743394466894623,
      "grad_norm": 0.5177541971206665,
      "learning_rate": 5.628302766552689e-06,
      "loss": 0.2158,
      "step": 11251
    },
    {
      "epoch": 0.8744171588436431,
      "grad_norm": 0.3510948419570923,
      "learning_rate": 5.627914205781785e-06,
      "loss": 0.1763,
      "step": 11252
    },
    {
      "epoch": 0.8744948709978241,
      "grad_norm": 0.9213662147521973,
      "learning_rate": 5.627525645010881e-06,
      "loss": 0.1674,
      "step": 11253
    },
    {
      "epoch": 0.8745725831520049,
      "grad_norm": 0.29591086506843567,
      "learning_rate": 5.627137084239976e-06,
      "loss": 0.207,
      "step": 11254
    },
    {
      "epoch": 0.8746502953061859,
      "grad_norm": 1.0275516510009766,
      "learning_rate": 5.626748523469071e-06,
      "loss": 0.3511,
      "step": 11255
    },
    {
      "epoch": 0.8747280074603668,
      "grad_norm": 0.6604178547859192,
      "learning_rate": 5.626359962698167e-06,
      "loss": 0.4196,
      "step": 11256
    },
    {
      "epoch": 0.8748057196145477,
      "grad_norm": 0.5919895768165588,
      "learning_rate": 5.625971401927261e-06,
      "loss": 0.311,
      "step": 11257
    },
    {
      "epoch": 0.8748834317687286,
      "grad_norm": 0.1879047155380249,
      "learning_rate": 5.625582841156357e-06,
      "loss": 0.0305,
      "step": 11258
    },
    {
      "epoch": 0.8749611439229096,
      "grad_norm": 0.26981666684150696,
      "learning_rate": 5.625194280385453e-06,
      "loss": 0.1573,
      "step": 11259
    },
    {
      "epoch": 0.8750388560770904,
      "grad_norm": 0.1911434829235077,
      "learning_rate": 5.624805719614548e-06,
      "loss": 0.0939,
      "step": 11260
    },
    {
      "epoch": 0.8751165682312714,
      "grad_norm": 0.2656720280647278,
      "learning_rate": 5.624417158843644e-06,
      "loss": 0.1536,
      "step": 11261
    },
    {
      "epoch": 0.8751942803854523,
      "grad_norm": 0.24563731253147125,
      "learning_rate": 5.624028598072739e-06,
      "loss": 0.077,
      "step": 11262
    },
    {
      "epoch": 0.8752719925396332,
      "grad_norm": 0.1654237061738968,
      "learning_rate": 5.623640037301834e-06,
      "loss": 0.0442,
      "step": 11263
    },
    {
      "epoch": 0.8753497046938141,
      "grad_norm": 0.3836638629436493,
      "learning_rate": 5.62325147653093e-06,
      "loss": 0.1043,
      "step": 11264
    },
    {
      "epoch": 0.8754274168479951,
      "grad_norm": 0.4286212921142578,
      "learning_rate": 5.622862915760026e-06,
      "loss": 0.2419,
      "step": 11265
    },
    {
      "epoch": 0.8755051290021759,
      "grad_norm": 0.4412998855113983,
      "learning_rate": 5.62247435498912e-06,
      "loss": 0.1618,
      "step": 11266
    },
    {
      "epoch": 0.8755828411563569,
      "grad_norm": 0.5975053906440735,
      "learning_rate": 5.622085794218216e-06,
      "loss": 0.2303,
      "step": 11267
    },
    {
      "epoch": 0.8756605533105377,
      "grad_norm": 0.44166356325149536,
      "learning_rate": 5.621697233447312e-06,
      "loss": 0.2006,
      "step": 11268
    },
    {
      "epoch": 0.8757382654647187,
      "grad_norm": 0.21051174402236938,
      "learning_rate": 5.621308672676407e-06,
      "loss": 0.083,
      "step": 11269
    },
    {
      "epoch": 0.8758159776188996,
      "grad_norm": 0.31819120049476624,
      "learning_rate": 5.620920111905502e-06,
      "loss": 0.0537,
      "step": 11270
    },
    {
      "epoch": 0.8758936897730805,
      "grad_norm": 0.23074690997600555,
      "learning_rate": 5.620531551134598e-06,
      "loss": 0.133,
      "step": 11271
    },
    {
      "epoch": 0.8759714019272614,
      "grad_norm": 0.30073082447052,
      "learning_rate": 5.620142990363693e-06,
      "loss": 0.024,
      "step": 11272
    },
    {
      "epoch": 0.8760491140814424,
      "grad_norm": 0.3931833803653717,
      "learning_rate": 5.619754429592789e-06,
      "loss": 0.1143,
      "step": 11273
    },
    {
      "epoch": 0.8761268262356232,
      "grad_norm": 0.40878012776374817,
      "learning_rate": 5.619365868821885e-06,
      "loss": 0.5698,
      "step": 11274
    },
    {
      "epoch": 0.8762045383898042,
      "grad_norm": 0.5972669720649719,
      "learning_rate": 5.6189773080509805e-06,
      "loss": 0.139,
      "step": 11275
    },
    {
      "epoch": 0.8762822505439851,
      "grad_norm": 0.27001768350601196,
      "learning_rate": 5.618588747280075e-06,
      "loss": 0.1549,
      "step": 11276
    },
    {
      "epoch": 0.876359962698166,
      "grad_norm": 0.2733929455280304,
      "learning_rate": 5.6182001865091704e-06,
      "loss": 0.09,
      "step": 11277
    },
    {
      "epoch": 0.8764376748523469,
      "grad_norm": 0.29002559185028076,
      "learning_rate": 5.617811625738266e-06,
      "loss": 0.1152,
      "step": 11278
    },
    {
      "epoch": 0.8765153870065279,
      "grad_norm": 0.6596512198448181,
      "learning_rate": 5.617423064967361e-06,
      "loss": 0.1998,
      "step": 11279
    },
    {
      "epoch": 0.8765930991607087,
      "grad_norm": 0.5613585710525513,
      "learning_rate": 5.617034504196457e-06,
      "loss": 0.4836,
      "step": 11280
    },
    {
      "epoch": 0.8766708113148897,
      "grad_norm": 0.17510534822940826,
      "learning_rate": 5.616645943425553e-06,
      "loss": 0.0669,
      "step": 11281
    },
    {
      "epoch": 0.8767485234690706,
      "grad_norm": 0.055917128920555115,
      "learning_rate": 5.616257382654648e-06,
      "loss": 0.0123,
      "step": 11282
    },
    {
      "epoch": 0.8768262356232515,
      "grad_norm": 0.06528159976005554,
      "learning_rate": 5.6158688218837435e-06,
      "loss": 0.0073,
      "step": 11283
    },
    {
      "epoch": 0.8769039477774324,
      "grad_norm": 0.742249071598053,
      "learning_rate": 5.615480261112839e-06,
      "loss": 0.2952,
      "step": 11284
    },
    {
      "epoch": 0.8769816599316133,
      "grad_norm": 0.8317896723747253,
      "learning_rate": 5.6150917003419334e-06,
      "loss": 0.4711,
      "step": 11285
    },
    {
      "epoch": 0.8770593720857942,
      "grad_norm": 0.19666528701782227,
      "learning_rate": 5.614703139571029e-06,
      "loss": 0.0447,
      "step": 11286
    },
    {
      "epoch": 0.8771370842399752,
      "grad_norm": 0.1965414434671402,
      "learning_rate": 5.614314578800125e-06,
      "loss": 0.0652,
      "step": 11287
    },
    {
      "epoch": 0.877214796394156,
      "grad_norm": 0.32724276185035706,
      "learning_rate": 5.61392601802922e-06,
      "loss": 0.1619,
      "step": 11288
    },
    {
      "epoch": 0.877292508548337,
      "grad_norm": 1.3337124586105347,
      "learning_rate": 5.613537457258316e-06,
      "loss": 0.4613,
      "step": 11289
    },
    {
      "epoch": 0.8773702207025179,
      "grad_norm": 1.1671043634414673,
      "learning_rate": 5.6131488964874116e-06,
      "loss": 0.248,
      "step": 11290
    },
    {
      "epoch": 0.8774479328566988,
      "grad_norm": 0.5335811376571655,
      "learning_rate": 5.6127603357165065e-06,
      "loss": 0.3741,
      "step": 11291
    },
    {
      "epoch": 0.8775256450108797,
      "grad_norm": 0.3012637495994568,
      "learning_rate": 5.612371774945602e-06,
      "loss": 0.1667,
      "step": 11292
    },
    {
      "epoch": 0.8776033571650607,
      "grad_norm": 0.5832312107086182,
      "learning_rate": 5.611983214174698e-06,
      "loss": 0.2936,
      "step": 11293
    },
    {
      "epoch": 0.8776810693192415,
      "grad_norm": 0.7039884328842163,
      "learning_rate": 5.611594653403792e-06,
      "loss": 0.1811,
      "step": 11294
    },
    {
      "epoch": 0.8777587814734225,
      "grad_norm": 0.16210854053497314,
      "learning_rate": 5.611206092632888e-06,
      "loss": 0.1007,
      "step": 11295
    },
    {
      "epoch": 0.8778364936276034,
      "grad_norm": 0.6629757285118103,
      "learning_rate": 5.610817531861984e-06,
      "loss": 0.2922,
      "step": 11296
    },
    {
      "epoch": 0.8779142057817843,
      "grad_norm": 0.24947403371334076,
      "learning_rate": 5.610428971091079e-06,
      "loss": 0.0963,
      "step": 11297
    },
    {
      "epoch": 0.8779919179359652,
      "grad_norm": 0.3776891827583313,
      "learning_rate": 5.6100404103201746e-06,
      "loss": 0.8001,
      "step": 11298
    },
    {
      "epoch": 0.878069630090146,
      "grad_norm": 0.4120863676071167,
      "learning_rate": 5.60965184954927e-06,
      "loss": 0.0818,
      "step": 11299
    },
    {
      "epoch": 0.878147342244327,
      "grad_norm": 0.1738828867673874,
      "learning_rate": 5.609263288778365e-06,
      "loss": 0.0207,
      "step": 11300
    },
    {
      "epoch": 0.878225054398508,
      "grad_norm": 0.0787680521607399,
      "learning_rate": 5.608874728007461e-06,
      "loss": 0.0201,
      "step": 11301
    },
    {
      "epoch": 0.8783027665526888,
      "grad_norm": 0.1535228192806244,
      "learning_rate": 5.608486167236557e-06,
      "loss": 0.0406,
      "step": 11302
    },
    {
      "epoch": 0.8783804787068697,
      "grad_norm": 1.074957251548767,
      "learning_rate": 5.608097606465651e-06,
      "loss": 0.4454,
      "step": 11303
    },
    {
      "epoch": 0.8784581908610507,
      "grad_norm": 0.9412479400634766,
      "learning_rate": 5.607709045694747e-06,
      "loss": 0.4734,
      "step": 11304
    },
    {
      "epoch": 0.8785359030152315,
      "grad_norm": 0.584851086139679,
      "learning_rate": 5.607320484923843e-06,
      "loss": 0.2676,
      "step": 11305
    },
    {
      "epoch": 0.8786136151694125,
      "grad_norm": 0.7491536140441895,
      "learning_rate": 5.606931924152938e-06,
      "loss": 0.3818,
      "step": 11306
    },
    {
      "epoch": 0.8786913273235935,
      "grad_norm": 0.6421388983726501,
      "learning_rate": 5.606543363382033e-06,
      "loss": 0.3526,
      "step": 11307
    },
    {
      "epoch": 0.8787690394777743,
      "grad_norm": 0.2915935218334198,
      "learning_rate": 5.606154802611129e-06,
      "loss": 0.1249,
      "step": 11308
    },
    {
      "epoch": 0.8788467516319552,
      "grad_norm": 0.3121723234653473,
      "learning_rate": 5.605766241840225e-06,
      "loss": 0.126,
      "step": 11309
    },
    {
      "epoch": 0.8789244637861362,
      "grad_norm": 0.9560068845748901,
      "learning_rate": 5.605377681069319e-06,
      "loss": 0.2497,
      "step": 11310
    },
    {
      "epoch": 0.879002175940317,
      "grad_norm": 0.4307629466056824,
      "learning_rate": 5.604989120298415e-06,
      "loss": 0.1675,
      "step": 11311
    },
    {
      "epoch": 0.879079888094498,
      "grad_norm": 0.3109509348869324,
      "learning_rate": 5.604600559527511e-06,
      "loss": 0.0667,
      "step": 11312
    },
    {
      "epoch": 0.8791576002486788,
      "grad_norm": 0.39874330163002014,
      "learning_rate": 5.604211998756606e-06,
      "loss": 0.0555,
      "step": 11313
    },
    {
      "epoch": 0.8792353124028598,
      "grad_norm": 0.44973161816596985,
      "learning_rate": 5.603823437985701e-06,
      "loss": 0.2075,
      "step": 11314
    },
    {
      "epoch": 0.8793130245570407,
      "grad_norm": 0.6987766623497009,
      "learning_rate": 5.603434877214797e-06,
      "loss": 0.2035,
      "step": 11315
    },
    {
      "epoch": 0.8793907367112216,
      "grad_norm": 1.2306243181228638,
      "learning_rate": 5.603046316443892e-06,
      "loss": 0.1999,
      "step": 11316
    },
    {
      "epoch": 0.8794684488654025,
      "grad_norm": 0.6632766723632812,
      "learning_rate": 5.602657755672988e-06,
      "loss": 0.3344,
      "step": 11317
    },
    {
      "epoch": 0.8795461610195835,
      "grad_norm": 0.49435845017433167,
      "learning_rate": 5.602269194902084e-06,
      "loss": 0.452,
      "step": 11318
    },
    {
      "epoch": 0.8796238731737643,
      "grad_norm": 0.424702525138855,
      "learning_rate": 5.601880634131178e-06,
      "loss": 0.288,
      "step": 11319
    },
    {
      "epoch": 0.8797015853279453,
      "grad_norm": 0.8319663405418396,
      "learning_rate": 5.601492073360274e-06,
      "loss": 0.3127,
      "step": 11320
    },
    {
      "epoch": 0.8797792974821262,
      "grad_norm": 0.2427060753107071,
      "learning_rate": 5.601103512589369e-06,
      "loss": 0.0744,
      "step": 11321
    },
    {
      "epoch": 0.8798570096363071,
      "grad_norm": 11.197929382324219,
      "learning_rate": 5.600714951818464e-06,
      "loss": 1.9169,
      "step": 11322
    },
    {
      "epoch": 0.879934721790488,
      "grad_norm": 0.5319470167160034,
      "learning_rate": 5.60032639104756e-06,
      "loss": 0.1192,
      "step": 11323
    },
    {
      "epoch": 0.880012433944669,
      "grad_norm": 0.14080995321273804,
      "learning_rate": 5.599937830276656e-06,
      "loss": 0.05,
      "step": 11324
    },
    {
      "epoch": 0.8800901460988498,
      "grad_norm": 0.6893885135650635,
      "learning_rate": 5.599549269505751e-06,
      "loss": 0.408,
      "step": 11325
    },
    {
      "epoch": 0.8801678582530308,
      "grad_norm": 0.2595398724079132,
      "learning_rate": 5.599160708734847e-06,
      "loss": 0.0961,
      "step": 11326
    },
    {
      "epoch": 0.8802455704072117,
      "grad_norm": 0.4302722215652466,
      "learning_rate": 5.5987721479639425e-06,
      "loss": 0.3353,
      "step": 11327
    },
    {
      "epoch": 0.8803232825613926,
      "grad_norm": 0.45044150948524475,
      "learning_rate": 5.598383587193037e-06,
      "loss": 0.5157,
      "step": 11328
    },
    {
      "epoch": 0.8804009947155735,
      "grad_norm": 0.1866365522146225,
      "learning_rate": 5.597995026422132e-06,
      "loss": 0.0941,
      "step": 11329
    },
    {
      "epoch": 0.8804787068697544,
      "grad_norm": 0.8704665899276733,
      "learning_rate": 5.597606465651228e-06,
      "loss": 0.7759,
      "step": 11330
    },
    {
      "epoch": 0.8805564190239353,
      "grad_norm": 0.27244454622268677,
      "learning_rate": 5.597217904880323e-06,
      "loss": 0.0308,
      "step": 11331
    },
    {
      "epoch": 0.8806341311781163,
      "grad_norm": 0.2662526071071625,
      "learning_rate": 5.596829344109419e-06,
      "loss": 0.2249,
      "step": 11332
    },
    {
      "epoch": 0.8807118433322971,
      "grad_norm": 0.3441992700099945,
      "learning_rate": 5.596440783338515e-06,
      "loss": 0.0842,
      "step": 11333
    },
    {
      "epoch": 0.8807895554864781,
      "grad_norm": 0.20283916592597961,
      "learning_rate": 5.59605222256761e-06,
      "loss": 0.1277,
      "step": 11334
    },
    {
      "epoch": 0.880867267640659,
      "grad_norm": 0.43098700046539307,
      "learning_rate": 5.5956636617967055e-06,
      "loss": 0.2626,
      "step": 11335
    },
    {
      "epoch": 0.8809449797948399,
      "grad_norm": 19.167797088623047,
      "learning_rate": 5.595275101025801e-06,
      "loss": 0.6013,
      "step": 11336
    },
    {
      "epoch": 0.8810226919490208,
      "grad_norm": 0.5171082615852356,
      "learning_rate": 5.594886540254897e-06,
      "loss": 0.1149,
      "step": 11337
    },
    {
      "epoch": 0.8811004041032018,
      "grad_norm": 0.670333743095398,
      "learning_rate": 5.594497979483991e-06,
      "loss": 0.646,
      "step": 11338
    },
    {
      "epoch": 0.8811781162573826,
      "grad_norm": 0.5500730872154236,
      "learning_rate": 5.594109418713087e-06,
      "loss": 0.3035,
      "step": 11339
    },
    {
      "epoch": 0.8812558284115636,
      "grad_norm": 0.4369543194770813,
      "learning_rate": 5.593720857942183e-06,
      "loss": 0.3811,
      "step": 11340
    },
    {
      "epoch": 0.8813335405657445,
      "grad_norm": 0.450876384973526,
      "learning_rate": 5.593332297171278e-06,
      "loss": 0.4865,
      "step": 11341
    },
    {
      "epoch": 0.8814112527199254,
      "grad_norm": 0.3837267756462097,
      "learning_rate": 5.5929437364003735e-06,
      "loss": 0.2618,
      "step": 11342
    },
    {
      "epoch": 0.8814889648741063,
      "grad_norm": 0.7779783606529236,
      "learning_rate": 5.592555175629469e-06,
      "loss": 0.3957,
      "step": 11343
    },
    {
      "epoch": 0.8815666770282872,
      "grad_norm": 0.32201331853866577,
      "learning_rate": 5.592166614858564e-06,
      "loss": 0.1877,
      "step": 11344
    },
    {
      "epoch": 0.8816443891824681,
      "grad_norm": 0.3172759711742401,
      "learning_rate": 5.59177805408766e-06,
      "loss": 0.2592,
      "step": 11345
    },
    {
      "epoch": 0.8817221013366491,
      "grad_norm": 0.5119823813438416,
      "learning_rate": 5.591389493316756e-06,
      "loss": 0.1563,
      "step": 11346
    },
    {
      "epoch": 0.8817998134908299,
      "grad_norm": 0.6386556625366211,
      "learning_rate": 5.59100093254585e-06,
      "loss": 0.1011,
      "step": 11347
    },
    {
      "epoch": 0.8818775256450109,
      "grad_norm": 0.32893499732017517,
      "learning_rate": 5.590612371774946e-06,
      "loss": 0.2182,
      "step": 11348
    },
    {
      "epoch": 0.8819552377991918,
      "grad_norm": 0.44924816489219666,
      "learning_rate": 5.5902238110040416e-06,
      "loss": 0.5125,
      "step": 11349
    },
    {
      "epoch": 0.8820329499533727,
      "grad_norm": 0.283284068107605,
      "learning_rate": 5.5898352502331365e-06,
      "loss": 0.0735,
      "step": 11350
    },
    {
      "epoch": 0.8821106621075536,
      "grad_norm": 0.303829550743103,
      "learning_rate": 5.589446689462232e-06,
      "loss": 0.1139,
      "step": 11351
    },
    {
      "epoch": 0.8821883742617346,
      "grad_norm": 0.334900438785553,
      "learning_rate": 5.589058128691328e-06,
      "loss": 0.0884,
      "step": 11352
    },
    {
      "epoch": 0.8822660864159154,
      "grad_norm": 0.5348868370056152,
      "learning_rate": 5.588669567920423e-06,
      "loss": 1.0598,
      "step": 11353
    },
    {
      "epoch": 0.8823437985700964,
      "grad_norm": 0.4196103811264038,
      "learning_rate": 5.588281007149519e-06,
      "loss": 0.1615,
      "step": 11354
    },
    {
      "epoch": 0.8824215107242773,
      "grad_norm": 0.5502858757972717,
      "learning_rate": 5.587892446378615e-06,
      "loss": 0.5952,
      "step": 11355
    },
    {
      "epoch": 0.8824992228784582,
      "grad_norm": 0.5100449919700623,
      "learning_rate": 5.587503885607709e-06,
      "loss": 0.3662,
      "step": 11356
    },
    {
      "epoch": 0.8825769350326391,
      "grad_norm": 0.6616554856300354,
      "learning_rate": 5.5871153248368045e-06,
      "loss": 0.3516,
      "step": 11357
    },
    {
      "epoch": 0.8826546471868201,
      "grad_norm": 0.2736174464225769,
      "learning_rate": 5.5867267640659e-06,
      "loss": 0.0873,
      "step": 11358
    },
    {
      "epoch": 0.8827323593410009,
      "grad_norm": 0.7266693711280823,
      "learning_rate": 5.586338203294995e-06,
      "loss": 0.1098,
      "step": 11359
    },
    {
      "epoch": 0.8828100714951819,
      "grad_norm": 0.6270346641540527,
      "learning_rate": 5.585949642524091e-06,
      "loss": 0.1239,
      "step": 11360
    },
    {
      "epoch": 0.8828877836493627,
      "grad_norm": 0.0849834531545639,
      "learning_rate": 5.585561081753187e-06,
      "loss": 0.0109,
      "step": 11361
    },
    {
      "epoch": 0.8829654958035437,
      "grad_norm": 0.2776283323764801,
      "learning_rate": 5.585172520982282e-06,
      "loss": 0.1103,
      "step": 11362
    },
    {
      "epoch": 0.8830432079577246,
      "grad_norm": 0.05193650722503662,
      "learning_rate": 5.584783960211378e-06,
      "loss": 0.0085,
      "step": 11363
    },
    {
      "epoch": 0.8831209201119055,
      "grad_norm": 0.7161313891410828,
      "learning_rate": 5.5843953994404734e-06,
      "loss": 0.1792,
      "step": 11364
    },
    {
      "epoch": 0.8831986322660864,
      "grad_norm": 0.20953522622585297,
      "learning_rate": 5.5840068386695675e-06,
      "loss": 0.0921,
      "step": 11365
    },
    {
      "epoch": 0.8832763444202674,
      "grad_norm": 0.23913078010082245,
      "learning_rate": 5.583618277898663e-06,
      "loss": 0.1718,
      "step": 11366
    },
    {
      "epoch": 0.8833540565744482,
      "grad_norm": 0.38124072551727295,
      "learning_rate": 5.583229717127759e-06,
      "loss": 0.1183,
      "step": 11367
    },
    {
      "epoch": 0.8834317687286292,
      "grad_norm": 0.5465420484542847,
      "learning_rate": 5.582841156356855e-06,
      "loss": 0.563,
      "step": 11368
    },
    {
      "epoch": 0.8835094808828101,
      "grad_norm": 0.5964768528938293,
      "learning_rate": 5.58245259558595e-06,
      "loss": 0.3407,
      "step": 11369
    },
    {
      "epoch": 0.883587193036991,
      "grad_norm": 0.48185086250305176,
      "learning_rate": 5.582064034815046e-06,
      "loss": 0.6969,
      "step": 11370
    },
    {
      "epoch": 0.8836649051911719,
      "grad_norm": 0.2238309234380722,
      "learning_rate": 5.5816754740441415e-06,
      "loss": 0.1153,
      "step": 11371
    },
    {
      "epoch": 0.8837426173453529,
      "grad_norm": 0.5221503376960754,
      "learning_rate": 5.581286913273236e-06,
      "loss": 0.387,
      "step": 11372
    },
    {
      "epoch": 0.8838203294995337,
      "grad_norm": 0.06708633154630661,
      "learning_rate": 5.580898352502332e-06,
      "loss": 0.022,
      "step": 11373
    },
    {
      "epoch": 0.8838980416537147,
      "grad_norm": 0.49056383967399597,
      "learning_rate": 5.580509791731428e-06,
      "loss": 0.3928,
      "step": 11374
    },
    {
      "epoch": 0.8839757538078955,
      "grad_norm": 0.3918350636959076,
      "learning_rate": 5.580121230960522e-06,
      "loss": 0.0797,
      "step": 11375
    },
    {
      "epoch": 0.8840534659620765,
      "grad_norm": 0.3547199070453644,
      "learning_rate": 5.579732670189618e-06,
      "loss": 0.1252,
      "step": 11376
    },
    {
      "epoch": 0.8841311781162574,
      "grad_norm": 0.26863083243370056,
      "learning_rate": 5.579344109418714e-06,
      "loss": 0.19,
      "step": 11377
    },
    {
      "epoch": 0.8842088902704383,
      "grad_norm": 0.7235947847366333,
      "learning_rate": 5.578955548647809e-06,
      "loss": 0.3844,
      "step": 11378
    },
    {
      "epoch": 0.8842866024246192,
      "grad_norm": 0.7137007713317871,
      "learning_rate": 5.5785669878769045e-06,
      "loss": 0.3619,
      "step": 11379
    },
    {
      "epoch": 0.8843643145788002,
      "grad_norm": 0.47565793991088867,
      "learning_rate": 5.578178427106e-06,
      "loss": 0.4135,
      "step": 11380
    },
    {
      "epoch": 0.884442026732981,
      "grad_norm": 4.310397624969482,
      "learning_rate": 5.577789866335095e-06,
      "loss": 0.949,
      "step": 11381
    },
    {
      "epoch": 0.884519738887162,
      "grad_norm": 0.2605441212654114,
      "learning_rate": 5.577401305564191e-06,
      "loss": 0.0637,
      "step": 11382
    },
    {
      "epoch": 0.8845974510413429,
      "grad_norm": 0.8162254095077515,
      "learning_rate": 5.577012744793287e-06,
      "loss": 0.3484,
      "step": 11383
    },
    {
      "epoch": 0.8846751631955238,
      "grad_norm": 0.4473365843296051,
      "learning_rate": 5.576624184022381e-06,
      "loss": 0.1503,
      "step": 11384
    },
    {
      "epoch": 0.8847528753497047,
      "grad_norm": 0.3579420745372772,
      "learning_rate": 5.576235623251477e-06,
      "loss": 0.18,
      "step": 11385
    },
    {
      "epoch": 0.8848305875038857,
      "grad_norm": 0.18136149644851685,
      "learning_rate": 5.5758470624805725e-06,
      "loss": 0.0335,
      "step": 11386
    },
    {
      "epoch": 0.8849082996580665,
      "grad_norm": 0.4206078052520752,
      "learning_rate": 5.5754585017096674e-06,
      "loss": 0.2534,
      "step": 11387
    },
    {
      "epoch": 0.8849860118122475,
      "grad_norm": 0.4243738651275635,
      "learning_rate": 5.575069940938763e-06,
      "loss": 0.267,
      "step": 11388
    },
    {
      "epoch": 0.8850637239664283,
      "grad_norm": 0.7614466547966003,
      "learning_rate": 5.574681380167859e-06,
      "loss": 0.5416,
      "step": 11389
    },
    {
      "epoch": 0.8851414361206092,
      "grad_norm": 0.401065856218338,
      "learning_rate": 5.574292819396954e-06,
      "loss": 0.0483,
      "step": 11390
    },
    {
      "epoch": 0.8852191482747902,
      "grad_norm": 0.1395711898803711,
      "learning_rate": 5.57390425862605e-06,
      "loss": 0.0752,
      "step": 11391
    },
    {
      "epoch": 0.885296860428971,
      "grad_norm": 1.1366263628005981,
      "learning_rate": 5.5735156978551456e-06,
      "loss": 0.3062,
      "step": 11392
    },
    {
      "epoch": 0.885374572583152,
      "grad_norm": 0.1453903615474701,
      "learning_rate": 5.57312713708424e-06,
      "loss": 0.0609,
      "step": 11393
    },
    {
      "epoch": 0.885452284737333,
      "grad_norm": 0.8589288592338562,
      "learning_rate": 5.5727385763133355e-06,
      "loss": 0.7444,
      "step": 11394
    },
    {
      "epoch": 0.8855299968915138,
      "grad_norm": 1.1775188446044922,
      "learning_rate": 5.572350015542431e-06,
      "loss": 0.3402,
      "step": 11395
    },
    {
      "epoch": 0.8856077090456947,
      "grad_norm": 0.2812194228172302,
      "learning_rate": 5.571961454771526e-06,
      "loss": 0.1884,
      "step": 11396
    },
    {
      "epoch": 0.8856854211998757,
      "grad_norm": 0.43484506011009216,
      "learning_rate": 5.571572894000622e-06,
      "loss": 0.4033,
      "step": 11397
    },
    {
      "epoch": 0.8857631333540565,
      "grad_norm": 0.4561903178691864,
      "learning_rate": 5.571184333229718e-06,
      "loss": 0.1188,
      "step": 11398
    },
    {
      "epoch": 0.8858408455082375,
      "grad_norm": 0.28191620111465454,
      "learning_rate": 5.570795772458814e-06,
      "loss": 0.0623,
      "step": 11399
    },
    {
      "epoch": 0.8859185576624184,
      "grad_norm": 0.4484337568283081,
      "learning_rate": 5.5704072116879086e-06,
      "loss": 0.1709,
      "step": 11400
    },
    {
      "epoch": 0.8859962698165993,
      "grad_norm": 0.44403430819511414,
      "learning_rate": 5.570018650917004e-06,
      "loss": 0.2263,
      "step": 11401
    },
    {
      "epoch": 0.8860739819707802,
      "grad_norm": 0.1535969227552414,
      "learning_rate": 5.5696300901461e-06,
      "loss": 0.0701,
      "step": 11402
    },
    {
      "epoch": 0.8861516941249612,
      "grad_norm": 0.5445131659507751,
      "learning_rate": 5.569241529375194e-06,
      "loss": 0.2893,
      "step": 11403
    },
    {
      "epoch": 0.886229406279142,
      "grad_norm": 0.43198439478874207,
      "learning_rate": 5.56885296860429e-06,
      "loss": 0.232,
      "step": 11404
    },
    {
      "epoch": 0.886307118433323,
      "grad_norm": 0.3612590730190277,
      "learning_rate": 5.568464407833386e-06,
      "loss": 0.288,
      "step": 11405
    },
    {
      "epoch": 0.8863848305875038,
      "grad_norm": 0.21767084300518036,
      "learning_rate": 5.568075847062481e-06,
      "loss": 0.0407,
      "step": 11406
    },
    {
      "epoch": 0.8864625427416848,
      "grad_norm": 0.44494444131851196,
      "learning_rate": 5.567687286291577e-06,
      "loss": 0.4448,
      "step": 11407
    },
    {
      "epoch": 0.8865402548958657,
      "grad_norm": 0.3526858389377594,
      "learning_rate": 5.567298725520672e-06,
      "loss": 0.1403,
      "step": 11408
    },
    {
      "epoch": 0.8866179670500466,
      "grad_norm": 0.6036064028739929,
      "learning_rate": 5.566910164749767e-06,
      "loss": 0.306,
      "step": 11409
    },
    {
      "epoch": 0.8866956792042275,
      "grad_norm": 0.4775150716304779,
      "learning_rate": 5.566521603978863e-06,
      "loss": 0.4439,
      "step": 11410
    },
    {
      "epoch": 0.8867733913584085,
      "grad_norm": 0.18979676067829132,
      "learning_rate": 5.566133043207959e-06,
      "loss": 0.062,
      "step": 11411
    },
    {
      "epoch": 0.8868511035125893,
      "grad_norm": 0.4085201621055603,
      "learning_rate": 5.565744482437053e-06,
      "loss": 0.1143,
      "step": 11412
    },
    {
      "epoch": 0.8869288156667703,
      "grad_norm": 0.699572741985321,
      "learning_rate": 5.565355921666149e-06,
      "loss": 0.0845,
      "step": 11413
    },
    {
      "epoch": 0.8870065278209512,
      "grad_norm": 0.13430900871753693,
      "learning_rate": 5.564967360895245e-06,
      "loss": 0.0671,
      "step": 11414
    },
    {
      "epoch": 0.8870842399751321,
      "grad_norm": 0.2896991968154907,
      "learning_rate": 5.56457880012434e-06,
      "loss": 0.0716,
      "step": 11415
    },
    {
      "epoch": 0.887161952129313,
      "grad_norm": 0.8298974633216858,
      "learning_rate": 5.564190239353435e-06,
      "loss": 0.2406,
      "step": 11416
    },
    {
      "epoch": 0.887239664283494,
      "grad_norm": 0.21319976449012756,
      "learning_rate": 5.563801678582531e-06,
      "loss": 0.0588,
      "step": 11417
    },
    {
      "epoch": 0.8873173764376748,
      "grad_norm": 0.2630676329135895,
      "learning_rate": 5.563413117811626e-06,
      "loss": 0.2495,
      "step": 11418
    },
    {
      "epoch": 0.8873950885918558,
      "grad_norm": 0.44759973883628845,
      "learning_rate": 5.563024557040722e-06,
      "loss": 0.5616,
      "step": 11419
    },
    {
      "epoch": 0.8874728007460366,
      "grad_norm": 0.1678745299577713,
      "learning_rate": 5.562635996269818e-06,
      "loss": 0.1242,
      "step": 11420
    },
    {
      "epoch": 0.8875505129002176,
      "grad_norm": 0.07222358882427216,
      "learning_rate": 5.562247435498912e-06,
      "loss": 0.0112,
      "step": 11421
    },
    {
      "epoch": 0.8876282250543985,
      "grad_norm": 0.40023764967918396,
      "learning_rate": 5.561858874728008e-06,
      "loss": 0.3113,
      "step": 11422
    },
    {
      "epoch": 0.8877059372085794,
      "grad_norm": 0.5403366684913635,
      "learning_rate": 5.561470313957103e-06,
      "loss": 0.242,
      "step": 11423
    },
    {
      "epoch": 0.8877836493627603,
      "grad_norm": 0.5386359095573425,
      "learning_rate": 5.561081753186198e-06,
      "loss": 0.1565,
      "step": 11424
    },
    {
      "epoch": 0.8878613615169413,
      "grad_norm": 0.5430282950401306,
      "learning_rate": 5.560693192415294e-06,
      "loss": 0.3068,
      "step": 11425
    },
    {
      "epoch": 0.8879390736711221,
      "grad_norm": 0.057879019528627396,
      "learning_rate": 5.56030463164439e-06,
      "loss": 0.0076,
      "step": 11426
    },
    {
      "epoch": 0.8880167858253031,
      "grad_norm": 0.2235395312309265,
      "learning_rate": 5.559916070873486e-06,
      "loss": 0.1242,
      "step": 11427
    },
    {
      "epoch": 0.888094497979484,
      "grad_norm": 0.42293888330459595,
      "learning_rate": 5.559527510102581e-06,
      "loss": 0.2393,
      "step": 11428
    },
    {
      "epoch": 0.8881722101336649,
      "grad_norm": 0.5846194624900818,
      "learning_rate": 5.5591389493316765e-06,
      "loss": 0.241,
      "step": 11429
    },
    {
      "epoch": 0.8882499222878458,
      "grad_norm": 0.08173516392707825,
      "learning_rate": 5.5587503885607715e-06,
      "loss": 0.0139,
      "step": 11430
    },
    {
      "epoch": 0.8883276344420268,
      "grad_norm": 0.05162929743528366,
      "learning_rate": 5.558361827789866e-06,
      "loss": 0.0139,
      "step": 11431
    },
    {
      "epoch": 0.8884053465962076,
      "grad_norm": 0.2614966332912445,
      "learning_rate": 5.557973267018962e-06,
      "loss": 0.094,
      "step": 11432
    },
    {
      "epoch": 0.8884830587503886,
      "grad_norm": 1.589953064918518,
      "learning_rate": 5.557584706248058e-06,
      "loss": 0.9323,
      "step": 11433
    },
    {
      "epoch": 0.8885607709045695,
      "grad_norm": 0.18472528457641602,
      "learning_rate": 5.557196145477153e-06,
      "loss": 0.0968,
      "step": 11434
    },
    {
      "epoch": 0.8886384830587504,
      "grad_norm": 0.35511577129364014,
      "learning_rate": 5.556807584706249e-06,
      "loss": 0.241,
      "step": 11435
    },
    {
      "epoch": 0.8887161952129313,
      "grad_norm": 0.8006697297096252,
      "learning_rate": 5.5564190239353445e-06,
      "loss": 0.263,
      "step": 11436
    },
    {
      "epoch": 0.8887939073671122,
      "grad_norm": 0.12196101993322372,
      "learning_rate": 5.556030463164439e-06,
      "loss": 0.0435,
      "step": 11437
    },
    {
      "epoch": 0.8888716195212931,
      "grad_norm": 0.34652361273765564,
      "learning_rate": 5.5556419023935344e-06,
      "loss": 0.1037,
      "step": 11438
    },
    {
      "epoch": 0.8889493316754741,
      "grad_norm": 0.4823529124259949,
      "learning_rate": 5.55525334162263e-06,
      "loss": 0.1286,
      "step": 11439
    },
    {
      "epoch": 0.8890270438296549,
      "grad_norm": 0.24244758486747742,
      "learning_rate": 5.554864780851725e-06,
      "loss": 0.174,
      "step": 11440
    },
    {
      "epoch": 0.8891047559838359,
      "grad_norm": 0.17305903136730194,
      "learning_rate": 5.554476220080821e-06,
      "loss": 0.0443,
      "step": 11441
    },
    {
      "epoch": 0.8891824681380168,
      "grad_norm": 0.12274657934904099,
      "learning_rate": 5.554087659309917e-06,
      "loss": 0.0323,
      "step": 11442
    },
    {
      "epoch": 0.8892601802921977,
      "grad_norm": 0.24926546216011047,
      "learning_rate": 5.553699098539012e-06,
      "loss": 0.0718,
      "step": 11443
    },
    {
      "epoch": 0.8893378924463786,
      "grad_norm": 0.7333747744560242,
      "learning_rate": 5.5533105377681075e-06,
      "loss": 0.2404,
      "step": 11444
    },
    {
      "epoch": 0.8894156046005596,
      "grad_norm": 0.5020442008972168,
      "learning_rate": 5.552921976997203e-06,
      "loss": 0.322,
      "step": 11445
    },
    {
      "epoch": 0.8894933167547404,
      "grad_norm": 0.09332085400819778,
      "learning_rate": 5.5525334162262974e-06,
      "loss": 0.0513,
      "step": 11446
    },
    {
      "epoch": 0.8895710289089214,
      "grad_norm": 0.1195264607667923,
      "learning_rate": 5.552144855455393e-06,
      "loss": 0.0508,
      "step": 11447
    },
    {
      "epoch": 0.8896487410631023,
      "grad_norm": 0.6266845464706421,
      "learning_rate": 5.551756294684489e-06,
      "loss": 0.144,
      "step": 11448
    },
    {
      "epoch": 0.8897264532172832,
      "grad_norm": 0.252971351146698,
      "learning_rate": 5.551367733913584e-06,
      "loss": 0.0952,
      "step": 11449
    },
    {
      "epoch": 0.8898041653714641,
      "grad_norm": 0.40552106499671936,
      "learning_rate": 5.55097917314268e-06,
      "loss": 0.1652,
      "step": 11450
    },
    {
      "epoch": 0.889881877525645,
      "grad_norm": 0.39436936378479004,
      "learning_rate": 5.5505906123717756e-06,
      "loss": 0.4041,
      "step": 11451
    },
    {
      "epoch": 0.8899595896798259,
      "grad_norm": 0.06951114535331726,
      "learning_rate": 5.5502020516008705e-06,
      "loss": 0.0125,
      "step": 11452
    },
    {
      "epoch": 0.8900373018340069,
      "grad_norm": 0.7130008339881897,
      "learning_rate": 5.549813490829966e-06,
      "loss": 0.5219,
      "step": 11453
    },
    {
      "epoch": 0.8901150139881877,
      "grad_norm": 0.5106523036956787,
      "learning_rate": 5.549424930059062e-06,
      "loss": 0.2904,
      "step": 11454
    },
    {
      "epoch": 0.8901927261423687,
      "grad_norm": 0.7926690578460693,
      "learning_rate": 5.549036369288156e-06,
      "loss": 0.0871,
      "step": 11455
    },
    {
      "epoch": 0.8902704382965496,
      "grad_norm": 0.6886689066886902,
      "learning_rate": 5.548647808517252e-06,
      "loss": 0.3421,
      "step": 11456
    },
    {
      "epoch": 0.8903481504507305,
      "grad_norm": 0.2804591655731201,
      "learning_rate": 5.548259247746348e-06,
      "loss": 0.0717,
      "step": 11457
    },
    {
      "epoch": 0.8904258626049114,
      "grad_norm": 0.4033159613609314,
      "learning_rate": 5.547870686975444e-06,
      "loss": 0.0807,
      "step": 11458
    },
    {
      "epoch": 0.8905035747590924,
      "grad_norm": 0.30324769020080566,
      "learning_rate": 5.5474821262045385e-06,
      "loss": 0.0547,
      "step": 11459
    },
    {
      "epoch": 0.8905812869132732,
      "grad_norm": 0.781145453453064,
      "learning_rate": 5.547093565433634e-06,
      "loss": 0.2484,
      "step": 11460
    },
    {
      "epoch": 0.8906589990674542,
      "grad_norm": 0.6181382536888123,
      "learning_rate": 5.54670500466273e-06,
      "loss": 0.2177,
      "step": 11461
    },
    {
      "epoch": 0.8907367112216351,
      "grad_norm": 0.49750348925590515,
      "learning_rate": 5.546316443891825e-06,
      "loss": 0.2195,
      "step": 11462
    },
    {
      "epoch": 0.890814423375816,
      "grad_norm": 0.41833943128585815,
      "learning_rate": 5.545927883120921e-06,
      "loss": 0.3319,
      "step": 11463
    },
    {
      "epoch": 0.8908921355299969,
      "grad_norm": 0.3959762156009674,
      "learning_rate": 5.545539322350017e-06,
      "loss": 0.0545,
      "step": 11464
    },
    {
      "epoch": 0.8909698476841778,
      "grad_norm": 0.2563644051551819,
      "learning_rate": 5.545150761579111e-06,
      "loss": 0.0531,
      "step": 11465
    },
    {
      "epoch": 0.8910475598383587,
      "grad_norm": 0.16755782067775726,
      "learning_rate": 5.544762200808207e-06,
      "loss": 0.0369,
      "step": 11466
    },
    {
      "epoch": 0.8911252719925397,
      "grad_norm": 0.4573463797569275,
      "learning_rate": 5.544373640037302e-06,
      "loss": 0.1397,
      "step": 11467
    },
    {
      "epoch": 0.8912029841467205,
      "grad_norm": 0.14986878633499146,
      "learning_rate": 5.543985079266397e-06,
      "loss": 0.0445,
      "step": 11468
    },
    {
      "epoch": 0.8912806963009015,
      "grad_norm": 0.7834125757217407,
      "learning_rate": 5.543596518495493e-06,
      "loss": 0.5199,
      "step": 11469
    },
    {
      "epoch": 0.8913584084550824,
      "grad_norm": 0.21120795607566833,
      "learning_rate": 5.543207957724589e-06,
      "loss": 0.0367,
      "step": 11470
    },
    {
      "epoch": 0.8914361206092632,
      "grad_norm": 0.3545880615711212,
      "learning_rate": 5.542819396953684e-06,
      "loss": 0.1222,
      "step": 11471
    },
    {
      "epoch": 0.8915138327634442,
      "grad_norm": 0.24514959752559662,
      "learning_rate": 5.54243083618278e-06,
      "loss": 0.1498,
      "step": 11472
    },
    {
      "epoch": 0.8915915449176252,
      "grad_norm": 0.6379287242889404,
      "learning_rate": 5.5420422754118755e-06,
      "loss": 0.2311,
      "step": 11473
    },
    {
      "epoch": 0.891669257071806,
      "grad_norm": 0.06988304108381271,
      "learning_rate": 5.5416537146409696e-06,
      "loss": 0.0281,
      "step": 11474
    },
    {
      "epoch": 0.891746969225987,
      "grad_norm": 0.4712376594543457,
      "learning_rate": 5.541265153870065e-06,
      "loss": 0.8171,
      "step": 11475
    },
    {
      "epoch": 0.8918246813801679,
      "grad_norm": 0.5359349250793457,
      "learning_rate": 5.540876593099161e-06,
      "loss": 0.3984,
      "step": 11476
    },
    {
      "epoch": 0.8919023935343487,
      "grad_norm": 0.346402108669281,
      "learning_rate": 5.540488032328256e-06,
      "loss": 0.2452,
      "step": 11477
    },
    {
      "epoch": 0.8919801056885297,
      "grad_norm": 0.549615740776062,
      "learning_rate": 5.540099471557352e-06,
      "loss": 0.3656,
      "step": 11478
    },
    {
      "epoch": 0.8920578178427107,
      "grad_norm": 0.47454097867012024,
      "learning_rate": 5.539710910786448e-06,
      "loss": 0.1287,
      "step": 11479
    },
    {
      "epoch": 0.8921355299968915,
      "grad_norm": 0.4952258765697479,
      "learning_rate": 5.539322350015543e-06,
      "loss": 1.1888,
      "step": 11480
    },
    {
      "epoch": 0.8922132421510724,
      "grad_norm": 0.46841147541999817,
      "learning_rate": 5.5389337892446385e-06,
      "loss": 0.2295,
      "step": 11481
    },
    {
      "epoch": 0.8922909543052533,
      "grad_norm": 0.5004628896713257,
      "learning_rate": 5.538545228473734e-06,
      "loss": 0.0601,
      "step": 11482
    },
    {
      "epoch": 0.8923686664594342,
      "grad_norm": 0.7011035084724426,
      "learning_rate": 5.538156667702828e-06,
      "loss": 0.213,
      "step": 11483
    },
    {
      "epoch": 0.8924463786136152,
      "grad_norm": 0.48910391330718994,
      "learning_rate": 5.537768106931924e-06,
      "loss": 0.2385,
      "step": 11484
    },
    {
      "epoch": 0.892524090767796,
      "grad_norm": 0.13003194332122803,
      "learning_rate": 5.53737954616102e-06,
      "loss": 0.0353,
      "step": 11485
    },
    {
      "epoch": 0.892601802921977,
      "grad_norm": 0.574282169342041,
      "learning_rate": 5.536990985390115e-06,
      "loss": 0.3064,
      "step": 11486
    },
    {
      "epoch": 0.892679515076158,
      "grad_norm": 0.2246287316083908,
      "learning_rate": 5.536602424619211e-06,
      "loss": 0.1015,
      "step": 11487
    },
    {
      "epoch": 0.8927572272303388,
      "grad_norm": 0.1570654958486557,
      "learning_rate": 5.5362138638483065e-06,
      "loss": 0.0523,
      "step": 11488
    },
    {
      "epoch": 0.8928349393845197,
      "grad_norm": 0.6095284223556519,
      "learning_rate": 5.535825303077402e-06,
      "loss": 0.3468,
      "step": 11489
    },
    {
      "epoch": 0.8929126515387007,
      "grad_norm": 0.3563745617866516,
      "learning_rate": 5.535436742306497e-06,
      "loss": 0.271,
      "step": 11490
    },
    {
      "epoch": 0.8929903636928815,
      "grad_norm": 0.15998569130897522,
      "learning_rate": 5.535048181535593e-06,
      "loss": 0.0281,
      "step": 11491
    },
    {
      "epoch": 0.8930680758470625,
      "grad_norm": 0.23491185903549194,
      "learning_rate": 5.534659620764689e-06,
      "loss": 0.0804,
      "step": 11492
    },
    {
      "epoch": 0.8931457880012434,
      "grad_norm": 0.26116943359375,
      "learning_rate": 5.534271059993783e-06,
      "loss": 0.2458,
      "step": 11493
    },
    {
      "epoch": 0.8932235001554243,
      "grad_norm": 0.243343785405159,
      "learning_rate": 5.533882499222879e-06,
      "loss": 0.1895,
      "step": 11494
    },
    {
      "epoch": 0.8933012123096052,
      "grad_norm": 0.32654839754104614,
      "learning_rate": 5.5334939384519745e-06,
      "loss": 0.1459,
      "step": 11495
    },
    {
      "epoch": 0.8933789244637861,
      "grad_norm": 0.4278700351715088,
      "learning_rate": 5.5331053776810695e-06,
      "loss": 0.0585,
      "step": 11496
    },
    {
      "epoch": 0.893456636617967,
      "grad_norm": 1.2620819807052612,
      "learning_rate": 5.532716816910165e-06,
      "loss": 0.3912,
      "step": 11497
    },
    {
      "epoch": 0.893534348772148,
      "grad_norm": 0.1879817545413971,
      "learning_rate": 5.532328256139261e-06,
      "loss": 0.016,
      "step": 11498
    },
    {
      "epoch": 0.8936120609263288,
      "grad_norm": 1.0159498453140259,
      "learning_rate": 5.531939695368356e-06,
      "loss": 0.5484,
      "step": 11499
    },
    {
      "epoch": 0.8936897730805098,
      "grad_norm": 1.0347446203231812,
      "learning_rate": 5.531551134597452e-06,
      "loss": 0.2185,
      "step": 11500
    },
    {
      "epoch": 0.8937674852346907,
      "grad_norm": 0.40012434124946594,
      "learning_rate": 5.531162573826548e-06,
      "loss": 0.1585,
      "step": 11501
    },
    {
      "epoch": 0.8938451973888716,
      "grad_norm": 0.13302668929100037,
      "learning_rate": 5.530774013055642e-06,
      "loss": 0.0276,
      "step": 11502
    },
    {
      "epoch": 0.8939229095430525,
      "grad_norm": 0.40594422817230225,
      "learning_rate": 5.5303854522847375e-06,
      "loss": 0.2313,
      "step": 11503
    },
    {
      "epoch": 0.8940006216972335,
      "grad_norm": 0.623766303062439,
      "learning_rate": 5.529996891513833e-06,
      "loss": 0.2016,
      "step": 11504
    },
    {
      "epoch": 0.8940783338514143,
      "grad_norm": 0.17710427939891815,
      "learning_rate": 5.529608330742928e-06,
      "loss": 0.0995,
      "step": 11505
    },
    {
      "epoch": 0.8941560460055953,
      "grad_norm": 0.5003467202186584,
      "learning_rate": 5.529219769972024e-06,
      "loss": 0.3447,
      "step": 11506
    },
    {
      "epoch": 0.8942337581597762,
      "grad_norm": 0.18668654561042786,
      "learning_rate": 5.52883120920112e-06,
      "loss": 0.016,
      "step": 11507
    },
    {
      "epoch": 0.8943114703139571,
      "grad_norm": 0.19885587692260742,
      "learning_rate": 5.528442648430215e-06,
      "loss": 0.1397,
      "step": 11508
    },
    {
      "epoch": 0.894389182468138,
      "grad_norm": 0.21279309689998627,
      "learning_rate": 5.528054087659311e-06,
      "loss": 0.0222,
      "step": 11509
    },
    {
      "epoch": 0.8944668946223189,
      "grad_norm": 0.4531268775463104,
      "learning_rate": 5.527665526888406e-06,
      "loss": 0.3053,
      "step": 11510
    },
    {
      "epoch": 0.8945446067764998,
      "grad_norm": 0.29700514674186707,
      "learning_rate": 5.5272769661175005e-06,
      "loss": 0.1963,
      "step": 11511
    },
    {
      "epoch": 0.8946223189306808,
      "grad_norm": 0.25545865297317505,
      "learning_rate": 5.526888405346596e-06,
      "loss": 0.0906,
      "step": 11512
    },
    {
      "epoch": 0.8947000310848616,
      "grad_norm": 0.6097311973571777,
      "learning_rate": 5.526499844575692e-06,
      "loss": 0.4062,
      "step": 11513
    },
    {
      "epoch": 0.8947777432390426,
      "grad_norm": 0.11502864211797714,
      "learning_rate": 5.526111283804787e-06,
      "loss": 0.0301,
      "step": 11514
    },
    {
      "epoch": 0.8948554553932235,
      "grad_norm": 0.12663038074970245,
      "learning_rate": 5.525722723033883e-06,
      "loss": 0.0567,
      "step": 11515
    },
    {
      "epoch": 0.8949331675474044,
      "grad_norm": 0.8779774904251099,
      "learning_rate": 5.525334162262979e-06,
      "loss": 0.3398,
      "step": 11516
    },
    {
      "epoch": 0.8950108797015853,
      "grad_norm": 0.6472652554512024,
      "learning_rate": 5.524945601492074e-06,
      "loss": 0.4765,
      "step": 11517
    },
    {
      "epoch": 0.8950885918557663,
      "grad_norm": 1.0459649562835693,
      "learning_rate": 5.524557040721169e-06,
      "loss": 0.3171,
      "step": 11518
    },
    {
      "epoch": 0.8951663040099471,
      "grad_norm": 0.28606095910072327,
      "learning_rate": 5.524168479950265e-06,
      "loss": 0.1765,
      "step": 11519
    },
    {
      "epoch": 0.8952440161641281,
      "grad_norm": 0.28909197449684143,
      "learning_rate": 5.523779919179361e-06,
      "loss": 0.0574,
      "step": 11520
    },
    {
      "epoch": 0.895321728318309,
      "grad_norm": 0.29469728469848633,
      "learning_rate": 5.523391358408455e-06,
      "loss": 0.1018,
      "step": 11521
    },
    {
      "epoch": 0.8953994404724899,
      "grad_norm": 0.5354525446891785,
      "learning_rate": 5.523002797637551e-06,
      "loss": 0.4652,
      "step": 11522
    },
    {
      "epoch": 0.8954771526266708,
      "grad_norm": 0.5047106742858887,
      "learning_rate": 5.522614236866647e-06,
      "loss": 0.091,
      "step": 11523
    },
    {
      "epoch": 0.8955548647808518,
      "grad_norm": 0.29645243287086487,
      "learning_rate": 5.522225676095742e-06,
      "loss": 0.1049,
      "step": 11524
    },
    {
      "epoch": 0.8956325769350326,
      "grad_norm": 0.4919021725654602,
      "learning_rate": 5.521837115324837e-06,
      "loss": 0.2888,
      "step": 11525
    },
    {
      "epoch": 0.8957102890892136,
      "grad_norm": 0.38291940093040466,
      "learning_rate": 5.521448554553933e-06,
      "loss": 0.1742,
      "step": 11526
    },
    {
      "epoch": 0.8957880012433944,
      "grad_norm": 0.22993281483650208,
      "learning_rate": 5.521059993783028e-06,
      "loss": 0.0841,
      "step": 11527
    },
    {
      "epoch": 0.8958657133975754,
      "grad_norm": 0.5646952986717224,
      "learning_rate": 5.520671433012124e-06,
      "loss": 0.2182,
      "step": 11528
    },
    {
      "epoch": 0.8959434255517563,
      "grad_norm": 0.2592003643512726,
      "learning_rate": 5.52028287224122e-06,
      "loss": 0.1034,
      "step": 11529
    },
    {
      "epoch": 0.8960211377059372,
      "grad_norm": 0.23163501918315887,
      "learning_rate": 5.519894311470314e-06,
      "loss": 0.0897,
      "step": 11530
    },
    {
      "epoch": 0.8960988498601181,
      "grad_norm": 0.29160454869270325,
      "learning_rate": 5.51950575069941e-06,
      "loss": 0.1511,
      "step": 11531
    },
    {
      "epoch": 0.8961765620142991,
      "grad_norm": 0.3223966658115387,
      "learning_rate": 5.5191171899285055e-06,
      "loss": 0.0986,
      "step": 11532
    },
    {
      "epoch": 0.8962542741684799,
      "grad_norm": 0.8506273627281189,
      "learning_rate": 5.5187286291576e-06,
      "loss": 0.1932,
      "step": 11533
    },
    {
      "epoch": 0.8963319863226609,
      "grad_norm": 0.45236513018608093,
      "learning_rate": 5.518340068386696e-06,
      "loss": 0.1674,
      "step": 11534
    },
    {
      "epoch": 0.8964096984768418,
      "grad_norm": 0.086703822016716,
      "learning_rate": 5.517951507615792e-06,
      "loss": 0.0113,
      "step": 11535
    },
    {
      "epoch": 0.8964874106310227,
      "grad_norm": 0.7742214798927307,
      "learning_rate": 5.517562946844887e-06,
      "loss": 0.3743,
      "step": 11536
    },
    {
      "epoch": 0.8965651227852036,
      "grad_norm": 0.23801280558109283,
      "learning_rate": 5.517174386073983e-06,
      "loss": 0.1537,
      "step": 11537
    },
    {
      "epoch": 0.8966428349393846,
      "grad_norm": 0.6079792380332947,
      "learning_rate": 5.5167858253030785e-06,
      "loss": 0.4078,
      "step": 11538
    },
    {
      "epoch": 0.8967205470935654,
      "grad_norm": 0.15104663372039795,
      "learning_rate": 5.516397264532173e-06,
      "loss": 0.0237,
      "step": 11539
    },
    {
      "epoch": 0.8967982592477464,
      "grad_norm": 0.44578003883361816,
      "learning_rate": 5.5160087037612684e-06,
      "loss": 0.2124,
      "step": 11540
    },
    {
      "epoch": 0.8968759714019272,
      "grad_norm": 0.40015897154808044,
      "learning_rate": 5.515620142990364e-06,
      "loss": 0.1697,
      "step": 11541
    },
    {
      "epoch": 0.8969536835561082,
      "grad_norm": 0.3049332797527313,
      "learning_rate": 5.515231582219459e-06,
      "loss": 0.0907,
      "step": 11542
    },
    {
      "epoch": 0.8970313957102891,
      "grad_norm": 0.2362365424633026,
      "learning_rate": 5.514843021448555e-06,
      "loss": 0.0646,
      "step": 11543
    },
    {
      "epoch": 0.89710910786447,
      "grad_norm": 0.28884151577949524,
      "learning_rate": 5.514454460677651e-06,
      "loss": 0.144,
      "step": 11544
    },
    {
      "epoch": 0.8971868200186509,
      "grad_norm": 0.3036906123161316,
      "learning_rate": 5.514065899906746e-06,
      "loss": 0.0979,
      "step": 11545
    },
    {
      "epoch": 0.8972645321728319,
      "grad_norm": 0.49619871377944946,
      "learning_rate": 5.5136773391358415e-06,
      "loss": 0.2265,
      "step": 11546
    },
    {
      "epoch": 0.8973422443270127,
      "grad_norm": 0.1526087373495102,
      "learning_rate": 5.513288778364937e-06,
      "loss": 0.0416,
      "step": 11547
    },
    {
      "epoch": 0.8974199564811937,
      "grad_norm": 0.33861061930656433,
      "learning_rate": 5.512900217594033e-06,
      "loss": 0.0883,
      "step": 11548
    },
    {
      "epoch": 0.8974976686353746,
      "grad_norm": 0.10591491311788559,
      "learning_rate": 5.512511656823127e-06,
      "loss": 0.018,
      "step": 11549
    },
    {
      "epoch": 0.8975753807895555,
      "grad_norm": 0.29428818821907043,
      "learning_rate": 5.512123096052223e-06,
      "loss": 0.167,
      "step": 11550
    },
    {
      "epoch": 0.8976530929437364,
      "grad_norm": 0.3684594929218292,
      "learning_rate": 5.511734535281319e-06,
      "loss": 0.0786,
      "step": 11551
    },
    {
      "epoch": 0.8977308050979174,
      "grad_norm": 0.20703503489494324,
      "learning_rate": 5.511345974510414e-06,
      "loss": 0.0701,
      "step": 11552
    },
    {
      "epoch": 0.8978085172520982,
      "grad_norm": 0.31823694705963135,
      "learning_rate": 5.5109574137395096e-06,
      "loss": 0.1146,
      "step": 11553
    },
    {
      "epoch": 0.8978862294062792,
      "grad_norm": 0.33806782960891724,
      "learning_rate": 5.510568852968605e-06,
      "loss": 0.1332,
      "step": 11554
    },
    {
      "epoch": 0.8979639415604601,
      "grad_norm": 0.24247843027114868,
      "learning_rate": 5.5101802921977e-06,
      "loss": 0.0811,
      "step": 11555
    },
    {
      "epoch": 0.898041653714641,
      "grad_norm": 0.5267650485038757,
      "learning_rate": 5.509791731426795e-06,
      "loss": 0.2203,
      "step": 11556
    },
    {
      "epoch": 0.8981193658688219,
      "grad_norm": 0.5322645306587219,
      "learning_rate": 5.509403170655891e-06,
      "loss": 0.6728,
      "step": 11557
    },
    {
      "epoch": 0.8981970780230027,
      "grad_norm": 0.1059143915772438,
      "learning_rate": 5.509014609884986e-06,
      "loss": 0.0357,
      "step": 11558
    },
    {
      "epoch": 0.8982747901771837,
      "grad_norm": 0.20580509305000305,
      "learning_rate": 5.508626049114082e-06,
      "loss": 0.0662,
      "step": 11559
    },
    {
      "epoch": 0.8983525023313647,
      "grad_norm": 0.49674877524375916,
      "learning_rate": 5.508237488343178e-06,
      "loss": 0.1662,
      "step": 11560
    },
    {
      "epoch": 0.8984302144855455,
      "grad_norm": 0.33469802141189575,
      "learning_rate": 5.5078489275722726e-06,
      "loss": 0.1703,
      "step": 11561
    },
    {
      "epoch": 0.8985079266397265,
      "grad_norm": 0.1939261108636856,
      "learning_rate": 5.507460366801368e-06,
      "loss": 0.0726,
      "step": 11562
    },
    {
      "epoch": 0.8985856387939074,
      "grad_norm": 0.8204489946365356,
      "learning_rate": 5.507071806030464e-06,
      "loss": 0.7337,
      "step": 11563
    },
    {
      "epoch": 0.8986633509480882,
      "grad_norm": 0.6744778752326965,
      "learning_rate": 5.506683245259558e-06,
      "loss": 0.4107,
      "step": 11564
    },
    {
      "epoch": 0.8987410631022692,
      "grad_norm": 0.578575611114502,
      "learning_rate": 5.506294684488654e-06,
      "loss": 0.3971,
      "step": 11565
    },
    {
      "epoch": 0.8988187752564502,
      "grad_norm": 0.585875928401947,
      "learning_rate": 5.50590612371775e-06,
      "loss": 0.1806,
      "step": 11566
    },
    {
      "epoch": 0.898896487410631,
      "grad_norm": 0.5073556303977966,
      "learning_rate": 5.505517562946845e-06,
      "loss": 0.3258,
      "step": 11567
    },
    {
      "epoch": 0.898974199564812,
      "grad_norm": 0.5702890753746033,
      "learning_rate": 5.505129002175941e-06,
      "loss": 0.1929,
      "step": 11568
    },
    {
      "epoch": 0.8990519117189929,
      "grad_norm": 0.5003418326377869,
      "learning_rate": 5.504740441405036e-06,
      "loss": 0.3934,
      "step": 11569
    },
    {
      "epoch": 0.8991296238731737,
      "grad_norm": 0.18023845553398132,
      "learning_rate": 5.504351880634131e-06,
      "loss": 0.2702,
      "step": 11570
    },
    {
      "epoch": 0.8992073360273547,
      "grad_norm": 0.3183797597885132,
      "learning_rate": 5.503963319863227e-06,
      "loss": 0.2511,
      "step": 11571
    },
    {
      "epoch": 0.8992850481815355,
      "grad_norm": 0.3032788336277008,
      "learning_rate": 5.503574759092323e-06,
      "loss": 0.1242,
      "step": 11572
    },
    {
      "epoch": 0.8993627603357165,
      "grad_norm": 0.7432640194892883,
      "learning_rate": 5.503186198321417e-06,
      "loss": 0.5387,
      "step": 11573
    },
    {
      "epoch": 0.8994404724898974,
      "grad_norm": 0.45790284872055054,
      "learning_rate": 5.502797637550513e-06,
      "loss": 0.3302,
      "step": 11574
    },
    {
      "epoch": 0.8995181846440783,
      "grad_norm": 0.8661377429962158,
      "learning_rate": 5.502409076779609e-06,
      "loss": 0.3771,
      "step": 11575
    },
    {
      "epoch": 0.8995958967982592,
      "grad_norm": 0.3122779130935669,
      "learning_rate": 5.502020516008704e-06,
      "loss": 0.0797,
      "step": 11576
    },
    {
      "epoch": 0.8996736089524402,
      "grad_norm": 0.6651200652122498,
      "learning_rate": 5.501631955237799e-06,
      "loss": 0.8376,
      "step": 11577
    },
    {
      "epoch": 0.899751321106621,
      "grad_norm": 0.11115843057632446,
      "learning_rate": 5.501243394466895e-06,
      "loss": 0.0172,
      "step": 11578
    },
    {
      "epoch": 0.899829033260802,
      "grad_norm": 0.18191201984882355,
      "learning_rate": 5.500854833695991e-06,
      "loss": 0.0561,
      "step": 11579
    },
    {
      "epoch": 0.899906745414983,
      "grad_norm": 0.3764137327671051,
      "learning_rate": 5.500466272925086e-06,
      "loss": 0.1851,
      "step": 11580
    },
    {
      "epoch": 0.8999844575691638,
      "grad_norm": 0.14522390067577362,
      "learning_rate": 5.500077712154182e-06,
      "loss": 0.0591,
      "step": 11581
    },
    {
      "epoch": 0.9000621697233447,
      "grad_norm": 0.523554801940918,
      "learning_rate": 5.4996891513832775e-06,
      "loss": 0.1805,
      "step": 11582
    },
    {
      "epoch": 0.9001398818775257,
      "grad_norm": 0.5439876317977905,
      "learning_rate": 5.499300590612372e-06,
      "loss": 0.1764,
      "step": 11583
    },
    {
      "epoch": 0.9002175940317065,
      "grad_norm": 0.3429933786392212,
      "learning_rate": 5.498912029841467e-06,
      "loss": 0.0496,
      "step": 11584
    },
    {
      "epoch": 0.9002953061858875,
      "grad_norm": 0.24629449844360352,
      "learning_rate": 5.498523469070563e-06,
      "loss": 0.1082,
      "step": 11585
    },
    {
      "epoch": 0.9003730183400683,
      "grad_norm": 0.21492476761341095,
      "learning_rate": 5.498134908299658e-06,
      "loss": 0.0738,
      "step": 11586
    },
    {
      "epoch": 0.9004507304942493,
      "grad_norm": 0.5404176115989685,
      "learning_rate": 5.497746347528754e-06,
      "loss": 0.2869,
      "step": 11587
    },
    {
      "epoch": 0.9005284426484302,
      "grad_norm": 0.18043766915798187,
      "learning_rate": 5.49735778675785e-06,
      "loss": 0.0504,
      "step": 11588
    },
    {
      "epoch": 0.9006061548026111,
      "grad_norm": 0.6142482757568359,
      "learning_rate": 5.496969225986945e-06,
      "loss": 0.331,
      "step": 11589
    },
    {
      "epoch": 0.900683866956792,
      "grad_norm": 0.28090301156044006,
      "learning_rate": 5.4965806652160405e-06,
      "loss": 0.0783,
      "step": 11590
    },
    {
      "epoch": 0.900761579110973,
      "grad_norm": 0.7241001129150391,
      "learning_rate": 5.496192104445136e-06,
      "loss": 0.5885,
      "step": 11591
    },
    {
      "epoch": 0.9008392912651538,
      "grad_norm": 0.22354164719581604,
      "learning_rate": 5.49580354367423e-06,
      "loss": 0.0754,
      "step": 11592
    },
    {
      "epoch": 0.9009170034193348,
      "grad_norm": 0.3136504590511322,
      "learning_rate": 5.495414982903326e-06,
      "loss": 0.0354,
      "step": 11593
    },
    {
      "epoch": 0.9009947155735157,
      "grad_norm": 0.6772823929786682,
      "learning_rate": 5.495026422132422e-06,
      "loss": 0.3631,
      "step": 11594
    },
    {
      "epoch": 0.9010724277276966,
      "grad_norm": 0.6333391070365906,
      "learning_rate": 5.494637861361517e-06,
      "loss": 0.1708,
      "step": 11595
    },
    {
      "epoch": 0.9011501398818775,
      "grad_norm": 0.43762245774269104,
      "learning_rate": 5.494249300590613e-06,
      "loss": 0.1897,
      "step": 11596
    },
    {
      "epoch": 0.9012278520360585,
      "grad_norm": 0.1615983545780182,
      "learning_rate": 5.4938607398197085e-06,
      "loss": 0.0556,
      "step": 11597
    },
    {
      "epoch": 0.9013055641902393,
      "grad_norm": 0.4361359179019928,
      "learning_rate": 5.4934721790488035e-06,
      "loss": 0.3823,
      "step": 11598
    },
    {
      "epoch": 0.9013832763444203,
      "grad_norm": 0.441206693649292,
      "learning_rate": 5.493083618277899e-06,
      "loss": 0.151,
      "step": 11599
    },
    {
      "epoch": 0.9014609884986012,
      "grad_norm": 0.14923901855945587,
      "learning_rate": 5.492695057506995e-06,
      "loss": 0.0439,
      "step": 11600
    },
    {
      "epoch": 0.9015387006527821,
      "grad_norm": 0.33544209599494934,
      "learning_rate": 5.492306496736089e-06,
      "loss": 0.1356,
      "step": 11601
    },
    {
      "epoch": 0.901616412806963,
      "grad_norm": 0.2558463513851166,
      "learning_rate": 5.491917935965185e-06,
      "loss": 0.165,
      "step": 11602
    },
    {
      "epoch": 0.9016941249611439,
      "grad_norm": 1.7162041664123535,
      "learning_rate": 5.491529375194281e-06,
      "loss": 0.4982,
      "step": 11603
    },
    {
      "epoch": 0.9017718371153248,
      "grad_norm": 0.7877441048622131,
      "learning_rate": 5.491140814423376e-06,
      "loss": 0.2514,
      "step": 11604
    },
    {
      "epoch": 0.9018495492695058,
      "grad_norm": 0.11811093240976334,
      "learning_rate": 5.4907522536524715e-06,
      "loss": 0.0527,
      "step": 11605
    },
    {
      "epoch": 0.9019272614236866,
      "grad_norm": 0.1797441691160202,
      "learning_rate": 5.490363692881567e-06,
      "loss": 0.0404,
      "step": 11606
    },
    {
      "epoch": 0.9020049735778676,
      "grad_norm": 0.10323818027973175,
      "learning_rate": 5.489975132110662e-06,
      "loss": 0.0511,
      "step": 11607
    },
    {
      "epoch": 0.9020826857320485,
      "grad_norm": 1.015262484550476,
      "learning_rate": 5.489586571339758e-06,
      "loss": 0.1691,
      "step": 11608
    },
    {
      "epoch": 0.9021603978862294,
      "grad_norm": 0.3050602078437805,
      "learning_rate": 5.489198010568854e-06,
      "loss": 0.0653,
      "step": 11609
    },
    {
      "epoch": 0.9022381100404103,
      "grad_norm": 0.5376902222633362,
      "learning_rate": 5.48880944979795e-06,
      "loss": 0.3249,
      "step": 11610
    },
    {
      "epoch": 0.9023158221945913,
      "grad_norm": 0.2970500886440277,
      "learning_rate": 5.488420889027044e-06,
      "loss": 0.0976,
      "step": 11611
    },
    {
      "epoch": 0.9023935343487721,
      "grad_norm": 0.6404944658279419,
      "learning_rate": 5.4880323282561396e-06,
      "loss": 0.3123,
      "step": 11612
    },
    {
      "epoch": 0.9024712465029531,
      "grad_norm": 0.36652451753616333,
      "learning_rate": 5.487643767485235e-06,
      "loss": 0.5389,
      "step": 11613
    },
    {
      "epoch": 0.902548958657134,
      "grad_norm": 0.157515749335289,
      "learning_rate": 5.48725520671433e-06,
      "loss": 0.094,
      "step": 11614
    },
    {
      "epoch": 0.9026266708113149,
      "grad_norm": 0.2695760130882263,
      "learning_rate": 5.486866645943426e-06,
      "loss": 0.1396,
      "step": 11615
    },
    {
      "epoch": 0.9027043829654958,
      "grad_norm": 0.6438847184181213,
      "learning_rate": 5.486478085172522e-06,
      "loss": 0.5605,
      "step": 11616
    },
    {
      "epoch": 0.9027820951196767,
      "grad_norm": 0.21691814064979553,
      "learning_rate": 5.486089524401617e-06,
      "loss": 0.0664,
      "step": 11617
    },
    {
      "epoch": 0.9028598072738576,
      "grad_norm": 0.1419527679681778,
      "learning_rate": 5.485700963630713e-06,
      "loss": 0.036,
      "step": 11618
    },
    {
      "epoch": 0.9029375194280386,
      "grad_norm": 0.1086101233959198,
      "learning_rate": 5.4853124028598084e-06,
      "loss": 0.007,
      "step": 11619
    },
    {
      "epoch": 0.9030152315822194,
      "grad_norm": 0.6270655989646912,
      "learning_rate": 5.4849238420889025e-06,
      "loss": 0.2937,
      "step": 11620
    },
    {
      "epoch": 0.9030929437364004,
      "grad_norm": 0.11440972238779068,
      "learning_rate": 5.484535281317998e-06,
      "loss": 0.0483,
      "step": 11621
    },
    {
      "epoch": 0.9031706558905813,
      "grad_norm": 0.42767050862312317,
      "learning_rate": 5.484146720547094e-06,
      "loss": 0.0803,
      "step": 11622
    },
    {
      "epoch": 0.9032483680447622,
      "grad_norm": 0.4178414046764374,
      "learning_rate": 5.483758159776189e-06,
      "loss": 0.0998,
      "step": 11623
    },
    {
      "epoch": 0.9033260801989431,
      "grad_norm": 0.2538745701313019,
      "learning_rate": 5.483369599005285e-06,
      "loss": 0.0946,
      "step": 11624
    },
    {
      "epoch": 0.9034037923531241,
      "grad_norm": 0.32494115829467773,
      "learning_rate": 5.482981038234381e-06,
      "loss": 0.0409,
      "step": 11625
    },
    {
      "epoch": 0.9034815045073049,
      "grad_norm": 0.6510791182518005,
      "learning_rate": 5.482592477463476e-06,
      "loss": 0.1949,
      "step": 11626
    },
    {
      "epoch": 0.9035592166614859,
      "grad_norm": 1.1649657487869263,
      "learning_rate": 5.4822039166925714e-06,
      "loss": 0.2169,
      "step": 11627
    },
    {
      "epoch": 0.9036369288156668,
      "grad_norm": 0.14422154426574707,
      "learning_rate": 5.481815355921667e-06,
      "loss": 0.0759,
      "step": 11628
    },
    {
      "epoch": 0.9037146409698477,
      "grad_norm": 0.5307704210281372,
      "learning_rate": 5.481426795150761e-06,
      "loss": 0.3139,
      "step": 11629
    },
    {
      "epoch": 0.9037923531240286,
      "grad_norm": 0.14320199191570282,
      "learning_rate": 5.481038234379857e-06,
      "loss": 0.0789,
      "step": 11630
    },
    {
      "epoch": 0.9038700652782096,
      "grad_norm": 1.0004856586456299,
      "learning_rate": 5.480649673608953e-06,
      "loss": 0.3921,
      "step": 11631
    },
    {
      "epoch": 0.9039477774323904,
      "grad_norm": 0.8768545389175415,
      "learning_rate": 5.480261112838048e-06,
      "loss": 0.3174,
      "step": 11632
    },
    {
      "epoch": 0.9040254895865714,
      "grad_norm": 0.13972792029380798,
      "learning_rate": 5.479872552067144e-06,
      "loss": 0.0415,
      "step": 11633
    },
    {
      "epoch": 0.9041032017407522,
      "grad_norm": 0.2045264095067978,
      "learning_rate": 5.4794839912962395e-06,
      "loss": 0.1448,
      "step": 11634
    },
    {
      "epoch": 0.9041809138949332,
      "grad_norm": 0.4080909788608551,
      "learning_rate": 5.479095430525334e-06,
      "loss": 0.0954,
      "step": 11635
    },
    {
      "epoch": 0.9042586260491141,
      "grad_norm": 0.21481738984584808,
      "learning_rate": 5.47870686975443e-06,
      "loss": 0.1107,
      "step": 11636
    },
    {
      "epoch": 0.904336338203295,
      "grad_norm": 1.3255583047866821,
      "learning_rate": 5.478318308983526e-06,
      "loss": 0.2591,
      "step": 11637
    },
    {
      "epoch": 0.9044140503574759,
      "grad_norm": 0.451824814081192,
      "learning_rate": 5.47792974821262e-06,
      "loss": 0.2828,
      "step": 11638
    },
    {
      "epoch": 0.9044917625116569,
      "grad_norm": 0.4393875300884247,
      "learning_rate": 5.477541187441716e-06,
      "loss": 0.0713,
      "step": 11639
    },
    {
      "epoch": 0.9045694746658377,
      "grad_norm": 0.2580570876598358,
      "learning_rate": 5.477152626670812e-06,
      "loss": 0.0596,
      "step": 11640
    },
    {
      "epoch": 0.9046471868200187,
      "grad_norm": 0.28241145610809326,
      "learning_rate": 5.4767640658999075e-06,
      "loss": 0.0298,
      "step": 11641
    },
    {
      "epoch": 0.9047248989741996,
      "grad_norm": 0.32187655568122864,
      "learning_rate": 5.4763755051290024e-06,
      "loss": 0.0763,
      "step": 11642
    },
    {
      "epoch": 0.9048026111283805,
      "grad_norm": 0.2586660385131836,
      "learning_rate": 5.475986944358098e-06,
      "loss": 0.0792,
      "step": 11643
    },
    {
      "epoch": 0.9048803232825614,
      "grad_norm": 0.2463555783033371,
      "learning_rate": 5.475598383587194e-06,
      "loss": 0.0348,
      "step": 11644
    },
    {
      "epoch": 0.9049580354367424,
      "grad_norm": 0.45362377166748047,
      "learning_rate": 5.475209822816289e-06,
      "loss": 0.2121,
      "step": 11645
    },
    {
      "epoch": 0.9050357475909232,
      "grad_norm": 0.5567226409912109,
      "learning_rate": 5.474821262045385e-06,
      "loss": 0.2056,
      "step": 11646
    },
    {
      "epoch": 0.9051134597451042,
      "grad_norm": 0.5481433868408203,
      "learning_rate": 5.474432701274481e-06,
      "loss": 0.1705,
      "step": 11647
    },
    {
      "epoch": 0.905191171899285,
      "grad_norm": 0.19222000241279602,
      "learning_rate": 5.474044140503575e-06,
      "loss": 0.0706,
      "step": 11648
    },
    {
      "epoch": 0.905268884053466,
      "grad_norm": 0.8751773238182068,
      "learning_rate": 5.4736555797326705e-06,
      "loss": 0.4149,
      "step": 11649
    },
    {
      "epoch": 0.9053465962076469,
      "grad_norm": 0.590386688709259,
      "learning_rate": 5.473267018961766e-06,
      "loss": 0.2147,
      "step": 11650
    },
    {
      "epoch": 0.9054243083618277,
      "grad_norm": 0.3235158622264862,
      "learning_rate": 5.472878458190861e-06,
      "loss": 0.1221,
      "step": 11651
    },
    {
      "epoch": 0.9055020205160087,
      "grad_norm": 0.530003011226654,
      "learning_rate": 5.472489897419957e-06,
      "loss": 0.4481,
      "step": 11652
    },
    {
      "epoch": 0.9055797326701897,
      "grad_norm": 0.4982161819934845,
      "learning_rate": 5.472101336649053e-06,
      "loss": 0.3039,
      "step": 11653
    },
    {
      "epoch": 0.9056574448243705,
      "grad_norm": 0.7177813053131104,
      "learning_rate": 5.471712775878148e-06,
      "loss": 0.0751,
      "step": 11654
    },
    {
      "epoch": 0.9057351569785514,
      "grad_norm": 0.3078576326370239,
      "learning_rate": 5.4713242151072436e-06,
      "loss": 0.1244,
      "step": 11655
    },
    {
      "epoch": 0.9058128691327324,
      "grad_norm": 0.24142703413963318,
      "learning_rate": 5.470935654336339e-06,
      "loss": 0.061,
      "step": 11656
    },
    {
      "epoch": 0.9058905812869132,
      "grad_norm": 0.16112685203552246,
      "learning_rate": 5.4705470935654335e-06,
      "loss": 0.0504,
      "step": 11657
    },
    {
      "epoch": 0.9059682934410942,
      "grad_norm": 0.28189536929130554,
      "learning_rate": 5.470158532794529e-06,
      "loss": 0.157,
      "step": 11658
    },
    {
      "epoch": 0.9060460055952752,
      "grad_norm": 0.7639052271842957,
      "learning_rate": 5.469769972023625e-06,
      "loss": 0.332,
      "step": 11659
    },
    {
      "epoch": 0.906123717749456,
      "grad_norm": 0.49699750542640686,
      "learning_rate": 5.46938141125272e-06,
      "loss": 0.2317,
      "step": 11660
    },
    {
      "epoch": 0.906201429903637,
      "grad_norm": 0.4196745455265045,
      "learning_rate": 5.468992850481816e-06,
      "loss": 0.1421,
      "step": 11661
    },
    {
      "epoch": 0.9062791420578178,
      "grad_norm": 0.25180143117904663,
      "learning_rate": 5.468604289710912e-06,
      "loss": 0.0711,
      "step": 11662
    },
    {
      "epoch": 0.9063568542119987,
      "grad_norm": 0.5299776792526245,
      "learning_rate": 5.4682157289400066e-06,
      "loss": 0.4136,
      "step": 11663
    },
    {
      "epoch": 0.9064345663661797,
      "grad_norm": 0.32290270924568176,
      "learning_rate": 5.467827168169102e-06,
      "loss": 0.1546,
      "step": 11664
    },
    {
      "epoch": 0.9065122785203605,
      "grad_norm": 0.21406804025173187,
      "learning_rate": 5.467438607398198e-06,
      "loss": 0.0852,
      "step": 11665
    },
    {
      "epoch": 0.9065899906745415,
      "grad_norm": 0.15479108691215515,
      "learning_rate": 5.467050046627292e-06,
      "loss": 0.0429,
      "step": 11666
    },
    {
      "epoch": 0.9066677028287224,
      "grad_norm": 0.13272038102149963,
      "learning_rate": 5.466661485856388e-06,
      "loss": 0.0349,
      "step": 11667
    },
    {
      "epoch": 0.9067454149829033,
      "grad_norm": 0.3961144685745239,
      "learning_rate": 5.466272925085484e-06,
      "loss": 0.1341,
      "step": 11668
    },
    {
      "epoch": 0.9068231271370842,
      "grad_norm": 0.5941701531410217,
      "learning_rate": 5.465884364314579e-06,
      "loss": 0.24,
      "step": 11669
    },
    {
      "epoch": 0.9069008392912652,
      "grad_norm": 0.1542605757713318,
      "learning_rate": 5.465495803543675e-06,
      "loss": 0.0833,
      "step": 11670
    },
    {
      "epoch": 0.906978551445446,
      "grad_norm": 1.1245051622390747,
      "learning_rate": 5.46510724277277e-06,
      "loss": 0.7067,
      "step": 11671
    },
    {
      "epoch": 0.907056263599627,
      "grad_norm": 0.18136918544769287,
      "learning_rate": 5.464718682001866e-06,
      "loss": 0.0437,
      "step": 11672
    },
    {
      "epoch": 0.9071339757538079,
      "grad_norm": 0.18454226851463318,
      "learning_rate": 5.464330121230961e-06,
      "loss": 0.0387,
      "step": 11673
    },
    {
      "epoch": 0.9072116879079888,
      "grad_norm": 0.2326587736606598,
      "learning_rate": 5.463941560460057e-06,
      "loss": 0.1478,
      "step": 11674
    },
    {
      "epoch": 0.9072894000621697,
      "grad_norm": 0.1834779977798462,
      "learning_rate": 5.463552999689153e-06,
      "loss": 0.043,
      "step": 11675
    },
    {
      "epoch": 0.9073671122163507,
      "grad_norm": 0.2932558059692383,
      "learning_rate": 5.463164438918247e-06,
      "loss": 0.1026,
      "step": 11676
    },
    {
      "epoch": 0.9074448243705315,
      "grad_norm": 0.37779825925827026,
      "learning_rate": 5.462775878147343e-06,
      "loss": 0.3072,
      "step": 11677
    },
    {
      "epoch": 0.9075225365247125,
      "grad_norm": 0.17149803042411804,
      "learning_rate": 5.4623873173764384e-06,
      "loss": 0.037,
      "step": 11678
    },
    {
      "epoch": 0.9076002486788933,
      "grad_norm": 0.4292527735233307,
      "learning_rate": 5.461998756605533e-06,
      "loss": 0.4922,
      "step": 11679
    },
    {
      "epoch": 0.9076779608330743,
      "grad_norm": 0.32854223251342773,
      "learning_rate": 5.461610195834629e-06,
      "loss": 0.1945,
      "step": 11680
    },
    {
      "epoch": 0.9077556729872552,
      "grad_norm": 0.3151530921459198,
      "learning_rate": 5.461221635063725e-06,
      "loss": 0.0383,
      "step": 11681
    },
    {
      "epoch": 0.9078333851414361,
      "grad_norm": 0.47131842374801636,
      "learning_rate": 5.46083307429282e-06,
      "loss": 0.0877,
      "step": 11682
    },
    {
      "epoch": 0.907911097295617,
      "grad_norm": 0.861091136932373,
      "learning_rate": 5.460444513521915e-06,
      "loss": 0.411,
      "step": 11683
    },
    {
      "epoch": 0.907988809449798,
      "grad_norm": 0.2887376844882965,
      "learning_rate": 5.460055952751011e-06,
      "loss": 0.1492,
      "step": 11684
    },
    {
      "epoch": 0.9080665216039788,
      "grad_norm": 0.229648157954216,
      "learning_rate": 5.459667391980106e-06,
      "loss": 0.0737,
      "step": 11685
    },
    {
      "epoch": 0.9081442337581598,
      "grad_norm": 0.22412697970867157,
      "learning_rate": 5.459278831209201e-06,
      "loss": 0.0645,
      "step": 11686
    },
    {
      "epoch": 0.9082219459123407,
      "grad_norm": 0.6214447021484375,
      "learning_rate": 5.458890270438297e-06,
      "loss": 0.6667,
      "step": 11687
    },
    {
      "epoch": 0.9082996580665216,
      "grad_norm": 0.268542617559433,
      "learning_rate": 5.458501709667392e-06,
      "loss": 0.1413,
      "step": 11688
    },
    {
      "epoch": 0.9083773702207025,
      "grad_norm": 0.29716044664382935,
      "learning_rate": 5.458113148896488e-06,
      "loss": 0.1627,
      "step": 11689
    },
    {
      "epoch": 0.9084550823748835,
      "grad_norm": 0.26910632848739624,
      "learning_rate": 5.457724588125584e-06,
      "loss": 0.0971,
      "step": 11690
    },
    {
      "epoch": 0.9085327945290643,
      "grad_norm": 0.2320270985364914,
      "learning_rate": 5.457336027354678e-06,
      "loss": 0.1315,
      "step": 11691
    },
    {
      "epoch": 0.9086105066832453,
      "grad_norm": 0.5277429223060608,
      "learning_rate": 5.456947466583774e-06,
      "loss": 0.2868,
      "step": 11692
    },
    {
      "epoch": 0.9086882188374261,
      "grad_norm": 0.22445489466190338,
      "learning_rate": 5.4565589058128695e-06,
      "loss": 0.0287,
      "step": 11693
    },
    {
      "epoch": 0.9087659309916071,
      "grad_norm": 0.12221406400203705,
      "learning_rate": 5.456170345041964e-06,
      "loss": 0.0227,
      "step": 11694
    },
    {
      "epoch": 0.908843643145788,
      "grad_norm": 0.2511049509048462,
      "learning_rate": 5.45578178427106e-06,
      "loss": 0.0968,
      "step": 11695
    },
    {
      "epoch": 0.9089213552999689,
      "grad_norm": 0.26116496324539185,
      "learning_rate": 5.455393223500156e-06,
      "loss": 0.0583,
      "step": 11696
    },
    {
      "epoch": 0.9089990674541498,
      "grad_norm": 0.3156781494617462,
      "learning_rate": 5.455004662729251e-06,
      "loss": 0.0777,
      "step": 11697
    },
    {
      "epoch": 0.9090767796083308,
      "grad_norm": 0.209616556763649,
      "learning_rate": 5.454616101958347e-06,
      "loss": 0.1194,
      "step": 11698
    },
    {
      "epoch": 0.9091544917625116,
      "grad_norm": 0.2734171450138092,
      "learning_rate": 5.4542275411874425e-06,
      "loss": 0.1258,
      "step": 11699
    },
    {
      "epoch": 0.9092322039166926,
      "grad_norm": 0.4246319532394409,
      "learning_rate": 5.453838980416538e-06,
      "loss": 0.276,
      "step": 11700
    },
    {
      "epoch": 0.9093099160708735,
      "grad_norm": 0.14649927616119385,
      "learning_rate": 5.4534504196456324e-06,
      "loss": 0.1169,
      "step": 11701
    },
    {
      "epoch": 0.9093876282250544,
      "grad_norm": 0.15977758169174194,
      "learning_rate": 5.453061858874728e-06,
      "loss": 0.0508,
      "step": 11702
    },
    {
      "epoch": 0.9094653403792353,
      "grad_norm": 0.7425491213798523,
      "learning_rate": 5.452673298103824e-06,
      "loss": 0.3061,
      "step": 11703
    },
    {
      "epoch": 0.9095430525334163,
      "grad_norm": 0.5265611410140991,
      "learning_rate": 5.452284737332919e-06,
      "loss": 0.2383,
      "step": 11704
    },
    {
      "epoch": 0.9096207646875971,
      "grad_norm": 0.5398536920547485,
      "learning_rate": 5.451896176562015e-06,
      "loss": 0.2315,
      "step": 11705
    },
    {
      "epoch": 0.9096984768417781,
      "grad_norm": 0.5556799173355103,
      "learning_rate": 5.4515076157911106e-06,
      "loss": 0.1703,
      "step": 11706
    },
    {
      "epoch": 0.909776188995959,
      "grad_norm": 0.6241853833198547,
      "learning_rate": 5.4511190550202055e-06,
      "loss": 0.5227,
      "step": 11707
    },
    {
      "epoch": 0.9098539011501399,
      "grad_norm": 0.5742522478103638,
      "learning_rate": 5.450730494249301e-06,
      "loss": 0.2955,
      "step": 11708
    },
    {
      "epoch": 0.9099316133043208,
      "grad_norm": 0.2713094651699066,
      "learning_rate": 5.450341933478397e-06,
      "loss": 0.0912,
      "step": 11709
    },
    {
      "epoch": 0.9100093254585017,
      "grad_norm": 1.0242595672607422,
      "learning_rate": 5.449953372707491e-06,
      "loss": 0.3697,
      "step": 11710
    },
    {
      "epoch": 0.9100870376126826,
      "grad_norm": 0.29517248272895813,
      "learning_rate": 5.449564811936587e-06,
      "loss": 0.2288,
      "step": 11711
    },
    {
      "epoch": 0.9101647497668636,
      "grad_norm": 0.2026243507862091,
      "learning_rate": 5.449176251165683e-06,
      "loss": 0.0226,
      "step": 11712
    },
    {
      "epoch": 0.9102424619210444,
      "grad_norm": 0.22241711616516113,
      "learning_rate": 5.448787690394778e-06,
      "loss": 0.0265,
      "step": 11713
    },
    {
      "epoch": 0.9103201740752254,
      "grad_norm": 0.15319256484508514,
      "learning_rate": 5.4483991296238736e-06,
      "loss": 0.0326,
      "step": 11714
    },
    {
      "epoch": 0.9103978862294063,
      "grad_norm": 0.5309187173843384,
      "learning_rate": 5.448010568852969e-06,
      "loss": 0.366,
      "step": 11715
    },
    {
      "epoch": 0.9104755983835872,
      "grad_norm": 0.42102858424186707,
      "learning_rate": 5.447622008082064e-06,
      "loss": 0.3913,
      "step": 11716
    },
    {
      "epoch": 0.9105533105377681,
      "grad_norm": 0.38628533482551575,
      "learning_rate": 5.44723344731116e-06,
      "loss": 0.1533,
      "step": 11717
    },
    {
      "epoch": 0.9106310226919491,
      "grad_norm": 0.4715079069137573,
      "learning_rate": 5.446844886540256e-06,
      "loss": 0.429,
      "step": 11718
    },
    {
      "epoch": 0.9107087348461299,
      "grad_norm": 0.5438756346702576,
      "learning_rate": 5.44645632576935e-06,
      "loss": 0.2239,
      "step": 11719
    },
    {
      "epoch": 0.9107864470003109,
      "grad_norm": 0.6708055734634399,
      "learning_rate": 5.446067764998446e-06,
      "loss": 0.1355,
      "step": 11720
    },
    {
      "epoch": 0.9108641591544918,
      "grad_norm": 0.4734521508216858,
      "learning_rate": 5.445679204227542e-06,
      "loss": 0.1983,
      "step": 11721
    },
    {
      "epoch": 0.9109418713086727,
      "grad_norm": 0.36814701557159424,
      "learning_rate": 5.4452906434566365e-06,
      "loss": 0.1531,
      "step": 11722
    },
    {
      "epoch": 0.9110195834628536,
      "grad_norm": 0.07533188909292221,
      "learning_rate": 5.444902082685732e-06,
      "loss": 0.0358,
      "step": 11723
    },
    {
      "epoch": 0.9110972956170345,
      "grad_norm": 0.1923893690109253,
      "learning_rate": 5.444513521914828e-06,
      "loss": 0.1071,
      "step": 11724
    },
    {
      "epoch": 0.9111750077712154,
      "grad_norm": 0.3812336325645447,
      "learning_rate": 5.444124961143923e-06,
      "loss": 0.3014,
      "step": 11725
    },
    {
      "epoch": 0.9112527199253964,
      "grad_norm": 0.6000160574913025,
      "learning_rate": 5.443736400373019e-06,
      "loss": 0.2757,
      "step": 11726
    },
    {
      "epoch": 0.9113304320795772,
      "grad_norm": 0.27971941232681274,
      "learning_rate": 5.443347839602115e-06,
      "loss": 0.0529,
      "step": 11727
    },
    {
      "epoch": 0.9114081442337582,
      "grad_norm": 0.36981141567230225,
      "learning_rate": 5.442959278831209e-06,
      "loss": 0.1337,
      "step": 11728
    },
    {
      "epoch": 0.9114858563879391,
      "grad_norm": 0.4887924790382385,
      "learning_rate": 5.442570718060305e-06,
      "loss": 0.2217,
      "step": 11729
    },
    {
      "epoch": 0.91156356854212,
      "grad_norm": 0.3751446008682251,
      "learning_rate": 5.4421821572894e-06,
      "loss": 0.2229,
      "step": 11730
    },
    {
      "epoch": 0.9116412806963009,
      "grad_norm": 0.09400804340839386,
      "learning_rate": 5.441793596518496e-06,
      "loss": 0.0318,
      "step": 11731
    },
    {
      "epoch": 0.9117189928504819,
      "grad_norm": 0.07467920333147049,
      "learning_rate": 5.441405035747591e-06,
      "loss": 0.0269,
      "step": 11732
    },
    {
      "epoch": 0.9117967050046627,
      "grad_norm": 0.1000799834728241,
      "learning_rate": 5.441016474976687e-06,
      "loss": 0.0532,
      "step": 11733
    },
    {
      "epoch": 0.9118744171588437,
      "grad_norm": 0.20071987807750702,
      "learning_rate": 5.440627914205783e-06,
      "loss": 0.0697,
      "step": 11734
    },
    {
      "epoch": 0.9119521293130246,
      "grad_norm": 0.3147219717502594,
      "learning_rate": 5.440239353434878e-06,
      "loss": 0.0548,
      "step": 11735
    },
    {
      "epoch": 0.9120298414672054,
      "grad_norm": 0.6522684693336487,
      "learning_rate": 5.4398507926639735e-06,
      "loss": 0.6475,
      "step": 11736
    },
    {
      "epoch": 0.9121075536213864,
      "grad_norm": 0.20020651817321777,
      "learning_rate": 5.439462231893069e-06,
      "loss": 0.106,
      "step": 11737
    },
    {
      "epoch": 0.9121852657755672,
      "grad_norm": 0.27925583720207214,
      "learning_rate": 5.439073671122163e-06,
      "loss": 0.0987,
      "step": 11738
    },
    {
      "epoch": 0.9122629779297482,
      "grad_norm": 0.44213637709617615,
      "learning_rate": 5.438685110351259e-06,
      "loss": 0.2001,
      "step": 11739
    },
    {
      "epoch": 0.9123406900839292,
      "grad_norm": 0.7099601030349731,
      "learning_rate": 5.438296549580355e-06,
      "loss": 0.3189,
      "step": 11740
    },
    {
      "epoch": 0.91241840223811,
      "grad_norm": 1.0390257835388184,
      "learning_rate": 5.43790798880945e-06,
      "loss": 0.5981,
      "step": 11741
    },
    {
      "epoch": 0.912496114392291,
      "grad_norm": 0.11927563697099686,
      "learning_rate": 5.437519428038546e-06,
      "loss": 0.0275,
      "step": 11742
    },
    {
      "epoch": 0.9125738265464719,
      "grad_norm": 0.5374321341514587,
      "learning_rate": 5.4371308672676415e-06,
      "loss": 0.1267,
      "step": 11743
    },
    {
      "epoch": 0.9126515387006527,
      "grad_norm": 0.4195582866668701,
      "learning_rate": 5.4367423064967365e-06,
      "loss": 0.3291,
      "step": 11744
    },
    {
      "epoch": 0.9127292508548337,
      "grad_norm": 0.40781697630882263,
      "learning_rate": 5.436353745725832e-06,
      "loss": 0.0538,
      "step": 11745
    },
    {
      "epoch": 0.9128069630090146,
      "grad_norm": 0.5030781030654907,
      "learning_rate": 5.435965184954928e-06,
      "loss": 0.1718,
      "step": 11746
    },
    {
      "epoch": 0.9128846751631955,
      "grad_norm": 0.4931560754776001,
      "learning_rate": 5.435576624184022e-06,
      "loss": 0.8937,
      "step": 11747
    },
    {
      "epoch": 0.9129623873173764,
      "grad_norm": 0.20459908246994019,
      "learning_rate": 5.435188063413118e-06,
      "loss": 0.066,
      "step": 11748
    },
    {
      "epoch": 0.9130400994715574,
      "grad_norm": 0.09709177166223526,
      "learning_rate": 5.434799502642214e-06,
      "loss": 0.0171,
      "step": 11749
    },
    {
      "epoch": 0.9131178116257382,
      "grad_norm": 0.6941704750061035,
      "learning_rate": 5.434410941871309e-06,
      "loss": 0.212,
      "step": 11750
    },
    {
      "epoch": 0.9131955237799192,
      "grad_norm": 0.7496587038040161,
      "learning_rate": 5.4340223811004045e-06,
      "loss": 0.3197,
      "step": 11751
    },
    {
      "epoch": 0.9132732359341001,
      "grad_norm": 0.3064190745353699,
      "learning_rate": 5.4336338203295e-06,
      "loss": 0.2056,
      "step": 11752
    },
    {
      "epoch": 0.913350948088281,
      "grad_norm": 0.4290650188922882,
      "learning_rate": 5.433245259558595e-06,
      "loss": 0.1896,
      "step": 11753
    },
    {
      "epoch": 0.9134286602424619,
      "grad_norm": 0.33481818437576294,
      "learning_rate": 5.432856698787691e-06,
      "loss": 0.2109,
      "step": 11754
    },
    {
      "epoch": 0.9135063723966428,
      "grad_norm": 1.3614318370819092,
      "learning_rate": 5.432468138016787e-06,
      "loss": 0.1553,
      "step": 11755
    },
    {
      "epoch": 0.9135840845508237,
      "grad_norm": 0.5576739311218262,
      "learning_rate": 5.432079577245881e-06,
      "loss": 0.1809,
      "step": 11756
    },
    {
      "epoch": 0.9136617967050047,
      "grad_norm": 0.30462825298309326,
      "learning_rate": 5.431691016474977e-06,
      "loss": 0.1047,
      "step": 11757
    },
    {
      "epoch": 0.9137395088591855,
      "grad_norm": 0.5909420847892761,
      "learning_rate": 5.4313024557040725e-06,
      "loss": 0.2794,
      "step": 11758
    },
    {
      "epoch": 0.9138172210133665,
      "grad_norm": 0.11160004884004593,
      "learning_rate": 5.4309138949331675e-06,
      "loss": 0.0442,
      "step": 11759
    },
    {
      "epoch": 0.9138949331675474,
      "grad_norm": 0.4115353524684906,
      "learning_rate": 5.430525334162263e-06,
      "loss": 0.0529,
      "step": 11760
    },
    {
      "epoch": 0.9139726453217283,
      "grad_norm": 0.7199785113334656,
      "learning_rate": 5.430136773391359e-06,
      "loss": 0.1573,
      "step": 11761
    },
    {
      "epoch": 0.9140503574759092,
      "grad_norm": 0.18803982436656952,
      "learning_rate": 5.429748212620455e-06,
      "loss": 0.0448,
      "step": 11762
    },
    {
      "epoch": 0.9141280696300902,
      "grad_norm": 0.22203747928142548,
      "learning_rate": 5.42935965184955e-06,
      "loss": 0.2881,
      "step": 11763
    },
    {
      "epoch": 0.914205781784271,
      "grad_norm": 0.35619497299194336,
      "learning_rate": 5.428971091078646e-06,
      "loss": 0.0436,
      "step": 11764
    },
    {
      "epoch": 0.914283493938452,
      "grad_norm": 0.28646427392959595,
      "learning_rate": 5.428582530307741e-06,
      "loss": 0.1536,
      "step": 11765
    },
    {
      "epoch": 0.9143612060926329,
      "grad_norm": 0.4831487834453583,
      "learning_rate": 5.4281939695368355e-06,
      "loss": 0.4786,
      "step": 11766
    },
    {
      "epoch": 0.9144389182468138,
      "grad_norm": 0.4034593999385834,
      "learning_rate": 5.427805408765931e-06,
      "loss": 0.4507,
      "step": 11767
    },
    {
      "epoch": 0.9145166304009947,
      "grad_norm": 0.09235800057649612,
      "learning_rate": 5.427416847995027e-06,
      "loss": 0.0286,
      "step": 11768
    },
    {
      "epoch": 0.9145943425551756,
      "grad_norm": 0.44238242506980896,
      "learning_rate": 5.427028287224122e-06,
      "loss": 0.0972,
      "step": 11769
    },
    {
      "epoch": 0.9146720547093565,
      "grad_norm": 0.3004394769668579,
      "learning_rate": 5.426639726453218e-06,
      "loss": 0.1178,
      "step": 11770
    },
    {
      "epoch": 0.9147497668635375,
      "grad_norm": 0.268463671207428,
      "learning_rate": 5.426251165682314e-06,
      "loss": 0.1621,
      "step": 11771
    },
    {
      "epoch": 0.9148274790177183,
      "grad_norm": 0.19198304414749146,
      "learning_rate": 5.425862604911409e-06,
      "loss": 0.0385,
      "step": 11772
    },
    {
      "epoch": 0.9149051911718993,
      "grad_norm": 0.3247917592525482,
      "learning_rate": 5.425474044140504e-06,
      "loss": 0.4712,
      "step": 11773
    },
    {
      "epoch": 0.9149829033260802,
      "grad_norm": 1.0635029077529907,
      "learning_rate": 5.4250854833696e-06,
      "loss": 0.4683,
      "step": 11774
    },
    {
      "epoch": 0.9150606154802611,
      "grad_norm": 0.2783680260181427,
      "learning_rate": 5.424696922598694e-06,
      "loss": 0.1975,
      "step": 11775
    },
    {
      "epoch": 0.915138327634442,
      "grad_norm": 0.6119385361671448,
      "learning_rate": 5.42430836182779e-06,
      "loss": 0.3815,
      "step": 11776
    },
    {
      "epoch": 0.915216039788623,
      "grad_norm": 0.25260448455810547,
      "learning_rate": 5.423919801056886e-06,
      "loss": 0.0578,
      "step": 11777
    },
    {
      "epoch": 0.9152937519428038,
      "grad_norm": 0.2749975323677063,
      "learning_rate": 5.423531240285981e-06,
      "loss": 0.1265,
      "step": 11778
    },
    {
      "epoch": 0.9153714640969848,
      "grad_norm": 0.2612682282924652,
      "learning_rate": 5.423142679515077e-06,
      "loss": 0.073,
      "step": 11779
    },
    {
      "epoch": 0.9154491762511657,
      "grad_norm": 0.36362847685813904,
      "learning_rate": 5.4227541187441724e-06,
      "loss": 0.181,
      "step": 11780
    },
    {
      "epoch": 0.9155268884053466,
      "grad_norm": 0.03983777016401291,
      "learning_rate": 5.422365557973267e-06,
      "loss": 0.0032,
      "step": 11781
    },
    {
      "epoch": 0.9156046005595275,
      "grad_norm": 0.17979548871517181,
      "learning_rate": 5.421976997202363e-06,
      "loss": 0.1269,
      "step": 11782
    },
    {
      "epoch": 0.9156823127137085,
      "grad_norm": 0.22433021664619446,
      "learning_rate": 5.421588436431459e-06,
      "loss": 0.0338,
      "step": 11783
    },
    {
      "epoch": 0.9157600248678893,
      "grad_norm": 0.5002560615539551,
      "learning_rate": 5.421199875660553e-06,
      "loss": 0.2347,
      "step": 11784
    },
    {
      "epoch": 0.9158377370220703,
      "grad_norm": 0.09268499910831451,
      "learning_rate": 5.420811314889649e-06,
      "loss": 0.0153,
      "step": 11785
    },
    {
      "epoch": 0.9159154491762511,
      "grad_norm": 0.22088883817195892,
      "learning_rate": 5.420422754118745e-06,
      "loss": 0.0864,
      "step": 11786
    },
    {
      "epoch": 0.9159931613304321,
      "grad_norm": 0.2783726751804352,
      "learning_rate": 5.42003419334784e-06,
      "loss": 0.1239,
      "step": 11787
    },
    {
      "epoch": 0.916070873484613,
      "grad_norm": 0.1691843867301941,
      "learning_rate": 5.419645632576935e-06,
      "loss": 0.0842,
      "step": 11788
    },
    {
      "epoch": 0.9161485856387939,
      "grad_norm": 1.0365045070648193,
      "learning_rate": 5.419257071806031e-06,
      "loss": 0.6863,
      "step": 11789
    },
    {
      "epoch": 0.9162262977929748,
      "grad_norm": 0.3816489279270172,
      "learning_rate": 5.418868511035126e-06,
      "loss": 0.1119,
      "step": 11790
    },
    {
      "epoch": 0.9163040099471558,
      "grad_norm": 0.08752333372831345,
      "learning_rate": 5.418479950264222e-06,
      "loss": 0.0157,
      "step": 11791
    },
    {
      "epoch": 0.9163817221013366,
      "grad_norm": 0.16955730319023132,
      "learning_rate": 5.418091389493318e-06,
      "loss": 0.0403,
      "step": 11792
    },
    {
      "epoch": 0.9164594342555176,
      "grad_norm": 0.10969442874193192,
      "learning_rate": 5.4177028287224136e-06,
      "loss": 0.0795,
      "step": 11793
    },
    {
      "epoch": 0.9165371464096985,
      "grad_norm": 0.1876220554113388,
      "learning_rate": 5.417314267951508e-06,
      "loss": 0.0134,
      "step": 11794
    },
    {
      "epoch": 0.9166148585638794,
      "grad_norm": 0.28307464718818665,
      "learning_rate": 5.4169257071806035e-06,
      "loss": 0.1745,
      "step": 11795
    },
    {
      "epoch": 0.9166925707180603,
      "grad_norm": 0.3615306317806244,
      "learning_rate": 5.416537146409699e-06,
      "loss": 0.2029,
      "step": 11796
    },
    {
      "epoch": 0.9167702828722413,
      "grad_norm": 0.061562832444906235,
      "learning_rate": 5.416148585638794e-06,
      "loss": 0.0077,
      "step": 11797
    },
    {
      "epoch": 0.9168479950264221,
      "grad_norm": 0.3180094063282013,
      "learning_rate": 5.41576002486789e-06,
      "loss": 0.1729,
      "step": 11798
    },
    {
      "epoch": 0.9169257071806031,
      "grad_norm": 0.5903846025466919,
      "learning_rate": 5.415371464096986e-06,
      "loss": 0.5609,
      "step": 11799
    },
    {
      "epoch": 0.9170034193347839,
      "grad_norm": 0.25988468527793884,
      "learning_rate": 5.414982903326081e-06,
      "loss": 0.178,
      "step": 11800
    },
    {
      "epoch": 0.9170811314889649,
      "grad_norm": 0.15720798075199127,
      "learning_rate": 5.4145943425551765e-06,
      "loss": 0.0542,
      "step": 11801
    },
    {
      "epoch": 0.9171588436431458,
      "grad_norm": 0.1343509405851364,
      "learning_rate": 5.414205781784272e-06,
      "loss": 0.0508,
      "step": 11802
    },
    {
      "epoch": 0.9172365557973267,
      "grad_norm": 1.1540073156356812,
      "learning_rate": 5.4138172210133664e-06,
      "loss": 0.2617,
      "step": 11803
    },
    {
      "epoch": 0.9173142679515076,
      "grad_norm": 0.5511746406555176,
      "learning_rate": 5.413428660242462e-06,
      "loss": 0.1501,
      "step": 11804
    },
    {
      "epoch": 0.9173919801056886,
      "grad_norm": 0.32696330547332764,
      "learning_rate": 5.413040099471558e-06,
      "loss": 0.1553,
      "step": 11805
    },
    {
      "epoch": 0.9174696922598694,
      "grad_norm": 0.2272617518901825,
      "learning_rate": 5.412651538700653e-06,
      "loss": 0.0894,
      "step": 11806
    },
    {
      "epoch": 0.9175474044140504,
      "grad_norm": 0.7339686155319214,
      "learning_rate": 5.412262977929749e-06,
      "loss": 0.5299,
      "step": 11807
    },
    {
      "epoch": 0.9176251165682313,
      "grad_norm": 0.2857239246368408,
      "learning_rate": 5.411874417158845e-06,
      "loss": 0.1289,
      "step": 11808
    },
    {
      "epoch": 0.9177028287224122,
      "grad_norm": 0.39175960421562195,
      "learning_rate": 5.4114858563879395e-06,
      "loss": 0.162,
      "step": 11809
    },
    {
      "epoch": 0.9177805408765931,
      "grad_norm": 0.35852810740470886,
      "learning_rate": 5.4110972956170345e-06,
      "loss": 0.1496,
      "step": 11810
    },
    {
      "epoch": 0.9178582530307741,
      "grad_norm": 0.11255922168493271,
      "learning_rate": 5.41070873484613e-06,
      "loss": 0.0359,
      "step": 11811
    },
    {
      "epoch": 0.9179359651849549,
      "grad_norm": 0.516160786151886,
      "learning_rate": 5.410320174075225e-06,
      "loss": 0.1044,
      "step": 11812
    },
    {
      "epoch": 0.9180136773391359,
      "grad_norm": 0.3622561991214752,
      "learning_rate": 5.409931613304321e-06,
      "loss": 0.4491,
      "step": 11813
    },
    {
      "epoch": 0.9180913894933167,
      "grad_norm": 0.08472999930381775,
      "learning_rate": 5.409543052533417e-06,
      "loss": 0.0179,
      "step": 11814
    },
    {
      "epoch": 0.9181691016474977,
      "grad_norm": 0.9031696319580078,
      "learning_rate": 5.409154491762512e-06,
      "loss": 0.3587,
      "step": 11815
    },
    {
      "epoch": 0.9182468138016786,
      "grad_norm": 0.38776955008506775,
      "learning_rate": 5.4087659309916076e-06,
      "loss": 0.1294,
      "step": 11816
    },
    {
      "epoch": 0.9183245259558594,
      "grad_norm": 0.3639785945415497,
      "learning_rate": 5.408377370220703e-06,
      "loss": 0.137,
      "step": 11817
    },
    {
      "epoch": 0.9184022381100404,
      "grad_norm": 0.5884650945663452,
      "learning_rate": 5.4079888094497975e-06,
      "loss": 0.3644,
      "step": 11818
    },
    {
      "epoch": 0.9184799502642214,
      "grad_norm": 0.32115939259529114,
      "learning_rate": 5.407600248678893e-06,
      "loss": 0.1162,
      "step": 11819
    },
    {
      "epoch": 0.9185576624184022,
      "grad_norm": 0.2897784411907196,
      "learning_rate": 5.407211687907989e-06,
      "loss": 0.1467,
      "step": 11820
    },
    {
      "epoch": 0.9186353745725832,
      "grad_norm": 0.26524296402931213,
      "learning_rate": 5.406823127137085e-06,
      "loss": 0.0662,
      "step": 11821
    },
    {
      "epoch": 0.9187130867267641,
      "grad_norm": 0.604027271270752,
      "learning_rate": 5.40643456636618e-06,
      "loss": 0.2407,
      "step": 11822
    },
    {
      "epoch": 0.918790798880945,
      "grad_norm": 0.32633528113365173,
      "learning_rate": 5.406046005595276e-06,
      "loss": 0.1703,
      "step": 11823
    },
    {
      "epoch": 0.9188685110351259,
      "grad_norm": 0.11317798495292664,
      "learning_rate": 5.405657444824371e-06,
      "loss": 0.0363,
      "step": 11824
    },
    {
      "epoch": 0.9189462231893069,
      "grad_norm": 0.20304502546787262,
      "learning_rate": 5.405268884053466e-06,
      "loss": 0.0499,
      "step": 11825
    },
    {
      "epoch": 0.9190239353434877,
      "grad_norm": 0.4170372486114502,
      "learning_rate": 5.404880323282562e-06,
      "loss": 0.1201,
      "step": 11826
    },
    {
      "epoch": 0.9191016474976687,
      "grad_norm": 0.25404953956604004,
      "learning_rate": 5.404491762511658e-06,
      "loss": 0.0716,
      "step": 11827
    },
    {
      "epoch": 0.9191793596518496,
      "grad_norm": 0.4350850582122803,
      "learning_rate": 5.404103201740752e-06,
      "loss": 0.1802,
      "step": 11828
    },
    {
      "epoch": 0.9192570718060304,
      "grad_norm": 0.3339621126651764,
      "learning_rate": 5.403714640969848e-06,
      "loss": 0.1408,
      "step": 11829
    },
    {
      "epoch": 0.9193347839602114,
      "grad_norm": 0.2831394374370575,
      "learning_rate": 5.403326080198944e-06,
      "loss": 0.1254,
      "step": 11830
    },
    {
      "epoch": 0.9194124961143922,
      "grad_norm": 0.12675261497497559,
      "learning_rate": 5.402937519428039e-06,
      "loss": 0.0479,
      "step": 11831
    },
    {
      "epoch": 0.9194902082685732,
      "grad_norm": 0.5927371978759766,
      "learning_rate": 5.402548958657134e-06,
      "loss": 0.2904,
      "step": 11832
    },
    {
      "epoch": 0.9195679204227541,
      "grad_norm": 0.7307326197624207,
      "learning_rate": 5.40216039788623e-06,
      "loss": 0.2976,
      "step": 11833
    },
    {
      "epoch": 0.919645632576935,
      "grad_norm": 0.20487476885318756,
      "learning_rate": 5.401771837115325e-06,
      "loss": 0.0738,
      "step": 11834
    },
    {
      "epoch": 0.9197233447311159,
      "grad_norm": 0.5938732624053955,
      "learning_rate": 5.401383276344421e-06,
      "loss": 0.1976,
      "step": 11835
    },
    {
      "epoch": 0.9198010568852969,
      "grad_norm": 0.6951871514320374,
      "learning_rate": 5.400994715573517e-06,
      "loss": 0.611,
      "step": 11836
    },
    {
      "epoch": 0.9198787690394777,
      "grad_norm": 0.349985808134079,
      "learning_rate": 5.400606154802611e-06,
      "loss": 0.0749,
      "step": 11837
    },
    {
      "epoch": 0.9199564811936587,
      "grad_norm": 0.33028072118759155,
      "learning_rate": 5.400217594031707e-06,
      "loss": 0.555,
      "step": 11838
    },
    {
      "epoch": 0.9200341933478396,
      "grad_norm": 0.24921086430549622,
      "learning_rate": 5.399829033260802e-06,
      "loss": 0.1291,
      "step": 11839
    },
    {
      "epoch": 0.9201119055020205,
      "grad_norm": 0.34686073660850525,
      "learning_rate": 5.399440472489897e-06,
      "loss": 0.1724,
      "step": 11840
    },
    {
      "epoch": 0.9201896176562014,
      "grad_norm": 0.2775959372520447,
      "learning_rate": 5.399051911718993e-06,
      "loss": 0.1592,
      "step": 11841
    },
    {
      "epoch": 0.9202673298103824,
      "grad_norm": 0.09962839633226395,
      "learning_rate": 5.398663350948089e-06,
      "loss": 0.0398,
      "step": 11842
    },
    {
      "epoch": 0.9203450419645632,
      "grad_norm": 0.4900825321674347,
      "learning_rate": 5.398274790177184e-06,
      "loss": 0.1177,
      "step": 11843
    },
    {
      "epoch": 0.9204227541187442,
      "grad_norm": 0.3372209370136261,
      "learning_rate": 5.39788622940628e-06,
      "loss": 0.1024,
      "step": 11844
    },
    {
      "epoch": 0.920500466272925,
      "grad_norm": 0.19667774438858032,
      "learning_rate": 5.3974976686353755e-06,
      "loss": 0.1023,
      "step": 11845
    },
    {
      "epoch": 0.920578178427106,
      "grad_norm": 0.7890257835388184,
      "learning_rate": 5.39710910786447e-06,
      "loss": 0.3392,
      "step": 11846
    },
    {
      "epoch": 0.9206558905812869,
      "grad_norm": 0.09296426177024841,
      "learning_rate": 5.396720547093565e-06,
      "loss": 0.0194,
      "step": 11847
    },
    {
      "epoch": 0.9207336027354678,
      "grad_norm": 1.0492604970932007,
      "learning_rate": 5.396331986322661e-06,
      "loss": 0.1818,
      "step": 11848
    },
    {
      "epoch": 0.9208113148896487,
      "grad_norm": 0.8576863408088684,
      "learning_rate": 5.395943425551756e-06,
      "loss": 0.853,
      "step": 11849
    },
    {
      "epoch": 0.9208890270438297,
      "grad_norm": 0.20711396634578705,
      "learning_rate": 5.395554864780852e-06,
      "loss": 0.0716,
      "step": 11850
    },
    {
      "epoch": 0.9209667391980105,
      "grad_norm": 1.1104726791381836,
      "learning_rate": 5.395166304009948e-06,
      "loss": 0.3234,
      "step": 11851
    },
    {
      "epoch": 0.9210444513521915,
      "grad_norm": 0.1870093196630478,
      "learning_rate": 5.3947777432390435e-06,
      "loss": 0.0707,
      "step": 11852
    },
    {
      "epoch": 0.9211221635063724,
      "grad_norm": 0.0639757439494133,
      "learning_rate": 5.3943891824681385e-06,
      "loss": 0.0073,
      "step": 11853
    },
    {
      "epoch": 0.9211998756605533,
      "grad_norm": 0.3512655794620514,
      "learning_rate": 5.394000621697234e-06,
      "loss": 0.2628,
      "step": 11854
    },
    {
      "epoch": 0.9212775878147342,
      "grad_norm": 0.08880104124546051,
      "learning_rate": 5.39361206092633e-06,
      "loss": 0.0512,
      "step": 11855
    },
    {
      "epoch": 0.9213552999689152,
      "grad_norm": 0.13687999546527863,
      "learning_rate": 5.393223500155424e-06,
      "loss": 0.052,
      "step": 11856
    },
    {
      "epoch": 0.921433012123096,
      "grad_norm": 0.24757251143455505,
      "learning_rate": 5.39283493938452e-06,
      "loss": 0.1714,
      "step": 11857
    },
    {
      "epoch": 0.921510724277277,
      "grad_norm": 0.3033173978328705,
      "learning_rate": 5.392446378613616e-06,
      "loss": 0.0975,
      "step": 11858
    },
    {
      "epoch": 0.9215884364314578,
      "grad_norm": 0.2002948820590973,
      "learning_rate": 5.392057817842711e-06,
      "loss": 0.0769,
      "step": 11859
    },
    {
      "epoch": 0.9216661485856388,
      "grad_norm": 0.593730092048645,
      "learning_rate": 5.3916692570718065e-06,
      "loss": 0.4922,
      "step": 11860
    },
    {
      "epoch": 0.9217438607398197,
      "grad_norm": 0.7221128940582275,
      "learning_rate": 5.391280696300902e-06,
      "loss": 0.3081,
      "step": 11861
    },
    {
      "epoch": 0.9218215728940006,
      "grad_norm": 0.7019843459129333,
      "learning_rate": 5.390892135529997e-06,
      "loss": 0.6443,
      "step": 11862
    },
    {
      "epoch": 0.9218992850481815,
      "grad_norm": 0.2587169110774994,
      "learning_rate": 5.390503574759093e-06,
      "loss": 0.0423,
      "step": 11863
    },
    {
      "epoch": 0.9219769972023625,
      "grad_norm": 0.6900258660316467,
      "learning_rate": 5.390115013988189e-06,
      "loss": 0.3448,
      "step": 11864
    },
    {
      "epoch": 0.9220547093565433,
      "grad_norm": 0.14366330206394196,
      "learning_rate": 5.389726453217283e-06,
      "loss": 0.0752,
      "step": 11865
    },
    {
      "epoch": 0.9221324215107243,
      "grad_norm": 0.20818759500980377,
      "learning_rate": 5.389337892446379e-06,
      "loss": 0.1287,
      "step": 11866
    },
    {
      "epoch": 0.9222101336649052,
      "grad_norm": 0.5098561644554138,
      "learning_rate": 5.3889493316754746e-06,
      "loss": 0.3082,
      "step": 11867
    },
    {
      "epoch": 0.9222878458190861,
      "grad_norm": 0.35212039947509766,
      "learning_rate": 5.3885607709045695e-06,
      "loss": 0.1341,
      "step": 11868
    },
    {
      "epoch": 0.922365557973267,
      "grad_norm": 0.4055022895336151,
      "learning_rate": 5.388172210133665e-06,
      "loss": 0.1583,
      "step": 11869
    },
    {
      "epoch": 0.922443270127448,
      "grad_norm": 0.5166193842887878,
      "learning_rate": 5.387783649362761e-06,
      "loss": 0.1512,
      "step": 11870
    },
    {
      "epoch": 0.9225209822816288,
      "grad_norm": 0.3303837478160858,
      "learning_rate": 5.387395088591856e-06,
      "loss": 0.3001,
      "step": 11871
    },
    {
      "epoch": 0.9225986944358098,
      "grad_norm": 0.5400872826576233,
      "learning_rate": 5.387006527820952e-06,
      "loss": 0.2668,
      "step": 11872
    },
    {
      "epoch": 0.9226764065899907,
      "grad_norm": 0.8454339504241943,
      "learning_rate": 5.386617967050048e-06,
      "loss": 0.5909,
      "step": 11873
    },
    {
      "epoch": 0.9227541187441716,
      "grad_norm": 0.4283176362514496,
      "learning_rate": 5.386229406279142e-06,
      "loss": 0.1257,
      "step": 11874
    },
    {
      "epoch": 0.9228318308983525,
      "grad_norm": 1.1378897428512573,
      "learning_rate": 5.3858408455082376e-06,
      "loss": 0.2551,
      "step": 11875
    },
    {
      "epoch": 0.9229095430525334,
      "grad_norm": 0.2884853184223175,
      "learning_rate": 5.385452284737333e-06,
      "loss": 0.128,
      "step": 11876
    },
    {
      "epoch": 0.9229872552067143,
      "grad_norm": 0.7876742482185364,
      "learning_rate": 5.385063723966428e-06,
      "loss": 0.3863,
      "step": 11877
    },
    {
      "epoch": 0.9230649673608953,
      "grad_norm": 1.0893986225128174,
      "learning_rate": 5.384675163195524e-06,
      "loss": 0.25,
      "step": 11878
    },
    {
      "epoch": 0.9231426795150761,
      "grad_norm": 0.4215400218963623,
      "learning_rate": 5.38428660242462e-06,
      "loss": 0.1573,
      "step": 11879
    },
    {
      "epoch": 0.9232203916692571,
      "grad_norm": 0.8119649291038513,
      "learning_rate": 5.383898041653715e-06,
      "loss": 1.201,
      "step": 11880
    },
    {
      "epoch": 0.923298103823438,
      "grad_norm": 0.235197052359581,
      "learning_rate": 5.383509480882811e-06,
      "loss": 0.0661,
      "step": 11881
    },
    {
      "epoch": 0.9233758159776189,
      "grad_norm": 0.46579721570014954,
      "learning_rate": 5.3831209201119064e-06,
      "loss": 0.4583,
      "step": 11882
    },
    {
      "epoch": 0.9234535281317998,
      "grad_norm": 0.2996084690093994,
      "learning_rate": 5.382732359341002e-06,
      "loss": 0.0807,
      "step": 11883
    },
    {
      "epoch": 0.9235312402859808,
      "grad_norm": 0.36578840017318726,
      "learning_rate": 5.382343798570096e-06,
      "loss": 0.215,
      "step": 11884
    },
    {
      "epoch": 0.9236089524401616,
      "grad_norm": 0.3991850018501282,
      "learning_rate": 5.381955237799192e-06,
      "loss": 0.0473,
      "step": 11885
    },
    {
      "epoch": 0.9236866645943426,
      "grad_norm": 0.5579749941825867,
      "learning_rate": 5.381566677028288e-06,
      "loss": 0.2011,
      "step": 11886
    },
    {
      "epoch": 0.9237643767485235,
      "grad_norm": 0.5752487182617188,
      "learning_rate": 5.381178116257383e-06,
      "loss": 0.297,
      "step": 11887
    },
    {
      "epoch": 0.9238420889027044,
      "grad_norm": 0.2186383306980133,
      "learning_rate": 5.380789555486479e-06,
      "loss": 0.0552,
      "step": 11888
    },
    {
      "epoch": 0.9239198010568853,
      "grad_norm": 0.2663017809391022,
      "learning_rate": 5.3804009947155745e-06,
      "loss": 0.0775,
      "step": 11889
    },
    {
      "epoch": 0.9239975132110662,
      "grad_norm": 0.15066403150558472,
      "learning_rate": 5.3800124339446694e-06,
      "loss": 0.0127,
      "step": 11890
    },
    {
      "epoch": 0.9240752253652471,
      "grad_norm": 0.5076501369476318,
      "learning_rate": 5.379623873173765e-06,
      "loss": 0.473,
      "step": 11891
    },
    {
      "epoch": 0.9241529375194281,
      "grad_norm": 0.18029536306858063,
      "learning_rate": 5.379235312402861e-06,
      "loss": 0.0639,
      "step": 11892
    },
    {
      "epoch": 0.9242306496736089,
      "grad_norm": 0.4843621850013733,
      "learning_rate": 5.378846751631955e-06,
      "loss": 0.3138,
      "step": 11893
    },
    {
      "epoch": 0.9243083618277899,
      "grad_norm": 0.26421546936035156,
      "learning_rate": 5.378458190861051e-06,
      "loss": 0.0627,
      "step": 11894
    },
    {
      "epoch": 0.9243860739819708,
      "grad_norm": 0.1660526841878891,
      "learning_rate": 5.378069630090147e-06,
      "loss": 0.0552,
      "step": 11895
    },
    {
      "epoch": 0.9244637861361517,
      "grad_norm": 0.11529850214719772,
      "learning_rate": 5.377681069319242e-06,
      "loss": 0.05,
      "step": 11896
    },
    {
      "epoch": 0.9245414982903326,
      "grad_norm": 0.7098133563995361,
      "learning_rate": 5.3772925085483375e-06,
      "loss": 0.3129,
      "step": 11897
    },
    {
      "epoch": 0.9246192104445136,
      "grad_norm": 0.6846673488616943,
      "learning_rate": 5.376903947777433e-06,
      "loss": 0.3319,
      "step": 11898
    },
    {
      "epoch": 0.9246969225986944,
      "grad_norm": 0.45859214663505554,
      "learning_rate": 5.376515387006528e-06,
      "loss": 0.23,
      "step": 11899
    },
    {
      "epoch": 0.9247746347528754,
      "grad_norm": 0.5601943135261536,
      "learning_rate": 5.376126826235624e-06,
      "loss": 0.4091,
      "step": 11900
    },
    {
      "epoch": 0.9248523469070563,
      "grad_norm": 0.35926690697669983,
      "learning_rate": 5.37573826546472e-06,
      "loss": 0.0644,
      "step": 11901
    },
    {
      "epoch": 0.9249300590612372,
      "grad_norm": 0.3807283937931061,
      "learning_rate": 5.375349704693814e-06,
      "loss": 0.2394,
      "step": 11902
    },
    {
      "epoch": 0.9250077712154181,
      "grad_norm": 0.5348297953605652,
      "learning_rate": 5.37496114392291e-06,
      "loss": 0.7574,
      "step": 11903
    },
    {
      "epoch": 0.9250854833695991,
      "grad_norm": 0.38435569405555725,
      "learning_rate": 5.3745725831520055e-06,
      "loss": 0.546,
      "step": 11904
    },
    {
      "epoch": 0.9251631955237799,
      "grad_norm": 1.5512502193450928,
      "learning_rate": 5.3741840223811004e-06,
      "loss": 0.979,
      "step": 11905
    },
    {
      "epoch": 0.9252409076779609,
      "grad_norm": 0.6848770380020142,
      "learning_rate": 5.373795461610196e-06,
      "loss": 0.2156,
      "step": 11906
    },
    {
      "epoch": 0.9253186198321417,
      "grad_norm": 0.7201295495033264,
      "learning_rate": 5.373406900839292e-06,
      "loss": 0.2722,
      "step": 11907
    },
    {
      "epoch": 0.9253963319863227,
      "grad_norm": 0.3453897535800934,
      "learning_rate": 5.373018340068387e-06,
      "loss": 0.0614,
      "step": 11908
    },
    {
      "epoch": 0.9254740441405036,
      "grad_norm": 0.5155221819877625,
      "learning_rate": 5.372629779297483e-06,
      "loss": 0.1639,
      "step": 11909
    },
    {
      "epoch": 0.9255517562946844,
      "grad_norm": 0.8844565153121948,
      "learning_rate": 5.372241218526579e-06,
      "loss": 0.2769,
      "step": 11910
    },
    {
      "epoch": 0.9256294684488654,
      "grad_norm": 0.28245970606803894,
      "learning_rate": 5.371852657755673e-06,
      "loss": 0.0546,
      "step": 11911
    },
    {
      "epoch": 0.9257071806030464,
      "grad_norm": 0.1851027011871338,
      "learning_rate": 5.3714640969847685e-06,
      "loss": 0.0396,
      "step": 11912
    },
    {
      "epoch": 0.9257848927572272,
      "grad_norm": 0.487517386674881,
      "learning_rate": 5.371075536213864e-06,
      "loss": 0.1004,
      "step": 11913
    },
    {
      "epoch": 0.9258626049114081,
      "grad_norm": 0.15207134187221527,
      "learning_rate": 5.37068697544296e-06,
      "loss": 0.0456,
      "step": 11914
    },
    {
      "epoch": 0.9259403170655891,
      "grad_norm": 0.2791604995727539,
      "learning_rate": 5.370298414672055e-06,
      "loss": 0.0258,
      "step": 11915
    },
    {
      "epoch": 0.92601802921977,
      "grad_norm": 0.3102284371852875,
      "learning_rate": 5.369909853901151e-06,
      "loss": 0.0503,
      "step": 11916
    },
    {
      "epoch": 0.9260957413739509,
      "grad_norm": 0.49995338916778564,
      "learning_rate": 5.369521293130247e-06,
      "loss": 0.2103,
      "step": 11917
    },
    {
      "epoch": 0.9261734535281319,
      "grad_norm": 0.4512309730052948,
      "learning_rate": 5.3691327323593416e-06,
      "loss": 0.2088,
      "step": 11918
    },
    {
      "epoch": 0.9262511656823127,
      "grad_norm": 0.3538437783718109,
      "learning_rate": 5.368744171588437e-06,
      "loss": 0.1892,
      "step": 11919
    },
    {
      "epoch": 0.9263288778364936,
      "grad_norm": 0.6558474898338318,
      "learning_rate": 5.368355610817533e-06,
      "loss": 0.2199,
      "step": 11920
    },
    {
      "epoch": 0.9264065899906745,
      "grad_norm": 0.22888121008872986,
      "learning_rate": 5.367967050046627e-06,
      "loss": 0.1914,
      "step": 11921
    },
    {
      "epoch": 0.9264843021448554,
      "grad_norm": 0.11905357241630554,
      "learning_rate": 5.367578489275723e-06,
      "loss": 0.042,
      "step": 11922
    },
    {
      "epoch": 0.9265620142990364,
      "grad_norm": 0.34781786799430847,
      "learning_rate": 5.367189928504819e-06,
      "loss": 0.284,
      "step": 11923
    },
    {
      "epoch": 0.9266397264532172,
      "grad_norm": 0.11507229506969452,
      "learning_rate": 5.366801367733914e-06,
      "loss": 0.0295,
      "step": 11924
    },
    {
      "epoch": 0.9267174386073982,
      "grad_norm": 0.5440924763679504,
      "learning_rate": 5.36641280696301e-06,
      "loss": 0.3594,
      "step": 11925
    },
    {
      "epoch": 0.9267951507615791,
      "grad_norm": 0.4769383668899536,
      "learning_rate": 5.366024246192105e-06,
      "loss": 0.1676,
      "step": 11926
    },
    {
      "epoch": 0.92687286291576,
      "grad_norm": 0.19316761195659637,
      "learning_rate": 5.3656356854212e-06,
      "loss": 0.1607,
      "step": 11927
    },
    {
      "epoch": 0.9269505750699409,
      "grad_norm": 0.9383822679519653,
      "learning_rate": 5.365247124650296e-06,
      "loss": 0.5854,
      "step": 11928
    },
    {
      "epoch": 0.9270282872241219,
      "grad_norm": 0.6988897919654846,
      "learning_rate": 5.364858563879391e-06,
      "loss": 0.2658,
      "step": 11929
    },
    {
      "epoch": 0.9271059993783027,
      "grad_norm": 0.2665914297103882,
      "learning_rate": 5.364470003108486e-06,
      "loss": 0.1217,
      "step": 11930
    },
    {
      "epoch": 0.9271837115324837,
      "grad_norm": 0.23774604499340057,
      "learning_rate": 5.364081442337582e-06,
      "loss": 0.1269,
      "step": 11931
    },
    {
      "epoch": 0.9272614236866646,
      "grad_norm": 0.09542518109083176,
      "learning_rate": 5.363692881566678e-06,
      "loss": 0.0204,
      "step": 11932
    },
    {
      "epoch": 0.9273391358408455,
      "grad_norm": 0.3031821548938751,
      "learning_rate": 5.363304320795773e-06,
      "loss": 0.2667,
      "step": 11933
    },
    {
      "epoch": 0.9274168479950264,
      "grad_norm": 1.5602110624313354,
      "learning_rate": 5.362915760024868e-06,
      "loss": 0.5569,
      "step": 11934
    },
    {
      "epoch": 0.9274945601492073,
      "grad_norm": 0.29475972056388855,
      "learning_rate": 5.362527199253964e-06,
      "loss": 0.1634,
      "step": 11935
    },
    {
      "epoch": 0.9275722723033882,
      "grad_norm": 0.23419934511184692,
      "learning_rate": 5.362138638483058e-06,
      "loss": 0.1002,
      "step": 11936
    },
    {
      "epoch": 0.9276499844575692,
      "grad_norm": 0.3219798505306244,
      "learning_rate": 5.361750077712154e-06,
      "loss": 0.1274,
      "step": 11937
    },
    {
      "epoch": 0.92772769661175,
      "grad_norm": 0.2403208464384079,
      "learning_rate": 5.36136151694125e-06,
      "loss": 0.1169,
      "step": 11938
    },
    {
      "epoch": 0.927805408765931,
      "grad_norm": 0.38735607266426086,
      "learning_rate": 5.360972956170345e-06,
      "loss": 0.139,
      "step": 11939
    },
    {
      "epoch": 0.9278831209201119,
      "grad_norm": 0.573154866695404,
      "learning_rate": 5.360584395399441e-06,
      "loss": 0.1506,
      "step": 11940
    },
    {
      "epoch": 0.9279608330742928,
      "grad_norm": 0.3022708296775818,
      "learning_rate": 5.3601958346285364e-06,
      "loss": 0.0928,
      "step": 11941
    },
    {
      "epoch": 0.9280385452284737,
      "grad_norm": 0.33748504519462585,
      "learning_rate": 5.359807273857631e-06,
      "loss": 0.2509,
      "step": 11942
    },
    {
      "epoch": 0.9281162573826547,
      "grad_norm": 0.6242719888687134,
      "learning_rate": 5.359418713086727e-06,
      "loss": 0.0776,
      "step": 11943
    },
    {
      "epoch": 0.9281939695368355,
      "grad_norm": 0.2297848016023636,
      "learning_rate": 5.359030152315823e-06,
      "loss": 0.0791,
      "step": 11944
    },
    {
      "epoch": 0.9282716816910165,
      "grad_norm": 0.308437317609787,
      "learning_rate": 5.358641591544919e-06,
      "loss": 0.4554,
      "step": 11945
    },
    {
      "epoch": 0.9283493938451974,
      "grad_norm": 0.22450876235961914,
      "learning_rate": 5.358253030774013e-06,
      "loss": 0.0968,
      "step": 11946
    },
    {
      "epoch": 0.9284271059993783,
      "grad_norm": 0.10865338891744614,
      "learning_rate": 5.357864470003109e-06,
      "loss": 0.0246,
      "step": 11947
    },
    {
      "epoch": 0.9285048181535592,
      "grad_norm": 0.27540552616119385,
      "learning_rate": 5.3574759092322045e-06,
      "loss": 0.0879,
      "step": 11948
    },
    {
      "epoch": 0.9285825303077402,
      "grad_norm": 0.27622053027153015,
      "learning_rate": 5.357087348461299e-06,
      "loss": 0.0744,
      "step": 11949
    },
    {
      "epoch": 0.928660242461921,
      "grad_norm": 0.9978793263435364,
      "learning_rate": 5.356698787690395e-06,
      "loss": 0.5173,
      "step": 11950
    },
    {
      "epoch": 0.928737954616102,
      "grad_norm": 0.6125805377960205,
      "learning_rate": 5.356310226919491e-06,
      "loss": 0.2809,
      "step": 11951
    },
    {
      "epoch": 0.9288156667702828,
      "grad_norm": 0.15986093878746033,
      "learning_rate": 5.355921666148586e-06,
      "loss": 0.0982,
      "step": 11952
    },
    {
      "epoch": 0.9288933789244638,
      "grad_norm": 0.1660829335451126,
      "learning_rate": 5.355533105377682e-06,
      "loss": 0.0386,
      "step": 11953
    },
    {
      "epoch": 0.9289710910786447,
      "grad_norm": 0.4910182058811188,
      "learning_rate": 5.3551445446067776e-06,
      "loss": 0.4329,
      "step": 11954
    },
    {
      "epoch": 0.9290488032328256,
      "grad_norm": 0.4097403883934021,
      "learning_rate": 5.354755983835872e-06,
      "loss": 0.2797,
      "step": 11955
    },
    {
      "epoch": 0.9291265153870065,
      "grad_norm": 0.26669010519981384,
      "learning_rate": 5.3543674230649675e-06,
      "loss": 0.1183,
      "step": 11956
    },
    {
      "epoch": 0.9292042275411875,
      "grad_norm": 0.5260873436927795,
      "learning_rate": 5.353978862294063e-06,
      "loss": 0.2654,
      "step": 11957
    },
    {
      "epoch": 0.9292819396953683,
      "grad_norm": 0.40043509006500244,
      "learning_rate": 5.353590301523158e-06,
      "loss": 0.112,
      "step": 11958
    },
    {
      "epoch": 0.9293596518495493,
      "grad_norm": 0.24882079660892487,
      "learning_rate": 5.353201740752254e-06,
      "loss": 0.0663,
      "step": 11959
    },
    {
      "epoch": 0.9294373640037302,
      "grad_norm": 0.4395557940006256,
      "learning_rate": 5.35281317998135e-06,
      "loss": 0.1281,
      "step": 11960
    },
    {
      "epoch": 0.9295150761579111,
      "grad_norm": 0.3835282623767853,
      "learning_rate": 5.352424619210445e-06,
      "loss": 0.1593,
      "step": 11961
    },
    {
      "epoch": 0.929592788312092,
      "grad_norm": 0.0497032031416893,
      "learning_rate": 5.3520360584395405e-06,
      "loss": 0.0101,
      "step": 11962
    },
    {
      "epoch": 0.929670500466273,
      "grad_norm": 0.46747690439224243,
      "learning_rate": 5.351647497668636e-06,
      "loss": 0.3178,
      "step": 11963
    },
    {
      "epoch": 0.9297482126204538,
      "grad_norm": 0.2714696228504181,
      "learning_rate": 5.3512589368977304e-06,
      "loss": 0.355,
      "step": 11964
    },
    {
      "epoch": 0.9298259247746348,
      "grad_norm": 0.1055387556552887,
      "learning_rate": 5.350870376126826e-06,
      "loss": 0.0198,
      "step": 11965
    },
    {
      "epoch": 0.9299036369288156,
      "grad_norm": 0.5213946104049683,
      "learning_rate": 5.350481815355922e-06,
      "loss": 0.1531,
      "step": 11966
    },
    {
      "epoch": 0.9299813490829966,
      "grad_norm": 0.7259607315063477,
      "learning_rate": 5.350093254585017e-06,
      "loss": 0.2594,
      "step": 11967
    },
    {
      "epoch": 0.9300590612371775,
      "grad_norm": 0.38110435009002686,
      "learning_rate": 5.349704693814113e-06,
      "loss": 0.0855,
      "step": 11968
    },
    {
      "epoch": 0.9301367733913584,
      "grad_norm": 0.8884970545768738,
      "learning_rate": 5.3493161330432086e-06,
      "loss": 0.4866,
      "step": 11969
    },
    {
      "epoch": 0.9302144855455393,
      "grad_norm": 0.4883364737033844,
      "learning_rate": 5.3489275722723035e-06,
      "loss": 0.4782,
      "step": 11970
    },
    {
      "epoch": 0.9302921976997203,
      "grad_norm": 0.16154345870018005,
      "learning_rate": 5.348539011501399e-06,
      "loss": 0.0549,
      "step": 11971
    },
    {
      "epoch": 0.9303699098539011,
      "grad_norm": 0.10681111365556717,
      "learning_rate": 5.348150450730495e-06,
      "loss": 0.027,
      "step": 11972
    },
    {
      "epoch": 0.9304476220080821,
      "grad_norm": 1.1116397380828857,
      "learning_rate": 5.347761889959591e-06,
      "loss": 0.1785,
      "step": 11973
    },
    {
      "epoch": 0.930525334162263,
      "grad_norm": 0.4128406047821045,
      "learning_rate": 5.347373329188685e-06,
      "loss": 0.192,
      "step": 11974
    },
    {
      "epoch": 0.9306030463164439,
      "grad_norm": 0.7168096303939819,
      "learning_rate": 5.346984768417781e-06,
      "loss": 0.3926,
      "step": 11975
    },
    {
      "epoch": 0.9306807584706248,
      "grad_norm": 0.4128206670284271,
      "learning_rate": 5.346596207646877e-06,
      "loss": 0.1408,
      "step": 11976
    },
    {
      "epoch": 0.9307584706248058,
      "grad_norm": 0.36103230714797974,
      "learning_rate": 5.3462076468759716e-06,
      "loss": 0.2293,
      "step": 11977
    },
    {
      "epoch": 0.9308361827789866,
      "grad_norm": 0.2270851880311966,
      "learning_rate": 5.345819086105067e-06,
      "loss": 0.0509,
      "step": 11978
    },
    {
      "epoch": 0.9309138949331676,
      "grad_norm": 0.6593685746192932,
      "learning_rate": 5.345430525334163e-06,
      "loss": 0.2997,
      "step": 11979
    },
    {
      "epoch": 0.9309916070873485,
      "grad_norm": 0.484347403049469,
      "learning_rate": 5.345041964563258e-06,
      "loss": 0.1404,
      "step": 11980
    },
    {
      "epoch": 0.9310693192415294,
      "grad_norm": 0.33998772501945496,
      "learning_rate": 5.344653403792354e-06,
      "loss": 0.0539,
      "step": 11981
    },
    {
      "epoch": 0.9311470313957103,
      "grad_norm": 0.14679068326950073,
      "learning_rate": 5.34426484302145e-06,
      "loss": 0.0656,
      "step": 11982
    },
    {
      "epoch": 0.9312247435498912,
      "grad_norm": 0.24554535746574402,
      "learning_rate": 5.343876282250544e-06,
      "loss": 0.0812,
      "step": 11983
    },
    {
      "epoch": 0.9313024557040721,
      "grad_norm": 0.46149301528930664,
      "learning_rate": 5.34348772147964e-06,
      "loss": 0.2149,
      "step": 11984
    },
    {
      "epoch": 0.9313801678582531,
      "grad_norm": 0.2862027585506439,
      "learning_rate": 5.343099160708735e-06,
      "loss": 0.1622,
      "step": 11985
    },
    {
      "epoch": 0.9314578800124339,
      "grad_norm": 0.3963734805583954,
      "learning_rate": 5.34271059993783e-06,
      "loss": 0.2607,
      "step": 11986
    },
    {
      "epoch": 0.9315355921666149,
      "grad_norm": 0.2432594895362854,
      "learning_rate": 5.342322039166926e-06,
      "loss": 0.1205,
      "step": 11987
    },
    {
      "epoch": 0.9316133043207958,
      "grad_norm": 0.3852880597114563,
      "learning_rate": 5.341933478396022e-06,
      "loss": 0.1765,
      "step": 11988
    },
    {
      "epoch": 0.9316910164749767,
      "grad_norm": 0.1946084052324295,
      "learning_rate": 5.341544917625117e-06,
      "loss": 0.0681,
      "step": 11989
    },
    {
      "epoch": 0.9317687286291576,
      "grad_norm": 0.4534412920475006,
      "learning_rate": 5.341156356854213e-06,
      "loss": 0.2142,
      "step": 11990
    },
    {
      "epoch": 0.9318464407833386,
      "grad_norm": 0.32742834091186523,
      "learning_rate": 5.3407677960833085e-06,
      "loss": 0.1405,
      "step": 11991
    },
    {
      "epoch": 0.9319241529375194,
      "grad_norm": 0.36268699169158936,
      "learning_rate": 5.340379235312403e-06,
      "loss": 0.1135,
      "step": 11992
    },
    {
      "epoch": 0.9320018650917004,
      "grad_norm": 0.061558257788419724,
      "learning_rate": 5.339990674541498e-06,
      "loss": 0.0105,
      "step": 11993
    },
    {
      "epoch": 0.9320795772458813,
      "grad_norm": 0.256357342004776,
      "learning_rate": 5.339602113770594e-06,
      "loss": 0.1395,
      "step": 11994
    },
    {
      "epoch": 0.9321572894000622,
      "grad_norm": 0.8684170842170715,
      "learning_rate": 5.339213552999689e-06,
      "loss": 0.1844,
      "step": 11995
    },
    {
      "epoch": 0.9322350015542431,
      "grad_norm": 0.14642930030822754,
      "learning_rate": 5.338824992228785e-06,
      "loss": 0.0265,
      "step": 11996
    },
    {
      "epoch": 0.932312713708424,
      "grad_norm": 1.0796456336975098,
      "learning_rate": 5.338436431457881e-06,
      "loss": 0.2184,
      "step": 11997
    },
    {
      "epoch": 0.9323904258626049,
      "grad_norm": 0.7024854421615601,
      "learning_rate": 5.338047870686976e-06,
      "loss": 0.3123,
      "step": 11998
    },
    {
      "epoch": 0.9324681380167859,
      "grad_norm": 1.1252961158752441,
      "learning_rate": 5.3376593099160715e-06,
      "loss": 0.2806,
      "step": 11999
    },
    {
      "epoch": 0.9325458501709667,
      "grad_norm": 0.7050132751464844,
      "learning_rate": 5.337270749145167e-06,
      "loss": 0.8181,
      "step": 12000
    },
    {
      "epoch": 0.9326235623251476,
      "grad_norm": 0.3828830122947693,
      "learning_rate": 5.336882188374261e-06,
      "loss": 0.3062,
      "step": 12001
    },
    {
      "epoch": 0.9327012744793286,
      "grad_norm": 0.17897625267505646,
      "learning_rate": 5.336493627603357e-06,
      "loss": 0.0819,
      "step": 12002
    },
    {
      "epoch": 0.9327789866335094,
      "grad_norm": 0.34876877069473267,
      "learning_rate": 5.336105066832453e-06,
      "loss": 0.1567,
      "step": 12003
    },
    {
      "epoch": 0.9328566987876904,
      "grad_norm": 0.28883054852485657,
      "learning_rate": 5.335716506061549e-06,
      "loss": 0.2109,
      "step": 12004
    },
    {
      "epoch": 0.9329344109418714,
      "grad_norm": 0.29155755043029785,
      "learning_rate": 5.335327945290644e-06,
      "loss": 0.3999,
      "step": 12005
    },
    {
      "epoch": 0.9330121230960522,
      "grad_norm": 0.23011891543865204,
      "learning_rate": 5.3349393845197395e-06,
      "loss": 0.0522,
      "step": 12006
    },
    {
      "epoch": 0.9330898352502331,
      "grad_norm": 0.6847723722457886,
      "learning_rate": 5.334550823748835e-06,
      "loss": 0.4688,
      "step": 12007
    },
    {
      "epoch": 0.9331675474044141,
      "grad_norm": 0.34743762016296387,
      "learning_rate": 5.33416226297793e-06,
      "loss": 0.1861,
      "step": 12008
    },
    {
      "epoch": 0.9332452595585949,
      "grad_norm": 0.5269045829772949,
      "learning_rate": 5.333773702207026e-06,
      "loss": 0.2655,
      "step": 12009
    },
    {
      "epoch": 0.9333229717127759,
      "grad_norm": 0.11163009703159332,
      "learning_rate": 5.333385141436122e-06,
      "loss": 0.0763,
      "step": 12010
    },
    {
      "epoch": 0.9334006838669567,
      "grad_norm": 0.280653715133667,
      "learning_rate": 5.332996580665216e-06,
      "loss": 0.0877,
      "step": 12011
    },
    {
      "epoch": 0.9334783960211377,
      "grad_norm": 0.8834781646728516,
      "learning_rate": 5.332608019894312e-06,
      "loss": 0.2357,
      "step": 12012
    },
    {
      "epoch": 0.9335561081753186,
      "grad_norm": 0.27442851662635803,
      "learning_rate": 5.3322194591234075e-06,
      "loss": 0.0944,
      "step": 12013
    },
    {
      "epoch": 0.9336338203294995,
      "grad_norm": 0.25025755167007446,
      "learning_rate": 5.3318308983525025e-06,
      "loss": 0.0519,
      "step": 12014
    },
    {
      "epoch": 0.9337115324836804,
      "grad_norm": 0.5150420069694519,
      "learning_rate": 5.331442337581598e-06,
      "loss": 0.6215,
      "step": 12015
    },
    {
      "epoch": 0.9337892446378614,
      "grad_norm": 0.373542845249176,
      "learning_rate": 5.331053776810694e-06,
      "loss": 0.0849,
      "step": 12016
    },
    {
      "epoch": 0.9338669567920422,
      "grad_norm": 0.2689313292503357,
      "learning_rate": 5.330665216039789e-06,
      "loss": 0.1419,
      "step": 12017
    },
    {
      "epoch": 0.9339446689462232,
      "grad_norm": 0.15465517342090607,
      "learning_rate": 5.330276655268885e-06,
      "loss": 0.0832,
      "step": 12018
    },
    {
      "epoch": 0.9340223811004041,
      "grad_norm": 0.16408611834049225,
      "learning_rate": 5.329888094497981e-06,
      "loss": 0.0684,
      "step": 12019
    },
    {
      "epoch": 0.934100093254585,
      "grad_norm": 0.3970354199409485,
      "learning_rate": 5.329499533727075e-06,
      "loss": 0.2415,
      "step": 12020
    },
    {
      "epoch": 0.9341778054087659,
      "grad_norm": 0.43341416120529175,
      "learning_rate": 5.3291109729561705e-06,
      "loss": 0.5255,
      "step": 12021
    },
    {
      "epoch": 0.9342555175629469,
      "grad_norm": 0.5795060396194458,
      "learning_rate": 5.328722412185266e-06,
      "loss": 0.326,
      "step": 12022
    },
    {
      "epoch": 0.9343332297171277,
      "grad_norm": 0.6188023686408997,
      "learning_rate": 5.328333851414361e-06,
      "loss": 0.3387,
      "step": 12023
    },
    {
      "epoch": 0.9344109418713087,
      "grad_norm": 0.5461434721946716,
      "learning_rate": 5.327945290643457e-06,
      "loss": 0.7906,
      "step": 12024
    },
    {
      "epoch": 0.9344886540254896,
      "grad_norm": 0.34734436869621277,
      "learning_rate": 5.327556729872553e-06,
      "loss": 0.13,
      "step": 12025
    },
    {
      "epoch": 0.9345663661796705,
      "grad_norm": 0.5060615539550781,
      "learning_rate": 5.327168169101648e-06,
      "loss": 0.2835,
      "step": 12026
    },
    {
      "epoch": 0.9346440783338514,
      "grad_norm": 0.5464545488357544,
      "learning_rate": 5.326779608330744e-06,
      "loss": 0.2422,
      "step": 12027
    },
    {
      "epoch": 0.9347217904880323,
      "grad_norm": 0.36666160821914673,
      "learning_rate": 5.326391047559839e-06,
      "loss": 0.2188,
      "step": 12028
    },
    {
      "epoch": 0.9347995026422132,
      "grad_norm": 0.3579649031162262,
      "learning_rate": 5.3260024867889335e-06,
      "loss": 0.1594,
      "step": 12029
    },
    {
      "epoch": 0.9348772147963942,
      "grad_norm": 0.22684720158576965,
      "learning_rate": 5.325613926018029e-06,
      "loss": 0.0921,
      "step": 12030
    },
    {
      "epoch": 0.934954926950575,
      "grad_norm": 0.34955552220344543,
      "learning_rate": 5.325225365247125e-06,
      "loss": 0.3571,
      "step": 12031
    },
    {
      "epoch": 0.935032639104756,
      "grad_norm": 0.40438389778137207,
      "learning_rate": 5.32483680447622e-06,
      "loss": 0.3263,
      "step": 12032
    },
    {
      "epoch": 0.9351103512589369,
      "grad_norm": 0.36015620827674866,
      "learning_rate": 5.324448243705316e-06,
      "loss": 0.1998,
      "step": 12033
    },
    {
      "epoch": 0.9351880634131178,
      "grad_norm": 0.2586177587509155,
      "learning_rate": 5.324059682934412e-06,
      "loss": 0.1838,
      "step": 12034
    },
    {
      "epoch": 0.9352657755672987,
      "grad_norm": 0.12862883508205414,
      "learning_rate": 5.3236711221635074e-06,
      "loss": 0.0194,
      "step": 12035
    },
    {
      "epoch": 0.9353434877214797,
      "grad_norm": 0.5685215592384338,
      "learning_rate": 5.323282561392602e-06,
      "loss": 0.3112,
      "step": 12036
    },
    {
      "epoch": 0.9354211998756605,
      "grad_norm": 0.17380571365356445,
      "learning_rate": 5.322894000621698e-06,
      "loss": 0.0691,
      "step": 12037
    },
    {
      "epoch": 0.9354989120298415,
      "grad_norm": 0.5762618184089661,
      "learning_rate": 5.322505439850794e-06,
      "loss": 0.1699,
      "step": 12038
    },
    {
      "epoch": 0.9355766241840224,
      "grad_norm": 0.29714009165763855,
      "learning_rate": 5.322116879079888e-06,
      "loss": 0.0535,
      "step": 12039
    },
    {
      "epoch": 0.9356543363382033,
      "grad_norm": 0.5661556720733643,
      "learning_rate": 5.321728318308984e-06,
      "loss": 0.2891,
      "step": 12040
    },
    {
      "epoch": 0.9357320484923842,
      "grad_norm": 0.52834552526474,
      "learning_rate": 5.32133975753808e-06,
      "loss": 0.8212,
      "step": 12041
    },
    {
      "epoch": 0.9358097606465651,
      "grad_norm": 0.4830888509750366,
      "learning_rate": 5.320951196767175e-06,
      "loss": 0.355,
      "step": 12042
    },
    {
      "epoch": 0.935887472800746,
      "grad_norm": 0.19619089365005493,
      "learning_rate": 5.3205626359962704e-06,
      "loss": 0.0824,
      "step": 12043
    },
    {
      "epoch": 0.935965184954927,
      "grad_norm": 0.9844396114349365,
      "learning_rate": 5.320174075225366e-06,
      "loss": 0.7793,
      "step": 12044
    },
    {
      "epoch": 0.9360428971091078,
      "grad_norm": 0.11288172006607056,
      "learning_rate": 5.319785514454461e-06,
      "loss": 0.0861,
      "step": 12045
    },
    {
      "epoch": 0.9361206092632888,
      "grad_norm": 0.16956879198551178,
      "learning_rate": 5.319396953683557e-06,
      "loss": 0.0364,
      "step": 12046
    },
    {
      "epoch": 0.9361983214174697,
      "grad_norm": 0.4656113088130951,
      "learning_rate": 5.319008392912653e-06,
      "loss": 0.2699,
      "step": 12047
    },
    {
      "epoch": 0.9362760335716506,
      "grad_norm": 0.8498764038085938,
      "learning_rate": 5.318619832141747e-06,
      "loss": 0.3387,
      "step": 12048
    },
    {
      "epoch": 0.9363537457258315,
      "grad_norm": 0.4131729006767273,
      "learning_rate": 5.318231271370843e-06,
      "loss": 0.2376,
      "step": 12049
    },
    {
      "epoch": 0.9364314578800125,
      "grad_norm": 0.45458224415779114,
      "learning_rate": 5.3178427105999385e-06,
      "loss": 0.0842,
      "step": 12050
    },
    {
      "epoch": 0.9365091700341933,
      "grad_norm": 0.15770672261714935,
      "learning_rate": 5.317454149829033e-06,
      "loss": 0.0178,
      "step": 12051
    },
    {
      "epoch": 0.9365868821883743,
      "grad_norm": 0.4205114543437958,
      "learning_rate": 5.317065589058129e-06,
      "loss": 0.1558,
      "step": 12052
    },
    {
      "epoch": 0.9366645943425552,
      "grad_norm": 0.8218522071838379,
      "learning_rate": 5.316677028287225e-06,
      "loss": 0.3816,
      "step": 12053
    },
    {
      "epoch": 0.9367423064967361,
      "grad_norm": 0.20977696776390076,
      "learning_rate": 5.31628846751632e-06,
      "loss": 0.0352,
      "step": 12054
    },
    {
      "epoch": 0.936820018650917,
      "grad_norm": 0.3310326933860779,
      "learning_rate": 5.315899906745416e-06,
      "loss": 0.1314,
      "step": 12055
    },
    {
      "epoch": 0.936897730805098,
      "grad_norm": 0.5646641254425049,
      "learning_rate": 5.315511345974511e-06,
      "loss": 0.1638,
      "step": 12056
    },
    {
      "epoch": 0.9369754429592788,
      "grad_norm": 0.12069957703351974,
      "learning_rate": 5.315122785203606e-06,
      "loss": 0.0286,
      "step": 12057
    },
    {
      "epoch": 0.9370531551134598,
      "grad_norm": 0.7651422023773193,
      "learning_rate": 5.3147342244327015e-06,
      "loss": 0.3106,
      "step": 12058
    },
    {
      "epoch": 0.9371308672676406,
      "grad_norm": 0.2366759181022644,
      "learning_rate": 5.314345663661797e-06,
      "loss": 0.0485,
      "step": 12059
    },
    {
      "epoch": 0.9372085794218216,
      "grad_norm": 0.35807812213897705,
      "learning_rate": 5.313957102890892e-06,
      "loss": 0.0659,
      "step": 12060
    },
    {
      "epoch": 0.9372862915760025,
      "grad_norm": 0.5616790652275085,
      "learning_rate": 5.313568542119988e-06,
      "loss": 0.1377,
      "step": 12061
    },
    {
      "epoch": 0.9373640037301834,
      "grad_norm": 0.5628538131713867,
      "learning_rate": 5.313179981349084e-06,
      "loss": 0.3081,
      "step": 12062
    },
    {
      "epoch": 0.9374417158843643,
      "grad_norm": 0.23306560516357422,
      "learning_rate": 5.312791420578178e-06,
      "loss": 0.055,
      "step": 12063
    },
    {
      "epoch": 0.9375194280385453,
      "grad_norm": 0.5296558141708374,
      "learning_rate": 5.312402859807274e-06,
      "loss": 0.1975,
      "step": 12064
    },
    {
      "epoch": 0.9375971401927261,
      "grad_norm": 0.7003787159919739,
      "learning_rate": 5.3120142990363695e-06,
      "loss": 0.3075,
      "step": 12065
    },
    {
      "epoch": 0.9376748523469071,
      "grad_norm": 0.1917324662208557,
      "learning_rate": 5.311625738265465e-06,
      "loss": 0.0212,
      "step": 12066
    },
    {
      "epoch": 0.937752564501088,
      "grad_norm": 0.5756158232688904,
      "learning_rate": 5.31123717749456e-06,
      "loss": 0.1652,
      "step": 12067
    },
    {
      "epoch": 0.9378302766552689,
      "grad_norm": 0.19683115184307098,
      "learning_rate": 5.310848616723656e-06,
      "loss": 0.1226,
      "step": 12068
    },
    {
      "epoch": 0.9379079888094498,
      "grad_norm": 2.075674057006836,
      "learning_rate": 5.310460055952752e-06,
      "loss": 0.5281,
      "step": 12069
    },
    {
      "epoch": 0.9379857009636308,
      "grad_norm": 0.21079647541046143,
      "learning_rate": 5.310071495181847e-06,
      "loss": 0.0617,
      "step": 12070
    },
    {
      "epoch": 0.9380634131178116,
      "grad_norm": 0.08892150223255157,
      "learning_rate": 5.309682934410943e-06,
      "loss": 0.0184,
      "step": 12071
    },
    {
      "epoch": 0.9381411252719926,
      "grad_norm": 0.547725260257721,
      "learning_rate": 5.309294373640038e-06,
      "loss": 0.2078,
      "step": 12072
    },
    {
      "epoch": 0.9382188374261734,
      "grad_norm": 0.3778860867023468,
      "learning_rate": 5.3089058128691325e-06,
      "loss": 0.116,
      "step": 12073
    },
    {
      "epoch": 0.9382965495803544,
      "grad_norm": 0.3523724377155304,
      "learning_rate": 5.308517252098228e-06,
      "loss": 0.196,
      "step": 12074
    },
    {
      "epoch": 0.9383742617345353,
      "grad_norm": 0.37766754627227783,
      "learning_rate": 5.308128691327324e-06,
      "loss": 0.2079,
      "step": 12075
    },
    {
      "epoch": 0.9384519738887162,
      "grad_norm": 0.1548423171043396,
      "learning_rate": 5.307740130556419e-06,
      "loss": 0.0456,
      "step": 12076
    },
    {
      "epoch": 0.9385296860428971,
      "grad_norm": 0.3039327561855316,
      "learning_rate": 5.307351569785515e-06,
      "loss": 0.06,
      "step": 12077
    },
    {
      "epoch": 0.9386073981970781,
      "grad_norm": 0.32082656025886536,
      "learning_rate": 5.306963009014611e-06,
      "loss": 0.0514,
      "step": 12078
    },
    {
      "epoch": 0.9386851103512589,
      "grad_norm": 0.6880064606666565,
      "learning_rate": 5.3065744482437056e-06,
      "loss": 0.3855,
      "step": 12079
    },
    {
      "epoch": 0.9387628225054399,
      "grad_norm": 0.5197975635528564,
      "learning_rate": 5.306185887472801e-06,
      "loss": 0.3293,
      "step": 12080
    },
    {
      "epoch": 0.9388405346596208,
      "grad_norm": 0.136330246925354,
      "learning_rate": 5.305797326701897e-06,
      "loss": 0.027,
      "step": 12081
    },
    {
      "epoch": 0.9389182468138016,
      "grad_norm": 0.20884522795677185,
      "learning_rate": 5.305408765930991e-06,
      "loss": 0.0469,
      "step": 12082
    },
    {
      "epoch": 0.9389959589679826,
      "grad_norm": 0.20387844741344452,
      "learning_rate": 5.305020205160087e-06,
      "loss": 0.04,
      "step": 12083
    },
    {
      "epoch": 0.9390736711221636,
      "grad_norm": 0.33150240778923035,
      "learning_rate": 5.304631644389183e-06,
      "loss": 0.1862,
      "step": 12084
    },
    {
      "epoch": 0.9391513832763444,
      "grad_norm": 0.2117229551076889,
      "learning_rate": 5.304243083618278e-06,
      "loss": 0.0545,
      "step": 12085
    },
    {
      "epoch": 0.9392290954305254,
      "grad_norm": 0.9599300026893616,
      "learning_rate": 5.303854522847374e-06,
      "loss": 0.8606,
      "step": 12086
    },
    {
      "epoch": 0.9393068075847062,
      "grad_norm": 0.7571879029273987,
      "learning_rate": 5.303465962076469e-06,
      "loss": 0.0952,
      "step": 12087
    },
    {
      "epoch": 0.9393845197388871,
      "grad_norm": 0.4409630000591278,
      "learning_rate": 5.303077401305564e-06,
      "loss": 0.1186,
      "step": 12088
    },
    {
      "epoch": 0.9394622318930681,
      "grad_norm": 0.15787722170352936,
      "learning_rate": 5.30268884053466e-06,
      "loss": 0.1336,
      "step": 12089
    },
    {
      "epoch": 0.9395399440472489,
      "grad_norm": 0.20994612574577332,
      "learning_rate": 5.302300279763756e-06,
      "loss": 0.0299,
      "step": 12090
    },
    {
      "epoch": 0.9396176562014299,
      "grad_norm": 0.30994030833244324,
      "learning_rate": 5.30191171899285e-06,
      "loss": 0.1545,
      "step": 12091
    },
    {
      "epoch": 0.9396953683556108,
      "grad_norm": 0.18270054459571838,
      "learning_rate": 5.301523158221946e-06,
      "loss": 0.0302,
      "step": 12092
    },
    {
      "epoch": 0.9397730805097917,
      "grad_norm": 0.3258209526538849,
      "learning_rate": 5.301134597451042e-06,
      "loss": 0.0926,
      "step": 12093
    },
    {
      "epoch": 0.9398507926639726,
      "grad_norm": 0.9190302491188049,
      "learning_rate": 5.300746036680137e-06,
      "loss": 0.3264,
      "step": 12094
    },
    {
      "epoch": 0.9399285048181536,
      "grad_norm": 0.2897452116012573,
      "learning_rate": 5.300357475909232e-06,
      "loss": 0.1248,
      "step": 12095
    },
    {
      "epoch": 0.9400062169723344,
      "grad_norm": 0.8569088578224182,
      "learning_rate": 5.299968915138328e-06,
      "loss": 0.1774,
      "step": 12096
    },
    {
      "epoch": 0.9400839291265154,
      "grad_norm": 0.17235326766967773,
      "learning_rate": 5.299580354367424e-06,
      "loss": 0.0297,
      "step": 12097
    },
    {
      "epoch": 0.9401616412806963,
      "grad_norm": 0.8969335556030273,
      "learning_rate": 5.299191793596519e-06,
      "loss": 0.3882,
      "step": 12098
    },
    {
      "epoch": 0.9402393534348772,
      "grad_norm": 0.4258215129375458,
      "learning_rate": 5.298803232825615e-06,
      "loss": 0.2092,
      "step": 12099
    },
    {
      "epoch": 0.9403170655890581,
      "grad_norm": 0.16283851861953735,
      "learning_rate": 5.2984146720547105e-06,
      "loss": 0.0169,
      "step": 12100
    },
    {
      "epoch": 0.9403947777432391,
      "grad_norm": 0.3208739161491394,
      "learning_rate": 5.298026111283805e-06,
      "loss": 0.1534,
      "step": 12101
    },
    {
      "epoch": 0.9404724898974199,
      "grad_norm": 0.29060521721839905,
      "learning_rate": 5.2976375505129e-06,
      "loss": 0.0864,
      "step": 12102
    },
    {
      "epoch": 0.9405502020516009,
      "grad_norm": 0.23361410200595856,
      "learning_rate": 5.297248989741996e-06,
      "loss": 0.1609,
      "step": 12103
    },
    {
      "epoch": 0.9406279142057817,
      "grad_norm": 0.5113871693611145,
      "learning_rate": 5.296860428971091e-06,
      "loss": 0.1305,
      "step": 12104
    },
    {
      "epoch": 0.9407056263599627,
      "grad_norm": 0.29283449053764343,
      "learning_rate": 5.296471868200187e-06,
      "loss": 0.0676,
      "step": 12105
    },
    {
      "epoch": 0.9407833385141436,
      "grad_norm": 0.5527242422103882,
      "learning_rate": 5.296083307429283e-06,
      "loss": 0.2881,
      "step": 12106
    },
    {
      "epoch": 0.9408610506683245,
      "grad_norm": 0.4229053258895874,
      "learning_rate": 5.295694746658378e-06,
      "loss": 0.1519,
      "step": 12107
    },
    {
      "epoch": 0.9409387628225054,
      "grad_norm": 1.0092663764953613,
      "learning_rate": 5.2953061858874735e-06,
      "loss": 0.431,
      "step": 12108
    },
    {
      "epoch": 0.9410164749766864,
      "grad_norm": 0.4158296585083008,
      "learning_rate": 5.294917625116569e-06,
      "loss": 0.0823,
      "step": 12109
    },
    {
      "epoch": 0.9410941871308672,
      "grad_norm": 0.2705768942832947,
      "learning_rate": 5.294529064345663e-06,
      "loss": 0.0684,
      "step": 12110
    },
    {
      "epoch": 0.9411718992850482,
      "grad_norm": 0.6351249814033508,
      "learning_rate": 5.294140503574759e-06,
      "loss": 0.4398,
      "step": 12111
    },
    {
      "epoch": 0.9412496114392291,
      "grad_norm": 0.5436488389968872,
      "learning_rate": 5.293751942803855e-06,
      "loss": 0.2817,
      "step": 12112
    },
    {
      "epoch": 0.94132732359341,
      "grad_norm": 0.34420421719551086,
      "learning_rate": 5.29336338203295e-06,
      "loss": 0.1148,
      "step": 12113
    },
    {
      "epoch": 0.9414050357475909,
      "grad_norm": 1.1080074310302734,
      "learning_rate": 5.292974821262046e-06,
      "loss": 0.5469,
      "step": 12114
    },
    {
      "epoch": 0.9414827479017719,
      "grad_norm": 0.4195074439048767,
      "learning_rate": 5.2925862604911415e-06,
      "loss": 0.2779,
      "step": 12115
    },
    {
      "epoch": 0.9415604600559527,
      "grad_norm": 0.20793648064136505,
      "learning_rate": 5.2921976997202365e-06,
      "loss": 0.1845,
      "step": 12116
    },
    {
      "epoch": 0.9416381722101337,
      "grad_norm": 0.12770074605941772,
      "learning_rate": 5.291809138949332e-06,
      "loss": 0.0529,
      "step": 12117
    },
    {
      "epoch": 0.9417158843643145,
      "grad_norm": 1.0778789520263672,
      "learning_rate": 5.291420578178428e-06,
      "loss": 0.4289,
      "step": 12118
    },
    {
      "epoch": 0.9417935965184955,
      "grad_norm": 0.5648854970932007,
      "learning_rate": 5.291032017407522e-06,
      "loss": 0.2062,
      "step": 12119
    },
    {
      "epoch": 0.9418713086726764,
      "grad_norm": 0.32393878698349,
      "learning_rate": 5.290643456636618e-06,
      "loss": 0.1421,
      "step": 12120
    },
    {
      "epoch": 0.9419490208268573,
      "grad_norm": 0.7891618013381958,
      "learning_rate": 5.290254895865714e-06,
      "loss": 0.1769,
      "step": 12121
    },
    {
      "epoch": 0.9420267329810382,
      "grad_norm": 0.38346996903419495,
      "learning_rate": 5.289866335094809e-06,
      "loss": 0.0911,
      "step": 12122
    },
    {
      "epoch": 0.9421044451352192,
      "grad_norm": 0.38996708393096924,
      "learning_rate": 5.2894777743239045e-06,
      "loss": 0.3135,
      "step": 12123
    },
    {
      "epoch": 0.9421821572894,
      "grad_norm": 0.6602193713188171,
      "learning_rate": 5.289089213553e-06,
      "loss": 0.4212,
      "step": 12124
    },
    {
      "epoch": 0.942259869443581,
      "grad_norm": 0.24255619943141937,
      "learning_rate": 5.288700652782096e-06,
      "loss": 0.0775,
      "step": 12125
    },
    {
      "epoch": 0.9423375815977619,
      "grad_norm": 0.5370789766311646,
      "learning_rate": 5.288312092011191e-06,
      "loss": 0.4637,
      "step": 12126
    },
    {
      "epoch": 0.9424152937519428,
      "grad_norm": 0.30265286564826965,
      "learning_rate": 5.287923531240287e-06,
      "loss": 0.0449,
      "step": 12127
    },
    {
      "epoch": 0.9424930059061237,
      "grad_norm": 0.25847572088241577,
      "learning_rate": 5.287534970469383e-06,
      "loss": 0.1185,
      "step": 12128
    },
    {
      "epoch": 0.9425707180603047,
      "grad_norm": 0.24756725132465363,
      "learning_rate": 5.287146409698477e-06,
      "loss": 0.0549,
      "step": 12129
    },
    {
      "epoch": 0.9426484302144855,
      "grad_norm": 0.9628839492797852,
      "learning_rate": 5.2867578489275726e-06,
      "loss": 0.6319,
      "step": 12130
    },
    {
      "epoch": 0.9427261423686665,
      "grad_norm": 0.2977910339832306,
      "learning_rate": 5.286369288156668e-06,
      "loss": 0.058,
      "step": 12131
    },
    {
      "epoch": 0.9428038545228474,
      "grad_norm": 0.3801894187927246,
      "learning_rate": 5.285980727385763e-06,
      "loss": 0.0753,
      "step": 12132
    },
    {
      "epoch": 0.9428815666770283,
      "grad_norm": 0.4757774770259857,
      "learning_rate": 5.285592166614859e-06,
      "loss": 0.1224,
      "step": 12133
    },
    {
      "epoch": 0.9429592788312092,
      "grad_norm": 0.6650996208190918,
      "learning_rate": 5.285203605843955e-06,
      "loss": 0.565,
      "step": 12134
    },
    {
      "epoch": 0.9430369909853901,
      "grad_norm": 0.4118850827217102,
      "learning_rate": 5.28481504507305e-06,
      "loss": 0.1281,
      "step": 12135
    },
    {
      "epoch": 0.943114703139571,
      "grad_norm": 0.14693252742290497,
      "learning_rate": 5.284426484302146e-06,
      "loss": 0.0666,
      "step": 12136
    },
    {
      "epoch": 0.943192415293752,
      "grad_norm": 0.2525651752948761,
      "learning_rate": 5.2840379235312415e-06,
      "loss": 0.0432,
      "step": 12137
    },
    {
      "epoch": 0.9432701274479328,
      "grad_norm": 0.22501270473003387,
      "learning_rate": 5.2836493627603356e-06,
      "loss": 0.1014,
      "step": 12138
    },
    {
      "epoch": 0.9433478396021138,
      "grad_norm": 1.0585545301437378,
      "learning_rate": 5.283260801989431e-06,
      "loss": 0.2437,
      "step": 12139
    },
    {
      "epoch": 0.9434255517562947,
      "grad_norm": 0.5259090662002563,
      "learning_rate": 5.282872241218527e-06,
      "loss": 0.3811,
      "step": 12140
    },
    {
      "epoch": 0.9435032639104756,
      "grad_norm": 0.4575243592262268,
      "learning_rate": 5.282483680447622e-06,
      "loss": 0.2694,
      "step": 12141
    },
    {
      "epoch": 0.9435809760646565,
      "grad_norm": 0.639870822429657,
      "learning_rate": 5.282095119676718e-06,
      "loss": 0.3784,
      "step": 12142
    },
    {
      "epoch": 0.9436586882188375,
      "grad_norm": 0.8121074438095093,
      "learning_rate": 5.281706558905814e-06,
      "loss": 0.6308,
      "step": 12143
    },
    {
      "epoch": 0.9437364003730183,
      "grad_norm": 0.22614890336990356,
      "learning_rate": 5.281317998134909e-06,
      "loss": 0.096,
      "step": 12144
    },
    {
      "epoch": 0.9438141125271993,
      "grad_norm": 0.3265380561351776,
      "learning_rate": 5.2809294373640044e-06,
      "loss": 0.0271,
      "step": 12145
    },
    {
      "epoch": 0.9438918246813802,
      "grad_norm": 0.29393041133880615,
      "learning_rate": 5.2805408765931e-06,
      "loss": 0.1146,
      "step": 12146
    },
    {
      "epoch": 0.9439695368355611,
      "grad_norm": 0.2385222315788269,
      "learning_rate": 5.280152315822194e-06,
      "loss": 0.1195,
      "step": 12147
    },
    {
      "epoch": 0.944047248989742,
      "grad_norm": 0.4292305111885071,
      "learning_rate": 5.27976375505129e-06,
      "loss": 0.3231,
      "step": 12148
    },
    {
      "epoch": 0.9441249611439229,
      "grad_norm": 0.10154388099908829,
      "learning_rate": 5.279375194280386e-06,
      "loss": 0.0183,
      "step": 12149
    },
    {
      "epoch": 0.9442026732981038,
      "grad_norm": 0.13693326711654663,
      "learning_rate": 5.278986633509481e-06,
      "loss": 0.0308,
      "step": 12150
    },
    {
      "epoch": 0.9442803854522848,
      "grad_norm": 1.1190941333770752,
      "learning_rate": 5.278598072738577e-06,
      "loss": 0.1551,
      "step": 12151
    },
    {
      "epoch": 0.9443580976064656,
      "grad_norm": 0.5691196322441101,
      "learning_rate": 5.2782095119676725e-06,
      "loss": 0.2177,
      "step": 12152
    },
    {
      "epoch": 0.9444358097606466,
      "grad_norm": 0.08229150623083115,
      "learning_rate": 5.2778209511967674e-06,
      "loss": 0.039,
      "step": 12153
    },
    {
      "epoch": 0.9445135219148275,
      "grad_norm": 0.48235857486724854,
      "learning_rate": 5.277432390425863e-06,
      "loss": 0.4934,
      "step": 12154
    },
    {
      "epoch": 0.9445912340690084,
      "grad_norm": 0.8546832203865051,
      "learning_rate": 5.277043829654959e-06,
      "loss": 0.3105,
      "step": 12155
    },
    {
      "epoch": 0.9446689462231893,
      "grad_norm": 0.35328686237335205,
      "learning_rate": 5.276655268884055e-06,
      "loss": 0.0998,
      "step": 12156
    },
    {
      "epoch": 0.9447466583773703,
      "grad_norm": 0.49514132738113403,
      "learning_rate": 5.276266708113149e-06,
      "loss": 0.1328,
      "step": 12157
    },
    {
      "epoch": 0.9448243705315511,
      "grad_norm": 0.4319199323654175,
      "learning_rate": 5.275878147342245e-06,
      "loss": 0.2696,
      "step": 12158
    },
    {
      "epoch": 0.9449020826857321,
      "grad_norm": 0.5681377053260803,
      "learning_rate": 5.2754895865713405e-06,
      "loss": 0.0735,
      "step": 12159
    },
    {
      "epoch": 0.944979794839913,
      "grad_norm": 0.34181538224220276,
      "learning_rate": 5.2751010258004355e-06,
      "loss": 0.2243,
      "step": 12160
    },
    {
      "epoch": 0.9450575069940939,
      "grad_norm": 0.2641308903694153,
      "learning_rate": 5.274712465029531e-06,
      "loss": 0.1115,
      "step": 12161
    },
    {
      "epoch": 0.9451352191482748,
      "grad_norm": 0.26179975271224976,
      "learning_rate": 5.274323904258627e-06,
      "loss": 0.092,
      "step": 12162
    },
    {
      "epoch": 0.9452129313024557,
      "grad_norm": 0.35954201221466064,
      "learning_rate": 5.273935343487722e-06,
      "loss": 0.245,
      "step": 12163
    },
    {
      "epoch": 0.9452906434566366,
      "grad_norm": 0.5531539916992188,
      "learning_rate": 5.273546782716818e-06,
      "loss": 0.2549,
      "step": 12164
    },
    {
      "epoch": 0.9453683556108176,
      "grad_norm": 0.2491532415151596,
      "learning_rate": 5.273158221945914e-06,
      "loss": 0.0692,
      "step": 12165
    },
    {
      "epoch": 0.9454460677649984,
      "grad_norm": 0.47362855076789856,
      "learning_rate": 5.272769661175008e-06,
      "loss": 0.1328,
      "step": 12166
    },
    {
      "epoch": 0.9455237799191794,
      "grad_norm": 0.495206743478775,
      "learning_rate": 5.2723811004041035e-06,
      "loss": 0.3668,
      "step": 12167
    },
    {
      "epoch": 0.9456014920733603,
      "grad_norm": 0.2285325974225998,
      "learning_rate": 5.271992539633199e-06,
      "loss": 0.0742,
      "step": 12168
    },
    {
      "epoch": 0.9456792042275411,
      "grad_norm": 0.4223693013191223,
      "learning_rate": 5.271603978862294e-06,
      "loss": 0.1913,
      "step": 12169
    },
    {
      "epoch": 0.9457569163817221,
      "grad_norm": 0.2983587086200714,
      "learning_rate": 5.27121541809139e-06,
      "loss": 0.091,
      "step": 12170
    },
    {
      "epoch": 0.945834628535903,
      "grad_norm": 0.39713066816329956,
      "learning_rate": 5.270826857320486e-06,
      "loss": 0.1823,
      "step": 12171
    },
    {
      "epoch": 0.9459123406900839,
      "grad_norm": 0.3676493167877197,
      "learning_rate": 5.270438296549581e-06,
      "loss": 0.3074,
      "step": 12172
    },
    {
      "epoch": 0.9459900528442649,
      "grad_norm": 0.3149837851524353,
      "learning_rate": 5.270049735778677e-06,
      "loss": 0.1223,
      "step": 12173
    },
    {
      "epoch": 0.9460677649984458,
      "grad_norm": 0.19993580877780914,
      "learning_rate": 5.269661175007772e-06,
      "loss": 0.0433,
      "step": 12174
    },
    {
      "epoch": 0.9461454771526266,
      "grad_norm": 0.28776153922080994,
      "learning_rate": 5.2692726142368665e-06,
      "loss": 0.0774,
      "step": 12175
    },
    {
      "epoch": 0.9462231893068076,
      "grad_norm": 0.5623649954795837,
      "learning_rate": 5.268884053465962e-06,
      "loss": 0.5221,
      "step": 12176
    },
    {
      "epoch": 0.9463009014609886,
      "grad_norm": 0.09348808228969574,
      "learning_rate": 5.268495492695058e-06,
      "loss": 0.0548,
      "step": 12177
    },
    {
      "epoch": 0.9463786136151694,
      "grad_norm": 0.22689378261566162,
      "learning_rate": 5.268106931924153e-06,
      "loss": 0.082,
      "step": 12178
    },
    {
      "epoch": 0.9464563257693503,
      "grad_norm": 0.07197970896959305,
      "learning_rate": 5.267718371153249e-06,
      "loss": 0.043,
      "step": 12179
    },
    {
      "epoch": 0.9465340379235312,
      "grad_norm": 0.35569024085998535,
      "learning_rate": 5.267329810382345e-06,
      "loss": 0.2645,
      "step": 12180
    },
    {
      "epoch": 0.9466117500777121,
      "grad_norm": 0.20392169058322906,
      "learning_rate": 5.2669412496114396e-06,
      "loss": 0.074,
      "step": 12181
    },
    {
      "epoch": 0.9466894622318931,
      "grad_norm": 0.7590749263763428,
      "learning_rate": 5.2665526888405345e-06,
      "loss": 0.242,
      "step": 12182
    },
    {
      "epoch": 0.9467671743860739,
      "grad_norm": 0.26510876417160034,
      "learning_rate": 5.26616412806963e-06,
      "loss": 0.1021,
      "step": 12183
    },
    {
      "epoch": 0.9468448865402549,
      "grad_norm": 0.2168315351009369,
      "learning_rate": 5.265775567298725e-06,
      "loss": 0.0359,
      "step": 12184
    },
    {
      "epoch": 0.9469225986944358,
      "grad_norm": 0.5382965207099915,
      "learning_rate": 5.265387006527821e-06,
      "loss": 0.1263,
      "step": 12185
    },
    {
      "epoch": 0.9470003108486167,
      "grad_norm": 0.3616340160369873,
      "learning_rate": 5.264998445756917e-06,
      "loss": 0.245,
      "step": 12186
    },
    {
      "epoch": 0.9470780230027976,
      "grad_norm": 0.7820506691932678,
      "learning_rate": 5.264609884986013e-06,
      "loss": 0.2726,
      "step": 12187
    },
    {
      "epoch": 0.9471557351569786,
      "grad_norm": 0.479716956615448,
      "learning_rate": 5.264221324215108e-06,
      "loss": 0.2056,
      "step": 12188
    },
    {
      "epoch": 0.9472334473111594,
      "grad_norm": 0.414914071559906,
      "learning_rate": 5.263832763444203e-06,
      "loss": 0.3801,
      "step": 12189
    },
    {
      "epoch": 0.9473111594653404,
      "grad_norm": 0.8029688000679016,
      "learning_rate": 5.263444202673299e-06,
      "loss": 0.2857,
      "step": 12190
    },
    {
      "epoch": 0.9473888716195213,
      "grad_norm": 0.09844502061605453,
      "learning_rate": 5.263055641902393e-06,
      "loss": 0.0285,
      "step": 12191
    },
    {
      "epoch": 0.9474665837737022,
      "grad_norm": 1.1665133237838745,
      "learning_rate": 5.262667081131489e-06,
      "loss": 0.4677,
      "step": 12192
    },
    {
      "epoch": 0.9475442959278831,
      "grad_norm": 0.5369105339050293,
      "learning_rate": 5.262278520360585e-06,
      "loss": 0.1551,
      "step": 12193
    },
    {
      "epoch": 0.947622008082064,
      "grad_norm": 0.32484951615333557,
      "learning_rate": 5.26188995958968e-06,
      "loss": 0.109,
      "step": 12194
    },
    {
      "epoch": 0.9476997202362449,
      "grad_norm": 0.6362106800079346,
      "learning_rate": 5.261501398818776e-06,
      "loss": 0.3278,
      "step": 12195
    },
    {
      "epoch": 0.9477774323904259,
      "grad_norm": 0.5448357462882996,
      "learning_rate": 5.2611128380478714e-06,
      "loss": 0.117,
      "step": 12196
    },
    {
      "epoch": 0.9478551445446067,
      "grad_norm": 0.6450823545455933,
      "learning_rate": 5.260724277276966e-06,
      "loss": 0.3604,
      "step": 12197
    },
    {
      "epoch": 0.9479328566987877,
      "grad_norm": 0.700096607208252,
      "learning_rate": 5.260335716506062e-06,
      "loss": 0.5944,
      "step": 12198
    },
    {
      "epoch": 0.9480105688529686,
      "grad_norm": 0.645451545715332,
      "learning_rate": 5.259947155735158e-06,
      "loss": 0.1173,
      "step": 12199
    },
    {
      "epoch": 0.9480882810071495,
      "grad_norm": 0.4480327069759369,
      "learning_rate": 5.259558594964252e-06,
      "loss": 0.2809,
      "step": 12200
    },
    {
      "epoch": 0.9481659931613304,
      "grad_norm": 0.416205495595932,
      "learning_rate": 5.259170034193348e-06,
      "loss": 0.3237,
      "step": 12201
    },
    {
      "epoch": 0.9482437053155114,
      "grad_norm": 0.4476471245288849,
      "learning_rate": 5.258781473422444e-06,
      "loss": 0.1328,
      "step": 12202
    },
    {
      "epoch": 0.9483214174696922,
      "grad_norm": 0.5437174439430237,
      "learning_rate": 5.258392912651539e-06,
      "loss": 0.3845,
      "step": 12203
    },
    {
      "epoch": 0.9483991296238732,
      "grad_norm": 0.6834957003593445,
      "learning_rate": 5.2580043518806344e-06,
      "loss": 0.2651,
      "step": 12204
    },
    {
      "epoch": 0.9484768417780541,
      "grad_norm": 0.5468155145645142,
      "learning_rate": 5.25761579110973e-06,
      "loss": 0.209,
      "step": 12205
    },
    {
      "epoch": 0.948554553932235,
      "grad_norm": 0.3306371569633484,
      "learning_rate": 5.257227230338825e-06,
      "loss": 0.0458,
      "step": 12206
    },
    {
      "epoch": 0.9486322660864159,
      "grad_norm": 0.19532153010368347,
      "learning_rate": 5.256838669567921e-06,
      "loss": 0.0368,
      "step": 12207
    },
    {
      "epoch": 0.9487099782405968,
      "grad_norm": 0.23984237015247345,
      "learning_rate": 5.256450108797017e-06,
      "loss": 0.1698,
      "step": 12208
    },
    {
      "epoch": 0.9487876903947777,
      "grad_norm": 0.0794578492641449,
      "learning_rate": 5.256061548026111e-06,
      "loss": 0.0198,
      "step": 12209
    },
    {
      "epoch": 0.9488654025489587,
      "grad_norm": 0.19713854789733887,
      "learning_rate": 5.255672987255207e-06,
      "loss": 0.025,
      "step": 12210
    },
    {
      "epoch": 0.9489431147031395,
      "grad_norm": 0.3642061948776245,
      "learning_rate": 5.2552844264843025e-06,
      "loss": 0.1833,
      "step": 12211
    },
    {
      "epoch": 0.9490208268573205,
      "grad_norm": 0.47174304723739624,
      "learning_rate": 5.254895865713397e-06,
      "loss": 0.288,
      "step": 12212
    },
    {
      "epoch": 0.9490985390115014,
      "grad_norm": 0.4146033525466919,
      "learning_rate": 5.254507304942493e-06,
      "loss": 0.1893,
      "step": 12213
    },
    {
      "epoch": 0.9491762511656823,
      "grad_norm": 0.22122833132743835,
      "learning_rate": 5.254118744171589e-06,
      "loss": 0.1113,
      "step": 12214
    },
    {
      "epoch": 0.9492539633198632,
      "grad_norm": 0.388847678899765,
      "learning_rate": 5.253730183400684e-06,
      "loss": 0.1822,
      "step": 12215
    },
    {
      "epoch": 0.9493316754740442,
      "grad_norm": 0.2360154092311859,
      "learning_rate": 5.25334162262978e-06,
      "loss": 0.1207,
      "step": 12216
    },
    {
      "epoch": 0.949409387628225,
      "grad_norm": 0.28488388657569885,
      "learning_rate": 5.2529530618588756e-06,
      "loss": 0.1262,
      "step": 12217
    },
    {
      "epoch": 0.949487099782406,
      "grad_norm": 0.2122768759727478,
      "learning_rate": 5.252564501087971e-06,
      "loss": 0.029,
      "step": 12218
    },
    {
      "epoch": 0.9495648119365869,
      "grad_norm": 1.2346084117889404,
      "learning_rate": 5.2521759403170654e-06,
      "loss": 0.2673,
      "step": 12219
    },
    {
      "epoch": 0.9496425240907678,
      "grad_norm": 0.04403684288263321,
      "learning_rate": 5.251787379546161e-06,
      "loss": 0.0196,
      "step": 12220
    },
    {
      "epoch": 0.9497202362449487,
      "grad_norm": 0.44198888540267944,
      "learning_rate": 5.251398818775257e-06,
      "loss": 0.3708,
      "step": 12221
    },
    {
      "epoch": 0.9497979483991297,
      "grad_norm": 0.1972871869802475,
      "learning_rate": 5.251010258004352e-06,
      "loss": 0.0511,
      "step": 12222
    },
    {
      "epoch": 0.9498756605533105,
      "grad_norm": 0.4183390140533447,
      "learning_rate": 5.250621697233448e-06,
      "loss": 0.1129,
      "step": 12223
    },
    {
      "epoch": 0.9499533727074915,
      "grad_norm": 0.46557268500328064,
      "learning_rate": 5.250233136462544e-06,
      "loss": 0.3785,
      "step": 12224
    },
    {
      "epoch": 0.9500310848616723,
      "grad_norm": 0.21150916814804077,
      "learning_rate": 5.2498445756916385e-06,
      "loss": 0.0525,
      "step": 12225
    },
    {
      "epoch": 0.9501087970158533,
      "grad_norm": 0.3536720871925354,
      "learning_rate": 5.249456014920734e-06,
      "loss": 0.254,
      "step": 12226
    },
    {
      "epoch": 0.9501865091700342,
      "grad_norm": 0.36552324891090393,
      "learning_rate": 5.24906745414983e-06,
      "loss": 0.0891,
      "step": 12227
    },
    {
      "epoch": 0.9502642213242151,
      "grad_norm": 0.1852692812681198,
      "learning_rate": 5.248678893378924e-06,
      "loss": 0.0552,
      "step": 12228
    },
    {
      "epoch": 0.950341933478396,
      "grad_norm": 0.4109145998954773,
      "learning_rate": 5.24829033260802e-06,
      "loss": 0.271,
      "step": 12229
    },
    {
      "epoch": 0.950419645632577,
      "grad_norm": 0.7450968027114868,
      "learning_rate": 5.247901771837116e-06,
      "loss": 0.809,
      "step": 12230
    },
    {
      "epoch": 0.9504973577867578,
      "grad_norm": 1.2375805377960205,
      "learning_rate": 5.247513211066211e-06,
      "loss": 0.8543,
      "step": 12231
    },
    {
      "epoch": 0.9505750699409388,
      "grad_norm": 0.4717547297477722,
      "learning_rate": 5.2471246502953066e-06,
      "loss": 0.5096,
      "step": 12232
    },
    {
      "epoch": 0.9506527820951197,
      "grad_norm": 0.46125203371047974,
      "learning_rate": 5.246736089524402e-06,
      "loss": 0.264,
      "step": 12233
    },
    {
      "epoch": 0.9507304942493006,
      "grad_norm": 0.24777992069721222,
      "learning_rate": 5.246347528753497e-06,
      "loss": 0.0816,
      "step": 12234
    },
    {
      "epoch": 0.9508082064034815,
      "grad_norm": 0.47447842359542847,
      "learning_rate": 5.245958967982593e-06,
      "loss": 0.1898,
      "step": 12235
    },
    {
      "epoch": 0.9508859185576625,
      "grad_norm": 0.165974423289299,
      "learning_rate": 5.245570407211689e-06,
      "loss": 0.0683,
      "step": 12236
    },
    {
      "epoch": 0.9509636307118433,
      "grad_norm": 0.2918134927749634,
      "learning_rate": 5.245181846440783e-06,
      "loss": 0.1101,
      "step": 12237
    },
    {
      "epoch": 0.9510413428660243,
      "grad_norm": 0.13403670489788055,
      "learning_rate": 5.244793285669879e-06,
      "loss": 0.0477,
      "step": 12238
    },
    {
      "epoch": 0.9511190550202051,
      "grad_norm": 0.11851346492767334,
      "learning_rate": 5.244404724898975e-06,
      "loss": 0.0257,
      "step": 12239
    },
    {
      "epoch": 0.9511967671743861,
      "grad_norm": 0.2676348090171814,
      "learning_rate": 5.2440161641280696e-06,
      "loss": 0.245,
      "step": 12240
    },
    {
      "epoch": 0.951274479328567,
      "grad_norm": 0.7633982300758362,
      "learning_rate": 5.243627603357165e-06,
      "loss": 0.3804,
      "step": 12241
    },
    {
      "epoch": 0.9513521914827479,
      "grad_norm": 0.30129697918891907,
      "learning_rate": 5.243239042586261e-06,
      "loss": 0.157,
      "step": 12242
    },
    {
      "epoch": 0.9514299036369288,
      "grad_norm": 0.145543172955513,
      "learning_rate": 5.242850481815356e-06,
      "loss": 0.0584,
      "step": 12243
    },
    {
      "epoch": 0.9515076157911098,
      "grad_norm": 0.2644636332988739,
      "learning_rate": 5.242461921044452e-06,
      "loss": 0.0293,
      "step": 12244
    },
    {
      "epoch": 0.9515853279452906,
      "grad_norm": 0.3836205303668976,
      "learning_rate": 5.242073360273548e-06,
      "loss": 0.2255,
      "step": 12245
    },
    {
      "epoch": 0.9516630400994716,
      "grad_norm": 0.527770459651947,
      "learning_rate": 5.2416847995026435e-06,
      "loss": 0.5898,
      "step": 12246
    },
    {
      "epoch": 0.9517407522536525,
      "grad_norm": 0.41688910126686096,
      "learning_rate": 5.241296238731738e-06,
      "loss": 0.1136,
      "step": 12247
    },
    {
      "epoch": 0.9518184644078334,
      "grad_norm": 0.3104170560836792,
      "learning_rate": 5.240907677960833e-06,
      "loss": 0.2242,
      "step": 12248
    },
    {
      "epoch": 0.9518961765620143,
      "grad_norm": 0.6374518871307373,
      "learning_rate": 5.240519117189929e-06,
      "loss": 0.2998,
      "step": 12249
    },
    {
      "epoch": 0.9519738887161953,
      "grad_norm": 0.3478284776210785,
      "learning_rate": 5.240130556419024e-06,
      "loss": 0.356,
      "step": 12250
    },
    {
      "epoch": 0.9520516008703761,
      "grad_norm": 0.5744078159332275,
      "learning_rate": 5.23974199564812e-06,
      "loss": 0.1796,
      "step": 12251
    },
    {
      "epoch": 0.9521293130245571,
      "grad_norm": 0.5359140038490295,
      "learning_rate": 5.239353434877216e-06,
      "loss": 0.4344,
      "step": 12252
    },
    {
      "epoch": 0.952207025178738,
      "grad_norm": 0.23515790700912476,
      "learning_rate": 5.238964874106311e-06,
      "loss": 0.1249,
      "step": 12253
    },
    {
      "epoch": 0.9522847373329189,
      "grad_norm": 0.9884894490242004,
      "learning_rate": 5.2385763133354065e-06,
      "loss": 0.5539,
      "step": 12254
    },
    {
      "epoch": 0.9523624494870998,
      "grad_norm": 0.4709089398384094,
      "learning_rate": 5.238187752564502e-06,
      "loss": 0.2733,
      "step": 12255
    },
    {
      "epoch": 0.9524401616412806,
      "grad_norm": 0.25209856033325195,
      "learning_rate": 5.237799191793596e-06,
      "loss": 0.0725,
      "step": 12256
    },
    {
      "epoch": 0.9525178737954616,
      "grad_norm": 0.37498852610588074,
      "learning_rate": 5.237410631022692e-06,
      "loss": 0.3295,
      "step": 12257
    },
    {
      "epoch": 0.9525955859496426,
      "grad_norm": 0.5013213157653809,
      "learning_rate": 5.237022070251788e-06,
      "loss": 0.3059,
      "step": 12258
    },
    {
      "epoch": 0.9526732981038234,
      "grad_norm": 0.37897542119026184,
      "learning_rate": 5.236633509480883e-06,
      "loss": 0.3975,
      "step": 12259
    },
    {
      "epoch": 0.9527510102580043,
      "grad_norm": 0.4738810956478119,
      "learning_rate": 5.236244948709979e-06,
      "loss": 0.1268,
      "step": 12260
    },
    {
      "epoch": 0.9528287224121853,
      "grad_norm": 0.6687389612197876,
      "learning_rate": 5.2358563879390745e-06,
      "loss": 0.2,
      "step": 12261
    },
    {
      "epoch": 0.9529064345663661,
      "grad_norm": 0.14906126260757446,
      "learning_rate": 5.2354678271681695e-06,
      "loss": 0.0534,
      "step": 12262
    },
    {
      "epoch": 0.9529841467205471,
      "grad_norm": 0.19091558456420898,
      "learning_rate": 5.235079266397265e-06,
      "loss": 0.0607,
      "step": 12263
    },
    {
      "epoch": 0.953061858874728,
      "grad_norm": 0.21915225684642792,
      "learning_rate": 5.234690705626361e-06,
      "loss": 0.1076,
      "step": 12264
    },
    {
      "epoch": 0.9531395710289089,
      "grad_norm": 0.575898289680481,
      "learning_rate": 5.234302144855455e-06,
      "loss": 0.2402,
      "step": 12265
    },
    {
      "epoch": 0.9532172831830898,
      "grad_norm": 0.3638366162776947,
      "learning_rate": 5.233913584084551e-06,
      "loss": 0.2847,
      "step": 12266
    },
    {
      "epoch": 0.9532949953372708,
      "grad_norm": 0.6617895364761353,
      "learning_rate": 5.233525023313647e-06,
      "loss": 0.3294,
      "step": 12267
    },
    {
      "epoch": 0.9533727074914516,
      "grad_norm": 0.2993945777416229,
      "learning_rate": 5.233136462542742e-06,
      "loss": 0.1535,
      "step": 12268
    },
    {
      "epoch": 0.9534504196456326,
      "grad_norm": 0.6015808582305908,
      "learning_rate": 5.2327479017718375e-06,
      "loss": 0.4227,
      "step": 12269
    },
    {
      "epoch": 0.9535281317998134,
      "grad_norm": 0.10345462709665298,
      "learning_rate": 5.232359341000933e-06,
      "loss": 0.045,
      "step": 12270
    },
    {
      "epoch": 0.9536058439539944,
      "grad_norm": 0.2908545434474945,
      "learning_rate": 5.231970780230028e-06,
      "loss": 0.2261,
      "step": 12271
    },
    {
      "epoch": 0.9536835561081753,
      "grad_norm": 0.5742756724357605,
      "learning_rate": 5.231582219459124e-06,
      "loss": 0.2568,
      "step": 12272
    },
    {
      "epoch": 0.9537612682623562,
      "grad_norm": 0.3369372487068176,
      "learning_rate": 5.23119365868822e-06,
      "loss": 0.2291,
      "step": 12273
    },
    {
      "epoch": 0.9538389804165371,
      "grad_norm": 0.26768746972084045,
      "learning_rate": 5.230805097917314e-06,
      "loss": 0.0465,
      "step": 12274
    },
    {
      "epoch": 0.9539166925707181,
      "grad_norm": 0.35843345522880554,
      "learning_rate": 5.23041653714641e-06,
      "loss": 0.0902,
      "step": 12275
    },
    {
      "epoch": 0.9539944047248989,
      "grad_norm": 0.23595061898231506,
      "learning_rate": 5.2300279763755055e-06,
      "loss": 0.0666,
      "step": 12276
    },
    {
      "epoch": 0.9540721168790799,
      "grad_norm": 0.2570522427558899,
      "learning_rate": 5.229639415604601e-06,
      "loss": 0.0806,
      "step": 12277
    },
    {
      "epoch": 0.9541498290332608,
      "grad_norm": 0.263864129781723,
      "learning_rate": 5.229250854833696e-06,
      "loss": 0.141,
      "step": 12278
    },
    {
      "epoch": 0.9542275411874417,
      "grad_norm": 0.8178929686546326,
      "learning_rate": 5.228862294062792e-06,
      "loss": 0.1458,
      "step": 12279
    },
    {
      "epoch": 0.9543052533416226,
      "grad_norm": 0.3538209795951843,
      "learning_rate": 5.228473733291888e-06,
      "loss": 0.1701,
      "step": 12280
    },
    {
      "epoch": 0.9543829654958036,
      "grad_norm": 0.30265843868255615,
      "learning_rate": 5.228085172520983e-06,
      "loss": 0.0461,
      "step": 12281
    },
    {
      "epoch": 0.9544606776499844,
      "grad_norm": 0.2423604428768158,
      "learning_rate": 5.227696611750079e-06,
      "loss": 0.0956,
      "step": 12282
    },
    {
      "epoch": 0.9545383898041654,
      "grad_norm": 0.41684094071388245,
      "learning_rate": 5.227308050979174e-06,
      "loss": 0.1081,
      "step": 12283
    },
    {
      "epoch": 0.9546161019583462,
      "grad_norm": 0.7622475028038025,
      "learning_rate": 5.2269194902082685e-06,
      "loss": 0.2163,
      "step": 12284
    },
    {
      "epoch": 0.9546938141125272,
      "grad_norm": 0.2047813981771469,
      "learning_rate": 5.226530929437364e-06,
      "loss": 0.0243,
      "step": 12285
    },
    {
      "epoch": 0.9547715262667081,
      "grad_norm": 0.2027936577796936,
      "learning_rate": 5.22614236866646e-06,
      "loss": 0.0658,
      "step": 12286
    },
    {
      "epoch": 0.954849238420889,
      "grad_norm": 0.5334393978118896,
      "learning_rate": 5.225753807895555e-06,
      "loss": 0.1227,
      "step": 12287
    },
    {
      "epoch": 0.9549269505750699,
      "grad_norm": 1.9934303760528564,
      "learning_rate": 5.225365247124651e-06,
      "loss": 0.5336,
      "step": 12288
    },
    {
      "epoch": 0.9550046627292509,
      "grad_norm": 0.9767347574234009,
      "learning_rate": 5.224976686353747e-06,
      "loss": 0.5509,
      "step": 12289
    },
    {
      "epoch": 0.9550823748834317,
      "grad_norm": 0.16726046800613403,
      "learning_rate": 5.224588125582842e-06,
      "loss": 0.0198,
      "step": 12290
    },
    {
      "epoch": 0.9551600870376127,
      "grad_norm": 0.4406206011772156,
      "learning_rate": 5.224199564811937e-06,
      "loss": 0.1049,
      "step": 12291
    },
    {
      "epoch": 0.9552377991917936,
      "grad_norm": 0.8249695301055908,
      "learning_rate": 5.223811004041033e-06,
      "loss": 0.7507,
      "step": 12292
    },
    {
      "epoch": 0.9553155113459745,
      "grad_norm": 0.5204582810401917,
      "learning_rate": 5.223422443270127e-06,
      "loss": 0.456,
      "step": 12293
    },
    {
      "epoch": 0.9553932235001554,
      "grad_norm": 0.3681967854499817,
      "learning_rate": 5.223033882499223e-06,
      "loss": 0.2194,
      "step": 12294
    },
    {
      "epoch": 0.9554709356543364,
      "grad_norm": 0.30800625681877136,
      "learning_rate": 5.222645321728319e-06,
      "loss": 0.1763,
      "step": 12295
    },
    {
      "epoch": 0.9555486478085172,
      "grad_norm": 0.7942472696304321,
      "learning_rate": 5.222256760957414e-06,
      "loss": 0.381,
      "step": 12296
    },
    {
      "epoch": 0.9556263599626982,
      "grad_norm": 0.13942593336105347,
      "learning_rate": 5.22186820018651e-06,
      "loss": 0.0408,
      "step": 12297
    },
    {
      "epoch": 0.9557040721168791,
      "grad_norm": 0.16824933886528015,
      "learning_rate": 5.2214796394156054e-06,
      "loss": 0.0205,
      "step": 12298
    },
    {
      "epoch": 0.95578178427106,
      "grad_norm": 0.543651282787323,
      "learning_rate": 5.2210910786447e-06,
      "loss": 0.0907,
      "step": 12299
    },
    {
      "epoch": 0.9558594964252409,
      "grad_norm": 0.1350143998861313,
      "learning_rate": 5.220702517873796e-06,
      "loss": 0.0205,
      "step": 12300
    },
    {
      "epoch": 0.9559372085794218,
      "grad_norm": 0.43075695633888245,
      "learning_rate": 5.220313957102892e-06,
      "loss": 0.5153,
      "step": 12301
    },
    {
      "epoch": 0.9560149207336027,
      "grad_norm": 0.46306970715522766,
      "learning_rate": 5.219925396331986e-06,
      "loss": 0.3282,
      "step": 12302
    },
    {
      "epoch": 0.9560926328877837,
      "grad_norm": 0.4130828082561493,
      "learning_rate": 5.219536835561082e-06,
      "loss": 0.1496,
      "step": 12303
    },
    {
      "epoch": 0.9561703450419645,
      "grad_norm": 0.12847156822681427,
      "learning_rate": 5.219148274790178e-06,
      "loss": 0.0358,
      "step": 12304
    },
    {
      "epoch": 0.9562480571961455,
      "grad_norm": 0.21286150813102722,
      "learning_rate": 5.218759714019273e-06,
      "loss": 0.0833,
      "step": 12305
    },
    {
      "epoch": 0.9563257693503264,
      "grad_norm": 0.14736315608024597,
      "learning_rate": 5.2183711532483684e-06,
      "loss": 0.0805,
      "step": 12306
    },
    {
      "epoch": 0.9564034815045073,
      "grad_norm": 0.434472918510437,
      "learning_rate": 5.217982592477464e-06,
      "loss": 0.186,
      "step": 12307
    },
    {
      "epoch": 0.9564811936586882,
      "grad_norm": 0.1414412260055542,
      "learning_rate": 5.21759403170656e-06,
      "loss": 0.0523,
      "step": 12308
    },
    {
      "epoch": 0.9565589058128692,
      "grad_norm": 1.0716102123260498,
      "learning_rate": 5.217205470935654e-06,
      "loss": 0.31,
      "step": 12309
    },
    {
      "epoch": 0.95663661796705,
      "grad_norm": 0.5183322429656982,
      "learning_rate": 5.21681691016475e-06,
      "loss": 0.1916,
      "step": 12310
    },
    {
      "epoch": 0.956714330121231,
      "grad_norm": 0.2854544222354889,
      "learning_rate": 5.216428349393846e-06,
      "loss": 0.1086,
      "step": 12311
    },
    {
      "epoch": 0.9567920422754119,
      "grad_norm": 0.42520764470100403,
      "learning_rate": 5.216039788622941e-06,
      "loss": 0.3572,
      "step": 12312
    },
    {
      "epoch": 0.9568697544295928,
      "grad_norm": 0.36484089493751526,
      "learning_rate": 5.2156512278520365e-06,
      "loss": 0.5679,
      "step": 12313
    },
    {
      "epoch": 0.9569474665837737,
      "grad_norm": 0.23383809626102448,
      "learning_rate": 5.215262667081132e-06,
      "loss": 0.0344,
      "step": 12314
    },
    {
      "epoch": 0.9570251787379546,
      "grad_norm": 0.4157510995864868,
      "learning_rate": 5.214874106310227e-06,
      "loss": 0.1281,
      "step": 12315
    },
    {
      "epoch": 0.9571028908921355,
      "grad_norm": 0.23460593819618225,
      "learning_rate": 5.214485545539323e-06,
      "loss": 0.0923,
      "step": 12316
    },
    {
      "epoch": 0.9571806030463165,
      "grad_norm": 0.31139472126960754,
      "learning_rate": 5.214096984768419e-06,
      "loss": 0.2615,
      "step": 12317
    },
    {
      "epoch": 0.9572583152004973,
      "grad_norm": 0.22065632045269012,
      "learning_rate": 5.213708423997513e-06,
      "loss": 0.076,
      "step": 12318
    },
    {
      "epoch": 0.9573360273546783,
      "grad_norm": 0.6840162873268127,
      "learning_rate": 5.213319863226609e-06,
      "loss": 0.5711,
      "step": 12319
    },
    {
      "epoch": 0.9574137395088592,
      "grad_norm": 0.7436143755912781,
      "learning_rate": 5.2129313024557045e-06,
      "loss": 0.1798,
      "step": 12320
    },
    {
      "epoch": 0.9574914516630401,
      "grad_norm": 0.17485204339027405,
      "learning_rate": 5.2125427416847995e-06,
      "loss": 0.0444,
      "step": 12321
    },
    {
      "epoch": 0.957569163817221,
      "grad_norm": 0.4771795868873596,
      "learning_rate": 5.212154180913895e-06,
      "loss": 0.2524,
      "step": 12322
    },
    {
      "epoch": 0.957646875971402,
      "grad_norm": 0.9655829668045044,
      "learning_rate": 5.211765620142991e-06,
      "loss": 0.1055,
      "step": 12323
    },
    {
      "epoch": 0.9577245881255828,
      "grad_norm": 0.17139223217964172,
      "learning_rate": 5.211377059372086e-06,
      "loss": 0.0471,
      "step": 12324
    },
    {
      "epoch": 0.9578023002797638,
      "grad_norm": 0.17514543235301971,
      "learning_rate": 5.210988498601182e-06,
      "loss": 0.0604,
      "step": 12325
    },
    {
      "epoch": 0.9578800124339447,
      "grad_norm": 0.7314287424087524,
      "learning_rate": 5.210599937830278e-06,
      "loss": 0.2315,
      "step": 12326
    },
    {
      "epoch": 0.9579577245881256,
      "grad_norm": 0.2876419425010681,
      "learning_rate": 5.210211377059372e-06,
      "loss": 0.0884,
      "step": 12327
    },
    {
      "epoch": 0.9580354367423065,
      "grad_norm": 0.200005441904068,
      "learning_rate": 5.2098228162884675e-06,
      "loss": 0.0759,
      "step": 12328
    },
    {
      "epoch": 0.9581131488964875,
      "grad_norm": 0.2935180366039276,
      "learning_rate": 5.209434255517563e-06,
      "loss": 0.2245,
      "step": 12329
    },
    {
      "epoch": 0.9581908610506683,
      "grad_norm": 0.7738843560218811,
      "learning_rate": 5.209045694746658e-06,
      "loss": 0.0628,
      "step": 12330
    },
    {
      "epoch": 0.9582685732048493,
      "grad_norm": 0.4616270959377289,
      "learning_rate": 5.208657133975754e-06,
      "loss": 0.1087,
      "step": 12331
    },
    {
      "epoch": 0.9583462853590301,
      "grad_norm": 0.280630499124527,
      "learning_rate": 5.20826857320485e-06,
      "loss": 0.2046,
      "step": 12332
    },
    {
      "epoch": 0.9584239975132111,
      "grad_norm": 0.5343958139419556,
      "learning_rate": 5.207880012433945e-06,
      "loss": 0.1016,
      "step": 12333
    },
    {
      "epoch": 0.958501709667392,
      "grad_norm": 0.7222985625267029,
      "learning_rate": 5.207491451663041e-06,
      "loss": 0.4747,
      "step": 12334
    },
    {
      "epoch": 0.9585794218215729,
      "grad_norm": 0.12129788100719452,
      "learning_rate": 5.207102890892136e-06,
      "loss": 0.0204,
      "step": 12335
    },
    {
      "epoch": 0.9586571339757538,
      "grad_norm": 0.18092568218708038,
      "learning_rate": 5.2067143301212305e-06,
      "loss": 0.0508,
      "step": 12336
    },
    {
      "epoch": 0.9587348461299348,
      "grad_norm": 0.2695586383342743,
      "learning_rate": 5.206325769350326e-06,
      "loss": 0.0824,
      "step": 12337
    },
    {
      "epoch": 0.9588125582841156,
      "grad_norm": 0.5443301796913147,
      "learning_rate": 5.205937208579422e-06,
      "loss": 0.2388,
      "step": 12338
    },
    {
      "epoch": 0.9588902704382966,
      "grad_norm": 0.293891966342926,
      "learning_rate": 5.205548647808518e-06,
      "loss": 0.1375,
      "step": 12339
    },
    {
      "epoch": 0.9589679825924775,
      "grad_norm": 0.19462800025939941,
      "learning_rate": 5.205160087037613e-06,
      "loss": 0.0549,
      "step": 12340
    },
    {
      "epoch": 0.9590456947466584,
      "grad_norm": 0.39715978503227234,
      "learning_rate": 5.204771526266709e-06,
      "loss": 0.1866,
      "step": 12341
    },
    {
      "epoch": 0.9591234069008393,
      "grad_norm": 0.11255921423435211,
      "learning_rate": 5.204382965495804e-06,
      "loss": 0.0214,
      "step": 12342
    },
    {
      "epoch": 0.9592011190550203,
      "grad_norm": 1.1726081371307373,
      "learning_rate": 5.203994404724899e-06,
      "loss": 1.1534,
      "step": 12343
    },
    {
      "epoch": 0.9592788312092011,
      "grad_norm": 0.16024380922317505,
      "learning_rate": 5.203605843953995e-06,
      "loss": 0.1091,
      "step": 12344
    },
    {
      "epoch": 0.959356543363382,
      "grad_norm": 0.6492034792900085,
      "learning_rate": 5.203217283183091e-06,
      "loss": 0.5169,
      "step": 12345
    },
    {
      "epoch": 0.9594342555175629,
      "grad_norm": 0.5344544053077698,
      "learning_rate": 5.202828722412185e-06,
      "loss": 0.8188,
      "step": 12346
    },
    {
      "epoch": 0.9595119676717438,
      "grad_norm": 0.11984604597091675,
      "learning_rate": 5.202440161641281e-06,
      "loss": 0.0188,
      "step": 12347
    },
    {
      "epoch": 0.9595896798259248,
      "grad_norm": 0.20829090476036072,
      "learning_rate": 5.202051600870377e-06,
      "loss": 0.0715,
      "step": 12348
    },
    {
      "epoch": 0.9596673919801056,
      "grad_norm": 0.3279895782470703,
      "learning_rate": 5.201663040099472e-06,
      "loss": 0.1581,
      "step": 12349
    },
    {
      "epoch": 0.9597451041342866,
      "grad_norm": 0.26089417934417725,
      "learning_rate": 5.201274479328567e-06,
      "loss": 0.1409,
      "step": 12350
    },
    {
      "epoch": 0.9598228162884676,
      "grad_norm": 0.32307204604148865,
      "learning_rate": 5.200885918557663e-06,
      "loss": 0.4336,
      "step": 12351
    },
    {
      "epoch": 0.9599005284426484,
      "grad_norm": 0.4268321394920349,
      "learning_rate": 5.200497357786758e-06,
      "loss": 0.2399,
      "step": 12352
    },
    {
      "epoch": 0.9599782405968293,
      "grad_norm": 0.7880470752716064,
      "learning_rate": 5.200108797015854e-06,
      "loss": 1.0753,
      "step": 12353
    },
    {
      "epoch": 0.9600559527510103,
      "grad_norm": 0.4803301990032196,
      "learning_rate": 5.19972023624495e-06,
      "loss": 0.353,
      "step": 12354
    },
    {
      "epoch": 0.9601336649051911,
      "grad_norm": 1.14546537399292,
      "learning_rate": 5.199331675474044e-06,
      "loss": 0.7096,
      "step": 12355
    },
    {
      "epoch": 0.9602113770593721,
      "grad_norm": 0.08115048706531525,
      "learning_rate": 5.19894311470314e-06,
      "loss": 0.0197,
      "step": 12356
    },
    {
      "epoch": 0.960289089213553,
      "grad_norm": 0.6022602319717407,
      "learning_rate": 5.1985545539322354e-06,
      "loss": 0.2745,
      "step": 12357
    },
    {
      "epoch": 0.9603668013677339,
      "grad_norm": 0.2271486222743988,
      "learning_rate": 5.19816599316133e-06,
      "loss": 0.1398,
      "step": 12358
    },
    {
      "epoch": 0.9604445135219148,
      "grad_norm": 0.6261141896247864,
      "learning_rate": 5.197777432390426e-06,
      "loss": 0.1921,
      "step": 12359
    },
    {
      "epoch": 0.9605222256760957,
      "grad_norm": 0.3347559869289398,
      "learning_rate": 5.197388871619522e-06,
      "loss": 0.0286,
      "step": 12360
    },
    {
      "epoch": 0.9605999378302766,
      "grad_norm": 0.25148776173591614,
      "learning_rate": 5.197000310848617e-06,
      "loss": 0.1095,
      "step": 12361
    },
    {
      "epoch": 0.9606776499844576,
      "grad_norm": 1.1422194242477417,
      "learning_rate": 5.196611750077713e-06,
      "loss": 0.5897,
      "step": 12362
    },
    {
      "epoch": 0.9607553621386384,
      "grad_norm": 0.42284730076789856,
      "learning_rate": 5.1962231893068085e-06,
      "loss": 0.1193,
      "step": 12363
    },
    {
      "epoch": 0.9608330742928194,
      "grad_norm": 0.6869050860404968,
      "learning_rate": 5.195834628535903e-06,
      "loss": 0.3105,
      "step": 12364
    },
    {
      "epoch": 0.9609107864470003,
      "grad_norm": 0.4978775978088379,
      "learning_rate": 5.195446067764998e-06,
      "loss": 0.0775,
      "step": 12365
    },
    {
      "epoch": 0.9609884986011812,
      "grad_norm": 0.33086714148521423,
      "learning_rate": 5.195057506994094e-06,
      "loss": 0.3331,
      "step": 12366
    },
    {
      "epoch": 0.9610662107553621,
      "grad_norm": 0.6261879801750183,
      "learning_rate": 5.194668946223189e-06,
      "loss": 0.1955,
      "step": 12367
    },
    {
      "epoch": 0.9611439229095431,
      "grad_norm": 0.4118720293045044,
      "learning_rate": 5.194280385452285e-06,
      "loss": 0.5447,
      "step": 12368
    },
    {
      "epoch": 0.9612216350637239,
      "grad_norm": 0.5483705997467041,
      "learning_rate": 5.193891824681381e-06,
      "loss": 0.449,
      "step": 12369
    },
    {
      "epoch": 0.9612993472179049,
      "grad_norm": 0.25174176692962646,
      "learning_rate": 5.1935032639104766e-06,
      "loss": 0.1392,
      "step": 12370
    },
    {
      "epoch": 0.9613770593720858,
      "grad_norm": 0.19572636485099792,
      "learning_rate": 5.1931147031395715e-06,
      "loss": 0.0611,
      "step": 12371
    },
    {
      "epoch": 0.9614547715262667,
      "grad_norm": 0.4154691994190216,
      "learning_rate": 5.192726142368667e-06,
      "loss": 0.1347,
      "step": 12372
    },
    {
      "epoch": 0.9615324836804476,
      "grad_norm": 0.3796543478965759,
      "learning_rate": 5.192337581597763e-06,
      "loss": 0.1431,
      "step": 12373
    },
    {
      "epoch": 0.9616101958346286,
      "grad_norm": 0.25980788469314575,
      "learning_rate": 5.191949020826857e-06,
      "loss": 0.2244,
      "step": 12374
    },
    {
      "epoch": 0.9616879079888094,
      "grad_norm": 1.0013785362243652,
      "learning_rate": 5.191560460055953e-06,
      "loss": 0.3088,
      "step": 12375
    },
    {
      "epoch": 0.9617656201429904,
      "grad_norm": 0.5440547466278076,
      "learning_rate": 5.191171899285049e-06,
      "loss": 0.0402,
      "step": 12376
    },
    {
      "epoch": 0.9618433322971712,
      "grad_norm": 0.15499673783779144,
      "learning_rate": 5.190783338514144e-06,
      "loss": 0.0882,
      "step": 12377
    },
    {
      "epoch": 0.9619210444513522,
      "grad_norm": 0.19652186334133148,
      "learning_rate": 5.1903947777432395e-06,
      "loss": 0.0187,
      "step": 12378
    },
    {
      "epoch": 0.9619987566055331,
      "grad_norm": 0.6168209910392761,
      "learning_rate": 5.190006216972335e-06,
      "loss": 0.1758,
      "step": 12379
    },
    {
      "epoch": 0.962076468759714,
      "grad_norm": 0.3207107186317444,
      "learning_rate": 5.18961765620143e-06,
      "loss": 0.0818,
      "step": 12380
    },
    {
      "epoch": 0.9621541809138949,
      "grad_norm": 0.671808660030365,
      "learning_rate": 5.189229095430526e-06,
      "loss": 0.395,
      "step": 12381
    },
    {
      "epoch": 0.9622318930680759,
      "grad_norm": 0.25256645679473877,
      "learning_rate": 5.188840534659622e-06,
      "loss": 0.0747,
      "step": 12382
    },
    {
      "epoch": 0.9623096052222567,
      "grad_norm": 0.2572120130062103,
      "learning_rate": 5.188451973888716e-06,
      "loss": 0.1616,
      "step": 12383
    },
    {
      "epoch": 0.9623873173764377,
      "grad_norm": 0.754793643951416,
      "learning_rate": 5.188063413117812e-06,
      "loss": 0.2157,
      "step": 12384
    },
    {
      "epoch": 0.9624650295306186,
      "grad_norm": 0.1295194923877716,
      "learning_rate": 5.187674852346908e-06,
      "loss": 0.0311,
      "step": 12385
    },
    {
      "epoch": 0.9625427416847995,
      "grad_norm": 0.21401819586753845,
      "learning_rate": 5.1872862915760025e-06,
      "loss": 0.0482,
      "step": 12386
    },
    {
      "epoch": 0.9626204538389804,
      "grad_norm": 0.5400509238243103,
      "learning_rate": 5.186897730805098e-06,
      "loss": 0.3251,
      "step": 12387
    },
    {
      "epoch": 0.9626981659931614,
      "grad_norm": 0.5247318148612976,
      "learning_rate": 5.186509170034194e-06,
      "loss": 0.2335,
      "step": 12388
    },
    {
      "epoch": 0.9627758781473422,
      "grad_norm": 0.25831639766693115,
      "learning_rate": 5.186120609263289e-06,
      "loss": 0.0456,
      "step": 12389
    },
    {
      "epoch": 0.9628535903015232,
      "grad_norm": 0.1938600093126297,
      "learning_rate": 5.185732048492385e-06,
      "loss": 0.0937,
      "step": 12390
    },
    {
      "epoch": 0.962931302455704,
      "grad_norm": 0.5413983464241028,
      "learning_rate": 5.185343487721481e-06,
      "loss": 0.0471,
      "step": 12391
    },
    {
      "epoch": 0.963009014609885,
      "grad_norm": 0.0976051539182663,
      "learning_rate": 5.184954926950575e-06,
      "loss": 0.0165,
      "step": 12392
    },
    {
      "epoch": 0.9630867267640659,
      "grad_norm": 0.1457914561033249,
      "learning_rate": 5.1845663661796706e-06,
      "loss": 0.0244,
      "step": 12393
    },
    {
      "epoch": 0.9631644389182468,
      "grad_norm": 0.04935014247894287,
      "learning_rate": 5.184177805408766e-06,
      "loss": 0.0059,
      "step": 12394
    },
    {
      "epoch": 0.9632421510724277,
      "grad_norm": 0.2537207305431366,
      "learning_rate": 5.183789244637861e-06,
      "loss": 0.114,
      "step": 12395
    },
    {
      "epoch": 0.9633198632266087,
      "grad_norm": 0.1339126080274582,
      "learning_rate": 5.183400683866957e-06,
      "loss": 0.0168,
      "step": 12396
    },
    {
      "epoch": 0.9633975753807895,
      "grad_norm": 0.33829206228256226,
      "learning_rate": 5.183012123096053e-06,
      "loss": 0.0421,
      "step": 12397
    },
    {
      "epoch": 0.9634752875349705,
      "grad_norm": 0.3813059329986572,
      "learning_rate": 5.182623562325149e-06,
      "loss": 0.1097,
      "step": 12398
    },
    {
      "epoch": 0.9635529996891514,
      "grad_norm": 0.3706052899360657,
      "learning_rate": 5.182235001554244e-06,
      "loss": 0.5275,
      "step": 12399
    },
    {
      "epoch": 0.9636307118433323,
      "grad_norm": 0.11461486667394638,
      "learning_rate": 5.1818464407833395e-06,
      "loss": 0.047,
      "step": 12400
    },
    {
      "epoch": 0.9637084239975132,
      "grad_norm": 0.39228296279907227,
      "learning_rate": 5.181457880012435e-06,
      "loss": 0.0584,
      "step": 12401
    },
    {
      "epoch": 0.9637861361516942,
      "grad_norm": 0.37902212142944336,
      "learning_rate": 5.181069319241529e-06,
      "loss": 0.4276,
      "step": 12402
    },
    {
      "epoch": 0.963863848305875,
      "grad_norm": 0.8116480708122253,
      "learning_rate": 5.180680758470625e-06,
      "loss": 0.6545,
      "step": 12403
    },
    {
      "epoch": 0.963941560460056,
      "grad_norm": 0.31268423795700073,
      "learning_rate": 5.180292197699721e-06,
      "loss": 0.1439,
      "step": 12404
    },
    {
      "epoch": 0.9640192726142369,
      "grad_norm": 0.33061131834983826,
      "learning_rate": 5.179903636928816e-06,
      "loss": 0.2212,
      "step": 12405
    },
    {
      "epoch": 0.9640969847684178,
      "grad_norm": 0.34146368503570557,
      "learning_rate": 5.179515076157912e-06,
      "loss": 0.5342,
      "step": 12406
    },
    {
      "epoch": 0.9641746969225987,
      "grad_norm": 0.37527602910995483,
      "learning_rate": 5.1791265153870075e-06,
      "loss": 0.1517,
      "step": 12407
    },
    {
      "epoch": 0.9642524090767796,
      "grad_norm": 0.9215173125267029,
      "learning_rate": 5.1787379546161024e-06,
      "loss": 0.5028,
      "step": 12408
    },
    {
      "epoch": 0.9643301212309605,
      "grad_norm": 0.6698177456855774,
      "learning_rate": 5.178349393845198e-06,
      "loss": 0.4054,
      "step": 12409
    },
    {
      "epoch": 0.9644078333851415,
      "grad_norm": 0.7706784009933472,
      "learning_rate": 5.177960833074294e-06,
      "loss": 0.5262,
      "step": 12410
    },
    {
      "epoch": 0.9644855455393223,
      "grad_norm": 0.9419934153556824,
      "learning_rate": 5.177572272303388e-06,
      "loss": 0.2172,
      "step": 12411
    },
    {
      "epoch": 0.9645632576935033,
      "grad_norm": 0.6469334363937378,
      "learning_rate": 5.177183711532484e-06,
      "loss": 0.3392,
      "step": 12412
    },
    {
      "epoch": 0.9646409698476842,
      "grad_norm": 0.7856921553611755,
      "learning_rate": 5.17679515076158e-06,
      "loss": 0.3562,
      "step": 12413
    },
    {
      "epoch": 0.9647186820018651,
      "grad_norm": 0.9325293302536011,
      "learning_rate": 5.176406589990675e-06,
      "loss": 0.3502,
      "step": 12414
    },
    {
      "epoch": 0.964796394156046,
      "grad_norm": 0.17925766110420227,
      "learning_rate": 5.1760180292197705e-06,
      "loss": 0.0653,
      "step": 12415
    },
    {
      "epoch": 0.964874106310227,
      "grad_norm": 0.2982654571533203,
      "learning_rate": 5.175629468448866e-06,
      "loss": 0.0455,
      "step": 12416
    },
    {
      "epoch": 0.9649518184644078,
      "grad_norm": 1.9978502988815308,
      "learning_rate": 5.175240907677961e-06,
      "loss": 0.3442,
      "step": 12417
    },
    {
      "epoch": 0.9650295306185888,
      "grad_norm": 0.6657814383506775,
      "learning_rate": 5.174852346907057e-06,
      "loss": 0.2336,
      "step": 12418
    },
    {
      "epoch": 0.9651072427727697,
      "grad_norm": 0.5493472218513489,
      "learning_rate": 5.174463786136153e-06,
      "loss": 0.1747,
      "step": 12419
    },
    {
      "epoch": 0.9651849549269506,
      "grad_norm": 0.1942436695098877,
      "learning_rate": 5.174075225365247e-06,
      "loss": 0.0686,
      "step": 12420
    },
    {
      "epoch": 0.9652626670811315,
      "grad_norm": 0.4054142236709595,
      "learning_rate": 5.173686664594343e-06,
      "loss": 0.2513,
      "step": 12421
    },
    {
      "epoch": 0.9653403792353124,
      "grad_norm": 0.6672301888465881,
      "learning_rate": 5.1732981038234385e-06,
      "loss": 0.2508,
      "step": 12422
    },
    {
      "epoch": 0.9654180913894933,
      "grad_norm": 0.14101164042949677,
      "learning_rate": 5.1729095430525335e-06,
      "loss": 0.0323,
      "step": 12423
    },
    {
      "epoch": 0.9654958035436743,
      "grad_norm": 0.5730040669441223,
      "learning_rate": 5.172520982281629e-06,
      "loss": 0.3468,
      "step": 12424
    },
    {
      "epoch": 0.9655735156978551,
      "grad_norm": 0.11147722601890564,
      "learning_rate": 5.172132421510725e-06,
      "loss": 0.0239,
      "step": 12425
    },
    {
      "epoch": 0.965651227852036,
      "grad_norm": 0.3958783447742462,
      "learning_rate": 5.17174386073982e-06,
      "loss": 0.2036,
      "step": 12426
    },
    {
      "epoch": 0.965728940006217,
      "grad_norm": 0.47581401467323303,
      "learning_rate": 5.171355299968916e-06,
      "loss": 0.1812,
      "step": 12427
    },
    {
      "epoch": 0.9658066521603978,
      "grad_norm": 1.5605236291885376,
      "learning_rate": 5.170966739198012e-06,
      "loss": 0.2847,
      "step": 12428
    },
    {
      "epoch": 0.9658843643145788,
      "grad_norm": 0.3840123414993286,
      "learning_rate": 5.1705781784271065e-06,
      "loss": 0.0506,
      "step": 12429
    },
    {
      "epoch": 0.9659620764687598,
      "grad_norm": 0.7889741659164429,
      "learning_rate": 5.1701896176562015e-06,
      "loss": 0.3605,
      "step": 12430
    },
    {
      "epoch": 0.9660397886229406,
      "grad_norm": 0.5661336779594421,
      "learning_rate": 5.169801056885297e-06,
      "loss": 0.3397,
      "step": 12431
    },
    {
      "epoch": 0.9661175007771216,
      "grad_norm": 0.4786994457244873,
      "learning_rate": 5.169412496114393e-06,
      "loss": 0.1482,
      "step": 12432
    },
    {
      "epoch": 0.9661952129313025,
      "grad_norm": 0.6634638905525208,
      "learning_rate": 5.169023935343488e-06,
      "loss": 0.3207,
      "step": 12433
    },
    {
      "epoch": 0.9662729250854833,
      "grad_norm": 0.2940739691257477,
      "learning_rate": 5.168635374572584e-06,
      "loss": 0.0783,
      "step": 12434
    },
    {
      "epoch": 0.9663506372396643,
      "grad_norm": 1.290934443473816,
      "learning_rate": 5.16824681380168e-06,
      "loss": 0.3417,
      "step": 12435
    },
    {
      "epoch": 0.9664283493938451,
      "grad_norm": 0.6002167463302612,
      "learning_rate": 5.167858253030774e-06,
      "loss": 0.3234,
      "step": 12436
    },
    {
      "epoch": 0.9665060615480261,
      "grad_norm": 0.6530560255050659,
      "learning_rate": 5.1674696922598695e-06,
      "loss": 0.0893,
      "step": 12437
    },
    {
      "epoch": 0.966583773702207,
      "grad_norm": 0.1362334042787552,
      "learning_rate": 5.167081131488965e-06,
      "loss": 0.0627,
      "step": 12438
    },
    {
      "epoch": 0.9666614858563879,
      "grad_norm": 0.6804422736167908,
      "learning_rate": 5.16669257071806e-06,
      "loss": 0.4207,
      "step": 12439
    },
    {
      "epoch": 0.9667391980105688,
      "grad_norm": 0.530758798122406,
      "learning_rate": 5.166304009947156e-06,
      "loss": 0.3152,
      "step": 12440
    },
    {
      "epoch": 0.9668169101647498,
      "grad_norm": 0.7038787603378296,
      "learning_rate": 5.165915449176252e-06,
      "loss": 0.1617,
      "step": 12441
    },
    {
      "epoch": 0.9668946223189306,
      "grad_norm": 0.2597132921218872,
      "learning_rate": 5.165526888405347e-06,
      "loss": 0.079,
      "step": 12442
    },
    {
      "epoch": 0.9669723344731116,
      "grad_norm": 0.3005550801753998,
      "learning_rate": 5.165138327634443e-06,
      "loss": 0.1226,
      "step": 12443
    },
    {
      "epoch": 0.9670500466272925,
      "grad_norm": 0.30058276653289795,
      "learning_rate": 5.164749766863538e-06,
      "loss": 0.0614,
      "step": 12444
    },
    {
      "epoch": 0.9671277587814734,
      "grad_norm": 0.4583209156990051,
      "learning_rate": 5.1643612060926325e-06,
      "loss": 0.5419,
      "step": 12445
    },
    {
      "epoch": 0.9672054709356543,
      "grad_norm": 0.3429926931858063,
      "learning_rate": 5.163972645321728e-06,
      "loss": 0.0661,
      "step": 12446
    },
    {
      "epoch": 0.9672831830898353,
      "grad_norm": 0.23038272559642792,
      "learning_rate": 5.163584084550824e-06,
      "loss": 0.101,
      "step": 12447
    },
    {
      "epoch": 0.9673608952440161,
      "grad_norm": 0.8210515379905701,
      "learning_rate": 5.163195523779919e-06,
      "loss": 0.705,
      "step": 12448
    },
    {
      "epoch": 0.9674386073981971,
      "grad_norm": 0.14509588479995728,
      "learning_rate": 5.162806963009015e-06,
      "loss": 0.0317,
      "step": 12449
    },
    {
      "epoch": 0.967516319552378,
      "grad_norm": 0.29348838329315186,
      "learning_rate": 5.162418402238111e-06,
      "loss": 0.2247,
      "step": 12450
    },
    {
      "epoch": 0.9675940317065589,
      "grad_norm": 0.555639922618866,
      "learning_rate": 5.162029841467206e-06,
      "loss": 0.0435,
      "step": 12451
    },
    {
      "epoch": 0.9676717438607398,
      "grad_norm": 0.5107098817825317,
      "learning_rate": 5.161641280696301e-06,
      "loss": 0.1951,
      "step": 12452
    },
    {
      "epoch": 0.9677494560149207,
      "grad_norm": 0.7679898142814636,
      "learning_rate": 5.161252719925397e-06,
      "loss": 0.3659,
      "step": 12453
    },
    {
      "epoch": 0.9678271681691016,
      "grad_norm": 0.43174901604652405,
      "learning_rate": 5.160864159154491e-06,
      "loss": 0.0787,
      "step": 12454
    },
    {
      "epoch": 0.9679048803232826,
      "grad_norm": 0.4791412651538849,
      "learning_rate": 5.160475598383587e-06,
      "loss": 0.3856,
      "step": 12455
    },
    {
      "epoch": 0.9679825924774634,
      "grad_norm": 0.3509563207626343,
      "learning_rate": 5.160087037612683e-06,
      "loss": 0.2302,
      "step": 12456
    },
    {
      "epoch": 0.9680603046316444,
      "grad_norm": 0.5234859585762024,
      "learning_rate": 5.159698476841778e-06,
      "loss": 0.2575,
      "step": 12457
    },
    {
      "epoch": 0.9681380167858253,
      "grad_norm": 0.08170077204704285,
      "learning_rate": 5.159309916070874e-06,
      "loss": 0.0225,
      "step": 12458
    },
    {
      "epoch": 0.9682157289400062,
      "grad_norm": 0.309970885515213,
      "learning_rate": 5.1589213552999694e-06,
      "loss": 0.1554,
      "step": 12459
    },
    {
      "epoch": 0.9682934410941871,
      "grad_norm": 0.6717435121536255,
      "learning_rate": 5.158532794529065e-06,
      "loss": 0.4455,
      "step": 12460
    },
    {
      "epoch": 0.9683711532483681,
      "grad_norm": 0.4817844033241272,
      "learning_rate": 5.15814423375816e-06,
      "loss": 0.3869,
      "step": 12461
    },
    {
      "epoch": 0.9684488654025489,
      "grad_norm": 0.9311173558235168,
      "learning_rate": 5.157755672987256e-06,
      "loss": 0.59,
      "step": 12462
    },
    {
      "epoch": 0.9685265775567299,
      "grad_norm": 0.09642637521028519,
      "learning_rate": 5.157367112216352e-06,
      "loss": 0.0504,
      "step": 12463
    },
    {
      "epoch": 0.9686042897109108,
      "grad_norm": 0.2150801420211792,
      "learning_rate": 5.156978551445446e-06,
      "loss": 0.0321,
      "step": 12464
    },
    {
      "epoch": 0.9686820018650917,
      "grad_norm": 0.2266719490289688,
      "learning_rate": 5.156589990674542e-06,
      "loss": 0.0565,
      "step": 12465
    },
    {
      "epoch": 0.9687597140192726,
      "grad_norm": 0.3615027070045471,
      "learning_rate": 5.1562014299036375e-06,
      "loss": 0.1251,
      "step": 12466
    },
    {
      "epoch": 0.9688374261734535,
      "grad_norm": 0.33035680651664734,
      "learning_rate": 5.1558128691327324e-06,
      "loss": 0.3851,
      "step": 12467
    },
    {
      "epoch": 0.9689151383276344,
      "grad_norm": 0.488779753446579,
      "learning_rate": 5.155424308361828e-06,
      "loss": 0.2209,
      "step": 12468
    },
    {
      "epoch": 0.9689928504818154,
      "grad_norm": 0.4678274095058441,
      "learning_rate": 5.155035747590924e-06,
      "loss": 0.3222,
      "step": 12469
    },
    {
      "epoch": 0.9690705626359962,
      "grad_norm": 0.6090452671051025,
      "learning_rate": 5.154647186820019e-06,
      "loss": 0.0908,
      "step": 12470
    },
    {
      "epoch": 0.9691482747901772,
      "grad_norm": 0.20140227675437927,
      "learning_rate": 5.154258626049115e-06,
      "loss": 0.0472,
      "step": 12471
    },
    {
      "epoch": 0.9692259869443581,
      "grad_norm": 0.4919801950454712,
      "learning_rate": 5.1538700652782106e-06,
      "loss": 0.193,
      "step": 12472
    },
    {
      "epoch": 0.969303699098539,
      "grad_norm": 0.18816465139389038,
      "learning_rate": 5.153481504507305e-06,
      "loss": 0.0822,
      "step": 12473
    },
    {
      "epoch": 0.9693814112527199,
      "grad_norm": 0.4346201717853546,
      "learning_rate": 5.1530929437364005e-06,
      "loss": 0.1025,
      "step": 12474
    },
    {
      "epoch": 0.9694591234069009,
      "grad_norm": 0.20027795433998108,
      "learning_rate": 5.152704382965496e-06,
      "loss": 0.0119,
      "step": 12475
    },
    {
      "epoch": 0.9695368355610817,
      "grad_norm": 0.3265080153942108,
      "learning_rate": 5.152315822194591e-06,
      "loss": 0.1207,
      "step": 12476
    },
    {
      "epoch": 0.9696145477152627,
      "grad_norm": 0.5348919034004211,
      "learning_rate": 5.151927261423687e-06,
      "loss": 0.1697,
      "step": 12477
    },
    {
      "epoch": 0.9696922598694436,
      "grad_norm": 0.5695845484733582,
      "learning_rate": 5.151538700652783e-06,
      "loss": 0.1638,
      "step": 12478
    },
    {
      "epoch": 0.9697699720236245,
      "grad_norm": 1.3398312330245972,
      "learning_rate": 5.151150139881878e-06,
      "loss": 0.5192,
      "step": 12479
    },
    {
      "epoch": 0.9698476841778054,
      "grad_norm": 0.21890565752983093,
      "learning_rate": 5.1507615791109735e-06,
      "loss": 0.2159,
      "step": 12480
    },
    {
      "epoch": 0.9699253963319864,
      "grad_norm": 0.41039958596229553,
      "learning_rate": 5.150373018340069e-06,
      "loss": 0.1733,
      "step": 12481
    },
    {
      "epoch": 0.9700031084861672,
      "grad_norm": 0.432097852230072,
      "learning_rate": 5.1499844575691634e-06,
      "loss": 0.2697,
      "step": 12482
    },
    {
      "epoch": 0.9700808206403482,
      "grad_norm": 0.3329991400241852,
      "learning_rate": 5.149595896798259e-06,
      "loss": 0.128,
      "step": 12483
    },
    {
      "epoch": 0.970158532794529,
      "grad_norm": 0.1499238759279251,
      "learning_rate": 5.149207336027355e-06,
      "loss": 0.0524,
      "step": 12484
    },
    {
      "epoch": 0.97023624494871,
      "grad_norm": 0.5227094888687134,
      "learning_rate": 5.14881877525645e-06,
      "loss": 0.2008,
      "step": 12485
    },
    {
      "epoch": 0.9703139571028909,
      "grad_norm": 0.1692829728126526,
      "learning_rate": 5.148430214485546e-06,
      "loss": 0.0385,
      "step": 12486
    },
    {
      "epoch": 0.9703916692570718,
      "grad_norm": 0.18910804390907288,
      "learning_rate": 5.148041653714642e-06,
      "loss": 0.027,
      "step": 12487
    },
    {
      "epoch": 0.9704693814112527,
      "grad_norm": 0.19861242175102234,
      "learning_rate": 5.1476530929437365e-06,
      "loss": 0.0909,
      "step": 12488
    },
    {
      "epoch": 0.9705470935654337,
      "grad_norm": 0.1235564649105072,
      "learning_rate": 5.147264532172832e-06,
      "loss": 0.121,
      "step": 12489
    },
    {
      "epoch": 0.9706248057196145,
      "grad_norm": 0.6474453210830688,
      "learning_rate": 5.146875971401928e-06,
      "loss": 0.1584,
      "step": 12490
    },
    {
      "epoch": 0.9707025178737955,
      "grad_norm": 0.23715540766716003,
      "learning_rate": 5.146487410631024e-06,
      "loss": 0.0627,
      "step": 12491
    },
    {
      "epoch": 0.9707802300279764,
      "grad_norm": 0.02607450820505619,
      "learning_rate": 5.146098849860118e-06,
      "loss": 0.0072,
      "step": 12492
    },
    {
      "epoch": 0.9708579421821573,
      "grad_norm": 0.5491557121276855,
      "learning_rate": 5.145710289089214e-06,
      "loss": 0.1854,
      "step": 12493
    },
    {
      "epoch": 0.9709356543363382,
      "grad_norm": 0.5832816958427429,
      "learning_rate": 5.14532172831831e-06,
      "loss": 0.2766,
      "step": 12494
    },
    {
      "epoch": 0.9710133664905192,
      "grad_norm": 0.18074724078178406,
      "learning_rate": 5.1449331675474046e-06,
      "loss": 0.0396,
      "step": 12495
    },
    {
      "epoch": 0.9710910786447,
      "grad_norm": 0.47591283917427063,
      "learning_rate": 5.1445446067765e-06,
      "loss": 0.165,
      "step": 12496
    },
    {
      "epoch": 0.971168790798881,
      "grad_norm": 0.3442915678024292,
      "learning_rate": 5.144156046005596e-06,
      "loss": 0.1139,
      "step": 12497
    },
    {
      "epoch": 0.9712465029530618,
      "grad_norm": 2.1410622596740723,
      "learning_rate": 5.143767485234691e-06,
      "loss": 0.1822,
      "step": 12498
    },
    {
      "epoch": 0.9713242151072428,
      "grad_norm": 0.09846965223550797,
      "learning_rate": 5.143378924463787e-06,
      "loss": 0.0326,
      "step": 12499
    },
    {
      "epoch": 0.9714019272614237,
      "grad_norm": 0.4265570342540741,
      "learning_rate": 5.142990363692883e-06,
      "loss": 0.2814,
      "step": 12500
    },
    {
      "epoch": 0.9714796394156046,
      "grad_norm": 0.1559963971376419,
      "learning_rate": 5.142601802921977e-06,
      "loss": 0.0375,
      "step": 12501
    },
    {
      "epoch": 0.9715573515697855,
      "grad_norm": 0.5620703101158142,
      "learning_rate": 5.142213242151073e-06,
      "loss": 0.1174,
      "step": 12502
    },
    {
      "epoch": 0.9716350637239665,
      "grad_norm": 0.3718019425868988,
      "learning_rate": 5.141824681380168e-06,
      "loss": 0.0638,
      "step": 12503
    },
    {
      "epoch": 0.9717127758781473,
      "grad_norm": 0.25505730509757996,
      "learning_rate": 5.141436120609263e-06,
      "loss": 0.0926,
      "step": 12504
    },
    {
      "epoch": 0.9717904880323283,
      "grad_norm": 0.5384474992752075,
      "learning_rate": 5.141047559838359e-06,
      "loss": 0.4683,
      "step": 12505
    },
    {
      "epoch": 0.9718682001865092,
      "grad_norm": 0.3350549042224884,
      "learning_rate": 5.140658999067455e-06,
      "loss": 0.11,
      "step": 12506
    },
    {
      "epoch": 0.97194591234069,
      "grad_norm": 0.3023904860019684,
      "learning_rate": 5.14027043829655e-06,
      "loss": 0.0562,
      "step": 12507
    },
    {
      "epoch": 0.972023624494871,
      "grad_norm": 0.11859101802110672,
      "learning_rate": 5.139881877525646e-06,
      "loss": 0.0419,
      "step": 12508
    },
    {
      "epoch": 0.972101336649052,
      "grad_norm": 1.4417612552642822,
      "learning_rate": 5.1394933167547415e-06,
      "loss": 0.6687,
      "step": 12509
    },
    {
      "epoch": 0.9721790488032328,
      "grad_norm": 0.8826738595962524,
      "learning_rate": 5.139104755983836e-06,
      "loss": 0.2245,
      "step": 12510
    },
    {
      "epoch": 0.9722567609574138,
      "grad_norm": 0.40691623091697693,
      "learning_rate": 5.138716195212931e-06,
      "loss": 0.416,
      "step": 12511
    },
    {
      "epoch": 0.9723344731115946,
      "grad_norm": 0.44216930866241455,
      "learning_rate": 5.138327634442027e-06,
      "loss": 0.2912,
      "step": 12512
    },
    {
      "epoch": 0.9724121852657756,
      "grad_norm": 0.6416675448417664,
      "learning_rate": 5.137939073671122e-06,
      "loss": 0.3052,
      "step": 12513
    },
    {
      "epoch": 0.9724898974199565,
      "grad_norm": 0.04724004864692688,
      "learning_rate": 5.137550512900218e-06,
      "loss": 0.0164,
      "step": 12514
    },
    {
      "epoch": 0.9725676095741373,
      "grad_norm": 0.5368012189865112,
      "learning_rate": 5.137161952129314e-06,
      "loss": 0.3709,
      "step": 12515
    },
    {
      "epoch": 0.9726453217283183,
      "grad_norm": 0.7342483401298523,
      "learning_rate": 5.136773391358409e-06,
      "loss": 0.3651,
      "step": 12516
    },
    {
      "epoch": 0.9727230338824993,
      "grad_norm": 0.09277846664190292,
      "learning_rate": 5.1363848305875045e-06,
      "loss": 0.0409,
      "step": 12517
    },
    {
      "epoch": 0.9728007460366801,
      "grad_norm": 0.458327054977417,
      "learning_rate": 5.1359962698166e-06,
      "loss": 0.3327,
      "step": 12518
    },
    {
      "epoch": 0.972878458190861,
      "grad_norm": 0.19554173946380615,
      "learning_rate": 5.135607709045696e-06,
      "loss": 0.0474,
      "step": 12519
    },
    {
      "epoch": 0.972956170345042,
      "grad_norm": 0.2078820914030075,
      "learning_rate": 5.13521914827479e-06,
      "loss": 0.0787,
      "step": 12520
    },
    {
      "epoch": 0.9730338824992228,
      "grad_norm": 0.26078981161117554,
      "learning_rate": 5.134830587503886e-06,
      "loss": 0.0727,
      "step": 12521
    },
    {
      "epoch": 0.9731115946534038,
      "grad_norm": 0.43878763914108276,
      "learning_rate": 5.134442026732982e-06,
      "loss": 0.168,
      "step": 12522
    },
    {
      "epoch": 0.9731893068075848,
      "grad_norm": 0.12658081948757172,
      "learning_rate": 5.134053465962077e-06,
      "loss": 0.0233,
      "step": 12523
    },
    {
      "epoch": 0.9732670189617656,
      "grad_norm": 0.27227240800857544,
      "learning_rate": 5.1336649051911725e-06,
      "loss": 0.0872,
      "step": 12524
    },
    {
      "epoch": 0.9733447311159465,
      "grad_norm": 0.44039198756217957,
      "learning_rate": 5.133276344420268e-06,
      "loss": 0.2499,
      "step": 12525
    },
    {
      "epoch": 0.9734224432701275,
      "grad_norm": 0.28024667501449585,
      "learning_rate": 5.132887783649363e-06,
      "loss": 0.0675,
      "step": 12526
    },
    {
      "epoch": 0.9735001554243083,
      "grad_norm": 0.37452420592308044,
      "learning_rate": 5.132499222878459e-06,
      "loss": 0.0863,
      "step": 12527
    },
    {
      "epoch": 0.9735778675784893,
      "grad_norm": 0.2770507335662842,
      "learning_rate": 5.132110662107555e-06,
      "loss": 0.0609,
      "step": 12528
    },
    {
      "epoch": 0.9736555797326701,
      "grad_norm": 0.8065552115440369,
      "learning_rate": 5.131722101336649e-06,
      "loss": 0.2312,
      "step": 12529
    },
    {
      "epoch": 0.9737332918868511,
      "grad_norm": 1.09697687625885,
      "learning_rate": 5.131333540565745e-06,
      "loss": 0.096,
      "step": 12530
    },
    {
      "epoch": 0.973811004041032,
      "grad_norm": 0.663312554359436,
      "learning_rate": 5.1309449797948406e-06,
      "loss": 0.2532,
      "step": 12531
    },
    {
      "epoch": 0.9738887161952129,
      "grad_norm": 0.5237575173377991,
      "learning_rate": 5.1305564190239355e-06,
      "loss": 0.1787,
      "step": 12532
    },
    {
      "epoch": 0.9739664283493938,
      "grad_norm": 0.2725164294242859,
      "learning_rate": 5.130167858253031e-06,
      "loss": 0.2922,
      "step": 12533
    },
    {
      "epoch": 0.9740441405035748,
      "grad_norm": 0.3465035855770111,
      "learning_rate": 5.129779297482127e-06,
      "loss": 0.2729,
      "step": 12534
    },
    {
      "epoch": 0.9741218526577556,
      "grad_norm": 0.10014113783836365,
      "learning_rate": 5.129390736711222e-06,
      "loss": 0.0156,
      "step": 12535
    },
    {
      "epoch": 0.9741995648119366,
      "grad_norm": 0.12743830680847168,
      "learning_rate": 5.129002175940318e-06,
      "loss": 0.0337,
      "step": 12536
    },
    {
      "epoch": 0.9742772769661175,
      "grad_norm": 0.3100467920303345,
      "learning_rate": 5.128613615169414e-06,
      "loss": 0.0884,
      "step": 12537
    },
    {
      "epoch": 0.9743549891202984,
      "grad_norm": 0.21888567507266998,
      "learning_rate": 5.128225054398508e-06,
      "loss": 0.044,
      "step": 12538
    },
    {
      "epoch": 0.9744327012744793,
      "grad_norm": 0.8134653568267822,
      "learning_rate": 5.1278364936276035e-06,
      "loss": 0.3608,
      "step": 12539
    },
    {
      "epoch": 0.9745104134286603,
      "grad_norm": 0.8044140338897705,
      "learning_rate": 5.127447932856699e-06,
      "loss": 0.5718,
      "step": 12540
    },
    {
      "epoch": 0.9745881255828411,
      "grad_norm": 0.8645051121711731,
      "learning_rate": 5.127059372085794e-06,
      "loss": 0.3031,
      "step": 12541
    },
    {
      "epoch": 0.9746658377370221,
      "grad_norm": 0.19027253985404968,
      "learning_rate": 5.12667081131489e-06,
      "loss": 0.1307,
      "step": 12542
    },
    {
      "epoch": 0.9747435498912029,
      "grad_norm": 0.945257306098938,
      "learning_rate": 5.126282250543986e-06,
      "loss": 0.6379,
      "step": 12543
    },
    {
      "epoch": 0.9748212620453839,
      "grad_norm": 0.3875258266925812,
      "learning_rate": 5.125893689773081e-06,
      "loss": 0.3174,
      "step": 12544
    },
    {
      "epoch": 0.9748989741995648,
      "grad_norm": 0.21409951150417328,
      "learning_rate": 5.125505129002177e-06,
      "loss": 0.1301,
      "step": 12545
    },
    {
      "epoch": 0.9749766863537457,
      "grad_norm": 0.2843687832355499,
      "learning_rate": 5.125116568231272e-06,
      "loss": 0.3457,
      "step": 12546
    },
    {
      "epoch": 0.9750543985079266,
      "grad_norm": 0.45368024706840515,
      "learning_rate": 5.1247280074603665e-06,
      "loss": 0.1039,
      "step": 12547
    },
    {
      "epoch": 0.9751321106621076,
      "grad_norm": 0.35914531350135803,
      "learning_rate": 5.124339446689462e-06,
      "loss": 0.2315,
      "step": 12548
    },
    {
      "epoch": 0.9752098228162884,
      "grad_norm": 0.30706480145454407,
      "learning_rate": 5.123950885918558e-06,
      "loss": 0.0271,
      "step": 12549
    },
    {
      "epoch": 0.9752875349704694,
      "grad_norm": 0.2060789167881012,
      "learning_rate": 5.123562325147654e-06,
      "loss": 0.0941,
      "step": 12550
    },
    {
      "epoch": 0.9753652471246503,
      "grad_norm": 0.22229325771331787,
      "learning_rate": 5.123173764376749e-06,
      "loss": 0.0318,
      "step": 12551
    },
    {
      "epoch": 0.9754429592788312,
      "grad_norm": 0.34804287552833557,
      "learning_rate": 5.122785203605845e-06,
      "loss": 0.1107,
      "step": 12552
    },
    {
      "epoch": 0.9755206714330121,
      "grad_norm": 0.5430372357368469,
      "learning_rate": 5.1223966428349405e-06,
      "loss": 0.7551,
      "step": 12553
    },
    {
      "epoch": 0.9755983835871931,
      "grad_norm": 0.6615850329399109,
      "learning_rate": 5.122008082064035e-06,
      "loss": 0.1379,
      "step": 12554
    },
    {
      "epoch": 0.9756760957413739,
      "grad_norm": 0.1305878907442093,
      "learning_rate": 5.12161952129313e-06,
      "loss": 0.031,
      "step": 12555
    },
    {
      "epoch": 0.9757538078955549,
      "grad_norm": 0.22780218720436096,
      "learning_rate": 5.121230960522226e-06,
      "loss": 0.1087,
      "step": 12556
    },
    {
      "epoch": 0.9758315200497357,
      "grad_norm": 0.9829328656196594,
      "learning_rate": 5.120842399751321e-06,
      "loss": 0.5136,
      "step": 12557
    },
    {
      "epoch": 0.9759092322039167,
      "grad_norm": 0.38030529022216797,
      "learning_rate": 5.120453838980417e-06,
      "loss": 0.2966,
      "step": 12558
    },
    {
      "epoch": 0.9759869443580976,
      "grad_norm": 0.9702447652816772,
      "learning_rate": 5.120065278209513e-06,
      "loss": 0.2478,
      "step": 12559
    },
    {
      "epoch": 0.9760646565122785,
      "grad_norm": 0.16829949617385864,
      "learning_rate": 5.119676717438608e-06,
      "loss": 0.0633,
      "step": 12560
    },
    {
      "epoch": 0.9761423686664594,
      "grad_norm": 0.5140562057495117,
      "learning_rate": 5.1192881566677034e-06,
      "loss": 0.3083,
      "step": 12561
    },
    {
      "epoch": 0.9762200808206404,
      "grad_norm": 0.17743536829948425,
      "learning_rate": 5.118899595896799e-06,
      "loss": 0.0318,
      "step": 12562
    },
    {
      "epoch": 0.9762977929748212,
      "grad_norm": 0.2824046313762665,
      "learning_rate": 5.118511035125893e-06,
      "loss": 0.1097,
      "step": 12563
    },
    {
      "epoch": 0.9763755051290022,
      "grad_norm": 0.8555887937545776,
      "learning_rate": 5.118122474354989e-06,
      "loss": 0.1286,
      "step": 12564
    },
    {
      "epoch": 0.9764532172831831,
      "grad_norm": 0.2773922085762024,
      "learning_rate": 5.117733913584085e-06,
      "loss": 0.056,
      "step": 12565
    },
    {
      "epoch": 0.976530929437364,
      "grad_norm": 0.08779990673065186,
      "learning_rate": 5.11734535281318e-06,
      "loss": 0.0517,
      "step": 12566
    },
    {
      "epoch": 0.9766086415915449,
      "grad_norm": 0.30169883370399475,
      "learning_rate": 5.116956792042276e-06,
      "loss": 0.186,
      "step": 12567
    },
    {
      "epoch": 0.9766863537457259,
      "grad_norm": 0.6574237942695618,
      "learning_rate": 5.1165682312713715e-06,
      "loss": 0.3036,
      "step": 12568
    },
    {
      "epoch": 0.9767640658999067,
      "grad_norm": 0.42209193110466003,
      "learning_rate": 5.1161796705004664e-06,
      "loss": 0.0619,
      "step": 12569
    },
    {
      "epoch": 0.9768417780540877,
      "grad_norm": 0.7080439925193787,
      "learning_rate": 5.115791109729562e-06,
      "loss": 0.5134,
      "step": 12570
    },
    {
      "epoch": 0.9769194902082686,
      "grad_norm": 0.6662470102310181,
      "learning_rate": 5.115402548958658e-06,
      "loss": 0.255,
      "step": 12571
    },
    {
      "epoch": 0.9769972023624495,
      "grad_norm": 0.4616686999797821,
      "learning_rate": 5.115013988187752e-06,
      "loss": 0.0799,
      "step": 12572
    },
    {
      "epoch": 0.9770749145166304,
      "grad_norm": 0.4603783190250397,
      "learning_rate": 5.114625427416848e-06,
      "loss": 0.1539,
      "step": 12573
    },
    {
      "epoch": 0.9771526266708113,
      "grad_norm": 0.26108235120773315,
      "learning_rate": 5.114236866645944e-06,
      "loss": 0.1544,
      "step": 12574
    },
    {
      "epoch": 0.9772303388249922,
      "grad_norm": 0.18148982524871826,
      "learning_rate": 5.113848305875039e-06,
      "loss": 0.0243,
      "step": 12575
    },
    {
      "epoch": 0.9773080509791732,
      "grad_norm": 0.6242520809173584,
      "learning_rate": 5.1134597451041345e-06,
      "loss": 0.2095,
      "step": 12576
    },
    {
      "epoch": 0.977385763133354,
      "grad_norm": 0.3066011667251587,
      "learning_rate": 5.11307118433323e-06,
      "loss": 0.1822,
      "step": 12577
    },
    {
      "epoch": 0.977463475287535,
      "grad_norm": 0.3469286262989044,
      "learning_rate": 5.112682623562325e-06,
      "loss": 0.1114,
      "step": 12578
    },
    {
      "epoch": 0.9775411874417159,
      "grad_norm": 0.3180599510669708,
      "learning_rate": 5.112294062791421e-06,
      "loss": 0.121,
      "step": 12579
    },
    {
      "epoch": 0.9776188995958968,
      "grad_norm": 0.318230539560318,
      "learning_rate": 5.111905502020517e-06,
      "loss": 0.2208,
      "step": 12580
    },
    {
      "epoch": 0.9776966117500777,
      "grad_norm": 0.37366870045661926,
      "learning_rate": 5.111516941249613e-06,
      "loss": 0.1058,
      "step": 12581
    },
    {
      "epoch": 0.9777743239042587,
      "grad_norm": 0.2646470069885254,
      "learning_rate": 5.111128380478707e-06,
      "loss": 0.1043,
      "step": 12582
    },
    {
      "epoch": 0.9778520360584395,
      "grad_norm": 1.0636305809020996,
      "learning_rate": 5.1107398197078025e-06,
      "loss": 0.2367,
      "step": 12583
    },
    {
      "epoch": 0.9779297482126205,
      "grad_norm": 0.23914794623851776,
      "learning_rate": 5.110351258936898e-06,
      "loss": 0.1456,
      "step": 12584
    },
    {
      "epoch": 0.9780074603668014,
      "grad_norm": 0.420102059841156,
      "learning_rate": 5.109962698165993e-06,
      "loss": 0.1251,
      "step": 12585
    },
    {
      "epoch": 0.9780851725209823,
      "grad_norm": 0.2760564684867859,
      "learning_rate": 5.109574137395089e-06,
      "loss": 0.0546,
      "step": 12586
    },
    {
      "epoch": 0.9781628846751632,
      "grad_norm": 0.42484885454177856,
      "learning_rate": 5.109185576624185e-06,
      "loss": 0.1723,
      "step": 12587
    },
    {
      "epoch": 0.9782405968293441,
      "grad_norm": 0.49145203828811646,
      "learning_rate": 5.10879701585328e-06,
      "loss": 0.218,
      "step": 12588
    },
    {
      "epoch": 0.978318308983525,
      "grad_norm": 0.21511919796466827,
      "learning_rate": 5.108408455082376e-06,
      "loss": 0.0828,
      "step": 12589
    },
    {
      "epoch": 0.978396021137706,
      "grad_norm": 1.0827369689941406,
      "learning_rate": 5.108019894311471e-06,
      "loss": 0.5133,
      "step": 12590
    },
    {
      "epoch": 0.9784737332918868,
      "grad_norm": 0.19897009432315826,
      "learning_rate": 5.1076313335405655e-06,
      "loss": 0.0726,
      "step": 12591
    },
    {
      "epoch": 0.9785514454460678,
      "grad_norm": 0.9310462474822998,
      "learning_rate": 5.107242772769661e-06,
      "loss": 0.6076,
      "step": 12592
    },
    {
      "epoch": 0.9786291576002487,
      "grad_norm": 0.5826932787895203,
      "learning_rate": 5.106854211998757e-06,
      "loss": 0.1319,
      "step": 12593
    },
    {
      "epoch": 0.9787068697544296,
      "grad_norm": 1.0625529289245605,
      "learning_rate": 5.106465651227852e-06,
      "loss": 0.3886,
      "step": 12594
    },
    {
      "epoch": 0.9787845819086105,
      "grad_norm": 0.32091864943504333,
      "learning_rate": 5.106077090456948e-06,
      "loss": 0.3137,
      "step": 12595
    },
    {
      "epoch": 0.9788622940627915,
      "grad_norm": 0.3002723157405853,
      "learning_rate": 5.105688529686044e-06,
      "loss": 0.0461,
      "step": 12596
    },
    {
      "epoch": 0.9789400062169723,
      "grad_norm": 0.7214033603668213,
      "learning_rate": 5.105299968915139e-06,
      "loss": 0.2981,
      "step": 12597
    },
    {
      "epoch": 0.9790177183711533,
      "grad_norm": 0.3512474596500397,
      "learning_rate": 5.104911408144234e-06,
      "loss": 0.0514,
      "step": 12598
    },
    {
      "epoch": 0.9790954305253342,
      "grad_norm": 0.19070817530155182,
      "learning_rate": 5.10452284737333e-06,
      "loss": 0.1199,
      "step": 12599
    },
    {
      "epoch": 0.979173142679515,
      "grad_norm": 0.9760549068450928,
      "learning_rate": 5.104134286602424e-06,
      "loss": 0.4398,
      "step": 12600
    },
    {
      "epoch": 0.979250854833696,
      "grad_norm": 0.5059530138969421,
      "learning_rate": 5.10374572583152e-06,
      "loss": 0.374,
      "step": 12601
    },
    {
      "epoch": 0.979328566987877,
      "grad_norm": 0.24507199227809906,
      "learning_rate": 5.103357165060616e-06,
      "loss": 0.0793,
      "step": 12602
    },
    {
      "epoch": 0.9794062791420578,
      "grad_norm": 0.12550415098667145,
      "learning_rate": 5.102968604289711e-06,
      "loss": 0.0138,
      "step": 12603
    },
    {
      "epoch": 0.9794839912962388,
      "grad_norm": 0.16974839568138123,
      "learning_rate": 5.102580043518807e-06,
      "loss": 0.08,
      "step": 12604
    },
    {
      "epoch": 0.9795617034504196,
      "grad_norm": 0.21300341188907623,
      "learning_rate": 5.102191482747902e-06,
      "loss": 0.122,
      "step": 12605
    },
    {
      "epoch": 0.9796394156046005,
      "grad_norm": 0.959921658039093,
      "learning_rate": 5.101802921976997e-06,
      "loss": 0.3174,
      "step": 12606
    },
    {
      "epoch": 0.9797171277587815,
      "grad_norm": 0.2484421283006668,
      "learning_rate": 5.101414361206093e-06,
      "loss": 0.1147,
      "step": 12607
    },
    {
      "epoch": 0.9797948399129623,
      "grad_norm": 0.2563014030456543,
      "learning_rate": 5.101025800435189e-06,
      "loss": 0.032,
      "step": 12608
    },
    {
      "epoch": 0.9798725520671433,
      "grad_norm": 0.22502566874027252,
      "learning_rate": 5.100637239664283e-06,
      "loss": 0.0863,
      "step": 12609
    },
    {
      "epoch": 0.9799502642213243,
      "grad_norm": 0.8053240180015564,
      "learning_rate": 5.100248678893379e-06,
      "loss": 0.3037,
      "step": 12610
    },
    {
      "epoch": 0.9800279763755051,
      "grad_norm": 0.2444925606250763,
      "learning_rate": 5.099860118122475e-06,
      "loss": 0.0722,
      "step": 12611
    },
    {
      "epoch": 0.980105688529686,
      "grad_norm": 0.3955935835838318,
      "learning_rate": 5.0994715573515704e-06,
      "loss": 0.1,
      "step": 12612
    },
    {
      "epoch": 0.980183400683867,
      "grad_norm": 1.2539784908294678,
      "learning_rate": 5.099082996580665e-06,
      "loss": 0.3413,
      "step": 12613
    },
    {
      "epoch": 0.9802611128380478,
      "grad_norm": 0.8238785862922668,
      "learning_rate": 5.098694435809761e-06,
      "loss": 0.1165,
      "step": 12614
    },
    {
      "epoch": 0.9803388249922288,
      "grad_norm": 0.4606855511665344,
      "learning_rate": 5.098305875038857e-06,
      "loss": 0.3234,
      "step": 12615
    },
    {
      "epoch": 0.9804165371464098,
      "grad_norm": 0.7686135768890381,
      "learning_rate": 5.097917314267952e-06,
      "loss": 0.1144,
      "step": 12616
    },
    {
      "epoch": 0.9804942493005906,
      "grad_norm": 0.2662279009819031,
      "learning_rate": 5.097528753497048e-06,
      "loss": 0.0876,
      "step": 12617
    },
    {
      "epoch": 0.9805719614547715,
      "grad_norm": 0.19828814268112183,
      "learning_rate": 5.0971401927261435e-06,
      "loss": 0.0805,
      "step": 12618
    },
    {
      "epoch": 0.9806496736089524,
      "grad_norm": 0.3995802104473114,
      "learning_rate": 5.096751631955238e-06,
      "loss": 0.3626,
      "step": 12619
    },
    {
      "epoch": 0.9807273857631333,
      "grad_norm": 0.39358246326446533,
      "learning_rate": 5.0963630711843334e-06,
      "loss": 0.3341,
      "step": 12620
    },
    {
      "epoch": 0.9808050979173143,
      "grad_norm": 0.4532628655433655,
      "learning_rate": 5.095974510413429e-06,
      "loss": 0.1888,
      "step": 12621
    },
    {
      "epoch": 0.9808828100714951,
      "grad_norm": 0.27824047207832336,
      "learning_rate": 5.095585949642524e-06,
      "loss": 0.1481,
      "step": 12622
    },
    {
      "epoch": 0.9809605222256761,
      "grad_norm": 0.6263450980186462,
      "learning_rate": 5.09519738887162e-06,
      "loss": 0.2307,
      "step": 12623
    },
    {
      "epoch": 0.981038234379857,
      "grad_norm": 0.3646722733974457,
      "learning_rate": 5.094808828100716e-06,
      "loss": 0.0535,
      "step": 12624
    },
    {
      "epoch": 0.9811159465340379,
      "grad_norm": 0.648134708404541,
      "learning_rate": 5.094420267329811e-06,
      "loss": 0.2475,
      "step": 12625
    },
    {
      "epoch": 0.9811936586882188,
      "grad_norm": 0.14449062943458557,
      "learning_rate": 5.0940317065589065e-06,
      "loss": 0.0423,
      "step": 12626
    },
    {
      "epoch": 0.9812713708423998,
      "grad_norm": 0.4000857174396515,
      "learning_rate": 5.093643145788002e-06,
      "loss": 0.0808,
      "step": 12627
    },
    {
      "epoch": 0.9813490829965806,
      "grad_norm": 0.6224083304405212,
      "learning_rate": 5.093254585017096e-06,
      "loss": 0.2232,
      "step": 12628
    },
    {
      "epoch": 0.9814267951507616,
      "grad_norm": 0.41537749767303467,
      "learning_rate": 5.092866024246192e-06,
      "loss": 0.0962,
      "step": 12629
    },
    {
      "epoch": 0.9815045073049425,
      "grad_norm": 0.4854942858219147,
      "learning_rate": 5.092477463475288e-06,
      "loss": 0.2192,
      "step": 12630
    },
    {
      "epoch": 0.9815822194591234,
      "grad_norm": 0.7898426055908203,
      "learning_rate": 5.092088902704383e-06,
      "loss": 0.2734,
      "step": 12631
    },
    {
      "epoch": 0.9816599316133043,
      "grad_norm": 0.4887191355228424,
      "learning_rate": 5.091700341933479e-06,
      "loss": 0.3008,
      "step": 12632
    },
    {
      "epoch": 0.9817376437674852,
      "grad_norm": 0.2925123870372772,
      "learning_rate": 5.0913117811625746e-06,
      "loss": 0.0988,
      "step": 12633
    },
    {
      "epoch": 0.9818153559216661,
      "grad_norm": 0.3294634521007538,
      "learning_rate": 5.0909232203916695e-06,
      "loss": 0.1051,
      "step": 12634
    },
    {
      "epoch": 0.9818930680758471,
      "grad_norm": 0.21857216954231262,
      "learning_rate": 5.090534659620765e-06,
      "loss": 0.1834,
      "step": 12635
    },
    {
      "epoch": 0.9819707802300279,
      "grad_norm": 0.21093443036079407,
      "learning_rate": 5.090146098849861e-06,
      "loss": 0.0674,
      "step": 12636
    },
    {
      "epoch": 0.9820484923842089,
      "grad_norm": 0.4606547951698303,
      "learning_rate": 5.089757538078955e-06,
      "loss": 0.1736,
      "step": 12637
    },
    {
      "epoch": 0.9821262045383898,
      "grad_norm": 0.3630090355873108,
      "learning_rate": 5.089368977308051e-06,
      "loss": 0.1633,
      "step": 12638
    },
    {
      "epoch": 0.9822039166925707,
      "grad_norm": 0.26473671197891235,
      "learning_rate": 5.088980416537147e-06,
      "loss": 0.0466,
      "step": 12639
    },
    {
      "epoch": 0.9822816288467516,
      "grad_norm": 0.5060771107673645,
      "learning_rate": 5.088591855766242e-06,
      "loss": 0.1489,
      "step": 12640
    },
    {
      "epoch": 0.9823593410009326,
      "grad_norm": 0.5940549373626709,
      "learning_rate": 5.0882032949953375e-06,
      "loss": 0.6678,
      "step": 12641
    },
    {
      "epoch": 0.9824370531551134,
      "grad_norm": 0.4795408546924591,
      "learning_rate": 5.087814734224433e-06,
      "loss": 0.0966,
      "step": 12642
    },
    {
      "epoch": 0.9825147653092944,
      "grad_norm": 0.4672399163246155,
      "learning_rate": 5.087426173453529e-06,
      "loss": 0.2428,
      "step": 12643
    },
    {
      "epoch": 0.9825924774634753,
      "grad_norm": 0.4819662868976593,
      "learning_rate": 5.087037612682624e-06,
      "loss": 0.3364,
      "step": 12644
    },
    {
      "epoch": 0.9826701896176562,
      "grad_norm": 0.785649299621582,
      "learning_rate": 5.08664905191172e-06,
      "loss": 0.2688,
      "step": 12645
    },
    {
      "epoch": 0.9827479017718371,
      "grad_norm": 0.1651293933391571,
      "learning_rate": 5.086260491140816e-06,
      "loss": 0.0898,
      "step": 12646
    },
    {
      "epoch": 0.9828256139260181,
      "grad_norm": 0.3028450906276703,
      "learning_rate": 5.08587193036991e-06,
      "loss": 0.1432,
      "step": 12647
    },
    {
      "epoch": 0.9829033260801989,
      "grad_norm": 0.3716539740562439,
      "learning_rate": 5.085483369599006e-06,
      "loss": 0.1648,
      "step": 12648
    },
    {
      "epoch": 0.9829810382343799,
      "grad_norm": 0.45823386311531067,
      "learning_rate": 5.085094808828101e-06,
      "loss": 0.5143,
      "step": 12649
    },
    {
      "epoch": 0.9830587503885607,
      "grad_norm": 0.38019269704818726,
      "learning_rate": 5.084706248057196e-06,
      "loss": 0.5499,
      "step": 12650
    },
    {
      "epoch": 0.9831364625427417,
      "grad_norm": 0.6114362478256226,
      "learning_rate": 5.084317687286292e-06,
      "loss": 0.3346,
      "step": 12651
    },
    {
      "epoch": 0.9832141746969226,
      "grad_norm": 0.3754236102104187,
      "learning_rate": 5.083929126515388e-06,
      "loss": 0.1019,
      "step": 12652
    },
    {
      "epoch": 0.9832918868511035,
      "grad_norm": 0.3678847849369049,
      "learning_rate": 5.083540565744483e-06,
      "loss": 0.2069,
      "step": 12653
    },
    {
      "epoch": 0.9833695990052844,
      "grad_norm": 0.39728447794914246,
      "learning_rate": 5.083152004973579e-06,
      "loss": 0.0972,
      "step": 12654
    },
    {
      "epoch": 0.9834473111594654,
      "grad_norm": 0.29336193203926086,
      "learning_rate": 5.0827634442026745e-06,
      "loss": 0.0923,
      "step": 12655
    },
    {
      "epoch": 0.9835250233136462,
      "grad_norm": 0.28752368688583374,
      "learning_rate": 5.0823748834317686e-06,
      "loss": 0.1427,
      "step": 12656
    },
    {
      "epoch": 0.9836027354678272,
      "grad_norm": 0.26882436871528625,
      "learning_rate": 5.081986322660864e-06,
      "loss": 0.125,
      "step": 12657
    },
    {
      "epoch": 0.9836804476220081,
      "grad_norm": 0.2384205013513565,
      "learning_rate": 5.08159776188996e-06,
      "loss": 0.0956,
      "step": 12658
    },
    {
      "epoch": 0.983758159776189,
      "grad_norm": 0.33817750215530396,
      "learning_rate": 5.081209201119055e-06,
      "loss": 0.2738,
      "step": 12659
    },
    {
      "epoch": 0.9838358719303699,
      "grad_norm": 0.7375668287277222,
      "learning_rate": 5.080820640348151e-06,
      "loss": 0.3021,
      "step": 12660
    },
    {
      "epoch": 0.9839135840845509,
      "grad_norm": 0.45726272463798523,
      "learning_rate": 5.080432079577247e-06,
      "loss": 0.132,
      "step": 12661
    },
    {
      "epoch": 0.9839912962387317,
      "grad_norm": 0.3219189941883087,
      "learning_rate": 5.080043518806342e-06,
      "loss": 0.048,
      "step": 12662
    },
    {
      "epoch": 0.9840690083929127,
      "grad_norm": 0.27141839265823364,
      "learning_rate": 5.0796549580354374e-06,
      "loss": 0.142,
      "step": 12663
    },
    {
      "epoch": 0.9841467205470935,
      "grad_norm": 0.3965209126472473,
      "learning_rate": 5.079266397264533e-06,
      "loss": 0.1322,
      "step": 12664
    },
    {
      "epoch": 0.9842244327012745,
      "grad_norm": 0.4458027482032776,
      "learning_rate": 5.078877836493627e-06,
      "loss": 0.1648,
      "step": 12665
    },
    {
      "epoch": 0.9843021448554554,
      "grad_norm": 0.6497376561164856,
      "learning_rate": 5.078489275722723e-06,
      "loss": 0.2408,
      "step": 12666
    },
    {
      "epoch": 0.9843798570096363,
      "grad_norm": 0.12886624038219452,
      "learning_rate": 5.078100714951819e-06,
      "loss": 0.0197,
      "step": 12667
    },
    {
      "epoch": 0.9844575691638172,
      "grad_norm": 0.17988596856594086,
      "learning_rate": 5.077712154180914e-06,
      "loss": 0.0379,
      "step": 12668
    },
    {
      "epoch": 0.9845352813179982,
      "grad_norm": 0.3887289762496948,
      "learning_rate": 5.07732359341001e-06,
      "loss": 0.1564,
      "step": 12669
    },
    {
      "epoch": 0.984612993472179,
      "grad_norm": 0.209755539894104,
      "learning_rate": 5.0769350326391055e-06,
      "loss": 0.1021,
      "step": 12670
    },
    {
      "epoch": 0.98469070562636,
      "grad_norm": 0.1681222766637802,
      "learning_rate": 5.076546471868201e-06,
      "loss": 0.0835,
      "step": 12671
    },
    {
      "epoch": 0.9847684177805409,
      "grad_norm": 0.07832597196102142,
      "learning_rate": 5.076157911097296e-06,
      "loss": 0.0376,
      "step": 12672
    },
    {
      "epoch": 0.9848461299347218,
      "grad_norm": 0.5381059050559998,
      "learning_rate": 5.075769350326392e-06,
      "loss": 0.1972,
      "step": 12673
    },
    {
      "epoch": 0.9849238420889027,
      "grad_norm": 1.2855675220489502,
      "learning_rate": 5.075380789555488e-06,
      "loss": 0.5062,
      "step": 12674
    },
    {
      "epoch": 0.9850015542430837,
      "grad_norm": 0.5713793039321899,
      "learning_rate": 5.074992228784582e-06,
      "loss": 0.0449,
      "step": 12675
    },
    {
      "epoch": 0.9850792663972645,
      "grad_norm": 0.3366735875606537,
      "learning_rate": 5.074603668013678e-06,
      "loss": 0.1594,
      "step": 12676
    },
    {
      "epoch": 0.9851569785514455,
      "grad_norm": 0.5559985041618347,
      "learning_rate": 5.0742151072427735e-06,
      "loss": 0.1169,
      "step": 12677
    },
    {
      "epoch": 0.9852346907056264,
      "grad_norm": 0.4017028510570526,
      "learning_rate": 5.0738265464718685e-06,
      "loss": 0.1936,
      "step": 12678
    },
    {
      "epoch": 0.9853124028598073,
      "grad_norm": 0.1359982043504715,
      "learning_rate": 5.073437985700964e-06,
      "loss": 0.0836,
      "step": 12679
    },
    {
      "epoch": 0.9853901150139882,
      "grad_norm": 0.202698215842247,
      "learning_rate": 5.07304942493006e-06,
      "loss": 0.0669,
      "step": 12680
    },
    {
      "epoch": 0.985467827168169,
      "grad_norm": 0.4172418415546417,
      "learning_rate": 5.072660864159155e-06,
      "loss": 0.1685,
      "step": 12681
    },
    {
      "epoch": 0.98554553932235,
      "grad_norm": 0.4315471947193146,
      "learning_rate": 5.07227230338825e-06,
      "loss": 0.0887,
      "step": 12682
    },
    {
      "epoch": 0.985623251476531,
      "grad_norm": 0.11644192039966583,
      "learning_rate": 5.071883742617346e-06,
      "loss": 0.0235,
      "step": 12683
    },
    {
      "epoch": 0.9857009636307118,
      "grad_norm": 0.8562182188034058,
      "learning_rate": 5.071495181846441e-06,
      "loss": 0.4622,
      "step": 12684
    },
    {
      "epoch": 0.9857786757848928,
      "grad_norm": 0.31838956475257874,
      "learning_rate": 5.0711066210755365e-06,
      "loss": 0.4549,
      "step": 12685
    },
    {
      "epoch": 0.9858563879390737,
      "grad_norm": 0.37526392936706543,
      "learning_rate": 5.070718060304632e-06,
      "loss": 0.0969,
      "step": 12686
    },
    {
      "epoch": 0.9859341000932546,
      "grad_norm": 0.11669106781482697,
      "learning_rate": 5.070329499533727e-06,
      "loss": 0.007,
      "step": 12687
    },
    {
      "epoch": 0.9860118122474355,
      "grad_norm": 0.09752409905195236,
      "learning_rate": 5.069940938762823e-06,
      "loss": 0.0337,
      "step": 12688
    },
    {
      "epoch": 0.9860895244016165,
      "grad_norm": 0.3872983753681183,
      "learning_rate": 5.069552377991919e-06,
      "loss": 0.2001,
      "step": 12689
    },
    {
      "epoch": 0.9861672365557973,
      "grad_norm": 0.12809500098228455,
      "learning_rate": 5.069163817221013e-06,
      "loss": 0.018,
      "step": 12690
    },
    {
      "epoch": 0.9862449487099783,
      "grad_norm": 0.4980471432209015,
      "learning_rate": 5.068775256450109e-06,
      "loss": 0.5022,
      "step": 12691
    },
    {
      "epoch": 0.9863226608641592,
      "grad_norm": 0.19488473236560822,
      "learning_rate": 5.0683866956792045e-06,
      "loss": 0.2811,
      "step": 12692
    },
    {
      "epoch": 0.98640037301834,
      "grad_norm": 0.5805014967918396,
      "learning_rate": 5.0679981349082995e-06,
      "loss": 0.3194,
      "step": 12693
    },
    {
      "epoch": 0.986478085172521,
      "grad_norm": 0.6912997961044312,
      "learning_rate": 5.067609574137395e-06,
      "loss": 0.145,
      "step": 12694
    },
    {
      "epoch": 0.9865557973267018,
      "grad_norm": 0.13207003474235535,
      "learning_rate": 5.067221013366491e-06,
      "loss": 0.0217,
      "step": 12695
    },
    {
      "epoch": 0.9866335094808828,
      "grad_norm": 0.4081176817417145,
      "learning_rate": 5.066832452595586e-06,
      "loss": 0.2425,
      "step": 12696
    },
    {
      "epoch": 0.9867112216350638,
      "grad_norm": 0.2065018266439438,
      "learning_rate": 5.066443891824682e-06,
      "loss": 0.0289,
      "step": 12697
    },
    {
      "epoch": 0.9867889337892446,
      "grad_norm": 0.21709562838077545,
      "learning_rate": 5.066055331053778e-06,
      "loss": 0.0925,
      "step": 12698
    },
    {
      "epoch": 0.9868666459434255,
      "grad_norm": 0.5387577414512634,
      "learning_rate": 5.065666770282872e-06,
      "loss": 0.0794,
      "step": 12699
    },
    {
      "epoch": 0.9869443580976065,
      "grad_norm": 0.5279303789138794,
      "learning_rate": 5.0652782095119675e-06,
      "loss": 0.1403,
      "step": 12700
    },
    {
      "epoch": 0.9870220702517873,
      "grad_norm": 0.15918630361557007,
      "learning_rate": 5.064889648741063e-06,
      "loss": 0.0341,
      "step": 12701
    },
    {
      "epoch": 0.9870997824059683,
      "grad_norm": 0.431281179189682,
      "learning_rate": 5.064501087970159e-06,
      "loss": 0.3715,
      "step": 12702
    },
    {
      "epoch": 0.9871774945601492,
      "grad_norm": 0.49924010038375854,
      "learning_rate": 5.064112527199254e-06,
      "loss": 0.3012,
      "step": 12703
    },
    {
      "epoch": 0.9872552067143301,
      "grad_norm": 0.6372382044792175,
      "learning_rate": 5.06372396642835e-06,
      "loss": 0.2491,
      "step": 12704
    },
    {
      "epoch": 0.987332918868511,
      "grad_norm": 0.3424290418624878,
      "learning_rate": 5.063335405657446e-06,
      "loss": 0.2856,
      "step": 12705
    },
    {
      "epoch": 0.987410631022692,
      "grad_norm": 0.6684541702270508,
      "learning_rate": 5.062946844886541e-06,
      "loss": 0.2042,
      "step": 12706
    },
    {
      "epoch": 0.9874883431768728,
      "grad_norm": 0.4486595094203949,
      "learning_rate": 5.062558284115636e-06,
      "loss": 0.1536,
      "step": 12707
    },
    {
      "epoch": 0.9875660553310538,
      "grad_norm": 0.5032650828361511,
      "learning_rate": 5.062169723344732e-06,
      "loss": 0.1899,
      "step": 12708
    },
    {
      "epoch": 0.9876437674852346,
      "grad_norm": 0.02488936483860016,
      "learning_rate": 5.061781162573826e-06,
      "loss": 0.0029,
      "step": 12709
    },
    {
      "epoch": 0.9877214796394156,
      "grad_norm": 0.9828674793243408,
      "learning_rate": 5.061392601802922e-06,
      "loss": 0.2707,
      "step": 12710
    },
    {
      "epoch": 0.9877991917935965,
      "grad_norm": 0.6451132893562317,
      "learning_rate": 5.061004041032018e-06,
      "loss": 0.3891,
      "step": 12711
    },
    {
      "epoch": 0.9878769039477774,
      "grad_norm": 0.2766589820384979,
      "learning_rate": 5.060615480261113e-06,
      "loss": 0.1311,
      "step": 12712
    },
    {
      "epoch": 0.9879546161019583,
      "grad_norm": 0.4372040927410126,
      "learning_rate": 5.060226919490209e-06,
      "loss": 0.0218,
      "step": 12713
    },
    {
      "epoch": 0.9880323282561393,
      "grad_norm": 0.27764180302619934,
      "learning_rate": 5.0598383587193045e-06,
      "loss": 0.1561,
      "step": 12714
    },
    {
      "epoch": 0.9881100404103201,
      "grad_norm": 0.30392369627952576,
      "learning_rate": 5.059449797948399e-06,
      "loss": 0.144,
      "step": 12715
    },
    {
      "epoch": 0.9881877525645011,
      "grad_norm": 0.2810435891151428,
      "learning_rate": 5.059061237177495e-06,
      "loss": 0.1439,
      "step": 12716
    },
    {
      "epoch": 0.988265464718682,
      "grad_norm": 0.09172466397285461,
      "learning_rate": 5.058672676406591e-06,
      "loss": 0.011,
      "step": 12717
    },
    {
      "epoch": 0.9883431768728629,
      "grad_norm": 0.23439623415470123,
      "learning_rate": 5.058284115635685e-06,
      "loss": 0.058,
      "step": 12718
    },
    {
      "epoch": 0.9884208890270438,
      "grad_norm": 0.43022462725639343,
      "learning_rate": 5.057895554864781e-06,
      "loss": 0.1457,
      "step": 12719
    },
    {
      "epoch": 0.9884986011812248,
      "grad_norm": 0.46575069427490234,
      "learning_rate": 5.057506994093877e-06,
      "loss": 0.1768,
      "step": 12720
    },
    {
      "epoch": 0.9885763133354056,
      "grad_norm": 0.43930163979530334,
      "learning_rate": 5.057118433322972e-06,
      "loss": 0.09,
      "step": 12721
    },
    {
      "epoch": 0.9886540254895866,
      "grad_norm": 0.34836092591285706,
      "learning_rate": 5.0567298725520674e-06,
      "loss": 0.1355,
      "step": 12722
    },
    {
      "epoch": 0.9887317376437675,
      "grad_norm": 0.36606648564338684,
      "learning_rate": 5.056341311781163e-06,
      "loss": 0.1304,
      "step": 12723
    },
    {
      "epoch": 0.9888094497979484,
      "grad_norm": 0.7944069504737854,
      "learning_rate": 5.055952751010258e-06,
      "loss": 0.5256,
      "step": 12724
    },
    {
      "epoch": 0.9888871619521293,
      "grad_norm": 0.36764395236968994,
      "learning_rate": 5.055564190239354e-06,
      "loss": 0.1014,
      "step": 12725
    },
    {
      "epoch": 0.9889648741063102,
      "grad_norm": 0.5716530084609985,
      "learning_rate": 5.05517562946845e-06,
      "loss": 0.2539,
      "step": 12726
    },
    {
      "epoch": 0.9890425862604911,
      "grad_norm": 0.2806258201599121,
      "learning_rate": 5.054787068697544e-06,
      "loss": 0.1623,
      "step": 12727
    },
    {
      "epoch": 0.9891202984146721,
      "grad_norm": 0.4922722280025482,
      "learning_rate": 5.05439850792664e-06,
      "loss": 0.1918,
      "step": 12728
    },
    {
      "epoch": 0.9891980105688529,
      "grad_norm": 0.21291233599185944,
      "learning_rate": 5.0540099471557355e-06,
      "loss": 0.0338,
      "step": 12729
    },
    {
      "epoch": 0.9892757227230339,
      "grad_norm": 0.369628369808197,
      "learning_rate": 5.0536213863848304e-06,
      "loss": 0.2026,
      "step": 12730
    },
    {
      "epoch": 0.9893534348772148,
      "grad_norm": 0.09736009687185287,
      "learning_rate": 5.053232825613926e-06,
      "loss": 0.0193,
      "step": 12731
    },
    {
      "epoch": 0.9894311470313957,
      "grad_norm": 0.9022911190986633,
      "learning_rate": 5.052844264843022e-06,
      "loss": 0.2687,
      "step": 12732
    },
    {
      "epoch": 0.9895088591855766,
      "grad_norm": 0.2718574106693268,
      "learning_rate": 5.052455704072118e-06,
      "loss": 0.0563,
      "step": 12733
    },
    {
      "epoch": 0.9895865713397576,
      "grad_norm": 0.3208558261394501,
      "learning_rate": 5.052067143301213e-06,
      "loss": 0.0414,
      "step": 12734
    },
    {
      "epoch": 0.9896642834939384,
      "grad_norm": 0.039424166083335876,
      "learning_rate": 5.0516785825303086e-06,
      "loss": 0.0175,
      "step": 12735
    },
    {
      "epoch": 0.9897419956481194,
      "grad_norm": 0.5499714016914368,
      "learning_rate": 5.051290021759404e-06,
      "loss": 0.2788,
      "step": 12736
    },
    {
      "epoch": 0.9898197078023003,
      "grad_norm": 0.41448625922203064,
      "learning_rate": 5.0509014609884985e-06,
      "loss": 0.1387,
      "step": 12737
    },
    {
      "epoch": 0.9898974199564812,
      "grad_norm": 0.33744513988494873,
      "learning_rate": 5.050512900217594e-06,
      "loss": 0.1563,
      "step": 12738
    },
    {
      "epoch": 0.9899751321106621,
      "grad_norm": 0.5280469059944153,
      "learning_rate": 5.05012433944669e-06,
      "loss": 0.1127,
      "step": 12739
    },
    {
      "epoch": 0.990052844264843,
      "grad_norm": 0.14090308547019958,
      "learning_rate": 5.049735778675785e-06,
      "loss": 0.0287,
      "step": 12740
    },
    {
      "epoch": 0.9901305564190239,
      "grad_norm": 0.29302453994750977,
      "learning_rate": 5.049347217904881e-06,
      "loss": 0.1541,
      "step": 12741
    },
    {
      "epoch": 0.9902082685732049,
      "grad_norm": 0.5607009530067444,
      "learning_rate": 5.048958657133977e-06,
      "loss": 0.4036,
      "step": 12742
    },
    {
      "epoch": 0.9902859807273857,
      "grad_norm": 0.5003174543380737,
      "learning_rate": 5.0485700963630715e-06,
      "loss": 0.1958,
      "step": 12743
    },
    {
      "epoch": 0.9903636928815667,
      "grad_norm": 0.12816230952739716,
      "learning_rate": 5.048181535592167e-06,
      "loss": 0.0385,
      "step": 12744
    },
    {
      "epoch": 0.9904414050357476,
      "grad_norm": 0.7215830087661743,
      "learning_rate": 5.047792974821263e-06,
      "loss": 0.2497,
      "step": 12745
    },
    {
      "epoch": 0.9905191171899285,
      "grad_norm": 0.21771404147148132,
      "learning_rate": 5.047404414050357e-06,
      "loss": 0.0354,
      "step": 12746
    },
    {
      "epoch": 0.9905968293441094,
      "grad_norm": 0.4201849102973938,
      "learning_rate": 5.047015853279453e-06,
      "loss": 0.0807,
      "step": 12747
    },
    {
      "epoch": 0.9906745414982904,
      "grad_norm": 1.3150124549865723,
      "learning_rate": 5.046627292508549e-06,
      "loss": 0.3296,
      "step": 12748
    },
    {
      "epoch": 0.9907522536524712,
      "grad_norm": 0.24149253964424133,
      "learning_rate": 5.046238731737644e-06,
      "loss": 0.0408,
      "step": 12749
    },
    {
      "epoch": 0.9908299658066522,
      "grad_norm": 0.13723145425319672,
      "learning_rate": 5.04585017096674e-06,
      "loss": 0.0227,
      "step": 12750
    },
    {
      "epoch": 0.9909076779608331,
      "grad_norm": 0.5004657506942749,
      "learning_rate": 5.045461610195835e-06,
      "loss": 0.2955,
      "step": 12751
    },
    {
      "epoch": 0.990985390115014,
      "grad_norm": 0.24140186607837677,
      "learning_rate": 5.04507304942493e-06,
      "loss": 0.0928,
      "step": 12752
    },
    {
      "epoch": 0.9910631022691949,
      "grad_norm": 0.16482526063919067,
      "learning_rate": 5.044684488654026e-06,
      "loss": 0.0468,
      "step": 12753
    },
    {
      "epoch": 0.9911408144233759,
      "grad_norm": 0.3156753480434418,
      "learning_rate": 5.044295927883122e-06,
      "loss": 0.0415,
      "step": 12754
    },
    {
      "epoch": 0.9912185265775567,
      "grad_norm": 0.32550475001335144,
      "learning_rate": 5.043907367112216e-06,
      "loss": 0.0971,
      "step": 12755
    },
    {
      "epoch": 0.9912962387317377,
      "grad_norm": 0.13916140794754028,
      "learning_rate": 5.043518806341312e-06,
      "loss": 0.0317,
      "step": 12756
    },
    {
      "epoch": 0.9913739508859185,
      "grad_norm": 0.2651875615119934,
      "learning_rate": 5.043130245570408e-06,
      "loss": 0.1043,
      "step": 12757
    },
    {
      "epoch": 0.9914516630400995,
      "grad_norm": 0.5407810211181641,
      "learning_rate": 5.0427416847995026e-06,
      "loss": 0.2196,
      "step": 12758
    },
    {
      "epoch": 0.9915293751942804,
      "grad_norm": 1.1449358463287354,
      "learning_rate": 5.042353124028598e-06,
      "loss": 0.2681,
      "step": 12759
    },
    {
      "epoch": 0.9916070873484613,
      "grad_norm": 0.42757418751716614,
      "learning_rate": 5.041964563257694e-06,
      "loss": 0.1765,
      "step": 12760
    },
    {
      "epoch": 0.9916847995026422,
      "grad_norm": 0.5982403755187988,
      "learning_rate": 5.041576002486789e-06,
      "loss": 0.2111,
      "step": 12761
    },
    {
      "epoch": 0.9917625116568232,
      "grad_norm": 0.5168637037277222,
      "learning_rate": 5.041187441715885e-06,
      "loss": 0.0789,
      "step": 12762
    },
    {
      "epoch": 0.991840223811004,
      "grad_norm": 0.3045295774936676,
      "learning_rate": 5.040798880944981e-06,
      "loss": 0.1716,
      "step": 12763
    },
    {
      "epoch": 0.991917935965185,
      "grad_norm": 0.6612604260444641,
      "learning_rate": 5.0404103201740765e-06,
      "loss": 0.3353,
      "step": 12764
    },
    {
      "epoch": 0.9919956481193659,
      "grad_norm": 0.37094196677207947,
      "learning_rate": 5.040021759403171e-06,
      "loss": 0.187,
      "step": 12765
    },
    {
      "epoch": 0.9920733602735468,
      "grad_norm": 0.3501015603542328,
      "learning_rate": 5.039633198632266e-06,
      "loss": 0.1161,
      "step": 12766
    },
    {
      "epoch": 0.9921510724277277,
      "grad_norm": 0.34595662355422974,
      "learning_rate": 5.039244637861362e-06,
      "loss": 0.2282,
      "step": 12767
    },
    {
      "epoch": 0.9922287845819087,
      "grad_norm": 0.6250573396682739,
      "learning_rate": 5.038856077090457e-06,
      "loss": 0.4116,
      "step": 12768
    },
    {
      "epoch": 0.9923064967360895,
      "grad_norm": 0.5954515337944031,
      "learning_rate": 5.038467516319553e-06,
      "loss": 0.1875,
      "step": 12769
    },
    {
      "epoch": 0.9923842088902705,
      "grad_norm": 0.5918124914169312,
      "learning_rate": 5.038078955548649e-06,
      "loss": 0.216,
      "step": 12770
    },
    {
      "epoch": 0.9924619210444513,
      "grad_norm": 0.6830294728279114,
      "learning_rate": 5.037690394777744e-06,
      "loss": 0.3093,
      "step": 12771
    },
    {
      "epoch": 0.9925396331986323,
      "grad_norm": 0.44272881746292114,
      "learning_rate": 5.0373018340068395e-06,
      "loss": 0.5217,
      "step": 12772
    },
    {
      "epoch": 0.9926173453528132,
      "grad_norm": 0.3656601309776306,
      "learning_rate": 5.036913273235935e-06,
      "loss": 0.1745,
      "step": 12773
    },
    {
      "epoch": 0.992695057506994,
      "grad_norm": 0.2351849377155304,
      "learning_rate": 5.036524712465029e-06,
      "loss": 0.0476,
      "step": 12774
    },
    {
      "epoch": 0.992772769661175,
      "grad_norm": 0.5651596784591675,
      "learning_rate": 5.036136151694125e-06,
      "loss": 0.2745,
      "step": 12775
    },
    {
      "epoch": 0.992850481815356,
      "grad_norm": 0.35845357179641724,
      "learning_rate": 5.035747590923221e-06,
      "loss": 0.1548,
      "step": 12776
    },
    {
      "epoch": 0.9929281939695368,
      "grad_norm": 0.22348172962665558,
      "learning_rate": 5.035359030152316e-06,
      "loss": 0.0327,
      "step": 12777
    },
    {
      "epoch": 0.9930059061237178,
      "grad_norm": 0.6239669322967529,
      "learning_rate": 5.034970469381412e-06,
      "loss": 0.7327,
      "step": 12778
    },
    {
      "epoch": 0.9930836182778987,
      "grad_norm": 0.5190632939338684,
      "learning_rate": 5.0345819086105075e-06,
      "loss": 0.141,
      "step": 12779
    },
    {
      "epoch": 0.9931613304320795,
      "grad_norm": 0.9277952313423157,
      "learning_rate": 5.0341933478396025e-06,
      "loss": 0.5616,
      "step": 12780
    },
    {
      "epoch": 0.9932390425862605,
      "grad_norm": 0.29149889945983887,
      "learning_rate": 5.033804787068698e-06,
      "loss": 0.0961,
      "step": 12781
    },
    {
      "epoch": 0.9933167547404415,
      "grad_norm": 0.5618006587028503,
      "learning_rate": 5.033416226297794e-06,
      "loss": 0.1356,
      "step": 12782
    },
    {
      "epoch": 0.9933944668946223,
      "grad_norm": 0.5433986186981201,
      "learning_rate": 5.033027665526888e-06,
      "loss": 0.3718,
      "step": 12783
    },
    {
      "epoch": 0.9934721790488033,
      "grad_norm": 0.4122157096862793,
      "learning_rate": 5.032639104755984e-06,
      "loss": 0.0557,
      "step": 12784
    },
    {
      "epoch": 0.9935498912029841,
      "grad_norm": 0.2680802345275879,
      "learning_rate": 5.03225054398508e-06,
      "loss": 0.0438,
      "step": 12785
    },
    {
      "epoch": 0.993627603357165,
      "grad_norm": 0.4924311637878418,
      "learning_rate": 5.031861983214175e-06,
      "loss": 0.4997,
      "step": 12786
    },
    {
      "epoch": 0.993705315511346,
      "grad_norm": 0.026892075315117836,
      "learning_rate": 5.0314734224432705e-06,
      "loss": 0.0032,
      "step": 12787
    },
    {
      "epoch": 0.9937830276655268,
      "grad_norm": 0.02740127220749855,
      "learning_rate": 5.031084861672366e-06,
      "loss": 0.0042,
      "step": 12788
    },
    {
      "epoch": 0.9938607398197078,
      "grad_norm": 0.16286304593086243,
      "learning_rate": 5.030696300901461e-06,
      "loss": 0.0393,
      "step": 12789
    },
    {
      "epoch": 0.9939384519738887,
      "grad_norm": 0.14580164849758148,
      "learning_rate": 5.030307740130557e-06,
      "loss": 0.0264,
      "step": 12790
    },
    {
      "epoch": 0.9940161641280696,
      "grad_norm": 0.25072595477104187,
      "learning_rate": 5.029919179359653e-06,
      "loss": 0.1874,
      "step": 12791
    },
    {
      "epoch": 0.9940938762822505,
      "grad_norm": 0.6821562647819519,
      "learning_rate": 5.029530618588747e-06,
      "loss": 0.3186,
      "step": 12792
    },
    {
      "epoch": 0.9941715884364315,
      "grad_norm": 0.864914059638977,
      "learning_rate": 5.029142057817843e-06,
      "loss": 0.3933,
      "step": 12793
    },
    {
      "epoch": 0.9942493005906123,
      "grad_norm": 1.0889781713485718,
      "learning_rate": 5.0287534970469386e-06,
      "loss": 0.5786,
      "step": 12794
    },
    {
      "epoch": 0.9943270127447933,
      "grad_norm": 0.39460110664367676,
      "learning_rate": 5.028364936276034e-06,
      "loss": 0.1397,
      "step": 12795
    },
    {
      "epoch": 0.9944047248989742,
      "grad_norm": 0.46829044818878174,
      "learning_rate": 5.027976375505129e-06,
      "loss": 0.0242,
      "step": 12796
    },
    {
      "epoch": 0.9944824370531551,
      "grad_norm": 0.32978108525276184,
      "learning_rate": 5.027587814734225e-06,
      "loss": 0.1085,
      "step": 12797
    },
    {
      "epoch": 0.994560149207336,
      "grad_norm": 0.6701361536979675,
      "learning_rate": 5.027199253963321e-06,
      "loss": 0.1877,
      "step": 12798
    },
    {
      "epoch": 0.994637861361517,
      "grad_norm": 1.2924277782440186,
      "learning_rate": 5.026810693192416e-06,
      "loss": 0.4352,
      "step": 12799
    },
    {
      "epoch": 0.9947155735156978,
      "grad_norm": 1.1844680309295654,
      "learning_rate": 5.026422132421512e-06,
      "loss": 0.3978,
      "step": 12800
    },
    {
      "epoch": 0.9947932856698788,
      "grad_norm": 0.1420409083366394,
      "learning_rate": 5.0260335716506074e-06,
      "loss": 0.0412,
      "step": 12801
    },
    {
      "epoch": 0.9948709978240596,
      "grad_norm": 0.586755633354187,
      "learning_rate": 5.0256450108797015e-06,
      "loss": 0.3484,
      "step": 12802
    },
    {
      "epoch": 0.9949487099782406,
      "grad_norm": 0.2930057644844055,
      "learning_rate": 5.025256450108797e-06,
      "loss": 0.0429,
      "step": 12803
    },
    {
      "epoch": 0.9950264221324215,
      "grad_norm": 0.1872037947177887,
      "learning_rate": 5.024867889337893e-06,
      "loss": 0.065,
      "step": 12804
    },
    {
      "epoch": 0.9951041342866024,
      "grad_norm": 0.6066544651985168,
      "learning_rate": 5.024479328566988e-06,
      "loss": 0.6446,
      "step": 12805
    },
    {
      "epoch": 0.9951818464407833,
      "grad_norm": 0.16962558031082153,
      "learning_rate": 5.024090767796084e-06,
      "loss": 0.043,
      "step": 12806
    },
    {
      "epoch": 0.9952595585949643,
      "grad_norm": 0.6538004875183105,
      "learning_rate": 5.02370220702518e-06,
      "loss": 0.2827,
      "step": 12807
    },
    {
      "epoch": 0.9953372707491451,
      "grad_norm": 0.2529970109462738,
      "learning_rate": 5.023313646254275e-06,
      "loss": 0.0513,
      "step": 12808
    },
    {
      "epoch": 0.9954149829033261,
      "grad_norm": 0.1148708313703537,
      "learning_rate": 5.0229250854833696e-06,
      "loss": 0.0302,
      "step": 12809
    },
    {
      "epoch": 0.995492695057507,
      "grad_norm": 0.5938360095024109,
      "learning_rate": 5.022536524712465e-06,
      "loss": 0.1087,
      "step": 12810
    },
    {
      "epoch": 0.9955704072116879,
      "grad_norm": 0.21815674006938934,
      "learning_rate": 5.02214796394156e-06,
      "loss": 0.0759,
      "step": 12811
    },
    {
      "epoch": 0.9956481193658688,
      "grad_norm": 0.4732336103916168,
      "learning_rate": 5.021759403170656e-06,
      "loss": 0.4492,
      "step": 12812
    },
    {
      "epoch": 0.9957258315200498,
      "grad_norm": 0.35346052050590515,
      "learning_rate": 5.021370842399752e-06,
      "loss": 0.2038,
      "step": 12813
    },
    {
      "epoch": 0.9958035436742306,
      "grad_norm": 0.34403878450393677,
      "learning_rate": 5.020982281628847e-06,
      "loss": 0.1845,
      "step": 12814
    },
    {
      "epoch": 0.9958812558284116,
      "grad_norm": 0.578414797782898,
      "learning_rate": 5.020593720857943e-06,
      "loss": 0.6859,
      "step": 12815
    },
    {
      "epoch": 0.9959589679825924,
      "grad_norm": 0.5100753307342529,
      "learning_rate": 5.0202051600870385e-06,
      "loss": 0.2351,
      "step": 12816
    },
    {
      "epoch": 0.9960366801367734,
      "grad_norm": 0.32520854473114014,
      "learning_rate": 5.0198165993161326e-06,
      "loss": 0.0665,
      "step": 12817
    },
    {
      "epoch": 0.9961143922909543,
      "grad_norm": 0.2131662219762802,
      "learning_rate": 5.019428038545228e-06,
      "loss": 0.0861,
      "step": 12818
    },
    {
      "epoch": 0.9961921044451352,
      "grad_norm": 0.35887113213539124,
      "learning_rate": 5.019039477774324e-06,
      "loss": 0.1477,
      "step": 12819
    },
    {
      "epoch": 0.9962698165993161,
      "grad_norm": 0.3271704614162445,
      "learning_rate": 5.018650917003419e-06,
      "loss": 0.0599,
      "step": 12820
    },
    {
      "epoch": 0.9963475287534971,
      "grad_norm": 0.5250306129455566,
      "learning_rate": 5.018262356232515e-06,
      "loss": 0.1814,
      "step": 12821
    },
    {
      "epoch": 0.9964252409076779,
      "grad_norm": 0.2841602563858032,
      "learning_rate": 5.017873795461611e-06,
      "loss": 0.1071,
      "step": 12822
    },
    {
      "epoch": 0.9965029530618589,
      "grad_norm": 0.3864142894744873,
      "learning_rate": 5.0174852346907065e-06,
      "loss": 0.1685,
      "step": 12823
    },
    {
      "epoch": 0.9965806652160398,
      "grad_norm": 0.4465785622596741,
      "learning_rate": 5.0170966739198014e-06,
      "loss": 0.0717,
      "step": 12824
    },
    {
      "epoch": 0.9966583773702207,
      "grad_norm": 0.3573746383190155,
      "learning_rate": 5.016708113148897e-06,
      "loss": 0.1524,
      "step": 12825
    },
    {
      "epoch": 0.9967360895244016,
      "grad_norm": 0.13318800926208496,
      "learning_rate": 5.016319552377993e-06,
      "loss": 0.0273,
      "step": 12826
    },
    {
      "epoch": 0.9968138016785826,
      "grad_norm": 0.5574960112571716,
      "learning_rate": 5.015930991607087e-06,
      "loss": 0.4265,
      "step": 12827
    },
    {
      "epoch": 0.9968915138327634,
      "grad_norm": 0.36921021342277527,
      "learning_rate": 5.015542430836183e-06,
      "loss": 0.1768,
      "step": 12828
    },
    {
      "epoch": 0.9969692259869444,
      "grad_norm": 0.38449081778526306,
      "learning_rate": 5.015153870065279e-06,
      "loss": 0.0894,
      "step": 12829
    },
    {
      "epoch": 0.9970469381411253,
      "grad_norm": 0.6559488773345947,
      "learning_rate": 5.014765309294374e-06,
      "loss": 0.4323,
      "step": 12830
    },
    {
      "epoch": 0.9971246502953062,
      "grad_norm": 0.7569707632064819,
      "learning_rate": 5.0143767485234695e-06,
      "loss": 0.5759,
      "step": 12831
    },
    {
      "epoch": 0.9972023624494871,
      "grad_norm": 0.8206492066383362,
      "learning_rate": 5.013988187752565e-06,
      "loss": 0.119,
      "step": 12832
    },
    {
      "epoch": 0.997280074603668,
      "grad_norm": 0.4427472949028015,
      "learning_rate": 5.01359962698166e-06,
      "loss": 0.1921,
      "step": 12833
    },
    {
      "epoch": 0.9973577867578489,
      "grad_norm": 0.49864041805267334,
      "learning_rate": 5.013211066210756e-06,
      "loss": 0.2808,
      "step": 12834
    },
    {
      "epoch": 0.9974354989120299,
      "grad_norm": 0.3086891770362854,
      "learning_rate": 5.012822505439852e-06,
      "loss": 0.1078,
      "step": 12835
    },
    {
      "epoch": 0.9975132110662107,
      "grad_norm": 0.4294929802417755,
      "learning_rate": 5.012433944668946e-06,
      "loss": 0.2019,
      "step": 12836
    },
    {
      "epoch": 0.9975909232203917,
      "grad_norm": 0.7286332845687866,
      "learning_rate": 5.012045383898042e-06,
      "loss": 0.3639,
      "step": 12837
    },
    {
      "epoch": 0.9976686353745726,
      "grad_norm": 0.22136284410953522,
      "learning_rate": 5.0116568231271375e-06,
      "loss": 0.0591,
      "step": 12838
    },
    {
      "epoch": 0.9977463475287535,
      "grad_norm": 0.5195528864860535,
      "learning_rate": 5.0112682623562325e-06,
      "loss": 0.3081,
      "step": 12839
    },
    {
      "epoch": 0.9978240596829344,
      "grad_norm": 0.5724639892578125,
      "learning_rate": 5.010879701585328e-06,
      "loss": 0.2749,
      "step": 12840
    },
    {
      "epoch": 0.9979017718371154,
      "grad_norm": 0.10475624352693558,
      "learning_rate": 5.010491140814424e-06,
      "loss": 0.0307,
      "step": 12841
    },
    {
      "epoch": 0.9979794839912962,
      "grad_norm": 0.5417777895927429,
      "learning_rate": 5.010102580043519e-06,
      "loss": 0.2752,
      "step": 12842
    },
    {
      "epoch": 0.9980571961454772,
      "grad_norm": 0.22525528073310852,
      "learning_rate": 5.009714019272615e-06,
      "loss": 0.0433,
      "step": 12843
    },
    {
      "epoch": 0.9981349082996581,
      "grad_norm": 0.5930424928665161,
      "learning_rate": 5.009325458501711e-06,
      "loss": 0.4165,
      "step": 12844
    },
    {
      "epoch": 0.998212620453839,
      "grad_norm": 4.083072662353516,
      "learning_rate": 5.008936897730805e-06,
      "loss": 0.9799,
      "step": 12845
    },
    {
      "epoch": 0.9982903326080199,
      "grad_norm": 0.2533312439918518,
      "learning_rate": 5.0085483369599005e-06,
      "loss": 0.0511,
      "step": 12846
    },
    {
      "epoch": 0.9983680447622008,
      "grad_norm": 0.2489101141691208,
      "learning_rate": 5.008159776188996e-06,
      "loss": 0.0333,
      "step": 12847
    },
    {
      "epoch": 0.9984457569163817,
      "grad_norm": 0.6111014485359192,
      "learning_rate": 5.007771215418091e-06,
      "loss": 0.2396,
      "step": 12848
    },
    {
      "epoch": 0.9985234690705627,
      "grad_norm": 1.0767499208450317,
      "learning_rate": 5.007382654647187e-06,
      "loss": 0.2502,
      "step": 12849
    },
    {
      "epoch": 0.9986011812247435,
      "grad_norm": 0.7246614694595337,
      "learning_rate": 5.006994093876283e-06,
      "loss": 0.1414,
      "step": 12850
    },
    {
      "epoch": 0.9986788933789245,
      "grad_norm": 0.3957156836986542,
      "learning_rate": 5.006605533105378e-06,
      "loss": 0.2044,
      "step": 12851
    },
    {
      "epoch": 0.9987566055331054,
      "grad_norm": 0.8405882120132446,
      "learning_rate": 5.006216972334474e-06,
      "loss": 1.3627,
      "step": 12852
    },
    {
      "epoch": 0.9988343176872863,
      "grad_norm": 0.2407403141260147,
      "learning_rate": 5.005828411563569e-06,
      "loss": 0.0649,
      "step": 12853
    },
    {
      "epoch": 0.9989120298414672,
      "grad_norm": 0.6911278963088989,
      "learning_rate": 5.005439850792665e-06,
      "loss": 0.2718,
      "step": 12854
    },
    {
      "epoch": 0.9989897419956482,
      "grad_norm": 0.5227063894271851,
      "learning_rate": 5.005051290021759e-06,
      "loss": 0.3325,
      "step": 12855
    },
    {
      "epoch": 0.999067454149829,
      "grad_norm": 0.4004822373390198,
      "learning_rate": 5.004662729250855e-06,
      "loss": 0.2012,
      "step": 12856
    },
    {
      "epoch": 0.99914516630401,
      "grad_norm": 0.707992434501648,
      "learning_rate": 5.004274168479951e-06,
      "loss": 0.3156,
      "step": 12857
    },
    {
      "epoch": 0.9992228784581909,
      "grad_norm": 0.43314340710639954,
      "learning_rate": 5.003885607709046e-06,
      "loss": 0.1257,
      "step": 12858
    },
    {
      "epoch": 0.9993005906123718,
      "grad_norm": 0.5818749070167542,
      "learning_rate": 5.003497046938142e-06,
      "loss": 0.2523,
      "step": 12859
    },
    {
      "epoch": 0.9993783027665527,
      "grad_norm": 0.50806725025177,
      "learning_rate": 5.003108486167237e-06,
      "loss": 0.1248,
      "step": 12860
    },
    {
      "epoch": 0.9994560149207335,
      "grad_norm": 0.14402760565280914,
      "learning_rate": 5.002719925396332e-06,
      "loss": 0.026,
      "step": 12861
    },
    {
      "epoch": 0.9995337270749145,
      "grad_norm": 0.7407313585281372,
      "learning_rate": 5.002331364625428e-06,
      "loss": 0.1467,
      "step": 12862
    },
    {
      "epoch": 0.9996114392290955,
      "grad_norm": 0.11529282480478287,
      "learning_rate": 5.001942803854524e-06,
      "loss": 0.0187,
      "step": 12863
    },
    {
      "epoch": 0.9996891513832763,
      "grad_norm": 0.5962581634521484,
      "learning_rate": 5.001554243083618e-06,
      "loss": 0.2988,
      "step": 12864
    },
    {
      "epoch": 0.9997668635374573,
      "grad_norm": 0.43360739946365356,
      "learning_rate": 5.001165682312714e-06,
      "loss": 0.2272,
      "step": 12865
    },
    {
      "epoch": 0.9998445756916382,
      "grad_norm": 0.21448931097984314,
      "learning_rate": 5.00077712154181e-06,
      "loss": 0.0631,
      "step": 12866
    },
    {
      "epoch": 0.999922287845819,
      "grad_norm": 0.4259706437587738,
      "learning_rate": 5.000388560770905e-06,
      "loss": 0.1221,
      "step": 12867
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.21103961765766144,
      "learning_rate": 5e-06,
      "loss": 0.0565,
      "step": 12868
    },
    {
      "epoch": 1.0000777121541808,
      "grad_norm": 0.5550696849822998,
      "learning_rate": 4.999611439229095e-06,
      "loss": 0.3058,
      "step": 12869
    },
    {
      "epoch": 1.000155424308362,
      "grad_norm": 0.4265693426132202,
      "learning_rate": 4.999222878458191e-06,
      "loss": 0.1897,
      "step": 12870
    },
    {
      "epoch": 1.0002331364625427,
      "grad_norm": 0.4275955855846405,
      "learning_rate": 4.998834317687287e-06,
      "loss": 1.262,
      "step": 12871
    },
    {
      "epoch": 1.0003108486167236,
      "grad_norm": 0.13015644252300262,
      "learning_rate": 4.998445756916382e-06,
      "loss": 0.0384,
      "step": 12872
    },
    {
      "epoch": 1.0003885607709047,
      "grad_norm": 0.46631911396980286,
      "learning_rate": 4.998057196145478e-06,
      "loss": 0.2854,
      "step": 12873
    },
    {
      "epoch": 1.0004662729250855,
      "grad_norm": 0.41245341300964355,
      "learning_rate": 4.997668635374573e-06,
      "loss": 0.8057,
      "step": 12874
    },
    {
      "epoch": 1.0005439850792663,
      "grad_norm": 0.6643985509872437,
      "learning_rate": 4.9972800746036684e-06,
      "loss": 0.2559,
      "step": 12875
    },
    {
      "epoch": 1.0006216972334474,
      "grad_norm": 0.43109098076820374,
      "learning_rate": 4.996891513832764e-06,
      "loss": 0.1683,
      "step": 12876
    },
    {
      "epoch": 1.0006994093876282,
      "grad_norm": 0.12232694774866104,
      "learning_rate": 4.996502953061859e-06,
      "loss": 0.0217,
      "step": 12877
    },
    {
      "epoch": 1.000777121541809,
      "grad_norm": 0.3842613995075226,
      "learning_rate": 4.996114392290955e-06,
      "loss": 0.3531,
      "step": 12878
    },
    {
      "epoch": 1.0008548336959902,
      "grad_norm": 0.16145487129688263,
      "learning_rate": 4.99572583152005e-06,
      "loss": 0.0927,
      "step": 12879
    },
    {
      "epoch": 1.000932545850171,
      "grad_norm": 0.5355775952339172,
      "learning_rate": 4.995337270749146e-06,
      "loss": 0.3882,
      "step": 12880
    },
    {
      "epoch": 1.0010102580043518,
      "grad_norm": 1.1089726686477661,
      "learning_rate": 4.9949487099782415e-06,
      "loss": 0.1362,
      "step": 12881
    },
    {
      "epoch": 1.001087970158533,
      "grad_norm": 0.33250418305397034,
      "learning_rate": 4.9945601492073365e-06,
      "loss": 0.1107,
      "step": 12882
    },
    {
      "epoch": 1.0011656823127137,
      "grad_norm": 0.1881752759218216,
      "learning_rate": 4.9941715884364314e-06,
      "loss": 0.1652,
      "step": 12883
    },
    {
      "epoch": 1.0012433944668946,
      "grad_norm": 0.6536591053009033,
      "learning_rate": 4.993783027665527e-06,
      "loss": 0.1342,
      "step": 12884
    },
    {
      "epoch": 1.0013211066210754,
      "grad_norm": 0.36597689986228943,
      "learning_rate": 4.993394466894623e-06,
      "loss": 0.1233,
      "step": 12885
    },
    {
      "epoch": 1.0013988187752565,
      "grad_norm": 0.7847546339035034,
      "learning_rate": 4.993005906123718e-06,
      "loss": 0.2214,
      "step": 12886
    },
    {
      "epoch": 1.0014765309294373,
      "grad_norm": 0.31483492255210876,
      "learning_rate": 4.992617345352814e-06,
      "loss": 0.067,
      "step": 12887
    },
    {
      "epoch": 1.0015542430836182,
      "grad_norm": 0.34699520468711853,
      "learning_rate": 4.992228784581909e-06,
      "loss": 0.2978,
      "step": 12888
    },
    {
      "epoch": 1.0016319552377992,
      "grad_norm": 0.185609370470047,
      "learning_rate": 4.9918402238110045e-06,
      "loss": 0.0403,
      "step": 12889
    },
    {
      "epoch": 1.00170966739198,
      "grad_norm": 0.2981933355331421,
      "learning_rate": 4.9914516630401e-06,
      "loss": 0.1659,
      "step": 12890
    },
    {
      "epoch": 1.001787379546161,
      "grad_norm": 0.3146485388278961,
      "learning_rate": 4.991063102269195e-06,
      "loss": 0.0415,
      "step": 12891
    },
    {
      "epoch": 1.001865091700342,
      "grad_norm": 0.4229554235935211,
      "learning_rate": 4.990674541498291e-06,
      "loss": 0.1204,
      "step": 12892
    },
    {
      "epoch": 1.0019428038545228,
      "grad_norm": 0.20007570087909698,
      "learning_rate": 4.990285980727386e-06,
      "loss": 0.0853,
      "step": 12893
    },
    {
      "epoch": 1.0020205160087037,
      "grad_norm": 0.36374446749687195,
      "learning_rate": 4.989897419956482e-06,
      "loss": 0.0613,
      "step": 12894
    },
    {
      "epoch": 1.0020982281628847,
      "grad_norm": 0.3427303731441498,
      "learning_rate": 4.989508859185578e-06,
      "loss": 0.2115,
      "step": 12895
    },
    {
      "epoch": 1.0021759403170656,
      "grad_norm": 1.115993618965149,
      "learning_rate": 4.9891202984146726e-06,
      "loss": 0.2914,
      "step": 12896
    },
    {
      "epoch": 1.0022536524712464,
      "grad_norm": 0.5071195363998413,
      "learning_rate": 4.9887317376437675e-06,
      "loss": 0.45,
      "step": 12897
    },
    {
      "epoch": 1.0023313646254275,
      "grad_norm": 0.1290193349123001,
      "learning_rate": 4.988343176872863e-06,
      "loss": 0.0329,
      "step": 12898
    },
    {
      "epoch": 1.0024090767796083,
      "grad_norm": 0.09330500662326813,
      "learning_rate": 4.987954616101959e-06,
      "loss": 0.0123,
      "step": 12899
    },
    {
      "epoch": 1.0024867889337892,
      "grad_norm": 0.24788783490657806,
      "learning_rate": 4.987566055331054e-06,
      "loss": 0.1501,
      "step": 12900
    },
    {
      "epoch": 1.0025645010879702,
      "grad_norm": 0.14630135893821716,
      "learning_rate": 4.98717749456015e-06,
      "loss": 0.0439,
      "step": 12901
    },
    {
      "epoch": 1.002642213242151,
      "grad_norm": 9.08742618560791,
      "learning_rate": 4.986788933789245e-06,
      "loss": 2.5438,
      "step": 12902
    },
    {
      "epoch": 1.002719925396332,
      "grad_norm": 0.20947685837745667,
      "learning_rate": 4.986400373018341e-06,
      "loss": 0.0395,
      "step": 12903
    },
    {
      "epoch": 1.002797637550513,
      "grad_norm": 0.250026673078537,
      "learning_rate": 4.986011812247436e-06,
      "loss": 0.0574,
      "step": 12904
    },
    {
      "epoch": 1.0028753497046938,
      "grad_norm": 0.32646289467811584,
      "learning_rate": 4.985623251476531e-06,
      "loss": 0.1168,
      "step": 12905
    },
    {
      "epoch": 1.0029530618588747,
      "grad_norm": 0.5492501854896545,
      "learning_rate": 4.985234690705627e-06,
      "loss": 0.3137,
      "step": 12906
    },
    {
      "epoch": 1.0030307740130557,
      "grad_norm": 0.14254726469516754,
      "learning_rate": 4.984846129934722e-06,
      "loss": 0.0083,
      "step": 12907
    },
    {
      "epoch": 1.0031084861672366,
      "grad_norm": 0.5301249027252197,
      "learning_rate": 4.984457569163818e-06,
      "loss": 0.2392,
      "step": 12908
    },
    {
      "epoch": 1.0031861983214174,
      "grad_norm": 0.4175192415714264,
      "learning_rate": 4.984069008392914e-06,
      "loss": 0.0653,
      "step": 12909
    },
    {
      "epoch": 1.0032639104755985,
      "grad_norm": 0.30629852414131165,
      "learning_rate": 4.983680447622009e-06,
      "loss": 0.2469,
      "step": 12910
    },
    {
      "epoch": 1.0033416226297793,
      "grad_norm": 0.33261409401893616,
      "learning_rate": 4.983291886851104e-06,
      "loss": 0.0548,
      "step": 12911
    },
    {
      "epoch": 1.0034193347839602,
      "grad_norm": 0.5519812107086182,
      "learning_rate": 4.982903326080199e-06,
      "loss": 0.2083,
      "step": 12912
    },
    {
      "epoch": 1.0034970469381412,
      "grad_norm": 0.42592379450798035,
      "learning_rate": 4.982514765309295e-06,
      "loss": 0.2896,
      "step": 12913
    },
    {
      "epoch": 1.003574759092322,
      "grad_norm": 0.9473140835762024,
      "learning_rate": 4.98212620453839e-06,
      "loss": 0.3224,
      "step": 12914
    },
    {
      "epoch": 1.003652471246503,
      "grad_norm": 0.610984206199646,
      "learning_rate": 4.981737643767486e-06,
      "loss": 0.9519,
      "step": 12915
    },
    {
      "epoch": 1.0037301834006838,
      "grad_norm": 0.2827335596084595,
      "learning_rate": 4.981349082996581e-06,
      "loss": 0.1064,
      "step": 12916
    },
    {
      "epoch": 1.0038078955548648,
      "grad_norm": 0.09093557298183441,
      "learning_rate": 4.980960522225677e-06,
      "loss": 0.0124,
      "step": 12917
    },
    {
      "epoch": 1.0038856077090457,
      "grad_norm": 0.15730512142181396,
      "learning_rate": 4.9805719614547725e-06,
      "loss": 0.0397,
      "step": 12918
    },
    {
      "epoch": 1.0039633198632265,
      "grad_norm": 0.19883011281490326,
      "learning_rate": 4.980183400683867e-06,
      "loss": 0.0406,
      "step": 12919
    },
    {
      "epoch": 1.0040410320174076,
      "grad_norm": 0.636008620262146,
      "learning_rate": 4.979794839912962e-06,
      "loss": 0.4521,
      "step": 12920
    },
    {
      "epoch": 1.0041187441715884,
      "grad_norm": 0.4870380759239197,
      "learning_rate": 4.979406279142058e-06,
      "loss": 0.0892,
      "step": 12921
    },
    {
      "epoch": 1.0041964563257693,
      "grad_norm": 0.8243651986122131,
      "learning_rate": 4.979017718371154e-06,
      "loss": 0.5268,
      "step": 12922
    },
    {
      "epoch": 1.0042741684799503,
      "grad_norm": 0.1458732932806015,
      "learning_rate": 4.97862915760025e-06,
      "loss": 0.0293,
      "step": 12923
    },
    {
      "epoch": 1.0043518806341312,
      "grad_norm": 0.39511698484420776,
      "learning_rate": 4.978240596829345e-06,
      "loss": 0.3275,
      "step": 12924
    },
    {
      "epoch": 1.004429592788312,
      "grad_norm": 0.4100455045700073,
      "learning_rate": 4.97785203605844e-06,
      "loss": 0.1753,
      "step": 12925
    },
    {
      "epoch": 1.004507304942493,
      "grad_norm": 0.45145416259765625,
      "learning_rate": 4.9774634752875354e-06,
      "loss": 0.0976,
      "step": 12926
    },
    {
      "epoch": 1.004585017096674,
      "grad_norm": 0.39871564507484436,
      "learning_rate": 4.977074914516631e-06,
      "loss": 0.162,
      "step": 12927
    },
    {
      "epoch": 1.0046627292508548,
      "grad_norm": 0.665849506855011,
      "learning_rate": 4.976686353745726e-06,
      "loss": 0.5421,
      "step": 12928
    },
    {
      "epoch": 1.0047404414050358,
      "grad_norm": 0.11348976194858551,
      "learning_rate": 4.976297792974822e-06,
      "loss": 0.0685,
      "step": 12929
    },
    {
      "epoch": 1.0048181535592167,
      "grad_norm": 0.3634861707687378,
      "learning_rate": 4.975909232203917e-06,
      "loss": 0.2267,
      "step": 12930
    },
    {
      "epoch": 1.0048958657133975,
      "grad_norm": 0.5480009317398071,
      "learning_rate": 4.975520671433013e-06,
      "loss": 0.2552,
      "step": 12931
    },
    {
      "epoch": 1.0049735778675786,
      "grad_norm": 0.2441457360982895,
      "learning_rate": 4.975132110662108e-06,
      "loss": 0.1134,
      "step": 12932
    },
    {
      "epoch": 1.0050512900217594,
      "grad_norm": 0.15933234989643097,
      "learning_rate": 4.9747435498912035e-06,
      "loss": 0.0348,
      "step": 12933
    },
    {
      "epoch": 1.0051290021759403,
      "grad_norm": 0.4220380485057831,
      "learning_rate": 4.9743549891202984e-06,
      "loss": 0.2497,
      "step": 12934
    },
    {
      "epoch": 1.0052067143301213,
      "grad_norm": 0.8983907103538513,
      "learning_rate": 4.973966428349394e-06,
      "loss": 0.305,
      "step": 12935
    },
    {
      "epoch": 1.0052844264843022,
      "grad_norm": 0.20213665068149567,
      "learning_rate": 4.973577867578489e-06,
      "loss": 0.0677,
      "step": 12936
    },
    {
      "epoch": 1.005362138638483,
      "grad_norm": 0.2913142442703247,
      "learning_rate": 4.973189306807585e-06,
      "loss": 0.1511,
      "step": 12937
    },
    {
      "epoch": 1.005439850792664,
      "grad_norm": 0.07571137696504593,
      "learning_rate": 4.972800746036681e-06,
      "loss": 0.0042,
      "step": 12938
    },
    {
      "epoch": 1.005517562946845,
      "grad_norm": 0.37242820858955383,
      "learning_rate": 4.972412185265776e-06,
      "loss": 0.0455,
      "step": 12939
    },
    {
      "epoch": 1.0055952751010258,
      "grad_norm": 0.2275594174861908,
      "learning_rate": 4.9720236244948715e-06,
      "loss": 0.158,
      "step": 12940
    },
    {
      "epoch": 1.0056729872552068,
      "grad_norm": 0.3867998421192169,
      "learning_rate": 4.9716350637239665e-06,
      "loss": 0.1092,
      "step": 12941
    },
    {
      "epoch": 1.0057506994093877,
      "grad_norm": 0.23788274824619293,
      "learning_rate": 4.971246502953062e-06,
      "loss": 0.0617,
      "step": 12942
    },
    {
      "epoch": 1.0058284115635685,
      "grad_norm": 0.7137004137039185,
      "learning_rate": 4.970857942182158e-06,
      "loss": 0.2662,
      "step": 12943
    },
    {
      "epoch": 1.0059061237177493,
      "grad_norm": 1.351555585861206,
      "learning_rate": 4.970469381411253e-06,
      "loss": 1.0349,
      "step": 12944
    },
    {
      "epoch": 1.0059838358719304,
      "grad_norm": 0.2180802822113037,
      "learning_rate": 4.970080820640348e-06,
      "loss": 0.0671,
      "step": 12945
    },
    {
      "epoch": 1.0060615480261113,
      "grad_norm": 0.05574658885598183,
      "learning_rate": 4.969692259869444e-06,
      "loss": 0.0045,
      "step": 12946
    },
    {
      "epoch": 1.006139260180292,
      "grad_norm": 0.2740795612335205,
      "learning_rate": 4.9693036990985396e-06,
      "loss": 0.1117,
      "step": 12947
    },
    {
      "epoch": 1.0062169723344732,
      "grad_norm": 0.30200496315956116,
      "learning_rate": 4.9689151383276345e-06,
      "loss": 0.2203,
      "step": 12948
    },
    {
      "epoch": 1.006294684488654,
      "grad_norm": 0.07038101553916931,
      "learning_rate": 4.96852657755673e-06,
      "loss": 0.0329,
      "step": 12949
    },
    {
      "epoch": 1.0063723966428348,
      "grad_norm": 0.1986747533082962,
      "learning_rate": 4.968138016785825e-06,
      "loss": 0.0543,
      "step": 12950
    },
    {
      "epoch": 1.006450108797016,
      "grad_norm": 0.4463139772415161,
      "learning_rate": 4.967749456014921e-06,
      "loss": 0.2337,
      "step": 12951
    },
    {
      "epoch": 1.0065278209511967,
      "grad_norm": 0.2432035505771637,
      "learning_rate": 4.967360895244017e-06,
      "loss": 0.1009,
      "step": 12952
    },
    {
      "epoch": 1.0066055331053776,
      "grad_norm": 0.37581369280815125,
      "learning_rate": 4.966972334473112e-06,
      "loss": 0.1591,
      "step": 12953
    },
    {
      "epoch": 1.0066832452595587,
      "grad_norm": 0.4586322605609894,
      "learning_rate": 4.966583773702208e-06,
      "loss": 0.5136,
      "step": 12954
    },
    {
      "epoch": 1.0067609574137395,
      "grad_norm": 0.07877806574106216,
      "learning_rate": 4.9661952129313025e-06,
      "loss": 0.0073,
      "step": 12955
    },
    {
      "epoch": 1.0068386695679203,
      "grad_norm": 0.6312496662139893,
      "learning_rate": 4.965806652160398e-06,
      "loss": 0.1276,
      "step": 12956
    },
    {
      "epoch": 1.0069163817221014,
      "grad_norm": 0.6816586852073669,
      "learning_rate": 4.965418091389494e-06,
      "loss": 0.3545,
      "step": 12957
    },
    {
      "epoch": 1.0069940938762822,
      "grad_norm": 0.4840979278087616,
      "learning_rate": 4.965029530618589e-06,
      "loss": 0.3961,
      "step": 12958
    },
    {
      "epoch": 1.007071806030463,
      "grad_norm": 0.5252900719642639,
      "learning_rate": 4.964640969847684e-06,
      "loss": 0.0781,
      "step": 12959
    },
    {
      "epoch": 1.0071495181846442,
      "grad_norm": 0.3387792408466339,
      "learning_rate": 4.96425240907678e-06,
      "loss": 0.1498,
      "step": 12960
    },
    {
      "epoch": 1.007227230338825,
      "grad_norm": 0.3780949115753174,
      "learning_rate": 4.963863848305876e-06,
      "loss": 0.1692,
      "step": 12961
    },
    {
      "epoch": 1.0073049424930058,
      "grad_norm": 0.31011053919792175,
      "learning_rate": 4.963475287534971e-06,
      "loss": 0.055,
      "step": 12962
    },
    {
      "epoch": 1.007382654647187,
      "grad_norm": 0.9566829800605774,
      "learning_rate": 4.963086726764066e-06,
      "loss": 0.53,
      "step": 12963
    },
    {
      "epoch": 1.0074603668013677,
      "grad_norm": 0.2292598932981491,
      "learning_rate": 4.962698165993161e-06,
      "loss": 0.0675,
      "step": 12964
    },
    {
      "epoch": 1.0075380789555486,
      "grad_norm": 0.21437568962574005,
      "learning_rate": 4.962309605222257e-06,
      "loss": 0.0857,
      "step": 12965
    },
    {
      "epoch": 1.0076157911097297,
      "grad_norm": 0.8352850675582886,
      "learning_rate": 4.961921044451353e-06,
      "loss": 0.0811,
      "step": 12966
    },
    {
      "epoch": 1.0076935032639105,
      "grad_norm": 0.2458147257566452,
      "learning_rate": 4.961532483680448e-06,
      "loss": 0.0406,
      "step": 12967
    },
    {
      "epoch": 1.0077712154180913,
      "grad_norm": 0.6495869755744934,
      "learning_rate": 4.961143922909544e-06,
      "loss": 0.1897,
      "step": 12968
    },
    {
      "epoch": 1.0078489275722724,
      "grad_norm": 0.687785267829895,
      "learning_rate": 4.960755362138639e-06,
      "loss": 0.1563,
      "step": 12969
    },
    {
      "epoch": 1.0079266397264532,
      "grad_norm": 0.1570446789264679,
      "learning_rate": 4.960366801367734e-06,
      "loss": 0.0346,
      "step": 12970
    },
    {
      "epoch": 1.008004351880634,
      "grad_norm": 0.48784157633781433,
      "learning_rate": 4.95997824059683e-06,
      "loss": 0.1093,
      "step": 12971
    },
    {
      "epoch": 1.0080820640348152,
      "grad_norm": 0.44283270835876465,
      "learning_rate": 4.959589679825925e-06,
      "loss": 0.0831,
      "step": 12972
    },
    {
      "epoch": 1.008159776188996,
      "grad_norm": 0.5399669408798218,
      "learning_rate": 4.95920111905502e-06,
      "loss": 0.1504,
      "step": 12973
    },
    {
      "epoch": 1.0082374883431768,
      "grad_norm": 0.45111924409866333,
      "learning_rate": 4.958812558284116e-06,
      "loss": 0.2283,
      "step": 12974
    },
    {
      "epoch": 1.0083152004973577,
      "grad_norm": 0.1612212210893631,
      "learning_rate": 4.958423997513212e-06,
      "loss": 0.0371,
      "step": 12975
    },
    {
      "epoch": 1.0083929126515387,
      "grad_norm": 0.1667061150074005,
      "learning_rate": 4.958035436742307e-06,
      "loss": 0.0272,
      "step": 12976
    },
    {
      "epoch": 1.0084706248057196,
      "grad_norm": 0.29639652371406555,
      "learning_rate": 4.9576468759714025e-06,
      "loss": 0.0995,
      "step": 12977
    },
    {
      "epoch": 1.0085483369599004,
      "grad_norm": 0.7285158634185791,
      "learning_rate": 4.957258315200497e-06,
      "loss": 0.5445,
      "step": 12978
    },
    {
      "epoch": 1.0086260491140815,
      "grad_norm": 1.4755959510803223,
      "learning_rate": 4.956869754429593e-06,
      "loss": 0.2556,
      "step": 12979
    },
    {
      "epoch": 1.0087037612682623,
      "grad_norm": 0.1641147881746292,
      "learning_rate": 4.956481193658689e-06,
      "loss": 0.0363,
      "step": 12980
    },
    {
      "epoch": 1.0087814734224432,
      "grad_norm": 0.496255099773407,
      "learning_rate": 4.956092632887784e-06,
      "loss": 0.0685,
      "step": 12981
    },
    {
      "epoch": 1.0088591855766242,
      "grad_norm": 0.6270982027053833,
      "learning_rate": 4.95570407211688e-06,
      "loss": 0.1774,
      "step": 12982
    },
    {
      "epoch": 1.008936897730805,
      "grad_norm": 0.4693606495857239,
      "learning_rate": 4.955315511345975e-06,
      "loss": 0.2607,
      "step": 12983
    },
    {
      "epoch": 1.009014609884986,
      "grad_norm": 0.6524761319160461,
      "learning_rate": 4.9549269505750705e-06,
      "loss": 0.2727,
      "step": 12984
    },
    {
      "epoch": 1.009092322039167,
      "grad_norm": 0.9424449801445007,
      "learning_rate": 4.954538389804166e-06,
      "loss": 0.1521,
      "step": 12985
    },
    {
      "epoch": 1.0091700341933478,
      "grad_norm": 0.5093590021133423,
      "learning_rate": 4.954149829033261e-06,
      "loss": 0.0618,
      "step": 12986
    },
    {
      "epoch": 1.0092477463475287,
      "grad_norm": 0.44343557953834534,
      "learning_rate": 4.953761268262356e-06,
      "loss": 0.5133,
      "step": 12987
    },
    {
      "epoch": 1.0093254585017097,
      "grad_norm": 0.557225227355957,
      "learning_rate": 4.953372707491452e-06,
      "loss": 0.1382,
      "step": 12988
    },
    {
      "epoch": 1.0094031706558906,
      "grad_norm": 0.22134295105934143,
      "learning_rate": 4.952984146720548e-06,
      "loss": 0.0598,
      "step": 12989
    },
    {
      "epoch": 1.0094808828100714,
      "grad_norm": 0.25187063217163086,
      "learning_rate": 4.952595585949643e-06,
      "loss": 0.145,
      "step": 12990
    },
    {
      "epoch": 1.0095585949642525,
      "grad_norm": 0.7680816054344177,
      "learning_rate": 4.9522070251787385e-06,
      "loss": 0.3921,
      "step": 12991
    },
    {
      "epoch": 1.0096363071184333,
      "grad_norm": 0.34464311599731445,
      "learning_rate": 4.9518184644078335e-06,
      "loss": 0.2748,
      "step": 12992
    },
    {
      "epoch": 1.0097140192726142,
      "grad_norm": 0.5826324820518494,
      "learning_rate": 4.951429903636929e-06,
      "loss": 0.2403,
      "step": 12993
    },
    {
      "epoch": 1.0097917314267952,
      "grad_norm": 0.16626499593257904,
      "learning_rate": 4.951041342866025e-06,
      "loss": 0.0398,
      "step": 12994
    },
    {
      "epoch": 1.009869443580976,
      "grad_norm": 0.026618050411343575,
      "learning_rate": 4.95065278209512e-06,
      "loss": 0.0018,
      "step": 12995
    },
    {
      "epoch": 1.009947155735157,
      "grad_norm": 0.44391268491744995,
      "learning_rate": 4.950264221324215e-06,
      "loss": 0.1512,
      "step": 12996
    },
    {
      "epoch": 1.010024867889338,
      "grad_norm": 0.1944698691368103,
      "learning_rate": 4.949875660553311e-06,
      "loss": 0.056,
      "step": 12997
    },
    {
      "epoch": 1.0101025800435188,
      "grad_norm": 0.16309897601604462,
      "learning_rate": 4.9494870997824066e-06,
      "loss": 0.104,
      "step": 12998
    },
    {
      "epoch": 1.0101802921976997,
      "grad_norm": 0.22715218365192413,
      "learning_rate": 4.949098539011502e-06,
      "loss": 0.0752,
      "step": 12999
    },
    {
      "epoch": 1.0102580043518807,
      "grad_norm": 0.11184129118919373,
      "learning_rate": 4.948709978240597e-06,
      "loss": 0.0163,
      "step": 13000
    },
    {
      "epoch": 1.0103357165060616,
      "grad_norm": 1.2457619905471802,
      "learning_rate": 4.948321417469692e-06,
      "loss": 0.5446,
      "step": 13001
    },
    {
      "epoch": 1.0104134286602424,
      "grad_norm": 0.31317615509033203,
      "learning_rate": 4.947932856698788e-06,
      "loss": 0.0463,
      "step": 13002
    },
    {
      "epoch": 1.0104911408144235,
      "grad_norm": 0.6764681935310364,
      "learning_rate": 4.947544295927884e-06,
      "loss": 0.4203,
      "step": 13003
    },
    {
      "epoch": 1.0105688529686043,
      "grad_norm": 0.16255860030651093,
      "learning_rate": 4.947155735156979e-06,
      "loss": 0.0825,
      "step": 13004
    },
    {
      "epoch": 1.0106465651227852,
      "grad_norm": 0.5857584476470947,
      "learning_rate": 4.946767174386075e-06,
      "loss": 0.1423,
      "step": 13005
    },
    {
      "epoch": 1.010724277276966,
      "grad_norm": 0.21689802408218384,
      "learning_rate": 4.9463786136151695e-06,
      "loss": 0.0921,
      "step": 13006
    },
    {
      "epoch": 1.010801989431147,
      "grad_norm": 0.4742075204849243,
      "learning_rate": 4.945990052844265e-06,
      "loss": 0.2512,
      "step": 13007
    },
    {
      "epoch": 1.010879701585328,
      "grad_norm": 0.15114542841911316,
      "learning_rate": 4.945601492073361e-06,
      "loss": 0.115,
      "step": 13008
    },
    {
      "epoch": 1.0109574137395088,
      "grad_norm": 0.4921700060367584,
      "learning_rate": 4.945212931302456e-06,
      "loss": 0.6408,
      "step": 13009
    },
    {
      "epoch": 1.0110351258936898,
      "grad_norm": 0.03525823354721069,
      "learning_rate": 4.944824370531551e-06,
      "loss": 0.0024,
      "step": 13010
    },
    {
      "epoch": 1.0111128380478707,
      "grad_norm": 0.11195150017738342,
      "learning_rate": 4.944435809760647e-06,
      "loss": 0.0197,
      "step": 13011
    },
    {
      "epoch": 1.0111905502020515,
      "grad_norm": 0.150386244058609,
      "learning_rate": 4.944047248989743e-06,
      "loss": 0.0279,
      "step": 13012
    },
    {
      "epoch": 1.0112682623562326,
      "grad_norm": 0.2012166529893875,
      "learning_rate": 4.9436586882188384e-06,
      "loss": 0.0763,
      "step": 13013
    },
    {
      "epoch": 1.0113459745104134,
      "grad_norm": 0.40433797240257263,
      "learning_rate": 4.943270127447933e-06,
      "loss": 0.0399,
      "step": 13014
    },
    {
      "epoch": 1.0114236866645943,
      "grad_norm": 0.3822075128555298,
      "learning_rate": 4.942881566677028e-06,
      "loss": 0.1139,
      "step": 13015
    },
    {
      "epoch": 1.0115013988187753,
      "grad_norm": 0.8778885006904602,
      "learning_rate": 4.942493005906124e-06,
      "loss": 0.1562,
      "step": 13016
    },
    {
      "epoch": 1.0115791109729562,
      "grad_norm": 0.5362949967384338,
      "learning_rate": 4.94210444513522e-06,
      "loss": 0.4742,
      "step": 13017
    },
    {
      "epoch": 1.011656823127137,
      "grad_norm": 0.2706189751625061,
      "learning_rate": 4.941715884364315e-06,
      "loss": 0.1139,
      "step": 13018
    },
    {
      "epoch": 1.011734535281318,
      "grad_norm": 0.5560725331306458,
      "learning_rate": 4.941327323593411e-06,
      "loss": 0.2195,
      "step": 13019
    },
    {
      "epoch": 1.011812247435499,
      "grad_norm": 0.2058073729276657,
      "learning_rate": 4.940938762822506e-06,
      "loss": 0.0838,
      "step": 13020
    },
    {
      "epoch": 1.0118899595896798,
      "grad_norm": 0.49098047614097595,
      "learning_rate": 4.940550202051601e-06,
      "loss": 0.3424,
      "step": 13021
    },
    {
      "epoch": 1.0119676717438608,
      "grad_norm": 0.5404255390167236,
      "learning_rate": 4.940161641280697e-06,
      "loss": 1.0059,
      "step": 13022
    },
    {
      "epoch": 1.0120453838980417,
      "grad_norm": 0.7528658509254456,
      "learning_rate": 4.939773080509792e-06,
      "loss": 0.6723,
      "step": 13023
    },
    {
      "epoch": 1.0121230960522225,
      "grad_norm": 0.34432363510131836,
      "learning_rate": 4.939384519738887e-06,
      "loss": 0.1399,
      "step": 13024
    },
    {
      "epoch": 1.0122008082064036,
      "grad_norm": 0.28639888763427734,
      "learning_rate": 4.938995958967983e-06,
      "loss": 0.0293,
      "step": 13025
    },
    {
      "epoch": 1.0122785203605844,
      "grad_norm": 0.27094852924346924,
      "learning_rate": 4.938607398197079e-06,
      "loss": 0.1132,
      "step": 13026
    },
    {
      "epoch": 1.0123562325147653,
      "grad_norm": 0.9163392186164856,
      "learning_rate": 4.938218837426174e-06,
      "loss": 0.1509,
      "step": 13027
    },
    {
      "epoch": 1.0124339446689463,
      "grad_norm": 0.13676917552947998,
      "learning_rate": 4.9378302766552695e-06,
      "loss": 0.0304,
      "step": 13028
    },
    {
      "epoch": 1.0125116568231272,
      "grad_norm": 0.19419080018997192,
      "learning_rate": 4.937441715884364e-06,
      "loss": 0.0879,
      "step": 13029
    },
    {
      "epoch": 1.012589368977308,
      "grad_norm": 0.32447144389152527,
      "learning_rate": 4.93705315511346e-06,
      "loss": 0.1147,
      "step": 13030
    },
    {
      "epoch": 1.012667081131489,
      "grad_norm": 0.35465797781944275,
      "learning_rate": 4.936664594342556e-06,
      "loss": 0.1353,
      "step": 13031
    },
    {
      "epoch": 1.01274479328567,
      "grad_norm": 0.17603562772274017,
      "learning_rate": 4.936276033571651e-06,
      "loss": 0.0403,
      "step": 13032
    },
    {
      "epoch": 1.0128225054398508,
      "grad_norm": 0.12895283102989197,
      "learning_rate": 4.935887472800747e-06,
      "loss": 0.0274,
      "step": 13033
    },
    {
      "epoch": 1.0129002175940318,
      "grad_norm": 0.9750245809555054,
      "learning_rate": 4.935498912029842e-06,
      "loss": 0.302,
      "step": 13034
    },
    {
      "epoch": 1.0129779297482127,
      "grad_norm": 0.3937950134277344,
      "learning_rate": 4.9351103512589375e-06,
      "loss": 0.0686,
      "step": 13035
    },
    {
      "epoch": 1.0130556419023935,
      "grad_norm": 0.6564182043075562,
      "learning_rate": 4.934721790488033e-06,
      "loss": 0.4693,
      "step": 13036
    },
    {
      "epoch": 1.0131333540565743,
      "grad_norm": 0.18625183403491974,
      "learning_rate": 4.934333229717128e-06,
      "loss": 0.0814,
      "step": 13037
    },
    {
      "epoch": 1.0132110662107554,
      "grad_norm": 0.3352103531360626,
      "learning_rate": 4.933944668946223e-06,
      "loss": 0.1258,
      "step": 13038
    },
    {
      "epoch": 1.0132887783649362,
      "grad_norm": 0.7235698103904724,
      "learning_rate": 4.933556108175319e-06,
      "loss": 0.4774,
      "step": 13039
    },
    {
      "epoch": 1.013366490519117,
      "grad_norm": 0.27537623047828674,
      "learning_rate": 4.933167547404415e-06,
      "loss": 0.0559,
      "step": 13040
    },
    {
      "epoch": 1.0134442026732982,
      "grad_norm": 0.5154942870140076,
      "learning_rate": 4.93277898663351e-06,
      "loss": 0.2369,
      "step": 13041
    },
    {
      "epoch": 1.013521914827479,
      "grad_norm": 0.6846364736557007,
      "learning_rate": 4.9323904258626055e-06,
      "loss": 0.4318,
      "step": 13042
    },
    {
      "epoch": 1.0135996269816598,
      "grad_norm": 0.365927517414093,
      "learning_rate": 4.9320018650917005e-06,
      "loss": 0.1814,
      "step": 13043
    },
    {
      "epoch": 1.013677339135841,
      "grad_norm": 0.6891750693321228,
      "learning_rate": 4.931613304320796e-06,
      "loss": 0.4284,
      "step": 13044
    },
    {
      "epoch": 1.0137550512900217,
      "grad_norm": 0.46657633781433105,
      "learning_rate": 4.931224743549892e-06,
      "loss": 0.0657,
      "step": 13045
    },
    {
      "epoch": 1.0138327634442026,
      "grad_norm": 0.9102072715759277,
      "learning_rate": 4.930836182778987e-06,
      "loss": 0.4906,
      "step": 13046
    },
    {
      "epoch": 1.0139104755983837,
      "grad_norm": 0.5423157215118408,
      "learning_rate": 4.930447622008083e-06,
      "loss": 0.201,
      "step": 13047
    },
    {
      "epoch": 1.0139881877525645,
      "grad_norm": 0.06145019084215164,
      "learning_rate": 4.930059061237178e-06,
      "loss": 0.0069,
      "step": 13048
    },
    {
      "epoch": 1.0140658999067453,
      "grad_norm": 0.43816569447517395,
      "learning_rate": 4.9296705004662736e-06,
      "loss": 0.2238,
      "step": 13049
    },
    {
      "epoch": 1.0141436120609264,
      "grad_norm": 0.25943049788475037,
      "learning_rate": 4.929281939695369e-06,
      "loss": 0.0398,
      "step": 13050
    },
    {
      "epoch": 1.0142213242151072,
      "grad_norm": 0.4873357117176056,
      "learning_rate": 4.928893378924464e-06,
      "loss": 0.2024,
      "step": 13051
    },
    {
      "epoch": 1.014299036369288,
      "grad_norm": 0.24368417263031006,
      "learning_rate": 4.928504818153559e-06,
      "loss": 0.0721,
      "step": 13052
    },
    {
      "epoch": 1.0143767485234692,
      "grad_norm": 0.11081798374652863,
      "learning_rate": 4.928116257382655e-06,
      "loss": 0.0188,
      "step": 13053
    },
    {
      "epoch": 1.01445446067765,
      "grad_norm": 0.9372770190238953,
      "learning_rate": 4.927727696611751e-06,
      "loss": 0.2272,
      "step": 13054
    },
    {
      "epoch": 1.0145321728318308,
      "grad_norm": 0.5163248777389526,
      "learning_rate": 4.927339135840846e-06,
      "loss": 0.7203,
      "step": 13055
    },
    {
      "epoch": 1.014609884986012,
      "grad_norm": 0.10471078008413315,
      "learning_rate": 4.926950575069942e-06,
      "loss": 0.0518,
      "step": 13056
    },
    {
      "epoch": 1.0146875971401927,
      "grad_norm": 0.2949555814266205,
      "learning_rate": 4.9265620142990365e-06,
      "loss": 0.1087,
      "step": 13057
    },
    {
      "epoch": 1.0147653092943736,
      "grad_norm": 0.24290531873703003,
      "learning_rate": 4.926173453528132e-06,
      "loss": 0.0735,
      "step": 13058
    },
    {
      "epoch": 1.0148430214485546,
      "grad_norm": 0.19719503819942474,
      "learning_rate": 4.925784892757227e-06,
      "loss": 0.1221,
      "step": 13059
    },
    {
      "epoch": 1.0149207336027355,
      "grad_norm": 0.4750153422355652,
      "learning_rate": 4.925396331986323e-06,
      "loss": 0.1535,
      "step": 13060
    },
    {
      "epoch": 1.0149984457569163,
      "grad_norm": 0.1987738311290741,
      "learning_rate": 4.925007771215419e-06,
      "loss": 0.0489,
      "step": 13061
    },
    {
      "epoch": 1.0150761579110974,
      "grad_norm": 0.8243994116783142,
      "learning_rate": 4.924619210444514e-06,
      "loss": 0.222,
      "step": 13062
    },
    {
      "epoch": 1.0151538700652782,
      "grad_norm": 0.4779304265975952,
      "learning_rate": 4.924230649673609e-06,
      "loss": 0.2057,
      "step": 13063
    },
    {
      "epoch": 1.015231582219459,
      "grad_norm": 0.3762032985687256,
      "learning_rate": 4.923842088902705e-06,
      "loss": 0.1428,
      "step": 13064
    },
    {
      "epoch": 1.01530929437364,
      "grad_norm": 0.20272621512413025,
      "learning_rate": 4.9234535281318e-06,
      "loss": 0.0461,
      "step": 13065
    },
    {
      "epoch": 1.015387006527821,
      "grad_norm": 0.4326142370700836,
      "learning_rate": 4.923064967360895e-06,
      "loss": 0.1895,
      "step": 13066
    },
    {
      "epoch": 1.0154647186820018,
      "grad_norm": 0.3512542247772217,
      "learning_rate": 4.922676406589991e-06,
      "loss": 0.2074,
      "step": 13067
    },
    {
      "epoch": 1.0155424308361827,
      "grad_norm": 0.8183087706565857,
      "learning_rate": 4.922287845819086e-06,
      "loss": 0.2033,
      "step": 13068
    },
    {
      "epoch": 1.0156201429903637,
      "grad_norm": 0.5236591100692749,
      "learning_rate": 4.921899285048182e-06,
      "loss": 0.125,
      "step": 13069
    },
    {
      "epoch": 1.0156978551445446,
      "grad_norm": 0.2293173223733902,
      "learning_rate": 4.921510724277278e-06,
      "loss": 0.1202,
      "step": 13070
    },
    {
      "epoch": 1.0157755672987254,
      "grad_norm": 1.2956569194793701,
      "learning_rate": 4.921122163506373e-06,
      "loss": 0.857,
      "step": 13071
    },
    {
      "epoch": 1.0158532794529065,
      "grad_norm": 0.1761123090982437,
      "learning_rate": 4.9207336027354676e-06,
      "loss": 0.032,
      "step": 13072
    },
    {
      "epoch": 1.0159309916070873,
      "grad_norm": 0.5767239928245544,
      "learning_rate": 4.920345041964563e-06,
      "loss": 0.0789,
      "step": 13073
    },
    {
      "epoch": 1.0160087037612682,
      "grad_norm": 0.11952301114797592,
      "learning_rate": 4.919956481193659e-06,
      "loss": 0.1355,
      "step": 13074
    },
    {
      "epoch": 1.0160864159154492,
      "grad_norm": 0.332599401473999,
      "learning_rate": 4.919567920422755e-06,
      "loss": 0.0757,
      "step": 13075
    },
    {
      "epoch": 1.01616412806963,
      "grad_norm": 0.2567961513996124,
      "learning_rate": 4.91917935965185e-06,
      "loss": 0.0505,
      "step": 13076
    },
    {
      "epoch": 1.016241840223811,
      "grad_norm": 0.34470734000205994,
      "learning_rate": 4.918790798880945e-06,
      "loss": 0.3676,
      "step": 13077
    },
    {
      "epoch": 1.016319552377992,
      "grad_norm": 0.815857470035553,
      "learning_rate": 4.918402238110041e-06,
      "loss": 0.5211,
      "step": 13078
    },
    {
      "epoch": 1.0163972645321728,
      "grad_norm": 0.704159677028656,
      "learning_rate": 4.9180136773391365e-06,
      "loss": 0.7768,
      "step": 13079
    },
    {
      "epoch": 1.0164749766863537,
      "grad_norm": 0.20292574167251587,
      "learning_rate": 4.917625116568231e-06,
      "loss": 0.0498,
      "step": 13080
    },
    {
      "epoch": 1.0165526888405347,
      "grad_norm": 0.4231354594230652,
      "learning_rate": 4.917236555797327e-06,
      "loss": 0.2298,
      "step": 13081
    },
    {
      "epoch": 1.0166304009947156,
      "grad_norm": 1.106500506401062,
      "learning_rate": 4.916847995026422e-06,
      "loss": 0.2423,
      "step": 13082
    },
    {
      "epoch": 1.0167081131488964,
      "grad_norm": 0.2686278820037842,
      "learning_rate": 4.916459434255518e-06,
      "loss": 0.2119,
      "step": 13083
    },
    {
      "epoch": 1.0167858253030775,
      "grad_norm": 0.14889571070671082,
      "learning_rate": 4.916070873484614e-06,
      "loss": 0.0589,
      "step": 13084
    },
    {
      "epoch": 1.0168635374572583,
      "grad_norm": 0.06525955349206924,
      "learning_rate": 4.915682312713709e-06,
      "loss": 0.0372,
      "step": 13085
    },
    {
      "epoch": 1.0169412496114392,
      "grad_norm": 0.32626861333847046,
      "learning_rate": 4.915293751942804e-06,
      "loss": 0.2553,
      "step": 13086
    },
    {
      "epoch": 1.0170189617656202,
      "grad_norm": 0.32620424032211304,
      "learning_rate": 4.9149051911718994e-06,
      "loss": 0.1267,
      "step": 13087
    },
    {
      "epoch": 1.017096673919801,
      "grad_norm": 0.5816073417663574,
      "learning_rate": 4.914516630400995e-06,
      "loss": 0.166,
      "step": 13088
    },
    {
      "epoch": 1.017174386073982,
      "grad_norm": 0.47217419743537903,
      "learning_rate": 4.914128069630091e-06,
      "loss": 0.1739,
      "step": 13089
    },
    {
      "epoch": 1.017252098228163,
      "grad_norm": 0.40122100710868835,
      "learning_rate": 4.913739508859186e-06,
      "loss": 0.3397,
      "step": 13090
    },
    {
      "epoch": 1.0173298103823438,
      "grad_norm": 0.37945616245269775,
      "learning_rate": 4.913350948088281e-06,
      "loss": 0.1142,
      "step": 13091
    },
    {
      "epoch": 1.0174075225365247,
      "grad_norm": 0.564848780632019,
      "learning_rate": 4.912962387317377e-06,
      "loss": 0.5692,
      "step": 13092
    },
    {
      "epoch": 1.0174852346907057,
      "grad_norm": 0.13475371897220612,
      "learning_rate": 4.9125738265464725e-06,
      "loss": 0.0137,
      "step": 13093
    },
    {
      "epoch": 1.0175629468448866,
      "grad_norm": 0.40934619307518005,
      "learning_rate": 4.9121852657755675e-06,
      "loss": 0.1161,
      "step": 13094
    },
    {
      "epoch": 1.0176406589990674,
      "grad_norm": 0.6275354027748108,
      "learning_rate": 4.911796705004663e-06,
      "loss": 0.1419,
      "step": 13095
    },
    {
      "epoch": 1.0177183711532485,
      "grad_norm": 0.6290115714073181,
      "learning_rate": 4.911408144233758e-06,
      "loss": 0.5653,
      "step": 13096
    },
    {
      "epoch": 1.0177960833074293,
      "grad_norm": 0.33870208263397217,
      "learning_rate": 4.911019583462854e-06,
      "loss": 0.0625,
      "step": 13097
    },
    {
      "epoch": 1.0178737954616102,
      "grad_norm": 0.47107866406440735,
      "learning_rate": 4.91063102269195e-06,
      "loss": 0.0963,
      "step": 13098
    },
    {
      "epoch": 1.017951507615791,
      "grad_norm": 0.12129411846399307,
      "learning_rate": 4.910242461921045e-06,
      "loss": 0.0663,
      "step": 13099
    },
    {
      "epoch": 1.018029219769972,
      "grad_norm": 0.7392822504043579,
      "learning_rate": 4.90985390115014e-06,
      "loss": 0.1736,
      "step": 13100
    },
    {
      "epoch": 1.018106931924153,
      "grad_norm": 0.3851904571056366,
      "learning_rate": 4.9094653403792355e-06,
      "loss": 0.2587,
      "step": 13101
    },
    {
      "epoch": 1.0181846440783338,
      "grad_norm": 0.6393359899520874,
      "learning_rate": 4.909076779608331e-06,
      "loss": 0.1677,
      "step": 13102
    },
    {
      "epoch": 1.0182623562325148,
      "grad_norm": 1.157470464706421,
      "learning_rate": 4.908688218837426e-06,
      "loss": 0.3611,
      "step": 13103
    },
    {
      "epoch": 1.0183400683866957,
      "grad_norm": 0.2334975302219391,
      "learning_rate": 4.908299658066522e-06,
      "loss": 0.2478,
      "step": 13104
    },
    {
      "epoch": 1.0184177805408765,
      "grad_norm": 0.5587769150733948,
      "learning_rate": 4.907911097295617e-06,
      "loss": 0.2517,
      "step": 13105
    },
    {
      "epoch": 1.0184954926950576,
      "grad_norm": 0.7878054976463318,
      "learning_rate": 4.907522536524713e-06,
      "loss": 0.268,
      "step": 13106
    },
    {
      "epoch": 1.0185732048492384,
      "grad_norm": 0.39390984177589417,
      "learning_rate": 4.907133975753809e-06,
      "loss": 0.103,
      "step": 13107
    },
    {
      "epoch": 1.0186509170034193,
      "grad_norm": 0.47022175788879395,
      "learning_rate": 4.9067454149829036e-06,
      "loss": 0.2435,
      "step": 13108
    },
    {
      "epoch": 1.0187286291576003,
      "grad_norm": 0.37928667664527893,
      "learning_rate": 4.906356854211999e-06,
      "loss": 0.2007,
      "step": 13109
    },
    {
      "epoch": 1.0188063413117812,
      "grad_norm": 0.867516279220581,
      "learning_rate": 4.905968293441094e-06,
      "loss": 0.3904,
      "step": 13110
    },
    {
      "epoch": 1.018884053465962,
      "grad_norm": 0.34563812613487244,
      "learning_rate": 4.90557973267019e-06,
      "loss": 0.1771,
      "step": 13111
    },
    {
      "epoch": 1.018961765620143,
      "grad_norm": 0.481564998626709,
      "learning_rate": 4.905191171899286e-06,
      "loss": 0.2796,
      "step": 13112
    },
    {
      "epoch": 1.019039477774324,
      "grad_norm": 0.3091961741447449,
      "learning_rate": 4.904802611128381e-06,
      "loss": 0.173,
      "step": 13113
    },
    {
      "epoch": 1.0191171899285048,
      "grad_norm": 0.42747417092323303,
      "learning_rate": 4.904414050357476e-06,
      "loss": 0.2016,
      "step": 13114
    },
    {
      "epoch": 1.0191949020826858,
      "grad_norm": 0.1921727955341339,
      "learning_rate": 4.904025489586572e-06,
      "loss": 0.0687,
      "step": 13115
    },
    {
      "epoch": 1.0192726142368667,
      "grad_norm": 0.6716891527175903,
      "learning_rate": 4.903636928815667e-06,
      "loss": 0.3221,
      "step": 13116
    },
    {
      "epoch": 1.0193503263910475,
      "grad_norm": 0.11623333394527435,
      "learning_rate": 4.903248368044762e-06,
      "loss": 0.0833,
      "step": 13117
    },
    {
      "epoch": 1.0194280385452286,
      "grad_norm": 0.1326642781496048,
      "learning_rate": 4.902859807273858e-06,
      "loss": 0.0482,
      "step": 13118
    },
    {
      "epoch": 1.0195057506994094,
      "grad_norm": 1.1259868144989014,
      "learning_rate": 4.902471246502953e-06,
      "loss": 0.082,
      "step": 13119
    },
    {
      "epoch": 1.0195834628535902,
      "grad_norm": 0.2591445744037628,
      "learning_rate": 4.902082685732049e-06,
      "loss": 0.1052,
      "step": 13120
    },
    {
      "epoch": 1.0196611750077713,
      "grad_norm": 0.6180893182754517,
      "learning_rate": 4.901694124961145e-06,
      "loss": 0.0673,
      "step": 13121
    },
    {
      "epoch": 1.0197388871619522,
      "grad_norm": 0.6988433599472046,
      "learning_rate": 4.90130556419024e-06,
      "loss": 0.4864,
      "step": 13122
    },
    {
      "epoch": 1.019816599316133,
      "grad_norm": 0.3265111744403839,
      "learning_rate": 4.900917003419335e-06,
      "loss": 0.2403,
      "step": 13123
    },
    {
      "epoch": 1.019894311470314,
      "grad_norm": 0.4116733968257904,
      "learning_rate": 4.90052844264843e-06,
      "loss": 0.1538,
      "step": 13124
    },
    {
      "epoch": 1.019972023624495,
      "grad_norm": 0.36248454451560974,
      "learning_rate": 4.900139881877526e-06,
      "loss": 0.0955,
      "step": 13125
    },
    {
      "epoch": 1.0200497357786757,
      "grad_norm": 0.4098033607006073,
      "learning_rate": 4.899751321106622e-06,
      "loss": 0.2053,
      "step": 13126
    },
    {
      "epoch": 1.0201274479328566,
      "grad_norm": 0.8444209694862366,
      "learning_rate": 4.899362760335717e-06,
      "loss": 0.6124,
      "step": 13127
    },
    {
      "epoch": 1.0202051600870377,
      "grad_norm": 0.27788397669792175,
      "learning_rate": 4.898974199564812e-06,
      "loss": 0.0305,
      "step": 13128
    },
    {
      "epoch": 1.0202828722412185,
      "grad_norm": 0.258044570684433,
      "learning_rate": 4.898585638793908e-06,
      "loss": 0.1577,
      "step": 13129
    },
    {
      "epoch": 1.0203605843953993,
      "grad_norm": 0.373631089925766,
      "learning_rate": 4.8981970780230035e-06,
      "loss": 0.3006,
      "step": 13130
    },
    {
      "epoch": 1.0204382965495804,
      "grad_norm": 0.4401605725288391,
      "learning_rate": 4.897808517252098e-06,
      "loss": 0.4101,
      "step": 13131
    },
    {
      "epoch": 1.0205160087037612,
      "grad_norm": 0.6375961899757385,
      "learning_rate": 4.897419956481194e-06,
      "loss": 0.3559,
      "step": 13132
    },
    {
      "epoch": 1.020593720857942,
      "grad_norm": 0.2186165601015091,
      "learning_rate": 4.897031395710289e-06,
      "loss": 0.0647,
      "step": 13133
    },
    {
      "epoch": 1.0206714330121232,
      "grad_norm": 0.383878231048584,
      "learning_rate": 4.896642834939385e-06,
      "loss": 0.0798,
      "step": 13134
    },
    {
      "epoch": 1.020749145166304,
      "grad_norm": 0.10089783370494843,
      "learning_rate": 4.896254274168481e-06,
      "loss": 0.0505,
      "step": 13135
    },
    {
      "epoch": 1.0208268573204848,
      "grad_norm": 0.33807286620140076,
      "learning_rate": 4.895865713397576e-06,
      "loss": 0.2106,
      "step": 13136
    },
    {
      "epoch": 1.020904569474666,
      "grad_norm": 0.43918105959892273,
      "learning_rate": 4.8954771526266715e-06,
      "loss": 0.1235,
      "step": 13137
    },
    {
      "epoch": 1.0209822816288467,
      "grad_norm": 0.7058300375938416,
      "learning_rate": 4.8950885918557664e-06,
      "loss": 1.1799,
      "step": 13138
    },
    {
      "epoch": 1.0210599937830276,
      "grad_norm": 0.23294219374656677,
      "learning_rate": 4.894700031084862e-06,
      "loss": 0.0279,
      "step": 13139
    },
    {
      "epoch": 1.0211377059372087,
      "grad_norm": 0.5611254572868347,
      "learning_rate": 4.894311470313958e-06,
      "loss": 0.3775,
      "step": 13140
    },
    {
      "epoch": 1.0212154180913895,
      "grad_norm": 0.45210355520248413,
      "learning_rate": 4.893922909543053e-06,
      "loss": 0.3799,
      "step": 13141
    },
    {
      "epoch": 1.0212931302455703,
      "grad_norm": 0.4723352789878845,
      "learning_rate": 4.893534348772148e-06,
      "loss": 0.5859,
      "step": 13142
    },
    {
      "epoch": 1.0213708423997514,
      "grad_norm": 1.0703308582305908,
      "learning_rate": 4.893145788001244e-06,
      "loss": 0.4928,
      "step": 13143
    },
    {
      "epoch": 1.0214485545539322,
      "grad_norm": 0.16169680655002594,
      "learning_rate": 4.8927572272303395e-06,
      "loss": 0.033,
      "step": 13144
    },
    {
      "epoch": 1.021526266708113,
      "grad_norm": 0.2943750023841858,
      "learning_rate": 4.8923686664594345e-06,
      "loss": 0.0774,
      "step": 13145
    },
    {
      "epoch": 1.0216039788622941,
      "grad_norm": 0.49510130286216736,
      "learning_rate": 4.89198010568853e-06,
      "loss": 0.1542,
      "step": 13146
    },
    {
      "epoch": 1.021681691016475,
      "grad_norm": 0.0511985681951046,
      "learning_rate": 4.891591544917625e-06,
      "loss": 0.0105,
      "step": 13147
    },
    {
      "epoch": 1.0217594031706558,
      "grad_norm": 0.6114425659179688,
      "learning_rate": 4.891202984146721e-06,
      "loss": 0.2891,
      "step": 13148
    },
    {
      "epoch": 1.021837115324837,
      "grad_norm": 0.3235245645046234,
      "learning_rate": 4.890814423375817e-06,
      "loss": 0.2359,
      "step": 13149
    },
    {
      "epoch": 1.0219148274790177,
      "grad_norm": 0.37463030219078064,
      "learning_rate": 4.890425862604912e-06,
      "loss": 0.2844,
      "step": 13150
    },
    {
      "epoch": 1.0219925396331986,
      "grad_norm": 0.3758313059806824,
      "learning_rate": 4.8900373018340076e-06,
      "loss": 0.1464,
      "step": 13151
    },
    {
      "epoch": 1.0220702517873796,
      "grad_norm": 0.157816544175148,
      "learning_rate": 4.8896487410631025e-06,
      "loss": 0.0402,
      "step": 13152
    },
    {
      "epoch": 1.0221479639415605,
      "grad_norm": 0.20119129121303558,
      "learning_rate": 4.889260180292198e-06,
      "loss": 0.0164,
      "step": 13153
    },
    {
      "epoch": 1.0222256760957413,
      "grad_norm": 0.2233886867761612,
      "learning_rate": 4.888871619521294e-06,
      "loss": 0.064,
      "step": 13154
    },
    {
      "epoch": 1.0223033882499224,
      "grad_norm": 0.09576338529586792,
      "learning_rate": 4.888483058750389e-06,
      "loss": 0.0314,
      "step": 13155
    },
    {
      "epoch": 1.0223811004041032,
      "grad_norm": 0.38106346130371094,
      "learning_rate": 4.888094497979484e-06,
      "loss": 0.2429,
      "step": 13156
    },
    {
      "epoch": 1.022458812558284,
      "grad_norm": 0.516169548034668,
      "learning_rate": 4.88770593720858e-06,
      "loss": 0.1703,
      "step": 13157
    },
    {
      "epoch": 1.022536524712465,
      "grad_norm": 0.2296101599931717,
      "learning_rate": 4.887317376437676e-06,
      "loss": 0.1094,
      "step": 13158
    },
    {
      "epoch": 1.022614236866646,
      "grad_norm": 0.5925929546356201,
      "learning_rate": 4.8869288156667706e-06,
      "loss": 0.3153,
      "step": 13159
    },
    {
      "epoch": 1.0226919490208268,
      "grad_norm": 0.43922510743141174,
      "learning_rate": 4.886540254895866e-06,
      "loss": 0.0629,
      "step": 13160
    },
    {
      "epoch": 1.0227696611750077,
      "grad_norm": 0.32292744517326355,
      "learning_rate": 4.886151694124961e-06,
      "loss": 0.1754,
      "step": 13161
    },
    {
      "epoch": 1.0228473733291887,
      "grad_norm": 1.1576064825057983,
      "learning_rate": 4.885763133354057e-06,
      "loss": 0.8001,
      "step": 13162
    },
    {
      "epoch": 1.0229250854833696,
      "grad_norm": 0.529136598110199,
      "learning_rate": 4.885374572583153e-06,
      "loss": 0.0906,
      "step": 13163
    },
    {
      "epoch": 1.0230027976375504,
      "grad_norm": 0.5095555782318115,
      "learning_rate": 4.884986011812248e-06,
      "loss": 0.7588,
      "step": 13164
    },
    {
      "epoch": 1.0230805097917315,
      "grad_norm": 0.5151169896125793,
      "learning_rate": 4.884597451041344e-06,
      "loss": 0.2135,
      "step": 13165
    },
    {
      "epoch": 1.0231582219459123,
      "grad_norm": 0.4240965247154236,
      "learning_rate": 4.884208890270439e-06,
      "loss": 0.1111,
      "step": 13166
    },
    {
      "epoch": 1.0232359341000932,
      "grad_norm": 0.9054454565048218,
      "learning_rate": 4.883820329499534e-06,
      "loss": 0.4483,
      "step": 13167
    },
    {
      "epoch": 1.0233136462542742,
      "grad_norm": 0.1116366982460022,
      "learning_rate": 4.88343176872863e-06,
      "loss": 0.0213,
      "step": 13168
    },
    {
      "epoch": 1.023391358408455,
      "grad_norm": 0.5167115926742554,
      "learning_rate": 4.883043207957725e-06,
      "loss": 0.6312,
      "step": 13169
    },
    {
      "epoch": 1.023469070562636,
      "grad_norm": 0.3137408196926117,
      "learning_rate": 4.88265464718682e-06,
      "loss": 0.1919,
      "step": 13170
    },
    {
      "epoch": 1.023546782716817,
      "grad_norm": 0.3068259656429291,
      "learning_rate": 4.882266086415916e-06,
      "loss": 0.1996,
      "step": 13171
    },
    {
      "epoch": 1.0236244948709978,
      "grad_norm": 0.16906553506851196,
      "learning_rate": 4.881877525645012e-06,
      "loss": 0.019,
      "step": 13172
    },
    {
      "epoch": 1.0237022070251787,
      "grad_norm": 1.366429090499878,
      "learning_rate": 4.881488964874107e-06,
      "loss": 0.6955,
      "step": 13173
    },
    {
      "epoch": 1.0237799191793597,
      "grad_norm": 0.352973997592926,
      "learning_rate": 4.8811004041032024e-06,
      "loss": 0.2608,
      "step": 13174
    },
    {
      "epoch": 1.0238576313335406,
      "grad_norm": 0.4028930962085724,
      "learning_rate": 4.880711843332297e-06,
      "loss": 0.151,
      "step": 13175
    },
    {
      "epoch": 1.0239353434877214,
      "grad_norm": 0.2776448130607605,
      "learning_rate": 4.880323282561393e-06,
      "loss": 0.0553,
      "step": 13176
    },
    {
      "epoch": 1.0240130556419025,
      "grad_norm": 0.7995688319206238,
      "learning_rate": 4.879934721790489e-06,
      "loss": 0.2134,
      "step": 13177
    },
    {
      "epoch": 1.0240907677960833,
      "grad_norm": 1.260948657989502,
      "learning_rate": 4.879546161019584e-06,
      "loss": 0.586,
      "step": 13178
    },
    {
      "epoch": 1.0241684799502642,
      "grad_norm": 0.6139568090438843,
      "learning_rate": 4.879157600248679e-06,
      "loss": 0.3803,
      "step": 13179
    },
    {
      "epoch": 1.0242461921044452,
      "grad_norm": 1.0341386795043945,
      "learning_rate": 4.878769039477775e-06,
      "loss": 0.6051,
      "step": 13180
    },
    {
      "epoch": 1.024323904258626,
      "grad_norm": 0.06713621318340302,
      "learning_rate": 4.8783804787068705e-06,
      "loss": 0.0188,
      "step": 13181
    },
    {
      "epoch": 1.024401616412807,
      "grad_norm": 0.2496953010559082,
      "learning_rate": 4.877991917935965e-06,
      "loss": 0.0963,
      "step": 13182
    },
    {
      "epoch": 1.024479328566988,
      "grad_norm": 0.511386513710022,
      "learning_rate": 4.877603357165061e-06,
      "loss": 0.2468,
      "step": 13183
    },
    {
      "epoch": 1.0245570407211688,
      "grad_norm": 0.44443461298942566,
      "learning_rate": 4.877214796394156e-06,
      "loss": 0.1046,
      "step": 13184
    },
    {
      "epoch": 1.0246347528753497,
      "grad_norm": 0.5705013871192932,
      "learning_rate": 4.876826235623252e-06,
      "loss": 0.1961,
      "step": 13185
    },
    {
      "epoch": 1.0247124650295305,
      "grad_norm": 0.5132876038551331,
      "learning_rate": 4.876437674852347e-06,
      "loss": 0.2698,
      "step": 13186
    },
    {
      "epoch": 1.0247901771837116,
      "grad_norm": 0.4548804461956024,
      "learning_rate": 4.876049114081443e-06,
      "loss": 0.3941,
      "step": 13187
    },
    {
      "epoch": 1.0248678893378924,
      "grad_norm": 0.19975845515727997,
      "learning_rate": 4.8756605533105385e-06,
      "loss": 0.0437,
      "step": 13188
    },
    {
      "epoch": 1.0249456014920733,
      "grad_norm": 0.5548545718193054,
      "learning_rate": 4.8752719925396334e-06,
      "loss": 0.1412,
      "step": 13189
    },
    {
      "epoch": 1.0250233136462543,
      "grad_norm": 0.7856160402297974,
      "learning_rate": 4.874883431768728e-06,
      "loss": 0.267,
      "step": 13190
    },
    {
      "epoch": 1.0251010258004352,
      "grad_norm": 0.5738603472709656,
      "learning_rate": 4.874494870997824e-06,
      "loss": 0.0886,
      "step": 13191
    },
    {
      "epoch": 1.025178737954616,
      "grad_norm": 0.19913311302661896,
      "learning_rate": 4.87410631022692e-06,
      "loss": 0.0044,
      "step": 13192
    },
    {
      "epoch": 1.025256450108797,
      "grad_norm": 0.8109468817710876,
      "learning_rate": 4.873717749456015e-06,
      "loss": 0.3099,
      "step": 13193
    },
    {
      "epoch": 1.025334162262978,
      "grad_norm": 0.836652398109436,
      "learning_rate": 4.873329188685111e-06,
      "loss": 0.7353,
      "step": 13194
    },
    {
      "epoch": 1.0254118744171588,
      "grad_norm": 0.602763295173645,
      "learning_rate": 4.872940627914206e-06,
      "loss": 0.2387,
      "step": 13195
    },
    {
      "epoch": 1.0254895865713398,
      "grad_norm": 0.6135194897651672,
      "learning_rate": 4.8725520671433015e-06,
      "loss": 0.3586,
      "step": 13196
    },
    {
      "epoch": 1.0255672987255207,
      "grad_norm": 0.3468901216983795,
      "learning_rate": 4.872163506372397e-06,
      "loss": 0.1832,
      "step": 13197
    },
    {
      "epoch": 1.0256450108797015,
      "grad_norm": 0.4960995316505432,
      "learning_rate": 4.871774945601492e-06,
      "loss": 0.4597,
      "step": 13198
    },
    {
      "epoch": 1.0257227230338826,
      "grad_norm": 0.09980075061321259,
      "learning_rate": 4.871386384830588e-06,
      "loss": 0.0539,
      "step": 13199
    },
    {
      "epoch": 1.0258004351880634,
      "grad_norm": 0.1416928768157959,
      "learning_rate": 4.870997824059683e-06,
      "loss": 0.0116,
      "step": 13200
    },
    {
      "epoch": 1.0258781473422443,
      "grad_norm": 0.936806857585907,
      "learning_rate": 4.870609263288779e-06,
      "loss": 0.1557,
      "step": 13201
    },
    {
      "epoch": 1.0259558594964253,
      "grad_norm": 0.3330039381980896,
      "learning_rate": 4.8702207025178746e-06,
      "loss": 0.2352,
      "step": 13202
    },
    {
      "epoch": 1.0260335716506062,
      "grad_norm": 0.20051360130310059,
      "learning_rate": 4.8698321417469695e-06,
      "loss": 0.0243,
      "step": 13203
    },
    {
      "epoch": 1.026111283804787,
      "grad_norm": 0.35786277055740356,
      "learning_rate": 4.8694435809760645e-06,
      "loss": 0.0538,
      "step": 13204
    },
    {
      "epoch": 1.026188995958968,
      "grad_norm": 0.21719661355018616,
      "learning_rate": 4.86905502020516e-06,
      "loss": 0.0338,
      "step": 13205
    },
    {
      "epoch": 1.026266708113149,
      "grad_norm": 0.74942547082901,
      "learning_rate": 4.868666459434256e-06,
      "loss": 0.3978,
      "step": 13206
    },
    {
      "epoch": 1.0263444202673297,
      "grad_norm": 0.43636539578437805,
      "learning_rate": 4.868277898663351e-06,
      "loss": 0.2563,
      "step": 13207
    },
    {
      "epoch": 1.0264221324215108,
      "grad_norm": 0.04374714940786362,
      "learning_rate": 4.867889337892447e-06,
      "loss": 0.0054,
      "step": 13208
    },
    {
      "epoch": 1.0264998445756917,
      "grad_norm": 0.14297626912593842,
      "learning_rate": 4.867500777121542e-06,
      "loss": 0.0601,
      "step": 13209
    },
    {
      "epoch": 1.0265775567298725,
      "grad_norm": 0.5023184418678284,
      "learning_rate": 4.8671122163506376e-06,
      "loss": 0.2571,
      "step": 13210
    },
    {
      "epoch": 1.0266552688840536,
      "grad_norm": 0.3706717789173126,
      "learning_rate": 4.866723655579733e-06,
      "loss": 0.095,
      "step": 13211
    },
    {
      "epoch": 1.0267329810382344,
      "grad_norm": 0.3129262626171112,
      "learning_rate": 4.866335094808828e-06,
      "loss": 0.062,
      "step": 13212
    },
    {
      "epoch": 1.0268106931924152,
      "grad_norm": 0.3619219958782196,
      "learning_rate": 4.865946534037924e-06,
      "loss": 0.0868,
      "step": 13213
    },
    {
      "epoch": 1.0268884053465963,
      "grad_norm": 0.5437942147254944,
      "learning_rate": 4.865557973267019e-06,
      "loss": 0.4278,
      "step": 13214
    },
    {
      "epoch": 1.0269661175007772,
      "grad_norm": 0.07765768468379974,
      "learning_rate": 4.865169412496115e-06,
      "loss": 0.0153,
      "step": 13215
    },
    {
      "epoch": 1.027043829654958,
      "grad_norm": 0.5877662301063538,
      "learning_rate": 4.864780851725211e-06,
      "loss": 0.3659,
      "step": 13216
    },
    {
      "epoch": 1.027121541809139,
      "grad_norm": 0.5963559746742249,
      "learning_rate": 4.864392290954306e-06,
      "loss": 0.3418,
      "step": 13217
    },
    {
      "epoch": 1.02719925396332,
      "grad_norm": 0.6695100665092468,
      "learning_rate": 4.8640037301834005e-06,
      "loss": 0.1567,
      "step": 13218
    },
    {
      "epoch": 1.0272769661175007,
      "grad_norm": 0.5360774397850037,
      "learning_rate": 4.863615169412496e-06,
      "loss": 0.3789,
      "step": 13219
    },
    {
      "epoch": 1.0273546782716816,
      "grad_norm": 0.25629955530166626,
      "learning_rate": 4.863226608641592e-06,
      "loss": 0.0523,
      "step": 13220
    },
    {
      "epoch": 1.0274323904258627,
      "grad_norm": 0.2669743597507477,
      "learning_rate": 4.862838047870687e-06,
      "loss": 0.2548,
      "step": 13221
    },
    {
      "epoch": 1.0275101025800435,
      "grad_norm": 0.7197136282920837,
      "learning_rate": 4.862449487099783e-06,
      "loss": 0.5649,
      "step": 13222
    },
    {
      "epoch": 1.0275878147342243,
      "grad_norm": 0.3641338348388672,
      "learning_rate": 4.862060926328878e-06,
      "loss": 0.1023,
      "step": 13223
    },
    {
      "epoch": 1.0276655268884054,
      "grad_norm": 0.3263808786869049,
      "learning_rate": 4.861672365557974e-06,
      "loss": 0.0697,
      "step": 13224
    },
    {
      "epoch": 1.0277432390425862,
      "grad_norm": 0.44046077132225037,
      "learning_rate": 4.8612838047870694e-06,
      "loss": 0.0844,
      "step": 13225
    },
    {
      "epoch": 1.027820951196767,
      "grad_norm": 0.38022348284721375,
      "learning_rate": 4.860895244016164e-06,
      "loss": 0.1853,
      "step": 13226
    },
    {
      "epoch": 1.0278986633509481,
      "grad_norm": 0.4423796832561493,
      "learning_rate": 4.86050668324526e-06,
      "loss": 0.3983,
      "step": 13227
    },
    {
      "epoch": 1.027976375505129,
      "grad_norm": 0.4090341329574585,
      "learning_rate": 4.860118122474355e-06,
      "loss": 0.1496,
      "step": 13228
    },
    {
      "epoch": 1.0280540876593098,
      "grad_norm": 0.666551947593689,
      "learning_rate": 4.859729561703451e-06,
      "loss": 0.1961,
      "step": 13229
    },
    {
      "epoch": 1.028131799813491,
      "grad_norm": 0.42609256505966187,
      "learning_rate": 4.859341000932547e-06,
      "loss": 0.1987,
      "step": 13230
    },
    {
      "epoch": 1.0282095119676717,
      "grad_norm": 0.5181500315666199,
      "learning_rate": 4.858952440161642e-06,
      "loss": 0.3348,
      "step": 13231
    },
    {
      "epoch": 1.0282872241218526,
      "grad_norm": 0.4087982773780823,
      "learning_rate": 4.858563879390737e-06,
      "loss": 0.1325,
      "step": 13232
    },
    {
      "epoch": 1.0283649362760336,
      "grad_norm": 0.4328533113002777,
      "learning_rate": 4.858175318619832e-06,
      "loss": 0.2003,
      "step": 13233
    },
    {
      "epoch": 1.0284426484302145,
      "grad_norm": 0.4825379550457001,
      "learning_rate": 4.857786757848928e-06,
      "loss": 0.2214,
      "step": 13234
    },
    {
      "epoch": 1.0285203605843953,
      "grad_norm": 0.6412907838821411,
      "learning_rate": 4.857398197078023e-06,
      "loss": 0.1664,
      "step": 13235
    },
    {
      "epoch": 1.0285980727385764,
      "grad_norm": 0.42388755083084106,
      "learning_rate": 4.857009636307119e-06,
      "loss": 0.1751,
      "step": 13236
    },
    {
      "epoch": 1.0286757848927572,
      "grad_norm": 0.3082875907421112,
      "learning_rate": 4.856621075536214e-06,
      "loss": 0.4317,
      "step": 13237
    },
    {
      "epoch": 1.028753497046938,
      "grad_norm": 0.21789433062076569,
      "learning_rate": 4.85623251476531e-06,
      "loss": 0.0302,
      "step": 13238
    },
    {
      "epoch": 1.0288312092011191,
      "grad_norm": 0.19640448689460754,
      "learning_rate": 4.8558439539944055e-06,
      "loss": 0.0262,
      "step": 13239
    },
    {
      "epoch": 1.0289089213553,
      "grad_norm": 0.2664494812488556,
      "learning_rate": 4.8554553932235004e-06,
      "loss": 0.059,
      "step": 13240
    },
    {
      "epoch": 1.0289866335094808,
      "grad_norm": 0.7761561870574951,
      "learning_rate": 4.855066832452596e-06,
      "loss": 0.759,
      "step": 13241
    },
    {
      "epoch": 1.029064345663662,
      "grad_norm": 0.26459601521492004,
      "learning_rate": 4.854678271681691e-06,
      "loss": 0.089,
      "step": 13242
    },
    {
      "epoch": 1.0291420578178427,
      "grad_norm": 0.2583746612071991,
      "learning_rate": 4.854289710910787e-06,
      "loss": 0.1578,
      "step": 13243
    },
    {
      "epoch": 1.0292197699720236,
      "grad_norm": 0.24973875284194946,
      "learning_rate": 4.853901150139883e-06,
      "loss": 0.0407,
      "step": 13244
    },
    {
      "epoch": 1.0292974821262046,
      "grad_norm": 5.843707084655762,
      "learning_rate": 4.853512589368978e-06,
      "loss": 0.0861,
      "step": 13245
    },
    {
      "epoch": 1.0293751942803855,
      "grad_norm": 0.3948562741279602,
      "learning_rate": 4.853124028598073e-06,
      "loss": 0.1013,
      "step": 13246
    },
    {
      "epoch": 1.0294529064345663,
      "grad_norm": 0.6084908246994019,
      "learning_rate": 4.8527354678271685e-06,
      "loss": 0.1881,
      "step": 13247
    },
    {
      "epoch": 1.0295306185887472,
      "grad_norm": 0.14409054815769196,
      "learning_rate": 4.852346907056264e-06,
      "loss": 0.0325,
      "step": 13248
    },
    {
      "epoch": 1.0296083307429282,
      "grad_norm": 0.6425146460533142,
      "learning_rate": 4.851958346285359e-06,
      "loss": 0.3322,
      "step": 13249
    },
    {
      "epoch": 1.029686042897109,
      "grad_norm": 0.3992544710636139,
      "learning_rate": 4.851569785514455e-06,
      "loss": 0.4862,
      "step": 13250
    },
    {
      "epoch": 1.02976375505129,
      "grad_norm": 0.7193050384521484,
      "learning_rate": 4.85118122474355e-06,
      "loss": 0.4701,
      "step": 13251
    },
    {
      "epoch": 1.029841467205471,
      "grad_norm": 0.2558872699737549,
      "learning_rate": 4.850792663972646e-06,
      "loss": 0.091,
      "step": 13252
    },
    {
      "epoch": 1.0299191793596518,
      "grad_norm": 0.5092759728431702,
      "learning_rate": 4.8504041032017416e-06,
      "loss": 0.3294,
      "step": 13253
    },
    {
      "epoch": 1.0299968915138327,
      "grad_norm": 0.5558773279190063,
      "learning_rate": 4.8500155424308365e-06,
      "loss": 0.1724,
      "step": 13254
    },
    {
      "epoch": 1.0300746036680137,
      "grad_norm": 0.10532734543085098,
      "learning_rate": 4.849626981659932e-06,
      "loss": 0.0526,
      "step": 13255
    },
    {
      "epoch": 1.0301523158221946,
      "grad_norm": 0.29342418909072876,
      "learning_rate": 4.849238420889027e-06,
      "loss": 0.063,
      "step": 13256
    },
    {
      "epoch": 1.0302300279763754,
      "grad_norm": 0.2833106815814972,
      "learning_rate": 4.848849860118123e-06,
      "loss": 0.158,
      "step": 13257
    },
    {
      "epoch": 1.0303077401305565,
      "grad_norm": 0.19804948568344116,
      "learning_rate": 4.848461299347219e-06,
      "loss": 0.0326,
      "step": 13258
    },
    {
      "epoch": 1.0303854522847373,
      "grad_norm": 0.11919663846492767,
      "learning_rate": 4.848072738576314e-06,
      "loss": 0.0243,
      "step": 13259
    },
    {
      "epoch": 1.0304631644389182,
      "grad_norm": 0.4938107132911682,
      "learning_rate": 4.847684177805409e-06,
      "loss": 0.201,
      "step": 13260
    },
    {
      "epoch": 1.0305408765930992,
      "grad_norm": 0.30500510334968567,
      "learning_rate": 4.8472956170345046e-06,
      "loss": 0.205,
      "step": 13261
    },
    {
      "epoch": 1.03061858874728,
      "grad_norm": 0.26578155159950256,
      "learning_rate": 4.8469070562636e-06,
      "loss": 0.1014,
      "step": 13262
    },
    {
      "epoch": 1.030696300901461,
      "grad_norm": 0.616073489189148,
      "learning_rate": 4.846518495492695e-06,
      "loss": 0.8795,
      "step": 13263
    },
    {
      "epoch": 1.030774013055642,
      "grad_norm": 0.33557191491127014,
      "learning_rate": 4.846129934721791e-06,
      "loss": 0.276,
      "step": 13264
    },
    {
      "epoch": 1.0308517252098228,
      "grad_norm": 0.47103819251060486,
      "learning_rate": 4.845741373950886e-06,
      "loss": 0.4205,
      "step": 13265
    },
    {
      "epoch": 1.0309294373640037,
      "grad_norm": 0.17192010581493378,
      "learning_rate": 4.845352813179982e-06,
      "loss": 0.0762,
      "step": 13266
    },
    {
      "epoch": 1.0310071495181847,
      "grad_norm": 0.3068512976169586,
      "learning_rate": 4.844964252409078e-06,
      "loss": 0.0955,
      "step": 13267
    },
    {
      "epoch": 1.0310848616723656,
      "grad_norm": 0.4935046434402466,
      "learning_rate": 4.844575691638173e-06,
      "loss": 0.1682,
      "step": 13268
    },
    {
      "epoch": 1.0311625738265464,
      "grad_norm": 0.793080747127533,
      "learning_rate": 4.8441871308672675e-06,
      "loss": 0.3695,
      "step": 13269
    },
    {
      "epoch": 1.0312402859807275,
      "grad_norm": 0.25063657760620117,
      "learning_rate": 4.843798570096363e-06,
      "loss": 0.0191,
      "step": 13270
    },
    {
      "epoch": 1.0313179981349083,
      "grad_norm": 0.34698066115379333,
      "learning_rate": 4.843410009325459e-06,
      "loss": 0.1465,
      "step": 13271
    },
    {
      "epoch": 1.0313957102890892,
      "grad_norm": 0.9493012428283691,
      "learning_rate": 4.843021448554555e-06,
      "loss": 0.4319,
      "step": 13272
    },
    {
      "epoch": 1.0314734224432702,
      "grad_norm": 0.820340096950531,
      "learning_rate": 4.84263288778365e-06,
      "loss": 0.2261,
      "step": 13273
    },
    {
      "epoch": 1.031551134597451,
      "grad_norm": 0.2508285641670227,
      "learning_rate": 4.842244327012745e-06,
      "loss": 0.0871,
      "step": 13274
    },
    {
      "epoch": 1.031628846751632,
      "grad_norm": 0.22011798620224,
      "learning_rate": 4.841855766241841e-06,
      "loss": 0.0558,
      "step": 13275
    },
    {
      "epoch": 1.031706558905813,
      "grad_norm": 0.2294224053621292,
      "learning_rate": 4.8414672054709364e-06,
      "loss": 0.0535,
      "step": 13276
    },
    {
      "epoch": 1.0317842710599938,
      "grad_norm": 0.500025749206543,
      "learning_rate": 4.841078644700031e-06,
      "loss": 0.1598,
      "step": 13277
    },
    {
      "epoch": 1.0318619832141747,
      "grad_norm": 0.36878788471221924,
      "learning_rate": 4.840690083929127e-06,
      "loss": 0.1278,
      "step": 13278
    },
    {
      "epoch": 1.0319396953683557,
      "grad_norm": 0.9652140140533447,
      "learning_rate": 4.840301523158222e-06,
      "loss": 0.3191,
      "step": 13279
    },
    {
      "epoch": 1.0320174075225366,
      "grad_norm": 0.2947724163532257,
      "learning_rate": 4.839912962387318e-06,
      "loss": 0.1284,
      "step": 13280
    },
    {
      "epoch": 1.0320951196767174,
      "grad_norm": 0.8193265199661255,
      "learning_rate": 4.839524401616414e-06,
      "loss": 0.1989,
      "step": 13281
    },
    {
      "epoch": 1.0321728318308983,
      "grad_norm": 0.5280788540840149,
      "learning_rate": 4.839135840845509e-06,
      "loss": 0.213,
      "step": 13282
    },
    {
      "epoch": 1.0322505439850793,
      "grad_norm": 0.38156554102897644,
      "learning_rate": 4.838747280074604e-06,
      "loss": 0.0406,
      "step": 13283
    },
    {
      "epoch": 1.0323282561392602,
      "grad_norm": 0.30601638555526733,
      "learning_rate": 4.838358719303699e-06,
      "loss": 0.0595,
      "step": 13284
    },
    {
      "epoch": 1.032405968293441,
      "grad_norm": 0.1297166347503662,
      "learning_rate": 4.837970158532795e-06,
      "loss": 0.057,
      "step": 13285
    },
    {
      "epoch": 1.032483680447622,
      "grad_norm": 0.15623816847801208,
      "learning_rate": 4.837581597761891e-06,
      "loss": 0.0529,
      "step": 13286
    },
    {
      "epoch": 1.032561392601803,
      "grad_norm": 0.30020296573638916,
      "learning_rate": 4.837193036990986e-06,
      "loss": 0.0884,
      "step": 13287
    },
    {
      "epoch": 1.0326391047559837,
      "grad_norm": 0.2690637409687042,
      "learning_rate": 4.836804476220081e-06,
      "loss": 0.0417,
      "step": 13288
    },
    {
      "epoch": 1.0327168169101648,
      "grad_norm": 0.5742512941360474,
      "learning_rate": 4.836415915449177e-06,
      "loss": 0.6446,
      "step": 13289
    },
    {
      "epoch": 1.0327945290643457,
      "grad_norm": 0.43717649579048157,
      "learning_rate": 4.8360273546782725e-06,
      "loss": 0.2768,
      "step": 13290
    },
    {
      "epoch": 1.0328722412185265,
      "grad_norm": 0.18450582027435303,
      "learning_rate": 4.8356387939073675e-06,
      "loss": 0.0446,
      "step": 13291
    },
    {
      "epoch": 1.0329499533727076,
      "grad_norm": 1.0097328424453735,
      "learning_rate": 4.835250233136463e-06,
      "loss": 0.2641,
      "step": 13292
    },
    {
      "epoch": 1.0330276655268884,
      "grad_norm": 0.32240504026412964,
      "learning_rate": 4.834861672365558e-06,
      "loss": 0.0702,
      "step": 13293
    },
    {
      "epoch": 1.0331053776810692,
      "grad_norm": 0.33150702714920044,
      "learning_rate": 4.834473111594654e-06,
      "loss": 0.1736,
      "step": 13294
    },
    {
      "epoch": 1.0331830898352503,
      "grad_norm": 0.31332525610923767,
      "learning_rate": 4.83408455082375e-06,
      "loss": 0.2455,
      "step": 13295
    },
    {
      "epoch": 1.0332608019894312,
      "grad_norm": 0.26717114448547363,
      "learning_rate": 4.833695990052845e-06,
      "loss": 0.1355,
      "step": 13296
    },
    {
      "epoch": 1.033338514143612,
      "grad_norm": 0.12475521117448807,
      "learning_rate": 4.83330742928194e-06,
      "loss": 0.0326,
      "step": 13297
    },
    {
      "epoch": 1.033416226297793,
      "grad_norm": 0.24906332790851593,
      "learning_rate": 4.8329188685110355e-06,
      "loss": 0.0477,
      "step": 13298
    },
    {
      "epoch": 1.033493938451974,
      "grad_norm": 0.5667821764945984,
      "learning_rate": 4.832530307740131e-06,
      "loss": 0.3969,
      "step": 13299
    },
    {
      "epoch": 1.0335716506061547,
      "grad_norm": 0.2937452793121338,
      "learning_rate": 4.832141746969226e-06,
      "loss": 0.16,
      "step": 13300
    },
    {
      "epoch": 1.0336493627603358,
      "grad_norm": 0.6852550506591797,
      "learning_rate": 4.831753186198322e-06,
      "loss": 0.2343,
      "step": 13301
    },
    {
      "epoch": 1.0337270749145167,
      "grad_norm": 0.3449799120426178,
      "learning_rate": 4.831364625427417e-06,
      "loss": 0.0618,
      "step": 13302
    },
    {
      "epoch": 1.0338047870686975,
      "grad_norm": 0.20942498743534088,
      "learning_rate": 4.830976064656513e-06,
      "loss": 0.0381,
      "step": 13303
    },
    {
      "epoch": 1.0338824992228786,
      "grad_norm": 0.36655938625335693,
      "learning_rate": 4.8305875038856086e-06,
      "loss": 0.132,
      "step": 13304
    },
    {
      "epoch": 1.0339602113770594,
      "grad_norm": 0.42410576343536377,
      "learning_rate": 4.8301989431147035e-06,
      "loss": 0.3236,
      "step": 13305
    },
    {
      "epoch": 1.0340379235312402,
      "grad_norm": 1.2809925079345703,
      "learning_rate": 4.829810382343799e-06,
      "loss": 0.8492,
      "step": 13306
    },
    {
      "epoch": 1.034115635685421,
      "grad_norm": 0.3933347463607788,
      "learning_rate": 4.829421821572894e-06,
      "loss": 0.1397,
      "step": 13307
    },
    {
      "epoch": 1.0341933478396022,
      "grad_norm": 0.24056395888328552,
      "learning_rate": 4.829033260801989e-06,
      "loss": 0.0312,
      "step": 13308
    },
    {
      "epoch": 1.034271059993783,
      "grad_norm": 0.5888739824295044,
      "learning_rate": 4.828644700031085e-06,
      "loss": 0.6914,
      "step": 13309
    },
    {
      "epoch": 1.0343487721479638,
      "grad_norm": 1.208541750907898,
      "learning_rate": 4.828256139260181e-06,
      "loss": 0.228,
      "step": 13310
    },
    {
      "epoch": 1.034426484302145,
      "grad_norm": 0.25259923934936523,
      "learning_rate": 4.827867578489276e-06,
      "loss": 0.0227,
      "step": 13311
    },
    {
      "epoch": 1.0345041964563257,
      "grad_norm": 0.13555070757865906,
      "learning_rate": 4.8274790177183716e-06,
      "loss": 0.0253,
      "step": 13312
    },
    {
      "epoch": 1.0345819086105066,
      "grad_norm": 0.17543506622314453,
      "learning_rate": 4.8270904569474665e-06,
      "loss": 0.0731,
      "step": 13313
    },
    {
      "epoch": 1.0346596207646876,
      "grad_norm": 0.40349361300468445,
      "learning_rate": 4.826701896176562e-06,
      "loss": 0.1894,
      "step": 13314
    },
    {
      "epoch": 1.0347373329188685,
      "grad_norm": 0.23155711591243744,
      "learning_rate": 4.826313335405658e-06,
      "loss": 0.0963,
      "step": 13315
    },
    {
      "epoch": 1.0348150450730493,
      "grad_norm": 0.17971016466617584,
      "learning_rate": 4.825924774634753e-06,
      "loss": 0.0562,
      "step": 13316
    },
    {
      "epoch": 1.0348927572272304,
      "grad_norm": 0.2563422918319702,
      "learning_rate": 4.825536213863849e-06,
      "loss": 0.0652,
      "step": 13317
    },
    {
      "epoch": 1.0349704693814112,
      "grad_norm": 0.1303035467863083,
      "learning_rate": 4.825147653092944e-06,
      "loss": 0.0629,
      "step": 13318
    },
    {
      "epoch": 1.035048181535592,
      "grad_norm": 0.4602551758289337,
      "learning_rate": 4.82475909232204e-06,
      "loss": 0.0892,
      "step": 13319
    },
    {
      "epoch": 1.0351258936897731,
      "grad_norm": 0.40687131881713867,
      "learning_rate": 4.824370531551135e-06,
      "loss": 0.0595,
      "step": 13320
    },
    {
      "epoch": 1.035203605843954,
      "grad_norm": 0.22734373807907104,
      "learning_rate": 4.82398197078023e-06,
      "loss": 0.1198,
      "step": 13321
    },
    {
      "epoch": 1.0352813179981348,
      "grad_norm": 0.04791731387376785,
      "learning_rate": 4.823593410009325e-06,
      "loss": 0.0084,
      "step": 13322
    },
    {
      "epoch": 1.035359030152316,
      "grad_norm": 0.26345109939575195,
      "learning_rate": 4.823204849238421e-06,
      "loss": 0.1,
      "step": 13323
    },
    {
      "epoch": 1.0354367423064967,
      "grad_norm": 0.311261385679245,
      "learning_rate": 4.822816288467517e-06,
      "loss": 0.1385,
      "step": 13324
    },
    {
      "epoch": 1.0355144544606776,
      "grad_norm": 0.679503858089447,
      "learning_rate": 4.822427727696612e-06,
      "loss": 0.2677,
      "step": 13325
    },
    {
      "epoch": 1.0355921666148586,
      "grad_norm": 1.183255672454834,
      "learning_rate": 4.822039166925708e-06,
      "loss": 0.8676,
      "step": 13326
    },
    {
      "epoch": 1.0356698787690395,
      "grad_norm": 0.15911605954170227,
      "learning_rate": 4.821650606154803e-06,
      "loss": 0.0235,
      "step": 13327
    },
    {
      "epoch": 1.0357475909232203,
      "grad_norm": 0.5518699884414673,
      "learning_rate": 4.821262045383898e-06,
      "loss": 0.4431,
      "step": 13328
    },
    {
      "epoch": 1.0358253030774014,
      "grad_norm": 0.710643470287323,
      "learning_rate": 4.820873484612994e-06,
      "loss": 0.1238,
      "step": 13329
    },
    {
      "epoch": 1.0359030152315822,
      "grad_norm": 0.34236887097358704,
      "learning_rate": 4.820484923842089e-06,
      "loss": 0.1818,
      "step": 13330
    },
    {
      "epoch": 1.035980727385763,
      "grad_norm": 0.45067697763442993,
      "learning_rate": 4.820096363071185e-06,
      "loss": 0.2431,
      "step": 13331
    },
    {
      "epoch": 1.0360584395399441,
      "grad_norm": 0.415619820356369,
      "learning_rate": 4.81970780230028e-06,
      "loss": 0.1752,
      "step": 13332
    },
    {
      "epoch": 1.036136151694125,
      "grad_norm": 0.07992755621671677,
      "learning_rate": 4.819319241529376e-06,
      "loss": 0.0255,
      "step": 13333
    },
    {
      "epoch": 1.0362138638483058,
      "grad_norm": 0.8137626051902771,
      "learning_rate": 4.8189306807584715e-06,
      "loss": 0.9366,
      "step": 13334
    },
    {
      "epoch": 1.036291576002487,
      "grad_norm": 0.5905678868293762,
      "learning_rate": 4.818542119987566e-06,
      "loss": 0.3366,
      "step": 13335
    },
    {
      "epoch": 1.0363692881566677,
      "grad_norm": 0.3268439769744873,
      "learning_rate": 4.818153559216661e-06,
      "loss": 0.1119,
      "step": 13336
    },
    {
      "epoch": 1.0364470003108486,
      "grad_norm": 0.12693123519420624,
      "learning_rate": 4.817764998445757e-06,
      "loss": 0.0408,
      "step": 13337
    },
    {
      "epoch": 1.0365247124650296,
      "grad_norm": 0.10852953791618347,
      "learning_rate": 4.817376437674853e-06,
      "loss": 0.0376,
      "step": 13338
    },
    {
      "epoch": 1.0366024246192105,
      "grad_norm": 0.7938529253005981,
      "learning_rate": 4.816987876903948e-06,
      "loss": 0.5282,
      "step": 13339
    },
    {
      "epoch": 1.0366801367733913,
      "grad_norm": 0.12908637523651123,
      "learning_rate": 4.816599316133044e-06,
      "loss": 0.0464,
      "step": 13340
    },
    {
      "epoch": 1.0367578489275722,
      "grad_norm": 0.43357953429222107,
      "learning_rate": 4.816210755362139e-06,
      "loss": 0.0431,
      "step": 13341
    },
    {
      "epoch": 1.0368355610817532,
      "grad_norm": 0.18776394426822662,
      "learning_rate": 4.8158221945912345e-06,
      "loss": 0.1881,
      "step": 13342
    },
    {
      "epoch": 1.036913273235934,
      "grad_norm": 0.5894145965576172,
      "learning_rate": 4.81543363382033e-06,
      "loss": 0.2348,
      "step": 13343
    },
    {
      "epoch": 1.036990985390115,
      "grad_norm": 1.5657954216003418,
      "learning_rate": 4.815045073049425e-06,
      "loss": 0.5975,
      "step": 13344
    },
    {
      "epoch": 1.037068697544296,
      "grad_norm": 0.8098502159118652,
      "learning_rate": 4.81465651227852e-06,
      "loss": 0.2832,
      "step": 13345
    },
    {
      "epoch": 1.0371464096984768,
      "grad_norm": 0.2311347872018814,
      "learning_rate": 4.814267951507616e-06,
      "loss": 0.0918,
      "step": 13346
    },
    {
      "epoch": 1.0372241218526577,
      "grad_norm": 0.3301554024219513,
      "learning_rate": 4.813879390736712e-06,
      "loss": 0.1975,
      "step": 13347
    },
    {
      "epoch": 1.0373018340068387,
      "grad_norm": 0.13845351338386536,
      "learning_rate": 4.8134908299658075e-06,
      "loss": 0.0185,
      "step": 13348
    },
    {
      "epoch": 1.0373795461610196,
      "grad_norm": 0.16936808824539185,
      "learning_rate": 4.8131022691949025e-06,
      "loss": 0.02,
      "step": 13349
    },
    {
      "epoch": 1.0374572583152004,
      "grad_norm": 0.17311681807041168,
      "learning_rate": 4.8127137084239974e-06,
      "loss": 0.0459,
      "step": 13350
    },
    {
      "epoch": 1.0375349704693815,
      "grad_norm": 0.388212651014328,
      "learning_rate": 4.812325147653093e-06,
      "loss": 0.138,
      "step": 13351
    },
    {
      "epoch": 1.0376126826235623,
      "grad_norm": 0.8416916728019714,
      "learning_rate": 4.811936586882189e-06,
      "loss": 0.2348,
      "step": 13352
    },
    {
      "epoch": 1.0376903947777432,
      "grad_norm": 0.453307569026947,
      "learning_rate": 4.811548026111284e-06,
      "loss": 0.1582,
      "step": 13353
    },
    {
      "epoch": 1.0377681069319242,
      "grad_norm": 0.6863734126091003,
      "learning_rate": 4.81115946534038e-06,
      "loss": 0.4203,
      "step": 13354
    },
    {
      "epoch": 1.037845819086105,
      "grad_norm": 0.3948516845703125,
      "learning_rate": 4.810770904569475e-06,
      "loss": 0.1846,
      "step": 13355
    },
    {
      "epoch": 1.037923531240286,
      "grad_norm": 1.2220643758773804,
      "learning_rate": 4.8103823437985705e-06,
      "loss": 0.2778,
      "step": 13356
    },
    {
      "epoch": 1.038001243394467,
      "grad_norm": 0.8053861856460571,
      "learning_rate": 4.809993783027666e-06,
      "loss": 0.8837,
      "step": 13357
    },
    {
      "epoch": 1.0380789555486478,
      "grad_norm": 1.2469921112060547,
      "learning_rate": 4.809605222256761e-06,
      "loss": 0.214,
      "step": 13358
    },
    {
      "epoch": 1.0381566677028287,
      "grad_norm": 0.17846085131168365,
      "learning_rate": 4.809216661485856e-06,
      "loss": 0.1048,
      "step": 13359
    },
    {
      "epoch": 1.0382343798570097,
      "grad_norm": 0.14553962647914886,
      "learning_rate": 4.808828100714952e-06,
      "loss": 0.0298,
      "step": 13360
    },
    {
      "epoch": 1.0383120920111906,
      "grad_norm": 0.9051425457000732,
      "learning_rate": 4.808439539944048e-06,
      "loss": 0.5112,
      "step": 13361
    },
    {
      "epoch": 1.0383898041653714,
      "grad_norm": 0.9336411952972412,
      "learning_rate": 4.808050979173144e-06,
      "loss": 0.47,
      "step": 13362
    },
    {
      "epoch": 1.0384675163195525,
      "grad_norm": 0.47861602902412415,
      "learning_rate": 4.8076624184022386e-06,
      "loss": 0.1025,
      "step": 13363
    },
    {
      "epoch": 1.0385452284737333,
      "grad_norm": 0.14521409571170807,
      "learning_rate": 4.8072738576313335e-06,
      "loss": 0.0205,
      "step": 13364
    },
    {
      "epoch": 1.0386229406279142,
      "grad_norm": 0.9311555624008179,
      "learning_rate": 4.806885296860429e-06,
      "loss": 0.3291,
      "step": 13365
    },
    {
      "epoch": 1.0387006527820952,
      "grad_norm": 0.4543830454349518,
      "learning_rate": 4.806496736089525e-06,
      "loss": 0.158,
      "step": 13366
    },
    {
      "epoch": 1.038778364936276,
      "grad_norm": 0.2962103486061096,
      "learning_rate": 4.80610817531862e-06,
      "loss": 0.1579,
      "step": 13367
    },
    {
      "epoch": 1.038856077090457,
      "grad_norm": 0.20406393706798553,
      "learning_rate": 4.805719614547716e-06,
      "loss": 0.0814,
      "step": 13368
    },
    {
      "epoch": 1.0389337892446378,
      "grad_norm": 0.21010328829288483,
      "learning_rate": 4.805331053776811e-06,
      "loss": 0.0258,
      "step": 13369
    },
    {
      "epoch": 1.0390115013988188,
      "grad_norm": 0.5565451383590698,
      "learning_rate": 4.804942493005907e-06,
      "loss": 0.1587,
      "step": 13370
    },
    {
      "epoch": 1.0390892135529997,
      "grad_norm": 0.4600696563720703,
      "learning_rate": 4.804553932235002e-06,
      "loss": 0.4538,
      "step": 13371
    },
    {
      "epoch": 1.0391669257071805,
      "grad_norm": 0.24349986016750336,
      "learning_rate": 4.804165371464097e-06,
      "loss": 0.0526,
      "step": 13372
    },
    {
      "epoch": 1.0392446378613616,
      "grad_norm": 0.21423204243183136,
      "learning_rate": 4.803776810693192e-06,
      "loss": 0.0351,
      "step": 13373
    },
    {
      "epoch": 1.0393223500155424,
      "grad_norm": 0.11101341247558594,
      "learning_rate": 4.803388249922288e-06,
      "loss": 0.0498,
      "step": 13374
    },
    {
      "epoch": 1.0394000621697232,
      "grad_norm": 0.18126031756401062,
      "learning_rate": 4.802999689151384e-06,
      "loss": 0.0385,
      "step": 13375
    },
    {
      "epoch": 1.0394777743239043,
      "grad_norm": 0.3413935601711273,
      "learning_rate": 4.802611128380479e-06,
      "loss": 0.156,
      "step": 13376
    },
    {
      "epoch": 1.0395554864780852,
      "grad_norm": 0.3328917324542999,
      "learning_rate": 4.802222567609575e-06,
      "loss": 0.0849,
      "step": 13377
    },
    {
      "epoch": 1.039633198632266,
      "grad_norm": 0.21112826466560364,
      "learning_rate": 4.80183400683867e-06,
      "loss": 0.054,
      "step": 13378
    },
    {
      "epoch": 1.039710910786447,
      "grad_norm": 0.07082861661911011,
      "learning_rate": 4.801445446067765e-06,
      "loss": 0.0085,
      "step": 13379
    },
    {
      "epoch": 1.039788622940628,
      "grad_norm": 0.12481483817100525,
      "learning_rate": 4.801056885296861e-06,
      "loss": 0.0675,
      "step": 13380
    },
    {
      "epoch": 1.0398663350948087,
      "grad_norm": 0.9107726216316223,
      "learning_rate": 4.800668324525956e-06,
      "loss": 0.2431,
      "step": 13381
    },
    {
      "epoch": 1.0399440472489898,
      "grad_norm": 0.4879886507987976,
      "learning_rate": 4.800279763755052e-06,
      "loss": 0.3701,
      "step": 13382
    },
    {
      "epoch": 1.0400217594031707,
      "grad_norm": 0.5909023880958557,
      "learning_rate": 4.799891202984147e-06,
      "loss": 0.1348,
      "step": 13383
    },
    {
      "epoch": 1.0400994715573515,
      "grad_norm": 0.7165559530258179,
      "learning_rate": 4.799502642213243e-06,
      "loss": 0.3302,
      "step": 13384
    },
    {
      "epoch": 1.0401771837115326,
      "grad_norm": 0.30276867747306824,
      "learning_rate": 4.7991140814423385e-06,
      "loss": 0.1246,
      "step": 13385
    },
    {
      "epoch": 1.0402548958657134,
      "grad_norm": 15.431386947631836,
      "learning_rate": 4.798725520671433e-06,
      "loss": 2.2052,
      "step": 13386
    },
    {
      "epoch": 1.0403326080198942,
      "grad_norm": 0.8423891067504883,
      "learning_rate": 4.798336959900528e-06,
      "loss": 0.3862,
      "step": 13387
    },
    {
      "epoch": 1.0404103201740753,
      "grad_norm": 0.2712130844593048,
      "learning_rate": 4.797948399129624e-06,
      "loss": 0.1155,
      "step": 13388
    },
    {
      "epoch": 1.0404880323282562,
      "grad_norm": 0.3339403569698334,
      "learning_rate": 4.79755983835872e-06,
      "loss": 0.4395,
      "step": 13389
    },
    {
      "epoch": 1.040565744482437,
      "grad_norm": 0.42765259742736816,
      "learning_rate": 4.797171277587815e-06,
      "loss": 0.097,
      "step": 13390
    },
    {
      "epoch": 1.040643456636618,
      "grad_norm": 1.0501081943511963,
      "learning_rate": 4.796782716816911e-06,
      "loss": 0.5146,
      "step": 13391
    },
    {
      "epoch": 1.040721168790799,
      "grad_norm": 0.4044942259788513,
      "learning_rate": 4.796394156046006e-06,
      "loss": 0.0716,
      "step": 13392
    },
    {
      "epoch": 1.0407988809449797,
      "grad_norm": 0.3702108561992645,
      "learning_rate": 4.7960055952751015e-06,
      "loss": 0.1073,
      "step": 13393
    },
    {
      "epoch": 1.0408765930991608,
      "grad_norm": 0.20346885919570923,
      "learning_rate": 4.795617034504197e-06,
      "loss": 0.0681,
      "step": 13394
    },
    {
      "epoch": 1.0409543052533416,
      "grad_norm": 0.5845720171928406,
      "learning_rate": 4.795228473733292e-06,
      "loss": 0.378,
      "step": 13395
    },
    {
      "epoch": 1.0410320174075225,
      "grad_norm": 0.2422550618648529,
      "learning_rate": 4.794839912962388e-06,
      "loss": 0.1796,
      "step": 13396
    },
    {
      "epoch": 1.0411097295617036,
      "grad_norm": 0.32918888330459595,
      "learning_rate": 4.794451352191483e-06,
      "loss": 0.1292,
      "step": 13397
    },
    {
      "epoch": 1.0411874417158844,
      "grad_norm": 0.13258394598960876,
      "learning_rate": 4.794062791420579e-06,
      "loss": 0.0308,
      "step": 13398
    },
    {
      "epoch": 1.0412651538700652,
      "grad_norm": 0.7079026103019714,
      "learning_rate": 4.7936742306496745e-06,
      "loss": 0.134,
      "step": 13399
    },
    {
      "epoch": 1.0413428660242463,
      "grad_norm": 0.7368998527526855,
      "learning_rate": 4.7932856698787695e-06,
      "loss": 0.1858,
      "step": 13400
    },
    {
      "epoch": 1.0414205781784271,
      "grad_norm": 0.9414028525352478,
      "learning_rate": 4.7928971091078644e-06,
      "loss": 0.3987,
      "step": 13401
    },
    {
      "epoch": 1.041498290332608,
      "grad_norm": 0.07765723019838333,
      "learning_rate": 4.79250854833696e-06,
      "loss": 0.014,
      "step": 13402
    },
    {
      "epoch": 1.0415760024867888,
      "grad_norm": 0.5563267469406128,
      "learning_rate": 4.792119987566056e-06,
      "loss": 0.3845,
      "step": 13403
    },
    {
      "epoch": 1.04165371464097,
      "grad_norm": 0.3411533236503601,
      "learning_rate": 4.791731426795151e-06,
      "loss": 0.1371,
      "step": 13404
    },
    {
      "epoch": 1.0417314267951507,
      "grad_norm": 0.8388972282409668,
      "learning_rate": 4.791342866024247e-06,
      "loss": 0.4687,
      "step": 13405
    },
    {
      "epoch": 1.0418091389493316,
      "grad_norm": 0.38780125975608826,
      "learning_rate": 4.790954305253342e-06,
      "loss": 0.0341,
      "step": 13406
    },
    {
      "epoch": 1.0418868511035126,
      "grad_norm": 0.20685486495494843,
      "learning_rate": 4.7905657444824375e-06,
      "loss": 0.0432,
      "step": 13407
    },
    {
      "epoch": 1.0419645632576935,
      "grad_norm": 0.4006824195384979,
      "learning_rate": 4.790177183711533e-06,
      "loss": 0.1892,
      "step": 13408
    },
    {
      "epoch": 1.0420422754118743,
      "grad_norm": 0.31961068511009216,
      "learning_rate": 4.789788622940628e-06,
      "loss": 0.1373,
      "step": 13409
    },
    {
      "epoch": 1.0421199875660554,
      "grad_norm": 0.38286861777305603,
      "learning_rate": 4.789400062169724e-06,
      "loss": 0.0992,
      "step": 13410
    },
    {
      "epoch": 1.0421976997202362,
      "grad_norm": 0.9205515384674072,
      "learning_rate": 4.789011501398819e-06,
      "loss": 0.1354,
      "step": 13411
    },
    {
      "epoch": 1.042275411874417,
      "grad_norm": 0.5578045845031738,
      "learning_rate": 4.788622940627915e-06,
      "loss": 0.208,
      "step": 13412
    },
    {
      "epoch": 1.0423531240285981,
      "grad_norm": 1.0712589025497437,
      "learning_rate": 4.788234379857011e-06,
      "loss": 0.215,
      "step": 13413
    },
    {
      "epoch": 1.042430836182779,
      "grad_norm": 1.1838524341583252,
      "learning_rate": 4.7878458190861056e-06,
      "loss": 0.5158,
      "step": 13414
    },
    {
      "epoch": 1.0425085483369598,
      "grad_norm": 0.09973890334367752,
      "learning_rate": 4.7874572583152005e-06,
      "loss": 0.041,
      "step": 13415
    },
    {
      "epoch": 1.042586260491141,
      "grad_norm": 0.5384469628334045,
      "learning_rate": 4.787068697544296e-06,
      "loss": 0.0955,
      "step": 13416
    },
    {
      "epoch": 1.0426639726453217,
      "grad_norm": 0.6710582971572876,
      "learning_rate": 4.786680136773392e-06,
      "loss": 0.2487,
      "step": 13417
    },
    {
      "epoch": 1.0427416847995026,
      "grad_norm": 1.8882395029067993,
      "learning_rate": 4.786291576002487e-06,
      "loss": 0.9787,
      "step": 13418
    },
    {
      "epoch": 1.0428193969536836,
      "grad_norm": 0.6324726939201355,
      "learning_rate": 4.785903015231583e-06,
      "loss": 0.1309,
      "step": 13419
    },
    {
      "epoch": 1.0428971091078645,
      "grad_norm": 0.1769513338804245,
      "learning_rate": 4.785514454460678e-06,
      "loss": 0.0869,
      "step": 13420
    },
    {
      "epoch": 1.0429748212620453,
      "grad_norm": 0.10428722947835922,
      "learning_rate": 4.785125893689774e-06,
      "loss": 0.0282,
      "step": 13421
    },
    {
      "epoch": 1.0430525334162264,
      "grad_norm": 0.5093812346458435,
      "learning_rate": 4.784737332918869e-06,
      "loss": 0.1282,
      "step": 13422
    },
    {
      "epoch": 1.0431302455704072,
      "grad_norm": 0.45290863513946533,
      "learning_rate": 4.784348772147964e-06,
      "loss": 0.176,
      "step": 13423
    },
    {
      "epoch": 1.043207957724588,
      "grad_norm": 0.5735242366790771,
      "learning_rate": 4.78396021137706e-06,
      "loss": 0.1657,
      "step": 13424
    },
    {
      "epoch": 1.0432856698787691,
      "grad_norm": 0.37498798966407776,
      "learning_rate": 4.783571650606155e-06,
      "loss": 0.2742,
      "step": 13425
    },
    {
      "epoch": 1.04336338203295,
      "grad_norm": 0.42484942078590393,
      "learning_rate": 4.783183089835251e-06,
      "loss": 0.0738,
      "step": 13426
    },
    {
      "epoch": 1.0434410941871308,
      "grad_norm": 0.3512208163738251,
      "learning_rate": 4.782794529064347e-06,
      "loss": 0.1984,
      "step": 13427
    },
    {
      "epoch": 1.0435188063413119,
      "grad_norm": 0.2001555860042572,
      "learning_rate": 4.782405968293442e-06,
      "loss": 0.08,
      "step": 13428
    },
    {
      "epoch": 1.0435965184954927,
      "grad_norm": 0.5705633163452148,
      "learning_rate": 4.782017407522537e-06,
      "loss": 0.1912,
      "step": 13429
    },
    {
      "epoch": 1.0436742306496736,
      "grad_norm": 0.3012669086456299,
      "learning_rate": 4.781628846751632e-06,
      "loss": 0.1558,
      "step": 13430
    },
    {
      "epoch": 1.0437519428038544,
      "grad_norm": 0.15396428108215332,
      "learning_rate": 4.781240285980727e-06,
      "loss": 0.0348,
      "step": 13431
    },
    {
      "epoch": 1.0438296549580355,
      "grad_norm": 0.17092426121234894,
      "learning_rate": 4.780851725209823e-06,
      "loss": 0.0573,
      "step": 13432
    },
    {
      "epoch": 1.0439073671122163,
      "grad_norm": 1.0735293626785278,
      "learning_rate": 4.780463164438919e-06,
      "loss": 0.1967,
      "step": 13433
    },
    {
      "epoch": 1.0439850792663972,
      "grad_norm": 0.3314247131347656,
      "learning_rate": 4.780074603668014e-06,
      "loss": 0.1955,
      "step": 13434
    },
    {
      "epoch": 1.0440627914205782,
      "grad_norm": 0.5827655792236328,
      "learning_rate": 4.779686042897109e-06,
      "loss": 0.2035,
      "step": 13435
    },
    {
      "epoch": 1.044140503574759,
      "grad_norm": 0.2252582460641861,
      "learning_rate": 4.779297482126205e-06,
      "loss": 0.0872,
      "step": 13436
    },
    {
      "epoch": 1.04421821572894,
      "grad_norm": 0.45634740591049194,
      "learning_rate": 4.7789089213553e-06,
      "loss": 0.1057,
      "step": 13437
    },
    {
      "epoch": 1.044295927883121,
      "grad_norm": 0.38369259238243103,
      "learning_rate": 4.778520360584396e-06,
      "loss": 0.2115,
      "step": 13438
    },
    {
      "epoch": 1.0443736400373018,
      "grad_norm": 0.4354105293750763,
      "learning_rate": 4.778131799813491e-06,
      "loss": 0.3539,
      "step": 13439
    },
    {
      "epoch": 1.0444513521914827,
      "grad_norm": 0.5383486747741699,
      "learning_rate": 4.777743239042586e-06,
      "loss": 0.2208,
      "step": 13440
    },
    {
      "epoch": 1.0445290643456637,
      "grad_norm": 0.29134732484817505,
      "learning_rate": 4.777354678271682e-06,
      "loss": 0.0975,
      "step": 13441
    },
    {
      "epoch": 1.0446067764998446,
      "grad_norm": 0.8961407542228699,
      "learning_rate": 4.776966117500778e-06,
      "loss": 0.5487,
      "step": 13442
    },
    {
      "epoch": 1.0446844886540254,
      "grad_norm": 0.6337489485740662,
      "learning_rate": 4.776577556729873e-06,
      "loss": 0.378,
      "step": 13443
    },
    {
      "epoch": 1.0447622008082065,
      "grad_norm": 0.3950013816356659,
      "learning_rate": 4.7761889959589685e-06,
      "loss": 0.2155,
      "step": 13444
    },
    {
      "epoch": 1.0448399129623873,
      "grad_norm": 0.5546140074729919,
      "learning_rate": 4.775800435188063e-06,
      "loss": 0.4166,
      "step": 13445
    },
    {
      "epoch": 1.0449176251165682,
      "grad_norm": 0.29608821868896484,
      "learning_rate": 4.775411874417159e-06,
      "loss": 0.2139,
      "step": 13446
    },
    {
      "epoch": 1.0449953372707492,
      "grad_norm": 0.45626863837242126,
      "learning_rate": 4.775023313646255e-06,
      "loss": 0.344,
      "step": 13447
    },
    {
      "epoch": 1.04507304942493,
      "grad_norm": 0.8154403567314148,
      "learning_rate": 4.77463475287535e-06,
      "loss": 0.4081,
      "step": 13448
    },
    {
      "epoch": 1.045150761579111,
      "grad_norm": 0.36574089527130127,
      "learning_rate": 4.774246192104445e-06,
      "loss": 0.2791,
      "step": 13449
    },
    {
      "epoch": 1.045228473733292,
      "grad_norm": 0.5821126699447632,
      "learning_rate": 4.773857631333541e-06,
      "loss": 0.4324,
      "step": 13450
    },
    {
      "epoch": 1.0453061858874728,
      "grad_norm": 1.1654069423675537,
      "learning_rate": 4.7734690705626365e-06,
      "loss": 0.227,
      "step": 13451
    },
    {
      "epoch": 1.0453838980416537,
      "grad_norm": 0.24661557376384735,
      "learning_rate": 4.7730805097917314e-06,
      "loss": 0.0611,
      "step": 13452
    },
    {
      "epoch": 1.0454616101958347,
      "grad_norm": 0.175045907497406,
      "learning_rate": 4.772691949020827e-06,
      "loss": 0.0951,
      "step": 13453
    },
    {
      "epoch": 1.0455393223500156,
      "grad_norm": 0.0717146098613739,
      "learning_rate": 4.772303388249922e-06,
      "loss": 0.0185,
      "step": 13454
    },
    {
      "epoch": 1.0456170345041964,
      "grad_norm": 0.09826540946960449,
      "learning_rate": 4.771914827479018e-06,
      "loss": 0.0137,
      "step": 13455
    },
    {
      "epoch": 1.0456947466583775,
      "grad_norm": 0.6145099997520447,
      "learning_rate": 4.771526266708114e-06,
      "loss": 0.1649,
      "step": 13456
    },
    {
      "epoch": 1.0457724588125583,
      "grad_norm": 0.4069773256778717,
      "learning_rate": 4.771137705937209e-06,
      "loss": 0.1967,
      "step": 13457
    },
    {
      "epoch": 1.0458501709667392,
      "grad_norm": 0.2392258197069168,
      "learning_rate": 4.7707491451663045e-06,
      "loss": 0.0797,
      "step": 13458
    },
    {
      "epoch": 1.0459278831209202,
      "grad_norm": 0.47850552201271057,
      "learning_rate": 4.7703605843953995e-06,
      "loss": 0.54,
      "step": 13459
    },
    {
      "epoch": 1.046005595275101,
      "grad_norm": 0.2547898590564728,
      "learning_rate": 4.769972023624495e-06,
      "loss": 0.0237,
      "step": 13460
    },
    {
      "epoch": 1.046083307429282,
      "grad_norm": 0.25017601251602173,
      "learning_rate": 4.769583462853591e-06,
      "loss": 0.1017,
      "step": 13461
    },
    {
      "epoch": 1.0461610195834627,
      "grad_norm": 0.5878403186798096,
      "learning_rate": 4.769194902082686e-06,
      "loss": 0.2611,
      "step": 13462
    },
    {
      "epoch": 1.0462387317376438,
      "grad_norm": 0.5297698974609375,
      "learning_rate": 4.768806341311781e-06,
      "loss": 0.0939,
      "step": 13463
    },
    {
      "epoch": 1.0463164438918247,
      "grad_norm": 0.41765376925468445,
      "learning_rate": 4.768417780540877e-06,
      "loss": 0.1791,
      "step": 13464
    },
    {
      "epoch": 1.0463941560460055,
      "grad_norm": 0.3155389428138733,
      "learning_rate": 4.7680292197699726e-06,
      "loss": 0.1281,
      "step": 13465
    },
    {
      "epoch": 1.0464718682001866,
      "grad_norm": 0.13885407149791718,
      "learning_rate": 4.7676406589990675e-06,
      "loss": 0.0195,
      "step": 13466
    },
    {
      "epoch": 1.0465495803543674,
      "grad_norm": 1.2068794965744019,
      "learning_rate": 4.767252098228163e-06,
      "loss": 0.5043,
      "step": 13467
    },
    {
      "epoch": 1.0466272925085482,
      "grad_norm": 0.5221962928771973,
      "learning_rate": 4.766863537457258e-06,
      "loss": 0.3849,
      "step": 13468
    },
    {
      "epoch": 1.0467050046627293,
      "grad_norm": 0.27570849657058716,
      "learning_rate": 4.766474976686354e-06,
      "loss": 0.0825,
      "step": 13469
    },
    {
      "epoch": 1.0467827168169102,
      "grad_norm": 0.4458639621734619,
      "learning_rate": 4.76608641591545e-06,
      "loss": 0.0956,
      "step": 13470
    },
    {
      "epoch": 1.046860428971091,
      "grad_norm": 0.4205286502838135,
      "learning_rate": 4.765697855144545e-06,
      "loss": 0.106,
      "step": 13471
    },
    {
      "epoch": 1.046938141125272,
      "grad_norm": 0.566632866859436,
      "learning_rate": 4.765309294373641e-06,
      "loss": 0.1459,
      "step": 13472
    },
    {
      "epoch": 1.047015853279453,
      "grad_norm": 0.2487279325723648,
      "learning_rate": 4.7649207336027356e-06,
      "loss": 0.0756,
      "step": 13473
    },
    {
      "epoch": 1.0470935654336337,
      "grad_norm": 0.22647416591644287,
      "learning_rate": 4.764532172831831e-06,
      "loss": 0.0573,
      "step": 13474
    },
    {
      "epoch": 1.0471712775878148,
      "grad_norm": 0.25436511635780334,
      "learning_rate": 4.764143612060927e-06,
      "loss": 0.1082,
      "step": 13475
    },
    {
      "epoch": 1.0472489897419957,
      "grad_norm": 0.07874438911676407,
      "learning_rate": 4.763755051290022e-06,
      "loss": 0.0268,
      "step": 13476
    },
    {
      "epoch": 1.0473267018961765,
      "grad_norm": 0.46224653720855713,
      "learning_rate": 4.763366490519117e-06,
      "loss": 0.13,
      "step": 13477
    },
    {
      "epoch": 1.0474044140503576,
      "grad_norm": 0.36145973205566406,
      "learning_rate": 4.762977929748213e-06,
      "loss": 0.1186,
      "step": 13478
    },
    {
      "epoch": 1.0474821262045384,
      "grad_norm": 0.6449660062789917,
      "learning_rate": 4.762589368977309e-06,
      "loss": 0.3335,
      "step": 13479
    },
    {
      "epoch": 1.0475598383587192,
      "grad_norm": 0.6803930997848511,
      "learning_rate": 4.762200808206404e-06,
      "loss": 0.5985,
      "step": 13480
    },
    {
      "epoch": 1.0476375505129003,
      "grad_norm": 0.16626252233982086,
      "learning_rate": 4.761812247435499e-06,
      "loss": 0.1067,
      "step": 13481
    },
    {
      "epoch": 1.0477152626670811,
      "grad_norm": 0.13832728564739227,
      "learning_rate": 4.761423686664594e-06,
      "loss": 0.0599,
      "step": 13482
    },
    {
      "epoch": 1.047792974821262,
      "grad_norm": 0.8168192505836487,
      "learning_rate": 4.76103512589369e-06,
      "loss": 1.0835,
      "step": 13483
    },
    {
      "epoch": 1.047870686975443,
      "grad_norm": 0.058425236493349075,
      "learning_rate": 4.760646565122786e-06,
      "loss": 0.022,
      "step": 13484
    },
    {
      "epoch": 1.047948399129624,
      "grad_norm": 0.6301819682121277,
      "learning_rate": 4.760258004351881e-06,
      "loss": 0.3746,
      "step": 13485
    },
    {
      "epoch": 1.0480261112838047,
      "grad_norm": 0.35481885075569153,
      "learning_rate": 4.759869443580977e-06,
      "loss": 0.1124,
      "step": 13486
    },
    {
      "epoch": 1.0481038234379858,
      "grad_norm": 0.1909639984369278,
      "learning_rate": 4.759480882810072e-06,
      "loss": 0.0713,
      "step": 13487
    },
    {
      "epoch": 1.0481815355921666,
      "grad_norm": 0.40139147639274597,
      "learning_rate": 4.7590923220391674e-06,
      "loss": 0.1517,
      "step": 13488
    },
    {
      "epoch": 1.0482592477463475,
      "grad_norm": 0.16063056886196136,
      "learning_rate": 4.758703761268263e-06,
      "loss": 0.0329,
      "step": 13489
    },
    {
      "epoch": 1.0483369599005283,
      "grad_norm": 0.43112272024154663,
      "learning_rate": 4.758315200497358e-06,
      "loss": 0.1838,
      "step": 13490
    },
    {
      "epoch": 1.0484146720547094,
      "grad_norm": 0.7242363095283508,
      "learning_rate": 4.757926639726453e-06,
      "loss": 0.2089,
      "step": 13491
    },
    {
      "epoch": 1.0484923842088902,
      "grad_norm": 0.4371766448020935,
      "learning_rate": 4.757538078955549e-06,
      "loss": 0.1994,
      "step": 13492
    },
    {
      "epoch": 1.048570096363071,
      "grad_norm": 0.5695533752441406,
      "learning_rate": 4.757149518184645e-06,
      "loss": 0.1591,
      "step": 13493
    },
    {
      "epoch": 1.0486478085172521,
      "grad_norm": 0.2749798595905304,
      "learning_rate": 4.75676095741374e-06,
      "loss": 0.1779,
      "step": 13494
    },
    {
      "epoch": 1.048725520671433,
      "grad_norm": 0.6760629415512085,
      "learning_rate": 4.7563723966428355e-06,
      "loss": 0.131,
      "step": 13495
    },
    {
      "epoch": 1.0488032328256138,
      "grad_norm": 0.1801709085702896,
      "learning_rate": 4.75598383587193e-06,
      "loss": 0.1321,
      "step": 13496
    },
    {
      "epoch": 1.048880944979795,
      "grad_norm": 0.4789857566356659,
      "learning_rate": 4.755595275101026e-06,
      "loss": 0.191,
      "step": 13497
    },
    {
      "epoch": 1.0489586571339757,
      "grad_norm": 0.19226956367492676,
      "learning_rate": 4.755206714330122e-06,
      "loss": 0.0555,
      "step": 13498
    },
    {
      "epoch": 1.0490363692881566,
      "grad_norm": 0.2724257707595825,
      "learning_rate": 4.754818153559217e-06,
      "loss": 0.0495,
      "step": 13499
    },
    {
      "epoch": 1.0491140814423376,
      "grad_norm": 0.14264805614948273,
      "learning_rate": 4.754429592788313e-06,
      "loss": 0.0279,
      "step": 13500
    },
    {
      "epoch": 1.0491917935965185,
      "grad_norm": 0.3742164671421051,
      "learning_rate": 4.754041032017408e-06,
      "loss": 0.1021,
      "step": 13501
    },
    {
      "epoch": 1.0492695057506993,
      "grad_norm": 0.6211943626403809,
      "learning_rate": 4.7536524712465035e-06,
      "loss": 0.3307,
      "step": 13502
    },
    {
      "epoch": 1.0493472179048804,
      "grad_norm": 0.2984073758125305,
      "learning_rate": 4.753263910475599e-06,
      "loss": 0.1496,
      "step": 13503
    },
    {
      "epoch": 1.0494249300590612,
      "grad_norm": 0.32842016220092773,
      "learning_rate": 4.752875349704694e-06,
      "loss": 0.1999,
      "step": 13504
    },
    {
      "epoch": 1.049502642213242,
      "grad_norm": 0.21927841007709503,
      "learning_rate": 4.752486788933789e-06,
      "loss": 0.0363,
      "step": 13505
    },
    {
      "epoch": 1.0495803543674231,
      "grad_norm": 0.3120651841163635,
      "learning_rate": 4.752098228162885e-06,
      "loss": 0.0656,
      "step": 13506
    },
    {
      "epoch": 1.049658066521604,
      "grad_norm": 0.21101251244544983,
      "learning_rate": 4.751709667391981e-06,
      "loss": 0.1194,
      "step": 13507
    },
    {
      "epoch": 1.0497357786757848,
      "grad_norm": 1.0872167348861694,
      "learning_rate": 4.751321106621076e-06,
      "loss": 0.4677,
      "step": 13508
    },
    {
      "epoch": 1.049813490829966,
      "grad_norm": 0.6248480677604675,
      "learning_rate": 4.7509325458501715e-06,
      "loss": 0.4004,
      "step": 13509
    },
    {
      "epoch": 1.0498912029841467,
      "grad_norm": 0.21711976826190948,
      "learning_rate": 4.7505439850792665e-06,
      "loss": 0.127,
      "step": 13510
    },
    {
      "epoch": 1.0499689151383276,
      "grad_norm": 0.3279273509979248,
      "learning_rate": 4.750155424308362e-06,
      "loss": 0.1188,
      "step": 13511
    },
    {
      "epoch": 1.0500466272925086,
      "grad_norm": 0.9064838290214539,
      "learning_rate": 4.749766863537458e-06,
      "loss": 0.3514,
      "step": 13512
    },
    {
      "epoch": 1.0501243394466895,
      "grad_norm": 0.2505963146686554,
      "learning_rate": 4.749378302766553e-06,
      "loss": 0.1029,
      "step": 13513
    },
    {
      "epoch": 1.0502020516008703,
      "grad_norm": 0.30581286549568176,
      "learning_rate": 4.748989741995649e-06,
      "loss": 0.0319,
      "step": 13514
    },
    {
      "epoch": 1.0502797637550514,
      "grad_norm": 0.35922732949256897,
      "learning_rate": 4.748601181224744e-06,
      "loss": 0.0814,
      "step": 13515
    },
    {
      "epoch": 1.0503574759092322,
      "grad_norm": 0.134795144200325,
      "learning_rate": 4.7482126204538396e-06,
      "loss": 0.0338,
      "step": 13516
    },
    {
      "epoch": 1.050435188063413,
      "grad_norm": 0.103620246052742,
      "learning_rate": 4.747824059682935e-06,
      "loss": 0.0101,
      "step": 13517
    },
    {
      "epoch": 1.0505129002175941,
      "grad_norm": 0.3951026201248169,
      "learning_rate": 4.74743549891203e-06,
      "loss": 0.2231,
      "step": 13518
    },
    {
      "epoch": 1.050590612371775,
      "grad_norm": 0.5098122358322144,
      "learning_rate": 4.747046938141125e-06,
      "loss": 0.2115,
      "step": 13519
    },
    {
      "epoch": 1.0506683245259558,
      "grad_norm": 0.306327760219574,
      "learning_rate": 4.746658377370221e-06,
      "loss": 0.1256,
      "step": 13520
    },
    {
      "epoch": 1.0507460366801369,
      "grad_norm": 0.6569129228591919,
      "learning_rate": 4.746269816599317e-06,
      "loss": 0.3042,
      "step": 13521
    },
    {
      "epoch": 1.0508237488343177,
      "grad_norm": 0.405493825674057,
      "learning_rate": 4.745881255828412e-06,
      "loss": 0.1615,
      "step": 13522
    },
    {
      "epoch": 1.0509014609884986,
      "grad_norm": 0.37596312165260315,
      "learning_rate": 4.745492695057508e-06,
      "loss": 0.0952,
      "step": 13523
    },
    {
      "epoch": 1.0509791731426794,
      "grad_norm": 0.2611338496208191,
      "learning_rate": 4.7451041342866026e-06,
      "loss": 0.0478,
      "step": 13524
    },
    {
      "epoch": 1.0510568852968605,
      "grad_norm": 0.7872489094734192,
      "learning_rate": 4.744715573515698e-06,
      "loss": 0.4312,
      "step": 13525
    },
    {
      "epoch": 1.0511345974510413,
      "grad_norm": 0.6274316310882568,
      "learning_rate": 4.744327012744794e-06,
      "loss": 0.371,
      "step": 13526
    },
    {
      "epoch": 1.0512123096052222,
      "grad_norm": 0.5254336595535278,
      "learning_rate": 4.743938451973889e-06,
      "loss": 0.1931,
      "step": 13527
    },
    {
      "epoch": 1.0512900217594032,
      "grad_norm": 0.7495618462562561,
      "learning_rate": 4.743549891202984e-06,
      "loss": 0.1604,
      "step": 13528
    },
    {
      "epoch": 1.051367733913584,
      "grad_norm": 0.43657031655311584,
      "learning_rate": 4.74316133043208e-06,
      "loss": 0.3665,
      "step": 13529
    },
    {
      "epoch": 1.051445446067765,
      "grad_norm": 0.20858566462993622,
      "learning_rate": 4.742772769661176e-06,
      "loss": 0.1151,
      "step": 13530
    },
    {
      "epoch": 1.051523158221946,
      "grad_norm": 0.6859224438667297,
      "learning_rate": 4.7423842088902714e-06,
      "loss": 0.219,
      "step": 13531
    },
    {
      "epoch": 1.0516008703761268,
      "grad_norm": 0.35622188448905945,
      "learning_rate": 4.741995648119366e-06,
      "loss": 0.136,
      "step": 13532
    },
    {
      "epoch": 1.0516785825303077,
      "grad_norm": 0.8118999004364014,
      "learning_rate": 4.741607087348461e-06,
      "loss": 0.1116,
      "step": 13533
    },
    {
      "epoch": 1.0517562946844887,
      "grad_norm": 0.1478726863861084,
      "learning_rate": 4.741218526577557e-06,
      "loss": 0.1099,
      "step": 13534
    },
    {
      "epoch": 1.0518340068386696,
      "grad_norm": 0.5085933804512024,
      "learning_rate": 4.740829965806653e-06,
      "loss": 0.2634,
      "step": 13535
    },
    {
      "epoch": 1.0519117189928504,
      "grad_norm": 0.4705602526664734,
      "learning_rate": 4.740441405035748e-06,
      "loss": 0.1608,
      "step": 13536
    },
    {
      "epoch": 1.0519894311470315,
      "grad_norm": 0.26463639736175537,
      "learning_rate": 4.740052844264844e-06,
      "loss": 0.0411,
      "step": 13537
    },
    {
      "epoch": 1.0520671433012123,
      "grad_norm": 0.577506959438324,
      "learning_rate": 4.739664283493939e-06,
      "loss": 0.2776,
      "step": 13538
    },
    {
      "epoch": 1.0521448554553932,
      "grad_norm": 0.12447039783000946,
      "learning_rate": 4.7392757227230344e-06,
      "loss": 0.0386,
      "step": 13539
    },
    {
      "epoch": 1.0522225676095742,
      "grad_norm": 0.46167606115341187,
      "learning_rate": 4.73888716195213e-06,
      "loss": 0.2947,
      "step": 13540
    },
    {
      "epoch": 1.052300279763755,
      "grad_norm": 0.19632303714752197,
      "learning_rate": 4.738498601181225e-06,
      "loss": 0.0888,
      "step": 13541
    },
    {
      "epoch": 1.052377991917936,
      "grad_norm": 0.3056643009185791,
      "learning_rate": 4.73811004041032e-06,
      "loss": 0.1425,
      "step": 13542
    },
    {
      "epoch": 1.052455704072117,
      "grad_norm": 0.7031358480453491,
      "learning_rate": 4.737721479639416e-06,
      "loss": 0.4301,
      "step": 13543
    },
    {
      "epoch": 1.0525334162262978,
      "grad_norm": 0.4965486228466034,
      "learning_rate": 4.737332918868512e-06,
      "loss": 0.051,
      "step": 13544
    },
    {
      "epoch": 1.0526111283804787,
      "grad_norm": 0.6318908929824829,
      "learning_rate": 4.7369443580976075e-06,
      "loss": 0.3055,
      "step": 13545
    },
    {
      "epoch": 1.0526888405346597,
      "grad_norm": 0.14333932101726532,
      "learning_rate": 4.7365557973267025e-06,
      "loss": 0.0218,
      "step": 13546
    },
    {
      "epoch": 1.0527665526888406,
      "grad_norm": 0.5263102650642395,
      "learning_rate": 4.736167236555797e-06,
      "loss": 0.0693,
      "step": 13547
    },
    {
      "epoch": 1.0528442648430214,
      "grad_norm": 0.6330055594444275,
      "learning_rate": 4.735778675784893e-06,
      "loss": 0.3717,
      "step": 13548
    },
    {
      "epoch": 1.0529219769972025,
      "grad_norm": 0.08152689784765244,
      "learning_rate": 4.735390115013989e-06,
      "loss": 0.0083,
      "step": 13549
    },
    {
      "epoch": 1.0529996891513833,
      "grad_norm": 0.14478257298469543,
      "learning_rate": 4.735001554243084e-06,
      "loss": 0.0472,
      "step": 13550
    },
    {
      "epoch": 1.0530774013055642,
      "grad_norm": 0.8542125821113586,
      "learning_rate": 4.73461299347218e-06,
      "loss": 0.332,
      "step": 13551
    },
    {
      "epoch": 1.053155113459745,
      "grad_norm": 1.2204104661941528,
      "learning_rate": 4.734224432701275e-06,
      "loss": 0.496,
      "step": 13552
    },
    {
      "epoch": 1.053232825613926,
      "grad_norm": 0.855895459651947,
      "learning_rate": 4.7338358719303705e-06,
      "loss": 0.2718,
      "step": 13553
    },
    {
      "epoch": 1.053310537768107,
      "grad_norm": 0.6457824110984802,
      "learning_rate": 4.733447311159466e-06,
      "loss": 0.4166,
      "step": 13554
    },
    {
      "epoch": 1.0533882499222877,
      "grad_norm": 0.36107003688812256,
      "learning_rate": 4.733058750388561e-06,
      "loss": 0.2773,
      "step": 13555
    },
    {
      "epoch": 1.0534659620764688,
      "grad_norm": 0.12473515421152115,
      "learning_rate": 4.732670189617656e-06,
      "loss": 0.0187,
      "step": 13556
    },
    {
      "epoch": 1.0535436742306497,
      "grad_norm": 0.4854966700077057,
      "learning_rate": 4.732281628846752e-06,
      "loss": 0.3877,
      "step": 13557
    },
    {
      "epoch": 1.0536213863848305,
      "grad_norm": 0.3465159833431244,
      "learning_rate": 4.731893068075847e-06,
      "loss": 0.0425,
      "step": 13558
    },
    {
      "epoch": 1.0536990985390116,
      "grad_norm": 0.3639742136001587,
      "learning_rate": 4.731504507304943e-06,
      "loss": 0.1918,
      "step": 13559
    },
    {
      "epoch": 1.0537768106931924,
      "grad_norm": 0.34480470418930054,
      "learning_rate": 4.7311159465340385e-06,
      "loss": 0.12,
      "step": 13560
    },
    {
      "epoch": 1.0538545228473732,
      "grad_norm": 1.2144620418548584,
      "learning_rate": 4.7307273857631335e-06,
      "loss": 0.278,
      "step": 13561
    },
    {
      "epoch": 1.0539322350015543,
      "grad_norm": 0.5640430450439453,
      "learning_rate": 4.730338824992229e-06,
      "loss": 0.1656,
      "step": 13562
    },
    {
      "epoch": 1.0540099471557351,
      "grad_norm": 0.4218918979167938,
      "learning_rate": 4.729950264221324e-06,
      "loss": 0.1156,
      "step": 13563
    },
    {
      "epoch": 1.054087659309916,
      "grad_norm": 0.32720503211021423,
      "learning_rate": 4.72956170345042e-06,
      "loss": 0.0919,
      "step": 13564
    },
    {
      "epoch": 1.054165371464097,
      "grad_norm": 0.7228509187698364,
      "learning_rate": 4.729173142679516e-06,
      "loss": 0.2096,
      "step": 13565
    },
    {
      "epoch": 1.054243083618278,
      "grad_norm": 0.21347887814044952,
      "learning_rate": 4.728784581908611e-06,
      "loss": 0.0975,
      "step": 13566
    },
    {
      "epoch": 1.0543207957724587,
      "grad_norm": 0.4634764492511749,
      "learning_rate": 4.728396021137706e-06,
      "loss": 0.0411,
      "step": 13567
    },
    {
      "epoch": 1.0543985079266398,
      "grad_norm": 0.4122990369796753,
      "learning_rate": 4.7280074603668015e-06,
      "loss": 0.1017,
      "step": 13568
    },
    {
      "epoch": 1.0544762200808206,
      "grad_norm": 0.3594094216823578,
      "learning_rate": 4.727618899595897e-06,
      "loss": 0.1112,
      "step": 13569
    },
    {
      "epoch": 1.0545539322350015,
      "grad_norm": 0.9569615721702576,
      "learning_rate": 4.727230338824992e-06,
      "loss": 0.4356,
      "step": 13570
    },
    {
      "epoch": 1.0546316443891826,
      "grad_norm": 0.5237470865249634,
      "learning_rate": 4.726841778054088e-06,
      "loss": 0.2317,
      "step": 13571
    },
    {
      "epoch": 1.0547093565433634,
      "grad_norm": 0.4987545609474182,
      "learning_rate": 4.726453217283183e-06,
      "loss": 0.1505,
      "step": 13572
    },
    {
      "epoch": 1.0547870686975442,
      "grad_norm": 0.0756916031241417,
      "learning_rate": 4.726064656512279e-06,
      "loss": 0.0219,
      "step": 13573
    },
    {
      "epoch": 1.0548647808517253,
      "grad_norm": 0.510903537273407,
      "learning_rate": 4.725676095741375e-06,
      "loss": 0.1266,
      "step": 13574
    },
    {
      "epoch": 1.0549424930059061,
      "grad_norm": 0.5631519556045532,
      "learning_rate": 4.7252875349704696e-06,
      "loss": 0.1863,
      "step": 13575
    },
    {
      "epoch": 1.055020205160087,
      "grad_norm": 0.2319377213716507,
      "learning_rate": 4.724898974199565e-06,
      "loss": 0.1849,
      "step": 13576
    },
    {
      "epoch": 1.055097917314268,
      "grad_norm": 0.5222575664520264,
      "learning_rate": 4.72451041342866e-06,
      "loss": 0.8195,
      "step": 13577
    },
    {
      "epoch": 1.055175629468449,
      "grad_norm": 0.25772517919540405,
      "learning_rate": 4.724121852657756e-06,
      "loss": 0.1635,
      "step": 13578
    },
    {
      "epoch": 1.0552533416226297,
      "grad_norm": 0.7789031863212585,
      "learning_rate": 4.723733291886852e-06,
      "loss": 0.2095,
      "step": 13579
    },
    {
      "epoch": 1.0553310537768108,
      "grad_norm": 1.299991488456726,
      "learning_rate": 4.723344731115947e-06,
      "loss": 0.1449,
      "step": 13580
    },
    {
      "epoch": 1.0554087659309916,
      "grad_norm": 0.5425999164581299,
      "learning_rate": 4.722956170345042e-06,
      "loss": 0.0462,
      "step": 13581
    },
    {
      "epoch": 1.0554864780851725,
      "grad_norm": 0.11251813918352127,
      "learning_rate": 4.722567609574138e-06,
      "loss": 0.0578,
      "step": 13582
    },
    {
      "epoch": 1.0555641902393533,
      "grad_norm": 0.22543063759803772,
      "learning_rate": 4.722179048803233e-06,
      "loss": 0.1034,
      "step": 13583
    },
    {
      "epoch": 1.0556419023935344,
      "grad_norm": 0.6609748005867004,
      "learning_rate": 4.721790488032328e-06,
      "loss": 0.9219,
      "step": 13584
    },
    {
      "epoch": 1.0557196145477152,
      "grad_norm": 0.8621063828468323,
      "learning_rate": 4.721401927261424e-06,
      "loss": 0.6574,
      "step": 13585
    },
    {
      "epoch": 1.055797326701896,
      "grad_norm": 1.8951189517974854,
      "learning_rate": 4.721013366490519e-06,
      "loss": 0.3827,
      "step": 13586
    },
    {
      "epoch": 1.0558750388560771,
      "grad_norm": 0.6196430921554565,
      "learning_rate": 4.720624805719615e-06,
      "loss": 0.4162,
      "step": 13587
    },
    {
      "epoch": 1.055952751010258,
      "grad_norm": 0.5588472485542297,
      "learning_rate": 4.720236244948711e-06,
      "loss": 0.1701,
      "step": 13588
    },
    {
      "epoch": 1.0560304631644388,
      "grad_norm": 0.16983415186405182,
      "learning_rate": 4.719847684177806e-06,
      "loss": 0.0291,
      "step": 13589
    },
    {
      "epoch": 1.05610817531862,
      "grad_norm": 0.48719385266304016,
      "learning_rate": 4.7194591234069014e-06,
      "loss": 0.1576,
      "step": 13590
    },
    {
      "epoch": 1.0561858874728007,
      "grad_norm": 0.2048390805721283,
      "learning_rate": 4.719070562635996e-06,
      "loss": 0.0195,
      "step": 13591
    },
    {
      "epoch": 1.0562635996269816,
      "grad_norm": 0.1995997130870819,
      "learning_rate": 4.718682001865092e-06,
      "loss": 0.0622,
      "step": 13592
    },
    {
      "epoch": 1.0563413117811626,
      "grad_norm": 0.41549989581108093,
      "learning_rate": 4.718293441094188e-06,
      "loss": 0.3455,
      "step": 13593
    },
    {
      "epoch": 1.0564190239353435,
      "grad_norm": 0.3870791792869568,
      "learning_rate": 4.717904880323283e-06,
      "loss": 0.2496,
      "step": 13594
    },
    {
      "epoch": 1.0564967360895243,
      "grad_norm": 0.4208182096481323,
      "learning_rate": 4.717516319552378e-06,
      "loss": 0.1071,
      "step": 13595
    },
    {
      "epoch": 1.0565744482437054,
      "grad_norm": 0.4095602035522461,
      "learning_rate": 4.717127758781474e-06,
      "loss": 0.2111,
      "step": 13596
    },
    {
      "epoch": 1.0566521603978862,
      "grad_norm": 0.2640771269798279,
      "learning_rate": 4.7167391980105695e-06,
      "loss": 0.0212,
      "step": 13597
    },
    {
      "epoch": 1.056729872552067,
      "grad_norm": 0.219787135720253,
      "learning_rate": 4.716350637239664e-06,
      "loss": 0.1064,
      "step": 13598
    },
    {
      "epoch": 1.0568075847062481,
      "grad_norm": 0.2625977396965027,
      "learning_rate": 4.71596207646876e-06,
      "loss": 0.0847,
      "step": 13599
    },
    {
      "epoch": 1.056885296860429,
      "grad_norm": 0.6229594349861145,
      "learning_rate": 4.715573515697855e-06,
      "loss": 0.2312,
      "step": 13600
    },
    {
      "epoch": 1.0569630090146098,
      "grad_norm": 0.5169556140899658,
      "learning_rate": 4.715184954926951e-06,
      "loss": 0.3279,
      "step": 13601
    },
    {
      "epoch": 1.0570407211687909,
      "grad_norm": 0.3626214265823364,
      "learning_rate": 4.714796394156047e-06,
      "loss": 0.1065,
      "step": 13602
    },
    {
      "epoch": 1.0571184333229717,
      "grad_norm": 0.8633511066436768,
      "learning_rate": 4.714407833385142e-06,
      "loss": 0.894,
      "step": 13603
    },
    {
      "epoch": 1.0571961454771526,
      "grad_norm": 0.6960393786430359,
      "learning_rate": 4.7140192726142375e-06,
      "loss": 0.33,
      "step": 13604
    },
    {
      "epoch": 1.0572738576313336,
      "grad_norm": 0.44218432903289795,
      "learning_rate": 4.7136307118433325e-06,
      "loss": 0.4227,
      "step": 13605
    },
    {
      "epoch": 1.0573515697855145,
      "grad_norm": 0.31643083691596985,
      "learning_rate": 4.713242151072428e-06,
      "loss": 0.1303,
      "step": 13606
    },
    {
      "epoch": 1.0574292819396953,
      "grad_norm": 0.7953797578811646,
      "learning_rate": 4.712853590301524e-06,
      "loss": 0.6962,
      "step": 13607
    },
    {
      "epoch": 1.0575069940938764,
      "grad_norm": 1.2299765348434448,
      "learning_rate": 4.712465029530619e-06,
      "loss": 0.6279,
      "step": 13608
    },
    {
      "epoch": 1.0575847062480572,
      "grad_norm": 0.300657719373703,
      "learning_rate": 4.712076468759714e-06,
      "loss": 0.1104,
      "step": 13609
    },
    {
      "epoch": 1.057662418402238,
      "grad_norm": 0.35568782687187195,
      "learning_rate": 4.71168790798881e-06,
      "loss": 0.1321,
      "step": 13610
    },
    {
      "epoch": 1.057740130556419,
      "grad_norm": 0.45686525106430054,
      "learning_rate": 4.7112993472179055e-06,
      "loss": 0.1641,
      "step": 13611
    },
    {
      "epoch": 1.0578178427106,
      "grad_norm": 0.2286228984594345,
      "learning_rate": 4.7109107864470005e-06,
      "loss": 0.0458,
      "step": 13612
    },
    {
      "epoch": 1.0578955548647808,
      "grad_norm": 0.3529563844203949,
      "learning_rate": 4.710522225676096e-06,
      "loss": 0.2074,
      "step": 13613
    },
    {
      "epoch": 1.0579732670189617,
      "grad_norm": 0.16586720943450928,
      "learning_rate": 4.710133664905191e-06,
      "loss": 0.0563,
      "step": 13614
    },
    {
      "epoch": 1.0580509791731427,
      "grad_norm": 0.33707091212272644,
      "learning_rate": 4.709745104134287e-06,
      "loss": 0.1624,
      "step": 13615
    },
    {
      "epoch": 1.0581286913273236,
      "grad_norm": 0.5400495529174805,
      "learning_rate": 4.709356543363383e-06,
      "loss": 0.2815,
      "step": 13616
    },
    {
      "epoch": 1.0582064034815044,
      "grad_norm": 0.7858678698539734,
      "learning_rate": 4.708967982592478e-06,
      "loss": 0.4299,
      "step": 13617
    },
    {
      "epoch": 1.0582841156356855,
      "grad_norm": 0.40949875116348267,
      "learning_rate": 4.708579421821573e-06,
      "loss": 0.3738,
      "step": 13618
    },
    {
      "epoch": 1.0583618277898663,
      "grad_norm": 0.4878045618534088,
      "learning_rate": 4.7081908610506685e-06,
      "loss": 0.0404,
      "step": 13619
    },
    {
      "epoch": 1.0584395399440472,
      "grad_norm": 0.30681419372558594,
      "learning_rate": 4.707802300279764e-06,
      "loss": 0.0761,
      "step": 13620
    },
    {
      "epoch": 1.0585172520982282,
      "grad_norm": 0.29354995489120483,
      "learning_rate": 4.70741373950886e-06,
      "loss": 0.1535,
      "step": 13621
    },
    {
      "epoch": 1.058594964252409,
      "grad_norm": 0.1827142834663391,
      "learning_rate": 4.707025178737955e-06,
      "loss": 0.0436,
      "step": 13622
    },
    {
      "epoch": 1.05867267640659,
      "grad_norm": 0.598678469657898,
      "learning_rate": 4.70663661796705e-06,
      "loss": 0.3058,
      "step": 13623
    },
    {
      "epoch": 1.058750388560771,
      "grad_norm": 0.09428343921899796,
      "learning_rate": 4.706248057196146e-06,
      "loss": 0.0279,
      "step": 13624
    },
    {
      "epoch": 1.0588281007149518,
      "grad_norm": 0.303361177444458,
      "learning_rate": 4.705859496425242e-06,
      "loss": 0.1441,
      "step": 13625
    },
    {
      "epoch": 1.0589058128691327,
      "grad_norm": 0.33161461353302,
      "learning_rate": 4.7054709356543366e-06,
      "loss": 0.1453,
      "step": 13626
    },
    {
      "epoch": 1.0589835250233137,
      "grad_norm": 0.7417061924934387,
      "learning_rate": 4.705082374883432e-06,
      "loss": 0.195,
      "step": 13627
    },
    {
      "epoch": 1.0590612371774946,
      "grad_norm": 0.4440404176712036,
      "learning_rate": 4.704693814112527e-06,
      "loss": 0.0662,
      "step": 13628
    },
    {
      "epoch": 1.0591389493316754,
      "grad_norm": 0.4473817050457001,
      "learning_rate": 4.704305253341623e-06,
      "loss": 0.1964,
      "step": 13629
    },
    {
      "epoch": 1.0592166614858565,
      "grad_norm": 0.36717489361763,
      "learning_rate": 4.703916692570719e-06,
      "loss": 0.1263,
      "step": 13630
    },
    {
      "epoch": 1.0592943736400373,
      "grad_norm": 0.36988744139671326,
      "learning_rate": 4.703528131799814e-06,
      "loss": 0.2216,
      "step": 13631
    },
    {
      "epoch": 1.0593720857942182,
      "grad_norm": 0.49757668375968933,
      "learning_rate": 4.703139571028909e-06,
      "loss": 0.2058,
      "step": 13632
    },
    {
      "epoch": 1.0594497979483992,
      "grad_norm": 0.6885166168212891,
      "learning_rate": 4.702751010258005e-06,
      "loss": 0.6708,
      "step": 13633
    },
    {
      "epoch": 1.05952751010258,
      "grad_norm": 0.5394508242607117,
      "learning_rate": 4.7023624494871e-06,
      "loss": 0.1959,
      "step": 13634
    },
    {
      "epoch": 1.059605222256761,
      "grad_norm": 1.0540962219238281,
      "learning_rate": 4.701973888716196e-06,
      "loss": 0.3004,
      "step": 13635
    },
    {
      "epoch": 1.059682934410942,
      "grad_norm": 0.44908303022384644,
      "learning_rate": 4.701585327945291e-06,
      "loss": 0.1278,
      "step": 13636
    },
    {
      "epoch": 1.0597606465651228,
      "grad_norm": 0.6990792155265808,
      "learning_rate": 4.701196767174386e-06,
      "loss": 0.1912,
      "step": 13637
    },
    {
      "epoch": 1.0598383587193037,
      "grad_norm": 0.08360448479652405,
      "learning_rate": 4.700808206403482e-06,
      "loss": 0.0225,
      "step": 13638
    },
    {
      "epoch": 1.0599160708734847,
      "grad_norm": 0.4723190367221832,
      "learning_rate": 4.700419645632578e-06,
      "loss": 0.1513,
      "step": 13639
    },
    {
      "epoch": 1.0599937830276656,
      "grad_norm": 0.2497549057006836,
      "learning_rate": 4.700031084861673e-06,
      "loss": 0.0776,
      "step": 13640
    },
    {
      "epoch": 1.0600714951818464,
      "grad_norm": 0.2976723909378052,
      "learning_rate": 4.6996425240907684e-06,
      "loss": 0.1846,
      "step": 13641
    },
    {
      "epoch": 1.0601492073360275,
      "grad_norm": 0.13379618525505066,
      "learning_rate": 4.699253963319863e-06,
      "loss": 0.0288,
      "step": 13642
    },
    {
      "epoch": 1.0602269194902083,
      "grad_norm": 0.20997455716133118,
      "learning_rate": 4.698865402548959e-06,
      "loss": 0.0784,
      "step": 13643
    },
    {
      "epoch": 1.0603046316443892,
      "grad_norm": 1.050756573677063,
      "learning_rate": 4.698476841778055e-06,
      "loss": 0.3384,
      "step": 13644
    },
    {
      "epoch": 1.06038234379857,
      "grad_norm": 1.080521583557129,
      "learning_rate": 4.69808828100715e-06,
      "loss": 0.4681,
      "step": 13645
    },
    {
      "epoch": 1.060460055952751,
      "grad_norm": 0.5973302125930786,
      "learning_rate": 4.697699720236245e-06,
      "loss": 0.3339,
      "step": 13646
    },
    {
      "epoch": 1.060537768106932,
      "grad_norm": 0.19725890457630157,
      "learning_rate": 4.697311159465341e-06,
      "loss": 0.0826,
      "step": 13647
    },
    {
      "epoch": 1.0606154802611127,
      "grad_norm": 0.6186376214027405,
      "learning_rate": 4.6969225986944365e-06,
      "loss": 0.1686,
      "step": 13648
    },
    {
      "epoch": 1.0606931924152938,
      "grad_norm": 0.172008216381073,
      "learning_rate": 4.696534037923531e-06,
      "loss": 0.0454,
      "step": 13649
    },
    {
      "epoch": 1.0607709045694746,
      "grad_norm": 1.0679322481155396,
      "learning_rate": 4.696145477152627e-06,
      "loss": 0.155,
      "step": 13650
    },
    {
      "epoch": 1.0608486167236555,
      "grad_norm": 0.23852741718292236,
      "learning_rate": 4.695756916381722e-06,
      "loss": 0.1814,
      "step": 13651
    },
    {
      "epoch": 1.0609263288778366,
      "grad_norm": 0.5004332661628723,
      "learning_rate": 4.695368355610818e-06,
      "loss": 0.2093,
      "step": 13652
    },
    {
      "epoch": 1.0610040410320174,
      "grad_norm": 0.2757096290588379,
      "learning_rate": 4.694979794839914e-06,
      "loss": 0.0808,
      "step": 13653
    },
    {
      "epoch": 1.0610817531861982,
      "grad_norm": 0.4309178590774536,
      "learning_rate": 4.694591234069009e-06,
      "loss": 0.1538,
      "step": 13654
    },
    {
      "epoch": 1.0611594653403793,
      "grad_norm": 0.4585192799568176,
      "learning_rate": 4.6942026732981045e-06,
      "loss": 0.0975,
      "step": 13655
    },
    {
      "epoch": 1.0612371774945601,
      "grad_norm": 0.1771143674850464,
      "learning_rate": 4.6938141125271995e-06,
      "loss": 0.0217,
      "step": 13656
    },
    {
      "epoch": 1.061314889648741,
      "grad_norm": 0.28305524587631226,
      "learning_rate": 4.693425551756295e-06,
      "loss": 0.1216,
      "step": 13657
    },
    {
      "epoch": 1.061392601802922,
      "grad_norm": 0.3504011034965515,
      "learning_rate": 4.693036990985391e-06,
      "loss": 0.1408,
      "step": 13658
    },
    {
      "epoch": 1.061470313957103,
      "grad_norm": 1.21382737159729,
      "learning_rate": 4.692648430214486e-06,
      "loss": 0.6999,
      "step": 13659
    },
    {
      "epoch": 1.0615480261112837,
      "grad_norm": 0.35712993144989014,
      "learning_rate": 4.692259869443581e-06,
      "loss": 0.1173,
      "step": 13660
    },
    {
      "epoch": 1.0616257382654648,
      "grad_norm": 0.7974339723587036,
      "learning_rate": 4.691871308672677e-06,
      "loss": 0.4987,
      "step": 13661
    },
    {
      "epoch": 1.0617034504196456,
      "grad_norm": 0.43898019194602966,
      "learning_rate": 4.6914827479017725e-06,
      "loss": 0.1572,
      "step": 13662
    },
    {
      "epoch": 1.0617811625738265,
      "grad_norm": 0.4130445122718811,
      "learning_rate": 4.6910941871308675e-06,
      "loss": 0.0785,
      "step": 13663
    },
    {
      "epoch": 1.0618588747280076,
      "grad_norm": 0.6553401350975037,
      "learning_rate": 4.690705626359963e-06,
      "loss": 0.2551,
      "step": 13664
    },
    {
      "epoch": 1.0619365868821884,
      "grad_norm": 0.24815937876701355,
      "learning_rate": 4.690317065589058e-06,
      "loss": 0.0542,
      "step": 13665
    },
    {
      "epoch": 1.0620142990363692,
      "grad_norm": 0.8783420920372009,
      "learning_rate": 4.689928504818154e-06,
      "loss": 0.2259,
      "step": 13666
    },
    {
      "epoch": 1.0620920111905503,
      "grad_norm": 0.19095201790332794,
      "learning_rate": 4.68953994404725e-06,
      "loss": 0.0415,
      "step": 13667
    },
    {
      "epoch": 1.0621697233447311,
      "grad_norm": 0.3157983720302582,
      "learning_rate": 4.689151383276345e-06,
      "loss": 0.1389,
      "step": 13668
    },
    {
      "epoch": 1.062247435498912,
      "grad_norm": 0.4845072031021118,
      "learning_rate": 4.688762822505441e-06,
      "loss": 0.4413,
      "step": 13669
    },
    {
      "epoch": 1.062325147653093,
      "grad_norm": 0.3329471945762634,
      "learning_rate": 4.6883742617345355e-06,
      "loss": 0.1244,
      "step": 13670
    },
    {
      "epoch": 1.062402859807274,
      "grad_norm": 0.23337000608444214,
      "learning_rate": 4.687985700963631e-06,
      "loss": 0.1208,
      "step": 13671
    },
    {
      "epoch": 1.0624805719614547,
      "grad_norm": 0.23575164377689362,
      "learning_rate": 4.687597140192727e-06,
      "loss": 0.0884,
      "step": 13672
    },
    {
      "epoch": 1.0625582841156356,
      "grad_norm": 0.34671008586883545,
      "learning_rate": 4.687208579421822e-06,
      "loss": 0.1448,
      "step": 13673
    },
    {
      "epoch": 1.0626359962698166,
      "grad_norm": 0.2091044932603836,
      "learning_rate": 4.686820018650917e-06,
      "loss": 0.0669,
      "step": 13674
    },
    {
      "epoch": 1.0627137084239975,
      "grad_norm": 0.48537513613700867,
      "learning_rate": 4.686431457880013e-06,
      "loss": 0.2051,
      "step": 13675
    },
    {
      "epoch": 1.0627914205781783,
      "grad_norm": 0.145277738571167,
      "learning_rate": 4.686042897109109e-06,
      "loss": 0.0156,
      "step": 13676
    },
    {
      "epoch": 1.0628691327323594,
      "grad_norm": 0.7932460904121399,
      "learning_rate": 4.6856543363382036e-06,
      "loss": 0.201,
      "step": 13677
    },
    {
      "epoch": 1.0629468448865402,
      "grad_norm": 0.5103028416633606,
      "learning_rate": 4.685265775567299e-06,
      "loss": 0.0965,
      "step": 13678
    },
    {
      "epoch": 1.063024557040721,
      "grad_norm": 0.1187918558716774,
      "learning_rate": 4.684877214796394e-06,
      "loss": 0.04,
      "step": 13679
    },
    {
      "epoch": 1.0631022691949021,
      "grad_norm": 0.48167040944099426,
      "learning_rate": 4.68448865402549e-06,
      "loss": 0.0762,
      "step": 13680
    },
    {
      "epoch": 1.063179981349083,
      "grad_norm": 0.23668648302555084,
      "learning_rate": 4.684100093254585e-06,
      "loss": 0.0264,
      "step": 13681
    },
    {
      "epoch": 1.0632576935032638,
      "grad_norm": 0.13115788996219635,
      "learning_rate": 4.683711532483681e-06,
      "loss": 0.0629,
      "step": 13682
    },
    {
      "epoch": 1.0633354056574449,
      "grad_norm": 0.2541647255420685,
      "learning_rate": 4.683322971712777e-06,
      "loss": 0.1253,
      "step": 13683
    },
    {
      "epoch": 1.0634131178116257,
      "grad_norm": 0.7040250301361084,
      "learning_rate": 4.682934410941872e-06,
      "loss": 0.3152,
      "step": 13684
    },
    {
      "epoch": 1.0634908299658066,
      "grad_norm": 0.39682087302207947,
      "learning_rate": 4.6825458501709666e-06,
      "loss": 0.081,
      "step": 13685
    },
    {
      "epoch": 1.0635685421199876,
      "grad_norm": 0.7678411602973938,
      "learning_rate": 4.682157289400062e-06,
      "loss": 0.2081,
      "step": 13686
    },
    {
      "epoch": 1.0636462542741685,
      "grad_norm": 0.1603686809539795,
      "learning_rate": 4.681768728629158e-06,
      "loss": 0.0899,
      "step": 13687
    },
    {
      "epoch": 1.0637239664283493,
      "grad_norm": 0.569370687007904,
      "learning_rate": 4.681380167858253e-06,
      "loss": 0.1363,
      "step": 13688
    },
    {
      "epoch": 1.0638016785825304,
      "grad_norm": 0.2820432782173157,
      "learning_rate": 4.680991607087349e-06,
      "loss": 0.0669,
      "step": 13689
    },
    {
      "epoch": 1.0638793907367112,
      "grad_norm": 0.34725943207740784,
      "learning_rate": 4.680603046316444e-06,
      "loss": 0.379,
      "step": 13690
    },
    {
      "epoch": 1.063957102890892,
      "grad_norm": 0.15255071222782135,
      "learning_rate": 4.68021448554554e-06,
      "loss": 0.0381,
      "step": 13691
    },
    {
      "epoch": 1.0640348150450731,
      "grad_norm": 0.28968700766563416,
      "learning_rate": 4.6798259247746354e-06,
      "loss": 0.1084,
      "step": 13692
    },
    {
      "epoch": 1.064112527199254,
      "grad_norm": 0.25224852561950684,
      "learning_rate": 4.67943736400373e-06,
      "loss": 0.1606,
      "step": 13693
    },
    {
      "epoch": 1.0641902393534348,
      "grad_norm": 0.41366109251976013,
      "learning_rate": 4.679048803232825e-06,
      "loss": 0.4068,
      "step": 13694
    },
    {
      "epoch": 1.0642679515076159,
      "grad_norm": 0.21508827805519104,
      "learning_rate": 4.678660242461921e-06,
      "loss": 0.0471,
      "step": 13695
    },
    {
      "epoch": 1.0643456636617967,
      "grad_norm": 0.5289586186408997,
      "learning_rate": 4.678271681691017e-06,
      "loss": 0.3263,
      "step": 13696
    },
    {
      "epoch": 1.0644233758159776,
      "grad_norm": 1.2496862411499023,
      "learning_rate": 4.677883120920113e-06,
      "loss": 0.3303,
      "step": 13697
    },
    {
      "epoch": 1.0645010879701586,
      "grad_norm": 0.9417237639427185,
      "learning_rate": 4.677494560149208e-06,
      "loss": 0.302,
      "step": 13698
    },
    {
      "epoch": 1.0645788001243395,
      "grad_norm": 1.1165423393249512,
      "learning_rate": 4.677105999378303e-06,
      "loss": 0.397,
      "step": 13699
    },
    {
      "epoch": 1.0646565122785203,
      "grad_norm": 0.5090906023979187,
      "learning_rate": 4.676717438607398e-06,
      "loss": 0.2396,
      "step": 13700
    },
    {
      "epoch": 1.0647342244327014,
      "grad_norm": 0.9883411526679993,
      "learning_rate": 4.676328877836494e-06,
      "loss": 0.1639,
      "step": 13701
    },
    {
      "epoch": 1.0648119365868822,
      "grad_norm": 0.5379588603973389,
      "learning_rate": 4.675940317065589e-06,
      "loss": 0.2046,
      "step": 13702
    },
    {
      "epoch": 1.064889648741063,
      "grad_norm": 0.17517919838428497,
      "learning_rate": 4.675551756294685e-06,
      "loss": 0.0321,
      "step": 13703
    },
    {
      "epoch": 1.0649673608952441,
      "grad_norm": 0.19662469625473022,
      "learning_rate": 4.67516319552378e-06,
      "loss": 0.0484,
      "step": 13704
    },
    {
      "epoch": 1.065045073049425,
      "grad_norm": 0.6579557061195374,
      "learning_rate": 4.674774634752876e-06,
      "loss": 0.5665,
      "step": 13705
    },
    {
      "epoch": 1.0651227852036058,
      "grad_norm": 0.4483109414577484,
      "learning_rate": 4.6743860739819715e-06,
      "loss": 0.1407,
      "step": 13706
    },
    {
      "epoch": 1.0652004973577867,
      "grad_norm": 0.3216398060321808,
      "learning_rate": 4.6739975132110665e-06,
      "loss": 0.167,
      "step": 13707
    },
    {
      "epoch": 1.0652782095119677,
      "grad_norm": 0.5720352530479431,
      "learning_rate": 4.673608952440161e-06,
      "loss": 0.1857,
      "step": 13708
    },
    {
      "epoch": 1.0653559216661486,
      "grad_norm": 0.40119972825050354,
      "learning_rate": 4.673220391669257e-06,
      "loss": 0.2606,
      "step": 13709
    },
    {
      "epoch": 1.0654336338203294,
      "grad_norm": 0.024749770760536194,
      "learning_rate": 4.672831830898353e-06,
      "loss": 0.0018,
      "step": 13710
    },
    {
      "epoch": 1.0655113459745105,
      "grad_norm": 1.903914451599121,
      "learning_rate": 4.672443270127449e-06,
      "loss": 0.2789,
      "step": 13711
    },
    {
      "epoch": 1.0655890581286913,
      "grad_norm": 0.44117239117622375,
      "learning_rate": 4.672054709356544e-06,
      "loss": 0.1193,
      "step": 13712
    },
    {
      "epoch": 1.0656667702828722,
      "grad_norm": 0.6019359230995178,
      "learning_rate": 4.671666148585639e-06,
      "loss": 0.4791,
      "step": 13713
    },
    {
      "epoch": 1.0657444824370532,
      "grad_norm": 0.2599142789840698,
      "learning_rate": 4.6712775878147345e-06,
      "loss": 0.087,
      "step": 13714
    },
    {
      "epoch": 1.065822194591234,
      "grad_norm": 0.2938894033432007,
      "learning_rate": 4.67088902704383e-06,
      "loss": 0.1502,
      "step": 13715
    },
    {
      "epoch": 1.065899906745415,
      "grad_norm": 0.2867988348007202,
      "learning_rate": 4.670500466272925e-06,
      "loss": 0.1225,
      "step": 13716
    },
    {
      "epoch": 1.065977618899596,
      "grad_norm": 0.6370201110839844,
      "learning_rate": 4.670111905502021e-06,
      "loss": 0.1887,
      "step": 13717
    },
    {
      "epoch": 1.0660553310537768,
      "grad_norm": 0.44114166498184204,
      "learning_rate": 4.669723344731116e-06,
      "loss": 0.1241,
      "step": 13718
    },
    {
      "epoch": 1.0661330432079577,
      "grad_norm": 0.33594903349876404,
      "learning_rate": 4.669334783960212e-06,
      "loss": 0.0822,
      "step": 13719
    },
    {
      "epoch": 1.0662107553621387,
      "grad_norm": 0.575802206993103,
      "learning_rate": 4.668946223189308e-06,
      "loss": 0.1056,
      "step": 13720
    },
    {
      "epoch": 1.0662884675163196,
      "grad_norm": 0.5380303859710693,
      "learning_rate": 4.6685576624184025e-06,
      "loss": 0.2872,
      "step": 13721
    },
    {
      "epoch": 1.0663661796705004,
      "grad_norm": 0.2682557702064514,
      "learning_rate": 4.6681691016474975e-06,
      "loss": 0.0343,
      "step": 13722
    },
    {
      "epoch": 1.0664438918246815,
      "grad_norm": 0.184373676776886,
      "learning_rate": 4.667780540876593e-06,
      "loss": 0.0629,
      "step": 13723
    },
    {
      "epoch": 1.0665216039788623,
      "grad_norm": 1.6239856481552124,
      "learning_rate": 4.667391980105689e-06,
      "loss": 0.2731,
      "step": 13724
    },
    {
      "epoch": 1.0665993161330432,
      "grad_norm": 0.5504816770553589,
      "learning_rate": 4.667003419334784e-06,
      "loss": 0.147,
      "step": 13725
    },
    {
      "epoch": 1.0666770282872242,
      "grad_norm": 0.18271121382713318,
      "learning_rate": 4.66661485856388e-06,
      "loss": 0.062,
      "step": 13726
    },
    {
      "epoch": 1.066754740441405,
      "grad_norm": 0.6255501508712769,
      "learning_rate": 4.666226297792975e-06,
      "loss": 0.2229,
      "step": 13727
    },
    {
      "epoch": 1.066832452595586,
      "grad_norm": 0.21263647079467773,
      "learning_rate": 4.6658377370220706e-06,
      "loss": 0.0376,
      "step": 13728
    },
    {
      "epoch": 1.066910164749767,
      "grad_norm": 0.8099119067192078,
      "learning_rate": 4.665449176251166e-06,
      "loss": 0.4169,
      "step": 13729
    },
    {
      "epoch": 1.0669878769039478,
      "grad_norm": 0.5548080205917358,
      "learning_rate": 4.665060615480261e-06,
      "loss": 0.3573,
      "step": 13730
    },
    {
      "epoch": 1.0670655890581286,
      "grad_norm": 0.49542227387428284,
      "learning_rate": 4.664672054709357e-06,
      "loss": 0.0723,
      "step": 13731
    },
    {
      "epoch": 1.0671433012123095,
      "grad_norm": 0.45886921882629395,
      "learning_rate": 4.664283493938452e-06,
      "loss": 0.088,
      "step": 13732
    },
    {
      "epoch": 1.0672210133664906,
      "grad_norm": 0.265986829996109,
      "learning_rate": 4.663894933167548e-06,
      "loss": 0.067,
      "step": 13733
    },
    {
      "epoch": 1.0672987255206714,
      "grad_norm": 0.3744010925292969,
      "learning_rate": 4.663506372396644e-06,
      "loss": 0.1446,
      "step": 13734
    },
    {
      "epoch": 1.0673764376748522,
      "grad_norm": 0.7099039554595947,
      "learning_rate": 4.663117811625739e-06,
      "loss": 0.4174,
      "step": 13735
    },
    {
      "epoch": 1.0674541498290333,
      "grad_norm": 0.5697202086448669,
      "learning_rate": 4.6627292508548336e-06,
      "loss": 0.1655,
      "step": 13736
    },
    {
      "epoch": 1.0675318619832141,
      "grad_norm": 0.5470404028892517,
      "learning_rate": 4.662340690083929e-06,
      "loss": 0.2514,
      "step": 13737
    },
    {
      "epoch": 1.067609574137395,
      "grad_norm": 0.6083188652992249,
      "learning_rate": 4.661952129313025e-06,
      "loss": 0.1737,
      "step": 13738
    },
    {
      "epoch": 1.067687286291576,
      "grad_norm": 0.14476726949214935,
      "learning_rate": 4.66156356854212e-06,
      "loss": 0.035,
      "step": 13739
    },
    {
      "epoch": 1.067764998445757,
      "grad_norm": 0.2551135718822479,
      "learning_rate": 4.661175007771216e-06,
      "loss": 0.0485,
      "step": 13740
    },
    {
      "epoch": 1.0678427105999377,
      "grad_norm": 0.54157954454422,
      "learning_rate": 4.660786447000311e-06,
      "loss": 0.17,
      "step": 13741
    },
    {
      "epoch": 1.0679204227541188,
      "grad_norm": 0.34345629811286926,
      "learning_rate": 4.660397886229407e-06,
      "loss": 0.1269,
      "step": 13742
    },
    {
      "epoch": 1.0679981349082996,
      "grad_norm": 0.03597882390022278,
      "learning_rate": 4.6600093254585024e-06,
      "loss": 0.0055,
      "step": 13743
    },
    {
      "epoch": 1.0680758470624805,
      "grad_norm": 0.45583054423332214,
      "learning_rate": 4.659620764687597e-06,
      "loss": 0.1188,
      "step": 13744
    },
    {
      "epoch": 1.0681535592166616,
      "grad_norm": 0.7620187997817993,
      "learning_rate": 4.659232203916693e-06,
      "loss": 0.1153,
      "step": 13745
    },
    {
      "epoch": 1.0682312713708424,
      "grad_norm": 0.106051966547966,
      "learning_rate": 4.658843643145788e-06,
      "loss": 0.16,
      "step": 13746
    },
    {
      "epoch": 1.0683089835250232,
      "grad_norm": 1.204404592514038,
      "learning_rate": 4.658455082374884e-06,
      "loss": 0.5336,
      "step": 13747
    },
    {
      "epoch": 1.0683866956792043,
      "grad_norm": 0.40231752395629883,
      "learning_rate": 4.65806652160398e-06,
      "loss": 0.4132,
      "step": 13748
    },
    {
      "epoch": 1.0684644078333851,
      "grad_norm": 0.5368881821632385,
      "learning_rate": 4.657677960833075e-06,
      "loss": 0.1042,
      "step": 13749
    },
    {
      "epoch": 1.068542119987566,
      "grad_norm": 0.5029093623161316,
      "learning_rate": 4.65728940006217e-06,
      "loss": 0.203,
      "step": 13750
    },
    {
      "epoch": 1.068619832141747,
      "grad_norm": 0.37137389183044434,
      "learning_rate": 4.6569008392912654e-06,
      "loss": 0.18,
      "step": 13751
    },
    {
      "epoch": 1.068697544295928,
      "grad_norm": 0.34797805547714233,
      "learning_rate": 4.656512278520361e-06,
      "loss": 0.1535,
      "step": 13752
    },
    {
      "epoch": 1.0687752564501087,
      "grad_norm": 0.2513469457626343,
      "learning_rate": 4.656123717749456e-06,
      "loss": 0.0678,
      "step": 13753
    },
    {
      "epoch": 1.0688529686042898,
      "grad_norm": 0.5668004751205444,
      "learning_rate": 4.655735156978552e-06,
      "loss": 0.3378,
      "step": 13754
    },
    {
      "epoch": 1.0689306807584706,
      "grad_norm": 0.6791971921920776,
      "learning_rate": 4.655346596207647e-06,
      "loss": 0.7367,
      "step": 13755
    },
    {
      "epoch": 1.0690083929126515,
      "grad_norm": 0.19865988194942474,
      "learning_rate": 4.654958035436743e-06,
      "loss": 0.0154,
      "step": 13756
    },
    {
      "epoch": 1.0690861050668325,
      "grad_norm": 0.38003629446029663,
      "learning_rate": 4.6545694746658385e-06,
      "loss": 0.1359,
      "step": 13757
    },
    {
      "epoch": 1.0691638172210134,
      "grad_norm": 0.3767148554325104,
      "learning_rate": 4.6541809138949335e-06,
      "loss": 0.164,
      "step": 13758
    },
    {
      "epoch": 1.0692415293751942,
      "grad_norm": 0.45318472385406494,
      "learning_rate": 4.653792353124029e-06,
      "loss": 0.1698,
      "step": 13759
    },
    {
      "epoch": 1.0693192415293753,
      "grad_norm": 0.9669132232666016,
      "learning_rate": 4.653403792353124e-06,
      "loss": 0.2361,
      "step": 13760
    },
    {
      "epoch": 1.0693969536835561,
      "grad_norm": 0.0760854110121727,
      "learning_rate": 4.65301523158222e-06,
      "loss": 0.0191,
      "step": 13761
    },
    {
      "epoch": 1.069474665837737,
      "grad_norm": 0.3996342420578003,
      "learning_rate": 4.652626670811316e-06,
      "loss": 0.0717,
      "step": 13762
    },
    {
      "epoch": 1.069552377991918,
      "grad_norm": 0.6440463066101074,
      "learning_rate": 4.652238110040411e-06,
      "loss": 1.1734,
      "step": 13763
    },
    {
      "epoch": 1.0696300901460989,
      "grad_norm": 0.03019793890416622,
      "learning_rate": 4.651849549269506e-06,
      "loss": 0.0018,
      "step": 13764
    },
    {
      "epoch": 1.0697078023002797,
      "grad_norm": 0.5445132851600647,
      "learning_rate": 4.6514609884986015e-06,
      "loss": 0.1274,
      "step": 13765
    },
    {
      "epoch": 1.0697855144544608,
      "grad_norm": 0.37717127799987793,
      "learning_rate": 4.651072427727697e-06,
      "loss": 0.1728,
      "step": 13766
    },
    {
      "epoch": 1.0698632266086416,
      "grad_norm": 0.31671202182769775,
      "learning_rate": 4.650683866956792e-06,
      "loss": 0.114,
      "step": 13767
    },
    {
      "epoch": 1.0699409387628225,
      "grad_norm": 0.5004703998565674,
      "learning_rate": 4.650295306185888e-06,
      "loss": 0.1954,
      "step": 13768
    },
    {
      "epoch": 1.0700186509170033,
      "grad_norm": 0.17464113235473633,
      "learning_rate": 4.649906745414983e-06,
      "loss": 0.0182,
      "step": 13769
    },
    {
      "epoch": 1.0700963630711844,
      "grad_norm": 0.5237030982971191,
      "learning_rate": 4.649518184644079e-06,
      "loss": 0.2406,
      "step": 13770
    },
    {
      "epoch": 1.0701740752253652,
      "grad_norm": 0.9747957587242126,
      "learning_rate": 4.649129623873175e-06,
      "loss": 0.282,
      "step": 13771
    },
    {
      "epoch": 1.070251787379546,
      "grad_norm": 0.6093716025352478,
      "learning_rate": 4.6487410631022695e-06,
      "loss": 0.8224,
      "step": 13772
    },
    {
      "epoch": 1.0703294995337271,
      "grad_norm": 0.13096988201141357,
      "learning_rate": 4.648352502331365e-06,
      "loss": 0.0774,
      "step": 13773
    },
    {
      "epoch": 1.070407211687908,
      "grad_norm": 0.21353811025619507,
      "learning_rate": 4.64796394156046e-06,
      "loss": 0.0616,
      "step": 13774
    },
    {
      "epoch": 1.0704849238420888,
      "grad_norm": 0.7201406955718994,
      "learning_rate": 4.647575380789556e-06,
      "loss": 0.266,
      "step": 13775
    },
    {
      "epoch": 1.0705626359962699,
      "grad_norm": 0.8580357432365417,
      "learning_rate": 4.647186820018652e-06,
      "loss": 0.1235,
      "step": 13776
    },
    {
      "epoch": 1.0706403481504507,
      "grad_norm": 0.6371917128562927,
      "learning_rate": 4.646798259247747e-06,
      "loss": 0.1499,
      "step": 13777
    },
    {
      "epoch": 1.0707180603046316,
      "grad_norm": 0.23581112921237946,
      "learning_rate": 4.646409698476842e-06,
      "loss": 0.0715,
      "step": 13778
    },
    {
      "epoch": 1.0707957724588126,
      "grad_norm": 0.2786039710044861,
      "learning_rate": 4.6460211377059376e-06,
      "loss": 0.0932,
      "step": 13779
    },
    {
      "epoch": 1.0708734846129935,
      "grad_norm": 0.2498481273651123,
      "learning_rate": 4.645632576935033e-06,
      "loss": 0.1253,
      "step": 13780
    },
    {
      "epoch": 1.0709511967671743,
      "grad_norm": 0.2170957773923874,
      "learning_rate": 4.645244016164128e-06,
      "loss": 0.0837,
      "step": 13781
    },
    {
      "epoch": 1.0710289089213554,
      "grad_norm": 0.13309279084205627,
      "learning_rate": 4.644855455393224e-06,
      "loss": 0.0229,
      "step": 13782
    },
    {
      "epoch": 1.0711066210755362,
      "grad_norm": 0.30133917927742004,
      "learning_rate": 4.644466894622319e-06,
      "loss": 0.1251,
      "step": 13783
    },
    {
      "epoch": 1.071184333229717,
      "grad_norm": 0.1257343590259552,
      "learning_rate": 4.644078333851415e-06,
      "loss": 0.0382,
      "step": 13784
    },
    {
      "epoch": 1.0712620453838981,
      "grad_norm": 0.35832762718200684,
      "learning_rate": 4.643689773080511e-06,
      "loss": 0.254,
      "step": 13785
    },
    {
      "epoch": 1.071339757538079,
      "grad_norm": 0.643138587474823,
      "learning_rate": 4.643301212309606e-06,
      "loss": 0.3872,
      "step": 13786
    },
    {
      "epoch": 1.0714174696922598,
      "grad_norm": 0.2504918873310089,
      "learning_rate": 4.642912651538701e-06,
      "loss": 0.0433,
      "step": 13787
    },
    {
      "epoch": 1.0714951818464409,
      "grad_norm": 0.39047908782958984,
      "learning_rate": 4.642524090767796e-06,
      "loss": 0.1482,
      "step": 13788
    },
    {
      "epoch": 1.0715728940006217,
      "grad_norm": 0.10777926445007324,
      "learning_rate": 4.642135529996892e-06,
      "loss": 0.0173,
      "step": 13789
    },
    {
      "epoch": 1.0716506061548026,
      "grad_norm": 0.4532581865787506,
      "learning_rate": 4.641746969225988e-06,
      "loss": 0.0632,
      "step": 13790
    },
    {
      "epoch": 1.0717283183089834,
      "grad_norm": 0.6156758666038513,
      "learning_rate": 4.641358408455083e-06,
      "loss": 0.1406,
      "step": 13791
    },
    {
      "epoch": 1.0718060304631645,
      "grad_norm": 0.3370550870895386,
      "learning_rate": 4.640969847684178e-06,
      "loss": 0.1836,
      "step": 13792
    },
    {
      "epoch": 1.0718837426173453,
      "grad_norm": 0.2710953652858734,
      "learning_rate": 4.640581286913274e-06,
      "loss": 0.0708,
      "step": 13793
    },
    {
      "epoch": 1.0719614547715262,
      "grad_norm": 0.5477587580680847,
      "learning_rate": 4.6401927261423694e-06,
      "loss": 0.2,
      "step": 13794
    },
    {
      "epoch": 1.0720391669257072,
      "grad_norm": 0.24647316336631775,
      "learning_rate": 4.639804165371464e-06,
      "loss": 0.0696,
      "step": 13795
    },
    {
      "epoch": 1.072116879079888,
      "grad_norm": 0.27519291639328003,
      "learning_rate": 4.63941560460056e-06,
      "loss": 0.1588,
      "step": 13796
    },
    {
      "epoch": 1.072194591234069,
      "grad_norm": 0.5764724016189575,
      "learning_rate": 4.639027043829655e-06,
      "loss": 0.2963,
      "step": 13797
    },
    {
      "epoch": 1.07227230338825,
      "grad_norm": 0.28999415040016174,
      "learning_rate": 4.638638483058751e-06,
      "loss": 0.0678,
      "step": 13798
    },
    {
      "epoch": 1.0723500155424308,
      "grad_norm": 0.26627299189567566,
      "learning_rate": 4.638249922287847e-06,
      "loss": 0.079,
      "step": 13799
    },
    {
      "epoch": 1.0724277276966117,
      "grad_norm": 0.36133503913879395,
      "learning_rate": 4.637861361516942e-06,
      "loss": 0.1361,
      "step": 13800
    },
    {
      "epoch": 1.0725054398507927,
      "grad_norm": 0.13313093781471252,
      "learning_rate": 4.637472800746037e-06,
      "loss": 0.0661,
      "step": 13801
    },
    {
      "epoch": 1.0725831520049736,
      "grad_norm": 0.6317468881607056,
      "learning_rate": 4.6370842399751324e-06,
      "loss": 0.0985,
      "step": 13802
    },
    {
      "epoch": 1.0726608641591544,
      "grad_norm": 0.716271162033081,
      "learning_rate": 4.636695679204228e-06,
      "loss": 0.4053,
      "step": 13803
    },
    {
      "epoch": 1.0727385763133355,
      "grad_norm": 0.35401037335395813,
      "learning_rate": 4.636307118433323e-06,
      "loss": 0.1065,
      "step": 13804
    },
    {
      "epoch": 1.0728162884675163,
      "grad_norm": 0.4181482791900635,
      "learning_rate": 4.635918557662419e-06,
      "loss": 0.1329,
      "step": 13805
    },
    {
      "epoch": 1.0728940006216972,
      "grad_norm": 0.119087815284729,
      "learning_rate": 4.635529996891514e-06,
      "loss": 0.0231,
      "step": 13806
    },
    {
      "epoch": 1.0729717127758782,
      "grad_norm": 0.11428474634885788,
      "learning_rate": 4.63514143612061e-06,
      "loss": 0.0182,
      "step": 13807
    },
    {
      "epoch": 1.073049424930059,
      "grad_norm": 0.32731422781944275,
      "learning_rate": 4.634752875349705e-06,
      "loss": 0.161,
      "step": 13808
    },
    {
      "epoch": 1.07312713708424,
      "grad_norm": 0.2560977637767792,
      "learning_rate": 4.6343643145788005e-06,
      "loss": 0.0577,
      "step": 13809
    },
    {
      "epoch": 1.073204849238421,
      "grad_norm": 1.0036094188690186,
      "learning_rate": 4.633975753807896e-06,
      "loss": 0.3081,
      "step": 13810
    },
    {
      "epoch": 1.0732825613926018,
      "grad_norm": 0.350734144449234,
      "learning_rate": 4.633587193036991e-06,
      "loss": 0.0478,
      "step": 13811
    },
    {
      "epoch": 1.0733602735467827,
      "grad_norm": 0.4202861487865448,
      "learning_rate": 4.633198632266086e-06,
      "loss": 0.131,
      "step": 13812
    },
    {
      "epoch": 1.0734379857009637,
      "grad_norm": 0.2177165001630783,
      "learning_rate": 4.632810071495182e-06,
      "loss": 0.0877,
      "step": 13813
    },
    {
      "epoch": 1.0735156978551446,
      "grad_norm": 0.48871317505836487,
      "learning_rate": 4.632421510724278e-06,
      "loss": 0.1457,
      "step": 13814
    },
    {
      "epoch": 1.0735934100093254,
      "grad_norm": 0.3181995749473572,
      "learning_rate": 4.632032949953373e-06,
      "loss": 0.141,
      "step": 13815
    },
    {
      "epoch": 1.0736711221635065,
      "grad_norm": 0.6995260119438171,
      "learning_rate": 4.6316443891824685e-06,
      "loss": 0.2011,
      "step": 13816
    },
    {
      "epoch": 1.0737488343176873,
      "grad_norm": 0.12203322350978851,
      "learning_rate": 4.6312558284115634e-06,
      "loss": 0.0434,
      "step": 13817
    },
    {
      "epoch": 1.0738265464718681,
      "grad_norm": 0.31774699687957764,
      "learning_rate": 4.630867267640659e-06,
      "loss": 0.1368,
      "step": 13818
    },
    {
      "epoch": 1.0739042586260492,
      "grad_norm": 1.4901483058929443,
      "learning_rate": 4.630478706869755e-06,
      "loss": 0.4892,
      "step": 13819
    },
    {
      "epoch": 1.07398197078023,
      "grad_norm": 0.43339481949806213,
      "learning_rate": 4.63009014609885e-06,
      "loss": 0.08,
      "step": 13820
    },
    {
      "epoch": 1.074059682934411,
      "grad_norm": 0.5251429677009583,
      "learning_rate": 4.629701585327946e-06,
      "loss": 0.2163,
      "step": 13821
    },
    {
      "epoch": 1.074137395088592,
      "grad_norm": 0.1843302994966507,
      "learning_rate": 4.629313024557041e-06,
      "loss": 0.0477,
      "step": 13822
    },
    {
      "epoch": 1.0742151072427728,
      "grad_norm": 0.43030214309692383,
      "learning_rate": 4.6289244637861365e-06,
      "loss": 0.132,
      "step": 13823
    },
    {
      "epoch": 1.0742928193969536,
      "grad_norm": 0.37006860971450806,
      "learning_rate": 4.628535903015232e-06,
      "loss": 0.1229,
      "step": 13824
    },
    {
      "epoch": 1.0743705315511347,
      "grad_norm": 0.4240446388721466,
      "learning_rate": 4.628147342244327e-06,
      "loss": 0.1652,
      "step": 13825
    },
    {
      "epoch": 1.0744482437053156,
      "grad_norm": 0.20687618851661682,
      "learning_rate": 4.627758781473422e-06,
      "loss": 0.0474,
      "step": 13826
    },
    {
      "epoch": 1.0745259558594964,
      "grad_norm": 0.5900565385818481,
      "learning_rate": 4.627370220702518e-06,
      "loss": 0.2175,
      "step": 13827
    },
    {
      "epoch": 1.0746036680136772,
      "grad_norm": 0.3259119987487793,
      "learning_rate": 4.626981659931614e-06,
      "loss": 0.0995,
      "step": 13828
    },
    {
      "epoch": 1.0746813801678583,
      "grad_norm": 0.22842898964881897,
      "learning_rate": 4.626593099160709e-06,
      "loss": 0.0446,
      "step": 13829
    },
    {
      "epoch": 1.0747590923220391,
      "grad_norm": 0.18425814807415009,
      "learning_rate": 4.6262045383898046e-06,
      "loss": 0.1345,
      "step": 13830
    },
    {
      "epoch": 1.07483680447622,
      "grad_norm": 0.19359180331230164,
      "learning_rate": 4.6258159776188995e-06,
      "loss": 0.0913,
      "step": 13831
    },
    {
      "epoch": 1.074914516630401,
      "grad_norm": 0.5643223524093628,
      "learning_rate": 4.625427416847995e-06,
      "loss": 0.5697,
      "step": 13832
    },
    {
      "epoch": 1.074992228784582,
      "grad_norm": 0.5234729051589966,
      "learning_rate": 4.625038856077091e-06,
      "loss": 0.6909,
      "step": 13833
    },
    {
      "epoch": 1.0750699409387627,
      "grad_norm": 0.19575384259223938,
      "learning_rate": 4.624650295306186e-06,
      "loss": 0.0573,
      "step": 13834
    },
    {
      "epoch": 1.0751476530929438,
      "grad_norm": 0.5947822332382202,
      "learning_rate": 4.624261734535282e-06,
      "loss": 0.0871,
      "step": 13835
    },
    {
      "epoch": 1.0752253652471246,
      "grad_norm": 0.6767290830612183,
      "learning_rate": 4.623873173764377e-06,
      "loss": 0.2831,
      "step": 13836
    },
    {
      "epoch": 1.0753030774013055,
      "grad_norm": 0.6161864995956421,
      "learning_rate": 4.623484612993473e-06,
      "loss": 0.5818,
      "step": 13837
    },
    {
      "epoch": 1.0753807895554865,
      "grad_norm": 0.11129572242498398,
      "learning_rate": 4.623096052222568e-06,
      "loss": 0.0329,
      "step": 13838
    },
    {
      "epoch": 1.0754585017096674,
      "grad_norm": 0.3990964889526367,
      "learning_rate": 4.622707491451663e-06,
      "loss": 0.2907,
      "step": 13839
    },
    {
      "epoch": 1.0755362138638482,
      "grad_norm": 0.17992495000362396,
      "learning_rate": 4.622318930680758e-06,
      "loss": 0.0481,
      "step": 13840
    },
    {
      "epoch": 1.0756139260180293,
      "grad_norm": 1.1116535663604736,
      "learning_rate": 4.621930369909854e-06,
      "loss": 0.4288,
      "step": 13841
    },
    {
      "epoch": 1.0756916381722101,
      "grad_norm": 0.7020525932312012,
      "learning_rate": 4.62154180913895e-06,
      "loss": 0.5709,
      "step": 13842
    },
    {
      "epoch": 1.075769350326391,
      "grad_norm": 0.3353694975376129,
      "learning_rate": 4.621153248368045e-06,
      "loss": 0.4334,
      "step": 13843
    },
    {
      "epoch": 1.075847062480572,
      "grad_norm": 0.5080479383468628,
      "learning_rate": 4.620764687597141e-06,
      "loss": 0.1242,
      "step": 13844
    },
    {
      "epoch": 1.075924774634753,
      "grad_norm": 0.10048165172338486,
      "learning_rate": 4.620376126826236e-06,
      "loss": 0.0296,
      "step": 13845
    },
    {
      "epoch": 1.0760024867889337,
      "grad_norm": 0.44110867381095886,
      "learning_rate": 4.619987566055331e-06,
      "loss": 0.0827,
      "step": 13846
    },
    {
      "epoch": 1.0760801989431148,
      "grad_norm": 0.6275142431259155,
      "learning_rate": 4.619599005284427e-06,
      "loss": 0.2591,
      "step": 13847
    },
    {
      "epoch": 1.0761579110972956,
      "grad_norm": 0.3001610040664673,
      "learning_rate": 4.619210444513522e-06,
      "loss": 0.0729,
      "step": 13848
    },
    {
      "epoch": 1.0762356232514765,
      "grad_norm": 0.2959781289100647,
      "learning_rate": 4.618821883742618e-06,
      "loss": 0.0792,
      "step": 13849
    },
    {
      "epoch": 1.0763133354056575,
      "grad_norm": 0.14697639644145966,
      "learning_rate": 4.618433322971713e-06,
      "loss": 0.1527,
      "step": 13850
    },
    {
      "epoch": 1.0763910475598384,
      "grad_norm": 0.3692222237586975,
      "learning_rate": 4.618044762200809e-06,
      "loss": 0.0796,
      "step": 13851
    },
    {
      "epoch": 1.0764687597140192,
      "grad_norm": 0.49941426515579224,
      "learning_rate": 4.6176562014299045e-06,
      "loss": 0.0893,
      "step": 13852
    },
    {
      "epoch": 1.0765464718682,
      "grad_norm": 0.3030969500541687,
      "learning_rate": 4.6172676406589994e-06,
      "loss": 0.0687,
      "step": 13853
    },
    {
      "epoch": 1.0766241840223811,
      "grad_norm": 0.9090386629104614,
      "learning_rate": 4.616879079888094e-06,
      "loss": 0.1622,
      "step": 13854
    },
    {
      "epoch": 1.076701896176562,
      "grad_norm": 0.30025342106819153,
      "learning_rate": 4.61649051911719e-06,
      "loss": 0.2036,
      "step": 13855
    },
    {
      "epoch": 1.0767796083307428,
      "grad_norm": 0.1960870772600174,
      "learning_rate": 4.616101958346286e-06,
      "loss": 0.0462,
      "step": 13856
    },
    {
      "epoch": 1.0768573204849239,
      "grad_norm": 0.1642221361398697,
      "learning_rate": 4.615713397575381e-06,
      "loss": 0.0567,
      "step": 13857
    },
    {
      "epoch": 1.0769350326391047,
      "grad_norm": 0.24080973863601685,
      "learning_rate": 4.615324836804477e-06,
      "loss": 0.1067,
      "step": 13858
    },
    {
      "epoch": 1.0770127447932856,
      "grad_norm": 0.5567890405654907,
      "learning_rate": 4.614936276033572e-06,
      "loss": 0.1551,
      "step": 13859
    },
    {
      "epoch": 1.0770904569474666,
      "grad_norm": 0.48792219161987305,
      "learning_rate": 4.6145477152626675e-06,
      "loss": 0.1253,
      "step": 13860
    },
    {
      "epoch": 1.0771681691016475,
      "grad_norm": 0.6507927179336548,
      "learning_rate": 4.614159154491763e-06,
      "loss": 0.29,
      "step": 13861
    },
    {
      "epoch": 1.0772458812558283,
      "grad_norm": 0.19981716573238373,
      "learning_rate": 4.613770593720858e-06,
      "loss": 0.0808,
      "step": 13862
    },
    {
      "epoch": 1.0773235934100094,
      "grad_norm": 0.5939998626708984,
      "learning_rate": 4.613382032949954e-06,
      "loss": 0.1267,
      "step": 13863
    },
    {
      "epoch": 1.0774013055641902,
      "grad_norm": 0.6439964771270752,
      "learning_rate": 4.612993472179049e-06,
      "loss": 0.1549,
      "step": 13864
    },
    {
      "epoch": 1.077479017718371,
      "grad_norm": 0.16753797233104706,
      "learning_rate": 4.612604911408145e-06,
      "loss": 0.0263,
      "step": 13865
    },
    {
      "epoch": 1.0775567298725521,
      "grad_norm": 0.14557650685310364,
      "learning_rate": 4.6122163506372406e-06,
      "loss": 0.0477,
      "step": 13866
    },
    {
      "epoch": 1.077634442026733,
      "grad_norm": 0.6164594292640686,
      "learning_rate": 4.6118277898663355e-06,
      "loss": 0.1473,
      "step": 13867
    },
    {
      "epoch": 1.0777121541809138,
      "grad_norm": 0.2818557620048523,
      "learning_rate": 4.6114392290954305e-06,
      "loss": 0.117,
      "step": 13868
    },
    {
      "epoch": 1.0777898663350949,
      "grad_norm": 0.8032468557357788,
      "learning_rate": 4.611050668324526e-06,
      "loss": 0.5539,
      "step": 13869
    },
    {
      "epoch": 1.0778675784892757,
      "grad_norm": 0.6555387377738953,
      "learning_rate": 4.610662107553622e-06,
      "loss": 0.1857,
      "step": 13870
    },
    {
      "epoch": 1.0779452906434566,
      "grad_norm": 0.1494847536087036,
      "learning_rate": 4.610273546782717e-06,
      "loss": 0.0391,
      "step": 13871
    },
    {
      "epoch": 1.0780230027976376,
      "grad_norm": 0.11928530782461166,
      "learning_rate": 4.609884986011813e-06,
      "loss": 0.0514,
      "step": 13872
    },
    {
      "epoch": 1.0781007149518185,
      "grad_norm": 0.7526299357414246,
      "learning_rate": 4.609496425240908e-06,
      "loss": 0.096,
      "step": 13873
    },
    {
      "epoch": 1.0781784271059993,
      "grad_norm": 0.15385229885578156,
      "learning_rate": 4.6091078644700035e-06,
      "loss": 0.0067,
      "step": 13874
    },
    {
      "epoch": 1.0782561392601804,
      "grad_norm": 0.5845015645027161,
      "learning_rate": 4.608719303699099e-06,
      "loss": 0.2231,
      "step": 13875
    },
    {
      "epoch": 1.0783338514143612,
      "grad_norm": 0.20166677236557007,
      "learning_rate": 4.608330742928194e-06,
      "loss": 0.1,
      "step": 13876
    },
    {
      "epoch": 1.078411563568542,
      "grad_norm": 0.5855337977409363,
      "learning_rate": 4.607942182157289e-06,
      "loss": 0.1497,
      "step": 13877
    },
    {
      "epoch": 1.0784892757227231,
      "grad_norm": 0.22353194653987885,
      "learning_rate": 4.607553621386385e-06,
      "loss": 0.0896,
      "step": 13878
    },
    {
      "epoch": 1.078566987876904,
      "grad_norm": 0.08924607932567596,
      "learning_rate": 4.607165060615481e-06,
      "loss": 0.0281,
      "step": 13879
    },
    {
      "epoch": 1.0786447000310848,
      "grad_norm": 1.171713948249817,
      "learning_rate": 4.606776499844577e-06,
      "loss": 0.7091,
      "step": 13880
    },
    {
      "epoch": 1.0787224121852659,
      "grad_norm": 0.29604682326316833,
      "learning_rate": 4.6063879390736716e-06,
      "loss": 0.0746,
      "step": 13881
    },
    {
      "epoch": 1.0788001243394467,
      "grad_norm": 0.39769247174263,
      "learning_rate": 4.6059993783027665e-06,
      "loss": 0.2501,
      "step": 13882
    },
    {
      "epoch": 1.0788778364936276,
      "grad_norm": 0.18103447556495667,
      "learning_rate": 4.605610817531862e-06,
      "loss": 0.0572,
      "step": 13883
    },
    {
      "epoch": 1.0789555486478086,
      "grad_norm": 0.4475034773349762,
      "learning_rate": 4.605222256760958e-06,
      "loss": 0.2219,
      "step": 13884
    },
    {
      "epoch": 1.0790332608019895,
      "grad_norm": 0.27850764989852905,
      "learning_rate": 4.604833695990053e-06,
      "loss": 0.1467,
      "step": 13885
    },
    {
      "epoch": 1.0791109729561703,
      "grad_norm": 2.0104939937591553,
      "learning_rate": 4.604445135219149e-06,
      "loss": 0.5766,
      "step": 13886
    },
    {
      "epoch": 1.0791886851103514,
      "grad_norm": 0.37980297207832336,
      "learning_rate": 4.604056574448244e-06,
      "loss": 0.0547,
      "step": 13887
    },
    {
      "epoch": 1.0792663972645322,
      "grad_norm": 0.22812630236148834,
      "learning_rate": 4.60366801367734e-06,
      "loss": 0.0848,
      "step": 13888
    },
    {
      "epoch": 1.079344109418713,
      "grad_norm": 0.20484009385108948,
      "learning_rate": 4.603279452906435e-06,
      "loss": 0.1127,
      "step": 13889
    },
    {
      "epoch": 1.079421821572894,
      "grad_norm": 0.3436432182788849,
      "learning_rate": 4.60289089213553e-06,
      "loss": 0.1095,
      "step": 13890
    },
    {
      "epoch": 1.079499533727075,
      "grad_norm": 0.600892186164856,
      "learning_rate": 4.602502331364625e-06,
      "loss": 0.368,
      "step": 13891
    },
    {
      "epoch": 1.0795772458812558,
      "grad_norm": 0.09813183546066284,
      "learning_rate": 4.602113770593721e-06,
      "loss": 0.0092,
      "step": 13892
    },
    {
      "epoch": 1.0796549580354367,
      "grad_norm": 0.5161078572273254,
      "learning_rate": 4.601725209822817e-06,
      "loss": 0.7004,
      "step": 13893
    },
    {
      "epoch": 1.0797326701896177,
      "grad_norm": 0.5357189774513245,
      "learning_rate": 4.601336649051913e-06,
      "loss": 0.0585,
      "step": 13894
    },
    {
      "epoch": 1.0798103823437986,
      "grad_norm": 0.4485713541507721,
      "learning_rate": 4.600948088281008e-06,
      "loss": 0.5823,
      "step": 13895
    },
    {
      "epoch": 1.0798880944979794,
      "grad_norm": 0.021983318030834198,
      "learning_rate": 4.600559527510103e-06,
      "loss": 0.0048,
      "step": 13896
    },
    {
      "epoch": 1.0799658066521605,
      "grad_norm": 0.31210169196128845,
      "learning_rate": 4.600170966739198e-06,
      "loss": 0.0725,
      "step": 13897
    },
    {
      "epoch": 1.0800435188063413,
      "grad_norm": 0.32319632172584534,
      "learning_rate": 4.599782405968294e-06,
      "loss": 0.1367,
      "step": 13898
    },
    {
      "epoch": 1.0801212309605221,
      "grad_norm": 0.28340497612953186,
      "learning_rate": 4.599393845197389e-06,
      "loss": 0.0458,
      "step": 13899
    },
    {
      "epoch": 1.0801989431147032,
      "grad_norm": 0.3589819073677063,
      "learning_rate": 4.599005284426485e-06,
      "loss": 0.1182,
      "step": 13900
    },
    {
      "epoch": 1.080276655268884,
      "grad_norm": 0.43681490421295166,
      "learning_rate": 4.59861672365558e-06,
      "loss": 0.1024,
      "step": 13901
    },
    {
      "epoch": 1.080354367423065,
      "grad_norm": 0.39129185676574707,
      "learning_rate": 4.598228162884676e-06,
      "loss": 0.0471,
      "step": 13902
    },
    {
      "epoch": 1.080432079577246,
      "grad_norm": 0.6198441982269287,
      "learning_rate": 4.5978396021137715e-06,
      "loss": 0.7593,
      "step": 13903
    },
    {
      "epoch": 1.0805097917314268,
      "grad_norm": 0.23494230210781097,
      "learning_rate": 4.5974510413428664e-06,
      "loss": 0.0773,
      "step": 13904
    },
    {
      "epoch": 1.0805875038856076,
      "grad_norm": 0.7337759137153625,
      "learning_rate": 4.597062480571961e-06,
      "loss": 0.1727,
      "step": 13905
    },
    {
      "epoch": 1.0806652160397887,
      "grad_norm": 0.34211158752441406,
      "learning_rate": 4.596673919801057e-06,
      "loss": 0.0545,
      "step": 13906
    },
    {
      "epoch": 1.0807429281939696,
      "grad_norm": 0.5128802061080933,
      "learning_rate": 4.596285359030153e-06,
      "loss": 0.1148,
      "step": 13907
    },
    {
      "epoch": 1.0808206403481504,
      "grad_norm": 0.7185108661651611,
      "learning_rate": 4.595896798259249e-06,
      "loss": 0.7494,
      "step": 13908
    },
    {
      "epoch": 1.0808983525023315,
      "grad_norm": 0.16765539348125458,
      "learning_rate": 4.595508237488344e-06,
      "loss": 0.0339,
      "step": 13909
    },
    {
      "epoch": 1.0809760646565123,
      "grad_norm": 0.5661486983299255,
      "learning_rate": 4.595119676717439e-06,
      "loss": 0.0972,
      "step": 13910
    },
    {
      "epoch": 1.0810537768106931,
      "grad_norm": 0.6199942231178284,
      "learning_rate": 4.5947311159465345e-06,
      "loss": 0.2566,
      "step": 13911
    },
    {
      "epoch": 1.0811314889648742,
      "grad_norm": 0.32504206895828247,
      "learning_rate": 4.59434255517563e-06,
      "loss": 0.1519,
      "step": 13912
    },
    {
      "epoch": 1.081209201119055,
      "grad_norm": 0.08535976707935333,
      "learning_rate": 4.593953994404725e-06,
      "loss": 0.0142,
      "step": 13913
    },
    {
      "epoch": 1.081286913273236,
      "grad_norm": 0.3089738190174103,
      "learning_rate": 4.593565433633821e-06,
      "loss": 0.1716,
      "step": 13914
    },
    {
      "epoch": 1.0813646254274167,
      "grad_norm": 0.5889770984649658,
      "learning_rate": 4.593176872862916e-06,
      "loss": 0.1894,
      "step": 13915
    },
    {
      "epoch": 1.0814423375815978,
      "grad_norm": 0.432510107755661,
      "learning_rate": 4.592788312092012e-06,
      "loss": 0.2258,
      "step": 13916
    },
    {
      "epoch": 1.0815200497357786,
      "grad_norm": 0.19082874059677124,
      "learning_rate": 4.5923997513211076e-06,
      "loss": 0.068,
      "step": 13917
    },
    {
      "epoch": 1.0815977618899595,
      "grad_norm": 0.25241410732269287,
      "learning_rate": 4.5920111905502025e-06,
      "loss": 0.1128,
      "step": 13918
    },
    {
      "epoch": 1.0816754740441406,
      "grad_norm": 0.6109176874160767,
      "learning_rate": 4.5916226297792975e-06,
      "loss": 0.196,
      "step": 13919
    },
    {
      "epoch": 1.0817531861983214,
      "grad_norm": 0.15013271570205688,
      "learning_rate": 4.591234069008393e-06,
      "loss": 0.0242,
      "step": 13920
    },
    {
      "epoch": 1.0818308983525022,
      "grad_norm": 0.5525215268135071,
      "learning_rate": 4.590845508237489e-06,
      "loss": 0.2079,
      "step": 13921
    },
    {
      "epoch": 1.0819086105066833,
      "grad_norm": 0.13885851204395294,
      "learning_rate": 4.590456947466584e-06,
      "loss": 0.0762,
      "step": 13922
    },
    {
      "epoch": 1.0819863226608641,
      "grad_norm": 0.26034408807754517,
      "learning_rate": 4.59006838669568e-06,
      "loss": 0.2299,
      "step": 13923
    },
    {
      "epoch": 1.082064034815045,
      "grad_norm": 0.3542347848415375,
      "learning_rate": 4.589679825924775e-06,
      "loss": 0.1122,
      "step": 13924
    },
    {
      "epoch": 1.082141746969226,
      "grad_norm": 1.106028437614441,
      "learning_rate": 4.5892912651538705e-06,
      "loss": 0.5489,
      "step": 13925
    },
    {
      "epoch": 1.082219459123407,
      "grad_norm": 0.38931670784950256,
      "learning_rate": 4.588902704382966e-06,
      "loss": 0.0972,
      "step": 13926
    },
    {
      "epoch": 1.0822971712775877,
      "grad_norm": 0.11523877829313278,
      "learning_rate": 4.588514143612061e-06,
      "loss": 0.0615,
      "step": 13927
    },
    {
      "epoch": 1.0823748834317688,
      "grad_norm": 0.5815200209617615,
      "learning_rate": 4.588125582841157e-06,
      "loss": 0.3481,
      "step": 13928
    },
    {
      "epoch": 1.0824525955859496,
      "grad_norm": 0.2771080434322357,
      "learning_rate": 4.587737022070252e-06,
      "loss": 0.1266,
      "step": 13929
    },
    {
      "epoch": 1.0825303077401305,
      "grad_norm": 0.39551258087158203,
      "learning_rate": 4.587348461299348e-06,
      "loss": 0.1347,
      "step": 13930
    },
    {
      "epoch": 1.0826080198943115,
      "grad_norm": 0.43207329511642456,
      "learning_rate": 4.586959900528443e-06,
      "loss": 0.0796,
      "step": 13931
    },
    {
      "epoch": 1.0826857320484924,
      "grad_norm": 0.2835339307785034,
      "learning_rate": 4.586571339757539e-06,
      "loss": 0.0669,
      "step": 13932
    },
    {
      "epoch": 1.0827634442026732,
      "grad_norm": 0.17429080605506897,
      "learning_rate": 4.5861827789866335e-06,
      "loss": 0.0459,
      "step": 13933
    },
    {
      "epoch": 1.0828411563568543,
      "grad_norm": 0.3390088379383087,
      "learning_rate": 4.585794218215729e-06,
      "loss": 0.1049,
      "step": 13934
    },
    {
      "epoch": 1.0829188685110351,
      "grad_norm": 0.36915433406829834,
      "learning_rate": 4.585405657444824e-06,
      "loss": 0.2118,
      "step": 13935
    },
    {
      "epoch": 1.082996580665216,
      "grad_norm": 0.46072033047676086,
      "learning_rate": 4.58501709667392e-06,
      "loss": 0.2112,
      "step": 13936
    },
    {
      "epoch": 1.083074292819397,
      "grad_norm": 0.13922688364982605,
      "learning_rate": 4.584628535903016e-06,
      "loss": 0.0467,
      "step": 13937
    },
    {
      "epoch": 1.0831520049735779,
      "grad_norm": 1.4142866134643555,
      "learning_rate": 4.584239975132111e-06,
      "loss": 0.556,
      "step": 13938
    },
    {
      "epoch": 1.0832297171277587,
      "grad_norm": 0.17180459201335907,
      "learning_rate": 4.583851414361207e-06,
      "loss": 0.0237,
      "step": 13939
    },
    {
      "epoch": 1.0833074292819398,
      "grad_norm": 0.837683916091919,
      "learning_rate": 4.5834628535903016e-06,
      "loss": 0.3696,
      "step": 13940
    },
    {
      "epoch": 1.0833851414361206,
      "grad_norm": 0.21313433349132538,
      "learning_rate": 4.583074292819397e-06,
      "loss": 0.0612,
      "step": 13941
    },
    {
      "epoch": 1.0834628535903015,
      "grad_norm": 0.5871248245239258,
      "learning_rate": 4.582685732048493e-06,
      "loss": 0.1685,
      "step": 13942
    },
    {
      "epoch": 1.0835405657444825,
      "grad_norm": 0.2944983243942261,
      "learning_rate": 4.582297171277588e-06,
      "loss": 0.0766,
      "step": 13943
    },
    {
      "epoch": 1.0836182778986634,
      "grad_norm": 0.5745618939399719,
      "learning_rate": 4.581908610506683e-06,
      "loss": 0.2171,
      "step": 13944
    },
    {
      "epoch": 1.0836959900528442,
      "grad_norm": 1.0102959871292114,
      "learning_rate": 4.581520049735779e-06,
      "loss": 0.5854,
      "step": 13945
    },
    {
      "epoch": 1.0837737022070253,
      "grad_norm": 0.3321191668510437,
      "learning_rate": 4.581131488964875e-06,
      "loss": 0.112,
      "step": 13946
    },
    {
      "epoch": 1.0838514143612061,
      "grad_norm": 0.14305755496025085,
      "learning_rate": 4.58074292819397e-06,
      "loss": 0.0282,
      "step": 13947
    },
    {
      "epoch": 1.083929126515387,
      "grad_norm": 0.24649913609027863,
      "learning_rate": 4.580354367423065e-06,
      "loss": 0.1666,
      "step": 13948
    },
    {
      "epoch": 1.0840068386695678,
      "grad_norm": 0.2445124238729477,
      "learning_rate": 4.57996580665216e-06,
      "loss": 0.0514,
      "step": 13949
    },
    {
      "epoch": 1.0840845508237489,
      "grad_norm": 0.825761616230011,
      "learning_rate": 4.579577245881256e-06,
      "loss": 0.0742,
      "step": 13950
    },
    {
      "epoch": 1.0841622629779297,
      "grad_norm": 0.563025176525116,
      "learning_rate": 4.579188685110352e-06,
      "loss": 0.197,
      "step": 13951
    },
    {
      "epoch": 1.0842399751321106,
      "grad_norm": 0.20752552151679993,
      "learning_rate": 4.578800124339447e-06,
      "loss": 0.109,
      "step": 13952
    },
    {
      "epoch": 1.0843176872862916,
      "grad_norm": 0.3580739200115204,
      "learning_rate": 4.578411563568543e-06,
      "loss": 0.1668,
      "step": 13953
    },
    {
      "epoch": 1.0843953994404725,
      "grad_norm": 0.42726078629493713,
      "learning_rate": 4.578023002797638e-06,
      "loss": 0.142,
      "step": 13954
    },
    {
      "epoch": 1.0844731115946533,
      "grad_norm": 0.6004952788352966,
      "learning_rate": 4.5776344420267334e-06,
      "loss": 0.0853,
      "step": 13955
    },
    {
      "epoch": 1.0845508237488344,
      "grad_norm": 0.13216020166873932,
      "learning_rate": 4.577245881255829e-06,
      "loss": 0.0425,
      "step": 13956
    },
    {
      "epoch": 1.0846285359030152,
      "grad_norm": 0.6530044078826904,
      "learning_rate": 4.576857320484924e-06,
      "loss": 0.1289,
      "step": 13957
    },
    {
      "epoch": 1.084706248057196,
      "grad_norm": 0.32833096385002136,
      "learning_rate": 4.576468759714019e-06,
      "loss": 0.1949,
      "step": 13958
    },
    {
      "epoch": 1.0847839602113771,
      "grad_norm": 0.3830203115940094,
      "learning_rate": 4.576080198943115e-06,
      "loss": 0.2796,
      "step": 13959
    },
    {
      "epoch": 1.084861672365558,
      "grad_norm": 0.6481932997703552,
      "learning_rate": 4.575691638172211e-06,
      "loss": 0.2468,
      "step": 13960
    },
    {
      "epoch": 1.0849393845197388,
      "grad_norm": 0.6173075437545776,
      "learning_rate": 4.575303077401306e-06,
      "loss": 0.2351,
      "step": 13961
    },
    {
      "epoch": 1.0850170966739199,
      "grad_norm": 0.5360580682754517,
      "learning_rate": 4.5749145166304015e-06,
      "loss": 0.6729,
      "step": 13962
    },
    {
      "epoch": 1.0850948088281007,
      "grad_norm": 1.2699565887451172,
      "learning_rate": 4.574525955859496e-06,
      "loss": 0.3118,
      "step": 13963
    },
    {
      "epoch": 1.0851725209822816,
      "grad_norm": 0.5885075330734253,
      "learning_rate": 4.574137395088592e-06,
      "loss": 0.1233,
      "step": 13964
    },
    {
      "epoch": 1.0852502331364626,
      "grad_norm": 0.27566805481910706,
      "learning_rate": 4.573748834317688e-06,
      "loss": 0.1022,
      "step": 13965
    },
    {
      "epoch": 1.0853279452906435,
      "grad_norm": 0.5934941172599792,
      "learning_rate": 4.573360273546783e-06,
      "loss": 0.4131,
      "step": 13966
    },
    {
      "epoch": 1.0854056574448243,
      "grad_norm": 0.18059593439102173,
      "learning_rate": 4.572971712775878e-06,
      "loss": 0.0555,
      "step": 13967
    },
    {
      "epoch": 1.0854833695990054,
      "grad_norm": 0.41032713651657104,
      "learning_rate": 4.572583152004974e-06,
      "loss": 0.286,
      "step": 13968
    },
    {
      "epoch": 1.0855610817531862,
      "grad_norm": 1.2080589532852173,
      "learning_rate": 4.5721945912340695e-06,
      "loss": 0.3504,
      "step": 13969
    },
    {
      "epoch": 1.085638793907367,
      "grad_norm": 0.1898004114627838,
      "learning_rate": 4.571806030463165e-06,
      "loss": 0.0275,
      "step": 13970
    },
    {
      "epoch": 1.0857165060615481,
      "grad_norm": 0.2597126066684723,
      "learning_rate": 4.57141746969226e-06,
      "loss": 0.1909,
      "step": 13971
    },
    {
      "epoch": 1.085794218215729,
      "grad_norm": 0.3159542381763458,
      "learning_rate": 4.571028908921355e-06,
      "loss": 0.1334,
      "step": 13972
    },
    {
      "epoch": 1.0858719303699098,
      "grad_norm": 0.23027917742729187,
      "learning_rate": 4.570640348150451e-06,
      "loss": 0.091,
      "step": 13973
    },
    {
      "epoch": 1.0859496425240907,
      "grad_norm": 0.4430944323539734,
      "learning_rate": 4.570251787379547e-06,
      "loss": 0.2398,
      "step": 13974
    },
    {
      "epoch": 1.0860273546782717,
      "grad_norm": 0.5634852647781372,
      "learning_rate": 4.569863226608642e-06,
      "loss": 0.1448,
      "step": 13975
    },
    {
      "epoch": 1.0861050668324526,
      "grad_norm": 0.6328558921813965,
      "learning_rate": 4.5694746658377375e-06,
      "loss": 0.4106,
      "step": 13976
    },
    {
      "epoch": 1.0861827789866334,
      "grad_norm": 0.16578631103038788,
      "learning_rate": 4.5690861050668325e-06,
      "loss": 0.0081,
      "step": 13977
    },
    {
      "epoch": 1.0862604911408145,
      "grad_norm": 0.2730977535247803,
      "learning_rate": 4.568697544295928e-06,
      "loss": 0.0427,
      "step": 13978
    },
    {
      "epoch": 1.0863382032949953,
      "grad_norm": 0.5471938252449036,
      "learning_rate": 4.568308983525024e-06,
      "loss": 0.1911,
      "step": 13979
    },
    {
      "epoch": 1.0864159154491762,
      "grad_norm": 0.23832064867019653,
      "learning_rate": 4.567920422754119e-06,
      "loss": 0.0579,
      "step": 13980
    },
    {
      "epoch": 1.0864936276033572,
      "grad_norm": 0.5636162161827087,
      "learning_rate": 4.567531861983214e-06,
      "loss": 0.267,
      "step": 13981
    },
    {
      "epoch": 1.086571339757538,
      "grad_norm": 0.1780943125486374,
      "learning_rate": 4.56714330121231e-06,
      "loss": 0.0865,
      "step": 13982
    },
    {
      "epoch": 1.086649051911719,
      "grad_norm": 0.6091588735580444,
      "learning_rate": 4.566754740441406e-06,
      "loss": 0.2756,
      "step": 13983
    },
    {
      "epoch": 1.0867267640659,
      "grad_norm": 0.40235722064971924,
      "learning_rate": 4.566366179670501e-06,
      "loss": 0.2154,
      "step": 13984
    },
    {
      "epoch": 1.0868044762200808,
      "grad_norm": 0.2819291353225708,
      "learning_rate": 4.565977618899596e-06,
      "loss": 0.0603,
      "step": 13985
    },
    {
      "epoch": 1.0868821883742616,
      "grad_norm": 0.5478025674819946,
      "learning_rate": 4.565589058128691e-06,
      "loss": 0.2557,
      "step": 13986
    },
    {
      "epoch": 1.0869599005284427,
      "grad_norm": 0.6863839626312256,
      "learning_rate": 4.565200497357787e-06,
      "loss": 0.1229,
      "step": 13987
    },
    {
      "epoch": 1.0870376126826236,
      "grad_norm": 0.41639071702957153,
      "learning_rate": 4.564811936586883e-06,
      "loss": 0.3358,
      "step": 13988
    },
    {
      "epoch": 1.0871153248368044,
      "grad_norm": 0.07803072035312653,
      "learning_rate": 4.564423375815978e-06,
      "loss": 0.022,
      "step": 13989
    },
    {
      "epoch": 1.0871930369909855,
      "grad_norm": 0.019426731392741203,
      "learning_rate": 4.564034815045074e-06,
      "loss": 0.0031,
      "step": 13990
    },
    {
      "epoch": 1.0872707491451663,
      "grad_norm": 0.4157832860946655,
      "learning_rate": 4.5636462542741686e-06,
      "loss": 0.3717,
      "step": 13991
    },
    {
      "epoch": 1.0873484612993471,
      "grad_norm": 0.44191744923591614,
      "learning_rate": 4.563257693503264e-06,
      "loss": 0.1238,
      "step": 13992
    },
    {
      "epoch": 1.0874261734535282,
      "grad_norm": 0.44792306423187256,
      "learning_rate": 4.56286913273236e-06,
      "loss": 0.1757,
      "step": 13993
    },
    {
      "epoch": 1.087503885607709,
      "grad_norm": 0.3858422338962555,
      "learning_rate": 4.562480571961455e-06,
      "loss": 0.2917,
      "step": 13994
    },
    {
      "epoch": 1.08758159776189,
      "grad_norm": 1.1568716764450073,
      "learning_rate": 4.56209201119055e-06,
      "loss": 0.3986,
      "step": 13995
    },
    {
      "epoch": 1.087659309916071,
      "grad_norm": 0.5284505486488342,
      "learning_rate": 4.561703450419646e-06,
      "loss": 0.082,
      "step": 13996
    },
    {
      "epoch": 1.0877370220702518,
      "grad_norm": 0.6434422135353088,
      "learning_rate": 4.561314889648742e-06,
      "loss": 0.2198,
      "step": 13997
    },
    {
      "epoch": 1.0878147342244326,
      "grad_norm": 0.6266769766807556,
      "learning_rate": 4.560926328877837e-06,
      "loss": 0.2248,
      "step": 13998
    },
    {
      "epoch": 1.0878924463786137,
      "grad_norm": 0.3821637034416199,
      "learning_rate": 4.560537768106932e-06,
      "loss": 0.1545,
      "step": 13999
    },
    {
      "epoch": 1.0879701585327946,
      "grad_norm": 0.3950881361961365,
      "learning_rate": 4.560149207336027e-06,
      "loss": 0.172,
      "step": 14000
    },
    {
      "epoch": 1.0880478706869754,
      "grad_norm": 0.5974242687225342,
      "learning_rate": 4.559760646565123e-06,
      "loss": 0.6459,
      "step": 14001
    },
    {
      "epoch": 1.0881255828411565,
      "grad_norm": 0.38866621255874634,
      "learning_rate": 4.559372085794219e-06,
      "loss": 0.1779,
      "step": 14002
    },
    {
      "epoch": 1.0882032949953373,
      "grad_norm": 0.20460893213748932,
      "learning_rate": 4.558983525023314e-06,
      "loss": 0.0387,
      "step": 14003
    },
    {
      "epoch": 1.0882810071495181,
      "grad_norm": 0.2626895010471344,
      "learning_rate": 4.55859496425241e-06,
      "loss": 0.0974,
      "step": 14004
    },
    {
      "epoch": 1.0883587193036992,
      "grad_norm": 0.7198017835617065,
      "learning_rate": 4.558206403481505e-06,
      "loss": 0.2735,
      "step": 14005
    },
    {
      "epoch": 1.08843643145788,
      "grad_norm": 0.20249558985233307,
      "learning_rate": 4.5578178427106004e-06,
      "loss": 0.0481,
      "step": 14006
    },
    {
      "epoch": 1.088514143612061,
      "grad_norm": 0.7452986836433411,
      "learning_rate": 4.557429281939696e-06,
      "loss": 0.276,
      "step": 14007
    },
    {
      "epoch": 1.088591855766242,
      "grad_norm": 0.15465858578681946,
      "learning_rate": 4.557040721168791e-06,
      "loss": 0.0509,
      "step": 14008
    },
    {
      "epoch": 1.0886695679204228,
      "grad_norm": 0.28233835101127625,
      "learning_rate": 4.556652160397886e-06,
      "loss": 0.093,
      "step": 14009
    },
    {
      "epoch": 1.0887472800746036,
      "grad_norm": 0.4479075074195862,
      "learning_rate": 4.556263599626982e-06,
      "loss": 0.1583,
      "step": 14010
    },
    {
      "epoch": 1.0888249922287845,
      "grad_norm": 0.21720801293849945,
      "learning_rate": 4.555875038856078e-06,
      "loss": 0.0713,
      "step": 14011
    },
    {
      "epoch": 1.0889027043829655,
      "grad_norm": 0.4101215600967407,
      "learning_rate": 4.555486478085173e-06,
      "loss": 0.2448,
      "step": 14012
    },
    {
      "epoch": 1.0889804165371464,
      "grad_norm": 0.6210959553718567,
      "learning_rate": 4.5550979173142685e-06,
      "loss": 0.3492,
      "step": 14013
    },
    {
      "epoch": 1.0890581286913272,
      "grad_norm": 0.5334618091583252,
      "learning_rate": 4.554709356543363e-06,
      "loss": 0.1688,
      "step": 14014
    },
    {
      "epoch": 1.0891358408455083,
      "grad_norm": 0.188728466629982,
      "learning_rate": 4.554320795772459e-06,
      "loss": 0.0447,
      "step": 14015
    },
    {
      "epoch": 1.0892135529996891,
      "grad_norm": 0.5626236200332642,
      "learning_rate": 4.553932235001555e-06,
      "loss": 0.1162,
      "step": 14016
    },
    {
      "epoch": 1.08929126515387,
      "grad_norm": 1.151667833328247,
      "learning_rate": 4.55354367423065e-06,
      "loss": 0.3706,
      "step": 14017
    },
    {
      "epoch": 1.089368977308051,
      "grad_norm": 0.5242443680763245,
      "learning_rate": 4.553155113459746e-06,
      "loss": 0.2321,
      "step": 14018
    },
    {
      "epoch": 1.0894466894622319,
      "grad_norm": 0.043224986642599106,
      "learning_rate": 4.552766552688841e-06,
      "loss": 0.005,
      "step": 14019
    },
    {
      "epoch": 1.0895244016164127,
      "grad_norm": 1.630022406578064,
      "learning_rate": 4.5523779919179365e-06,
      "loss": 0.1711,
      "step": 14020
    },
    {
      "epoch": 1.0896021137705938,
      "grad_norm": 0.5536898970603943,
      "learning_rate": 4.551989431147032e-06,
      "loss": 0.2306,
      "step": 14021
    },
    {
      "epoch": 1.0896798259247746,
      "grad_norm": 0.35783499479293823,
      "learning_rate": 4.551600870376127e-06,
      "loss": 0.1185,
      "step": 14022
    },
    {
      "epoch": 1.0897575380789555,
      "grad_norm": 0.6254439353942871,
      "learning_rate": 4.551212309605222e-06,
      "loss": 0.4623,
      "step": 14023
    },
    {
      "epoch": 1.0898352502331365,
      "grad_norm": 0.10074015706777573,
      "learning_rate": 4.550823748834318e-06,
      "loss": 0.0449,
      "step": 14024
    },
    {
      "epoch": 1.0899129623873174,
      "grad_norm": 0.38766297698020935,
      "learning_rate": 4.550435188063414e-06,
      "loss": 0.2557,
      "step": 14025
    },
    {
      "epoch": 1.0899906745414982,
      "grad_norm": 0.18591605126857758,
      "learning_rate": 4.550046627292509e-06,
      "loss": 0.0852,
      "step": 14026
    },
    {
      "epoch": 1.0900683866956793,
      "grad_norm": 0.49479520320892334,
      "learning_rate": 4.5496580665216045e-06,
      "loss": 0.1709,
      "step": 14027
    },
    {
      "epoch": 1.0901460988498601,
      "grad_norm": 0.40957728028297424,
      "learning_rate": 4.5492695057506995e-06,
      "loss": 0.1638,
      "step": 14028
    },
    {
      "epoch": 1.090223811004041,
      "grad_norm": 0.611545979976654,
      "learning_rate": 4.548880944979795e-06,
      "loss": 0.5637,
      "step": 14029
    },
    {
      "epoch": 1.090301523158222,
      "grad_norm": 0.40313437581062317,
      "learning_rate": 4.548492384208891e-06,
      "loss": 0.1659,
      "step": 14030
    },
    {
      "epoch": 1.0903792353124029,
      "grad_norm": 0.26798948645591736,
      "learning_rate": 4.548103823437986e-06,
      "loss": 0.2851,
      "step": 14031
    },
    {
      "epoch": 1.0904569474665837,
      "grad_norm": 0.42870840430259705,
      "learning_rate": 4.547715262667082e-06,
      "loss": 0.2029,
      "step": 14032
    },
    {
      "epoch": 1.0905346596207648,
      "grad_norm": 0.33364561200141907,
      "learning_rate": 4.547326701896177e-06,
      "loss": 0.3164,
      "step": 14033
    },
    {
      "epoch": 1.0906123717749456,
      "grad_norm": 0.389133095741272,
      "learning_rate": 4.546938141125273e-06,
      "loss": 0.3,
      "step": 14034
    },
    {
      "epoch": 1.0906900839291265,
      "grad_norm": 0.18616048991680145,
      "learning_rate": 4.546549580354368e-06,
      "loss": 0.0382,
      "step": 14035
    },
    {
      "epoch": 1.0907677960833073,
      "grad_norm": 1.241580843925476,
      "learning_rate": 4.546161019583463e-06,
      "loss": 0.5872,
      "step": 14036
    },
    {
      "epoch": 1.0908455082374884,
      "grad_norm": 0.22594159841537476,
      "learning_rate": 4.545772458812558e-06,
      "loss": 0.0438,
      "step": 14037
    },
    {
      "epoch": 1.0909232203916692,
      "grad_norm": 0.10553465038537979,
      "learning_rate": 4.545383898041654e-06,
      "loss": 0.0086,
      "step": 14038
    },
    {
      "epoch": 1.09100093254585,
      "grad_norm": 0.6266276836395264,
      "learning_rate": 4.54499533727075e-06,
      "loss": 0.3788,
      "step": 14039
    },
    {
      "epoch": 1.0910786447000311,
      "grad_norm": 0.23854272067546844,
      "learning_rate": 4.544606776499845e-06,
      "loss": 0.092,
      "step": 14040
    },
    {
      "epoch": 1.091156356854212,
      "grad_norm": 0.31328532099723816,
      "learning_rate": 4.544218215728941e-06,
      "loss": 0.3322,
      "step": 14041
    },
    {
      "epoch": 1.0912340690083928,
      "grad_norm": 0.43631711602211,
      "learning_rate": 4.5438296549580356e-06,
      "loss": 0.2536,
      "step": 14042
    },
    {
      "epoch": 1.0913117811625739,
      "grad_norm": 0.591666579246521,
      "learning_rate": 4.543441094187131e-06,
      "loss": 0.2723,
      "step": 14043
    },
    {
      "epoch": 1.0913894933167547,
      "grad_norm": 1.0871031284332275,
      "learning_rate": 4.543052533416227e-06,
      "loss": 0.4407,
      "step": 14044
    },
    {
      "epoch": 1.0914672054709356,
      "grad_norm": 0.5188723802566528,
      "learning_rate": 4.542663972645322e-06,
      "loss": 0.1492,
      "step": 14045
    },
    {
      "epoch": 1.0915449176251166,
      "grad_norm": 0.2247360497713089,
      "learning_rate": 4.542275411874418e-06,
      "loss": 0.0649,
      "step": 14046
    },
    {
      "epoch": 1.0916226297792975,
      "grad_norm": 0.5252273082733154,
      "learning_rate": 4.541886851103513e-06,
      "loss": 0.1975,
      "step": 14047
    },
    {
      "epoch": 1.0917003419334783,
      "grad_norm": 0.2858177125453949,
      "learning_rate": 4.541498290332609e-06,
      "loss": 0.0703,
      "step": 14048
    },
    {
      "epoch": 1.0917780540876594,
      "grad_norm": 0.6556422114372253,
      "learning_rate": 4.5411097295617045e-06,
      "loss": 0.3922,
      "step": 14049
    },
    {
      "epoch": 1.0918557662418402,
      "grad_norm": 0.2316388040781021,
      "learning_rate": 4.540721168790799e-06,
      "loss": 0.1051,
      "step": 14050
    },
    {
      "epoch": 1.091933478396021,
      "grad_norm": 0.12458102405071259,
      "learning_rate": 4.540332608019894e-06,
      "loss": 0.035,
      "step": 14051
    },
    {
      "epoch": 1.0920111905502021,
      "grad_norm": 0.02398551069200039,
      "learning_rate": 4.53994404724899e-06,
      "loss": 0.0025,
      "step": 14052
    },
    {
      "epoch": 1.092088902704383,
      "grad_norm": 0.6349565982818604,
      "learning_rate": 4.539555486478086e-06,
      "loss": 0.0886,
      "step": 14053
    },
    {
      "epoch": 1.0921666148585638,
      "grad_norm": 0.11581117659807205,
      "learning_rate": 4.539166925707181e-06,
      "loss": 0.0151,
      "step": 14054
    },
    {
      "epoch": 1.0922443270127449,
      "grad_norm": 0.6955565810203552,
      "learning_rate": 4.538778364936277e-06,
      "loss": 0.2038,
      "step": 14055
    },
    {
      "epoch": 1.0923220391669257,
      "grad_norm": 0.5636018514633179,
      "learning_rate": 4.538389804165372e-06,
      "loss": 0.2578,
      "step": 14056
    },
    {
      "epoch": 1.0923997513211066,
      "grad_norm": 0.2769327461719513,
      "learning_rate": 4.538001243394467e-06,
      "loss": 0.0591,
      "step": 14057
    },
    {
      "epoch": 1.0924774634752876,
      "grad_norm": 0.15560567378997803,
      "learning_rate": 4.537612682623562e-06,
      "loss": 0.0209,
      "step": 14058
    },
    {
      "epoch": 1.0925551756294685,
      "grad_norm": 0.03623105585575104,
      "learning_rate": 4.537224121852658e-06,
      "loss": 0.0015,
      "step": 14059
    },
    {
      "epoch": 1.0926328877836493,
      "grad_norm": 0.5810868740081787,
      "learning_rate": 4.536835561081754e-06,
      "loss": 0.1335,
      "step": 14060
    },
    {
      "epoch": 1.0927105999378304,
      "grad_norm": 0.4140789806842804,
      "learning_rate": 4.536447000310849e-06,
      "loss": 0.1671,
      "step": 14061
    },
    {
      "epoch": 1.0927883120920112,
      "grad_norm": 0.6263158917427063,
      "learning_rate": 4.536058439539944e-06,
      "loss": 0.5157,
      "step": 14062
    },
    {
      "epoch": 1.092866024246192,
      "grad_norm": 0.5496960878372192,
      "learning_rate": 4.53566987876904e-06,
      "loss": 0.0737,
      "step": 14063
    },
    {
      "epoch": 1.0929437364003731,
      "grad_norm": 0.280382364988327,
      "learning_rate": 4.5352813179981355e-06,
      "loss": 0.1132,
      "step": 14064
    },
    {
      "epoch": 1.093021448554554,
      "grad_norm": 0.344204843044281,
      "learning_rate": 4.5348927572272304e-06,
      "loss": 0.2759,
      "step": 14065
    },
    {
      "epoch": 1.0930991607087348,
      "grad_norm": 0.3383041024208069,
      "learning_rate": 4.534504196456326e-06,
      "loss": 0.0624,
      "step": 14066
    },
    {
      "epoch": 1.0931768728629159,
      "grad_norm": 0.6686468720436096,
      "learning_rate": 4.534115635685421e-06,
      "loss": 0.1911,
      "step": 14067
    },
    {
      "epoch": 1.0932545850170967,
      "grad_norm": 0.18572668731212616,
      "learning_rate": 4.533727074914517e-06,
      "loss": 0.0467,
      "step": 14068
    },
    {
      "epoch": 1.0933322971712776,
      "grad_norm": 0.12089528143405914,
      "learning_rate": 4.533338514143613e-06,
      "loss": 0.0399,
      "step": 14069
    },
    {
      "epoch": 1.0934100093254584,
      "grad_norm": 0.49924248456954956,
      "learning_rate": 4.532949953372708e-06,
      "loss": 0.2016,
      "step": 14070
    },
    {
      "epoch": 1.0934877214796395,
      "grad_norm": 0.03521334007382393,
      "learning_rate": 4.532561392601803e-06,
      "loss": 0.0073,
      "step": 14071
    },
    {
      "epoch": 1.0935654336338203,
      "grad_norm": 0.5895162224769592,
      "learning_rate": 4.5321728318308985e-06,
      "loss": 0.2608,
      "step": 14072
    },
    {
      "epoch": 1.0936431457880011,
      "grad_norm": 0.5027669072151184,
      "learning_rate": 4.531784271059994e-06,
      "loss": 0.2097,
      "step": 14073
    },
    {
      "epoch": 1.0937208579421822,
      "grad_norm": 0.15435801446437836,
      "learning_rate": 4.531395710289089e-06,
      "loss": 0.1287,
      "step": 14074
    },
    {
      "epoch": 1.093798570096363,
      "grad_norm": 0.5387815833091736,
      "learning_rate": 4.531007149518185e-06,
      "loss": 0.3312,
      "step": 14075
    },
    {
      "epoch": 1.093876282250544,
      "grad_norm": 0.5114213228225708,
      "learning_rate": 4.53061858874728e-06,
      "loss": 0.0993,
      "step": 14076
    },
    {
      "epoch": 1.093953994404725,
      "grad_norm": 0.49825266003608704,
      "learning_rate": 4.530230027976376e-06,
      "loss": 0.1342,
      "step": 14077
    },
    {
      "epoch": 1.0940317065589058,
      "grad_norm": 0.22087623178958893,
      "learning_rate": 4.5298414672054715e-06,
      "loss": 0.0524,
      "step": 14078
    },
    {
      "epoch": 1.0941094187130866,
      "grad_norm": 0.8710477948188782,
      "learning_rate": 4.5294529064345665e-06,
      "loss": 0.5561,
      "step": 14079
    },
    {
      "epoch": 1.0941871308672677,
      "grad_norm": 0.26391732692718506,
      "learning_rate": 4.529064345663662e-06,
      "loss": 0.0588,
      "step": 14080
    },
    {
      "epoch": 1.0942648430214486,
      "grad_norm": 1.0343180894851685,
      "learning_rate": 4.528675784892757e-06,
      "loss": 0.9072,
      "step": 14081
    },
    {
      "epoch": 1.0943425551756294,
      "grad_norm": 0.26585984230041504,
      "learning_rate": 4.528287224121853e-06,
      "loss": 0.1348,
      "step": 14082
    },
    {
      "epoch": 1.0944202673298105,
      "grad_norm": 0.2929685711860657,
      "learning_rate": 4.527898663350949e-06,
      "loss": 0.1797,
      "step": 14083
    },
    {
      "epoch": 1.0944979794839913,
      "grad_norm": 0.39896997809410095,
      "learning_rate": 4.527510102580044e-06,
      "loss": 0.1664,
      "step": 14084
    },
    {
      "epoch": 1.0945756916381721,
      "grad_norm": 0.1478337198495865,
      "learning_rate": 4.527121541809139e-06,
      "loss": 0.0815,
      "step": 14085
    },
    {
      "epoch": 1.0946534037923532,
      "grad_norm": 0.7013683319091797,
      "learning_rate": 4.5267329810382345e-06,
      "loss": 0.1696,
      "step": 14086
    },
    {
      "epoch": 1.094731115946534,
      "grad_norm": 0.233002170920372,
      "learning_rate": 4.52634442026733e-06,
      "loss": 0.1322,
      "step": 14087
    },
    {
      "epoch": 1.094808828100715,
      "grad_norm": 0.7273681163787842,
      "learning_rate": 4.525955859496425e-06,
      "loss": 0.1127,
      "step": 14088
    },
    {
      "epoch": 1.094886540254896,
      "grad_norm": 0.5469421148300171,
      "learning_rate": 4.525567298725521e-06,
      "loss": 0.4462,
      "step": 14089
    },
    {
      "epoch": 1.0949642524090768,
      "grad_norm": 0.556350588798523,
      "learning_rate": 4.525178737954616e-06,
      "loss": 0.2286,
      "step": 14090
    },
    {
      "epoch": 1.0950419645632576,
      "grad_norm": 1.2499358654022217,
      "learning_rate": 4.524790177183712e-06,
      "loss": 0.4682,
      "step": 14091
    },
    {
      "epoch": 1.0951196767174387,
      "grad_norm": 0.1822042614221573,
      "learning_rate": 4.524401616412808e-06,
      "loss": 0.0659,
      "step": 14092
    },
    {
      "epoch": 1.0951973888716195,
      "grad_norm": 0.24564868211746216,
      "learning_rate": 4.5240130556419026e-06,
      "loss": 0.0356,
      "step": 14093
    },
    {
      "epoch": 1.0952751010258004,
      "grad_norm": 0.25394266843795776,
      "learning_rate": 4.523624494870998e-06,
      "loss": 0.0595,
      "step": 14094
    },
    {
      "epoch": 1.0953528131799812,
      "grad_norm": 0.6838034987449646,
      "learning_rate": 4.523235934100093e-06,
      "loss": 0.1959,
      "step": 14095
    },
    {
      "epoch": 1.0954305253341623,
      "grad_norm": 0.23274926841259003,
      "learning_rate": 4.522847373329189e-06,
      "loss": 0.1212,
      "step": 14096
    },
    {
      "epoch": 1.0955082374883431,
      "grad_norm": 0.32986223697662354,
      "learning_rate": 4.522458812558285e-06,
      "loss": 0.112,
      "step": 14097
    },
    {
      "epoch": 1.095585949642524,
      "grad_norm": 0.4214475154876709,
      "learning_rate": 4.52207025178738e-06,
      "loss": 0.1126,
      "step": 14098
    },
    {
      "epoch": 1.095663661796705,
      "grad_norm": 0.35866114497184753,
      "learning_rate": 4.521681691016475e-06,
      "loss": 0.1463,
      "step": 14099
    },
    {
      "epoch": 1.0957413739508859,
      "grad_norm": 0.2503665089607239,
      "learning_rate": 4.521293130245571e-06,
      "loss": 0.3052,
      "step": 14100
    },
    {
      "epoch": 1.0958190861050667,
      "grad_norm": 0.28690022230148315,
      "learning_rate": 4.520904569474666e-06,
      "loss": 0.0552,
      "step": 14101
    },
    {
      "epoch": 1.0958967982592478,
      "grad_norm": 0.181807741522789,
      "learning_rate": 4.520516008703761e-06,
      "loss": 0.1254,
      "step": 14102
    },
    {
      "epoch": 1.0959745104134286,
      "grad_norm": 0.5582306385040283,
      "learning_rate": 4.520127447932857e-06,
      "loss": 0.2369,
      "step": 14103
    },
    {
      "epoch": 1.0960522225676095,
      "grad_norm": 0.2652813494205475,
      "learning_rate": 4.519738887161952e-06,
      "loss": 0.0337,
      "step": 14104
    },
    {
      "epoch": 1.0961299347217905,
      "grad_norm": 0.6529055833816528,
      "learning_rate": 4.519350326391048e-06,
      "loss": 0.2324,
      "step": 14105
    },
    {
      "epoch": 1.0962076468759714,
      "grad_norm": 0.3173210918903351,
      "learning_rate": 4.518961765620144e-06,
      "loss": 0.0548,
      "step": 14106
    },
    {
      "epoch": 1.0962853590301522,
      "grad_norm": 0.6655540466308594,
      "learning_rate": 4.518573204849239e-06,
      "loss": 0.558,
      "step": 14107
    },
    {
      "epoch": 1.0963630711843333,
      "grad_norm": 0.05119026079773903,
      "learning_rate": 4.5181846440783344e-06,
      "loss": 0.0033,
      "step": 14108
    },
    {
      "epoch": 1.0964407833385141,
      "grad_norm": 1.116607666015625,
      "learning_rate": 4.517796083307429e-06,
      "loss": 0.3735,
      "step": 14109
    },
    {
      "epoch": 1.096518495492695,
      "grad_norm": 0.24195565283298492,
      "learning_rate": 4.517407522536525e-06,
      "loss": 0.3313,
      "step": 14110
    },
    {
      "epoch": 1.096596207646876,
      "grad_norm": 0.09019830077886581,
      "learning_rate": 4.517018961765621e-06,
      "loss": 0.025,
      "step": 14111
    },
    {
      "epoch": 1.0966739198010569,
      "grad_norm": 0.029124056920409203,
      "learning_rate": 4.516630400994716e-06,
      "loss": 0.0067,
      "step": 14112
    },
    {
      "epoch": 1.0967516319552377,
      "grad_norm": 0.4722024202346802,
      "learning_rate": 4.516241840223811e-06,
      "loss": 0.1206,
      "step": 14113
    },
    {
      "epoch": 1.0968293441094188,
      "grad_norm": 0.24313503503799438,
      "learning_rate": 4.515853279452907e-06,
      "loss": 0.0732,
      "step": 14114
    },
    {
      "epoch": 1.0969070562635996,
      "grad_norm": 1.0247173309326172,
      "learning_rate": 4.5154647186820025e-06,
      "loss": 0.5504,
      "step": 14115
    },
    {
      "epoch": 1.0969847684177805,
      "grad_norm": 0.47206911444664,
      "learning_rate": 4.5150761579110974e-06,
      "loss": 0.1865,
      "step": 14116
    },
    {
      "epoch": 1.0970624805719615,
      "grad_norm": 0.49793705344200134,
      "learning_rate": 4.514687597140193e-06,
      "loss": 0.2971,
      "step": 14117
    },
    {
      "epoch": 1.0971401927261424,
      "grad_norm": 0.49239400029182434,
      "learning_rate": 4.514299036369288e-06,
      "loss": 0.2943,
      "step": 14118
    },
    {
      "epoch": 1.0972179048803232,
      "grad_norm": 0.5241976380348206,
      "learning_rate": 4.513910475598384e-06,
      "loss": 0.1216,
      "step": 14119
    },
    {
      "epoch": 1.0972956170345043,
      "grad_norm": 0.3499637246131897,
      "learning_rate": 4.51352191482748e-06,
      "loss": 0.1702,
      "step": 14120
    },
    {
      "epoch": 1.0973733291886851,
      "grad_norm": 0.3802708685398102,
      "learning_rate": 4.513133354056575e-06,
      "loss": 0.0922,
      "step": 14121
    },
    {
      "epoch": 1.097451041342866,
      "grad_norm": 1.6713650226593018,
      "learning_rate": 4.5127447932856705e-06,
      "loss": 0.5929,
      "step": 14122
    },
    {
      "epoch": 1.097528753497047,
      "grad_norm": 0.5354219079017639,
      "learning_rate": 4.5123562325147655e-06,
      "loss": 0.2533,
      "step": 14123
    },
    {
      "epoch": 1.0976064656512279,
      "grad_norm": 0.3802655339241028,
      "learning_rate": 4.511967671743861e-06,
      "loss": 0.1395,
      "step": 14124
    },
    {
      "epoch": 1.0976841778054087,
      "grad_norm": 0.4188736081123352,
      "learning_rate": 4.511579110972957e-06,
      "loss": 0.2252,
      "step": 14125
    },
    {
      "epoch": 1.0977618899595898,
      "grad_norm": 0.16833895444869995,
      "learning_rate": 4.511190550202052e-06,
      "loss": 0.0259,
      "step": 14126
    },
    {
      "epoch": 1.0978396021137706,
      "grad_norm": 0.22421182692050934,
      "learning_rate": 4.510801989431147e-06,
      "loss": 0.0618,
      "step": 14127
    },
    {
      "epoch": 1.0979173142679515,
      "grad_norm": 0.14916464686393738,
      "learning_rate": 4.510413428660243e-06,
      "loss": 0.0259,
      "step": 14128
    },
    {
      "epoch": 1.0979950264221325,
      "grad_norm": 0.8346429467201233,
      "learning_rate": 4.5100248678893386e-06,
      "loss": 0.1531,
      "step": 14129
    },
    {
      "epoch": 1.0980727385763134,
      "grad_norm": 0.3988092541694641,
      "learning_rate": 4.5096363071184335e-06,
      "loss": 0.3286,
      "step": 14130
    },
    {
      "epoch": 1.0981504507304942,
      "grad_norm": 0.1419006735086441,
      "learning_rate": 4.509247746347529e-06,
      "loss": 0.0366,
      "step": 14131
    },
    {
      "epoch": 1.098228162884675,
      "grad_norm": 0.6772776246070862,
      "learning_rate": 4.508859185576624e-06,
      "loss": 0.2412,
      "step": 14132
    },
    {
      "epoch": 1.0983058750388561,
      "grad_norm": 0.07270066440105438,
      "learning_rate": 4.50847062480572e-06,
      "loss": 0.0342,
      "step": 14133
    },
    {
      "epoch": 1.098383587193037,
      "grad_norm": 0.22963982820510864,
      "learning_rate": 4.508082064034816e-06,
      "loss": 0.0951,
      "step": 14134
    },
    {
      "epoch": 1.0984612993472178,
      "grad_norm": 0.5694887042045593,
      "learning_rate": 4.507693503263911e-06,
      "loss": 0.3523,
      "step": 14135
    },
    {
      "epoch": 1.0985390115013989,
      "grad_norm": 0.23849307000637054,
      "learning_rate": 4.507304942493007e-06,
      "loss": 0.0973,
      "step": 14136
    },
    {
      "epoch": 1.0986167236555797,
      "grad_norm": 0.33086884021759033,
      "learning_rate": 4.5069163817221015e-06,
      "loss": 0.0944,
      "step": 14137
    },
    {
      "epoch": 1.0986944358097606,
      "grad_norm": 0.2593553364276886,
      "learning_rate": 4.506527820951197e-06,
      "loss": 0.1974,
      "step": 14138
    },
    {
      "epoch": 1.0987721479639416,
      "grad_norm": 0.3676043748855591,
      "learning_rate": 4.506139260180293e-06,
      "loss": 0.1218,
      "step": 14139
    },
    {
      "epoch": 1.0988498601181225,
      "grad_norm": 0.7035354971885681,
      "learning_rate": 4.505750699409388e-06,
      "loss": 0.1662,
      "step": 14140
    },
    {
      "epoch": 1.0989275722723033,
      "grad_norm": 0.3404117226600647,
      "learning_rate": 4.505362138638483e-06,
      "loss": 0.1011,
      "step": 14141
    },
    {
      "epoch": 1.0990052844264844,
      "grad_norm": 0.5041955709457397,
      "learning_rate": 4.504973577867579e-06,
      "loss": 0.4857,
      "step": 14142
    },
    {
      "epoch": 1.0990829965806652,
      "grad_norm": 0.13129906356334686,
      "learning_rate": 4.504585017096675e-06,
      "loss": 0.0264,
      "step": 14143
    },
    {
      "epoch": 1.099160708734846,
      "grad_norm": 0.23765790462493896,
      "learning_rate": 4.5041964563257696e-06,
      "loss": 0.0692,
      "step": 14144
    },
    {
      "epoch": 1.0992384208890271,
      "grad_norm": 0.4924631118774414,
      "learning_rate": 4.503807895554865e-06,
      "loss": 0.2669,
      "step": 14145
    },
    {
      "epoch": 1.099316133043208,
      "grad_norm": 0.33109769225120544,
      "learning_rate": 4.50341933478396e-06,
      "loss": 0.1389,
      "step": 14146
    },
    {
      "epoch": 1.0993938451973888,
      "grad_norm": 0.6908568143844604,
      "learning_rate": 4.503030774013056e-06,
      "loss": 0.1498,
      "step": 14147
    },
    {
      "epoch": 1.0994715573515699,
      "grad_norm": 0.3752423822879791,
      "learning_rate": 4.502642213242152e-06,
      "loss": 0.1623,
      "step": 14148
    },
    {
      "epoch": 1.0995492695057507,
      "grad_norm": 0.5048731565475464,
      "learning_rate": 4.502253652471247e-06,
      "loss": 0.2994,
      "step": 14149
    },
    {
      "epoch": 1.0996269816599316,
      "grad_norm": 1.4333261251449585,
      "learning_rate": 4.501865091700342e-06,
      "loss": 0.3192,
      "step": 14150
    },
    {
      "epoch": 1.0997046938141126,
      "grad_norm": 0.6564441323280334,
      "learning_rate": 4.501476530929438e-06,
      "loss": 0.361,
      "step": 14151
    },
    {
      "epoch": 1.0997824059682935,
      "grad_norm": 0.5215510129928589,
      "learning_rate": 4.501087970158533e-06,
      "loss": 0.9149,
      "step": 14152
    },
    {
      "epoch": 1.0998601181224743,
      "grad_norm": 0.6914577484130859,
      "learning_rate": 4.500699409387629e-06,
      "loss": 0.3033,
      "step": 14153
    },
    {
      "epoch": 1.0999378302766554,
      "grad_norm": 0.8078857064247131,
      "learning_rate": 4.500310848616724e-06,
      "loss": 0.3429,
      "step": 14154
    },
    {
      "epoch": 1.1000155424308362,
      "grad_norm": 0.44812318682670593,
      "learning_rate": 4.499922287845819e-06,
      "loss": 0.3982,
      "step": 14155
    },
    {
      "epoch": 1.100093254585017,
      "grad_norm": 0.37227460741996765,
      "learning_rate": 4.499533727074915e-06,
      "loss": 0.2015,
      "step": 14156
    },
    {
      "epoch": 1.100170966739198,
      "grad_norm": 0.15559911727905273,
      "learning_rate": 4.499145166304011e-06,
      "loss": 0.0459,
      "step": 14157
    },
    {
      "epoch": 1.100248678893379,
      "grad_norm": 0.46899184584617615,
      "learning_rate": 4.498756605533106e-06,
      "loss": 0.2162,
      "step": 14158
    },
    {
      "epoch": 1.1003263910475598,
      "grad_norm": 0.42794308066368103,
      "learning_rate": 4.4983680447622014e-06,
      "loss": 0.1905,
      "step": 14159
    },
    {
      "epoch": 1.1004041032017406,
      "grad_norm": 0.435054212808609,
      "learning_rate": 4.497979483991296e-06,
      "loss": 0.2174,
      "step": 14160
    },
    {
      "epoch": 1.1004818153559217,
      "grad_norm": 0.7981048822402954,
      "learning_rate": 4.497590923220392e-06,
      "loss": 0.3658,
      "step": 14161
    },
    {
      "epoch": 1.1005595275101026,
      "grad_norm": 0.3132117688655853,
      "learning_rate": 4.497202362449488e-06,
      "loss": 0.0619,
      "step": 14162
    },
    {
      "epoch": 1.1006372396642834,
      "grad_norm": 0.596470832824707,
      "learning_rate": 4.496813801678583e-06,
      "loss": 0.3765,
      "step": 14163
    },
    {
      "epoch": 1.1007149518184645,
      "grad_norm": 0.30526214838027954,
      "learning_rate": 4.496425240907678e-06,
      "loss": 0.0787,
      "step": 14164
    },
    {
      "epoch": 1.1007926639726453,
      "grad_norm": 0.5688591003417969,
      "learning_rate": 4.496036680136774e-06,
      "loss": 0.3451,
      "step": 14165
    },
    {
      "epoch": 1.1008703761268261,
      "grad_norm": 0.643060564994812,
      "learning_rate": 4.4956481193658695e-06,
      "loss": 0.1716,
      "step": 14166
    },
    {
      "epoch": 1.1009480882810072,
      "grad_norm": 0.5098381638526917,
      "learning_rate": 4.495259558594965e-06,
      "loss": 0.1724,
      "step": 14167
    },
    {
      "epoch": 1.101025800435188,
      "grad_norm": 0.4944915771484375,
      "learning_rate": 4.49487099782406e-06,
      "loss": 0.2246,
      "step": 14168
    },
    {
      "epoch": 1.101103512589369,
      "grad_norm": 0.4242098033428192,
      "learning_rate": 4.494482437053155e-06,
      "loss": 0.1497,
      "step": 14169
    },
    {
      "epoch": 1.10118122474355,
      "grad_norm": 0.5266510844230652,
      "learning_rate": 4.494093876282251e-06,
      "loss": 0.2611,
      "step": 14170
    },
    {
      "epoch": 1.1012589368977308,
      "grad_norm": 0.32417258620262146,
      "learning_rate": 4.493705315511347e-06,
      "loss": 0.1421,
      "step": 14171
    },
    {
      "epoch": 1.1013366490519116,
      "grad_norm": 0.4751352369785309,
      "learning_rate": 4.493316754740442e-06,
      "loss": 0.1656,
      "step": 14172
    },
    {
      "epoch": 1.1014143612060927,
      "grad_norm": 0.3404686748981476,
      "learning_rate": 4.4929281939695375e-06,
      "loss": 0.2462,
      "step": 14173
    },
    {
      "epoch": 1.1014920733602735,
      "grad_norm": 1.1095573902130127,
      "learning_rate": 4.4925396331986325e-06,
      "loss": 0.2864,
      "step": 14174
    },
    {
      "epoch": 1.1015697855144544,
      "grad_norm": 0.6421428322792053,
      "learning_rate": 4.492151072427728e-06,
      "loss": 0.2553,
      "step": 14175
    },
    {
      "epoch": 1.1016474976686355,
      "grad_norm": 0.3793763220310211,
      "learning_rate": 4.491762511656824e-06,
      "loss": 0.1604,
      "step": 14176
    },
    {
      "epoch": 1.1017252098228163,
      "grad_norm": 0.4843849837779999,
      "learning_rate": 4.491373950885919e-06,
      "loss": 0.3608,
      "step": 14177
    },
    {
      "epoch": 1.1018029219769971,
      "grad_norm": 0.5352104306221008,
      "learning_rate": 4.490985390115014e-06,
      "loss": 0.1149,
      "step": 14178
    },
    {
      "epoch": 1.1018806341311782,
      "grad_norm": 0.28674376010894775,
      "learning_rate": 4.49059682934411e-06,
      "loss": 0.136,
      "step": 14179
    },
    {
      "epoch": 1.101958346285359,
      "grad_norm": 0.3331966996192932,
      "learning_rate": 4.4902082685732056e-06,
      "loss": 0.1549,
      "step": 14180
    },
    {
      "epoch": 1.10203605843954,
      "grad_norm": 0.6752682328224182,
      "learning_rate": 4.4898197078023005e-06,
      "loss": 0.4566,
      "step": 14181
    },
    {
      "epoch": 1.102113770593721,
      "grad_norm": 0.5798004269599915,
      "learning_rate": 4.489431147031396e-06,
      "loss": 0.3572,
      "step": 14182
    },
    {
      "epoch": 1.1021914827479018,
      "grad_norm": 0.326266348361969,
      "learning_rate": 4.489042586260491e-06,
      "loss": 0.1537,
      "step": 14183
    },
    {
      "epoch": 1.1022691949020826,
      "grad_norm": 0.2390422821044922,
      "learning_rate": 4.488654025489587e-06,
      "loss": 0.1216,
      "step": 14184
    },
    {
      "epoch": 1.1023469070562637,
      "grad_norm": 0.567716121673584,
      "learning_rate": 4.488265464718682e-06,
      "loss": 0.371,
      "step": 14185
    },
    {
      "epoch": 1.1024246192104445,
      "grad_norm": 0.7477320432662964,
      "learning_rate": 4.487876903947778e-06,
      "loss": 0.6221,
      "step": 14186
    },
    {
      "epoch": 1.1025023313646254,
      "grad_norm": 0.16264359652996063,
      "learning_rate": 4.487488343176874e-06,
      "loss": 0.041,
      "step": 14187
    },
    {
      "epoch": 1.1025800435188065,
      "grad_norm": 0.29555872082710266,
      "learning_rate": 4.4870997824059685e-06,
      "loss": 0.0962,
      "step": 14188
    },
    {
      "epoch": 1.1026577556729873,
      "grad_norm": 0.616908073425293,
      "learning_rate": 4.4867112216350635e-06,
      "loss": 0.2601,
      "step": 14189
    },
    {
      "epoch": 1.1027354678271681,
      "grad_norm": 0.08103048801422119,
      "learning_rate": 4.486322660864159e-06,
      "loss": 0.0164,
      "step": 14190
    },
    {
      "epoch": 1.1028131799813492,
      "grad_norm": 0.6651909947395325,
      "learning_rate": 4.485934100093255e-06,
      "loss": 0.1664,
      "step": 14191
    },
    {
      "epoch": 1.10289089213553,
      "grad_norm": 0.18406283855438232,
      "learning_rate": 4.48554553932235e-06,
      "loss": 0.0352,
      "step": 14192
    },
    {
      "epoch": 1.1029686042897109,
      "grad_norm": 0.36128944158554077,
      "learning_rate": 4.485156978551446e-06,
      "loss": 0.1244,
      "step": 14193
    },
    {
      "epoch": 1.1030463164438917,
      "grad_norm": 0.6968689560890198,
      "learning_rate": 4.484768417780541e-06,
      "loss": 0.3263,
      "step": 14194
    },
    {
      "epoch": 1.1031240285980728,
      "grad_norm": 0.5467562675476074,
      "learning_rate": 4.484379857009637e-06,
      "loss": 0.1768,
      "step": 14195
    },
    {
      "epoch": 1.1032017407522536,
      "grad_norm": 0.8102334141731262,
      "learning_rate": 4.483991296238732e-06,
      "loss": 0.4799,
      "step": 14196
    },
    {
      "epoch": 1.1032794529064345,
      "grad_norm": 0.11493027210235596,
      "learning_rate": 4.483602735467827e-06,
      "loss": 0.0322,
      "step": 14197
    },
    {
      "epoch": 1.1033571650606155,
      "grad_norm": 0.4042665362358093,
      "learning_rate": 4.483214174696923e-06,
      "loss": 0.4253,
      "step": 14198
    },
    {
      "epoch": 1.1034348772147964,
      "grad_norm": 0.3125563859939575,
      "learning_rate": 4.482825613926018e-06,
      "loss": 0.2013,
      "step": 14199
    },
    {
      "epoch": 1.1035125893689772,
      "grad_norm": 0.6174870729446411,
      "learning_rate": 4.482437053155114e-06,
      "loss": 0.089,
      "step": 14200
    },
    {
      "epoch": 1.1035903015231583,
      "grad_norm": 0.5274352431297302,
      "learning_rate": 4.48204849238421e-06,
      "loss": 0.2054,
      "step": 14201
    },
    {
      "epoch": 1.1036680136773391,
      "grad_norm": 0.13586798310279846,
      "learning_rate": 4.481659931613305e-06,
      "loss": 0.0631,
      "step": 14202
    },
    {
      "epoch": 1.10374572583152,
      "grad_norm": 0.26991012692451477,
      "learning_rate": 4.4812713708423996e-06,
      "loss": 0.0698,
      "step": 14203
    },
    {
      "epoch": 1.103823437985701,
      "grad_norm": 0.3992958068847656,
      "learning_rate": 4.480882810071495e-06,
      "loss": 0.23,
      "step": 14204
    },
    {
      "epoch": 1.1039011501398819,
      "grad_norm": 2.049863576889038,
      "learning_rate": 4.480494249300591e-06,
      "loss": 0.1835,
      "step": 14205
    },
    {
      "epoch": 1.1039788622940627,
      "grad_norm": 0.32821327447891235,
      "learning_rate": 4.480105688529686e-06,
      "loss": 0.1231,
      "step": 14206
    },
    {
      "epoch": 1.1040565744482438,
      "grad_norm": 0.5315964221954346,
      "learning_rate": 4.479717127758782e-06,
      "loss": 0.0956,
      "step": 14207
    },
    {
      "epoch": 1.1041342866024246,
      "grad_norm": 0.16467462480068207,
      "learning_rate": 4.479328566987877e-06,
      "loss": 0.0527,
      "step": 14208
    },
    {
      "epoch": 1.1042119987566055,
      "grad_norm": 0.3587939441204071,
      "learning_rate": 4.478940006216973e-06,
      "loss": 0.0469,
      "step": 14209
    },
    {
      "epoch": 1.1042897109107865,
      "grad_norm": 0.13771125674247742,
      "learning_rate": 4.4785514454460684e-06,
      "loss": 0.0193,
      "step": 14210
    },
    {
      "epoch": 1.1043674230649674,
      "grad_norm": 0.05716555565595627,
      "learning_rate": 4.478162884675163e-06,
      "loss": 0.0093,
      "step": 14211
    },
    {
      "epoch": 1.1044451352191482,
      "grad_norm": 0.601184606552124,
      "learning_rate": 4.477774323904259e-06,
      "loss": 0.3822,
      "step": 14212
    },
    {
      "epoch": 1.1045228473733293,
      "grad_norm": 0.589660108089447,
      "learning_rate": 4.477385763133354e-06,
      "loss": 0.6003,
      "step": 14213
    },
    {
      "epoch": 1.1046005595275101,
      "grad_norm": 0.5533627271652222,
      "learning_rate": 4.47699720236245e-06,
      "loss": 0.5029,
      "step": 14214
    },
    {
      "epoch": 1.104678271681691,
      "grad_norm": 0.2801593840122223,
      "learning_rate": 4.476608641591546e-06,
      "loss": 0.3024,
      "step": 14215
    },
    {
      "epoch": 1.1047559838358718,
      "grad_norm": 0.3978746235370636,
      "learning_rate": 4.476220080820641e-06,
      "loss": 0.1691,
      "step": 14216
    },
    {
      "epoch": 1.1048336959900529,
      "grad_norm": 0.319074422121048,
      "learning_rate": 4.475831520049736e-06,
      "loss": 0.0674,
      "step": 14217
    },
    {
      "epoch": 1.1049114081442337,
      "grad_norm": 2.0329084396362305,
      "learning_rate": 4.4754429592788314e-06,
      "loss": 0.666,
      "step": 14218
    },
    {
      "epoch": 1.1049891202984146,
      "grad_norm": 0.5815637111663818,
      "learning_rate": 4.475054398507927e-06,
      "loss": 0.3815,
      "step": 14219
    },
    {
      "epoch": 1.1050668324525956,
      "grad_norm": 0.6047809720039368,
      "learning_rate": 4.474665837737022e-06,
      "loss": 0.2265,
      "step": 14220
    },
    {
      "epoch": 1.1051445446067765,
      "grad_norm": 0.48475274443626404,
      "learning_rate": 4.474277276966118e-06,
      "loss": 0.2876,
      "step": 14221
    },
    {
      "epoch": 1.1052222567609573,
      "grad_norm": 0.47487324476242065,
      "learning_rate": 4.473888716195213e-06,
      "loss": 0.2706,
      "step": 14222
    },
    {
      "epoch": 1.1052999689151384,
      "grad_norm": 0.3620200753211975,
      "learning_rate": 4.473500155424309e-06,
      "loss": 0.1335,
      "step": 14223
    },
    {
      "epoch": 1.1053776810693192,
      "grad_norm": 0.3687749207019806,
      "learning_rate": 4.4731115946534045e-06,
      "loss": 0.1817,
      "step": 14224
    },
    {
      "epoch": 1.1054553932235,
      "grad_norm": 0.19270221889019012,
      "learning_rate": 4.4727230338824995e-06,
      "loss": 0.0734,
      "step": 14225
    },
    {
      "epoch": 1.1055331053776811,
      "grad_norm": 0.3721635937690735,
      "learning_rate": 4.472334473111594e-06,
      "loss": 0.1674,
      "step": 14226
    },
    {
      "epoch": 1.105610817531862,
      "grad_norm": 1.4335087537765503,
      "learning_rate": 4.47194591234069e-06,
      "loss": 0.7604,
      "step": 14227
    },
    {
      "epoch": 1.1056885296860428,
      "grad_norm": 0.45533040165901184,
      "learning_rate": 4.471557351569786e-06,
      "loss": 0.0227,
      "step": 14228
    },
    {
      "epoch": 1.1057662418402239,
      "grad_norm": 0.5254495739936829,
      "learning_rate": 4.471168790798882e-06,
      "loss": 0.3873,
      "step": 14229
    },
    {
      "epoch": 1.1058439539944047,
      "grad_norm": 0.3624797761440277,
      "learning_rate": 4.470780230027977e-06,
      "loss": 0.394,
      "step": 14230
    },
    {
      "epoch": 1.1059216661485856,
      "grad_norm": 0.20349988341331482,
      "learning_rate": 4.470391669257072e-06,
      "loss": 0.0664,
      "step": 14231
    },
    {
      "epoch": 1.1059993783027666,
      "grad_norm": 0.23225298523902893,
      "learning_rate": 4.4700031084861675e-06,
      "loss": 0.1262,
      "step": 14232
    },
    {
      "epoch": 1.1060770904569475,
      "grad_norm": 0.3519621789455414,
      "learning_rate": 4.469614547715263e-06,
      "loss": 0.1025,
      "step": 14233
    },
    {
      "epoch": 1.1061548026111283,
      "grad_norm": 0.18741461634635925,
      "learning_rate": 4.469225986944358e-06,
      "loss": 0.0678,
      "step": 14234
    },
    {
      "epoch": 1.1062325147653094,
      "grad_norm": 0.19507350027561188,
      "learning_rate": 4.468837426173454e-06,
      "loss": 0.0292,
      "step": 14235
    },
    {
      "epoch": 1.1063102269194902,
      "grad_norm": 0.2969987392425537,
      "learning_rate": 4.468448865402549e-06,
      "loss": 0.0899,
      "step": 14236
    },
    {
      "epoch": 1.106387939073671,
      "grad_norm": 0.23417435586452484,
      "learning_rate": 4.468060304631645e-06,
      "loss": 0.0478,
      "step": 14237
    },
    {
      "epoch": 1.1064656512278521,
      "grad_norm": 0.6302070617675781,
      "learning_rate": 4.467671743860741e-06,
      "loss": 0.2225,
      "step": 14238
    },
    {
      "epoch": 1.106543363382033,
      "grad_norm": 0.4892328083515167,
      "learning_rate": 4.4672831830898355e-06,
      "loss": 0.1692,
      "step": 14239
    },
    {
      "epoch": 1.1066210755362138,
      "grad_norm": 0.2934929430484772,
      "learning_rate": 4.4668946223189305e-06,
      "loss": 0.1728,
      "step": 14240
    },
    {
      "epoch": 1.1066987876903949,
      "grad_norm": 0.10163324326276779,
      "learning_rate": 4.466506061548026e-06,
      "loss": 0.0394,
      "step": 14241
    },
    {
      "epoch": 1.1067764998445757,
      "grad_norm": 0.10028593242168427,
      "learning_rate": 4.466117500777122e-06,
      "loss": 0.0284,
      "step": 14242
    },
    {
      "epoch": 1.1068542119987566,
      "grad_norm": 0.3300979733467102,
      "learning_rate": 4.465728940006218e-06,
      "loss": 0.0627,
      "step": 14243
    },
    {
      "epoch": 1.1069319241529376,
      "grad_norm": 0.16984714567661285,
      "learning_rate": 4.465340379235313e-06,
      "loss": 0.0576,
      "step": 14244
    },
    {
      "epoch": 1.1070096363071185,
      "grad_norm": 0.40564656257629395,
      "learning_rate": 4.464951818464408e-06,
      "loss": 0.1531,
      "step": 14245
    },
    {
      "epoch": 1.1070873484612993,
      "grad_norm": 0.7070844173431396,
      "learning_rate": 4.464563257693504e-06,
      "loss": 0.3911,
      "step": 14246
    },
    {
      "epoch": 1.1071650606154804,
      "grad_norm": 0.8010440468788147,
      "learning_rate": 4.464174696922599e-06,
      "loss": 0.3345,
      "step": 14247
    },
    {
      "epoch": 1.1072427727696612,
      "grad_norm": 0.35021060705184937,
      "learning_rate": 4.463786136151694e-06,
      "loss": 0.1972,
      "step": 14248
    },
    {
      "epoch": 1.107320484923842,
      "grad_norm": 0.25259852409362793,
      "learning_rate": 4.46339757538079e-06,
      "loss": 0.1514,
      "step": 14249
    },
    {
      "epoch": 1.1073981970780231,
      "grad_norm": 0.33862918615341187,
      "learning_rate": 4.463009014609885e-06,
      "loss": 0.2399,
      "step": 14250
    },
    {
      "epoch": 1.107475909232204,
      "grad_norm": 0.0971088781952858,
      "learning_rate": 4.462620453838981e-06,
      "loss": 0.0118,
      "step": 14251
    },
    {
      "epoch": 1.1075536213863848,
      "grad_norm": 0.4086485505104065,
      "learning_rate": 4.462231893068077e-06,
      "loss": 0.2536,
      "step": 14252
    },
    {
      "epoch": 1.1076313335405656,
      "grad_norm": 0.3730771839618683,
      "learning_rate": 4.461843332297172e-06,
      "loss": 0.1856,
      "step": 14253
    },
    {
      "epoch": 1.1077090456947467,
      "grad_norm": 1.249920129776001,
      "learning_rate": 4.4614547715262666e-06,
      "loss": 0.4774,
      "step": 14254
    },
    {
      "epoch": 1.1077867578489276,
      "grad_norm": 0.257514625787735,
      "learning_rate": 4.461066210755362e-06,
      "loss": 0.0629,
      "step": 14255
    },
    {
      "epoch": 1.1078644700031084,
      "grad_norm": 0.5465596318244934,
      "learning_rate": 4.460677649984458e-06,
      "loss": 0.5648,
      "step": 14256
    },
    {
      "epoch": 1.1079421821572895,
      "grad_norm": 0.14057563245296478,
      "learning_rate": 4.460289089213554e-06,
      "loss": 0.0365,
      "step": 14257
    },
    {
      "epoch": 1.1080198943114703,
      "grad_norm": 0.6370079517364502,
      "learning_rate": 4.459900528442649e-06,
      "loss": 0.1897,
      "step": 14258
    },
    {
      "epoch": 1.1080976064656511,
      "grad_norm": 0.3711940050125122,
      "learning_rate": 4.459511967671744e-06,
      "loss": 0.2225,
      "step": 14259
    },
    {
      "epoch": 1.1081753186198322,
      "grad_norm": 0.43615323305130005,
      "learning_rate": 4.45912340690084e-06,
      "loss": 0.0658,
      "step": 14260
    },
    {
      "epoch": 1.108253030774013,
      "grad_norm": 0.37558937072753906,
      "learning_rate": 4.4587348461299354e-06,
      "loss": 0.1264,
      "step": 14261
    },
    {
      "epoch": 1.108330742928194,
      "grad_norm": 0.32993510365486145,
      "learning_rate": 4.45834628535903e-06,
      "loss": 0.0391,
      "step": 14262
    },
    {
      "epoch": 1.108408455082375,
      "grad_norm": 0.35620951652526855,
      "learning_rate": 4.457957724588126e-06,
      "loss": 0.2197,
      "step": 14263
    },
    {
      "epoch": 1.1084861672365558,
      "grad_norm": 0.584653377532959,
      "learning_rate": 4.457569163817221e-06,
      "loss": 0.7605,
      "step": 14264
    },
    {
      "epoch": 1.1085638793907366,
      "grad_norm": 0.7603625059127808,
      "learning_rate": 4.457180603046317e-06,
      "loss": 0.1703,
      "step": 14265
    },
    {
      "epoch": 1.1086415915449177,
      "grad_norm": 0.26660841703414917,
      "learning_rate": 4.456792042275413e-06,
      "loss": 0.145,
      "step": 14266
    },
    {
      "epoch": 1.1087193036990985,
      "grad_norm": 0.07804782688617706,
      "learning_rate": 4.456403481504508e-06,
      "loss": 0.0156,
      "step": 14267
    },
    {
      "epoch": 1.1087970158532794,
      "grad_norm": 0.5769157409667969,
      "learning_rate": 4.456014920733603e-06,
      "loss": 0.1841,
      "step": 14268
    },
    {
      "epoch": 1.1088747280074605,
      "grad_norm": 0.08681445568799973,
      "learning_rate": 4.4556263599626984e-06,
      "loss": 0.0152,
      "step": 14269
    },
    {
      "epoch": 1.1089524401616413,
      "grad_norm": 0.36388713121414185,
      "learning_rate": 4.455237799191794e-06,
      "loss": 0.1672,
      "step": 14270
    },
    {
      "epoch": 1.1090301523158221,
      "grad_norm": 0.27071264386177063,
      "learning_rate": 4.454849238420889e-06,
      "loss": 0.1657,
      "step": 14271
    },
    {
      "epoch": 1.1091078644700032,
      "grad_norm": 0.23454459011554718,
      "learning_rate": 4.454460677649985e-06,
      "loss": 0.0644,
      "step": 14272
    },
    {
      "epoch": 1.109185576624184,
      "grad_norm": 0.6095060706138611,
      "learning_rate": 4.45407211687908e-06,
      "loss": 0.3057,
      "step": 14273
    },
    {
      "epoch": 1.1092632887783649,
      "grad_norm": 0.11576919257640839,
      "learning_rate": 4.453683556108176e-06,
      "loss": 0.0128,
      "step": 14274
    },
    {
      "epoch": 1.109341000932546,
      "grad_norm": 0.9332188367843628,
      "learning_rate": 4.4532949953372715e-06,
      "loss": 0.3564,
      "step": 14275
    },
    {
      "epoch": 1.1094187130867268,
      "grad_norm": 0.7501351833343506,
      "learning_rate": 4.4529064345663665e-06,
      "loss": 0.3745,
      "step": 14276
    },
    {
      "epoch": 1.1094964252409076,
      "grad_norm": 0.40052929520606995,
      "learning_rate": 4.452517873795462e-06,
      "loss": 0.1895,
      "step": 14277
    },
    {
      "epoch": 1.1095741373950885,
      "grad_norm": 0.16609255969524384,
      "learning_rate": 4.452129313024557e-06,
      "loss": 0.0574,
      "step": 14278
    },
    {
      "epoch": 1.1096518495492695,
      "grad_norm": 0.8690932989120483,
      "learning_rate": 4.451740752253653e-06,
      "loss": 0.1673,
      "step": 14279
    },
    {
      "epoch": 1.1097295617034504,
      "grad_norm": 0.28869369626045227,
      "learning_rate": 4.451352191482749e-06,
      "loss": 0.2611,
      "step": 14280
    },
    {
      "epoch": 1.1098072738576312,
      "grad_norm": 0.7799896597862244,
      "learning_rate": 4.450963630711844e-06,
      "loss": 0.0931,
      "step": 14281
    },
    {
      "epoch": 1.1098849860118123,
      "grad_norm": 0.4294898808002472,
      "learning_rate": 4.450575069940939e-06,
      "loss": 0.0984,
      "step": 14282
    },
    {
      "epoch": 1.1099626981659931,
      "grad_norm": 0.34312888979911804,
      "learning_rate": 4.4501865091700345e-06,
      "loss": 0.204,
      "step": 14283
    },
    {
      "epoch": 1.110040410320174,
      "grad_norm": 0.24264220893383026,
      "learning_rate": 4.44979794839913e-06,
      "loss": 0.0264,
      "step": 14284
    },
    {
      "epoch": 1.110118122474355,
      "grad_norm": 0.18759462237358093,
      "learning_rate": 4.449409387628225e-06,
      "loss": 0.0802,
      "step": 14285
    },
    {
      "epoch": 1.1101958346285359,
      "grad_norm": 0.45429396629333496,
      "learning_rate": 4.449020826857321e-06,
      "loss": 0.3711,
      "step": 14286
    },
    {
      "epoch": 1.1102735467827167,
      "grad_norm": 0.3814665675163269,
      "learning_rate": 4.448632266086416e-06,
      "loss": 0.1166,
      "step": 14287
    },
    {
      "epoch": 1.1103512589368978,
      "grad_norm": 0.3282569944858551,
      "learning_rate": 4.448243705315512e-06,
      "loss": 0.1813,
      "step": 14288
    },
    {
      "epoch": 1.1104289710910786,
      "grad_norm": 0.3183983862400055,
      "learning_rate": 4.447855144544608e-06,
      "loss": 0.0644,
      "step": 14289
    },
    {
      "epoch": 1.1105066832452595,
      "grad_norm": 0.4198268949985504,
      "learning_rate": 4.4474665837737025e-06,
      "loss": 0.116,
      "step": 14290
    },
    {
      "epoch": 1.1105843953994405,
      "grad_norm": 0.19420590996742249,
      "learning_rate": 4.447078023002798e-06,
      "loss": 0.1088,
      "step": 14291
    },
    {
      "epoch": 1.1106621075536214,
      "grad_norm": 0.5323917865753174,
      "learning_rate": 4.446689462231893e-06,
      "loss": 0.6931,
      "step": 14292
    },
    {
      "epoch": 1.1107398197078022,
      "grad_norm": 0.7829793691635132,
      "learning_rate": 4.446300901460989e-06,
      "loss": 0.3274,
      "step": 14293
    },
    {
      "epoch": 1.1108175318619833,
      "grad_norm": 0.2142103910446167,
      "learning_rate": 4.445912340690085e-06,
      "loss": 0.0397,
      "step": 14294
    },
    {
      "epoch": 1.1108952440161641,
      "grad_norm": 0.5628694295883179,
      "learning_rate": 4.44552377991918e-06,
      "loss": 0.2078,
      "step": 14295
    },
    {
      "epoch": 1.110972956170345,
      "grad_norm": 0.4237131178379059,
      "learning_rate": 4.445135219148275e-06,
      "loss": 0.2387,
      "step": 14296
    },
    {
      "epoch": 1.111050668324526,
      "grad_norm": 0.3640490472316742,
      "learning_rate": 4.444746658377371e-06,
      "loss": 0.1066,
      "step": 14297
    },
    {
      "epoch": 1.1111283804787069,
      "grad_norm": 0.2768594026565552,
      "learning_rate": 4.444358097606466e-06,
      "loss": 0.0541,
      "step": 14298
    },
    {
      "epoch": 1.1112060926328877,
      "grad_norm": 0.8337475061416626,
      "learning_rate": 4.443969536835561e-06,
      "loss": 0.5321,
      "step": 14299
    },
    {
      "epoch": 1.1112838047870688,
      "grad_norm": 0.38767462968826294,
      "learning_rate": 4.443580976064657e-06,
      "loss": 0.0438,
      "step": 14300
    },
    {
      "epoch": 1.1113615169412496,
      "grad_norm": 0.46569177508354187,
      "learning_rate": 4.443192415293752e-06,
      "loss": 0.1789,
      "step": 14301
    },
    {
      "epoch": 1.1114392290954305,
      "grad_norm": 0.21786203980445862,
      "learning_rate": 4.442803854522848e-06,
      "loss": 0.0705,
      "step": 14302
    },
    {
      "epoch": 1.1115169412496115,
      "grad_norm": 0.24906976521015167,
      "learning_rate": 4.442415293751944e-06,
      "loss": 0.2381,
      "step": 14303
    },
    {
      "epoch": 1.1115946534037924,
      "grad_norm": 0.4832482635974884,
      "learning_rate": 4.442026732981039e-06,
      "loss": 0.303,
      "step": 14304
    },
    {
      "epoch": 1.1116723655579732,
      "grad_norm": 0.48241719603538513,
      "learning_rate": 4.441638172210134e-06,
      "loss": 0.1404,
      "step": 14305
    },
    {
      "epoch": 1.1117500777121543,
      "grad_norm": 0.11767447739839554,
      "learning_rate": 4.441249611439229e-06,
      "loss": 0.1002,
      "step": 14306
    },
    {
      "epoch": 1.1118277898663351,
      "grad_norm": 0.8444827198982239,
      "learning_rate": 4.440861050668324e-06,
      "loss": 0.3967,
      "step": 14307
    },
    {
      "epoch": 1.111905502020516,
      "grad_norm": 0.348046213388443,
      "learning_rate": 4.44047248989742e-06,
      "loss": 0.103,
      "step": 14308
    },
    {
      "epoch": 1.111983214174697,
      "grad_norm": 0.14223529398441315,
      "learning_rate": 4.440083929126516e-06,
      "loss": 0.0195,
      "step": 14309
    },
    {
      "epoch": 1.1120609263288779,
      "grad_norm": 0.21543732285499573,
      "learning_rate": 4.439695368355611e-06,
      "loss": 0.1041,
      "step": 14310
    },
    {
      "epoch": 1.1121386384830587,
      "grad_norm": 0.4248691499233246,
      "learning_rate": 4.439306807584707e-06,
      "loss": 0.0795,
      "step": 14311
    },
    {
      "epoch": 1.1122163506372398,
      "grad_norm": 0.5200546383857727,
      "learning_rate": 4.438918246813802e-06,
      "loss": 0.2139,
      "step": 14312
    },
    {
      "epoch": 1.1122940627914206,
      "grad_norm": 0.35813963413238525,
      "learning_rate": 4.438529686042897e-06,
      "loss": 0.2023,
      "step": 14313
    },
    {
      "epoch": 1.1123717749456015,
      "grad_norm": 0.37470367550849915,
      "learning_rate": 4.438141125271993e-06,
      "loss": 0.102,
      "step": 14314
    },
    {
      "epoch": 1.1124494870997823,
      "grad_norm": 0.35763832926750183,
      "learning_rate": 4.437752564501088e-06,
      "loss": 0.1041,
      "step": 14315
    },
    {
      "epoch": 1.1125271992539634,
      "grad_norm": 0.3881901204586029,
      "learning_rate": 4.437364003730183e-06,
      "loss": 0.0628,
      "step": 14316
    },
    {
      "epoch": 1.1126049114081442,
      "grad_norm": 0.21603578329086304,
      "learning_rate": 4.436975442959279e-06,
      "loss": 0.0778,
      "step": 14317
    },
    {
      "epoch": 1.112682623562325,
      "grad_norm": 1.280727505683899,
      "learning_rate": 4.436586882188375e-06,
      "loss": 0.2165,
      "step": 14318
    },
    {
      "epoch": 1.1127603357165061,
      "grad_norm": 0.5473126173019409,
      "learning_rate": 4.4361983214174705e-06,
      "loss": 0.4179,
      "step": 14319
    },
    {
      "epoch": 1.112838047870687,
      "grad_norm": 0.9543372988700867,
      "learning_rate": 4.4358097606465654e-06,
      "loss": 0.2869,
      "step": 14320
    },
    {
      "epoch": 1.1129157600248678,
      "grad_norm": 0.33827751874923706,
      "learning_rate": 4.43542119987566e-06,
      "loss": 0.3439,
      "step": 14321
    },
    {
      "epoch": 1.1129934721790489,
      "grad_norm": 0.7673084139823914,
      "learning_rate": 4.435032639104756e-06,
      "loss": 0.2746,
      "step": 14322
    },
    {
      "epoch": 1.1130711843332297,
      "grad_norm": 0.5878243446350098,
      "learning_rate": 4.434644078333852e-06,
      "loss": 0.2591,
      "step": 14323
    },
    {
      "epoch": 1.1131488964874106,
      "grad_norm": 0.330809086561203,
      "learning_rate": 4.434255517562947e-06,
      "loss": 0.1611,
      "step": 14324
    },
    {
      "epoch": 1.1132266086415916,
      "grad_norm": 0.265798956155777,
      "learning_rate": 4.433866956792043e-06,
      "loss": 0.0257,
      "step": 14325
    },
    {
      "epoch": 1.1133043207957725,
      "grad_norm": 0.7168774008750916,
      "learning_rate": 4.433478396021138e-06,
      "loss": 0.9594,
      "step": 14326
    },
    {
      "epoch": 1.1133820329499533,
      "grad_norm": 0.22565782070159912,
      "learning_rate": 4.4330898352502335e-06,
      "loss": 0.0537,
      "step": 14327
    },
    {
      "epoch": 1.1134597451041344,
      "grad_norm": 0.23961055278778076,
      "learning_rate": 4.432701274479329e-06,
      "loss": 0.0672,
      "step": 14328
    },
    {
      "epoch": 1.1135374572583152,
      "grad_norm": 0.4825381934642792,
      "learning_rate": 4.432312713708424e-06,
      "loss": 0.1414,
      "step": 14329
    },
    {
      "epoch": 1.113615169412496,
      "grad_norm": 0.6594170331954956,
      "learning_rate": 4.431924152937519e-06,
      "loss": 0.5602,
      "step": 14330
    },
    {
      "epoch": 1.1136928815666771,
      "grad_norm": 0.9540302753448486,
      "learning_rate": 4.431535592166615e-06,
      "loss": 0.3737,
      "step": 14331
    },
    {
      "epoch": 1.113770593720858,
      "grad_norm": 0.5764344930648804,
      "learning_rate": 4.431147031395711e-06,
      "loss": 0.1275,
      "step": 14332
    },
    {
      "epoch": 1.1138483058750388,
      "grad_norm": 0.43949344754219055,
      "learning_rate": 4.4307584706248066e-06,
      "loss": 0.289,
      "step": 14333
    },
    {
      "epoch": 1.1139260180292199,
      "grad_norm": 0.4610801637172699,
      "learning_rate": 4.4303699098539015e-06,
      "loss": 0.1499,
      "step": 14334
    },
    {
      "epoch": 1.1140037301834007,
      "grad_norm": 0.2756234407424927,
      "learning_rate": 4.4299813490829965e-06,
      "loss": 0.0858,
      "step": 14335
    },
    {
      "epoch": 1.1140814423375816,
      "grad_norm": 0.2921826243400574,
      "learning_rate": 4.429592788312092e-06,
      "loss": 0.0978,
      "step": 14336
    },
    {
      "epoch": 1.1141591544917626,
      "grad_norm": 0.9752551913261414,
      "learning_rate": 4.429204227541188e-06,
      "loss": 0.5828,
      "step": 14337
    },
    {
      "epoch": 1.1142368666459435,
      "grad_norm": 0.33822688460350037,
      "learning_rate": 4.428815666770283e-06,
      "loss": 0.1527,
      "step": 14338
    },
    {
      "epoch": 1.1143145788001243,
      "grad_norm": 0.6351801753044128,
      "learning_rate": 4.428427105999379e-06,
      "loss": 0.0438,
      "step": 14339
    },
    {
      "epoch": 1.1143922909543051,
      "grad_norm": 0.37658628821372986,
      "learning_rate": 4.428038545228474e-06,
      "loss": 0.1033,
      "step": 14340
    },
    {
      "epoch": 1.1144700031084862,
      "grad_norm": 0.8804643154144287,
      "learning_rate": 4.4276499844575695e-06,
      "loss": 0.2966,
      "step": 14341
    },
    {
      "epoch": 1.114547715262667,
      "grad_norm": 0.11589683592319489,
      "learning_rate": 4.427261423686665e-06,
      "loss": 0.0153,
      "step": 14342
    },
    {
      "epoch": 1.114625427416848,
      "grad_norm": 0.2625289857387543,
      "learning_rate": 4.42687286291576e-06,
      "loss": 0.1077,
      "step": 14343
    },
    {
      "epoch": 1.114703139571029,
      "grad_norm": 0.3777749240398407,
      "learning_rate": 4.426484302144855e-06,
      "loss": 0.1745,
      "step": 14344
    },
    {
      "epoch": 1.1147808517252098,
      "grad_norm": 0.37158069014549255,
      "learning_rate": 4.426095741373951e-06,
      "loss": 0.1113,
      "step": 14345
    },
    {
      "epoch": 1.1148585638793906,
      "grad_norm": 0.5158178210258484,
      "learning_rate": 4.425707180603047e-06,
      "loss": 0.1558,
      "step": 14346
    },
    {
      "epoch": 1.1149362760335717,
      "grad_norm": 0.6957894563674927,
      "learning_rate": 4.425318619832142e-06,
      "loss": 0.2698,
      "step": 14347
    },
    {
      "epoch": 1.1150139881877525,
      "grad_norm": 0.36903637647628784,
      "learning_rate": 4.424930059061238e-06,
      "loss": 0.1237,
      "step": 14348
    },
    {
      "epoch": 1.1150917003419334,
      "grad_norm": 0.6687109470367432,
      "learning_rate": 4.4245414982903325e-06,
      "loss": 0.2102,
      "step": 14349
    },
    {
      "epoch": 1.1151694124961145,
      "grad_norm": 0.5107117295265198,
      "learning_rate": 4.424152937519428e-06,
      "loss": 0.1851,
      "step": 14350
    },
    {
      "epoch": 1.1152471246502953,
      "grad_norm": 0.46399107575416565,
      "learning_rate": 4.423764376748524e-06,
      "loss": 0.2233,
      "step": 14351
    },
    {
      "epoch": 1.1153248368044761,
      "grad_norm": 0.4507530629634857,
      "learning_rate": 4.423375815977619e-06,
      "loss": 0.1722,
      "step": 14352
    },
    {
      "epoch": 1.1154025489586572,
      "grad_norm": 0.5280252695083618,
      "learning_rate": 4.422987255206715e-06,
      "loss": 0.072,
      "step": 14353
    },
    {
      "epoch": 1.115480261112838,
      "grad_norm": 0.4706013798713684,
      "learning_rate": 4.42259869443581e-06,
      "loss": 0.4359,
      "step": 14354
    },
    {
      "epoch": 1.1155579732670189,
      "grad_norm": 0.1055288165807724,
      "learning_rate": 4.422210133664906e-06,
      "loss": 0.0341,
      "step": 14355
    },
    {
      "epoch": 1.1156356854212,
      "grad_norm": 0.15242615342140198,
      "learning_rate": 4.421821572894001e-06,
      "loss": 0.0596,
      "step": 14356
    },
    {
      "epoch": 1.1157133975753808,
      "grad_norm": 0.19433662295341492,
      "learning_rate": 4.421433012123096e-06,
      "loss": 0.0508,
      "step": 14357
    },
    {
      "epoch": 1.1157911097295616,
      "grad_norm": 0.8573373556137085,
      "learning_rate": 4.421044451352191e-06,
      "loss": 0.3727,
      "step": 14358
    },
    {
      "epoch": 1.1158688218837427,
      "grad_norm": 0.26001107692718506,
      "learning_rate": 4.420655890581287e-06,
      "loss": 0.1421,
      "step": 14359
    },
    {
      "epoch": 1.1159465340379235,
      "grad_norm": 0.40762946009635925,
      "learning_rate": 4.420267329810383e-06,
      "loss": 0.06,
      "step": 14360
    },
    {
      "epoch": 1.1160242461921044,
      "grad_norm": 0.2471436709165573,
      "learning_rate": 4.419878769039478e-06,
      "loss": 0.0292,
      "step": 14361
    },
    {
      "epoch": 1.1161019583462854,
      "grad_norm": 0.5711401104927063,
      "learning_rate": 4.419490208268574e-06,
      "loss": 0.5798,
      "step": 14362
    },
    {
      "epoch": 1.1161796705004663,
      "grad_norm": 0.19992351531982422,
      "learning_rate": 4.419101647497669e-06,
      "loss": 0.0222,
      "step": 14363
    },
    {
      "epoch": 1.1162573826546471,
      "grad_norm": 0.553501546382904,
      "learning_rate": 4.418713086726764e-06,
      "loss": 0.2088,
      "step": 14364
    },
    {
      "epoch": 1.1163350948088282,
      "grad_norm": 0.8463687896728516,
      "learning_rate": 4.41832452595586e-06,
      "loss": 0.5157,
      "step": 14365
    },
    {
      "epoch": 1.116412806963009,
      "grad_norm": 0.1913418173789978,
      "learning_rate": 4.417935965184955e-06,
      "loss": 0.2341,
      "step": 14366
    },
    {
      "epoch": 1.1164905191171899,
      "grad_norm": 1.0421133041381836,
      "learning_rate": 4.417547404414051e-06,
      "loss": 0.4017,
      "step": 14367
    },
    {
      "epoch": 1.116568231271371,
      "grad_norm": 0.08567211776971817,
      "learning_rate": 4.417158843643146e-06,
      "loss": 0.0053,
      "step": 14368
    },
    {
      "epoch": 1.1166459434255518,
      "grad_norm": 0.28725120425224304,
      "learning_rate": 4.416770282872242e-06,
      "loss": 0.1585,
      "step": 14369
    },
    {
      "epoch": 1.1167236555797326,
      "grad_norm": 0.5739873051643372,
      "learning_rate": 4.4163817221013375e-06,
      "loss": 0.1991,
      "step": 14370
    },
    {
      "epoch": 1.1168013677339137,
      "grad_norm": 0.16822588443756104,
      "learning_rate": 4.4159931613304324e-06,
      "loss": 0.0716,
      "step": 14371
    },
    {
      "epoch": 1.1168790798880945,
      "grad_norm": 0.21067029237747192,
      "learning_rate": 4.415604600559527e-06,
      "loss": 0.0299,
      "step": 14372
    },
    {
      "epoch": 1.1169567920422754,
      "grad_norm": 0.04169046878814697,
      "learning_rate": 4.415216039788623e-06,
      "loss": 0.0024,
      "step": 14373
    },
    {
      "epoch": 1.1170345041964562,
      "grad_norm": 0.3527508080005646,
      "learning_rate": 4.414827479017719e-06,
      "loss": 0.1392,
      "step": 14374
    },
    {
      "epoch": 1.1171122163506373,
      "grad_norm": 0.5446888208389282,
      "learning_rate": 4.414438918246814e-06,
      "loss": 0.199,
      "step": 14375
    },
    {
      "epoch": 1.1171899285048181,
      "grad_norm": 0.27908214926719666,
      "learning_rate": 4.41405035747591e-06,
      "loss": 0.099,
      "step": 14376
    },
    {
      "epoch": 1.117267640658999,
      "grad_norm": 0.6206379532814026,
      "learning_rate": 4.413661796705005e-06,
      "loss": 0.3629,
      "step": 14377
    },
    {
      "epoch": 1.11734535281318,
      "grad_norm": 0.20846477150917053,
      "learning_rate": 4.4132732359341005e-06,
      "loss": 0.0705,
      "step": 14378
    },
    {
      "epoch": 1.1174230649673609,
      "grad_norm": 0.45585891604423523,
      "learning_rate": 4.412884675163196e-06,
      "loss": 0.1621,
      "step": 14379
    },
    {
      "epoch": 1.1175007771215417,
      "grad_norm": 0.6652336120605469,
      "learning_rate": 4.412496114392291e-06,
      "loss": 0.2595,
      "step": 14380
    },
    {
      "epoch": 1.1175784892757228,
      "grad_norm": 0.4685900807380676,
      "learning_rate": 4.412107553621387e-06,
      "loss": 0.1227,
      "step": 14381
    },
    {
      "epoch": 1.1176562014299036,
      "grad_norm": 0.4182588756084442,
      "learning_rate": 4.411718992850482e-06,
      "loss": 0.2153,
      "step": 14382
    },
    {
      "epoch": 1.1177339135840845,
      "grad_norm": 0.45240357518196106,
      "learning_rate": 4.411330432079578e-06,
      "loss": 0.2245,
      "step": 14383
    },
    {
      "epoch": 1.1178116257382655,
      "grad_norm": 0.3091936707496643,
      "learning_rate": 4.4109418713086736e-06,
      "loss": 0.1241,
      "step": 14384
    },
    {
      "epoch": 1.1178893378924464,
      "grad_norm": 0.41194748878479004,
      "learning_rate": 4.4105533105377685e-06,
      "loss": 0.2405,
      "step": 14385
    },
    {
      "epoch": 1.1179670500466272,
      "grad_norm": 0.21380876004695892,
      "learning_rate": 4.4101647497668635e-06,
      "loss": 0.0512,
      "step": 14386
    },
    {
      "epoch": 1.1180447622008083,
      "grad_norm": 0.4523417353630066,
      "learning_rate": 4.409776188995959e-06,
      "loss": 0.2579,
      "step": 14387
    },
    {
      "epoch": 1.1181224743549891,
      "grad_norm": 1.3933172225952148,
      "learning_rate": 4.409387628225055e-06,
      "loss": 0.3871,
      "step": 14388
    },
    {
      "epoch": 1.11820018650917,
      "grad_norm": 0.6762793660163879,
      "learning_rate": 4.40899906745415e-06,
      "loss": 0.2808,
      "step": 14389
    },
    {
      "epoch": 1.118277898663351,
      "grad_norm": 0.5674751996994019,
      "learning_rate": 4.408610506683246e-06,
      "loss": 0.1488,
      "step": 14390
    },
    {
      "epoch": 1.1183556108175319,
      "grad_norm": 0.45334020256996155,
      "learning_rate": 4.408221945912341e-06,
      "loss": 0.2438,
      "step": 14391
    },
    {
      "epoch": 1.1184333229717127,
      "grad_norm": 0.5979193449020386,
      "learning_rate": 4.4078333851414366e-06,
      "loss": 0.1851,
      "step": 14392
    },
    {
      "epoch": 1.1185110351258938,
      "grad_norm": 0.6502503752708435,
      "learning_rate": 4.407444824370532e-06,
      "loss": 0.2601,
      "step": 14393
    },
    {
      "epoch": 1.1185887472800746,
      "grad_norm": 0.4365457594394684,
      "learning_rate": 4.407056263599627e-06,
      "loss": 0.08,
      "step": 14394
    },
    {
      "epoch": 1.1186664594342555,
      "grad_norm": 0.5709071159362793,
      "learning_rate": 4.406667702828723e-06,
      "loss": 0.4649,
      "step": 14395
    },
    {
      "epoch": 1.1187441715884365,
      "grad_norm": 0.7870426774024963,
      "learning_rate": 4.406279142057818e-06,
      "loss": 0.1931,
      "step": 14396
    },
    {
      "epoch": 1.1188218837426174,
      "grad_norm": 1.3455570936203003,
      "learning_rate": 4.405890581286914e-06,
      "loss": 0.8229,
      "step": 14397
    },
    {
      "epoch": 1.1188995958967982,
      "grad_norm": 0.281547486782074,
      "learning_rate": 4.40550202051601e-06,
      "loss": 0.0552,
      "step": 14398
    },
    {
      "epoch": 1.118977308050979,
      "grad_norm": 0.2841366231441498,
      "learning_rate": 4.405113459745105e-06,
      "loss": 0.0571,
      "step": 14399
    },
    {
      "epoch": 1.1190550202051601,
      "grad_norm": 0.22602294385433197,
      "learning_rate": 4.4047248989741995e-06,
      "loss": 0.0234,
      "step": 14400
    },
    {
      "epoch": 1.119132732359341,
      "grad_norm": 0.514249324798584,
      "learning_rate": 4.404336338203295e-06,
      "loss": 0.304,
      "step": 14401
    },
    {
      "epoch": 1.1192104445135218,
      "grad_norm": 0.5427321791648865,
      "learning_rate": 4.403947777432391e-06,
      "loss": 0.352,
      "step": 14402
    },
    {
      "epoch": 1.1192881566677029,
      "grad_norm": 0.1994081735610962,
      "learning_rate": 4.403559216661486e-06,
      "loss": 0.085,
      "step": 14403
    },
    {
      "epoch": 1.1193658688218837,
      "grad_norm": 0.4352903664112091,
      "learning_rate": 4.403170655890582e-06,
      "loss": 0.0785,
      "step": 14404
    },
    {
      "epoch": 1.1194435809760646,
      "grad_norm": 1.061793327331543,
      "learning_rate": 4.402782095119677e-06,
      "loss": 0.5515,
      "step": 14405
    },
    {
      "epoch": 1.1195212931302456,
      "grad_norm": 1.1725568771362305,
      "learning_rate": 4.402393534348773e-06,
      "loss": 0.5312,
      "step": 14406
    },
    {
      "epoch": 1.1195990052844265,
      "grad_norm": 0.3011763095855713,
      "learning_rate": 4.402004973577868e-06,
      "loss": 0.1101,
      "step": 14407
    },
    {
      "epoch": 1.1196767174386073,
      "grad_norm": 0.2617911994457245,
      "learning_rate": 4.401616412806963e-06,
      "loss": 0.0915,
      "step": 14408
    },
    {
      "epoch": 1.1197544295927884,
      "grad_norm": 0.49016812443733215,
      "learning_rate": 4.401227852036059e-06,
      "loss": 0.465,
      "step": 14409
    },
    {
      "epoch": 1.1198321417469692,
      "grad_norm": 0.5572080612182617,
      "learning_rate": 4.400839291265154e-06,
      "loss": 0.2026,
      "step": 14410
    },
    {
      "epoch": 1.11990985390115,
      "grad_norm": 0.3473473787307739,
      "learning_rate": 4.40045073049425e-06,
      "loss": 0.1023,
      "step": 14411
    },
    {
      "epoch": 1.1199875660553311,
      "grad_norm": 0.09981494396924973,
      "learning_rate": 4.400062169723346e-06,
      "loss": 0.0066,
      "step": 14412
    },
    {
      "epoch": 1.120065278209512,
      "grad_norm": 0.6194573044776917,
      "learning_rate": 4.399673608952441e-06,
      "loss": 0.1967,
      "step": 14413
    },
    {
      "epoch": 1.1201429903636928,
      "grad_norm": 1.1718322038650513,
      "learning_rate": 4.399285048181536e-06,
      "loss": 0.2688,
      "step": 14414
    },
    {
      "epoch": 1.1202207025178739,
      "grad_norm": 0.6803310513496399,
      "learning_rate": 4.398896487410631e-06,
      "loss": 0.6698,
      "step": 14415
    },
    {
      "epoch": 1.1202984146720547,
      "grad_norm": 0.34310051798820496,
      "learning_rate": 4.398507926639727e-06,
      "loss": 0.0469,
      "step": 14416
    },
    {
      "epoch": 1.1203761268262356,
      "grad_norm": 0.47694364190101624,
      "learning_rate": 4.398119365868822e-06,
      "loss": 0.438,
      "step": 14417
    },
    {
      "epoch": 1.1204538389804166,
      "grad_norm": 0.22369255125522614,
      "learning_rate": 4.397730805097918e-06,
      "loss": 0.0628,
      "step": 14418
    },
    {
      "epoch": 1.1205315511345975,
      "grad_norm": 0.10955817997455597,
      "learning_rate": 4.397342244327013e-06,
      "loss": 0.0165,
      "step": 14419
    },
    {
      "epoch": 1.1206092632887783,
      "grad_norm": 0.8986348509788513,
      "learning_rate": 4.396953683556109e-06,
      "loss": 0.3615,
      "step": 14420
    },
    {
      "epoch": 1.1206869754429594,
      "grad_norm": 0.49334269762039185,
      "learning_rate": 4.3965651227852045e-06,
      "loss": 0.0784,
      "step": 14421
    },
    {
      "epoch": 1.1207646875971402,
      "grad_norm": 0.5603634119033813,
      "learning_rate": 4.3961765620142994e-06,
      "loss": 0.3257,
      "step": 14422
    },
    {
      "epoch": 1.120842399751321,
      "grad_norm": 0.41309991478919983,
      "learning_rate": 4.395788001243394e-06,
      "loss": 0.0799,
      "step": 14423
    },
    {
      "epoch": 1.1209201119055021,
      "grad_norm": 0.2394554764032364,
      "learning_rate": 4.39539944047249e-06,
      "loss": 0.0458,
      "step": 14424
    },
    {
      "epoch": 1.120997824059683,
      "grad_norm": 0.3741892874240875,
      "learning_rate": 4.395010879701586e-06,
      "loss": 0.3175,
      "step": 14425
    },
    {
      "epoch": 1.1210755362138638,
      "grad_norm": 0.29573482275009155,
      "learning_rate": 4.394622318930682e-06,
      "loss": 0.0553,
      "step": 14426
    },
    {
      "epoch": 1.1211532483680449,
      "grad_norm": 0.5709049105644226,
      "learning_rate": 4.394233758159777e-06,
      "loss": 0.1487,
      "step": 14427
    },
    {
      "epoch": 1.1212309605222257,
      "grad_norm": 0.9625728726387024,
      "learning_rate": 4.393845197388872e-06,
      "loss": 0.1637,
      "step": 14428
    },
    {
      "epoch": 1.1213086726764065,
      "grad_norm": 0.5938054323196411,
      "learning_rate": 4.3934566366179675e-06,
      "loss": 0.1763,
      "step": 14429
    },
    {
      "epoch": 1.1213863848305876,
      "grad_norm": 0.450354665517807,
      "learning_rate": 4.3930680758470624e-06,
      "loss": 0.1933,
      "step": 14430
    },
    {
      "epoch": 1.1214640969847685,
      "grad_norm": 0.41621968150138855,
      "learning_rate": 4.392679515076158e-06,
      "loss": 0.1432,
      "step": 14431
    },
    {
      "epoch": 1.1215418091389493,
      "grad_norm": 0.11275238543748856,
      "learning_rate": 4.392290954305254e-06,
      "loss": 0.0179,
      "step": 14432
    },
    {
      "epoch": 1.1216195212931304,
      "grad_norm": 0.335110068321228,
      "learning_rate": 4.391902393534349e-06,
      "loss": 0.1086,
      "step": 14433
    },
    {
      "epoch": 1.1216972334473112,
      "grad_norm": 0.29922571778297424,
      "learning_rate": 4.391513832763444e-06,
      "loss": 0.0697,
      "step": 14434
    },
    {
      "epoch": 1.121774945601492,
      "grad_norm": 0.6485671401023865,
      "learning_rate": 4.39112527199254e-06,
      "loss": 0.2168,
      "step": 14435
    },
    {
      "epoch": 1.1218526577556729,
      "grad_norm": 0.018168233335018158,
      "learning_rate": 4.3907367112216355e-06,
      "loss": 0.003,
      "step": 14436
    },
    {
      "epoch": 1.121930369909854,
      "grad_norm": 0.19509702920913696,
      "learning_rate": 4.3903481504507305e-06,
      "loss": 0.0957,
      "step": 14437
    },
    {
      "epoch": 1.1220080820640348,
      "grad_norm": 0.6105595827102661,
      "learning_rate": 4.389959589679826e-06,
      "loss": 0.6458,
      "step": 14438
    },
    {
      "epoch": 1.1220857942182156,
      "grad_norm": 0.5845562815666199,
      "learning_rate": 4.389571028908921e-06,
      "loss": 0.2109,
      "step": 14439
    },
    {
      "epoch": 1.1221635063723967,
      "grad_norm": 0.685828685760498,
      "learning_rate": 4.389182468138017e-06,
      "loss": 0.2666,
      "step": 14440
    },
    {
      "epoch": 1.1222412185265775,
      "grad_norm": 0.4716812074184418,
      "learning_rate": 4.388793907367113e-06,
      "loss": 0.598,
      "step": 14441
    },
    {
      "epoch": 1.1223189306807584,
      "grad_norm": 0.659811794757843,
      "learning_rate": 4.388405346596208e-06,
      "loss": 0.14,
      "step": 14442
    },
    {
      "epoch": 1.1223966428349395,
      "grad_norm": 0.5230429768562317,
      "learning_rate": 4.3880167858253036e-06,
      "loss": 0.0452,
      "step": 14443
    },
    {
      "epoch": 1.1224743549891203,
      "grad_norm": 0.17957495152950287,
      "learning_rate": 4.3876282250543985e-06,
      "loss": 0.0587,
      "step": 14444
    },
    {
      "epoch": 1.1225520671433011,
      "grad_norm": 0.3303295075893402,
      "learning_rate": 4.387239664283494e-06,
      "loss": 0.5307,
      "step": 14445
    },
    {
      "epoch": 1.1226297792974822,
      "grad_norm": 1.2311476469039917,
      "learning_rate": 4.38685110351259e-06,
      "loss": 0.5117,
      "step": 14446
    },
    {
      "epoch": 1.122707491451663,
      "grad_norm": 0.7540314197540283,
      "learning_rate": 4.386462542741685e-06,
      "loss": 0.2945,
      "step": 14447
    },
    {
      "epoch": 1.1227852036058439,
      "grad_norm": 0.22505557537078857,
      "learning_rate": 4.38607398197078e-06,
      "loss": 0.0554,
      "step": 14448
    },
    {
      "epoch": 1.122862915760025,
      "grad_norm": 0.978691577911377,
      "learning_rate": 4.385685421199876e-06,
      "loss": 1.1349,
      "step": 14449
    },
    {
      "epoch": 1.1229406279142058,
      "grad_norm": 0.5193814635276794,
      "learning_rate": 4.385296860428972e-06,
      "loss": 0.2305,
      "step": 14450
    },
    {
      "epoch": 1.1230183400683866,
      "grad_norm": 0.43316221237182617,
      "learning_rate": 4.3849082996580665e-06,
      "loss": 0.1106,
      "step": 14451
    },
    {
      "epoch": 1.1230960522225677,
      "grad_norm": 0.5318679809570312,
      "learning_rate": 4.384519738887162e-06,
      "loss": 0.2816,
      "step": 14452
    },
    {
      "epoch": 1.1231737643767485,
      "grad_norm": 0.684090256690979,
      "learning_rate": 4.384131178116257e-06,
      "loss": 0.5491,
      "step": 14453
    },
    {
      "epoch": 1.1232514765309294,
      "grad_norm": 0.32894575595855713,
      "learning_rate": 4.383742617345353e-06,
      "loss": 0.1845,
      "step": 14454
    },
    {
      "epoch": 1.1233291886851104,
      "grad_norm": 1.4308128356933594,
      "learning_rate": 4.383354056574449e-06,
      "loss": 0.6923,
      "step": 14455
    },
    {
      "epoch": 1.1234069008392913,
      "grad_norm": 0.2265811264514923,
      "learning_rate": 4.382965495803544e-06,
      "loss": 0.0657,
      "step": 14456
    },
    {
      "epoch": 1.1234846129934721,
      "grad_norm": 0.6788957118988037,
      "learning_rate": 4.38257693503264e-06,
      "loss": 0.1732,
      "step": 14457
    },
    {
      "epoch": 1.1235623251476532,
      "grad_norm": 0.15244938433170319,
      "learning_rate": 4.3821883742617346e-06,
      "loss": 0.0391,
      "step": 14458
    },
    {
      "epoch": 1.123640037301834,
      "grad_norm": 0.458210825920105,
      "learning_rate": 4.38179981349083e-06,
      "loss": 0.302,
      "step": 14459
    },
    {
      "epoch": 1.1237177494560149,
      "grad_norm": 0.378277450799942,
      "learning_rate": 4.381411252719926e-06,
      "loss": 0.1358,
      "step": 14460
    },
    {
      "epoch": 1.1237954616101957,
      "grad_norm": 0.4689376652240753,
      "learning_rate": 4.381022691949021e-06,
      "loss": 0.1385,
      "step": 14461
    },
    {
      "epoch": 1.1238731737643768,
      "grad_norm": 1.2894035577774048,
      "learning_rate": 4.380634131178116e-06,
      "loss": 0.5082,
      "step": 14462
    },
    {
      "epoch": 1.1239508859185576,
      "grad_norm": 0.4283788800239563,
      "learning_rate": 4.380245570407212e-06,
      "loss": 0.0846,
      "step": 14463
    },
    {
      "epoch": 1.1240285980727385,
      "grad_norm": 0.31038591265678406,
      "learning_rate": 4.379857009636308e-06,
      "loss": 0.2366,
      "step": 14464
    },
    {
      "epoch": 1.1241063102269195,
      "grad_norm": 0.7582801580429077,
      "learning_rate": 4.379468448865403e-06,
      "loss": 0.517,
      "step": 14465
    },
    {
      "epoch": 1.1241840223811004,
      "grad_norm": 0.40707236528396606,
      "learning_rate": 4.379079888094498e-06,
      "loss": 0.0829,
      "step": 14466
    },
    {
      "epoch": 1.1242617345352812,
      "grad_norm": 0.5038475394248962,
      "learning_rate": 4.378691327323593e-06,
      "loss": 0.2954,
      "step": 14467
    },
    {
      "epoch": 1.1243394466894623,
      "grad_norm": 0.13359561562538147,
      "learning_rate": 4.378302766552689e-06,
      "loss": 0.026,
      "step": 14468
    },
    {
      "epoch": 1.1244171588436431,
      "grad_norm": 0.28424572944641113,
      "learning_rate": 4.377914205781785e-06,
      "loss": 0.1055,
      "step": 14469
    },
    {
      "epoch": 1.124494870997824,
      "grad_norm": 0.11564049124717712,
      "learning_rate": 4.37752564501088e-06,
      "loss": 0.0194,
      "step": 14470
    },
    {
      "epoch": 1.124572583152005,
      "grad_norm": 0.38297438621520996,
      "learning_rate": 4.377137084239976e-06,
      "loss": 0.1425,
      "step": 14471
    },
    {
      "epoch": 1.1246502953061859,
      "grad_norm": 0.7015596032142639,
      "learning_rate": 4.376748523469071e-06,
      "loss": 0.1896,
      "step": 14472
    },
    {
      "epoch": 1.1247280074603667,
      "grad_norm": 0.12274209409952164,
      "learning_rate": 4.3763599626981664e-06,
      "loss": 0.0405,
      "step": 14473
    },
    {
      "epoch": 1.1248057196145478,
      "grad_norm": 0.15318608283996582,
      "learning_rate": 4.375971401927262e-06,
      "loss": 0.0842,
      "step": 14474
    },
    {
      "epoch": 1.1248834317687286,
      "grad_norm": 0.17737466096878052,
      "learning_rate": 4.375582841156357e-06,
      "loss": 0.0336,
      "step": 14475
    },
    {
      "epoch": 1.1249611439229095,
      "grad_norm": 0.49434542655944824,
      "learning_rate": 4.375194280385452e-06,
      "loss": 0.4628,
      "step": 14476
    },
    {
      "epoch": 1.1250388560770905,
      "grad_norm": 0.6869981288909912,
      "learning_rate": 4.374805719614548e-06,
      "loss": 0.1653,
      "step": 14477
    },
    {
      "epoch": 1.1251165682312714,
      "grad_norm": 0.1941305696964264,
      "learning_rate": 4.374417158843644e-06,
      "loss": 0.0405,
      "step": 14478
    },
    {
      "epoch": 1.1251942803854522,
      "grad_norm": 0.5642894506454468,
      "learning_rate": 4.374028598072739e-06,
      "loss": 0.4219,
      "step": 14479
    },
    {
      "epoch": 1.1252719925396333,
      "grad_norm": 0.2120305597782135,
      "learning_rate": 4.3736400373018345e-06,
      "loss": 0.0436,
      "step": 14480
    },
    {
      "epoch": 1.1253497046938141,
      "grad_norm": 0.6587957143783569,
      "learning_rate": 4.3732514765309294e-06,
      "loss": 0.249,
      "step": 14481
    },
    {
      "epoch": 1.125427416847995,
      "grad_norm": 0.7228129506111145,
      "learning_rate": 4.372862915760025e-06,
      "loss": 0.2277,
      "step": 14482
    },
    {
      "epoch": 1.125505129002176,
      "grad_norm": 0.8978555202484131,
      "learning_rate": 4.372474354989121e-06,
      "loss": 0.2287,
      "step": 14483
    },
    {
      "epoch": 1.1255828411563569,
      "grad_norm": 0.34354785084724426,
      "learning_rate": 4.372085794218216e-06,
      "loss": 0.091,
      "step": 14484
    },
    {
      "epoch": 1.1256605533105377,
      "grad_norm": 0.2787325084209442,
      "learning_rate": 4.371697233447312e-06,
      "loss": 0.1006,
      "step": 14485
    },
    {
      "epoch": 1.1257382654647188,
      "grad_norm": 0.5067620277404785,
      "learning_rate": 4.371308672676407e-06,
      "loss": 0.1301,
      "step": 14486
    },
    {
      "epoch": 1.1258159776188996,
      "grad_norm": 0.1760106235742569,
      "learning_rate": 4.3709201119055025e-06,
      "loss": 0.075,
      "step": 14487
    },
    {
      "epoch": 1.1258936897730805,
      "grad_norm": 0.6396997570991516,
      "learning_rate": 4.370531551134598e-06,
      "loss": 0.2223,
      "step": 14488
    },
    {
      "epoch": 1.1259714019272615,
      "grad_norm": 0.23511365056037903,
      "learning_rate": 4.370142990363693e-06,
      "loss": 0.0238,
      "step": 14489
    },
    {
      "epoch": 1.1260491140814424,
      "grad_norm": 0.20884811878204346,
      "learning_rate": 4.369754429592788e-06,
      "loss": 0.0723,
      "step": 14490
    },
    {
      "epoch": 1.1261268262356232,
      "grad_norm": 0.4464479982852936,
      "learning_rate": 4.369365868821884e-06,
      "loss": 0.1925,
      "step": 14491
    },
    {
      "epoch": 1.1262045383898043,
      "grad_norm": 0.5461892485618591,
      "learning_rate": 4.36897730805098e-06,
      "loss": 0.3288,
      "step": 14492
    },
    {
      "epoch": 1.1262822505439851,
      "grad_norm": 0.4544045031070709,
      "learning_rate": 4.368588747280075e-06,
      "loss": 0.0909,
      "step": 14493
    },
    {
      "epoch": 1.126359962698166,
      "grad_norm": 0.18583647906780243,
      "learning_rate": 4.3682001865091706e-06,
      "loss": 0.0172,
      "step": 14494
    },
    {
      "epoch": 1.126437674852347,
      "grad_norm": 0.3727692663669586,
      "learning_rate": 4.3678116257382655e-06,
      "loss": 0.088,
      "step": 14495
    },
    {
      "epoch": 1.1265153870065279,
      "grad_norm": 0.9202505350112915,
      "learning_rate": 4.367423064967361e-06,
      "loss": 0.2411,
      "step": 14496
    },
    {
      "epoch": 1.1265930991607087,
      "grad_norm": 0.42020896077156067,
      "learning_rate": 4.367034504196457e-06,
      "loss": 0.2074,
      "step": 14497
    },
    {
      "epoch": 1.1266708113148896,
      "grad_norm": 0.4687524735927582,
      "learning_rate": 4.366645943425552e-06,
      "loss": 0.1219,
      "step": 14498
    },
    {
      "epoch": 1.1267485234690706,
      "grad_norm": 0.5516947507858276,
      "learning_rate": 4.366257382654647e-06,
      "loss": 0.3106,
      "step": 14499
    },
    {
      "epoch": 1.1268262356232515,
      "grad_norm": 0.06458404660224915,
      "learning_rate": 4.365868821883743e-06,
      "loss": 0.0049,
      "step": 14500
    },
    {
      "epoch": 1.1269039477774323,
      "grad_norm": 0.5639061331748962,
      "learning_rate": 4.365480261112839e-06,
      "loss": 0.3146,
      "step": 14501
    },
    {
      "epoch": 1.1269816599316134,
      "grad_norm": 0.4293860197067261,
      "learning_rate": 4.365091700341934e-06,
      "loss": 0.2397,
      "step": 14502
    },
    {
      "epoch": 1.1270593720857942,
      "grad_norm": 0.6912157535552979,
      "learning_rate": 4.364703139571029e-06,
      "loss": 0.1519,
      "step": 14503
    },
    {
      "epoch": 1.127137084239975,
      "grad_norm": 0.3454658091068268,
      "learning_rate": 4.364314578800124e-06,
      "loss": 0.0621,
      "step": 14504
    },
    {
      "epoch": 1.1272147963941561,
      "grad_norm": 0.1342775821685791,
      "learning_rate": 4.36392601802922e-06,
      "loss": 0.0273,
      "step": 14505
    },
    {
      "epoch": 1.127292508548337,
      "grad_norm": 0.19820939004421234,
      "learning_rate": 4.363537457258316e-06,
      "loss": 0.0386,
      "step": 14506
    },
    {
      "epoch": 1.1273702207025178,
      "grad_norm": 0.659839928150177,
      "learning_rate": 4.363148896487411e-06,
      "loss": 0.2842,
      "step": 14507
    },
    {
      "epoch": 1.1274479328566989,
      "grad_norm": 0.3601209819316864,
      "learning_rate": 4.362760335716507e-06,
      "loss": 0.2272,
      "step": 14508
    },
    {
      "epoch": 1.1275256450108797,
      "grad_norm": 0.16955645382404327,
      "learning_rate": 4.362371774945602e-06,
      "loss": 0.0673,
      "step": 14509
    },
    {
      "epoch": 1.1276033571650605,
      "grad_norm": 0.6963047385215759,
      "learning_rate": 4.361983214174697e-06,
      "loss": 0.2485,
      "step": 14510
    },
    {
      "epoch": 1.1276810693192416,
      "grad_norm": 0.8224449157714844,
      "learning_rate": 4.361594653403793e-06,
      "loss": 0.5503,
      "step": 14511
    },
    {
      "epoch": 1.1277587814734225,
      "grad_norm": 0.7850650548934937,
      "learning_rate": 4.361206092632888e-06,
      "loss": 0.4399,
      "step": 14512
    },
    {
      "epoch": 1.1278364936276033,
      "grad_norm": 0.303545743227005,
      "learning_rate": 4.360817531861983e-06,
      "loss": 0.1285,
      "step": 14513
    },
    {
      "epoch": 1.1279142057817844,
      "grad_norm": 0.7119564414024353,
      "learning_rate": 4.360428971091079e-06,
      "loss": 0.0629,
      "step": 14514
    },
    {
      "epoch": 1.1279919179359652,
      "grad_norm": 1.4462651014328003,
      "learning_rate": 4.360040410320175e-06,
      "loss": 0.4702,
      "step": 14515
    },
    {
      "epoch": 1.128069630090146,
      "grad_norm": 0.16665910184383392,
      "learning_rate": 4.3596518495492705e-06,
      "loss": 0.0329,
      "step": 14516
    },
    {
      "epoch": 1.128147342244327,
      "grad_norm": 0.7008572220802307,
      "learning_rate": 4.359263288778365e-06,
      "loss": 0.8081,
      "step": 14517
    },
    {
      "epoch": 1.128225054398508,
      "grad_norm": 1.2189271450042725,
      "learning_rate": 4.35887472800746e-06,
      "loss": 0.1859,
      "step": 14518
    },
    {
      "epoch": 1.1283027665526888,
      "grad_norm": 0.555343508720398,
      "learning_rate": 4.358486167236556e-06,
      "loss": 0.1955,
      "step": 14519
    },
    {
      "epoch": 1.1283804787068696,
      "grad_norm": 0.9189152717590332,
      "learning_rate": 4.358097606465652e-06,
      "loss": 0.4754,
      "step": 14520
    },
    {
      "epoch": 1.1284581908610507,
      "grad_norm": 0.5133121013641357,
      "learning_rate": 4.357709045694747e-06,
      "loss": 0.1602,
      "step": 14521
    },
    {
      "epoch": 1.1285359030152315,
      "grad_norm": 0.40691012144088745,
      "learning_rate": 4.357320484923843e-06,
      "loss": 0.1018,
      "step": 14522
    },
    {
      "epoch": 1.1286136151694124,
      "grad_norm": 0.5762749314308167,
      "learning_rate": 4.356931924152938e-06,
      "loss": 0.1462,
      "step": 14523
    },
    {
      "epoch": 1.1286913273235935,
      "grad_norm": 0.1398937702178955,
      "learning_rate": 4.3565433633820334e-06,
      "loss": 0.015,
      "step": 14524
    },
    {
      "epoch": 1.1287690394777743,
      "grad_norm": 0.692354142665863,
      "learning_rate": 4.356154802611129e-06,
      "loss": 0.4788,
      "step": 14525
    },
    {
      "epoch": 1.1288467516319551,
      "grad_norm": 0.3419159948825836,
      "learning_rate": 4.355766241840224e-06,
      "loss": 0.3592,
      "step": 14526
    },
    {
      "epoch": 1.1289244637861362,
      "grad_norm": 0.9122582674026489,
      "learning_rate": 4.355377681069319e-06,
      "loss": 0.5011,
      "step": 14527
    },
    {
      "epoch": 1.129002175940317,
      "grad_norm": 0.32937371730804443,
      "learning_rate": 4.354989120298415e-06,
      "loss": 0.0656,
      "step": 14528
    },
    {
      "epoch": 1.1290798880944979,
      "grad_norm": 0.30295684933662415,
      "learning_rate": 4.354600559527511e-06,
      "loss": 0.1061,
      "step": 14529
    },
    {
      "epoch": 1.129157600248679,
      "grad_norm": 0.07490967214107513,
      "learning_rate": 4.3542119987566065e-06,
      "loss": 0.0278,
      "step": 14530
    },
    {
      "epoch": 1.1292353124028598,
      "grad_norm": 0.49904608726501465,
      "learning_rate": 4.3538234379857015e-06,
      "loss": 0.1921,
      "step": 14531
    },
    {
      "epoch": 1.1293130245570406,
      "grad_norm": 0.42873483896255493,
      "learning_rate": 4.3534348772147964e-06,
      "loss": 0.1708,
      "step": 14532
    },
    {
      "epoch": 1.1293907367112217,
      "grad_norm": 0.15157125890254974,
      "learning_rate": 4.353046316443892e-06,
      "loss": 0.021,
      "step": 14533
    },
    {
      "epoch": 1.1294684488654025,
      "grad_norm": 0.5254427194595337,
      "learning_rate": 4.352657755672988e-06,
      "loss": 0.509,
      "step": 14534
    },
    {
      "epoch": 1.1295461610195834,
      "grad_norm": 0.8336669206619263,
      "learning_rate": 4.352269194902083e-06,
      "loss": 0.3426,
      "step": 14535
    },
    {
      "epoch": 1.1296238731737644,
      "grad_norm": 0.3429655432701111,
      "learning_rate": 4.351880634131179e-06,
      "loss": 0.1981,
      "step": 14536
    },
    {
      "epoch": 1.1297015853279453,
      "grad_norm": 0.7086704969406128,
      "learning_rate": 4.351492073360274e-06,
      "loss": 0.4715,
      "step": 14537
    },
    {
      "epoch": 1.1297792974821261,
      "grad_norm": 0.45216765999794006,
      "learning_rate": 4.3511035125893695e-06,
      "loss": 0.0897,
      "step": 14538
    },
    {
      "epoch": 1.1298570096363072,
      "grad_norm": 0.839216411113739,
      "learning_rate": 4.350714951818465e-06,
      "loss": 0.1328,
      "step": 14539
    },
    {
      "epoch": 1.129934721790488,
      "grad_norm": 0.7281966209411621,
      "learning_rate": 4.35032639104756e-06,
      "loss": 0.1149,
      "step": 14540
    },
    {
      "epoch": 1.1300124339446689,
      "grad_norm": 0.3133087754249573,
      "learning_rate": 4.349937830276655e-06,
      "loss": 0.0839,
      "step": 14541
    },
    {
      "epoch": 1.13009014609885,
      "grad_norm": 0.26649388670921326,
      "learning_rate": 4.349549269505751e-06,
      "loss": 0.0685,
      "step": 14542
    },
    {
      "epoch": 1.1301678582530308,
      "grad_norm": 0.6540003418922424,
      "learning_rate": 4.349160708734847e-06,
      "loss": 0.3815,
      "step": 14543
    },
    {
      "epoch": 1.1302455704072116,
      "grad_norm": 0.30263835191726685,
      "learning_rate": 4.348772147963942e-06,
      "loss": 0.1484,
      "step": 14544
    },
    {
      "epoch": 1.1303232825613927,
      "grad_norm": 0.16779659688472748,
      "learning_rate": 4.3483835871930376e-06,
      "loss": 0.042,
      "step": 14545
    },
    {
      "epoch": 1.1304009947155735,
      "grad_norm": 0.3829667866230011,
      "learning_rate": 4.3479950264221325e-06,
      "loss": 0.0734,
      "step": 14546
    },
    {
      "epoch": 1.1304787068697544,
      "grad_norm": 0.4438749849796295,
      "learning_rate": 4.347606465651228e-06,
      "loss": 0.1311,
      "step": 14547
    },
    {
      "epoch": 1.1305564190239354,
      "grad_norm": 0.33748579025268555,
      "learning_rate": 4.347217904880324e-06,
      "loss": 0.4618,
      "step": 14548
    },
    {
      "epoch": 1.1306341311781163,
      "grad_norm": 0.38016635179519653,
      "learning_rate": 4.346829344109419e-06,
      "loss": 0.3569,
      "step": 14549
    },
    {
      "epoch": 1.1307118433322971,
      "grad_norm": 0.9652995467185974,
      "learning_rate": 4.346440783338515e-06,
      "loss": 0.2732,
      "step": 14550
    },
    {
      "epoch": 1.1307895554864782,
      "grad_norm": 0.08715828508138657,
      "learning_rate": 4.34605222256761e-06,
      "loss": 0.0378,
      "step": 14551
    },
    {
      "epoch": 1.130867267640659,
      "grad_norm": 0.48544877767562866,
      "learning_rate": 4.345663661796706e-06,
      "loss": 0.1609,
      "step": 14552
    },
    {
      "epoch": 1.1309449797948399,
      "grad_norm": 0.07018303871154785,
      "learning_rate": 4.345275101025801e-06,
      "loss": 0.0167,
      "step": 14553
    },
    {
      "epoch": 1.131022691949021,
      "grad_norm": 0.30102378129959106,
      "learning_rate": 4.344886540254896e-06,
      "loss": 0.1425,
      "step": 14554
    },
    {
      "epoch": 1.1311004041032018,
      "grad_norm": 0.3131944537162781,
      "learning_rate": 4.344497979483991e-06,
      "loss": 0.1829,
      "step": 14555
    },
    {
      "epoch": 1.1311781162573826,
      "grad_norm": 0.31657060980796814,
      "learning_rate": 4.344109418713087e-06,
      "loss": 0.045,
      "step": 14556
    },
    {
      "epoch": 1.1312558284115637,
      "grad_norm": 0.25961315631866455,
      "learning_rate": 4.343720857942182e-06,
      "loss": 0.1659,
      "step": 14557
    },
    {
      "epoch": 1.1313335405657445,
      "grad_norm": 0.2728247046470642,
      "learning_rate": 4.343332297171278e-06,
      "loss": 0.0664,
      "step": 14558
    },
    {
      "epoch": 1.1314112527199254,
      "grad_norm": 0.12690062820911407,
      "learning_rate": 4.342943736400374e-06,
      "loss": 0.0362,
      "step": 14559
    },
    {
      "epoch": 1.1314889648741062,
      "grad_norm": 0.3464299440383911,
      "learning_rate": 4.342555175629469e-06,
      "loss": 0.0937,
      "step": 14560
    },
    {
      "epoch": 1.1315666770282873,
      "grad_norm": 0.12715110182762146,
      "learning_rate": 4.342166614858564e-06,
      "loss": 0.0341,
      "step": 14561
    },
    {
      "epoch": 1.1316443891824681,
      "grad_norm": 0.3341621458530426,
      "learning_rate": 4.341778054087659e-06,
      "loss": 0.0908,
      "step": 14562
    },
    {
      "epoch": 1.131722101336649,
      "grad_norm": 0.18890272080898285,
      "learning_rate": 4.341389493316755e-06,
      "loss": 0.0283,
      "step": 14563
    },
    {
      "epoch": 1.13179981349083,
      "grad_norm": 0.5694901347160339,
      "learning_rate": 4.341000932545851e-06,
      "loss": 0.2027,
      "step": 14564
    },
    {
      "epoch": 1.1318775256450109,
      "grad_norm": 0.17151810228824615,
      "learning_rate": 4.340612371774946e-06,
      "loss": 0.2575,
      "step": 14565
    },
    {
      "epoch": 1.1319552377991917,
      "grad_norm": 0.37576231360435486,
      "learning_rate": 4.340223811004041e-06,
      "loss": 0.053,
      "step": 14566
    },
    {
      "epoch": 1.1320329499533728,
      "grad_norm": 0.4838593900203705,
      "learning_rate": 4.339835250233137e-06,
      "loss": 0.1134,
      "step": 14567
    },
    {
      "epoch": 1.1321106621075536,
      "grad_norm": 0.9714879989624023,
      "learning_rate": 4.339446689462232e-06,
      "loss": 1.9739,
      "step": 14568
    },
    {
      "epoch": 1.1321883742617345,
      "grad_norm": 0.23949278891086578,
      "learning_rate": 4.339058128691327e-06,
      "loss": 0.0741,
      "step": 14569
    },
    {
      "epoch": 1.1322660864159155,
      "grad_norm": 0.18241778016090393,
      "learning_rate": 4.338669567920423e-06,
      "loss": 0.0308,
      "step": 14570
    },
    {
      "epoch": 1.1323437985700964,
      "grad_norm": 0.5093855261802673,
      "learning_rate": 4.338281007149518e-06,
      "loss": 0.4504,
      "step": 14571
    },
    {
      "epoch": 1.1324215107242772,
      "grad_norm": 0.5834211111068726,
      "learning_rate": 4.337892446378614e-06,
      "loss": 0.9347,
      "step": 14572
    },
    {
      "epoch": 1.1324992228784583,
      "grad_norm": 0.6381341218948364,
      "learning_rate": 4.33750388560771e-06,
      "loss": 0.1326,
      "step": 14573
    },
    {
      "epoch": 1.1325769350326391,
      "grad_norm": 0.2372719645500183,
      "learning_rate": 4.337115324836805e-06,
      "loss": 0.1599,
      "step": 14574
    },
    {
      "epoch": 1.13265464718682,
      "grad_norm": 0.6861530542373657,
      "learning_rate": 4.3367267640659e-06,
      "loss": 0.2709,
      "step": 14575
    },
    {
      "epoch": 1.132732359341001,
      "grad_norm": 0.3288910388946533,
      "learning_rate": 4.336338203294995e-06,
      "loss": 0.1507,
      "step": 14576
    },
    {
      "epoch": 1.1328100714951819,
      "grad_norm": 0.8504912853240967,
      "learning_rate": 4.335949642524091e-06,
      "loss": 0.5547,
      "step": 14577
    },
    {
      "epoch": 1.1328877836493627,
      "grad_norm": 0.2850319743156433,
      "learning_rate": 4.335561081753187e-06,
      "loss": 0.103,
      "step": 14578
    },
    {
      "epoch": 1.1329654958035436,
      "grad_norm": 0.22342854738235474,
      "learning_rate": 4.335172520982282e-06,
      "loss": 0.0866,
      "step": 14579
    },
    {
      "epoch": 1.1330432079577246,
      "grad_norm": 0.32886743545532227,
      "learning_rate": 4.334783960211377e-06,
      "loss": 0.1201,
      "step": 14580
    },
    {
      "epoch": 1.1331209201119055,
      "grad_norm": 0.32532140612602234,
      "learning_rate": 4.334395399440473e-06,
      "loss": 0.1036,
      "step": 14581
    },
    {
      "epoch": 1.1331986322660863,
      "grad_norm": 0.4795648753643036,
      "learning_rate": 4.3340068386695685e-06,
      "loss": 0.2163,
      "step": 14582
    },
    {
      "epoch": 1.1332763444202674,
      "grad_norm": 0.08759942650794983,
      "learning_rate": 4.3336182778986634e-06,
      "loss": 0.0144,
      "step": 14583
    },
    {
      "epoch": 1.1333540565744482,
      "grad_norm": 0.23544806241989136,
      "learning_rate": 4.333229717127759e-06,
      "loss": 0.0344,
      "step": 14584
    },
    {
      "epoch": 1.133431768728629,
      "grad_norm": 0.32654666900634766,
      "learning_rate": 4.332841156356854e-06,
      "loss": 0.1864,
      "step": 14585
    },
    {
      "epoch": 1.1335094808828101,
      "grad_norm": 0.18433956801891327,
      "learning_rate": 4.33245259558595e-06,
      "loss": 0.031,
      "step": 14586
    },
    {
      "epoch": 1.133587193036991,
      "grad_norm": 0.1725796014070511,
      "learning_rate": 4.332064034815046e-06,
      "loss": 0.014,
      "step": 14587
    },
    {
      "epoch": 1.1336649051911718,
      "grad_norm": 0.59778892993927,
      "learning_rate": 4.331675474044141e-06,
      "loss": 0.5241,
      "step": 14588
    },
    {
      "epoch": 1.1337426173453529,
      "grad_norm": 0.7769965529441833,
      "learning_rate": 4.331286913273236e-06,
      "loss": 0.5755,
      "step": 14589
    },
    {
      "epoch": 1.1338203294995337,
      "grad_norm": 0.40195098519325256,
      "learning_rate": 4.3308983525023315e-06,
      "loss": 0.1291,
      "step": 14590
    },
    {
      "epoch": 1.1338980416537146,
      "grad_norm": 0.3062434196472168,
      "learning_rate": 4.330509791731427e-06,
      "loss": 0.0744,
      "step": 14591
    },
    {
      "epoch": 1.1339757538078956,
      "grad_norm": 0.44993019104003906,
      "learning_rate": 4.330121230960523e-06,
      "loss": 0.3194,
      "step": 14592
    },
    {
      "epoch": 1.1340534659620765,
      "grad_norm": 0.7451509237289429,
      "learning_rate": 4.329732670189618e-06,
      "loss": 0.3409,
      "step": 14593
    },
    {
      "epoch": 1.1341311781162573,
      "grad_norm": 0.2045741081237793,
      "learning_rate": 4.329344109418713e-06,
      "loss": 0.0942,
      "step": 14594
    },
    {
      "epoch": 1.1342088902704384,
      "grad_norm": 1.2346771955490112,
      "learning_rate": 4.328955548647809e-06,
      "loss": 0.843,
      "step": 14595
    },
    {
      "epoch": 1.1342866024246192,
      "grad_norm": 0.0888834074139595,
      "learning_rate": 4.3285669878769046e-06,
      "loss": 0.03,
      "step": 14596
    },
    {
      "epoch": 1.1343643145788,
      "grad_norm": 0.16686110198497772,
      "learning_rate": 4.3281784271059995e-06,
      "loss": 0.0481,
      "step": 14597
    },
    {
      "epoch": 1.1344420267329811,
      "grad_norm": 0.29801031947135925,
      "learning_rate": 4.327789866335095e-06,
      "loss": 0.2014,
      "step": 14598
    },
    {
      "epoch": 1.134519738887162,
      "grad_norm": 0.07650744169950485,
      "learning_rate": 4.32740130556419e-06,
      "loss": 0.0113,
      "step": 14599
    },
    {
      "epoch": 1.1345974510413428,
      "grad_norm": 1.8607832193374634,
      "learning_rate": 4.327012744793286e-06,
      "loss": 0.2539,
      "step": 14600
    },
    {
      "epoch": 1.1346751631955239,
      "grad_norm": 0.19920144975185394,
      "learning_rate": 4.326624184022382e-06,
      "loss": 0.0278,
      "step": 14601
    },
    {
      "epoch": 1.1347528753497047,
      "grad_norm": 0.5135956406593323,
      "learning_rate": 4.326235623251477e-06,
      "loss": 0.1552,
      "step": 14602
    },
    {
      "epoch": 1.1348305875038855,
      "grad_norm": 0.3189451992511749,
      "learning_rate": 4.325847062480572e-06,
      "loss": 0.1114,
      "step": 14603
    },
    {
      "epoch": 1.1349082996580666,
      "grad_norm": 0.32982370257377625,
      "learning_rate": 4.3254585017096675e-06,
      "loss": 0.0885,
      "step": 14604
    },
    {
      "epoch": 1.1349860118122475,
      "grad_norm": 0.23668821156024933,
      "learning_rate": 4.325069940938763e-06,
      "loss": 0.0596,
      "step": 14605
    },
    {
      "epoch": 1.1350637239664283,
      "grad_norm": 0.20406247675418854,
      "learning_rate": 4.324681380167859e-06,
      "loss": 0.1117,
      "step": 14606
    },
    {
      "epoch": 1.1351414361206094,
      "grad_norm": 0.7391605973243713,
      "learning_rate": 4.324292819396954e-06,
      "loss": 0.3891,
      "step": 14607
    },
    {
      "epoch": 1.1352191482747902,
      "grad_norm": 0.5167508721351624,
      "learning_rate": 4.323904258626049e-06,
      "loss": 0.315,
      "step": 14608
    },
    {
      "epoch": 1.135296860428971,
      "grad_norm": 0.3147906959056854,
      "learning_rate": 4.323515697855145e-06,
      "loss": 0.0655,
      "step": 14609
    },
    {
      "epoch": 1.135374572583152,
      "grad_norm": 0.4401661157608032,
      "learning_rate": 4.323127137084241e-06,
      "loss": 0.1069,
      "step": 14610
    },
    {
      "epoch": 1.135452284737333,
      "grad_norm": 0.24612417817115784,
      "learning_rate": 4.322738576313336e-06,
      "loss": 0.0458,
      "step": 14611
    },
    {
      "epoch": 1.1355299968915138,
      "grad_norm": 0.5869178175926208,
      "learning_rate": 4.322350015542431e-06,
      "loss": 0.3561,
      "step": 14612
    },
    {
      "epoch": 1.1356077090456949,
      "grad_norm": 0.4108210802078247,
      "learning_rate": 4.321961454771526e-06,
      "loss": 0.1093,
      "step": 14613
    },
    {
      "epoch": 1.1356854211998757,
      "grad_norm": 0.21562889218330383,
      "learning_rate": 4.321572894000622e-06,
      "loss": 0.0985,
      "step": 14614
    },
    {
      "epoch": 1.1357631333540565,
      "grad_norm": 0.32285550236701965,
      "learning_rate": 4.321184333229718e-06,
      "loss": 0.0874,
      "step": 14615
    },
    {
      "epoch": 1.1358408455082376,
      "grad_norm": 0.12796762585639954,
      "learning_rate": 4.320795772458813e-06,
      "loss": 0.0162,
      "step": 14616
    },
    {
      "epoch": 1.1359185576624184,
      "grad_norm": 0.24979884922504425,
      "learning_rate": 4.320407211687908e-06,
      "loss": 0.0539,
      "step": 14617
    },
    {
      "epoch": 1.1359962698165993,
      "grad_norm": 0.7511030435562134,
      "learning_rate": 4.320018650917004e-06,
      "loss": 0.8669,
      "step": 14618
    },
    {
      "epoch": 1.1360739819707801,
      "grad_norm": 0.5343394875526428,
      "learning_rate": 4.319630090146099e-06,
      "loss": 0.185,
      "step": 14619
    },
    {
      "epoch": 1.1361516941249612,
      "grad_norm": 0.5156289339065552,
      "learning_rate": 4.319241529375194e-06,
      "loss": 0.3182,
      "step": 14620
    },
    {
      "epoch": 1.136229406279142,
      "grad_norm": 0.8200526237487793,
      "learning_rate": 4.31885296860429e-06,
      "loss": 0.2944,
      "step": 14621
    },
    {
      "epoch": 1.1363071184333229,
      "grad_norm": 0.9062533974647522,
      "learning_rate": 4.318464407833385e-06,
      "loss": 0.2075,
      "step": 14622
    },
    {
      "epoch": 1.136384830587504,
      "grad_norm": 0.44281280040740967,
      "learning_rate": 4.318075847062481e-06,
      "loss": 0.1572,
      "step": 14623
    },
    {
      "epoch": 1.1364625427416848,
      "grad_norm": 0.5954182744026184,
      "learning_rate": 4.317687286291577e-06,
      "loss": 0.3234,
      "step": 14624
    },
    {
      "epoch": 1.1365402548958656,
      "grad_norm": 0.37267860770225525,
      "learning_rate": 4.317298725520672e-06,
      "loss": 0.1308,
      "step": 14625
    },
    {
      "epoch": 1.1366179670500467,
      "grad_norm": 0.7834171652793884,
      "learning_rate": 4.3169101647497675e-06,
      "loss": 0.5654,
      "step": 14626
    },
    {
      "epoch": 1.1366956792042275,
      "grad_norm": 0.7335860729217529,
      "learning_rate": 4.316521603978862e-06,
      "loss": 0.5073,
      "step": 14627
    },
    {
      "epoch": 1.1367733913584084,
      "grad_norm": 0.3289234936237335,
      "learning_rate": 4.316133043207958e-06,
      "loss": 0.285,
      "step": 14628
    },
    {
      "epoch": 1.1368511035125894,
      "grad_norm": 0.8983393907546997,
      "learning_rate": 4.315744482437054e-06,
      "loss": 0.4093,
      "step": 14629
    },
    {
      "epoch": 1.1369288156667703,
      "grad_norm": 0.573377251625061,
      "learning_rate": 4.315355921666149e-06,
      "loss": 0.2123,
      "step": 14630
    },
    {
      "epoch": 1.1370065278209511,
      "grad_norm": 0.5460216999053955,
      "learning_rate": 4.314967360895244e-06,
      "loss": 0.1375,
      "step": 14631
    },
    {
      "epoch": 1.1370842399751322,
      "grad_norm": 0.5825854539871216,
      "learning_rate": 4.31457880012434e-06,
      "loss": 0.4092,
      "step": 14632
    },
    {
      "epoch": 1.137161952129313,
      "grad_norm": 0.5721986293792725,
      "learning_rate": 4.3141902393534355e-06,
      "loss": 0.0794,
      "step": 14633
    },
    {
      "epoch": 1.1372396642834939,
      "grad_norm": 0.429514080286026,
      "learning_rate": 4.3138016785825304e-06,
      "loss": 0.4584,
      "step": 14634
    },
    {
      "epoch": 1.137317376437675,
      "grad_norm": 0.4218169152736664,
      "learning_rate": 4.313413117811626e-06,
      "loss": 0.288,
      "step": 14635
    },
    {
      "epoch": 1.1373950885918558,
      "grad_norm": 0.5559373497962952,
      "learning_rate": 4.313024557040721e-06,
      "loss": 0.2124,
      "step": 14636
    },
    {
      "epoch": 1.1374728007460366,
      "grad_norm": 0.49064046144485474,
      "learning_rate": 4.312635996269817e-06,
      "loss": 0.2297,
      "step": 14637
    },
    {
      "epoch": 1.1375505129002175,
      "grad_norm": 0.30389514565467834,
      "learning_rate": 4.312247435498913e-06,
      "loss": 0.0645,
      "step": 14638
    },
    {
      "epoch": 1.1376282250543985,
      "grad_norm": 0.5363162755966187,
      "learning_rate": 4.311858874728008e-06,
      "loss": 0.1069,
      "step": 14639
    },
    {
      "epoch": 1.1377059372085794,
      "grad_norm": 0.24731463193893433,
      "learning_rate": 4.3114703139571035e-06,
      "loss": 0.0689,
      "step": 14640
    },
    {
      "epoch": 1.1377836493627602,
      "grad_norm": 2.0411009788513184,
      "learning_rate": 4.3110817531861985e-06,
      "loss": 0.5329,
      "step": 14641
    },
    {
      "epoch": 1.1378613615169413,
      "grad_norm": 0.16984058916568756,
      "learning_rate": 4.310693192415294e-06,
      "loss": 0.0295,
      "step": 14642
    },
    {
      "epoch": 1.1379390736711221,
      "grad_norm": 0.22327004373073578,
      "learning_rate": 4.31030463164439e-06,
      "loss": 0.0733,
      "step": 14643
    },
    {
      "epoch": 1.138016785825303,
      "grad_norm": 0.47562432289123535,
      "learning_rate": 4.309916070873485e-06,
      "loss": 0.08,
      "step": 14644
    },
    {
      "epoch": 1.138094497979484,
      "grad_norm": 1.2317274808883667,
      "learning_rate": 4.30952751010258e-06,
      "loss": 0.5483,
      "step": 14645
    },
    {
      "epoch": 1.1381722101336649,
      "grad_norm": 0.410038024187088,
      "learning_rate": 4.309138949331676e-06,
      "loss": 0.1818,
      "step": 14646
    },
    {
      "epoch": 1.1382499222878457,
      "grad_norm": 1.1263649463653564,
      "learning_rate": 4.3087503885607716e-06,
      "loss": 0.3484,
      "step": 14647
    },
    {
      "epoch": 1.1383276344420268,
      "grad_norm": 0.2623891234397888,
      "learning_rate": 4.3083618277898665e-06,
      "loss": 0.0789,
      "step": 14648
    },
    {
      "epoch": 1.1384053465962076,
      "grad_norm": 0.4470149576663971,
      "learning_rate": 4.307973267018962e-06,
      "loss": 0.1062,
      "step": 14649
    },
    {
      "epoch": 1.1384830587503885,
      "grad_norm": 0.34828752279281616,
      "learning_rate": 4.307584706248057e-06,
      "loss": 0.064,
      "step": 14650
    },
    {
      "epoch": 1.1385607709045695,
      "grad_norm": 0.8156434893608093,
      "learning_rate": 4.307196145477153e-06,
      "loss": 0.234,
      "step": 14651
    },
    {
      "epoch": 1.1386384830587504,
      "grad_norm": 0.50605708360672,
      "learning_rate": 4.306807584706249e-06,
      "loss": 0.251,
      "step": 14652
    },
    {
      "epoch": 1.1387161952129312,
      "grad_norm": 0.9041293263435364,
      "learning_rate": 4.306419023935344e-06,
      "loss": 0.5305,
      "step": 14653
    },
    {
      "epoch": 1.1387939073671123,
      "grad_norm": 0.5781218409538269,
      "learning_rate": 4.30603046316444e-06,
      "loss": 0.0777,
      "step": 14654
    },
    {
      "epoch": 1.1388716195212931,
      "grad_norm": 0.6047961115837097,
      "learning_rate": 4.3056419023935345e-06,
      "loss": 0.1366,
      "step": 14655
    },
    {
      "epoch": 1.138949331675474,
      "grad_norm": 0.3813011646270752,
      "learning_rate": 4.30525334162263e-06,
      "loss": 0.1036,
      "step": 14656
    },
    {
      "epoch": 1.139027043829655,
      "grad_norm": 0.1494067758321762,
      "learning_rate": 4.304864780851726e-06,
      "loss": 0.0549,
      "step": 14657
    },
    {
      "epoch": 1.1391047559838359,
      "grad_norm": 2.1831979751586914,
      "learning_rate": 4.304476220080821e-06,
      "loss": 0.6311,
      "step": 14658
    },
    {
      "epoch": 1.1391824681380167,
      "grad_norm": 0.18920780718326569,
      "learning_rate": 4.304087659309916e-06,
      "loss": 0.093,
      "step": 14659
    },
    {
      "epoch": 1.1392601802921978,
      "grad_norm": 0.6639572978019714,
      "learning_rate": 4.303699098539012e-06,
      "loss": 0.5187,
      "step": 14660
    },
    {
      "epoch": 1.1393378924463786,
      "grad_norm": 0.7916200160980225,
      "learning_rate": 4.303310537768108e-06,
      "loss": 0.3192,
      "step": 14661
    },
    {
      "epoch": 1.1394156046005595,
      "grad_norm": 0.3888002634048462,
      "learning_rate": 4.302921976997203e-06,
      "loss": 0.08,
      "step": 14662
    },
    {
      "epoch": 1.1394933167547405,
      "grad_norm": 0.6194896697998047,
      "learning_rate": 4.302533416226298e-06,
      "loss": 0.0688,
      "step": 14663
    },
    {
      "epoch": 1.1395710289089214,
      "grad_norm": 0.2692502737045288,
      "learning_rate": 4.302144855455393e-06,
      "loss": 0.0821,
      "step": 14664
    },
    {
      "epoch": 1.1396487410631022,
      "grad_norm": 0.37312817573547363,
      "learning_rate": 4.301756294684489e-06,
      "loss": 0.0509,
      "step": 14665
    },
    {
      "epoch": 1.1397264532172833,
      "grad_norm": 0.6331247091293335,
      "learning_rate": 4.301367733913585e-06,
      "loss": 0.4235,
      "step": 14666
    },
    {
      "epoch": 1.1398041653714641,
      "grad_norm": 0.3763071596622467,
      "learning_rate": 4.30097917314268e-06,
      "loss": 0.0821,
      "step": 14667
    },
    {
      "epoch": 1.139881877525645,
      "grad_norm": 0.5252389311790466,
      "learning_rate": 4.300590612371776e-06,
      "loss": 0.2058,
      "step": 14668
    },
    {
      "epoch": 1.139959589679826,
      "grad_norm": 0.5677880644798279,
      "learning_rate": 4.300202051600871e-06,
      "loss": 0.2366,
      "step": 14669
    },
    {
      "epoch": 1.1400373018340069,
      "grad_norm": 0.6479101181030273,
      "learning_rate": 4.299813490829966e-06,
      "loss": 0.19,
      "step": 14670
    },
    {
      "epoch": 1.1401150139881877,
      "grad_norm": 0.8793609738349915,
      "learning_rate": 4.299424930059062e-06,
      "loss": 0.3404,
      "step": 14671
    },
    {
      "epoch": 1.1401927261423688,
      "grad_norm": 0.3847271800041199,
      "learning_rate": 4.299036369288157e-06,
      "loss": 0.1229,
      "step": 14672
    },
    {
      "epoch": 1.1402704382965496,
      "grad_norm": 0.24659103155136108,
      "learning_rate": 4.298647808517252e-06,
      "loss": 0.1059,
      "step": 14673
    },
    {
      "epoch": 1.1403481504507305,
      "grad_norm": 0.347929984331131,
      "learning_rate": 4.298259247746348e-06,
      "loss": 0.0572,
      "step": 14674
    },
    {
      "epoch": 1.1404258626049115,
      "grad_norm": 0.3064638674259186,
      "learning_rate": 4.297870686975444e-06,
      "loss": 0.1553,
      "step": 14675
    },
    {
      "epoch": 1.1405035747590924,
      "grad_norm": 0.47497764229774475,
      "learning_rate": 4.297482126204539e-06,
      "loss": 0.1078,
      "step": 14676
    },
    {
      "epoch": 1.1405812869132732,
      "grad_norm": 0.43961796164512634,
      "learning_rate": 4.2970935654336345e-06,
      "loss": 0.1723,
      "step": 14677
    },
    {
      "epoch": 1.1406589990674543,
      "grad_norm": 0.16929055750370026,
      "learning_rate": 4.296705004662729e-06,
      "loss": 0.0762,
      "step": 14678
    },
    {
      "epoch": 1.1407367112216351,
      "grad_norm": 0.4955122470855713,
      "learning_rate": 4.296316443891825e-06,
      "loss": 0.2799,
      "step": 14679
    },
    {
      "epoch": 1.140814423375816,
      "grad_norm": 0.700385570526123,
      "learning_rate": 4.29592788312092e-06,
      "loss": 0.1023,
      "step": 14680
    },
    {
      "epoch": 1.1408921355299968,
      "grad_norm": 0.17406725883483887,
      "learning_rate": 4.295539322350016e-06,
      "loss": 0.0804,
      "step": 14681
    },
    {
      "epoch": 1.1409698476841779,
      "grad_norm": 0.30777743458747864,
      "learning_rate": 4.295150761579112e-06,
      "loss": 0.03,
      "step": 14682
    },
    {
      "epoch": 1.1410475598383587,
      "grad_norm": 0.18269497156143188,
      "learning_rate": 4.294762200808207e-06,
      "loss": 0.1013,
      "step": 14683
    },
    {
      "epoch": 1.1411252719925395,
      "grad_norm": 0.17846444249153137,
      "learning_rate": 4.294373640037302e-06,
      "loss": 0.0638,
      "step": 14684
    },
    {
      "epoch": 1.1412029841467206,
      "grad_norm": 1.5404404401779175,
      "learning_rate": 4.2939850792663974e-06,
      "loss": 1.6239,
      "step": 14685
    },
    {
      "epoch": 1.1412806963009015,
      "grad_norm": 0.3237193524837494,
      "learning_rate": 4.293596518495493e-06,
      "loss": 0.0906,
      "step": 14686
    },
    {
      "epoch": 1.1413584084550823,
      "grad_norm": 0.6828633546829224,
      "learning_rate": 4.293207957724588e-06,
      "loss": 0.1493,
      "step": 14687
    },
    {
      "epoch": 1.1414361206092634,
      "grad_norm": 0.6184950470924377,
      "learning_rate": 4.292819396953684e-06,
      "loss": 0.3577,
      "step": 14688
    },
    {
      "epoch": 1.1415138327634442,
      "grad_norm": 0.17261706292629242,
      "learning_rate": 4.292430836182779e-06,
      "loss": 0.03,
      "step": 14689
    },
    {
      "epoch": 1.141591544917625,
      "grad_norm": 0.1868642270565033,
      "learning_rate": 4.292042275411875e-06,
      "loss": 0.0594,
      "step": 14690
    },
    {
      "epoch": 1.141669257071806,
      "grad_norm": 0.7210533618927002,
      "learning_rate": 4.2916537146409705e-06,
      "loss": 0.122,
      "step": 14691
    },
    {
      "epoch": 1.141746969225987,
      "grad_norm": 0.23000648617744446,
      "learning_rate": 4.2912651538700655e-06,
      "loss": 0.1022,
      "step": 14692
    },
    {
      "epoch": 1.1418246813801678,
      "grad_norm": 0.9218196868896484,
      "learning_rate": 4.2908765930991604e-06,
      "loss": 0.346,
      "step": 14693
    },
    {
      "epoch": 1.1419023935343489,
      "grad_norm": 0.8798534274101257,
      "learning_rate": 4.290488032328256e-06,
      "loss": 0.627,
      "step": 14694
    },
    {
      "epoch": 1.1419801056885297,
      "grad_norm": 0.22920913994312286,
      "learning_rate": 4.290099471557352e-06,
      "loss": 0.1058,
      "step": 14695
    },
    {
      "epoch": 1.1420578178427105,
      "grad_norm": 0.3458661437034607,
      "learning_rate": 4.289710910786447e-06,
      "loss": 0.1168,
      "step": 14696
    },
    {
      "epoch": 1.1421355299968916,
      "grad_norm": 0.5781510472297668,
      "learning_rate": 4.289322350015543e-06,
      "loss": 0.2408,
      "step": 14697
    },
    {
      "epoch": 1.1422132421510724,
      "grad_norm": 0.8747134804725647,
      "learning_rate": 4.288933789244638e-06,
      "loss": 0.4512,
      "step": 14698
    },
    {
      "epoch": 1.1422909543052533,
      "grad_norm": 0.9546849727630615,
      "learning_rate": 4.2885452284737335e-06,
      "loss": 0.5304,
      "step": 14699
    },
    {
      "epoch": 1.1423686664594341,
      "grad_norm": 0.494974821805954,
      "learning_rate": 4.288156667702829e-06,
      "loss": 0.2359,
      "step": 14700
    },
    {
      "epoch": 1.1424463786136152,
      "grad_norm": 0.4273033142089844,
      "learning_rate": 4.287768106931924e-06,
      "loss": 0.2352,
      "step": 14701
    },
    {
      "epoch": 1.142524090767796,
      "grad_norm": 0.19696220755577087,
      "learning_rate": 4.28737954616102e-06,
      "loss": 0.1042,
      "step": 14702
    },
    {
      "epoch": 1.1426018029219769,
      "grad_norm": 0.7278681993484497,
      "learning_rate": 4.286990985390115e-06,
      "loss": 0.3972,
      "step": 14703
    },
    {
      "epoch": 1.142679515076158,
      "grad_norm": 0.876655101776123,
      "learning_rate": 4.286602424619211e-06,
      "loss": 0.0882,
      "step": 14704
    },
    {
      "epoch": 1.1427572272303388,
      "grad_norm": 0.24284379184246063,
      "learning_rate": 4.286213863848307e-06,
      "loss": 0.0734,
      "step": 14705
    },
    {
      "epoch": 1.1428349393845196,
      "grad_norm": 0.17503710091114044,
      "learning_rate": 4.2858253030774016e-06,
      "loss": 0.0532,
      "step": 14706
    },
    {
      "epoch": 1.1429126515387007,
      "grad_norm": 0.6497339606285095,
      "learning_rate": 4.2854367423064965e-06,
      "loss": 0.2669,
      "step": 14707
    },
    {
      "epoch": 1.1429903636928815,
      "grad_norm": 0.8530775904655457,
      "learning_rate": 4.285048181535592e-06,
      "loss": 0.3228,
      "step": 14708
    },
    {
      "epoch": 1.1430680758470624,
      "grad_norm": 0.761204719543457,
      "learning_rate": 4.284659620764688e-06,
      "loss": 0.2557,
      "step": 14709
    },
    {
      "epoch": 1.1431457880012434,
      "grad_norm": 0.5970560908317566,
      "learning_rate": 4.284271059993783e-06,
      "loss": 0.1426,
      "step": 14710
    },
    {
      "epoch": 1.1432235001554243,
      "grad_norm": 0.19184932112693787,
      "learning_rate": 4.283882499222879e-06,
      "loss": 0.0466,
      "step": 14711
    },
    {
      "epoch": 1.1433012123096051,
      "grad_norm": 0.30798545479774475,
      "learning_rate": 4.283493938451974e-06,
      "loss": 0.0822,
      "step": 14712
    },
    {
      "epoch": 1.1433789244637862,
      "grad_norm": 0.27530521154403687,
      "learning_rate": 4.28310537768107e-06,
      "loss": 0.0335,
      "step": 14713
    },
    {
      "epoch": 1.143456636617967,
      "grad_norm": 0.6380361318588257,
      "learning_rate": 4.282716816910165e-06,
      "loss": 0.3956,
      "step": 14714
    },
    {
      "epoch": 1.1435343487721479,
      "grad_norm": 0.513956606388092,
      "learning_rate": 4.28232825613926e-06,
      "loss": 0.266,
      "step": 14715
    },
    {
      "epoch": 1.143612060926329,
      "grad_norm": 0.13726748526096344,
      "learning_rate": 4.281939695368356e-06,
      "loss": 0.0557,
      "step": 14716
    },
    {
      "epoch": 1.1436897730805098,
      "grad_norm": 0.5680750608444214,
      "learning_rate": 4.281551134597451e-06,
      "loss": 0.3444,
      "step": 14717
    },
    {
      "epoch": 1.1437674852346906,
      "grad_norm": 0.6304605007171631,
      "learning_rate": 4.281162573826547e-06,
      "loss": 0.3568,
      "step": 14718
    },
    {
      "epoch": 1.1438451973888717,
      "grad_norm": 0.30082106590270996,
      "learning_rate": 4.280774013055643e-06,
      "loss": 0.0891,
      "step": 14719
    },
    {
      "epoch": 1.1439229095430525,
      "grad_norm": 0.5952631831169128,
      "learning_rate": 4.280385452284738e-06,
      "loss": 0.2743,
      "step": 14720
    },
    {
      "epoch": 1.1440006216972334,
      "grad_norm": 0.4046075940132141,
      "learning_rate": 4.2799968915138326e-06,
      "loss": 0.2618,
      "step": 14721
    },
    {
      "epoch": 1.1440783338514144,
      "grad_norm": 0.7280064821243286,
      "learning_rate": 4.279608330742928e-06,
      "loss": 0.2226,
      "step": 14722
    },
    {
      "epoch": 1.1441560460055953,
      "grad_norm": 0.06363748013973236,
      "learning_rate": 4.279219769972024e-06,
      "loss": 0.0242,
      "step": 14723
    },
    {
      "epoch": 1.1442337581597761,
      "grad_norm": 0.7701351046562195,
      "learning_rate": 4.278831209201119e-06,
      "loss": 0.3901,
      "step": 14724
    },
    {
      "epoch": 1.1443114703139572,
      "grad_norm": 0.4313790500164032,
      "learning_rate": 4.278442648430215e-06,
      "loss": 0.0594,
      "step": 14725
    },
    {
      "epoch": 1.144389182468138,
      "grad_norm": 2.189408779144287,
      "learning_rate": 4.27805408765931e-06,
      "loss": 1.0346,
      "step": 14726
    },
    {
      "epoch": 1.1444668946223189,
      "grad_norm": 0.16305404901504517,
      "learning_rate": 4.277665526888406e-06,
      "loss": 0.0572,
      "step": 14727
    },
    {
      "epoch": 1.1445446067765,
      "grad_norm": 0.5607831478118896,
      "learning_rate": 4.2772769661175015e-06,
      "loss": 0.1214,
      "step": 14728
    },
    {
      "epoch": 1.1446223189306808,
      "grad_norm": 0.278745174407959,
      "learning_rate": 4.276888405346596e-06,
      "loss": 0.1326,
      "step": 14729
    },
    {
      "epoch": 1.1447000310848616,
      "grad_norm": 0.5443593859672546,
      "learning_rate": 4.276499844575692e-06,
      "loss": 0.2199,
      "step": 14730
    },
    {
      "epoch": 1.1447777432390427,
      "grad_norm": 0.19819511473178864,
      "learning_rate": 4.276111283804787e-06,
      "loss": 0.0641,
      "step": 14731
    },
    {
      "epoch": 1.1448554553932235,
      "grad_norm": 0.18251177668571472,
      "learning_rate": 4.275722723033883e-06,
      "loss": 0.0271,
      "step": 14732
    },
    {
      "epoch": 1.1449331675474044,
      "grad_norm": 0.6061723232269287,
      "learning_rate": 4.275334162262979e-06,
      "loss": 0.2763,
      "step": 14733
    },
    {
      "epoch": 1.1450108797015854,
      "grad_norm": 0.5431120991706848,
      "learning_rate": 4.274945601492074e-06,
      "loss": 0.081,
      "step": 14734
    },
    {
      "epoch": 1.1450885918557663,
      "grad_norm": 0.5203427076339722,
      "learning_rate": 4.274557040721169e-06,
      "loss": 0.3368,
      "step": 14735
    },
    {
      "epoch": 1.1451663040099471,
      "grad_norm": 0.7995200157165527,
      "learning_rate": 4.2741684799502644e-06,
      "loss": 0.4866,
      "step": 14736
    },
    {
      "epoch": 1.1452440161641282,
      "grad_norm": 0.3950212001800537,
      "learning_rate": 4.27377991917936e-06,
      "loss": 0.5586,
      "step": 14737
    },
    {
      "epoch": 1.145321728318309,
      "grad_norm": 0.11135689169168472,
      "learning_rate": 4.273391358408455e-06,
      "loss": 0.0269,
      "step": 14738
    },
    {
      "epoch": 1.1453994404724899,
      "grad_norm": 0.5100089907646179,
      "learning_rate": 4.273002797637551e-06,
      "loss": 0.8778,
      "step": 14739
    },
    {
      "epoch": 1.145477152626671,
      "grad_norm": 0.9106693863868713,
      "learning_rate": 4.272614236866646e-06,
      "loss": 0.2343,
      "step": 14740
    },
    {
      "epoch": 1.1455548647808518,
      "grad_norm": 0.18255075812339783,
      "learning_rate": 4.272225676095742e-06,
      "loss": 0.0365,
      "step": 14741
    },
    {
      "epoch": 1.1456325769350326,
      "grad_norm": 0.38617831468582153,
      "learning_rate": 4.2718371153248375e-06,
      "loss": 0.1751,
      "step": 14742
    },
    {
      "epoch": 1.1457102890892135,
      "grad_norm": 0.4832395613193512,
      "learning_rate": 4.2714485545539325e-06,
      "loss": 0.1593,
      "step": 14743
    },
    {
      "epoch": 1.1457880012433945,
      "grad_norm": 0.753444492816925,
      "learning_rate": 4.271059993783028e-06,
      "loss": 0.346,
      "step": 14744
    },
    {
      "epoch": 1.1458657133975754,
      "grad_norm": 0.39312365651130676,
      "learning_rate": 4.270671433012123e-06,
      "loss": 0.1513,
      "step": 14745
    },
    {
      "epoch": 1.1459434255517562,
      "grad_norm": 0.3958215117454529,
      "learning_rate": 4.270282872241219e-06,
      "loss": 0.1767,
      "step": 14746
    },
    {
      "epoch": 1.1460211377059373,
      "grad_norm": 0.9200049638748169,
      "learning_rate": 4.269894311470315e-06,
      "loss": 0.3517,
      "step": 14747
    },
    {
      "epoch": 1.1460988498601181,
      "grad_norm": 0.27050310373306274,
      "learning_rate": 4.26950575069941e-06,
      "loss": 0.0675,
      "step": 14748
    },
    {
      "epoch": 1.146176562014299,
      "grad_norm": 0.5423142313957214,
      "learning_rate": 4.269117189928505e-06,
      "loss": 0.515,
      "step": 14749
    },
    {
      "epoch": 1.14625427416848,
      "grad_norm": 0.15618398785591125,
      "learning_rate": 4.2687286291576005e-06,
      "loss": 0.0335,
      "step": 14750
    },
    {
      "epoch": 1.1463319863226609,
      "grad_norm": 0.19189926981925964,
      "learning_rate": 4.268340068386696e-06,
      "loss": 0.0273,
      "step": 14751
    },
    {
      "epoch": 1.1464096984768417,
      "grad_norm": 0.2829524278640747,
      "learning_rate": 4.267951507615791e-06,
      "loss": 0.0831,
      "step": 14752
    },
    {
      "epoch": 1.1464874106310228,
      "grad_norm": 0.5284100770950317,
      "learning_rate": 4.267562946844887e-06,
      "loss": 0.1776,
      "step": 14753
    },
    {
      "epoch": 1.1465651227852036,
      "grad_norm": 0.6189520955085754,
      "learning_rate": 4.267174386073982e-06,
      "loss": 0.1678,
      "step": 14754
    },
    {
      "epoch": 1.1466428349393845,
      "grad_norm": 1.4176071882247925,
      "learning_rate": 4.266785825303078e-06,
      "loss": 0.5657,
      "step": 14755
    },
    {
      "epoch": 1.1467205470935655,
      "grad_norm": 0.9696453213691711,
      "learning_rate": 4.266397264532174e-06,
      "loss": 0.4242,
      "step": 14756
    },
    {
      "epoch": 1.1467982592477464,
      "grad_norm": 0.4495123624801636,
      "learning_rate": 4.2660087037612686e-06,
      "loss": 0.1732,
      "step": 14757
    },
    {
      "epoch": 1.1468759714019272,
      "grad_norm": 0.2400047481060028,
      "learning_rate": 4.265620142990364e-06,
      "loss": 0.0327,
      "step": 14758
    },
    {
      "epoch": 1.1469536835561083,
      "grad_norm": 0.35108619928359985,
      "learning_rate": 4.265231582219459e-06,
      "loss": 0.1904,
      "step": 14759
    },
    {
      "epoch": 1.1470313957102891,
      "grad_norm": 0.3089471161365509,
      "learning_rate": 4.264843021448555e-06,
      "loss": 0.1002,
      "step": 14760
    },
    {
      "epoch": 1.14710910786447,
      "grad_norm": 0.1268313229084015,
      "learning_rate": 4.264454460677651e-06,
      "loss": 0.1691,
      "step": 14761
    },
    {
      "epoch": 1.1471868200186508,
      "grad_norm": 0.22957812249660492,
      "learning_rate": 4.264065899906746e-06,
      "loss": 0.0693,
      "step": 14762
    },
    {
      "epoch": 1.1472645321728319,
      "grad_norm": 0.7996634244918823,
      "learning_rate": 4.263677339135841e-06,
      "loss": 0.774,
      "step": 14763
    },
    {
      "epoch": 1.1473422443270127,
      "grad_norm": 0.16351574659347534,
      "learning_rate": 4.263288778364937e-06,
      "loss": 0.0429,
      "step": 14764
    },
    {
      "epoch": 1.1474199564811935,
      "grad_norm": 1.0017199516296387,
      "learning_rate": 4.262900217594032e-06,
      "loss": 0.4559,
      "step": 14765
    },
    {
      "epoch": 1.1474976686353746,
      "grad_norm": 0.3685396909713745,
      "learning_rate": 4.262511656823127e-06,
      "loss": 0.1817,
      "step": 14766
    },
    {
      "epoch": 1.1475753807895555,
      "grad_norm": 0.9436355233192444,
      "learning_rate": 4.262123096052223e-06,
      "loss": 0.2425,
      "step": 14767
    },
    {
      "epoch": 1.1476530929437363,
      "grad_norm": 0.9977476000785828,
      "learning_rate": 4.261734535281318e-06,
      "loss": 0.6356,
      "step": 14768
    },
    {
      "epoch": 1.1477308050979174,
      "grad_norm": 0.2653084099292755,
      "learning_rate": 4.261345974510414e-06,
      "loss": 0.0415,
      "step": 14769
    },
    {
      "epoch": 1.1478085172520982,
      "grad_norm": 0.45320621132850647,
      "learning_rate": 4.26095741373951e-06,
      "loss": 0.0745,
      "step": 14770
    },
    {
      "epoch": 1.147886229406279,
      "grad_norm": 0.45418670773506165,
      "learning_rate": 4.260568852968605e-06,
      "loss": 0.1097,
      "step": 14771
    },
    {
      "epoch": 1.14796394156046,
      "grad_norm": 0.38141658902168274,
      "learning_rate": 4.2601802921977e-06,
      "loss": 0.2254,
      "step": 14772
    },
    {
      "epoch": 1.148041653714641,
      "grad_norm": 1.5178395509719849,
      "learning_rate": 4.259791731426795e-06,
      "loss": 0.8137,
      "step": 14773
    },
    {
      "epoch": 1.1481193658688218,
      "grad_norm": 0.3919987976551056,
      "learning_rate": 4.259403170655891e-06,
      "loss": 0.1412,
      "step": 14774
    },
    {
      "epoch": 1.1481970780230029,
      "grad_norm": 0.3043786883354187,
      "learning_rate": 4.259014609884987e-06,
      "loss": 0.1139,
      "step": 14775
    },
    {
      "epoch": 1.1482747901771837,
      "grad_norm": 0.23907789587974548,
      "learning_rate": 4.258626049114082e-06,
      "loss": 0.0342,
      "step": 14776
    },
    {
      "epoch": 1.1483525023313645,
      "grad_norm": 0.35880985856056213,
      "learning_rate": 4.258237488343177e-06,
      "loss": 0.4628,
      "step": 14777
    },
    {
      "epoch": 1.1484302144855456,
      "grad_norm": 0.2635204493999481,
      "learning_rate": 4.257848927572273e-06,
      "loss": 0.0743,
      "step": 14778
    },
    {
      "epoch": 1.1485079266397265,
      "grad_norm": 0.7685061693191528,
      "learning_rate": 4.2574603668013685e-06,
      "loss": 0.4961,
      "step": 14779
    },
    {
      "epoch": 1.1485856387939073,
      "grad_norm": 0.44972658157348633,
      "learning_rate": 4.257071806030463e-06,
      "loss": 0.2232,
      "step": 14780
    },
    {
      "epoch": 1.1486633509480884,
      "grad_norm": 0.35875093936920166,
      "learning_rate": 4.256683245259559e-06,
      "loss": 0.0953,
      "step": 14781
    },
    {
      "epoch": 1.1487410631022692,
      "grad_norm": 0.4560944736003876,
      "learning_rate": 4.256294684488654e-06,
      "loss": 0.0554,
      "step": 14782
    },
    {
      "epoch": 1.14881877525645,
      "grad_norm": 1.0901868343353271,
      "learning_rate": 4.25590612371775e-06,
      "loss": 0.3735,
      "step": 14783
    },
    {
      "epoch": 1.148896487410631,
      "grad_norm": 0.09960366785526276,
      "learning_rate": 4.255517562946846e-06,
      "loss": 0.0281,
      "step": 14784
    },
    {
      "epoch": 1.148974199564812,
      "grad_norm": 0.21610820293426514,
      "learning_rate": 4.255129002175941e-06,
      "loss": 0.0545,
      "step": 14785
    },
    {
      "epoch": 1.1490519117189928,
      "grad_norm": 0.8476993441581726,
      "learning_rate": 4.254740441405036e-06,
      "loss": 0.2864,
      "step": 14786
    },
    {
      "epoch": 1.1491296238731739,
      "grad_norm": 0.6469412446022034,
      "learning_rate": 4.2543518806341314e-06,
      "loss": 0.2827,
      "step": 14787
    },
    {
      "epoch": 1.1492073360273547,
      "grad_norm": 0.4360024333000183,
      "learning_rate": 4.253963319863227e-06,
      "loss": 0.1946,
      "step": 14788
    },
    {
      "epoch": 1.1492850481815355,
      "grad_norm": 0.08059030026197433,
      "learning_rate": 4.253574759092323e-06,
      "loss": 0.0175,
      "step": 14789
    },
    {
      "epoch": 1.1493627603357166,
      "grad_norm": 0.9078666567802429,
      "learning_rate": 4.253186198321418e-06,
      "loss": 0.3469,
      "step": 14790
    },
    {
      "epoch": 1.1494404724898974,
      "grad_norm": 0.575971245765686,
      "learning_rate": 4.252797637550513e-06,
      "loss": 0.2725,
      "step": 14791
    },
    {
      "epoch": 1.1495181846440783,
      "grad_norm": 0.2085847556591034,
      "learning_rate": 4.252409076779609e-06,
      "loss": 0.096,
      "step": 14792
    },
    {
      "epoch": 1.1495958967982594,
      "grad_norm": 0.25533396005630493,
      "learning_rate": 4.2520205160087045e-06,
      "loss": 0.0659,
      "step": 14793
    },
    {
      "epoch": 1.1496736089524402,
      "grad_norm": 0.23801030218601227,
      "learning_rate": 4.2516319552377995e-06,
      "loss": 0.0426,
      "step": 14794
    },
    {
      "epoch": 1.149751321106621,
      "grad_norm": 0.7329262495040894,
      "learning_rate": 4.251243394466895e-06,
      "loss": 0.1404,
      "step": 14795
    },
    {
      "epoch": 1.149829033260802,
      "grad_norm": 0.5831920504570007,
      "learning_rate": 4.25085483369599e-06,
      "loss": 0.0995,
      "step": 14796
    },
    {
      "epoch": 1.149906745414983,
      "grad_norm": 0.18017792701721191,
      "learning_rate": 4.250466272925086e-06,
      "loss": 0.0293,
      "step": 14797
    },
    {
      "epoch": 1.1499844575691638,
      "grad_norm": 0.43570026755332947,
      "learning_rate": 4.250077712154182e-06,
      "loss": 0.0889,
      "step": 14798
    },
    {
      "epoch": 1.1500621697233449,
      "grad_norm": 0.30495283007621765,
      "learning_rate": 4.249689151383277e-06,
      "loss": 0.459,
      "step": 14799
    },
    {
      "epoch": 1.1501398818775257,
      "grad_norm": 0.8060030341148376,
      "learning_rate": 4.249300590612372e-06,
      "loss": 0.4177,
      "step": 14800
    },
    {
      "epoch": 1.1502175940317065,
      "grad_norm": 0.2475619614124298,
      "learning_rate": 4.2489120298414675e-06,
      "loss": 0.055,
      "step": 14801
    },
    {
      "epoch": 1.1502953061858874,
      "grad_norm": 0.3364584743976593,
      "learning_rate": 4.248523469070563e-06,
      "loss": 0.2304,
      "step": 14802
    },
    {
      "epoch": 1.1503730183400684,
      "grad_norm": 0.20928582549095154,
      "learning_rate": 4.248134908299658e-06,
      "loss": 0.08,
      "step": 14803
    },
    {
      "epoch": 1.1504507304942493,
      "grad_norm": 0.4144984185695648,
      "learning_rate": 4.247746347528754e-06,
      "loss": 0.1984,
      "step": 14804
    },
    {
      "epoch": 1.1505284426484301,
      "grad_norm": 0.5773263573646545,
      "learning_rate": 4.247357786757849e-06,
      "loss": 0.2632,
      "step": 14805
    },
    {
      "epoch": 1.1506061548026112,
      "grad_norm": 0.4231117069721222,
      "learning_rate": 4.246969225986945e-06,
      "loss": 0.1662,
      "step": 14806
    },
    {
      "epoch": 1.150683866956792,
      "grad_norm": 0.5639690160751343,
      "learning_rate": 4.24658066521604e-06,
      "loss": 0.1301,
      "step": 14807
    },
    {
      "epoch": 1.1507615791109729,
      "grad_norm": 1.0669409036636353,
      "learning_rate": 4.2461921044451356e-06,
      "loss": 0.2036,
      "step": 14808
    },
    {
      "epoch": 1.150839291265154,
      "grad_norm": 0.13574807345867157,
      "learning_rate": 4.245803543674231e-06,
      "loss": 0.0441,
      "step": 14809
    },
    {
      "epoch": 1.1509170034193348,
      "grad_norm": 1.2824915647506714,
      "learning_rate": 4.245414982903326e-06,
      "loss": 0.926,
      "step": 14810
    },
    {
      "epoch": 1.1509947155735156,
      "grad_norm": 0.30891183018684387,
      "learning_rate": 4.245026422132421e-06,
      "loss": 0.1535,
      "step": 14811
    },
    {
      "epoch": 1.1510724277276967,
      "grad_norm": 0.3515641987323761,
      "learning_rate": 4.244637861361517e-06,
      "loss": 0.1782,
      "step": 14812
    },
    {
      "epoch": 1.1511501398818775,
      "grad_norm": 0.6970726251602173,
      "learning_rate": 4.244249300590613e-06,
      "loss": 0.3148,
      "step": 14813
    },
    {
      "epoch": 1.1512278520360584,
      "grad_norm": 0.5624448657035828,
      "learning_rate": 4.243860739819708e-06,
      "loss": 0.1529,
      "step": 14814
    },
    {
      "epoch": 1.1513055641902394,
      "grad_norm": 0.29755526781082153,
      "learning_rate": 4.243472179048804e-06,
      "loss": 0.103,
      "step": 14815
    },
    {
      "epoch": 1.1513832763444203,
      "grad_norm": 0.8888326287269592,
      "learning_rate": 4.2430836182778985e-06,
      "loss": 0.436,
      "step": 14816
    },
    {
      "epoch": 1.1514609884986011,
      "grad_norm": 0.3078910708427429,
      "learning_rate": 4.242695057506994e-06,
      "loss": 0.0557,
      "step": 14817
    },
    {
      "epoch": 1.1515387006527822,
      "grad_norm": 0.25619643926620483,
      "learning_rate": 4.24230649673609e-06,
      "loss": 0.0373,
      "step": 14818
    },
    {
      "epoch": 1.151616412806963,
      "grad_norm": 0.6668243408203125,
      "learning_rate": 4.241917935965185e-06,
      "loss": 0.3982,
      "step": 14819
    },
    {
      "epoch": 1.1516941249611439,
      "grad_norm": 0.5926918983459473,
      "learning_rate": 4.241529375194281e-06,
      "loss": 0.185,
      "step": 14820
    },
    {
      "epoch": 1.1517718371153247,
      "grad_norm": 0.5133681893348694,
      "learning_rate": 4.241140814423376e-06,
      "loss": 0.0887,
      "step": 14821
    },
    {
      "epoch": 1.1518495492695058,
      "grad_norm": 0.3261089026927948,
      "learning_rate": 4.240752253652472e-06,
      "loss": 0.3384,
      "step": 14822
    },
    {
      "epoch": 1.1519272614236866,
      "grad_norm": 0.42475613951683044,
      "learning_rate": 4.2403636928815674e-06,
      "loss": 0.0316,
      "step": 14823
    },
    {
      "epoch": 1.1520049735778675,
      "grad_norm": 0.6909275650978088,
      "learning_rate": 4.239975132110662e-06,
      "loss": 0.5933,
      "step": 14824
    },
    {
      "epoch": 1.1520826857320485,
      "grad_norm": 0.37763655185699463,
      "learning_rate": 4.239586571339757e-06,
      "loss": 0.2364,
      "step": 14825
    },
    {
      "epoch": 1.1521603978862294,
      "grad_norm": 0.22621124982833862,
      "learning_rate": 4.239198010568853e-06,
      "loss": 0.1007,
      "step": 14826
    },
    {
      "epoch": 1.1522381100404102,
      "grad_norm": 0.6812683939933777,
      "learning_rate": 4.238809449797949e-06,
      "loss": 0.2336,
      "step": 14827
    },
    {
      "epoch": 1.1523158221945913,
      "grad_norm": 0.7010796070098877,
      "learning_rate": 4.238420889027044e-06,
      "loss": 0.5302,
      "step": 14828
    },
    {
      "epoch": 1.1523935343487721,
      "grad_norm": 0.12664814293384552,
      "learning_rate": 4.23803232825614e-06,
      "loss": 0.049,
      "step": 14829
    },
    {
      "epoch": 1.152471246502953,
      "grad_norm": 0.2889796793460846,
      "learning_rate": 4.237643767485235e-06,
      "loss": 0.0611,
      "step": 14830
    },
    {
      "epoch": 1.152548958657134,
      "grad_norm": 0.09325898438692093,
      "learning_rate": 4.23725520671433e-06,
      "loss": 0.0218,
      "step": 14831
    },
    {
      "epoch": 1.1526266708113149,
      "grad_norm": 0.1302518993616104,
      "learning_rate": 4.236866645943426e-06,
      "loss": 0.038,
      "step": 14832
    },
    {
      "epoch": 1.1527043829654957,
      "grad_norm": 0.42046627402305603,
      "learning_rate": 4.236478085172521e-06,
      "loss": 0.0931,
      "step": 14833
    },
    {
      "epoch": 1.1527820951196768,
      "grad_norm": 0.3546923100948334,
      "learning_rate": 4.236089524401617e-06,
      "loss": 0.0666,
      "step": 14834
    },
    {
      "epoch": 1.1528598072738576,
      "grad_norm": 0.6531709432601929,
      "learning_rate": 4.235700963630712e-06,
      "loss": 0.239,
      "step": 14835
    },
    {
      "epoch": 1.1529375194280385,
      "grad_norm": 0.1396438479423523,
      "learning_rate": 4.235312402859808e-06,
      "loss": 0.06,
      "step": 14836
    },
    {
      "epoch": 1.1530152315822195,
      "grad_norm": 0.10489442944526672,
      "learning_rate": 4.2349238420889035e-06,
      "loss": 0.0108,
      "step": 14837
    },
    {
      "epoch": 1.1530929437364004,
      "grad_norm": 0.9137516617774963,
      "learning_rate": 4.2345352813179984e-06,
      "loss": 0.703,
      "step": 14838
    },
    {
      "epoch": 1.1531706558905812,
      "grad_norm": 0.750262439250946,
      "learning_rate": 4.234146720547093e-06,
      "loss": 0.3493,
      "step": 14839
    },
    {
      "epoch": 1.1532483680447623,
      "grad_norm": 0.3850269317626953,
      "learning_rate": 4.233758159776189e-06,
      "loss": 0.1778,
      "step": 14840
    },
    {
      "epoch": 1.1533260801989431,
      "grad_norm": 0.25134947896003723,
      "learning_rate": 4.233369599005285e-06,
      "loss": 0.3732,
      "step": 14841
    },
    {
      "epoch": 1.153403792353124,
      "grad_norm": 0.16765695810317993,
      "learning_rate": 4.23298103823438e-06,
      "loss": 0.0541,
      "step": 14842
    },
    {
      "epoch": 1.153481504507305,
      "grad_norm": 0.40623739361763,
      "learning_rate": 4.232592477463476e-06,
      "loss": 0.122,
      "step": 14843
    },
    {
      "epoch": 1.1535592166614859,
      "grad_norm": 0.79947429895401,
      "learning_rate": 4.232203916692571e-06,
      "loss": 0.1167,
      "step": 14844
    },
    {
      "epoch": 1.1536369288156667,
      "grad_norm": 0.04841373860836029,
      "learning_rate": 4.2318153559216665e-06,
      "loss": 0.0131,
      "step": 14845
    },
    {
      "epoch": 1.1537146409698478,
      "grad_norm": 0.3913189470767975,
      "learning_rate": 4.231426795150762e-06,
      "loss": 0.1275,
      "step": 14846
    },
    {
      "epoch": 1.1537923531240286,
      "grad_norm": 0.24155698716640472,
      "learning_rate": 4.231038234379857e-06,
      "loss": 0.1751,
      "step": 14847
    },
    {
      "epoch": 1.1538700652782095,
      "grad_norm": 0.8184231519699097,
      "learning_rate": 4.230649673608952e-06,
      "loss": 0.1357,
      "step": 14848
    },
    {
      "epoch": 1.1539477774323905,
      "grad_norm": 0.04422951862215996,
      "learning_rate": 4.230261112838048e-06,
      "loss": 0.0186,
      "step": 14849
    },
    {
      "epoch": 1.1540254895865714,
      "grad_norm": 0.5888978838920593,
      "learning_rate": 4.229872552067144e-06,
      "loss": 0.4916,
      "step": 14850
    },
    {
      "epoch": 1.1541032017407522,
      "grad_norm": 0.3858609199523926,
      "learning_rate": 4.2294839912962396e-06,
      "loss": 0.1721,
      "step": 14851
    },
    {
      "epoch": 1.1541809138949333,
      "grad_norm": 1.3534822463989258,
      "learning_rate": 4.2290954305253345e-06,
      "loss": 2.3241,
      "step": 14852
    },
    {
      "epoch": 1.1542586260491141,
      "grad_norm": 0.6739077568054199,
      "learning_rate": 4.2287068697544295e-06,
      "loss": 0.1212,
      "step": 14853
    },
    {
      "epoch": 1.154336338203295,
      "grad_norm": 0.2344515323638916,
      "learning_rate": 4.228318308983525e-06,
      "loss": 0.1075,
      "step": 14854
    },
    {
      "epoch": 1.154414050357476,
      "grad_norm": 0.25612789392471313,
      "learning_rate": 4.227929748212621e-06,
      "loss": 0.108,
      "step": 14855
    },
    {
      "epoch": 1.1544917625116569,
      "grad_norm": 1.0790059566497803,
      "learning_rate": 4.227541187441716e-06,
      "loss": 0.5397,
      "step": 14856
    },
    {
      "epoch": 1.1545694746658377,
      "grad_norm": 0.5263038277626038,
      "learning_rate": 4.227152626670812e-06,
      "loss": 0.1385,
      "step": 14857
    },
    {
      "epoch": 1.1546471868200188,
      "grad_norm": 0.22304624319076538,
      "learning_rate": 4.226764065899907e-06,
      "loss": 0.044,
      "step": 14858
    },
    {
      "epoch": 1.1547248989741996,
      "grad_norm": 1.5904369354248047,
      "learning_rate": 4.2263755051290026e-06,
      "loss": 0.227,
      "step": 14859
    },
    {
      "epoch": 1.1548026111283805,
      "grad_norm": 0.6777233481407166,
      "learning_rate": 4.225986944358098e-06,
      "loss": 0.1353,
      "step": 14860
    },
    {
      "epoch": 1.1548803232825615,
      "grad_norm": 0.36955615878105164,
      "learning_rate": 4.225598383587193e-06,
      "loss": 0.0434,
      "step": 14861
    },
    {
      "epoch": 1.1549580354367424,
      "grad_norm": 0.6773583292961121,
      "learning_rate": 4.225209822816288e-06,
      "loss": 0.3818,
      "step": 14862
    },
    {
      "epoch": 1.1550357475909232,
      "grad_norm": 0.8159719705581665,
      "learning_rate": 4.224821262045384e-06,
      "loss": 0.5176,
      "step": 14863
    },
    {
      "epoch": 1.155113459745104,
      "grad_norm": 0.29513800144195557,
      "learning_rate": 4.22443270127448e-06,
      "loss": 0.0486,
      "step": 14864
    },
    {
      "epoch": 1.155191171899285,
      "grad_norm": 0.5234189629554749,
      "learning_rate": 4.224044140503576e-06,
      "loss": 0.2164,
      "step": 14865
    },
    {
      "epoch": 1.155268884053466,
      "grad_norm": 0.46328046917915344,
      "learning_rate": 4.223655579732671e-06,
      "loss": 0.3198,
      "step": 14866
    },
    {
      "epoch": 1.1553465962076468,
      "grad_norm": 0.5400020480155945,
      "learning_rate": 4.2232670189617655e-06,
      "loss": 0.1005,
      "step": 14867
    },
    {
      "epoch": 1.1554243083618279,
      "grad_norm": 0.49619248509407043,
      "learning_rate": 4.222878458190861e-06,
      "loss": 0.756,
      "step": 14868
    },
    {
      "epoch": 1.1555020205160087,
      "grad_norm": 0.31387436389923096,
      "learning_rate": 4.222489897419957e-06,
      "loss": 0.0749,
      "step": 14869
    },
    {
      "epoch": 1.1555797326701895,
      "grad_norm": 0.46854138374328613,
      "learning_rate": 4.222101336649052e-06,
      "loss": 0.1753,
      "step": 14870
    },
    {
      "epoch": 1.1556574448243706,
      "grad_norm": 0.437671422958374,
      "learning_rate": 4.221712775878148e-06,
      "loss": 0.2421,
      "step": 14871
    },
    {
      "epoch": 1.1557351569785514,
      "grad_norm": 1.5203604698181152,
      "learning_rate": 4.221324215107243e-06,
      "loss": 0.2853,
      "step": 14872
    },
    {
      "epoch": 1.1558128691327323,
      "grad_norm": 8.517173767089844,
      "learning_rate": 4.220935654336339e-06,
      "loss": 1.0507,
      "step": 14873
    },
    {
      "epoch": 1.1558905812869134,
      "grad_norm": 0.22486530244350433,
      "learning_rate": 4.2205470935654344e-06,
      "loss": 0.03,
      "step": 14874
    },
    {
      "epoch": 1.1559682934410942,
      "grad_norm": 0.7395151853561401,
      "learning_rate": 4.220158532794529e-06,
      "loss": 0.143,
      "step": 14875
    },
    {
      "epoch": 1.156046005595275,
      "grad_norm": 0.40798455476760864,
      "learning_rate": 4.219769972023624e-06,
      "loss": 0.0449,
      "step": 14876
    },
    {
      "epoch": 1.156123717749456,
      "grad_norm": 0.13449300825595856,
      "learning_rate": 4.21938141125272e-06,
      "loss": 0.0394,
      "step": 14877
    },
    {
      "epoch": 1.156201429903637,
      "grad_norm": 0.1126212328672409,
      "learning_rate": 4.218992850481816e-06,
      "loss": 0.0159,
      "step": 14878
    },
    {
      "epoch": 1.1562791420578178,
      "grad_norm": 0.28081339597702026,
      "learning_rate": 4.218604289710912e-06,
      "loss": 0.133,
      "step": 14879
    },
    {
      "epoch": 1.1563568542119989,
      "grad_norm": 0.148691788315773,
      "learning_rate": 4.218215728940007e-06,
      "loss": 0.02,
      "step": 14880
    },
    {
      "epoch": 1.1564345663661797,
      "grad_norm": 0.3746419847011566,
      "learning_rate": 4.217827168169102e-06,
      "loss": 0.2142,
      "step": 14881
    },
    {
      "epoch": 1.1565122785203605,
      "grad_norm": 0.5575190782546997,
      "learning_rate": 4.217438607398197e-06,
      "loss": 0.1852,
      "step": 14882
    },
    {
      "epoch": 1.1565899906745414,
      "grad_norm": 0.4928168058395386,
      "learning_rate": 4.217050046627293e-06,
      "loss": 0.0707,
      "step": 14883
    },
    {
      "epoch": 1.1566677028287224,
      "grad_norm": 0.2975335419178009,
      "learning_rate": 4.216661485856388e-06,
      "loss": 0.1513,
      "step": 14884
    },
    {
      "epoch": 1.1567454149829033,
      "grad_norm": 0.2031882107257843,
      "learning_rate": 4.216272925085484e-06,
      "loss": 0.1574,
      "step": 14885
    },
    {
      "epoch": 1.1568231271370841,
      "grad_norm": 0.7702540159225464,
      "learning_rate": 4.215884364314579e-06,
      "loss": 0.3582,
      "step": 14886
    },
    {
      "epoch": 1.1569008392912652,
      "grad_norm": 0.23990969359874725,
      "learning_rate": 4.215495803543675e-06,
      "loss": 0.0749,
      "step": 14887
    },
    {
      "epoch": 1.156978551445446,
      "grad_norm": 0.4092565178871155,
      "learning_rate": 4.2151072427727705e-06,
      "loss": 0.1201,
      "step": 14888
    },
    {
      "epoch": 1.1570562635996269,
      "grad_norm": 0.5998697876930237,
      "learning_rate": 4.2147186820018655e-06,
      "loss": 0.2649,
      "step": 14889
    },
    {
      "epoch": 1.157133975753808,
      "grad_norm": 1.1503666639328003,
      "learning_rate": 4.21433012123096e-06,
      "loss": 0.3111,
      "step": 14890
    },
    {
      "epoch": 1.1572116879079888,
      "grad_norm": 1.0669344663619995,
      "learning_rate": 4.213941560460056e-06,
      "loss": 0.461,
      "step": 14891
    },
    {
      "epoch": 1.1572894000621696,
      "grad_norm": 0.650240421295166,
      "learning_rate": 4.213552999689152e-06,
      "loss": 0.3103,
      "step": 14892
    },
    {
      "epoch": 1.1573671122163507,
      "grad_norm": 0.37857702374458313,
      "learning_rate": 4.213164438918247e-06,
      "loss": 0.2047,
      "step": 14893
    },
    {
      "epoch": 1.1574448243705315,
      "grad_norm": 0.6522606015205383,
      "learning_rate": 4.212775878147343e-06,
      "loss": 0.3261,
      "step": 14894
    },
    {
      "epoch": 1.1575225365247124,
      "grad_norm": 1.7949175834655762,
      "learning_rate": 4.212387317376438e-06,
      "loss": 0.9307,
      "step": 14895
    },
    {
      "epoch": 1.1576002486788934,
      "grad_norm": 0.47245824337005615,
      "learning_rate": 4.2119987566055335e-06,
      "loss": 0.2253,
      "step": 14896
    },
    {
      "epoch": 1.1576779608330743,
      "grad_norm": 0.5805325508117676,
      "learning_rate": 4.211610195834629e-06,
      "loss": 0.2429,
      "step": 14897
    },
    {
      "epoch": 1.1577556729872551,
      "grad_norm": 0.5061736702919006,
      "learning_rate": 4.211221635063724e-06,
      "loss": 0.2707,
      "step": 14898
    },
    {
      "epoch": 1.1578333851414362,
      "grad_norm": 0.2904132008552551,
      "learning_rate": 4.21083307429282e-06,
      "loss": 0.1635,
      "step": 14899
    },
    {
      "epoch": 1.157911097295617,
      "grad_norm": 0.634380042552948,
      "learning_rate": 4.210444513521915e-06,
      "loss": 0.3573,
      "step": 14900
    },
    {
      "epoch": 1.1579888094497979,
      "grad_norm": 0.31197524070739746,
      "learning_rate": 4.210055952751011e-06,
      "loss": 0.0806,
      "step": 14901
    },
    {
      "epoch": 1.158066521603979,
      "grad_norm": 0.2692808508872986,
      "learning_rate": 4.2096673919801066e-06,
      "loss": 0.0858,
      "step": 14902
    },
    {
      "epoch": 1.1581442337581598,
      "grad_norm": 0.7371325492858887,
      "learning_rate": 4.2092788312092015e-06,
      "loss": 0.1639,
      "step": 14903
    },
    {
      "epoch": 1.1582219459123406,
      "grad_norm": 0.6498507261276245,
      "learning_rate": 4.2088902704382965e-06,
      "loss": 0.4137,
      "step": 14904
    },
    {
      "epoch": 1.1582996580665217,
      "grad_norm": 0.7380058765411377,
      "learning_rate": 4.208501709667392e-06,
      "loss": 0.2825,
      "step": 14905
    },
    {
      "epoch": 1.1583773702207025,
      "grad_norm": 14.058571815490723,
      "learning_rate": 4.208113148896488e-06,
      "loss": 1.8309,
      "step": 14906
    },
    {
      "epoch": 1.1584550823748834,
      "grad_norm": 0.38739871978759766,
      "learning_rate": 4.207724588125583e-06,
      "loss": 0.0872,
      "step": 14907
    },
    {
      "epoch": 1.1585327945290644,
      "grad_norm": 0.3029298186302185,
      "learning_rate": 4.207336027354679e-06,
      "loss": 0.0579,
      "step": 14908
    },
    {
      "epoch": 1.1586105066832453,
      "grad_norm": 0.5346867442131042,
      "learning_rate": 4.206947466583774e-06,
      "loss": 0.1863,
      "step": 14909
    },
    {
      "epoch": 1.1586882188374261,
      "grad_norm": 0.5718657374382019,
      "learning_rate": 4.2065589058128696e-06,
      "loss": 0.2491,
      "step": 14910
    },
    {
      "epoch": 1.1587659309916072,
      "grad_norm": 0.46930477023124695,
      "learning_rate": 4.206170345041965e-06,
      "loss": 0.2708,
      "step": 14911
    },
    {
      "epoch": 1.158843643145788,
      "grad_norm": 0.41349104046821594,
      "learning_rate": 4.20578178427106e-06,
      "loss": 0.1559,
      "step": 14912
    },
    {
      "epoch": 1.1589213552999689,
      "grad_norm": 0.30422672629356384,
      "learning_rate": 4.205393223500156e-06,
      "loss": 0.0588,
      "step": 14913
    },
    {
      "epoch": 1.15899906745415,
      "grad_norm": 0.5360945463180542,
      "learning_rate": 4.205004662729251e-06,
      "loss": 0.2424,
      "step": 14914
    },
    {
      "epoch": 1.1590767796083308,
      "grad_norm": 0.341815710067749,
      "learning_rate": 4.204616101958347e-06,
      "loss": 0.0595,
      "step": 14915
    },
    {
      "epoch": 1.1591544917625116,
      "grad_norm": 0.1607205718755722,
      "learning_rate": 4.204227541187443e-06,
      "loss": 0.0479,
      "step": 14916
    },
    {
      "epoch": 1.1592322039166927,
      "grad_norm": 0.30621010065078735,
      "learning_rate": 4.203838980416538e-06,
      "loss": 0.0392,
      "step": 14917
    },
    {
      "epoch": 1.1593099160708735,
      "grad_norm": 0.18499577045440674,
      "learning_rate": 4.2034504196456325e-06,
      "loss": 0.1208,
      "step": 14918
    },
    {
      "epoch": 1.1593876282250544,
      "grad_norm": 0.5123510956764221,
      "learning_rate": 4.203061858874728e-06,
      "loss": 0.1568,
      "step": 14919
    },
    {
      "epoch": 1.1594653403792354,
      "grad_norm": 0.27096500992774963,
      "learning_rate": 4.202673298103824e-06,
      "loss": 0.0988,
      "step": 14920
    },
    {
      "epoch": 1.1595430525334163,
      "grad_norm": 0.26403674483299255,
      "learning_rate": 4.202284737332919e-06,
      "loss": 0.1176,
      "step": 14921
    },
    {
      "epoch": 1.1596207646875971,
      "grad_norm": 0.3441489040851593,
      "learning_rate": 4.201896176562015e-06,
      "loss": 0.0372,
      "step": 14922
    },
    {
      "epoch": 1.159698476841778,
      "grad_norm": 0.5331480503082275,
      "learning_rate": 4.20150761579111e-06,
      "loss": 0.2159,
      "step": 14923
    },
    {
      "epoch": 1.159776188995959,
      "grad_norm": 0.3564639687538147,
      "learning_rate": 4.201119055020206e-06,
      "loss": 0.2216,
      "step": 14924
    },
    {
      "epoch": 1.1598539011501399,
      "grad_norm": 0.21125119924545288,
      "learning_rate": 4.2007304942493014e-06,
      "loss": 0.0716,
      "step": 14925
    },
    {
      "epoch": 1.1599316133043207,
      "grad_norm": 0.9418924450874329,
      "learning_rate": 4.200341933478396e-06,
      "loss": 0.6978,
      "step": 14926
    },
    {
      "epoch": 1.1600093254585018,
      "grad_norm": 0.32352641224861145,
      "learning_rate": 4.199953372707492e-06,
      "loss": 0.0608,
      "step": 14927
    },
    {
      "epoch": 1.1600870376126826,
      "grad_norm": 0.04165874794125557,
      "learning_rate": 4.199564811936587e-06,
      "loss": 0.0093,
      "step": 14928
    },
    {
      "epoch": 1.1601647497668635,
      "grad_norm": 1.485871434211731,
      "learning_rate": 4.199176251165683e-06,
      "loss": 0.2465,
      "step": 14929
    },
    {
      "epoch": 1.1602424619210445,
      "grad_norm": 0.6078124642372131,
      "learning_rate": 4.198787690394778e-06,
      "loss": 0.5071,
      "step": 14930
    },
    {
      "epoch": 1.1603201740752254,
      "grad_norm": 0.41228413581848145,
      "learning_rate": 4.198399129623874e-06,
      "loss": 0.047,
      "step": 14931
    },
    {
      "epoch": 1.1603978862294062,
      "grad_norm": 0.5882817506790161,
      "learning_rate": 4.198010568852969e-06,
      "loss": 0.592,
      "step": 14932
    },
    {
      "epoch": 1.1604755983835873,
      "grad_norm": 0.33827823400497437,
      "learning_rate": 4.197622008082064e-06,
      "loss": 0.1982,
      "step": 14933
    },
    {
      "epoch": 1.1605533105377681,
      "grad_norm": 0.5225057005882263,
      "learning_rate": 4.197233447311159e-06,
      "loss": 0.1646,
      "step": 14934
    },
    {
      "epoch": 1.160631022691949,
      "grad_norm": 0.30255454778671265,
      "learning_rate": 4.196844886540255e-06,
      "loss": 0.0743,
      "step": 14935
    },
    {
      "epoch": 1.16070873484613,
      "grad_norm": 0.48752713203430176,
      "learning_rate": 4.196456325769351e-06,
      "loss": 0.3247,
      "step": 14936
    },
    {
      "epoch": 1.1607864470003109,
      "grad_norm": 0.22687466442584991,
      "learning_rate": 4.196067764998446e-06,
      "loss": 0.0216,
      "step": 14937
    },
    {
      "epoch": 1.1608641591544917,
      "grad_norm": 0.9343074560165405,
      "learning_rate": 4.195679204227541e-06,
      "loss": 0.1164,
      "step": 14938
    },
    {
      "epoch": 1.1609418713086728,
      "grad_norm": 0.336931973695755,
      "learning_rate": 4.195290643456637e-06,
      "loss": 0.4485,
      "step": 14939
    },
    {
      "epoch": 1.1610195834628536,
      "grad_norm": 0.23843908309936523,
      "learning_rate": 4.1949020826857325e-06,
      "loss": 0.0306,
      "step": 14940
    },
    {
      "epoch": 1.1610972956170345,
      "grad_norm": 0.25756868720054626,
      "learning_rate": 4.194513521914828e-06,
      "loss": 0.0669,
      "step": 14941
    },
    {
      "epoch": 1.1611750077712153,
      "grad_norm": 0.2651215195655823,
      "learning_rate": 4.194124961143923e-06,
      "loss": 0.0353,
      "step": 14942
    },
    {
      "epoch": 1.1612527199253964,
      "grad_norm": 0.5973803400993347,
      "learning_rate": 4.193736400373018e-06,
      "loss": 0.3383,
      "step": 14943
    },
    {
      "epoch": 1.1613304320795772,
      "grad_norm": 0.3173367381095886,
      "learning_rate": 4.193347839602114e-06,
      "loss": 0.1154,
      "step": 14944
    },
    {
      "epoch": 1.161408144233758,
      "grad_norm": 0.2274283915758133,
      "learning_rate": 4.19295927883121e-06,
      "loss": 0.0764,
      "step": 14945
    },
    {
      "epoch": 1.161485856387939,
      "grad_norm": 0.6539130806922913,
      "learning_rate": 4.192570718060305e-06,
      "loss": 0.5201,
      "step": 14946
    },
    {
      "epoch": 1.16156356854212,
      "grad_norm": 0.5660280585289001,
      "learning_rate": 4.1921821572894005e-06,
      "loss": 0.0829,
      "step": 14947
    },
    {
      "epoch": 1.1616412806963008,
      "grad_norm": 0.4718278646469116,
      "learning_rate": 4.1917935965184954e-06,
      "loss": 0.1418,
      "step": 14948
    },
    {
      "epoch": 1.1617189928504819,
      "grad_norm": 0.316587895154953,
      "learning_rate": 4.191405035747591e-06,
      "loss": 0.071,
      "step": 14949
    },
    {
      "epoch": 1.1617967050046627,
      "grad_norm": 0.4091278314590454,
      "learning_rate": 4.191016474976687e-06,
      "loss": 0.1571,
      "step": 14950
    },
    {
      "epoch": 1.1618744171588435,
      "grad_norm": 0.3218507766723633,
      "learning_rate": 4.190627914205782e-06,
      "loss": 0.2347,
      "step": 14951
    },
    {
      "epoch": 1.1619521293130246,
      "grad_norm": 1.0128178596496582,
      "learning_rate": 4.190239353434877e-06,
      "loss": 0.547,
      "step": 14952
    },
    {
      "epoch": 1.1620298414672054,
      "grad_norm": 0.6133827567100525,
      "learning_rate": 4.189850792663973e-06,
      "loss": 0.2312,
      "step": 14953
    },
    {
      "epoch": 1.1621075536213863,
      "grad_norm": 0.7752682566642761,
      "learning_rate": 4.1894622318930685e-06,
      "loss": 0.5475,
      "step": 14954
    },
    {
      "epoch": 1.1621852657755674,
      "grad_norm": 0.4127528667449951,
      "learning_rate": 4.189073671122164e-06,
      "loss": 0.3205,
      "step": 14955
    },
    {
      "epoch": 1.1622629779297482,
      "grad_norm": 0.1521078646183014,
      "learning_rate": 4.188685110351259e-06,
      "loss": 0.0193,
      "step": 14956
    },
    {
      "epoch": 1.162340690083929,
      "grad_norm": 0.320400208234787,
      "learning_rate": 4.188296549580354e-06,
      "loss": 0.2426,
      "step": 14957
    },
    {
      "epoch": 1.16241840223811,
      "grad_norm": 0.7382081151008606,
      "learning_rate": 4.18790798880945e-06,
      "loss": 0.1433,
      "step": 14958
    },
    {
      "epoch": 1.162496114392291,
      "grad_norm": 0.8044252991676331,
      "learning_rate": 4.187519428038546e-06,
      "loss": 0.8352,
      "step": 14959
    },
    {
      "epoch": 1.1625738265464718,
      "grad_norm": 0.512122631072998,
      "learning_rate": 4.187130867267641e-06,
      "loss": 0.105,
      "step": 14960
    },
    {
      "epoch": 1.1626515387006529,
      "grad_norm": 0.7839471697807312,
      "learning_rate": 4.1867423064967366e-06,
      "loss": 0.2261,
      "step": 14961
    },
    {
      "epoch": 1.1627292508548337,
      "grad_norm": 0.4587063193321228,
      "learning_rate": 4.1863537457258315e-06,
      "loss": 0.0811,
      "step": 14962
    },
    {
      "epoch": 1.1628069630090145,
      "grad_norm": 0.9101134538650513,
      "learning_rate": 4.185965184954927e-06,
      "loss": 0.3656,
      "step": 14963
    },
    {
      "epoch": 1.1628846751631956,
      "grad_norm": 0.721229076385498,
      "learning_rate": 4.185576624184023e-06,
      "loss": 0.4376,
      "step": 14964
    },
    {
      "epoch": 1.1629623873173764,
      "grad_norm": 0.09990061074495316,
      "learning_rate": 4.185188063413118e-06,
      "loss": 0.0068,
      "step": 14965
    },
    {
      "epoch": 1.1630400994715573,
      "grad_norm": 0.49414658546447754,
      "learning_rate": 4.184799502642213e-06,
      "loss": 0.1759,
      "step": 14966
    },
    {
      "epoch": 1.1631178116257384,
      "grad_norm": 0.3227306008338928,
      "learning_rate": 4.184410941871309e-06,
      "loss": 0.0449,
      "step": 14967
    },
    {
      "epoch": 1.1631955237799192,
      "grad_norm": 0.2693650722503662,
      "learning_rate": 4.184022381100405e-06,
      "loss": 0.122,
      "step": 14968
    },
    {
      "epoch": 1.1632732359341,
      "grad_norm": 0.7235623598098755,
      "learning_rate": 4.1836338203294996e-06,
      "loss": 0.1724,
      "step": 14969
    },
    {
      "epoch": 1.163350948088281,
      "grad_norm": 0.4304952621459961,
      "learning_rate": 4.183245259558595e-06,
      "loss": 0.2906,
      "step": 14970
    },
    {
      "epoch": 1.163428660242462,
      "grad_norm": 0.6564367413520813,
      "learning_rate": 4.18285669878769e-06,
      "loss": 0.2404,
      "step": 14971
    },
    {
      "epoch": 1.1635063723966428,
      "grad_norm": 0.3008255362510681,
      "learning_rate": 4.182468138016786e-06,
      "loss": 0.1627,
      "step": 14972
    },
    {
      "epoch": 1.1635840845508238,
      "grad_norm": 0.3214809000492096,
      "learning_rate": 4.182079577245882e-06,
      "loss": 0.1979,
      "step": 14973
    },
    {
      "epoch": 1.1636617967050047,
      "grad_norm": 0.6049976348876953,
      "learning_rate": 4.181691016474977e-06,
      "loss": 0.1397,
      "step": 14974
    },
    {
      "epoch": 1.1637395088591855,
      "grad_norm": 0.4231257736682892,
      "learning_rate": 4.181302455704073e-06,
      "loss": 0.4024,
      "step": 14975
    },
    {
      "epoch": 1.1638172210133666,
      "grad_norm": 0.4892200827598572,
      "learning_rate": 4.180913894933168e-06,
      "loss": 0.1885,
      "step": 14976
    },
    {
      "epoch": 1.1638949331675474,
      "grad_norm": 0.4029359221458435,
      "learning_rate": 4.180525334162263e-06,
      "loss": 0.1617,
      "step": 14977
    },
    {
      "epoch": 1.1639726453217283,
      "grad_norm": 0.7702375054359436,
      "learning_rate": 4.180136773391359e-06,
      "loss": 0.2858,
      "step": 14978
    },
    {
      "epoch": 1.1640503574759093,
      "grad_norm": 0.8480321764945984,
      "learning_rate": 4.179748212620454e-06,
      "loss": 0.1129,
      "step": 14979
    },
    {
      "epoch": 1.1641280696300902,
      "grad_norm": 0.460989385843277,
      "learning_rate": 4.179359651849549e-06,
      "loss": 0.3337,
      "step": 14980
    },
    {
      "epoch": 1.164205781784271,
      "grad_norm": 0.41391515731811523,
      "learning_rate": 4.178971091078645e-06,
      "loss": 0.0697,
      "step": 14981
    },
    {
      "epoch": 1.164283493938452,
      "grad_norm": 0.5388995409011841,
      "learning_rate": 4.178582530307741e-06,
      "loss": 0.2241,
      "step": 14982
    },
    {
      "epoch": 1.164361206092633,
      "grad_norm": 0.3212241232395172,
      "learning_rate": 4.178193969536836e-06,
      "loss": 0.102,
      "step": 14983
    },
    {
      "epoch": 1.1644389182468138,
      "grad_norm": 0.22626230120658875,
      "learning_rate": 4.177805408765931e-06,
      "loss": 0.0836,
      "step": 14984
    },
    {
      "epoch": 1.1645166304009946,
      "grad_norm": 0.8973490595817566,
      "learning_rate": 4.177416847995026e-06,
      "loss": 0.1414,
      "step": 14985
    },
    {
      "epoch": 1.1645943425551757,
      "grad_norm": 0.5032066702842712,
      "learning_rate": 4.177028287224122e-06,
      "loss": 0.063,
      "step": 14986
    },
    {
      "epoch": 1.1646720547093565,
      "grad_norm": 0.3895099461078644,
      "learning_rate": 4.176639726453218e-06,
      "loss": 0.0774,
      "step": 14987
    },
    {
      "epoch": 1.1647497668635374,
      "grad_norm": 0.42108553647994995,
      "learning_rate": 4.176251165682313e-06,
      "loss": 0.1143,
      "step": 14988
    },
    {
      "epoch": 1.1648274790177184,
      "grad_norm": 0.30804985761642456,
      "learning_rate": 4.175862604911409e-06,
      "loss": 0.0434,
      "step": 14989
    },
    {
      "epoch": 1.1649051911718993,
      "grad_norm": 0.41339120268821716,
      "learning_rate": 4.175474044140504e-06,
      "loss": 0.2304,
      "step": 14990
    },
    {
      "epoch": 1.1649829033260801,
      "grad_norm": 0.311951607465744,
      "learning_rate": 4.1750854833695995e-06,
      "loss": 0.1291,
      "step": 14991
    },
    {
      "epoch": 1.1650606154802612,
      "grad_norm": 0.7073344588279724,
      "learning_rate": 4.174696922598695e-06,
      "loss": 0.2757,
      "step": 14992
    },
    {
      "epoch": 1.165138327634442,
      "grad_norm": 0.8168470859527588,
      "learning_rate": 4.17430836182779e-06,
      "loss": 0.2491,
      "step": 14993
    },
    {
      "epoch": 1.1652160397886229,
      "grad_norm": 0.37131980061531067,
      "learning_rate": 4.173919801056885e-06,
      "loss": 0.1382,
      "step": 14994
    },
    {
      "epoch": 1.165293751942804,
      "grad_norm": 0.6383723020553589,
      "learning_rate": 4.173531240285981e-06,
      "loss": 0.2916,
      "step": 14995
    },
    {
      "epoch": 1.1653714640969848,
      "grad_norm": 0.08818190544843674,
      "learning_rate": 4.173142679515077e-06,
      "loss": 0.0237,
      "step": 14996
    },
    {
      "epoch": 1.1654491762511656,
      "grad_norm": 0.14899687469005585,
      "learning_rate": 4.172754118744172e-06,
      "loss": 0.0358,
      "step": 14997
    },
    {
      "epoch": 1.1655268884053467,
      "grad_norm": 0.3599293529987335,
      "learning_rate": 4.1723655579732675e-06,
      "loss": 0.1051,
      "step": 14998
    },
    {
      "epoch": 1.1656046005595275,
      "grad_norm": 0.8251294493675232,
      "learning_rate": 4.1719769972023624e-06,
      "loss": 0.1413,
      "step": 14999
    },
    {
      "epoch": 1.1656823127137084,
      "grad_norm": 0.5321057438850403,
      "learning_rate": 4.171588436431458e-06,
      "loss": 0.0579,
      "step": 15000
    },
    {
      "epoch": 1.1657600248678894,
      "grad_norm": 0.1366470456123352,
      "learning_rate": 4.171199875660554e-06,
      "loss": 0.0406,
      "step": 15001
    },
    {
      "epoch": 1.1658377370220703,
      "grad_norm": 0.4292779266834259,
      "learning_rate": 4.170811314889649e-06,
      "loss": 0.0884,
      "step": 15002
    },
    {
      "epoch": 1.1659154491762511,
      "grad_norm": 0.6248193979263306,
      "learning_rate": 4.170422754118745e-06,
      "loss": 0.219,
      "step": 15003
    },
    {
      "epoch": 1.165993161330432,
      "grad_norm": 0.271351158618927,
      "learning_rate": 4.17003419334784e-06,
      "loss": 0.076,
      "step": 15004
    },
    {
      "epoch": 1.166070873484613,
      "grad_norm": 0.37580060958862305,
      "learning_rate": 4.1696456325769355e-06,
      "loss": 0.1034,
      "step": 15005
    },
    {
      "epoch": 1.1661485856387939,
      "grad_norm": 0.26605096459388733,
      "learning_rate": 4.169257071806031e-06,
      "loss": 0.1073,
      "step": 15006
    },
    {
      "epoch": 1.1662262977929747,
      "grad_norm": 0.37022173404693604,
      "learning_rate": 4.168868511035126e-06,
      "loss": 0.0786,
      "step": 15007
    },
    {
      "epoch": 1.1663040099471558,
      "grad_norm": 0.5743709206581116,
      "learning_rate": 4.168479950264221e-06,
      "loss": 0.3943,
      "step": 15008
    },
    {
      "epoch": 1.1663817221013366,
      "grad_norm": 0.18521901965141296,
      "learning_rate": 4.168091389493317e-06,
      "loss": 0.0603,
      "step": 15009
    },
    {
      "epoch": 1.1664594342555175,
      "grad_norm": 0.13658103346824646,
      "learning_rate": 4.167702828722413e-06,
      "loss": 0.0543,
      "step": 15010
    },
    {
      "epoch": 1.1665371464096985,
      "grad_norm": 0.3081490695476532,
      "learning_rate": 4.167314267951508e-06,
      "loss": 0.0614,
      "step": 15011
    },
    {
      "epoch": 1.1666148585638794,
      "grad_norm": 0.6180760264396667,
      "learning_rate": 4.1669257071806036e-06,
      "loss": 0.2568,
      "step": 15012
    },
    {
      "epoch": 1.1666925707180602,
      "grad_norm": 0.3381017744541168,
      "learning_rate": 4.1665371464096985e-06,
      "loss": 0.2158,
      "step": 15013
    },
    {
      "epoch": 1.1667702828722413,
      "grad_norm": 0.9248747825622559,
      "learning_rate": 4.166148585638794e-06,
      "loss": 0.3267,
      "step": 15014
    },
    {
      "epoch": 1.1668479950264221,
      "grad_norm": 0.30938076972961426,
      "learning_rate": 4.16576002486789e-06,
      "loss": 0.3099,
      "step": 15015
    },
    {
      "epoch": 1.166925707180603,
      "grad_norm": 0.23115481436252594,
      "learning_rate": 4.165371464096985e-06,
      "loss": 0.1012,
      "step": 15016
    },
    {
      "epoch": 1.167003419334784,
      "grad_norm": 0.7367239594459534,
      "learning_rate": 4.164982903326081e-06,
      "loss": 0.3077,
      "step": 15017
    },
    {
      "epoch": 1.1670811314889649,
      "grad_norm": 0.8367780447006226,
      "learning_rate": 4.164594342555176e-06,
      "loss": 0.2391,
      "step": 15018
    },
    {
      "epoch": 1.1671588436431457,
      "grad_norm": 0.4451589286327362,
      "learning_rate": 4.164205781784272e-06,
      "loss": 0.1683,
      "step": 15019
    },
    {
      "epoch": 1.1672365557973268,
      "grad_norm": 0.17421884834766388,
      "learning_rate": 4.163817221013367e-06,
      "loss": 0.0656,
      "step": 15020
    },
    {
      "epoch": 1.1673142679515076,
      "grad_norm": 0.20110222697257996,
      "learning_rate": 4.163428660242462e-06,
      "loss": 0.0967,
      "step": 15021
    },
    {
      "epoch": 1.1673919801056885,
      "grad_norm": 0.16652482748031616,
      "learning_rate": 4.163040099471557e-06,
      "loss": 0.0433,
      "step": 15022
    },
    {
      "epoch": 1.1674696922598695,
      "grad_norm": 0.3976542353630066,
      "learning_rate": 4.162651538700653e-06,
      "loss": 0.0665,
      "step": 15023
    },
    {
      "epoch": 1.1675474044140504,
      "grad_norm": 0.5888811945915222,
      "learning_rate": 4.162262977929749e-06,
      "loss": 0.3575,
      "step": 15024
    },
    {
      "epoch": 1.1676251165682312,
      "grad_norm": 0.45116156339645386,
      "learning_rate": 4.161874417158844e-06,
      "loss": 0.2632,
      "step": 15025
    },
    {
      "epoch": 1.1677028287224123,
      "grad_norm": 0.30652570724487305,
      "learning_rate": 4.16148585638794e-06,
      "loss": 0.1293,
      "step": 15026
    },
    {
      "epoch": 1.167780540876593,
      "grad_norm": 0.7907119989395142,
      "learning_rate": 4.161097295617035e-06,
      "loss": 0.7421,
      "step": 15027
    },
    {
      "epoch": 1.167858253030774,
      "grad_norm": 0.18547110259532928,
      "learning_rate": 4.16070873484613e-06,
      "loss": 0.0332,
      "step": 15028
    },
    {
      "epoch": 1.167935965184955,
      "grad_norm": 0.4501958191394806,
      "learning_rate": 4.160320174075226e-06,
      "loss": 0.3563,
      "step": 15029
    },
    {
      "epoch": 1.1680136773391359,
      "grad_norm": 0.1535143405199051,
      "learning_rate": 4.159931613304321e-06,
      "loss": 0.0426,
      "step": 15030
    },
    {
      "epoch": 1.1680913894933167,
      "grad_norm": 1.7306644916534424,
      "learning_rate": 4.159543052533417e-06,
      "loss": 0.3237,
      "step": 15031
    },
    {
      "epoch": 1.1681691016474978,
      "grad_norm": 0.2942151427268982,
      "learning_rate": 4.159154491762512e-06,
      "loss": 0.112,
      "step": 15032
    },
    {
      "epoch": 1.1682468138016786,
      "grad_norm": 0.32512152194976807,
      "learning_rate": 4.158765930991608e-06,
      "loss": 0.0396,
      "step": 15033
    },
    {
      "epoch": 1.1683245259558594,
      "grad_norm": 0.152145653963089,
      "learning_rate": 4.1583773702207035e-06,
      "loss": 0.0337,
      "step": 15034
    },
    {
      "epoch": 1.1684022381100405,
      "grad_norm": 1.3753455877304077,
      "learning_rate": 4.157988809449798e-06,
      "loss": 0.4139,
      "step": 15035
    },
    {
      "epoch": 1.1684799502642214,
      "grad_norm": 1.1806696653366089,
      "learning_rate": 4.157600248678893e-06,
      "loss": 0.9096,
      "step": 15036
    },
    {
      "epoch": 1.1685576624184022,
      "grad_norm": 0.2863762080669403,
      "learning_rate": 4.157211687907989e-06,
      "loss": 0.0747,
      "step": 15037
    },
    {
      "epoch": 1.1686353745725833,
      "grad_norm": 0.40643084049224854,
      "learning_rate": 4.156823127137085e-06,
      "loss": 0.0861,
      "step": 15038
    },
    {
      "epoch": 1.168713086726764,
      "grad_norm": 1.3284077644348145,
      "learning_rate": 4.15643456636618e-06,
      "loss": 0.4312,
      "step": 15039
    },
    {
      "epoch": 1.168790798880945,
      "grad_norm": 0.4421441853046417,
      "learning_rate": 4.156046005595276e-06,
      "loss": 0.2076,
      "step": 15040
    },
    {
      "epoch": 1.168868511035126,
      "grad_norm": 0.49422624707221985,
      "learning_rate": 4.155657444824371e-06,
      "loss": 0.1301,
      "step": 15041
    },
    {
      "epoch": 1.1689462231893069,
      "grad_norm": 0.404970645904541,
      "learning_rate": 4.1552688840534665e-06,
      "loss": 0.3013,
      "step": 15042
    },
    {
      "epoch": 1.1690239353434877,
      "grad_norm": 0.46324384212493896,
      "learning_rate": 4.154880323282562e-06,
      "loss": 0.0932,
      "step": 15043
    },
    {
      "epoch": 1.1691016474976685,
      "grad_norm": 0.7493346333503723,
      "learning_rate": 4.154491762511657e-06,
      "loss": 0.1793,
      "step": 15044
    },
    {
      "epoch": 1.1691793596518496,
      "grad_norm": 0.4553545415401459,
      "learning_rate": 4.154103201740752e-06,
      "loss": 0.3603,
      "step": 15045
    },
    {
      "epoch": 1.1692570718060304,
      "grad_norm": 0.35168391466140747,
      "learning_rate": 4.153714640969848e-06,
      "loss": 0.0874,
      "step": 15046
    },
    {
      "epoch": 1.1693347839602113,
      "grad_norm": 1.3062357902526855,
      "learning_rate": 4.153326080198944e-06,
      "loss": 0.4145,
      "step": 15047
    },
    {
      "epoch": 1.1694124961143924,
      "grad_norm": 0.08839704096317291,
      "learning_rate": 4.1529375194280395e-06,
      "loss": 0.0089,
      "step": 15048
    },
    {
      "epoch": 1.1694902082685732,
      "grad_norm": 0.20103059709072113,
      "learning_rate": 4.1525489586571345e-06,
      "loss": 0.0886,
      "step": 15049
    },
    {
      "epoch": 1.169567920422754,
      "grad_norm": 0.20901931822299957,
      "learning_rate": 4.1521603978862294e-06,
      "loss": 0.0621,
      "step": 15050
    },
    {
      "epoch": 1.169645632576935,
      "grad_norm": 0.11282812058925629,
      "learning_rate": 4.151771837115325e-06,
      "loss": 0.0281,
      "step": 15051
    },
    {
      "epoch": 1.169723344731116,
      "grad_norm": 0.5021096467971802,
      "learning_rate": 4.151383276344421e-06,
      "loss": 0.1738,
      "step": 15052
    },
    {
      "epoch": 1.1698010568852968,
      "grad_norm": 1.0022846460342407,
      "learning_rate": 4.150994715573516e-06,
      "loss": 0.1634,
      "step": 15053
    },
    {
      "epoch": 1.1698787690394779,
      "grad_norm": 0.24030552804470062,
      "learning_rate": 4.150606154802612e-06,
      "loss": 0.0336,
      "step": 15054
    },
    {
      "epoch": 1.1699564811936587,
      "grad_norm": 0.27926790714263916,
      "learning_rate": 4.150217594031707e-06,
      "loss": 0.0992,
      "step": 15055
    },
    {
      "epoch": 1.1700341933478395,
      "grad_norm": 0.526144802570343,
      "learning_rate": 4.149829033260802e-06,
      "loss": 0.2722,
      "step": 15056
    },
    {
      "epoch": 1.1701119055020206,
      "grad_norm": 0.14036959409713745,
      "learning_rate": 4.1494404724898975e-06,
      "loss": 0.0436,
      "step": 15057
    },
    {
      "epoch": 1.1701896176562014,
      "grad_norm": 0.514940083026886,
      "learning_rate": 4.149051911718993e-06,
      "loss": 0.394,
      "step": 15058
    },
    {
      "epoch": 1.1702673298103823,
      "grad_norm": 0.8662514090538025,
      "learning_rate": 4.148663350948088e-06,
      "loss": 0.5666,
      "step": 15059
    },
    {
      "epoch": 1.1703450419645633,
      "grad_norm": 0.2640455961227417,
      "learning_rate": 4.148274790177184e-06,
      "loss": 0.0349,
      "step": 15060
    },
    {
      "epoch": 1.1704227541187442,
      "grad_norm": 0.25354984402656555,
      "learning_rate": 4.147886229406279e-06,
      "loss": 0.1143,
      "step": 15061
    },
    {
      "epoch": 1.170500466272925,
      "grad_norm": 0.6378505825996399,
      "learning_rate": 4.147497668635375e-06,
      "loss": 0.148,
      "step": 15062
    },
    {
      "epoch": 1.1705781784271059,
      "grad_norm": 0.23963136970996857,
      "learning_rate": 4.1471091078644706e-06,
      "loss": 0.0482,
      "step": 15063
    },
    {
      "epoch": 1.170655890581287,
      "grad_norm": 0.6086680293083191,
      "learning_rate": 4.1467205470935655e-06,
      "loss": 0.1786,
      "step": 15064
    },
    {
      "epoch": 1.1707336027354678,
      "grad_norm": 1.108554482460022,
      "learning_rate": 4.146331986322661e-06,
      "loss": 0.2019,
      "step": 15065
    },
    {
      "epoch": 1.1708113148896486,
      "grad_norm": 0.10493201017379761,
      "learning_rate": 4.145943425551756e-06,
      "loss": 0.0384,
      "step": 15066
    },
    {
      "epoch": 1.1708890270438297,
      "grad_norm": 0.743645191192627,
      "learning_rate": 4.145554864780852e-06,
      "loss": 0.2013,
      "step": 15067
    },
    {
      "epoch": 1.1709667391980105,
      "grad_norm": 0.398490309715271,
      "learning_rate": 4.145166304009948e-06,
      "loss": 0.0978,
      "step": 15068
    },
    {
      "epoch": 1.1710444513521914,
      "grad_norm": 0.33348551392555237,
      "learning_rate": 4.144777743239043e-06,
      "loss": 0.1086,
      "step": 15069
    },
    {
      "epoch": 1.1711221635063724,
      "grad_norm": 0.7949180603027344,
      "learning_rate": 4.144389182468138e-06,
      "loss": 0.8543,
      "step": 15070
    },
    {
      "epoch": 1.1711998756605533,
      "grad_norm": 0.47840893268585205,
      "learning_rate": 4.1440006216972336e-06,
      "loss": 0.2488,
      "step": 15071
    },
    {
      "epoch": 1.1712775878147341,
      "grad_norm": 0.5794056057929993,
      "learning_rate": 4.143612060926329e-06,
      "loss": 0.1441,
      "step": 15072
    },
    {
      "epoch": 1.1713552999689152,
      "grad_norm": 0.5212157368659973,
      "learning_rate": 4.143223500155424e-06,
      "loss": 0.2982,
      "step": 15073
    },
    {
      "epoch": 1.171433012123096,
      "grad_norm": 0.16400296986103058,
      "learning_rate": 4.14283493938452e-06,
      "loss": 0.0747,
      "step": 15074
    },
    {
      "epoch": 1.1715107242772769,
      "grad_norm": 0.6341782808303833,
      "learning_rate": 4.142446378613615e-06,
      "loss": 0.3039,
      "step": 15075
    },
    {
      "epoch": 1.171588436431458,
      "grad_norm": 0.4393904507160187,
      "learning_rate": 4.142057817842711e-06,
      "loss": 0.175,
      "step": 15076
    },
    {
      "epoch": 1.1716661485856388,
      "grad_norm": 0.7308494448661804,
      "learning_rate": 4.141669257071807e-06,
      "loss": 0.8827,
      "step": 15077
    },
    {
      "epoch": 1.1717438607398196,
      "grad_norm": 0.5552225112915039,
      "learning_rate": 4.141280696300902e-06,
      "loss": 0.1062,
      "step": 15078
    },
    {
      "epoch": 1.1718215728940007,
      "grad_norm": 0.5477089285850525,
      "learning_rate": 4.140892135529997e-06,
      "loss": 0.2665,
      "step": 15079
    },
    {
      "epoch": 1.1718992850481815,
      "grad_norm": 0.3909297287464142,
      "learning_rate": 4.140503574759092e-06,
      "loss": 0.115,
      "step": 15080
    },
    {
      "epoch": 1.1719769972023624,
      "grad_norm": 0.47311654686927795,
      "learning_rate": 4.140115013988188e-06,
      "loss": 0.0738,
      "step": 15081
    },
    {
      "epoch": 1.1720547093565434,
      "grad_norm": 0.3503711521625519,
      "learning_rate": 4.139726453217284e-06,
      "loss": 0.1567,
      "step": 15082
    },
    {
      "epoch": 1.1721324215107243,
      "grad_norm": 0.5969266891479492,
      "learning_rate": 4.139337892446379e-06,
      "loss": 0.1451,
      "step": 15083
    },
    {
      "epoch": 1.1722101336649051,
      "grad_norm": 0.5087877511978149,
      "learning_rate": 4.138949331675474e-06,
      "loss": 0.2085,
      "step": 15084
    },
    {
      "epoch": 1.1722878458190862,
      "grad_norm": 0.43566828966140747,
      "learning_rate": 4.13856077090457e-06,
      "loss": 0.3399,
      "step": 15085
    },
    {
      "epoch": 1.172365557973267,
      "grad_norm": 0.33162471652030945,
      "learning_rate": 4.1381722101336654e-06,
      "loss": 0.0633,
      "step": 15086
    },
    {
      "epoch": 1.1724432701274479,
      "grad_norm": 0.15614159405231476,
      "learning_rate": 4.13778364936276e-06,
      "loss": 0.0489,
      "step": 15087
    },
    {
      "epoch": 1.172520982281629,
      "grad_norm": 0.13158300518989563,
      "learning_rate": 4.137395088591856e-06,
      "loss": 0.0177,
      "step": 15088
    },
    {
      "epoch": 1.1725986944358098,
      "grad_norm": 0.6795080304145813,
      "learning_rate": 4.137006527820951e-06,
      "loss": 0.1219,
      "step": 15089
    },
    {
      "epoch": 1.1726764065899906,
      "grad_norm": 0.21437232196331024,
      "learning_rate": 4.136617967050047e-06,
      "loss": 0.0557,
      "step": 15090
    },
    {
      "epoch": 1.1727541187441717,
      "grad_norm": 0.4253585934638977,
      "learning_rate": 4.136229406279143e-06,
      "loss": 0.1845,
      "step": 15091
    },
    {
      "epoch": 1.1728318308983525,
      "grad_norm": 0.5831630825996399,
      "learning_rate": 4.135840845508238e-06,
      "loss": 0.0561,
      "step": 15092
    },
    {
      "epoch": 1.1729095430525334,
      "grad_norm": 0.4660486876964569,
      "learning_rate": 4.1354522847373335e-06,
      "loss": 0.1384,
      "step": 15093
    },
    {
      "epoch": 1.1729872552067144,
      "grad_norm": 0.3232766091823578,
      "learning_rate": 4.135063723966428e-06,
      "loss": 0.0378,
      "step": 15094
    },
    {
      "epoch": 1.1730649673608953,
      "grad_norm": 0.4616009593009949,
      "learning_rate": 4.134675163195524e-06,
      "loss": 0.2463,
      "step": 15095
    },
    {
      "epoch": 1.1731426795150761,
      "grad_norm": 0.23710475862026215,
      "learning_rate": 4.13428660242462e-06,
      "loss": 0.0865,
      "step": 15096
    },
    {
      "epoch": 1.1732203916692572,
      "grad_norm": 0.22387243807315826,
      "learning_rate": 4.133898041653715e-06,
      "loss": 0.0818,
      "step": 15097
    },
    {
      "epoch": 1.173298103823438,
      "grad_norm": 0.20953015983104706,
      "learning_rate": 4.13350948088281e-06,
      "loss": 0.0804,
      "step": 15098
    },
    {
      "epoch": 1.1733758159776189,
      "grad_norm": 0.5613418817520142,
      "learning_rate": 4.133120920111906e-06,
      "loss": 0.4706,
      "step": 15099
    },
    {
      "epoch": 1.1734535281318,
      "grad_norm": 0.9914686679840088,
      "learning_rate": 4.1327323593410015e-06,
      "loss": 1.4075,
      "step": 15100
    },
    {
      "epoch": 1.1735312402859808,
      "grad_norm": 0.2147105485200882,
      "learning_rate": 4.1323437985700964e-06,
      "loss": 0.0242,
      "step": 15101
    },
    {
      "epoch": 1.1736089524401616,
      "grad_norm": 0.2252594232559204,
      "learning_rate": 4.131955237799192e-06,
      "loss": 0.0493,
      "step": 15102
    },
    {
      "epoch": 1.1736866645943427,
      "grad_norm": 0.35572266578674316,
      "learning_rate": 4.131566677028287e-06,
      "loss": 0.1584,
      "step": 15103
    },
    {
      "epoch": 1.1737643767485235,
      "grad_norm": 1.00926673412323,
      "learning_rate": 4.131178116257383e-06,
      "loss": 0.2828,
      "step": 15104
    },
    {
      "epoch": 1.1738420889027044,
      "grad_norm": 0.2932862341403961,
      "learning_rate": 4.130789555486479e-06,
      "loss": 0.0819,
      "step": 15105
    },
    {
      "epoch": 1.1739198010568852,
      "grad_norm": 0.43096810579299927,
      "learning_rate": 4.130400994715574e-06,
      "loss": 0.0925,
      "step": 15106
    },
    {
      "epoch": 1.1739975132110663,
      "grad_norm": 0.5152945518493652,
      "learning_rate": 4.1300124339446695e-06,
      "loss": 0.2859,
      "step": 15107
    },
    {
      "epoch": 1.174075225365247,
      "grad_norm": 0.5865306854248047,
      "learning_rate": 4.1296238731737645e-06,
      "loss": 0.1483,
      "step": 15108
    },
    {
      "epoch": 1.174152937519428,
      "grad_norm": 0.3811913728713989,
      "learning_rate": 4.12923531240286e-06,
      "loss": 0.234,
      "step": 15109
    },
    {
      "epoch": 1.174230649673609,
      "grad_norm": 0.5510791540145874,
      "learning_rate": 4.128846751631956e-06,
      "loss": 0.3743,
      "step": 15110
    },
    {
      "epoch": 1.1743083618277899,
      "grad_norm": 0.9064726233482361,
      "learning_rate": 4.128458190861051e-06,
      "loss": 0.2903,
      "step": 15111
    },
    {
      "epoch": 1.1743860739819707,
      "grad_norm": 0.41636577248573303,
      "learning_rate": 4.128069630090146e-06,
      "loss": 0.0354,
      "step": 15112
    },
    {
      "epoch": 1.1744637861361518,
      "grad_norm": 0.19071044027805328,
      "learning_rate": 4.127681069319242e-06,
      "loss": 0.0697,
      "step": 15113
    },
    {
      "epoch": 1.1745414982903326,
      "grad_norm": 0.21193909645080566,
      "learning_rate": 4.1272925085483376e-06,
      "loss": 0.2271,
      "step": 15114
    },
    {
      "epoch": 1.1746192104445135,
      "grad_norm": 0.47032395005226135,
      "learning_rate": 4.1269039477774325e-06,
      "loss": 0.1469,
      "step": 15115
    },
    {
      "epoch": 1.1746969225986945,
      "grad_norm": 0.2279849499464035,
      "learning_rate": 4.126515387006528e-06,
      "loss": 0.0589,
      "step": 15116
    },
    {
      "epoch": 1.1747746347528754,
      "grad_norm": 1.493180513381958,
      "learning_rate": 4.126126826235623e-06,
      "loss": 0.8703,
      "step": 15117
    },
    {
      "epoch": 1.1748523469070562,
      "grad_norm": 0.6000272631645203,
      "learning_rate": 4.125738265464719e-06,
      "loss": 0.9189,
      "step": 15118
    },
    {
      "epoch": 1.1749300590612373,
      "grad_norm": 0.4218485653400421,
      "learning_rate": 4.125349704693815e-06,
      "loss": 0.1951,
      "step": 15119
    },
    {
      "epoch": 1.175007771215418,
      "grad_norm": 1.4498482942581177,
      "learning_rate": 4.12496114392291e-06,
      "loss": 0.1817,
      "step": 15120
    },
    {
      "epoch": 1.175085483369599,
      "grad_norm": 0.5094186663627625,
      "learning_rate": 4.124572583152005e-06,
      "loss": 0.2077,
      "step": 15121
    },
    {
      "epoch": 1.17516319552378,
      "grad_norm": 0.40468335151672363,
      "learning_rate": 4.1241840223811006e-06,
      "loss": 0.1669,
      "step": 15122
    },
    {
      "epoch": 1.1752409076779609,
      "grad_norm": 0.8673649430274963,
      "learning_rate": 4.123795461610196e-06,
      "loss": 0.3035,
      "step": 15123
    },
    {
      "epoch": 1.1753186198321417,
      "grad_norm": 0.48386287689208984,
      "learning_rate": 4.123406900839292e-06,
      "loss": 0.2299,
      "step": 15124
    },
    {
      "epoch": 1.1753963319863225,
      "grad_norm": 0.7465695142745972,
      "learning_rate": 4.123018340068387e-06,
      "loss": 0.2614,
      "step": 15125
    },
    {
      "epoch": 1.1754740441405036,
      "grad_norm": 0.5129910707473755,
      "learning_rate": 4.122629779297482e-06,
      "loss": 0.3391,
      "step": 15126
    },
    {
      "epoch": 1.1755517562946844,
      "grad_norm": 0.24443505704402924,
      "learning_rate": 4.122241218526578e-06,
      "loss": 0.061,
      "step": 15127
    },
    {
      "epoch": 1.1756294684488653,
      "grad_norm": 0.16309481859207153,
      "learning_rate": 4.121852657755674e-06,
      "loss": 0.0114,
      "step": 15128
    },
    {
      "epoch": 1.1757071806030464,
      "grad_norm": 0.40221893787384033,
      "learning_rate": 4.121464096984769e-06,
      "loss": 0.0465,
      "step": 15129
    },
    {
      "epoch": 1.1757848927572272,
      "grad_norm": 0.9482532739639282,
      "learning_rate": 4.121075536213864e-06,
      "loss": 0.3454,
      "step": 15130
    },
    {
      "epoch": 1.175862604911408,
      "grad_norm": 1.0515257120132446,
      "learning_rate": 4.120686975442959e-06,
      "loss": 0.3695,
      "step": 15131
    },
    {
      "epoch": 1.175940317065589,
      "grad_norm": 0.44643092155456543,
      "learning_rate": 4.120298414672055e-06,
      "loss": 0.1569,
      "step": 15132
    },
    {
      "epoch": 1.17601802921977,
      "grad_norm": 0.10409275442361832,
      "learning_rate": 4.119909853901151e-06,
      "loss": 0.0457,
      "step": 15133
    },
    {
      "epoch": 1.1760957413739508,
      "grad_norm": 0.22145281732082367,
      "learning_rate": 4.119521293130246e-06,
      "loss": 0.0351,
      "step": 15134
    },
    {
      "epoch": 1.1761734535281319,
      "grad_norm": 0.3488020598888397,
      "learning_rate": 4.119132732359341e-06,
      "loss": 0.1033,
      "step": 15135
    },
    {
      "epoch": 1.1762511656823127,
      "grad_norm": 0.4084402322769165,
      "learning_rate": 4.118744171588437e-06,
      "loss": 0.1297,
      "step": 15136
    },
    {
      "epoch": 1.1763288778364935,
      "grad_norm": 0.5637880563735962,
      "learning_rate": 4.1183556108175324e-06,
      "loss": 0.1597,
      "step": 15137
    },
    {
      "epoch": 1.1764065899906746,
      "grad_norm": 0.45195895433425903,
      "learning_rate": 4.117967050046628e-06,
      "loss": 0.1747,
      "step": 15138
    },
    {
      "epoch": 1.1764843021448554,
      "grad_norm": 0.13199947774410248,
      "learning_rate": 4.117578489275723e-06,
      "loss": 0.0141,
      "step": 15139
    },
    {
      "epoch": 1.1765620142990363,
      "grad_norm": 0.10776688158512115,
      "learning_rate": 4.117189928504818e-06,
      "loss": 0.032,
      "step": 15140
    },
    {
      "epoch": 1.1766397264532173,
      "grad_norm": 0.6484169960021973,
      "learning_rate": 4.116801367733914e-06,
      "loss": 0.2768,
      "step": 15141
    },
    {
      "epoch": 1.1767174386073982,
      "grad_norm": 0.5883508324623108,
      "learning_rate": 4.11641280696301e-06,
      "loss": 0.1569,
      "step": 15142
    },
    {
      "epoch": 1.176795150761579,
      "grad_norm": 0.2816557288169861,
      "learning_rate": 4.116024246192105e-06,
      "loss": 0.1383,
      "step": 15143
    },
    {
      "epoch": 1.17687286291576,
      "grad_norm": 0.21179106831550598,
      "learning_rate": 4.1156356854212005e-06,
      "loss": 0.0484,
      "step": 15144
    },
    {
      "epoch": 1.176950575069941,
      "grad_norm": 0.9599310159683228,
      "learning_rate": 4.115247124650295e-06,
      "loss": 0.7623,
      "step": 15145
    },
    {
      "epoch": 1.1770282872241218,
      "grad_norm": 0.6423831582069397,
      "learning_rate": 4.114858563879391e-06,
      "loss": 0.139,
      "step": 15146
    },
    {
      "epoch": 1.1771059993783028,
      "grad_norm": 0.3204033076763153,
      "learning_rate": 4.114470003108487e-06,
      "loss": 0.0994,
      "step": 15147
    },
    {
      "epoch": 1.1771837115324837,
      "grad_norm": 1.229570746421814,
      "learning_rate": 4.114081442337582e-06,
      "loss": 0.2644,
      "step": 15148
    },
    {
      "epoch": 1.1772614236866645,
      "grad_norm": 0.23221313953399658,
      "learning_rate": 4.113692881566677e-06,
      "loss": 0.0576,
      "step": 15149
    },
    {
      "epoch": 1.1773391358408456,
      "grad_norm": 0.2553819715976715,
      "learning_rate": 4.113304320795773e-06,
      "loss": 0.0525,
      "step": 15150
    },
    {
      "epoch": 1.1774168479950264,
      "grad_norm": 0.33640339970588684,
      "learning_rate": 4.1129157600248685e-06,
      "loss": 0.0938,
      "step": 15151
    },
    {
      "epoch": 1.1774945601492073,
      "grad_norm": 0.21865585446357727,
      "learning_rate": 4.112527199253964e-06,
      "loss": 0.0452,
      "step": 15152
    },
    {
      "epoch": 1.1775722723033883,
      "grad_norm": 0.7676181793212891,
      "learning_rate": 4.112138638483059e-06,
      "loss": 0.3484,
      "step": 15153
    },
    {
      "epoch": 1.1776499844575692,
      "grad_norm": 0.37134623527526855,
      "learning_rate": 4.111750077712154e-06,
      "loss": 0.0594,
      "step": 15154
    },
    {
      "epoch": 1.17772769661175,
      "grad_norm": 0.7279243469238281,
      "learning_rate": 4.11136151694125e-06,
      "loss": 0.253,
      "step": 15155
    },
    {
      "epoch": 1.177805408765931,
      "grad_norm": 0.4743990898132324,
      "learning_rate": 4.110972956170346e-06,
      "loss": 0.1283,
      "step": 15156
    },
    {
      "epoch": 1.177883120920112,
      "grad_norm": 0.43599653244018555,
      "learning_rate": 4.110584395399441e-06,
      "loss": 0.1652,
      "step": 15157
    },
    {
      "epoch": 1.1779608330742928,
      "grad_norm": 0.7720634341239929,
      "learning_rate": 4.1101958346285365e-06,
      "loss": 0.0562,
      "step": 15158
    },
    {
      "epoch": 1.1780385452284738,
      "grad_norm": 0.29071614146232605,
      "learning_rate": 4.1098072738576315e-06,
      "loss": 0.1082,
      "step": 15159
    },
    {
      "epoch": 1.1781162573826547,
      "grad_norm": 0.9871322512626648,
      "learning_rate": 4.109418713086727e-06,
      "loss": 0.1881,
      "step": 15160
    },
    {
      "epoch": 1.1781939695368355,
      "grad_norm": 0.6485212445259094,
      "learning_rate": 4.109030152315823e-06,
      "loss": 0.3638,
      "step": 15161
    },
    {
      "epoch": 1.1782716816910166,
      "grad_norm": 0.23909781873226166,
      "learning_rate": 4.108641591544918e-06,
      "loss": 0.0663,
      "step": 15162
    },
    {
      "epoch": 1.1783493938451974,
      "grad_norm": 1.1055368185043335,
      "learning_rate": 4.108253030774013e-06,
      "loss": 0.1745,
      "step": 15163
    },
    {
      "epoch": 1.1784271059993783,
      "grad_norm": 0.5593454837799072,
      "learning_rate": 4.107864470003109e-06,
      "loss": 0.2573,
      "step": 15164
    },
    {
      "epoch": 1.1785048181535593,
      "grad_norm": 0.7872083783149719,
      "learning_rate": 4.1074759092322046e-06,
      "loss": 0.2621,
      "step": 15165
    },
    {
      "epoch": 1.1785825303077402,
      "grad_norm": 0.14057046175003052,
      "learning_rate": 4.1070873484612995e-06,
      "loss": 0.0077,
      "step": 15166
    },
    {
      "epoch": 1.178660242461921,
      "grad_norm": 0.6667982339859009,
      "learning_rate": 4.106698787690395e-06,
      "loss": 0.2792,
      "step": 15167
    },
    {
      "epoch": 1.1787379546161019,
      "grad_norm": 0.5304772257804871,
      "learning_rate": 4.10631022691949e-06,
      "loss": 0.1177,
      "step": 15168
    },
    {
      "epoch": 1.178815666770283,
      "grad_norm": 0.5417117476463318,
      "learning_rate": 4.105921666148586e-06,
      "loss": 0.1728,
      "step": 15169
    },
    {
      "epoch": 1.1788933789244638,
      "grad_norm": 0.6102001070976257,
      "learning_rate": 4.105533105377682e-06,
      "loss": 0.3145,
      "step": 15170
    },
    {
      "epoch": 1.1789710910786446,
      "grad_norm": 0.8213825225830078,
      "learning_rate": 4.105144544606777e-06,
      "loss": 0.5365,
      "step": 15171
    },
    {
      "epoch": 1.1790488032328257,
      "grad_norm": 0.2939404547214508,
      "learning_rate": 4.104755983835873e-06,
      "loss": 0.1765,
      "step": 15172
    },
    {
      "epoch": 1.1791265153870065,
      "grad_norm": 1.0110697746276855,
      "learning_rate": 4.1043674230649676e-06,
      "loss": 0.2044,
      "step": 15173
    },
    {
      "epoch": 1.1792042275411874,
      "grad_norm": 1.0491195917129517,
      "learning_rate": 4.103978862294063e-06,
      "loss": 0.7455,
      "step": 15174
    },
    {
      "epoch": 1.1792819396953684,
      "grad_norm": 0.6057230830192566,
      "learning_rate": 4.103590301523159e-06,
      "loss": 0.239,
      "step": 15175
    },
    {
      "epoch": 1.1793596518495493,
      "grad_norm": 3.2093663215637207,
      "learning_rate": 4.103201740752254e-06,
      "loss": 0.564,
      "step": 15176
    },
    {
      "epoch": 1.1794373640037301,
      "grad_norm": 0.42364540696144104,
      "learning_rate": 4.102813179981349e-06,
      "loss": 0.1315,
      "step": 15177
    },
    {
      "epoch": 1.1795150761579112,
      "grad_norm": 0.3308998942375183,
      "learning_rate": 4.102424619210445e-06,
      "loss": 0.0616,
      "step": 15178
    },
    {
      "epoch": 1.179592788312092,
      "grad_norm": 0.3115427494049072,
      "learning_rate": 4.102036058439541e-06,
      "loss": 0.0614,
      "step": 15179
    },
    {
      "epoch": 1.1796705004662729,
      "grad_norm": 0.46942248940467834,
      "learning_rate": 4.101647497668636e-06,
      "loss": 0.2171,
      "step": 15180
    },
    {
      "epoch": 1.179748212620454,
      "grad_norm": 0.4593401253223419,
      "learning_rate": 4.101258936897731e-06,
      "loss": 0.1567,
      "step": 15181
    },
    {
      "epoch": 1.1798259247746348,
      "grad_norm": 0.2105049341917038,
      "learning_rate": 4.100870376126826e-06,
      "loss": 0.0392,
      "step": 15182
    },
    {
      "epoch": 1.1799036369288156,
      "grad_norm": 0.48161739110946655,
      "learning_rate": 4.100481815355922e-06,
      "loss": 0.0325,
      "step": 15183
    },
    {
      "epoch": 1.1799813490829967,
      "grad_norm": 0.45768338441848755,
      "learning_rate": 4.100093254585017e-06,
      "loss": 0.0649,
      "step": 15184
    },
    {
      "epoch": 1.1800590612371775,
      "grad_norm": 0.3886202573776245,
      "learning_rate": 4.099704693814113e-06,
      "loss": 0.1075,
      "step": 15185
    },
    {
      "epoch": 1.1801367733913584,
      "grad_norm": 0.3647686839103699,
      "learning_rate": 4.099316133043209e-06,
      "loss": 0.2063,
      "step": 15186
    },
    {
      "epoch": 1.1802144855455392,
      "grad_norm": 0.40228360891342163,
      "learning_rate": 4.098927572272304e-06,
      "loss": 0.1132,
      "step": 15187
    },
    {
      "epoch": 1.1802921976997203,
      "grad_norm": 1.2764512300491333,
      "learning_rate": 4.098539011501399e-06,
      "loss": 0.4195,
      "step": 15188
    },
    {
      "epoch": 1.1803699098539011,
      "grad_norm": 0.3243725299835205,
      "learning_rate": 4.098150450730494e-06,
      "loss": 0.1331,
      "step": 15189
    },
    {
      "epoch": 1.180447622008082,
      "grad_norm": 0.5000951290130615,
      "learning_rate": 4.09776188995959e-06,
      "loss": 0.1445,
      "step": 15190
    },
    {
      "epoch": 1.180525334162263,
      "grad_norm": 0.33101215958595276,
      "learning_rate": 4.097373329188685e-06,
      "loss": 0.2743,
      "step": 15191
    },
    {
      "epoch": 1.1806030463164439,
      "grad_norm": 0.7183238863945007,
      "learning_rate": 4.096984768417781e-06,
      "loss": 0.3006,
      "step": 15192
    },
    {
      "epoch": 1.1806807584706247,
      "grad_norm": 0.23262245953083038,
      "learning_rate": 4.096596207646876e-06,
      "loss": 0.0656,
      "step": 15193
    },
    {
      "epoch": 1.1807584706248058,
      "grad_norm": 0.4511028528213501,
      "learning_rate": 4.096207646875972e-06,
      "loss": 0.2112,
      "step": 15194
    },
    {
      "epoch": 1.1808361827789866,
      "grad_norm": 0.3500201404094696,
      "learning_rate": 4.0958190861050675e-06,
      "loss": 0.1547,
      "step": 15195
    },
    {
      "epoch": 1.1809138949331675,
      "grad_norm": 1.16751229763031,
      "learning_rate": 4.095430525334162e-06,
      "loss": 0.3088,
      "step": 15196
    },
    {
      "epoch": 1.1809916070873485,
      "grad_norm": 0.4904000163078308,
      "learning_rate": 4.095041964563257e-06,
      "loss": 0.4992,
      "step": 15197
    },
    {
      "epoch": 1.1810693192415294,
      "grad_norm": 0.5784124732017517,
      "learning_rate": 4.094653403792353e-06,
      "loss": 0.6086,
      "step": 15198
    },
    {
      "epoch": 1.1811470313957102,
      "grad_norm": 0.13695551455020905,
      "learning_rate": 4.094264843021449e-06,
      "loss": 0.0047,
      "step": 15199
    },
    {
      "epoch": 1.1812247435498913,
      "grad_norm": 0.4280301630496979,
      "learning_rate": 4.093876282250545e-06,
      "loss": 0.1162,
      "step": 15200
    },
    {
      "epoch": 1.181302455704072,
      "grad_norm": 0.5001450181007385,
      "learning_rate": 4.09348772147964e-06,
      "loss": 0.1751,
      "step": 15201
    },
    {
      "epoch": 1.181380167858253,
      "grad_norm": 0.6007421016693115,
      "learning_rate": 4.093099160708735e-06,
      "loss": 0.1291,
      "step": 15202
    },
    {
      "epoch": 1.181457880012434,
      "grad_norm": 0.6269694566726685,
      "learning_rate": 4.0927105999378305e-06,
      "loss": 0.2422,
      "step": 15203
    },
    {
      "epoch": 1.1815355921666149,
      "grad_norm": 0.5859631299972534,
      "learning_rate": 4.092322039166926e-06,
      "loss": 0.1692,
      "step": 15204
    },
    {
      "epoch": 1.1816133043207957,
      "grad_norm": 0.33547696471214294,
      "learning_rate": 4.091933478396021e-06,
      "loss": 0.0575,
      "step": 15205
    },
    {
      "epoch": 1.1816910164749768,
      "grad_norm": 3.046736240386963,
      "learning_rate": 4.091544917625117e-06,
      "loss": 0.6244,
      "step": 15206
    },
    {
      "epoch": 1.1817687286291576,
      "grad_norm": 0.5097898244857788,
      "learning_rate": 4.091156356854212e-06,
      "loss": 0.0843,
      "step": 15207
    },
    {
      "epoch": 1.1818464407833384,
      "grad_norm": 0.618812084197998,
      "learning_rate": 4.090767796083308e-06,
      "loss": 0.1529,
      "step": 15208
    },
    {
      "epoch": 1.1819241529375195,
      "grad_norm": 0.1904100924730301,
      "learning_rate": 4.0903792353124035e-06,
      "loss": 0.0362,
      "step": 15209
    },
    {
      "epoch": 1.1820018650917004,
      "grad_norm": 0.521190881729126,
      "learning_rate": 4.0899906745414985e-06,
      "loss": 0.1239,
      "step": 15210
    },
    {
      "epoch": 1.1820795772458812,
      "grad_norm": 0.44109001755714417,
      "learning_rate": 4.0896021137705934e-06,
      "loss": 0.2241,
      "step": 15211
    },
    {
      "epoch": 1.1821572894000623,
      "grad_norm": 0.09628574550151825,
      "learning_rate": 4.089213552999689e-06,
      "loss": 0.033,
      "step": 15212
    },
    {
      "epoch": 1.182235001554243,
      "grad_norm": 0.3706831932067871,
      "learning_rate": 4.088824992228785e-06,
      "loss": 0.3504,
      "step": 15213
    },
    {
      "epoch": 1.182312713708424,
      "grad_norm": 1.3032690286636353,
      "learning_rate": 4.088436431457881e-06,
      "loss": 0.968,
      "step": 15214
    },
    {
      "epoch": 1.182390425862605,
      "grad_norm": 0.1727847009897232,
      "learning_rate": 4.088047870686976e-06,
      "loss": 0.0304,
      "step": 15215
    },
    {
      "epoch": 1.1824681380167859,
      "grad_norm": 0.466253399848938,
      "learning_rate": 4.087659309916071e-06,
      "loss": 0.0563,
      "step": 15216
    },
    {
      "epoch": 1.1825458501709667,
      "grad_norm": 0.6918273568153381,
      "learning_rate": 4.0872707491451665e-06,
      "loss": 0.2409,
      "step": 15217
    },
    {
      "epoch": 1.1826235623251478,
      "grad_norm": 0.269060879945755,
      "learning_rate": 4.086882188374262e-06,
      "loss": 0.1056,
      "step": 15218
    },
    {
      "epoch": 1.1827012744793286,
      "grad_norm": 0.4054983854293823,
      "learning_rate": 4.086493627603357e-06,
      "loss": 0.2063,
      "step": 15219
    },
    {
      "epoch": 1.1827789866335094,
      "grad_norm": 0.6319870352745056,
      "learning_rate": 4.086105066832453e-06,
      "loss": 0.5057,
      "step": 15220
    },
    {
      "epoch": 1.1828566987876905,
      "grad_norm": 0.5433294177055359,
      "learning_rate": 4.085716506061548e-06,
      "loss": 0.2468,
      "step": 15221
    },
    {
      "epoch": 1.1829344109418714,
      "grad_norm": 0.4247710704803467,
      "learning_rate": 4.085327945290644e-06,
      "loss": 0.147,
      "step": 15222
    },
    {
      "epoch": 1.1830121230960522,
      "grad_norm": 6.673443794250488,
      "learning_rate": 4.08493938451974e-06,
      "loss": 0.2511,
      "step": 15223
    },
    {
      "epoch": 1.1830898352502333,
      "grad_norm": 0.12257924675941467,
      "learning_rate": 4.0845508237488346e-06,
      "loss": 0.0207,
      "step": 15224
    },
    {
      "epoch": 1.183167547404414,
      "grad_norm": 0.3968748450279236,
      "learning_rate": 4.0841622629779295e-06,
      "loss": 0.3518,
      "step": 15225
    },
    {
      "epoch": 1.183245259558595,
      "grad_norm": 0.1761699765920639,
      "learning_rate": 4.083773702207025e-06,
      "loss": 0.0557,
      "step": 15226
    },
    {
      "epoch": 1.1833229717127758,
      "grad_norm": 1.7218966484069824,
      "learning_rate": 4.083385141436121e-06,
      "loss": 0.408,
      "step": 15227
    },
    {
      "epoch": 1.1834006838669568,
      "grad_norm": 0.5021416544914246,
      "learning_rate": 4.082996580665217e-06,
      "loss": 0.1586,
      "step": 15228
    },
    {
      "epoch": 1.1834783960211377,
      "grad_norm": 2.260124921798706,
      "learning_rate": 4.082608019894312e-06,
      "loss": 0.3317,
      "step": 15229
    },
    {
      "epoch": 1.1835561081753185,
      "grad_norm": 0.2131955921649933,
      "learning_rate": 4.082219459123407e-06,
      "loss": 0.033,
      "step": 15230
    },
    {
      "epoch": 1.1836338203294996,
      "grad_norm": 0.3023446202278137,
      "learning_rate": 4.081830898352503e-06,
      "loss": 0.0734,
      "step": 15231
    },
    {
      "epoch": 1.1837115324836804,
      "grad_norm": 0.4957645535469055,
      "learning_rate": 4.081442337581598e-06,
      "loss": 0.1165,
      "step": 15232
    },
    {
      "epoch": 1.1837892446378613,
      "grad_norm": 0.46671709418296814,
      "learning_rate": 4.081053776810693e-06,
      "loss": 0.1623,
      "step": 15233
    },
    {
      "epoch": 1.1838669567920423,
      "grad_norm": 0.2294563502073288,
      "learning_rate": 4.080665216039789e-06,
      "loss": 0.1145,
      "step": 15234
    },
    {
      "epoch": 1.1839446689462232,
      "grad_norm": 1.071755290031433,
      "learning_rate": 4.080276655268884e-06,
      "loss": 0.1907,
      "step": 15235
    },
    {
      "epoch": 1.184022381100404,
      "grad_norm": 0.8882368206977844,
      "learning_rate": 4.07988809449798e-06,
      "loss": 0.3964,
      "step": 15236
    },
    {
      "epoch": 1.184100093254585,
      "grad_norm": 0.17891912162303925,
      "learning_rate": 4.079499533727076e-06,
      "loss": 0.0793,
      "step": 15237
    },
    {
      "epoch": 1.184177805408766,
      "grad_norm": 0.9514418244361877,
      "learning_rate": 4.079110972956171e-06,
      "loss": 0.4465,
      "step": 15238
    },
    {
      "epoch": 1.1842555175629468,
      "grad_norm": 0.2928467094898224,
      "learning_rate": 4.078722412185266e-06,
      "loss": 0.0835,
      "step": 15239
    },
    {
      "epoch": 1.1843332297171278,
      "grad_norm": 0.35702723264694214,
      "learning_rate": 4.078333851414361e-06,
      "loss": 0.117,
      "step": 15240
    },
    {
      "epoch": 1.1844109418713087,
      "grad_norm": 0.2968430519104004,
      "learning_rate": 4.077945290643457e-06,
      "loss": 0.088,
      "step": 15241
    },
    {
      "epoch": 1.1844886540254895,
      "grad_norm": 1.0693953037261963,
      "learning_rate": 4.077556729872552e-06,
      "loss": 0.6475,
      "step": 15242
    },
    {
      "epoch": 1.1845663661796706,
      "grad_norm": 0.6365848779678345,
      "learning_rate": 4.077168169101648e-06,
      "loss": 0.1805,
      "step": 15243
    },
    {
      "epoch": 1.1846440783338514,
      "grad_norm": 0.5378632545471191,
      "learning_rate": 4.076779608330743e-06,
      "loss": 0.4093,
      "step": 15244
    },
    {
      "epoch": 1.1847217904880323,
      "grad_norm": 0.3977793753147125,
      "learning_rate": 4.076391047559839e-06,
      "loss": 0.2157,
      "step": 15245
    },
    {
      "epoch": 1.1847995026422131,
      "grad_norm": 0.3870921730995178,
      "learning_rate": 4.0760024867889345e-06,
      "loss": 0.2053,
      "step": 15246
    },
    {
      "epoch": 1.1848772147963942,
      "grad_norm": 0.05513966456055641,
      "learning_rate": 4.075613926018029e-06,
      "loss": 0.0082,
      "step": 15247
    },
    {
      "epoch": 1.184954926950575,
      "grad_norm": 0.071059450507164,
      "learning_rate": 4.075225365247125e-06,
      "loss": 0.026,
      "step": 15248
    },
    {
      "epoch": 1.1850326391047559,
      "grad_norm": 0.45690569281578064,
      "learning_rate": 4.07483680447622e-06,
      "loss": 0.0791,
      "step": 15249
    },
    {
      "epoch": 1.185110351258937,
      "grad_norm": 0.3886878192424774,
      "learning_rate": 4.074448243705316e-06,
      "loss": 0.1189,
      "step": 15250
    },
    {
      "epoch": 1.1851880634131178,
      "grad_norm": 0.32743048667907715,
      "learning_rate": 4.074059682934412e-06,
      "loss": 0.1829,
      "step": 15251
    },
    {
      "epoch": 1.1852657755672986,
      "grad_norm": 0.22381211817264557,
      "learning_rate": 4.073671122163507e-06,
      "loss": 0.0655,
      "step": 15252
    },
    {
      "epoch": 1.1853434877214797,
      "grad_norm": 0.498574823141098,
      "learning_rate": 4.073282561392602e-06,
      "loss": 0.3425,
      "step": 15253
    },
    {
      "epoch": 1.1854211998756605,
      "grad_norm": 0.26752129197120667,
      "learning_rate": 4.0728940006216975e-06,
      "loss": 0.1465,
      "step": 15254
    },
    {
      "epoch": 1.1854989120298414,
      "grad_norm": 0.4673258364200592,
      "learning_rate": 4.072505439850793e-06,
      "loss": 0.3324,
      "step": 15255
    },
    {
      "epoch": 1.1855766241840224,
      "grad_norm": 0.2784477174282074,
      "learning_rate": 4.072116879079888e-06,
      "loss": 0.0599,
      "step": 15256
    },
    {
      "epoch": 1.1856543363382033,
      "grad_norm": 0.48935845494270325,
      "learning_rate": 4.071728318308984e-06,
      "loss": 0.2112,
      "step": 15257
    },
    {
      "epoch": 1.1857320484923841,
      "grad_norm": 0.8476612567901611,
      "learning_rate": 4.071339757538079e-06,
      "loss": 0.2692,
      "step": 15258
    },
    {
      "epoch": 1.1858097606465652,
      "grad_norm": 1.4400209188461304,
      "learning_rate": 4.070951196767175e-06,
      "loss": 0.4464,
      "step": 15259
    },
    {
      "epoch": 1.185887472800746,
      "grad_norm": 0.657244086265564,
      "learning_rate": 4.0705626359962705e-06,
      "loss": 0.2538,
      "step": 15260
    },
    {
      "epoch": 1.1859651849549269,
      "grad_norm": 0.35928016901016235,
      "learning_rate": 4.0701740752253655e-06,
      "loss": 0.145,
      "step": 15261
    },
    {
      "epoch": 1.186042897109108,
      "grad_norm": 0.8068590760231018,
      "learning_rate": 4.069785514454461e-06,
      "loss": 0.5071,
      "step": 15262
    },
    {
      "epoch": 1.1861206092632888,
      "grad_norm": 0.6012719869613647,
      "learning_rate": 4.069396953683556e-06,
      "loss": 0.3249,
      "step": 15263
    },
    {
      "epoch": 1.1861983214174696,
      "grad_norm": 0.5281944274902344,
      "learning_rate": 4.069008392912652e-06,
      "loss": 0.2037,
      "step": 15264
    },
    {
      "epoch": 1.1862760335716507,
      "grad_norm": 0.5013775825500488,
      "learning_rate": 4.068619832141748e-06,
      "loss": 0.0968,
      "step": 15265
    },
    {
      "epoch": 1.1863537457258315,
      "grad_norm": 0.8323705196380615,
      "learning_rate": 4.068231271370843e-06,
      "loss": 0.4991,
      "step": 15266
    },
    {
      "epoch": 1.1864314578800124,
      "grad_norm": 0.3565564453601837,
      "learning_rate": 4.067842710599938e-06,
      "loss": 0.1043,
      "step": 15267
    },
    {
      "epoch": 1.1865091700341934,
      "grad_norm": 0.37916433811187744,
      "learning_rate": 4.0674541498290335e-06,
      "loss": 0.1332,
      "step": 15268
    },
    {
      "epoch": 1.1865868821883743,
      "grad_norm": 0.47310832142829895,
      "learning_rate": 4.067065589058129e-06,
      "loss": 0.1771,
      "step": 15269
    },
    {
      "epoch": 1.1866645943425551,
      "grad_norm": 0.2478654682636261,
      "learning_rate": 4.066677028287224e-06,
      "loss": 0.0298,
      "step": 15270
    },
    {
      "epoch": 1.1867423064967362,
      "grad_norm": 0.8430528044700623,
      "learning_rate": 4.06628846751632e-06,
      "loss": 0.3317,
      "step": 15271
    },
    {
      "epoch": 1.186820018650917,
      "grad_norm": 0.5536684989929199,
      "learning_rate": 4.065899906745415e-06,
      "loss": 0.4585,
      "step": 15272
    },
    {
      "epoch": 1.1868977308050979,
      "grad_norm": 0.18431074917316437,
      "learning_rate": 4.065511345974511e-06,
      "loss": 0.0756,
      "step": 15273
    },
    {
      "epoch": 1.186975442959279,
      "grad_norm": 0.10768705606460571,
      "learning_rate": 4.065122785203607e-06,
      "loss": 0.0186,
      "step": 15274
    },
    {
      "epoch": 1.1870531551134598,
      "grad_norm": 0.5488924384117126,
      "learning_rate": 4.0647342244327016e-06,
      "loss": 0.4779,
      "step": 15275
    },
    {
      "epoch": 1.1871308672676406,
      "grad_norm": 0.6389384865760803,
      "learning_rate": 4.064345663661797e-06,
      "loss": 0.1644,
      "step": 15276
    },
    {
      "epoch": 1.1872085794218217,
      "grad_norm": 0.5169821977615356,
      "learning_rate": 4.063957102890892e-06,
      "loss": 0.1688,
      "step": 15277
    },
    {
      "epoch": 1.1872862915760025,
      "grad_norm": 0.49573394656181335,
      "learning_rate": 4.063568542119988e-06,
      "loss": 0.1839,
      "step": 15278
    },
    {
      "epoch": 1.1873640037301834,
      "grad_norm": 0.4302048683166504,
      "learning_rate": 4.063179981349084e-06,
      "loss": 0.2926,
      "step": 15279
    },
    {
      "epoch": 1.1874417158843644,
      "grad_norm": 0.294526606798172,
      "learning_rate": 4.062791420578179e-06,
      "loss": 0.1153,
      "step": 15280
    },
    {
      "epoch": 1.1875194280385453,
      "grad_norm": 0.30128559470176697,
      "learning_rate": 4.062402859807274e-06,
      "loss": 0.1346,
      "step": 15281
    },
    {
      "epoch": 1.187597140192726,
      "grad_norm": 0.41996365785598755,
      "learning_rate": 4.06201429903637e-06,
      "loss": 0.0623,
      "step": 15282
    },
    {
      "epoch": 1.1876748523469072,
      "grad_norm": 0.46691665053367615,
      "learning_rate": 4.061625738265465e-06,
      "loss": 0.0446,
      "step": 15283
    },
    {
      "epoch": 1.187752564501088,
      "grad_norm": 0.6361358761787415,
      "learning_rate": 4.06123717749456e-06,
      "loss": 0.3218,
      "step": 15284
    },
    {
      "epoch": 1.1878302766552689,
      "grad_norm": 0.3232211768627167,
      "learning_rate": 4.060848616723656e-06,
      "loss": 0.1359,
      "step": 15285
    },
    {
      "epoch": 1.18790798880945,
      "grad_norm": 0.173557847738266,
      "learning_rate": 4.060460055952751e-06,
      "loss": 0.071,
      "step": 15286
    },
    {
      "epoch": 1.1879857009636308,
      "grad_norm": 0.3338983654975891,
      "learning_rate": 4.060071495181847e-06,
      "loss": 0.1157,
      "step": 15287
    },
    {
      "epoch": 1.1880634131178116,
      "grad_norm": 0.26841971278190613,
      "learning_rate": 4.059682934410943e-06,
      "loss": 0.3111,
      "step": 15288
    },
    {
      "epoch": 1.1881411252719924,
      "grad_norm": 0.5579404234886169,
      "learning_rate": 4.059294373640038e-06,
      "loss": 0.1448,
      "step": 15289
    },
    {
      "epoch": 1.1882188374261735,
      "grad_norm": 1.4797170162200928,
      "learning_rate": 4.0589058128691334e-06,
      "loss": 0.4462,
      "step": 15290
    },
    {
      "epoch": 1.1882965495803544,
      "grad_norm": 0.3956933617591858,
      "learning_rate": 4.058517252098228e-06,
      "loss": 0.4853,
      "step": 15291
    },
    {
      "epoch": 1.1883742617345352,
      "grad_norm": 1.0693142414093018,
      "learning_rate": 4.058128691327324e-06,
      "loss": 0.1192,
      "step": 15292
    },
    {
      "epoch": 1.1884519738887163,
      "grad_norm": 0.48841241002082825,
      "learning_rate": 4.05774013055642e-06,
      "loss": 0.2577,
      "step": 15293
    },
    {
      "epoch": 1.188529686042897,
      "grad_norm": 0.2944389283657074,
      "learning_rate": 4.057351569785515e-06,
      "loss": 0.0715,
      "step": 15294
    },
    {
      "epoch": 1.188607398197078,
      "grad_norm": 0.30844733119010925,
      "learning_rate": 4.05696300901461e-06,
      "loss": 0.0752,
      "step": 15295
    },
    {
      "epoch": 1.188685110351259,
      "grad_norm": 0.3683309257030487,
      "learning_rate": 4.056574448243706e-06,
      "loss": 0.1906,
      "step": 15296
    },
    {
      "epoch": 1.1887628225054399,
      "grad_norm": 0.274072527885437,
      "learning_rate": 4.0561858874728015e-06,
      "loss": 0.0854,
      "step": 15297
    },
    {
      "epoch": 1.1888405346596207,
      "grad_norm": 0.25062552094459534,
      "learning_rate": 4.055797326701896e-06,
      "loss": 0.028,
      "step": 15298
    },
    {
      "epoch": 1.1889182468138018,
      "grad_norm": 0.46813881397247314,
      "learning_rate": 4.055408765930992e-06,
      "loss": 0.5861,
      "step": 15299
    },
    {
      "epoch": 1.1889959589679826,
      "grad_norm": 0.3020152747631073,
      "learning_rate": 4.055020205160087e-06,
      "loss": 0.0485,
      "step": 15300
    },
    {
      "epoch": 1.1890736711221634,
      "grad_norm": 0.6176602244377136,
      "learning_rate": 4.054631644389183e-06,
      "loss": 0.2676,
      "step": 15301
    },
    {
      "epoch": 1.1891513832763445,
      "grad_norm": 0.17168085277080536,
      "learning_rate": 4.054243083618279e-06,
      "loss": 0.0858,
      "step": 15302
    },
    {
      "epoch": 1.1892290954305254,
      "grad_norm": 0.5181800723075867,
      "learning_rate": 4.053854522847374e-06,
      "loss": 0.2821,
      "step": 15303
    },
    {
      "epoch": 1.1893068075847062,
      "grad_norm": 0.4963994026184082,
      "learning_rate": 4.0534659620764695e-06,
      "loss": 0.164,
      "step": 15304
    },
    {
      "epoch": 1.1893845197388873,
      "grad_norm": 0.5140269994735718,
      "learning_rate": 4.0530774013055645e-06,
      "loss": 0.1272,
      "step": 15305
    },
    {
      "epoch": 1.189462231893068,
      "grad_norm": 0.9996728301048279,
      "learning_rate": 4.052688840534659e-06,
      "loss": 0.3155,
      "step": 15306
    },
    {
      "epoch": 1.189539944047249,
      "grad_norm": 0.19014695286750793,
      "learning_rate": 4.052300279763755e-06,
      "loss": 0.0082,
      "step": 15307
    },
    {
      "epoch": 1.1896176562014298,
      "grad_norm": 0.11224506795406342,
      "learning_rate": 4.051911718992851e-06,
      "loss": 0.0416,
      "step": 15308
    },
    {
      "epoch": 1.1896953683556108,
      "grad_norm": 0.24575446546077728,
      "learning_rate": 4.051523158221946e-06,
      "loss": 0.0969,
      "step": 15309
    },
    {
      "epoch": 1.1897730805097917,
      "grad_norm": 0.4577600657939911,
      "learning_rate": 4.051134597451042e-06,
      "loss": 0.1849,
      "step": 15310
    },
    {
      "epoch": 1.1898507926639725,
      "grad_norm": 0.3453545868396759,
      "learning_rate": 4.050746036680137e-06,
      "loss": 0.0713,
      "step": 15311
    },
    {
      "epoch": 1.1899285048181536,
      "grad_norm": 0.7991993427276611,
      "learning_rate": 4.0503574759092325e-06,
      "loss": 0.1623,
      "step": 15312
    },
    {
      "epoch": 1.1900062169723344,
      "grad_norm": 0.2686355710029602,
      "learning_rate": 4.049968915138328e-06,
      "loss": 0.078,
      "step": 15313
    },
    {
      "epoch": 1.1900839291265153,
      "grad_norm": 0.7971792221069336,
      "learning_rate": 4.049580354367423e-06,
      "loss": 0.6324,
      "step": 15314
    },
    {
      "epoch": 1.1901616412806963,
      "grad_norm": 0.5454800724983215,
      "learning_rate": 4.049191793596518e-06,
      "loss": 0.3726,
      "step": 15315
    },
    {
      "epoch": 1.1902393534348772,
      "grad_norm": 1.414709448814392,
      "learning_rate": 4.048803232825614e-06,
      "loss": 0.4742,
      "step": 15316
    },
    {
      "epoch": 1.190317065589058,
      "grad_norm": 0.8295570611953735,
      "learning_rate": 4.04841467205471e-06,
      "loss": 0.2303,
      "step": 15317
    },
    {
      "epoch": 1.190394777743239,
      "grad_norm": 0.9265949130058289,
      "learning_rate": 4.048026111283805e-06,
      "loss": 0.2901,
      "step": 15318
    },
    {
      "epoch": 1.19047248989742,
      "grad_norm": 0.3468259572982788,
      "learning_rate": 4.0476375505129005e-06,
      "loss": 0.1188,
      "step": 15319
    },
    {
      "epoch": 1.1905502020516008,
      "grad_norm": 0.23682843148708344,
      "learning_rate": 4.0472489897419955e-06,
      "loss": 0.1139,
      "step": 15320
    },
    {
      "epoch": 1.1906279142057818,
      "grad_norm": 0.507625937461853,
      "learning_rate": 4.046860428971091e-06,
      "loss": 0.1396,
      "step": 15321
    },
    {
      "epoch": 1.1907056263599627,
      "grad_norm": 1.078874111175537,
      "learning_rate": 4.046471868200187e-06,
      "loss": 0.1695,
      "step": 15322
    },
    {
      "epoch": 1.1907833385141435,
      "grad_norm": 0.8927115201950073,
      "learning_rate": 4.046083307429282e-06,
      "loss": 0.111,
      "step": 15323
    },
    {
      "epoch": 1.1908610506683246,
      "grad_norm": 0.33790305256843567,
      "learning_rate": 4.045694746658378e-06,
      "loss": 0.1715,
      "step": 15324
    },
    {
      "epoch": 1.1909387628225054,
      "grad_norm": 0.48587867617607117,
      "learning_rate": 4.045306185887473e-06,
      "loss": 0.147,
      "step": 15325
    },
    {
      "epoch": 1.1910164749766863,
      "grad_norm": 0.693213701248169,
      "learning_rate": 4.0449176251165686e-06,
      "loss": 0.1318,
      "step": 15326
    },
    {
      "epoch": 1.1910941871308673,
      "grad_norm": 0.9780478477478027,
      "learning_rate": 4.044529064345664e-06,
      "loss": 0.9321,
      "step": 15327
    },
    {
      "epoch": 1.1911718992850482,
      "grad_norm": 0.5539417862892151,
      "learning_rate": 4.044140503574759e-06,
      "loss": 0.2863,
      "step": 15328
    },
    {
      "epoch": 1.191249611439229,
      "grad_norm": 0.07630766928195953,
      "learning_rate": 4.043751942803854e-06,
      "loss": 0.0091,
      "step": 15329
    },
    {
      "epoch": 1.19132732359341,
      "grad_norm": 0.22460326552391052,
      "learning_rate": 4.04336338203295e-06,
      "loss": 0.027,
      "step": 15330
    },
    {
      "epoch": 1.191405035747591,
      "grad_norm": 0.3588338792324066,
      "learning_rate": 4.042974821262046e-06,
      "loss": 0.0963,
      "step": 15331
    },
    {
      "epoch": 1.1914827479017718,
      "grad_norm": 0.437513142824173,
      "learning_rate": 4.042586260491141e-06,
      "loss": 0.1069,
      "step": 15332
    },
    {
      "epoch": 1.1915604600559528,
      "grad_norm": 0.34393829107284546,
      "learning_rate": 4.042197699720237e-06,
      "loss": 0.1178,
      "step": 15333
    },
    {
      "epoch": 1.1916381722101337,
      "grad_norm": 0.7324525117874146,
      "learning_rate": 4.0418091389493316e-06,
      "loss": 0.2069,
      "step": 15334
    },
    {
      "epoch": 1.1917158843643145,
      "grad_norm": 0.4471127986907959,
      "learning_rate": 4.041420578178427e-06,
      "loss": 0.0934,
      "step": 15335
    },
    {
      "epoch": 1.1917935965184956,
      "grad_norm": 0.5112124085426331,
      "learning_rate": 4.041032017407523e-06,
      "loss": 0.2043,
      "step": 15336
    },
    {
      "epoch": 1.1918713086726764,
      "grad_norm": 0.4876426160335541,
      "learning_rate": 4.040643456636618e-06,
      "loss": 0.2726,
      "step": 15337
    },
    {
      "epoch": 1.1919490208268573,
      "grad_norm": 0.7309205532073975,
      "learning_rate": 4.040254895865714e-06,
      "loss": 0.1196,
      "step": 15338
    },
    {
      "epoch": 1.1920267329810383,
      "grad_norm": 0.5176889300346375,
      "learning_rate": 4.039866335094809e-06,
      "loss": 0.2349,
      "step": 15339
    },
    {
      "epoch": 1.1921044451352192,
      "grad_norm": 0.21555839478969574,
      "learning_rate": 4.039477774323905e-06,
      "loss": 0.1301,
      "step": 15340
    },
    {
      "epoch": 1.1921821572894,
      "grad_norm": 0.7185712456703186,
      "learning_rate": 4.0390892135530004e-06,
      "loss": 0.1866,
      "step": 15341
    },
    {
      "epoch": 1.192259869443581,
      "grad_norm": 1.01741623878479,
      "learning_rate": 4.038700652782095e-06,
      "loss": 0.0746,
      "step": 15342
    },
    {
      "epoch": 1.192337581597762,
      "grad_norm": 0.9956904053688049,
      "learning_rate": 4.03831209201119e-06,
      "loss": 0.1069,
      "step": 15343
    },
    {
      "epoch": 1.1924152937519428,
      "grad_norm": 0.35734960436820984,
      "learning_rate": 4.037923531240286e-06,
      "loss": 0.1159,
      "step": 15344
    },
    {
      "epoch": 1.1924930059061238,
      "grad_norm": 0.5092688202857971,
      "learning_rate": 4.037534970469382e-06,
      "loss": 0.1102,
      "step": 15345
    },
    {
      "epoch": 1.1925707180603047,
      "grad_norm": 0.23818336427211761,
      "learning_rate": 4.037146409698477e-06,
      "loss": 0.0259,
      "step": 15346
    },
    {
      "epoch": 1.1926484302144855,
      "grad_norm": 0.05588263273239136,
      "learning_rate": 4.036757848927573e-06,
      "loss": 0.0202,
      "step": 15347
    },
    {
      "epoch": 1.1927261423686664,
      "grad_norm": 0.9301668405532837,
      "learning_rate": 4.036369288156668e-06,
      "loss": 0.1982,
      "step": 15348
    },
    {
      "epoch": 1.1928038545228474,
      "grad_norm": 0.3768557608127594,
      "learning_rate": 4.0359807273857634e-06,
      "loss": 0.1721,
      "step": 15349
    },
    {
      "epoch": 1.1928815666770283,
      "grad_norm": 0.2158837765455246,
      "learning_rate": 4.035592166614859e-06,
      "loss": 0.0238,
      "step": 15350
    },
    {
      "epoch": 1.1929592788312091,
      "grad_norm": 0.3884497880935669,
      "learning_rate": 4.035203605843954e-06,
      "loss": 0.3847,
      "step": 15351
    },
    {
      "epoch": 1.1930369909853902,
      "grad_norm": 0.7484920024871826,
      "learning_rate": 4.03481504507305e-06,
      "loss": 0.6017,
      "step": 15352
    },
    {
      "epoch": 1.193114703139571,
      "grad_norm": 0.23122680187225342,
      "learning_rate": 4.034426484302145e-06,
      "loss": 0.1063,
      "step": 15353
    },
    {
      "epoch": 1.1931924152937519,
      "grad_norm": 0.9584426879882812,
      "learning_rate": 4.034037923531241e-06,
      "loss": 0.5374,
      "step": 15354
    },
    {
      "epoch": 1.193270127447933,
      "grad_norm": 0.4006153643131256,
      "learning_rate": 4.0336493627603365e-06,
      "loss": 0.1917,
      "step": 15355
    },
    {
      "epoch": 1.1933478396021138,
      "grad_norm": 0.6932468414306641,
      "learning_rate": 4.0332608019894315e-06,
      "loss": 0.4163,
      "step": 15356
    },
    {
      "epoch": 1.1934255517562946,
      "grad_norm": 0.5505080223083496,
      "learning_rate": 4.032872241218526e-06,
      "loss": 0.3328,
      "step": 15357
    },
    {
      "epoch": 1.1935032639104757,
      "grad_norm": 0.06868712604045868,
      "learning_rate": 4.032483680447622e-06,
      "loss": 0.0084,
      "step": 15358
    },
    {
      "epoch": 1.1935809760646565,
      "grad_norm": 0.2867089807987213,
      "learning_rate": 4.032095119676718e-06,
      "loss": 0.1646,
      "step": 15359
    },
    {
      "epoch": 1.1936586882188374,
      "grad_norm": 0.3605180084705353,
      "learning_rate": 4.031706558905813e-06,
      "loss": 0.0883,
      "step": 15360
    },
    {
      "epoch": 1.1937364003730184,
      "grad_norm": 0.3919277489185333,
      "learning_rate": 4.031317998134909e-06,
      "loss": 0.1836,
      "step": 15361
    },
    {
      "epoch": 1.1938141125271993,
      "grad_norm": 0.5918527841567993,
      "learning_rate": 4.030929437364004e-06,
      "loss": 0.3712,
      "step": 15362
    },
    {
      "epoch": 1.19389182468138,
      "grad_norm": 0.21763117611408234,
      "learning_rate": 4.0305408765930995e-06,
      "loss": 0.0608,
      "step": 15363
    },
    {
      "epoch": 1.1939695368355612,
      "grad_norm": 0.4216312766075134,
      "learning_rate": 4.030152315822195e-06,
      "loss": 0.2444,
      "step": 15364
    },
    {
      "epoch": 1.194047248989742,
      "grad_norm": 0.2692924737930298,
      "learning_rate": 4.02976375505129e-06,
      "loss": 0.0407,
      "step": 15365
    },
    {
      "epoch": 1.1941249611439229,
      "grad_norm": 0.49832895398139954,
      "learning_rate": 4.029375194280386e-06,
      "loss": 0.2707,
      "step": 15366
    },
    {
      "epoch": 1.1942026732981037,
      "grad_norm": 0.7540770769119263,
      "learning_rate": 4.028986633509481e-06,
      "loss": 0.3334,
      "step": 15367
    },
    {
      "epoch": 1.1942803854522848,
      "grad_norm": 0.2698450982570648,
      "learning_rate": 4.028598072738577e-06,
      "loss": 0.0714,
      "step": 15368
    },
    {
      "epoch": 1.1943580976064656,
      "grad_norm": 1.3208922147750854,
      "learning_rate": 4.028209511967673e-06,
      "loss": 0.4337,
      "step": 15369
    },
    {
      "epoch": 1.1944358097606464,
      "grad_norm": 0.2716102600097656,
      "learning_rate": 4.0278209511967675e-06,
      "loss": 0.0374,
      "step": 15370
    },
    {
      "epoch": 1.1945135219148275,
      "grad_norm": 0.25687551498413086,
      "learning_rate": 4.0274323904258625e-06,
      "loss": 0.0521,
      "step": 15371
    },
    {
      "epoch": 1.1945912340690084,
      "grad_norm": 0.09031618386507034,
      "learning_rate": 4.027043829654958e-06,
      "loss": 0.0285,
      "step": 15372
    },
    {
      "epoch": 1.1946689462231892,
      "grad_norm": 0.496441125869751,
      "learning_rate": 4.026655268884054e-06,
      "loss": 0.1977,
      "step": 15373
    },
    {
      "epoch": 1.1947466583773703,
      "grad_norm": 0.7026538252830505,
      "learning_rate": 4.026266708113149e-06,
      "loss": 0.3305,
      "step": 15374
    },
    {
      "epoch": 1.194824370531551,
      "grad_norm": 0.2133023589849472,
      "learning_rate": 4.025878147342245e-06,
      "loss": 0.0365,
      "step": 15375
    },
    {
      "epoch": 1.194902082685732,
      "grad_norm": 0.5607560276985168,
      "learning_rate": 4.02548958657134e-06,
      "loss": 0.181,
      "step": 15376
    },
    {
      "epoch": 1.194979794839913,
      "grad_norm": 0.751519501209259,
      "learning_rate": 4.0251010258004356e-06,
      "loss": 0.1343,
      "step": 15377
    },
    {
      "epoch": 1.1950575069940939,
      "grad_norm": 0.40782007575035095,
      "learning_rate": 4.024712465029531e-06,
      "loss": 1.0267,
      "step": 15378
    },
    {
      "epoch": 1.1951352191482747,
      "grad_norm": 0.2236180305480957,
      "learning_rate": 4.024323904258626e-06,
      "loss": 0.0768,
      "step": 15379
    },
    {
      "epoch": 1.1952129313024558,
      "grad_norm": 0.5577514171600342,
      "learning_rate": 4.023935343487722e-06,
      "loss": 0.1172,
      "step": 15380
    },
    {
      "epoch": 1.1952906434566366,
      "grad_norm": 0.6080499291419983,
      "learning_rate": 4.023546782716817e-06,
      "loss": 0.3712,
      "step": 15381
    },
    {
      "epoch": 1.1953683556108174,
      "grad_norm": 0.10350459069013596,
      "learning_rate": 4.023158221945913e-06,
      "loss": 0.0297,
      "step": 15382
    },
    {
      "epoch": 1.1954460677649985,
      "grad_norm": 0.07810129970312119,
      "learning_rate": 4.022769661175009e-06,
      "loss": 0.0063,
      "step": 15383
    },
    {
      "epoch": 1.1955237799191794,
      "grad_norm": 0.9708000421524048,
      "learning_rate": 4.022381100404104e-06,
      "loss": 0.1179,
      "step": 15384
    },
    {
      "epoch": 1.1956014920733602,
      "grad_norm": 0.5631545782089233,
      "learning_rate": 4.0219925396331986e-06,
      "loss": 0.262,
      "step": 15385
    },
    {
      "epoch": 1.1956792042275413,
      "grad_norm": 0.48101571202278137,
      "learning_rate": 4.021603978862294e-06,
      "loss": 0.0588,
      "step": 15386
    },
    {
      "epoch": 1.195756916381722,
      "grad_norm": 0.856828510761261,
      "learning_rate": 4.02121541809139e-06,
      "loss": 0.1855,
      "step": 15387
    },
    {
      "epoch": 1.195834628535903,
      "grad_norm": 0.3395783603191376,
      "learning_rate": 4.020826857320485e-06,
      "loss": 0.1296,
      "step": 15388
    },
    {
      "epoch": 1.195912340690084,
      "grad_norm": 0.8788698315620422,
      "learning_rate": 4.020438296549581e-06,
      "loss": 0.5514,
      "step": 15389
    },
    {
      "epoch": 1.1959900528442649,
      "grad_norm": 0.4251445233821869,
      "learning_rate": 4.020049735778676e-06,
      "loss": 0.1595,
      "step": 15390
    },
    {
      "epoch": 1.1960677649984457,
      "grad_norm": 0.6015011072158813,
      "learning_rate": 4.019661175007772e-06,
      "loss": 0.5084,
      "step": 15391
    },
    {
      "epoch": 1.1961454771526268,
      "grad_norm": 0.3825460970401764,
      "learning_rate": 4.0192726142368674e-06,
      "loss": 0.3362,
      "step": 15392
    },
    {
      "epoch": 1.1962231893068076,
      "grad_norm": 0.31441062688827515,
      "learning_rate": 4.018884053465962e-06,
      "loss": 0.1376,
      "step": 15393
    },
    {
      "epoch": 1.1963009014609884,
      "grad_norm": 0.8794305920600891,
      "learning_rate": 4.018495492695057e-06,
      "loss": 0.3449,
      "step": 15394
    },
    {
      "epoch": 1.1963786136151695,
      "grad_norm": 0.15459831058979034,
      "learning_rate": 4.018106931924153e-06,
      "loss": 0.0213,
      "step": 15395
    },
    {
      "epoch": 1.1964563257693503,
      "grad_norm": 0.3327866792678833,
      "learning_rate": 4.017718371153249e-06,
      "loss": 0.1037,
      "step": 15396
    },
    {
      "epoch": 1.1965340379235312,
      "grad_norm": 0.3124627470970154,
      "learning_rate": 4.017329810382345e-06,
      "loss": 0.0678,
      "step": 15397
    },
    {
      "epoch": 1.1966117500777123,
      "grad_norm": 0.7364677786827087,
      "learning_rate": 4.01694124961144e-06,
      "loss": 0.2115,
      "step": 15398
    },
    {
      "epoch": 1.196689462231893,
      "grad_norm": 0.6900484561920166,
      "learning_rate": 4.016552688840535e-06,
      "loss": 0.1045,
      "step": 15399
    },
    {
      "epoch": 1.196767174386074,
      "grad_norm": 0.4753526449203491,
      "learning_rate": 4.0161641280696304e-06,
      "loss": 0.237,
      "step": 15400
    },
    {
      "epoch": 1.196844886540255,
      "grad_norm": 0.4081639051437378,
      "learning_rate": 4.015775567298726e-06,
      "loss": 0.1216,
      "step": 15401
    },
    {
      "epoch": 1.1969225986944358,
      "grad_norm": 0.2824627161026001,
      "learning_rate": 4.015387006527821e-06,
      "loss": 0.0854,
      "step": 15402
    },
    {
      "epoch": 1.1970003108486167,
      "grad_norm": 0.21436448395252228,
      "learning_rate": 4.014998445756917e-06,
      "loss": 0.0737,
      "step": 15403
    },
    {
      "epoch": 1.1970780230027978,
      "grad_norm": 0.968904435634613,
      "learning_rate": 4.014609884986012e-06,
      "loss": 0.3371,
      "step": 15404
    },
    {
      "epoch": 1.1971557351569786,
      "grad_norm": 0.63005530834198,
      "learning_rate": 4.014221324215108e-06,
      "loss": 0.2777,
      "step": 15405
    },
    {
      "epoch": 1.1972334473111594,
      "grad_norm": 0.9837981462478638,
      "learning_rate": 4.0138327634442035e-06,
      "loss": 0.1184,
      "step": 15406
    },
    {
      "epoch": 1.1973111594653405,
      "grad_norm": 0.6658442616462708,
      "learning_rate": 4.0134442026732985e-06,
      "loss": 0.4515,
      "step": 15407
    },
    {
      "epoch": 1.1973888716195213,
      "grad_norm": 0.6979955434799194,
      "learning_rate": 4.013055641902393e-06,
      "loss": 0.1525,
      "step": 15408
    },
    {
      "epoch": 1.1974665837737022,
      "grad_norm": 0.27198126912117004,
      "learning_rate": 4.012667081131489e-06,
      "loss": 0.0988,
      "step": 15409
    },
    {
      "epoch": 1.197544295927883,
      "grad_norm": 0.45710331201553345,
      "learning_rate": 4.012278520360585e-06,
      "loss": 0.0762,
      "step": 15410
    },
    {
      "epoch": 1.197622008082064,
      "grad_norm": 0.46670642495155334,
      "learning_rate": 4.011889959589681e-06,
      "loss": 0.2864,
      "step": 15411
    },
    {
      "epoch": 1.197699720236245,
      "grad_norm": 0.1382635533809662,
      "learning_rate": 4.011501398818776e-06,
      "loss": 0.0394,
      "step": 15412
    },
    {
      "epoch": 1.1977774323904258,
      "grad_norm": 0.298118531703949,
      "learning_rate": 4.011112838047871e-06,
      "loss": 0.0618,
      "step": 15413
    },
    {
      "epoch": 1.1978551445446068,
      "grad_norm": 0.49971482157707214,
      "learning_rate": 4.0107242772769665e-06,
      "loss": 0.2203,
      "step": 15414
    },
    {
      "epoch": 1.1979328566987877,
      "grad_norm": 0.10394808650016785,
      "learning_rate": 4.010335716506062e-06,
      "loss": 0.0346,
      "step": 15415
    },
    {
      "epoch": 1.1980105688529685,
      "grad_norm": 0.7617865800857544,
      "learning_rate": 4.009947155735157e-06,
      "loss": 0.2833,
      "step": 15416
    },
    {
      "epoch": 1.1980882810071496,
      "grad_norm": 0.7012377381324768,
      "learning_rate": 4.009558594964253e-06,
      "loss": 0.7746,
      "step": 15417
    },
    {
      "epoch": 1.1981659931613304,
      "grad_norm": 0.24358536303043365,
      "learning_rate": 4.009170034193348e-06,
      "loss": 0.0721,
      "step": 15418
    },
    {
      "epoch": 1.1982437053155113,
      "grad_norm": 1.7457398176193237,
      "learning_rate": 4.008781473422444e-06,
      "loss": 0.153,
      "step": 15419
    },
    {
      "epoch": 1.1983214174696923,
      "grad_norm": 0.4780683219432831,
      "learning_rate": 4.00839291265154e-06,
      "loss": 0.1488,
      "step": 15420
    },
    {
      "epoch": 1.1983991296238732,
      "grad_norm": 0.48265954852104187,
      "learning_rate": 4.0080043518806345e-06,
      "loss": 0.2579,
      "step": 15421
    },
    {
      "epoch": 1.198476841778054,
      "grad_norm": 0.24825377762317657,
      "learning_rate": 4.0076157911097295e-06,
      "loss": 0.1261,
      "step": 15422
    },
    {
      "epoch": 1.198554553932235,
      "grad_norm": 0.20273949205875397,
      "learning_rate": 4.007227230338825e-06,
      "loss": 0.0306,
      "step": 15423
    },
    {
      "epoch": 1.198632266086416,
      "grad_norm": 0.7655230760574341,
      "learning_rate": 4.006838669567921e-06,
      "loss": 0.1999,
      "step": 15424
    },
    {
      "epoch": 1.1987099782405968,
      "grad_norm": 0.7387967109680176,
      "learning_rate": 4.006450108797017e-06,
      "loss": 0.3268,
      "step": 15425
    },
    {
      "epoch": 1.1987876903947778,
      "grad_norm": 0.45757320523262024,
      "learning_rate": 4.006061548026112e-06,
      "loss": 0.1627,
      "step": 15426
    },
    {
      "epoch": 1.1988654025489587,
      "grad_norm": 0.45530956983566284,
      "learning_rate": 4.005672987255207e-06,
      "loss": 0.1651,
      "step": 15427
    },
    {
      "epoch": 1.1989431147031395,
      "grad_norm": 0.06758125126361847,
      "learning_rate": 4.0052844264843026e-06,
      "loss": 0.0263,
      "step": 15428
    },
    {
      "epoch": 1.1990208268573204,
      "grad_norm": 0.8322378396987915,
      "learning_rate": 4.0048958657133975e-06,
      "loss": 0.1589,
      "step": 15429
    },
    {
      "epoch": 1.1990985390115014,
      "grad_norm": 0.49691739678382874,
      "learning_rate": 4.004507304942493e-06,
      "loss": 0.0192,
      "step": 15430
    },
    {
      "epoch": 1.1991762511656823,
      "grad_norm": 0.18673835694789886,
      "learning_rate": 4.004118744171589e-06,
      "loss": 0.0221,
      "step": 15431
    },
    {
      "epoch": 1.1992539633198631,
      "grad_norm": 0.2287014275789261,
      "learning_rate": 4.003730183400684e-06,
      "loss": 0.0325,
      "step": 15432
    },
    {
      "epoch": 1.1993316754740442,
      "grad_norm": 0.1712416708469391,
      "learning_rate": 4.003341622629779e-06,
      "loss": 0.135,
      "step": 15433
    },
    {
      "epoch": 1.199409387628225,
      "grad_norm": 0.23783887922763824,
      "learning_rate": 4.002953061858875e-06,
      "loss": 0.0666,
      "step": 15434
    },
    {
      "epoch": 1.1994870997824059,
      "grad_norm": 0.46388375759124756,
      "learning_rate": 4.002564501087971e-06,
      "loss": 0.2314,
      "step": 15435
    },
    {
      "epoch": 1.199564811936587,
      "grad_norm": 0.4829009175300598,
      "learning_rate": 4.0021759403170656e-06,
      "loss": 0.1457,
      "step": 15436
    },
    {
      "epoch": 1.1996425240907678,
      "grad_norm": 0.4047752618789673,
      "learning_rate": 4.001787379546161e-06,
      "loss": 0.04,
      "step": 15437
    },
    {
      "epoch": 1.1997202362449486,
      "grad_norm": 0.2524286210536957,
      "learning_rate": 4.001398818775256e-06,
      "loss": 0.0378,
      "step": 15438
    },
    {
      "epoch": 1.1997979483991297,
      "grad_norm": 0.6077106595039368,
      "learning_rate": 4.001010258004352e-06,
      "loss": 0.1038,
      "step": 15439
    },
    {
      "epoch": 1.1998756605533105,
      "grad_norm": 0.36215680837631226,
      "learning_rate": 4.000621697233448e-06,
      "loss": 0.0734,
      "step": 15440
    },
    {
      "epoch": 1.1999533727074914,
      "grad_norm": 0.6586071252822876,
      "learning_rate": 4.000233136462543e-06,
      "loss": 0.062,
      "step": 15441
    },
    {
      "epoch": 1.2000310848616724,
      "grad_norm": 1.0640658140182495,
      "learning_rate": 3.999844575691639e-06,
      "loss": 0.4224,
      "step": 15442
    },
    {
      "epoch": 1.2001087970158533,
      "grad_norm": 0.33940452337265015,
      "learning_rate": 3.999456014920734e-06,
      "loss": 0.0682,
      "step": 15443
    },
    {
      "epoch": 1.200186509170034,
      "grad_norm": 0.21382398903369904,
      "learning_rate": 3.999067454149829e-06,
      "loss": 0.0294,
      "step": 15444
    },
    {
      "epoch": 1.2002642213242152,
      "grad_norm": 0.7001895308494568,
      "learning_rate": 3.998678893378925e-06,
      "loss": 0.331,
      "step": 15445
    },
    {
      "epoch": 1.200341933478396,
      "grad_norm": 0.24655573070049286,
      "learning_rate": 3.99829033260802e-06,
      "loss": 0.093,
      "step": 15446
    },
    {
      "epoch": 1.2004196456325769,
      "grad_norm": 0.15537284314632416,
      "learning_rate": 3.997901771837115e-06,
      "loss": 0.0192,
      "step": 15447
    },
    {
      "epoch": 1.200497357786758,
      "grad_norm": 0.07127704471349716,
      "learning_rate": 3.997513211066211e-06,
      "loss": 0.0298,
      "step": 15448
    },
    {
      "epoch": 1.2005750699409388,
      "grad_norm": 0.3078003525733948,
      "learning_rate": 3.997124650295307e-06,
      "loss": 0.1223,
      "step": 15449
    },
    {
      "epoch": 1.2006527820951196,
      "grad_norm": 0.12910422682762146,
      "learning_rate": 3.996736089524402e-06,
      "loss": 0.029,
      "step": 15450
    },
    {
      "epoch": 1.2007304942493007,
      "grad_norm": 0.31899839639663696,
      "learning_rate": 3.9963475287534974e-06,
      "loss": 0.1195,
      "step": 15451
    },
    {
      "epoch": 1.2008082064034815,
      "grad_norm": 0.29139596223831177,
      "learning_rate": 3.995958967982592e-06,
      "loss": 0.1033,
      "step": 15452
    },
    {
      "epoch": 1.2008859185576624,
      "grad_norm": 0.34892895817756653,
      "learning_rate": 3.995570407211688e-06,
      "loss": 0.1182,
      "step": 15453
    },
    {
      "epoch": 1.2009636307118434,
      "grad_norm": 0.5117130279541016,
      "learning_rate": 3.995181846440784e-06,
      "loss": 0.2216,
      "step": 15454
    },
    {
      "epoch": 1.2010413428660243,
      "grad_norm": 0.3834827244281769,
      "learning_rate": 3.994793285669879e-06,
      "loss": 0.2024,
      "step": 15455
    },
    {
      "epoch": 1.201119055020205,
      "grad_norm": 0.3781527578830719,
      "learning_rate": 3.994404724898975e-06,
      "loss": 0.0853,
      "step": 15456
    },
    {
      "epoch": 1.2011967671743862,
      "grad_norm": 0.5022979378700256,
      "learning_rate": 3.99401616412807e-06,
      "loss": 0.252,
      "step": 15457
    },
    {
      "epoch": 1.201274479328567,
      "grad_norm": 0.1237390786409378,
      "learning_rate": 3.9936276033571655e-06,
      "loss": 0.0279,
      "step": 15458
    },
    {
      "epoch": 1.2013521914827479,
      "grad_norm": 1.57762610912323,
      "learning_rate": 3.993239042586261e-06,
      "loss": 0.4153,
      "step": 15459
    },
    {
      "epoch": 1.201429903636929,
      "grad_norm": 0.3868861794471741,
      "learning_rate": 3.992850481815356e-06,
      "loss": 0.1909,
      "step": 15460
    },
    {
      "epoch": 1.2015076157911098,
      "grad_norm": 0.44140323996543884,
      "learning_rate": 3.992461921044451e-06,
      "loss": 0.2702,
      "step": 15461
    },
    {
      "epoch": 1.2015853279452906,
      "grad_norm": 0.46829548478126526,
      "learning_rate": 3.992073360273547e-06,
      "loss": 0.1037,
      "step": 15462
    },
    {
      "epoch": 1.2016630400994717,
      "grad_norm": 0.2052105814218521,
      "learning_rate": 3.991684799502643e-06,
      "loss": 0.0345,
      "step": 15463
    },
    {
      "epoch": 1.2017407522536525,
      "grad_norm": 0.2592150568962097,
      "learning_rate": 3.991296238731738e-06,
      "loss": 0.0532,
      "step": 15464
    },
    {
      "epoch": 1.2018184644078334,
      "grad_norm": 0.12028485536575317,
      "learning_rate": 3.9909076779608335e-06,
      "loss": 0.0368,
      "step": 15465
    },
    {
      "epoch": 1.2018961765620144,
      "grad_norm": 1.1296205520629883,
      "learning_rate": 3.9905191171899285e-06,
      "loss": 0.3297,
      "step": 15466
    },
    {
      "epoch": 1.2019738887161953,
      "grad_norm": 0.5884513854980469,
      "learning_rate": 3.990130556419024e-06,
      "loss": 0.238,
      "step": 15467
    },
    {
      "epoch": 1.202051600870376,
      "grad_norm": 0.585193395614624,
      "learning_rate": 3.98974199564812e-06,
      "loss": 0.2255,
      "step": 15468
    },
    {
      "epoch": 1.202129313024557,
      "grad_norm": 0.3581946790218353,
      "learning_rate": 3.989353434877215e-06,
      "loss": 0.1155,
      "step": 15469
    },
    {
      "epoch": 1.202207025178738,
      "grad_norm": 0.10486967861652374,
      "learning_rate": 3.98896487410631e-06,
      "loss": 0.0162,
      "step": 15470
    },
    {
      "epoch": 1.2022847373329189,
      "grad_norm": 0.41049957275390625,
      "learning_rate": 3.988576313335406e-06,
      "loss": 0.1367,
      "step": 15471
    },
    {
      "epoch": 1.2023624494870997,
      "grad_norm": 0.15927062928676605,
      "learning_rate": 3.9881877525645015e-06,
      "loss": 0.0724,
      "step": 15472
    },
    {
      "epoch": 1.2024401616412808,
      "grad_norm": 0.10989201068878174,
      "learning_rate": 3.987799191793597e-06,
      "loss": 0.0992,
      "step": 15473
    },
    {
      "epoch": 1.2025178737954616,
      "grad_norm": 0.7676632404327393,
      "learning_rate": 3.987410631022692e-06,
      "loss": 0.2956,
      "step": 15474
    },
    {
      "epoch": 1.2025955859496424,
      "grad_norm": 0.2729944586753845,
      "learning_rate": 3.987022070251787e-06,
      "loss": 0.0876,
      "step": 15475
    },
    {
      "epoch": 1.2026732981038235,
      "grad_norm": 0.8087897300720215,
      "learning_rate": 3.986633509480883e-06,
      "loss": 0.774,
      "step": 15476
    },
    {
      "epoch": 1.2027510102580043,
      "grad_norm": 0.35242366790771484,
      "learning_rate": 3.986244948709979e-06,
      "loss": 0.0523,
      "step": 15477
    },
    {
      "epoch": 1.2028287224121852,
      "grad_norm": 0.19395963847637177,
      "learning_rate": 3.985856387939074e-06,
      "loss": 0.034,
      "step": 15478
    },
    {
      "epoch": 1.2029064345663663,
      "grad_norm": 0.5449482798576355,
      "learning_rate": 3.9854678271681696e-06,
      "loss": 0.1161,
      "step": 15479
    },
    {
      "epoch": 1.202984146720547,
      "grad_norm": 0.9478517770767212,
      "learning_rate": 3.9850792663972645e-06,
      "loss": 0.3015,
      "step": 15480
    },
    {
      "epoch": 1.203061858874728,
      "grad_norm": 0.2149970531463623,
      "learning_rate": 3.98469070562636e-06,
      "loss": 0.075,
      "step": 15481
    },
    {
      "epoch": 1.203139571028909,
      "grad_norm": 0.869404137134552,
      "learning_rate": 3.984302144855456e-06,
      "loss": 0.4253,
      "step": 15482
    },
    {
      "epoch": 1.2032172831830898,
      "grad_norm": 0.17914330959320068,
      "learning_rate": 3.983913584084551e-06,
      "loss": 0.0376,
      "step": 15483
    },
    {
      "epoch": 1.2032949953372707,
      "grad_norm": 0.4607178866863251,
      "learning_rate": 3.983525023313646e-06,
      "loss": 0.1963,
      "step": 15484
    },
    {
      "epoch": 1.2033727074914518,
      "grad_norm": 0.8139925003051758,
      "learning_rate": 3.983136462542742e-06,
      "loss": 0.4107,
      "step": 15485
    },
    {
      "epoch": 1.2034504196456326,
      "grad_norm": 0.3290027976036072,
      "learning_rate": 3.982747901771838e-06,
      "loss": 0.0666,
      "step": 15486
    },
    {
      "epoch": 1.2035281317998134,
      "grad_norm": 0.4806402623653412,
      "learning_rate": 3.982359341000933e-06,
      "loss": 0.1272,
      "step": 15487
    },
    {
      "epoch": 1.2036058439539943,
      "grad_norm": 0.4439074397087097,
      "learning_rate": 3.981970780230028e-06,
      "loss": 0.7182,
      "step": 15488
    },
    {
      "epoch": 1.2036835561081753,
      "grad_norm": 0.5944570302963257,
      "learning_rate": 3.981582219459123e-06,
      "loss": 0.372,
      "step": 15489
    },
    {
      "epoch": 1.2037612682623562,
      "grad_norm": 0.1535124033689499,
      "learning_rate": 3.981193658688219e-06,
      "loss": 0.077,
      "step": 15490
    },
    {
      "epoch": 1.203838980416537,
      "grad_norm": 0.08323941379785538,
      "learning_rate": 3.980805097917315e-06,
      "loss": 0.0787,
      "step": 15491
    },
    {
      "epoch": 1.203916692570718,
      "grad_norm": 0.6485003232955933,
      "learning_rate": 3.98041653714641e-06,
      "loss": 0.2182,
      "step": 15492
    },
    {
      "epoch": 1.203994404724899,
      "grad_norm": 0.17412927746772766,
      "learning_rate": 3.980027976375506e-06,
      "loss": 0.0558,
      "step": 15493
    },
    {
      "epoch": 1.2040721168790798,
      "grad_norm": 0.48537662625312805,
      "learning_rate": 3.979639415604601e-06,
      "loss": 0.1382,
      "step": 15494
    },
    {
      "epoch": 1.2041498290332608,
      "grad_norm": 0.41950517892837524,
      "learning_rate": 3.979250854833696e-06,
      "loss": 0.4893,
      "step": 15495
    },
    {
      "epoch": 1.2042275411874417,
      "grad_norm": 0.37037453055381775,
      "learning_rate": 3.978862294062792e-06,
      "loss": 0.169,
      "step": 15496
    },
    {
      "epoch": 1.2043052533416225,
      "grad_norm": 1.1400954723358154,
      "learning_rate": 3.978473733291887e-06,
      "loss": 0.2358,
      "step": 15497
    },
    {
      "epoch": 1.2043829654958036,
      "grad_norm": 0.5401731729507446,
      "learning_rate": 3.978085172520982e-06,
      "loss": 0.5382,
      "step": 15498
    },
    {
      "epoch": 1.2044606776499844,
      "grad_norm": 0.7078084945678711,
      "learning_rate": 3.977696611750078e-06,
      "loss": 0.116,
      "step": 15499
    },
    {
      "epoch": 1.2045383898041653,
      "grad_norm": 0.42129790782928467,
      "learning_rate": 3.977308050979174e-06,
      "loss": 0.199,
      "step": 15500
    },
    {
      "epoch": 1.2046161019583463,
      "grad_norm": 0.3833361864089966,
      "learning_rate": 3.9769194902082695e-06,
      "loss": 0.2258,
      "step": 15501
    },
    {
      "epoch": 1.2046938141125272,
      "grad_norm": 0.5541876554489136,
      "learning_rate": 3.9765309294373644e-06,
      "loss": 0.0676,
      "step": 15502
    },
    {
      "epoch": 1.204771526266708,
      "grad_norm": 0.6331759095191956,
      "learning_rate": 3.976142368666459e-06,
      "loss": 0.337,
      "step": 15503
    },
    {
      "epoch": 1.204849238420889,
      "grad_norm": 0.3095334470272064,
      "learning_rate": 3.975753807895555e-06,
      "loss": 0.1079,
      "step": 15504
    },
    {
      "epoch": 1.20492695057507,
      "grad_norm": 1.070590615272522,
      "learning_rate": 3.975365247124651e-06,
      "loss": 0.1478,
      "step": 15505
    },
    {
      "epoch": 1.2050046627292508,
      "grad_norm": 0.42743703722953796,
      "learning_rate": 3.974976686353746e-06,
      "loss": 0.1807,
      "step": 15506
    },
    {
      "epoch": 1.2050823748834318,
      "grad_norm": 0.4061044752597809,
      "learning_rate": 3.974588125582842e-06,
      "loss": 0.1264,
      "step": 15507
    },
    {
      "epoch": 1.2051600870376127,
      "grad_norm": 0.41440415382385254,
      "learning_rate": 3.974199564811937e-06,
      "loss": 0.1289,
      "step": 15508
    },
    {
      "epoch": 1.2052377991917935,
      "grad_norm": 0.9384752511978149,
      "learning_rate": 3.9738110040410325e-06,
      "loss": 0.3945,
      "step": 15509
    },
    {
      "epoch": 1.2053155113459746,
      "grad_norm": 0.6414946913719177,
      "learning_rate": 3.973422443270128e-06,
      "loss": 0.1311,
      "step": 15510
    },
    {
      "epoch": 1.2053932235001554,
      "grad_norm": 0.29537391662597656,
      "learning_rate": 3.973033882499223e-06,
      "loss": 0.0714,
      "step": 15511
    },
    {
      "epoch": 1.2054709356543363,
      "grad_norm": 0.3702705502510071,
      "learning_rate": 3.972645321728318e-06,
      "loss": 0.1702,
      "step": 15512
    },
    {
      "epoch": 1.2055486478085173,
      "grad_norm": 0.2808232307434082,
      "learning_rate": 3.972256760957414e-06,
      "loss": 0.0582,
      "step": 15513
    },
    {
      "epoch": 1.2056263599626982,
      "grad_norm": 0.617084801197052,
      "learning_rate": 3.97186820018651e-06,
      "loss": 0.1382,
      "step": 15514
    },
    {
      "epoch": 1.205704072116879,
      "grad_norm": 0.28515341877937317,
      "learning_rate": 3.971479639415605e-06,
      "loss": 0.0439,
      "step": 15515
    },
    {
      "epoch": 1.20578178427106,
      "grad_norm": 0.5422236919403076,
      "learning_rate": 3.9710910786447005e-06,
      "loss": 0.1231,
      "step": 15516
    },
    {
      "epoch": 1.205859496425241,
      "grad_norm": 0.6329231262207031,
      "learning_rate": 3.9707025178737955e-06,
      "loss": 0.1074,
      "step": 15517
    },
    {
      "epoch": 1.2059372085794218,
      "grad_norm": 0.4228529632091522,
      "learning_rate": 3.970313957102891e-06,
      "loss": 0.2458,
      "step": 15518
    },
    {
      "epoch": 1.2060149207336028,
      "grad_norm": 0.4990273714065552,
      "learning_rate": 3.969925396331987e-06,
      "loss": 0.0869,
      "step": 15519
    },
    {
      "epoch": 1.2060926328877837,
      "grad_norm": 0.525364339351654,
      "learning_rate": 3.969536835561082e-06,
      "loss": 0.1896,
      "step": 15520
    },
    {
      "epoch": 1.2061703450419645,
      "grad_norm": 0.8335362076759338,
      "learning_rate": 3.969148274790178e-06,
      "loss": 0.2111,
      "step": 15521
    },
    {
      "epoch": 1.2062480571961456,
      "grad_norm": 0.49628525972366333,
      "learning_rate": 3.968759714019273e-06,
      "loss": 0.1069,
      "step": 15522
    },
    {
      "epoch": 1.2063257693503264,
      "grad_norm": 0.5666581392288208,
      "learning_rate": 3.9683711532483685e-06,
      "loss": 0.328,
      "step": 15523
    },
    {
      "epoch": 1.2064034815045073,
      "grad_norm": 0.682404637336731,
      "learning_rate": 3.967982592477464e-06,
      "loss": 0.3908,
      "step": 15524
    },
    {
      "epoch": 1.2064811936586883,
      "grad_norm": 0.23379012942314148,
      "learning_rate": 3.967594031706559e-06,
      "loss": 0.101,
      "step": 15525
    },
    {
      "epoch": 1.2065589058128692,
      "grad_norm": 0.05514812469482422,
      "learning_rate": 3.967205470935654e-06,
      "loss": 0.0057,
      "step": 15526
    },
    {
      "epoch": 1.20663661796705,
      "grad_norm": 0.23736728727817535,
      "learning_rate": 3.96681691016475e-06,
      "loss": 0.0748,
      "step": 15527
    },
    {
      "epoch": 1.206714330121231,
      "grad_norm": 0.4662713408470154,
      "learning_rate": 3.966428349393846e-06,
      "loss": 0.2616,
      "step": 15528
    },
    {
      "epoch": 1.206792042275412,
      "grad_norm": 0.5615962743759155,
      "learning_rate": 3.966039788622941e-06,
      "loss": 0.3101,
      "step": 15529
    },
    {
      "epoch": 1.2068697544295928,
      "grad_norm": 0.42189496755599976,
      "learning_rate": 3.965651227852037e-06,
      "loss": 0.5422,
      "step": 15530
    },
    {
      "epoch": 1.2069474665837736,
      "grad_norm": 1.7449196577072144,
      "learning_rate": 3.9652626670811315e-06,
      "loss": 0.4343,
      "step": 15531
    },
    {
      "epoch": 1.2070251787379547,
      "grad_norm": 0.302377849817276,
      "learning_rate": 3.964874106310227e-06,
      "loss": 0.1135,
      "step": 15532
    },
    {
      "epoch": 1.2071028908921355,
      "grad_norm": 0.44982200860977173,
      "learning_rate": 3.964485545539323e-06,
      "loss": 0.1351,
      "step": 15533
    },
    {
      "epoch": 1.2071806030463164,
      "grad_norm": 0.5928593277931213,
      "learning_rate": 3.964096984768418e-06,
      "loss": 0.2099,
      "step": 15534
    },
    {
      "epoch": 1.2072583152004974,
      "grad_norm": 0.38359320163726807,
      "learning_rate": 3.963708423997514e-06,
      "loss": 0.1128,
      "step": 15535
    },
    {
      "epoch": 1.2073360273546783,
      "grad_norm": 0.32453685998916626,
      "learning_rate": 3.963319863226609e-06,
      "loss": 0.0818,
      "step": 15536
    },
    {
      "epoch": 1.207413739508859,
      "grad_norm": 0.13668183982372284,
      "learning_rate": 3.962931302455705e-06,
      "loss": 0.0252,
      "step": 15537
    },
    {
      "epoch": 1.2074914516630402,
      "grad_norm": 0.29853934049606323,
      "learning_rate": 3.9625427416848e-06,
      "loss": 0.08,
      "step": 15538
    },
    {
      "epoch": 1.207569163817221,
      "grad_norm": 0.4996308386325836,
      "learning_rate": 3.962154180913895e-06,
      "loss": 0.2206,
      "step": 15539
    },
    {
      "epoch": 1.2076468759714019,
      "grad_norm": 0.24540987610816956,
      "learning_rate": 3.96176562014299e-06,
      "loss": 0.0381,
      "step": 15540
    },
    {
      "epoch": 1.207724588125583,
      "grad_norm": 0.5587760210037231,
      "learning_rate": 3.961377059372086e-06,
      "loss": 0.0673,
      "step": 15541
    },
    {
      "epoch": 1.2078023002797638,
      "grad_norm": 0.345937043428421,
      "learning_rate": 3.960988498601182e-06,
      "loss": 0.0808,
      "step": 15542
    },
    {
      "epoch": 1.2078800124339446,
      "grad_norm": 0.29010850191116333,
      "learning_rate": 3.960599937830277e-06,
      "loss": 0.1497,
      "step": 15543
    },
    {
      "epoch": 1.2079577245881257,
      "grad_norm": 0.4744690954685211,
      "learning_rate": 3.960211377059373e-06,
      "loss": 0.1432,
      "step": 15544
    },
    {
      "epoch": 1.2080354367423065,
      "grad_norm": 4.333370685577393,
      "learning_rate": 3.959822816288468e-06,
      "loss": 0.0769,
      "step": 15545
    },
    {
      "epoch": 1.2081131488964874,
      "grad_norm": 0.27836093306541443,
      "learning_rate": 3.959434255517563e-06,
      "loss": 0.0298,
      "step": 15546
    },
    {
      "epoch": 1.2081908610506684,
      "grad_norm": 0.5268571376800537,
      "learning_rate": 3.959045694746659e-06,
      "loss": 0.3123,
      "step": 15547
    },
    {
      "epoch": 1.2082685732048493,
      "grad_norm": 0.30228662490844727,
      "learning_rate": 3.958657133975754e-06,
      "loss": 0.1233,
      "step": 15548
    },
    {
      "epoch": 1.20834628535903,
      "grad_norm": 0.38708460330963135,
      "learning_rate": 3.95826857320485e-06,
      "loss": 0.4646,
      "step": 15549
    },
    {
      "epoch": 1.208423997513211,
      "grad_norm": 0.3906022906303406,
      "learning_rate": 3.957880012433945e-06,
      "loss": 0.0641,
      "step": 15550
    },
    {
      "epoch": 1.208501709667392,
      "grad_norm": 0.13015395402908325,
      "learning_rate": 3.957491451663041e-06,
      "loss": 0.0346,
      "step": 15551
    },
    {
      "epoch": 1.2085794218215729,
      "grad_norm": 0.3807310163974762,
      "learning_rate": 3.9571028908921365e-06,
      "loss": 0.0964,
      "step": 15552
    },
    {
      "epoch": 1.2086571339757537,
      "grad_norm": 0.2693914771080017,
      "learning_rate": 3.9567143301212314e-06,
      "loss": 0.1041,
      "step": 15553
    },
    {
      "epoch": 1.2087348461299348,
      "grad_norm": 0.8899129033088684,
      "learning_rate": 3.956325769350326e-06,
      "loss": 0.3187,
      "step": 15554
    },
    {
      "epoch": 1.2088125582841156,
      "grad_norm": 0.9476833939552307,
      "learning_rate": 3.955937208579422e-06,
      "loss": 0.3655,
      "step": 15555
    },
    {
      "epoch": 1.2088902704382964,
      "grad_norm": 0.742928683757782,
      "learning_rate": 3.955548647808517e-06,
      "loss": 0.1095,
      "step": 15556
    },
    {
      "epoch": 1.2089679825924775,
      "grad_norm": 0.6596347689628601,
      "learning_rate": 3.955160087037613e-06,
      "loss": 0.1883,
      "step": 15557
    },
    {
      "epoch": 1.2090456947466584,
      "grad_norm": 0.18521271646022797,
      "learning_rate": 3.954771526266709e-06,
      "loss": 0.0487,
      "step": 15558
    },
    {
      "epoch": 1.2091234069008392,
      "grad_norm": 0.04430845379829407,
      "learning_rate": 3.954382965495804e-06,
      "loss": 0.0042,
      "step": 15559
    },
    {
      "epoch": 1.2092011190550203,
      "grad_norm": 0.11576300114393234,
      "learning_rate": 3.953994404724899e-06,
      "loss": 0.0137,
      "step": 15560
    },
    {
      "epoch": 1.209278831209201,
      "grad_norm": 0.828496515750885,
      "learning_rate": 3.953605843953994e-06,
      "loss": 0.5899,
      "step": 15561
    },
    {
      "epoch": 1.209356543363382,
      "grad_norm": 0.12293444573879242,
      "learning_rate": 3.95321728318309e-06,
      "loss": 0.0478,
      "step": 15562
    },
    {
      "epoch": 1.209434255517563,
      "grad_norm": 0.5368307828903198,
      "learning_rate": 3.952828722412186e-06,
      "loss": 0.2363,
      "step": 15563
    },
    {
      "epoch": 1.2095119676717438,
      "grad_norm": 0.5465265512466431,
      "learning_rate": 3.952440161641281e-06,
      "loss": 0.0992,
      "step": 15564
    },
    {
      "epoch": 1.2095896798259247,
      "grad_norm": 0.4809301793575287,
      "learning_rate": 3.952051600870376e-06,
      "loss": 0.1237,
      "step": 15565
    },
    {
      "epoch": 1.2096673919801058,
      "grad_norm": 0.306084007024765,
      "learning_rate": 3.951663040099472e-06,
      "loss": 0.149,
      "step": 15566
    },
    {
      "epoch": 1.2097451041342866,
      "grad_norm": 0.699124276638031,
      "learning_rate": 3.9512744793285675e-06,
      "loss": 0.2122,
      "step": 15567
    },
    {
      "epoch": 1.2098228162884674,
      "grad_norm": 0.17573580145835876,
      "learning_rate": 3.9508859185576625e-06,
      "loss": 0.0616,
      "step": 15568
    },
    {
      "epoch": 1.2099005284426485,
      "grad_norm": 0.5509025454521179,
      "learning_rate": 3.950497357786758e-06,
      "loss": 0.1211,
      "step": 15569
    },
    {
      "epoch": 1.2099782405968293,
      "grad_norm": 0.16289366781711578,
      "learning_rate": 3.950108797015853e-06,
      "loss": 0.0837,
      "step": 15570
    },
    {
      "epoch": 1.2100559527510102,
      "grad_norm": 0.32976722717285156,
      "learning_rate": 3.949720236244949e-06,
      "loss": 0.0388,
      "step": 15571
    },
    {
      "epoch": 1.2101336649051913,
      "grad_norm": 0.4087204337120056,
      "learning_rate": 3.949331675474045e-06,
      "loss": 0.3178,
      "step": 15572
    },
    {
      "epoch": 1.210211377059372,
      "grad_norm": 0.9644507765769958,
      "learning_rate": 3.94894311470314e-06,
      "loss": 0.8314,
      "step": 15573
    },
    {
      "epoch": 1.210289089213553,
      "grad_norm": 0.6433035135269165,
      "learning_rate": 3.948554553932235e-06,
      "loss": 0.1905,
      "step": 15574
    },
    {
      "epoch": 1.210366801367734,
      "grad_norm": 0.9318330883979797,
      "learning_rate": 3.9481659931613305e-06,
      "loss": 0.3215,
      "step": 15575
    },
    {
      "epoch": 1.2104445135219148,
      "grad_norm": 0.6785303354263306,
      "learning_rate": 3.947777432390426e-06,
      "loss": 0.3934,
      "step": 15576
    },
    {
      "epoch": 1.2105222256760957,
      "grad_norm": 0.6860145330429077,
      "learning_rate": 3.947388871619522e-06,
      "loss": 0.2939,
      "step": 15577
    },
    {
      "epoch": 1.2105999378302768,
      "grad_norm": 0.19658514857292175,
      "learning_rate": 3.947000310848617e-06,
      "loss": 0.0587,
      "step": 15578
    },
    {
      "epoch": 1.2106776499844576,
      "grad_norm": 0.5290129780769348,
      "learning_rate": 3.946611750077712e-06,
      "loss": 0.1682,
      "step": 15579
    },
    {
      "epoch": 1.2107553621386384,
      "grad_norm": 0.48422184586524963,
      "learning_rate": 3.946223189306808e-06,
      "loss": 0.1715,
      "step": 15580
    },
    {
      "epoch": 1.2108330742928195,
      "grad_norm": 0.459548681974411,
      "learning_rate": 3.945834628535904e-06,
      "loss": 0.121,
      "step": 15581
    },
    {
      "epoch": 1.2109107864470003,
      "grad_norm": 0.426082044839859,
      "learning_rate": 3.9454460677649985e-06,
      "loss": 0.3375,
      "step": 15582
    },
    {
      "epoch": 1.2109884986011812,
      "grad_norm": 0.2760432958602905,
      "learning_rate": 3.945057506994094e-06,
      "loss": 0.0198,
      "step": 15583
    },
    {
      "epoch": 1.2110662107553622,
      "grad_norm": 0.4962771534919739,
      "learning_rate": 3.944668946223189e-06,
      "loss": 0.2221,
      "step": 15584
    },
    {
      "epoch": 1.211143922909543,
      "grad_norm": 0.3926956355571747,
      "learning_rate": 3.944280385452285e-06,
      "loss": 0.3193,
      "step": 15585
    },
    {
      "epoch": 1.211221635063724,
      "grad_norm": 0.09233269840478897,
      "learning_rate": 3.943891824681381e-06,
      "loss": 0.0255,
      "step": 15586
    },
    {
      "epoch": 1.211299347217905,
      "grad_norm": 0.2630707621574402,
      "learning_rate": 3.943503263910476e-06,
      "loss": 0.0754,
      "step": 15587
    },
    {
      "epoch": 1.2113770593720858,
      "grad_norm": 0.4359305799007416,
      "learning_rate": 3.943114703139571e-06,
      "loss": 0.1779,
      "step": 15588
    },
    {
      "epoch": 1.2114547715262667,
      "grad_norm": 0.25803929567337036,
      "learning_rate": 3.9427261423686666e-06,
      "loss": 0.0789,
      "step": 15589
    },
    {
      "epoch": 1.2115324836804475,
      "grad_norm": 0.6539172530174255,
      "learning_rate": 3.942337581597762e-06,
      "loss": 0.163,
      "step": 15590
    },
    {
      "epoch": 1.2116101958346286,
      "grad_norm": 0.04242648929357529,
      "learning_rate": 3.941949020826857e-06,
      "loss": 0.0029,
      "step": 15591
    },
    {
      "epoch": 1.2116879079888094,
      "grad_norm": 0.11502836644649506,
      "learning_rate": 3.941560460055953e-06,
      "loss": 0.0432,
      "step": 15592
    },
    {
      "epoch": 1.2117656201429903,
      "grad_norm": 0.4214290380477905,
      "learning_rate": 3.941171899285048e-06,
      "loss": 0.2738,
      "step": 15593
    },
    {
      "epoch": 1.2118433322971713,
      "grad_norm": 0.8774753212928772,
      "learning_rate": 3.940783338514144e-06,
      "loss": 0.347,
      "step": 15594
    },
    {
      "epoch": 1.2119210444513522,
      "grad_norm": 0.1339980512857437,
      "learning_rate": 3.94039477774324e-06,
      "loss": 0.0245,
      "step": 15595
    },
    {
      "epoch": 1.211998756605533,
      "grad_norm": 0.23397187888622284,
      "learning_rate": 3.940006216972335e-06,
      "loss": 0.0419,
      "step": 15596
    },
    {
      "epoch": 1.212076468759714,
      "grad_norm": 0.18034186959266663,
      "learning_rate": 3.93961765620143e-06,
      "loss": 0.0646,
      "step": 15597
    },
    {
      "epoch": 1.212154180913895,
      "grad_norm": 0.1716562956571579,
      "learning_rate": 3.939229095430525e-06,
      "loss": 0.0393,
      "step": 15598
    },
    {
      "epoch": 1.2122318930680758,
      "grad_norm": 0.4887497127056122,
      "learning_rate": 3.938840534659621e-06,
      "loss": 0.0672,
      "step": 15599
    },
    {
      "epoch": 1.2123096052222568,
      "grad_norm": 0.6941525936126709,
      "learning_rate": 3.938451973888717e-06,
      "loss": 0.2673,
      "step": 15600
    },
    {
      "epoch": 1.2123873173764377,
      "grad_norm": 0.04578474164009094,
      "learning_rate": 3.938063413117812e-06,
      "loss": 0.0029,
      "step": 15601
    },
    {
      "epoch": 1.2124650295306185,
      "grad_norm": 0.2284533679485321,
      "learning_rate": 3.937674852346907e-06,
      "loss": 0.1129,
      "step": 15602
    },
    {
      "epoch": 1.2125427416847996,
      "grad_norm": 0.6335222721099854,
      "learning_rate": 3.937286291576003e-06,
      "loss": 0.1351,
      "step": 15603
    },
    {
      "epoch": 1.2126204538389804,
      "grad_norm": 0.3676038086414337,
      "learning_rate": 3.9368977308050984e-06,
      "loss": 0.0488,
      "step": 15604
    },
    {
      "epoch": 1.2126981659931613,
      "grad_norm": 0.5029661655426025,
      "learning_rate": 3.936509170034193e-06,
      "loss": 0.0939,
      "step": 15605
    },
    {
      "epoch": 1.2127758781473423,
      "grad_norm": 0.5222945809364319,
      "learning_rate": 3.936120609263289e-06,
      "loss": 0.2834,
      "step": 15606
    },
    {
      "epoch": 1.2128535903015232,
      "grad_norm": 1.9940125942230225,
      "learning_rate": 3.935732048492384e-06,
      "loss": 0.2503,
      "step": 15607
    },
    {
      "epoch": 1.212931302455704,
      "grad_norm": 0.14921726286411285,
      "learning_rate": 3.93534348772148e-06,
      "loss": 0.0677,
      "step": 15608
    },
    {
      "epoch": 1.2130090146098849,
      "grad_norm": 0.06512429565191269,
      "learning_rate": 3.934954926950576e-06,
      "loss": 0.0084,
      "step": 15609
    },
    {
      "epoch": 1.213086726764066,
      "grad_norm": 0.7483561038970947,
      "learning_rate": 3.934566366179671e-06,
      "loss": 0.3606,
      "step": 15610
    },
    {
      "epoch": 1.2131644389182468,
      "grad_norm": 0.38709452748298645,
      "learning_rate": 3.9341778054087665e-06,
      "loss": 0.1701,
      "step": 15611
    },
    {
      "epoch": 1.2132421510724276,
      "grad_norm": 1.2967400550842285,
      "learning_rate": 3.933789244637861e-06,
      "loss": 0.8297,
      "step": 15612
    },
    {
      "epoch": 1.2133198632266087,
      "grad_norm": 0.26347815990448,
      "learning_rate": 3.933400683866957e-06,
      "loss": 0.0618,
      "step": 15613
    },
    {
      "epoch": 1.2133975753807895,
      "grad_norm": 0.4636583626270294,
      "learning_rate": 3.933012123096053e-06,
      "loss": 0.2056,
      "step": 15614
    },
    {
      "epoch": 1.2134752875349704,
      "grad_norm": 0.6987247467041016,
      "learning_rate": 3.932623562325148e-06,
      "loss": 0.2442,
      "step": 15615
    },
    {
      "epoch": 1.2135529996891514,
      "grad_norm": 0.5069754123687744,
      "learning_rate": 3.932235001554243e-06,
      "loss": 0.3888,
      "step": 15616
    },
    {
      "epoch": 1.2136307118433323,
      "grad_norm": 0.8659136295318604,
      "learning_rate": 3.931846440783339e-06,
      "loss": 0.3929,
      "step": 15617
    },
    {
      "epoch": 1.213708423997513,
      "grad_norm": 0.6014659404754639,
      "learning_rate": 3.9314578800124345e-06,
      "loss": 0.3551,
      "step": 15618
    },
    {
      "epoch": 1.2137861361516942,
      "grad_norm": 1.0646206140518188,
      "learning_rate": 3.9310693192415295e-06,
      "loss": 0.3805,
      "step": 15619
    },
    {
      "epoch": 1.213863848305875,
      "grad_norm": 0.7265204787254333,
      "learning_rate": 3.930680758470625e-06,
      "loss": 0.5672,
      "step": 15620
    },
    {
      "epoch": 1.2139415604600559,
      "grad_norm": 0.771660566329956,
      "learning_rate": 3.93029219769972e-06,
      "loss": 0.1909,
      "step": 15621
    },
    {
      "epoch": 1.214019272614237,
      "grad_norm": 0.3633866012096405,
      "learning_rate": 3.929903636928816e-06,
      "loss": 0.2427,
      "step": 15622
    },
    {
      "epoch": 1.2140969847684178,
      "grad_norm": 0.7631196975708008,
      "learning_rate": 3.929515076157912e-06,
      "loss": 0.2616,
      "step": 15623
    },
    {
      "epoch": 1.2141746969225986,
      "grad_norm": 0.5698334574699402,
      "learning_rate": 3.929126515387007e-06,
      "loss": 0.2819,
      "step": 15624
    },
    {
      "epoch": 1.2142524090767797,
      "grad_norm": 1.2674976587295532,
      "learning_rate": 3.9287379546161025e-06,
      "loss": 0.4605,
      "step": 15625
    },
    {
      "epoch": 1.2143301212309605,
      "grad_norm": 0.2557046711444855,
      "learning_rate": 3.9283493938451975e-06,
      "loss": 0.0813,
      "step": 15626
    },
    {
      "epoch": 1.2144078333851414,
      "grad_norm": 0.23058602213859558,
      "learning_rate": 3.927960833074293e-06,
      "loss": 0.0492,
      "step": 15627
    },
    {
      "epoch": 1.2144855455393224,
      "grad_norm": 0.8055425882339478,
      "learning_rate": 3.927572272303389e-06,
      "loss": 0.4057,
      "step": 15628
    },
    {
      "epoch": 1.2145632576935033,
      "grad_norm": 0.20199160277843475,
      "learning_rate": 3.927183711532484e-06,
      "loss": 0.0739,
      "step": 15629
    },
    {
      "epoch": 1.214640969847684,
      "grad_norm": 0.3525297939777374,
      "learning_rate": 3.926795150761579e-06,
      "loss": 0.1179,
      "step": 15630
    },
    {
      "epoch": 1.2147186820018652,
      "grad_norm": 0.6701555848121643,
      "learning_rate": 3.926406589990675e-06,
      "loss": 0.2886,
      "step": 15631
    },
    {
      "epoch": 1.214796394156046,
      "grad_norm": 0.5390767455101013,
      "learning_rate": 3.926018029219771e-06,
      "loss": 0.0966,
      "step": 15632
    },
    {
      "epoch": 1.2148741063102269,
      "grad_norm": 0.6130411028862,
      "learning_rate": 3.9256294684488655e-06,
      "loss": 0.1863,
      "step": 15633
    },
    {
      "epoch": 1.214951818464408,
      "grad_norm": 0.7080170512199402,
      "learning_rate": 3.925240907677961e-06,
      "loss": 0.1581,
      "step": 15634
    },
    {
      "epoch": 1.2150295306185888,
      "grad_norm": 0.28707587718963623,
      "learning_rate": 3.924852346907056e-06,
      "loss": 0.0577,
      "step": 15635
    },
    {
      "epoch": 1.2151072427727696,
      "grad_norm": 0.3508106470108032,
      "learning_rate": 3.924463786136152e-06,
      "loss": 0.1165,
      "step": 15636
    },
    {
      "epoch": 1.2151849549269507,
      "grad_norm": 0.5010256171226501,
      "learning_rate": 3.924075225365248e-06,
      "loss": 0.127,
      "step": 15637
    },
    {
      "epoch": 1.2152626670811315,
      "grad_norm": 0.21050840616226196,
      "learning_rate": 3.923686664594343e-06,
      "loss": 0.0365,
      "step": 15638
    },
    {
      "epoch": 1.2153403792353124,
      "grad_norm": 0.5154986381530762,
      "learning_rate": 3.923298103823439e-06,
      "loss": 0.2173,
      "step": 15639
    },
    {
      "epoch": 1.2154180913894934,
      "grad_norm": 0.3834201693534851,
      "learning_rate": 3.9229095430525336e-06,
      "loss": 0.1222,
      "step": 15640
    },
    {
      "epoch": 1.2154958035436743,
      "grad_norm": 0.9552006125450134,
      "learning_rate": 3.922520982281629e-06,
      "loss": 0.4934,
      "step": 15641
    },
    {
      "epoch": 1.215573515697855,
      "grad_norm": 0.8683368563652039,
      "learning_rate": 3.922132421510725e-06,
      "loss": 0.5675,
      "step": 15642
    },
    {
      "epoch": 1.2156512278520362,
      "grad_norm": 0.44672220945358276,
      "learning_rate": 3.92174386073982e-06,
      "loss": 0.1779,
      "step": 15643
    },
    {
      "epoch": 1.215728940006217,
      "grad_norm": 0.7450540661811829,
      "learning_rate": 3.921355299968915e-06,
      "loss": 0.269,
      "step": 15644
    },
    {
      "epoch": 1.2158066521603978,
      "grad_norm": 0.6092286109924316,
      "learning_rate": 3.920966739198011e-06,
      "loss": 0.4979,
      "step": 15645
    },
    {
      "epoch": 1.215884364314579,
      "grad_norm": 0.3592267334461212,
      "learning_rate": 3.920578178427107e-06,
      "loss": 0.034,
      "step": 15646
    },
    {
      "epoch": 1.2159620764687598,
      "grad_norm": 1.012509822845459,
      "learning_rate": 3.920189617656202e-06,
      "loss": 0.249,
      "step": 15647
    },
    {
      "epoch": 1.2160397886229406,
      "grad_norm": 0.5072720050811768,
      "learning_rate": 3.919801056885297e-06,
      "loss": 0.0985,
      "step": 15648
    },
    {
      "epoch": 1.2161175007771217,
      "grad_norm": 0.25740760564804077,
      "learning_rate": 3.919412496114392e-06,
      "loss": 0.047,
      "step": 15649
    },
    {
      "epoch": 1.2161952129313025,
      "grad_norm": 0.9016323089599609,
      "learning_rate": 3.919023935343488e-06,
      "loss": 0.2705,
      "step": 15650
    },
    {
      "epoch": 1.2162729250854833,
      "grad_norm": 0.20860962569713593,
      "learning_rate": 3.918635374572584e-06,
      "loss": 0.1272,
      "step": 15651
    },
    {
      "epoch": 1.2163506372396642,
      "grad_norm": 0.020722681656479836,
      "learning_rate": 3.918246813801679e-06,
      "loss": 0.0105,
      "step": 15652
    },
    {
      "epoch": 1.2164283493938453,
      "grad_norm": 0.9078615307807922,
      "learning_rate": 3.917858253030775e-06,
      "loss": 0.2514,
      "step": 15653
    },
    {
      "epoch": 1.216506061548026,
      "grad_norm": 0.3367946147918701,
      "learning_rate": 3.91746969225987e-06,
      "loss": 0.1855,
      "step": 15654
    },
    {
      "epoch": 1.216583773702207,
      "grad_norm": 0.26155394315719604,
      "learning_rate": 3.9170811314889654e-06,
      "loss": 0.0764,
      "step": 15655
    },
    {
      "epoch": 1.216661485856388,
      "grad_norm": 0.37591552734375,
      "learning_rate": 3.916692570718061e-06,
      "loss": 0.1638,
      "step": 15656
    },
    {
      "epoch": 1.2167391980105688,
      "grad_norm": 0.2930487096309662,
      "learning_rate": 3.916304009947156e-06,
      "loss": 0.092,
      "step": 15657
    },
    {
      "epoch": 1.2168169101647497,
      "grad_norm": 0.1263773888349533,
      "learning_rate": 3.915915449176251e-06,
      "loss": 0.0603,
      "step": 15658
    },
    {
      "epoch": 1.2168946223189308,
      "grad_norm": 0.2999922037124634,
      "learning_rate": 3.915526888405347e-06,
      "loss": 0.0985,
      "step": 15659
    },
    {
      "epoch": 1.2169723344731116,
      "grad_norm": 1.0158318281173706,
      "learning_rate": 3.915138327634443e-06,
      "loss": 0.3637,
      "step": 15660
    },
    {
      "epoch": 1.2170500466272924,
      "grad_norm": 0.670068621635437,
      "learning_rate": 3.914749766863538e-06,
      "loss": 0.2125,
      "step": 15661
    },
    {
      "epoch": 1.2171277587814735,
      "grad_norm": 0.5077812075614929,
      "learning_rate": 3.9143612060926335e-06,
      "loss": 0.22,
      "step": 15662
    },
    {
      "epoch": 1.2172054709356543,
      "grad_norm": 0.35266807675361633,
      "learning_rate": 3.9139726453217284e-06,
      "loss": 0.1083,
      "step": 15663
    },
    {
      "epoch": 1.2172831830898352,
      "grad_norm": 0.5829131603240967,
      "learning_rate": 3.913584084550824e-06,
      "loss": 0.3731,
      "step": 15664
    },
    {
      "epoch": 1.2173608952440163,
      "grad_norm": 0.37220802903175354,
      "learning_rate": 3.91319552377992e-06,
      "loss": 0.0803,
      "step": 15665
    },
    {
      "epoch": 1.217438607398197,
      "grad_norm": 0.3109729588031769,
      "learning_rate": 3.912806963009015e-06,
      "loss": 0.1429,
      "step": 15666
    },
    {
      "epoch": 1.217516319552378,
      "grad_norm": 0.126731276512146,
      "learning_rate": 3.91241840223811e-06,
      "loss": 0.027,
      "step": 15667
    },
    {
      "epoch": 1.217594031706559,
      "grad_norm": 1.1547870635986328,
      "learning_rate": 3.912029841467206e-06,
      "loss": 0.2962,
      "step": 15668
    },
    {
      "epoch": 1.2176717438607398,
      "grad_norm": 0.466263085603714,
      "learning_rate": 3.9116412806963015e-06,
      "loss": 0.1484,
      "step": 15669
    },
    {
      "epoch": 1.2177494560149207,
      "grad_norm": 0.2887120842933655,
      "learning_rate": 3.911252719925397e-06,
      "loss": 0.08,
      "step": 15670
    },
    {
      "epoch": 1.2178271681691015,
      "grad_norm": 0.359991192817688,
      "learning_rate": 3.910864159154492e-06,
      "loss": 0.0198,
      "step": 15671
    },
    {
      "epoch": 1.2179048803232826,
      "grad_norm": 0.2225717306137085,
      "learning_rate": 3.910475598383587e-06,
      "loss": 0.1098,
      "step": 15672
    },
    {
      "epoch": 1.2179825924774634,
      "grad_norm": 0.33536481857299805,
      "learning_rate": 3.910087037612683e-06,
      "loss": 0.0555,
      "step": 15673
    },
    {
      "epoch": 1.2180603046316443,
      "grad_norm": 0.722434401512146,
      "learning_rate": 3.909698476841779e-06,
      "loss": 0.5492,
      "step": 15674
    },
    {
      "epoch": 1.2181380167858253,
      "grad_norm": 0.662712812423706,
      "learning_rate": 3.909309916070874e-06,
      "loss": 0.2703,
      "step": 15675
    },
    {
      "epoch": 1.2182157289400062,
      "grad_norm": 7.576417446136475,
      "learning_rate": 3.9089213552999695e-06,
      "loss": 0.8393,
      "step": 15676
    },
    {
      "epoch": 1.218293441094187,
      "grad_norm": 0.24663449823856354,
      "learning_rate": 3.9085327945290645e-06,
      "loss": 0.1254,
      "step": 15677
    },
    {
      "epoch": 1.218371153248368,
      "grad_norm": 0.4388768672943115,
      "learning_rate": 3.90814423375816e-06,
      "loss": 0.2287,
      "step": 15678
    },
    {
      "epoch": 1.218448865402549,
      "grad_norm": 0.37077948451042175,
      "learning_rate": 3.907755672987255e-06,
      "loss": 0.1638,
      "step": 15679
    },
    {
      "epoch": 1.2185265775567298,
      "grad_norm": 0.4056379497051239,
      "learning_rate": 3.907367112216351e-06,
      "loss": 0.1685,
      "step": 15680
    },
    {
      "epoch": 1.2186042897109108,
      "grad_norm": 0.25173208117485046,
      "learning_rate": 3.906978551445446e-06,
      "loss": 0.0515,
      "step": 15681
    },
    {
      "epoch": 1.2186820018650917,
      "grad_norm": 0.3908117115497589,
      "learning_rate": 3.906589990674542e-06,
      "loss": 0.0759,
      "step": 15682
    },
    {
      "epoch": 1.2187597140192725,
      "grad_norm": 0.46864306926727295,
      "learning_rate": 3.906201429903637e-06,
      "loss": 0.1185,
      "step": 15683
    },
    {
      "epoch": 1.2188374261734536,
      "grad_norm": 0.7525776028633118,
      "learning_rate": 3.9058128691327325e-06,
      "loss": 0.1349,
      "step": 15684
    },
    {
      "epoch": 1.2189151383276344,
      "grad_norm": 0.6371036171913147,
      "learning_rate": 3.905424308361828e-06,
      "loss": 0.1431,
      "step": 15685
    },
    {
      "epoch": 1.2189928504818153,
      "grad_norm": 0.927247941493988,
      "learning_rate": 3.905035747590923e-06,
      "loss": 0.0443,
      "step": 15686
    },
    {
      "epoch": 1.2190705626359963,
      "grad_norm": 0.16426832973957062,
      "learning_rate": 3.904647186820019e-06,
      "loss": 0.0405,
      "step": 15687
    },
    {
      "epoch": 1.2191482747901772,
      "grad_norm": 0.4542284607887268,
      "learning_rate": 3.904258626049114e-06,
      "loss": 0.165,
      "step": 15688
    },
    {
      "epoch": 1.219225986944358,
      "grad_norm": 0.45802587270736694,
      "learning_rate": 3.90387006527821e-06,
      "loss": 0.0799,
      "step": 15689
    },
    {
      "epoch": 1.219303699098539,
      "grad_norm": 0.33879879117012024,
      "learning_rate": 3.903481504507306e-06,
      "loss": 0.0669,
      "step": 15690
    },
    {
      "epoch": 1.21938141125272,
      "grad_norm": 0.12661157548427582,
      "learning_rate": 3.9030929437364006e-06,
      "loss": 0.0475,
      "step": 15691
    },
    {
      "epoch": 1.2194591234069008,
      "grad_norm": 0.6600916981697083,
      "learning_rate": 3.9027043829654955e-06,
      "loss": 0.4148,
      "step": 15692
    },
    {
      "epoch": 1.2195368355610818,
      "grad_norm": 0.4710724949836731,
      "learning_rate": 3.902315822194591e-06,
      "loss": 0.0976,
      "step": 15693
    },
    {
      "epoch": 1.2196145477152627,
      "grad_norm": 0.3845652937889099,
      "learning_rate": 3.901927261423687e-06,
      "loss": 0.2219,
      "step": 15694
    },
    {
      "epoch": 1.2196922598694435,
      "grad_norm": 0.25603625178337097,
      "learning_rate": 3.901538700652782e-06,
      "loss": 0.0379,
      "step": 15695
    },
    {
      "epoch": 1.2197699720236246,
      "grad_norm": 1.5522035360336304,
      "learning_rate": 3.901150139881878e-06,
      "loss": 0.3933,
      "step": 15696
    },
    {
      "epoch": 1.2198476841778054,
      "grad_norm": 0.8042344450950623,
      "learning_rate": 3.900761579110973e-06,
      "loss": 0.1808,
      "step": 15697
    },
    {
      "epoch": 1.2199253963319863,
      "grad_norm": 0.4654190242290497,
      "learning_rate": 3.900373018340069e-06,
      "loss": 0.1246,
      "step": 15698
    },
    {
      "epoch": 1.2200031084861673,
      "grad_norm": 0.8306145668029785,
      "learning_rate": 3.899984457569164e-06,
      "loss": 0.1351,
      "step": 15699
    },
    {
      "epoch": 1.2200808206403482,
      "grad_norm": 0.5246801972389221,
      "learning_rate": 3.899595896798259e-06,
      "loss": 0.0891,
      "step": 15700
    },
    {
      "epoch": 1.220158532794529,
      "grad_norm": 0.3132805824279785,
      "learning_rate": 3.899207336027355e-06,
      "loss": 0.0489,
      "step": 15701
    },
    {
      "epoch": 1.22023624494871,
      "grad_norm": 0.3878307342529297,
      "learning_rate": 3.89881877525645e-06,
      "loss": 0.0967,
      "step": 15702
    },
    {
      "epoch": 1.220313957102891,
      "grad_norm": 0.5541689991950989,
      "learning_rate": 3.898430214485546e-06,
      "loss": 0.1389,
      "step": 15703
    },
    {
      "epoch": 1.2203916692570718,
      "grad_norm": 0.4384942054748535,
      "learning_rate": 3.898041653714642e-06,
      "loss": 0.1228,
      "step": 15704
    },
    {
      "epoch": 1.2204693814112528,
      "grad_norm": 0.7244314551353455,
      "learning_rate": 3.897653092943737e-06,
      "loss": 0.0873,
      "step": 15705
    },
    {
      "epoch": 1.2205470935654337,
      "grad_norm": 0.4683189392089844,
      "learning_rate": 3.897264532172832e-06,
      "loss": 0.3042,
      "step": 15706
    },
    {
      "epoch": 1.2206248057196145,
      "grad_norm": 0.385110467672348,
      "learning_rate": 3.896875971401927e-06,
      "loss": 0.1286,
      "step": 15707
    },
    {
      "epoch": 1.2207025178737956,
      "grad_norm": 0.2321113646030426,
      "learning_rate": 3.896487410631023e-06,
      "loss": 0.0608,
      "step": 15708
    },
    {
      "epoch": 1.2207802300279764,
      "grad_norm": 0.6783148050308228,
      "learning_rate": 3.896098849860118e-06,
      "loss": 0.3507,
      "step": 15709
    },
    {
      "epoch": 1.2208579421821573,
      "grad_norm": 0.5233142971992493,
      "learning_rate": 3.895710289089214e-06,
      "loss": 0.356,
      "step": 15710
    },
    {
      "epoch": 1.2209356543363383,
      "grad_norm": 1.3743019104003906,
      "learning_rate": 3.895321728318309e-06,
      "loss": 0.3416,
      "step": 15711
    },
    {
      "epoch": 1.2210133664905192,
      "grad_norm": 0.4504269063472748,
      "learning_rate": 3.894933167547405e-06,
      "loss": 0.471,
      "step": 15712
    },
    {
      "epoch": 1.2210910786447,
      "grad_norm": 0.849137544631958,
      "learning_rate": 3.8945446067765005e-06,
      "loss": 0.461,
      "step": 15713
    },
    {
      "epoch": 1.2211687907988809,
      "grad_norm": 0.5026596188545227,
      "learning_rate": 3.8941560460055954e-06,
      "loss": 0.1783,
      "step": 15714
    },
    {
      "epoch": 1.221246502953062,
      "grad_norm": 0.6942711472511292,
      "learning_rate": 3.893767485234691e-06,
      "loss": 0.4313,
      "step": 15715
    },
    {
      "epoch": 1.2213242151072428,
      "grad_norm": 0.714762270450592,
      "learning_rate": 3.893378924463786e-06,
      "loss": 0.2123,
      "step": 15716
    },
    {
      "epoch": 1.2214019272614236,
      "grad_norm": 0.30606359243392944,
      "learning_rate": 3.892990363692882e-06,
      "loss": 0.0451,
      "step": 15717
    },
    {
      "epoch": 1.2214796394156047,
      "grad_norm": 0.27836543321609497,
      "learning_rate": 3.892601802921978e-06,
      "loss": 0.073,
      "step": 15718
    },
    {
      "epoch": 1.2215573515697855,
      "grad_norm": 0.5327210426330566,
      "learning_rate": 3.892213242151073e-06,
      "loss": 0.1655,
      "step": 15719
    },
    {
      "epoch": 1.2216350637239664,
      "grad_norm": 0.23648567497730255,
      "learning_rate": 3.891824681380168e-06,
      "loss": 0.0349,
      "step": 15720
    },
    {
      "epoch": 1.2217127758781474,
      "grad_norm": 0.2545110881328583,
      "learning_rate": 3.8914361206092635e-06,
      "loss": 0.1265,
      "step": 15721
    },
    {
      "epoch": 1.2217904880323283,
      "grad_norm": 0.5219231843948364,
      "learning_rate": 3.891047559838359e-06,
      "loss": 0.1568,
      "step": 15722
    },
    {
      "epoch": 1.221868200186509,
      "grad_norm": 1.0434174537658691,
      "learning_rate": 3.890658999067454e-06,
      "loss": 0.3755,
      "step": 15723
    },
    {
      "epoch": 1.2219459123406902,
      "grad_norm": 0.5278180241584778,
      "learning_rate": 3.89027043829655e-06,
      "loss": 0.124,
      "step": 15724
    },
    {
      "epoch": 1.222023624494871,
      "grad_norm": 0.65798020362854,
      "learning_rate": 3.889881877525645e-06,
      "loss": 0.1749,
      "step": 15725
    },
    {
      "epoch": 1.2221013366490519,
      "grad_norm": 0.6476747989654541,
      "learning_rate": 3.889493316754741e-06,
      "loss": 0.3812,
      "step": 15726
    },
    {
      "epoch": 1.222179048803233,
      "grad_norm": 0.394132137298584,
      "learning_rate": 3.8891047559838366e-06,
      "loss": 0.3678,
      "step": 15727
    },
    {
      "epoch": 1.2222567609574138,
      "grad_norm": 0.2298896610736847,
      "learning_rate": 3.8887161952129315e-06,
      "loss": 0.0694,
      "step": 15728
    },
    {
      "epoch": 1.2223344731115946,
      "grad_norm": 0.5205127596855164,
      "learning_rate": 3.888327634442027e-06,
      "loss": 0.4253,
      "step": 15729
    },
    {
      "epoch": 1.2224121852657757,
      "grad_norm": 0.45419594645500183,
      "learning_rate": 3.887939073671122e-06,
      "loss": 0.2509,
      "step": 15730
    },
    {
      "epoch": 1.2224898974199565,
      "grad_norm": 0.5223599672317505,
      "learning_rate": 3.887550512900218e-06,
      "loss": 0.2174,
      "step": 15731
    },
    {
      "epoch": 1.2225676095741373,
      "grad_norm": 0.47193971276283264,
      "learning_rate": 3.887161952129314e-06,
      "loss": 0.1878,
      "step": 15732
    },
    {
      "epoch": 1.2226453217283182,
      "grad_norm": 0.33528152108192444,
      "learning_rate": 3.886773391358409e-06,
      "loss": 0.0398,
      "step": 15733
    },
    {
      "epoch": 1.2227230338824993,
      "grad_norm": 0.6257261037826538,
      "learning_rate": 3.886384830587504e-06,
      "loss": 0.2492,
      "step": 15734
    },
    {
      "epoch": 1.22280074603668,
      "grad_norm": 0.608015239238739,
      "learning_rate": 3.8859962698165995e-06,
      "loss": 0.3312,
      "step": 15735
    },
    {
      "epoch": 1.222878458190861,
      "grad_norm": 0.5065554976463318,
      "learning_rate": 3.885607709045695e-06,
      "loss": 0.2747,
      "step": 15736
    },
    {
      "epoch": 1.222956170345042,
      "grad_norm": 0.2718626856803894,
      "learning_rate": 3.88521914827479e-06,
      "loss": 0.1799,
      "step": 15737
    },
    {
      "epoch": 1.2230338824992228,
      "grad_norm": 0.5743499994277954,
      "learning_rate": 3.884830587503886e-06,
      "loss": 0.1155,
      "step": 15738
    },
    {
      "epoch": 1.2231115946534037,
      "grad_norm": 0.31679534912109375,
      "learning_rate": 3.884442026732981e-06,
      "loss": 0.0256,
      "step": 15739
    },
    {
      "epoch": 1.2231893068075848,
      "grad_norm": 0.43768787384033203,
      "learning_rate": 3.884053465962077e-06,
      "loss": 0.2206,
      "step": 15740
    },
    {
      "epoch": 1.2232670189617656,
      "grad_norm": 0.44877368211746216,
      "learning_rate": 3.883664905191173e-06,
      "loss": 0.0449,
      "step": 15741
    },
    {
      "epoch": 1.2233447311159464,
      "grad_norm": 0.6410030126571655,
      "learning_rate": 3.8832763444202676e-06,
      "loss": 0.5831,
      "step": 15742
    },
    {
      "epoch": 1.2234224432701275,
      "grad_norm": 0.4359511733055115,
      "learning_rate": 3.8828877836493625e-06,
      "loss": 0.0827,
      "step": 15743
    },
    {
      "epoch": 1.2235001554243083,
      "grad_norm": 0.4242624342441559,
      "learning_rate": 3.882499222878458e-06,
      "loss": 0.1982,
      "step": 15744
    },
    {
      "epoch": 1.2235778675784892,
      "grad_norm": 0.24503913521766663,
      "learning_rate": 3.882110662107554e-06,
      "loss": 0.1212,
      "step": 15745
    },
    {
      "epoch": 1.2236555797326703,
      "grad_norm": 0.7389543652534485,
      "learning_rate": 3.88172210133665e-06,
      "loss": 0.3404,
      "step": 15746
    },
    {
      "epoch": 1.223733291886851,
      "grad_norm": 0.2169012874364853,
      "learning_rate": 3.881333540565745e-06,
      "loss": 0.1196,
      "step": 15747
    },
    {
      "epoch": 1.223811004041032,
      "grad_norm": 0.5434993505477905,
      "learning_rate": 3.88094497979484e-06,
      "loss": 0.3185,
      "step": 15748
    },
    {
      "epoch": 1.223888716195213,
      "grad_norm": 0.30257701873779297,
      "learning_rate": 3.880556419023936e-06,
      "loss": 0.3314,
      "step": 15749
    },
    {
      "epoch": 1.2239664283493938,
      "grad_norm": 0.42631274461746216,
      "learning_rate": 3.880167858253031e-06,
      "loss": 0.2087,
      "step": 15750
    },
    {
      "epoch": 1.2240441405035747,
      "grad_norm": 1.1832939386367798,
      "learning_rate": 3.879779297482126e-06,
      "loss": 0.4111,
      "step": 15751
    },
    {
      "epoch": 1.2241218526577557,
      "grad_norm": 0.7495964765548706,
      "learning_rate": 3.879390736711222e-06,
      "loss": 0.2744,
      "step": 15752
    },
    {
      "epoch": 1.2241995648119366,
      "grad_norm": 0.6311096549034119,
      "learning_rate": 3.879002175940317e-06,
      "loss": 0.141,
      "step": 15753
    },
    {
      "epoch": 1.2242772769661174,
      "grad_norm": 0.6508479118347168,
      "learning_rate": 3.878613615169413e-06,
      "loss": 0.1632,
      "step": 15754
    },
    {
      "epoch": 1.2243549891202985,
      "grad_norm": 0.45383018255233765,
      "learning_rate": 3.878225054398509e-06,
      "loss": 0.4739,
      "step": 15755
    },
    {
      "epoch": 1.2244327012744793,
      "grad_norm": 0.37256842851638794,
      "learning_rate": 3.877836493627604e-06,
      "loss": 0.0941,
      "step": 15756
    },
    {
      "epoch": 1.2245104134286602,
      "grad_norm": 0.5277233123779297,
      "learning_rate": 3.877447932856699e-06,
      "loss": 0.2188,
      "step": 15757
    },
    {
      "epoch": 1.2245881255828412,
      "grad_norm": 0.2708214521408081,
      "learning_rate": 3.877059372085794e-06,
      "loss": 0.0855,
      "step": 15758
    },
    {
      "epoch": 1.224665837737022,
      "grad_norm": 0.27130213379859924,
      "learning_rate": 3.87667081131489e-06,
      "loss": 0.0959,
      "step": 15759
    },
    {
      "epoch": 1.224743549891203,
      "grad_norm": 0.25997936725616455,
      "learning_rate": 3.876282250543986e-06,
      "loss": 0.1188,
      "step": 15760
    },
    {
      "epoch": 1.224821262045384,
      "grad_norm": 0.6665351390838623,
      "learning_rate": 3.875893689773081e-06,
      "loss": 0.0983,
      "step": 15761
    },
    {
      "epoch": 1.2248989741995648,
      "grad_norm": 0.5484298467636108,
      "learning_rate": 3.875505129002176e-06,
      "loss": 0.368,
      "step": 15762
    },
    {
      "epoch": 1.2249766863537457,
      "grad_norm": 1.6226754188537598,
      "learning_rate": 3.875116568231272e-06,
      "loss": 0.35,
      "step": 15763
    },
    {
      "epoch": 1.2250543985079267,
      "grad_norm": 0.591246485710144,
      "learning_rate": 3.8747280074603675e-06,
      "loss": 0.543,
      "step": 15764
    },
    {
      "epoch": 1.2251321106621076,
      "grad_norm": 0.48123008012771606,
      "learning_rate": 3.8743394466894624e-06,
      "loss": 0.1773,
      "step": 15765
    },
    {
      "epoch": 1.2252098228162884,
      "grad_norm": 0.5626085996627808,
      "learning_rate": 3.873950885918558e-06,
      "loss": 0.1994,
      "step": 15766
    },
    {
      "epoch": 1.2252875349704695,
      "grad_norm": 0.35981935262680054,
      "learning_rate": 3.873562325147653e-06,
      "loss": 0.0533,
      "step": 15767
    },
    {
      "epoch": 1.2253652471246503,
      "grad_norm": 0.31744420528411865,
      "learning_rate": 3.873173764376749e-06,
      "loss": 0.1308,
      "step": 15768
    },
    {
      "epoch": 1.2254429592788312,
      "grad_norm": 2.1525752544403076,
      "learning_rate": 3.872785203605845e-06,
      "loss": 0.3223,
      "step": 15769
    },
    {
      "epoch": 1.2255206714330122,
      "grad_norm": 0.3977147936820984,
      "learning_rate": 3.87239664283494e-06,
      "loss": 0.0715,
      "step": 15770
    },
    {
      "epoch": 1.225598383587193,
      "grad_norm": 0.3153349757194519,
      "learning_rate": 3.872008082064035e-06,
      "loss": 0.0424,
      "step": 15771
    },
    {
      "epoch": 1.225676095741374,
      "grad_norm": 0.36032459139823914,
      "learning_rate": 3.8716195212931305e-06,
      "loss": 0.0743,
      "step": 15772
    },
    {
      "epoch": 1.2257538078955548,
      "grad_norm": 0.990746021270752,
      "learning_rate": 3.871230960522226e-06,
      "loss": 0.7289,
      "step": 15773
    },
    {
      "epoch": 1.2258315200497358,
      "grad_norm": 0.8721203804016113,
      "learning_rate": 3.870842399751322e-06,
      "loss": 0.2074,
      "step": 15774
    },
    {
      "epoch": 1.2259092322039167,
      "grad_norm": 0.292671263217926,
      "learning_rate": 3.870453838980417e-06,
      "loss": 0.0851,
      "step": 15775
    },
    {
      "epoch": 1.2259869443580975,
      "grad_norm": 0.2720412313938141,
      "learning_rate": 3.870065278209512e-06,
      "loss": 0.5832,
      "step": 15776
    },
    {
      "epoch": 1.2260646565122786,
      "grad_norm": 0.3525436818599701,
      "learning_rate": 3.869676717438608e-06,
      "loss": 0.068,
      "step": 15777
    },
    {
      "epoch": 1.2261423686664594,
      "grad_norm": 0.5280675888061523,
      "learning_rate": 3.8692881566677036e-06,
      "loss": 0.2033,
      "step": 15778
    },
    {
      "epoch": 1.2262200808206403,
      "grad_norm": 0.3955214321613312,
      "learning_rate": 3.8688995958967985e-06,
      "loss": 0.1029,
      "step": 15779
    },
    {
      "epoch": 1.2262977929748213,
      "grad_norm": 0.2049938589334488,
      "learning_rate": 3.868511035125894e-06,
      "loss": 0.0809,
      "step": 15780
    },
    {
      "epoch": 1.2263755051290022,
      "grad_norm": 0.5050203204154968,
      "learning_rate": 3.868122474354989e-06,
      "loss": 0.1552,
      "step": 15781
    },
    {
      "epoch": 1.226453217283183,
      "grad_norm": 0.3458162546157837,
      "learning_rate": 3.867733913584085e-06,
      "loss": 0.0917,
      "step": 15782
    },
    {
      "epoch": 1.226530929437364,
      "grad_norm": 0.25305700302124023,
      "learning_rate": 3.867345352813181e-06,
      "loss": 0.0864,
      "step": 15783
    },
    {
      "epoch": 1.226608641591545,
      "grad_norm": 0.9095795154571533,
      "learning_rate": 3.866956792042276e-06,
      "loss": 0.3356,
      "step": 15784
    },
    {
      "epoch": 1.2266863537457258,
      "grad_norm": 0.13005445897579193,
      "learning_rate": 3.866568231271371e-06,
      "loss": 0.0205,
      "step": 15785
    },
    {
      "epoch": 1.2267640658999068,
      "grad_norm": 0.31043073534965515,
      "learning_rate": 3.8661796705004665e-06,
      "loss": 0.1049,
      "step": 15786
    },
    {
      "epoch": 1.2268417780540877,
      "grad_norm": 0.5238416194915771,
      "learning_rate": 3.865791109729562e-06,
      "loss": 0.1039,
      "step": 15787
    },
    {
      "epoch": 1.2269194902082685,
      "grad_norm": 0.4636772572994232,
      "learning_rate": 3.865402548958657e-06,
      "loss": 0.3722,
      "step": 15788
    },
    {
      "epoch": 1.2269972023624496,
      "grad_norm": 0.5529170632362366,
      "learning_rate": 3.865013988187753e-06,
      "loss": 0.06,
      "step": 15789
    },
    {
      "epoch": 1.2270749145166304,
      "grad_norm": 0.4370996057987213,
      "learning_rate": 3.864625427416848e-06,
      "loss": 0.0381,
      "step": 15790
    },
    {
      "epoch": 1.2271526266708113,
      "grad_norm": 0.42087700963020325,
      "learning_rate": 3.864236866645944e-06,
      "loss": 0.092,
      "step": 15791
    },
    {
      "epoch": 1.227230338824992,
      "grad_norm": 0.7847191095352173,
      "learning_rate": 3.86384830587504e-06,
      "loss": 0.4644,
      "step": 15792
    },
    {
      "epoch": 1.2273080509791732,
      "grad_norm": 0.45513394474983215,
      "learning_rate": 3.863459745104135e-06,
      "loss": 0.1518,
      "step": 15793
    },
    {
      "epoch": 1.227385763133354,
      "grad_norm": 0.3347363770008087,
      "learning_rate": 3.86307118433323e-06,
      "loss": 0.1546,
      "step": 15794
    },
    {
      "epoch": 1.2274634752875349,
      "grad_norm": 0.45463964343070984,
      "learning_rate": 3.862682623562325e-06,
      "loss": 0.3133,
      "step": 15795
    },
    {
      "epoch": 1.227541187441716,
      "grad_norm": 0.03971928358078003,
      "learning_rate": 3.862294062791421e-06,
      "loss": 0.0053,
      "step": 15796
    },
    {
      "epoch": 1.2276188995958968,
      "grad_norm": 0.2865578830242157,
      "learning_rate": 3.861905502020517e-06,
      "loss": 0.0763,
      "step": 15797
    },
    {
      "epoch": 1.2276966117500776,
      "grad_norm": 0.5221678018569946,
      "learning_rate": 3.861516941249612e-06,
      "loss": 0.0692,
      "step": 15798
    },
    {
      "epoch": 1.2277743239042587,
      "grad_norm": 1.635301113128662,
      "learning_rate": 3.861128380478707e-06,
      "loss": 0.2984,
      "step": 15799
    },
    {
      "epoch": 1.2278520360584395,
      "grad_norm": 0.5624051094055176,
      "learning_rate": 3.860739819707803e-06,
      "loss": 0.216,
      "step": 15800
    },
    {
      "epoch": 1.2279297482126204,
      "grad_norm": 0.056026384234428406,
      "learning_rate": 3.860351258936898e-06,
      "loss": 0.008,
      "step": 15801
    },
    {
      "epoch": 1.2280074603668014,
      "grad_norm": 0.4958348870277405,
      "learning_rate": 3.859962698165993e-06,
      "loss": 0.0943,
      "step": 15802
    },
    {
      "epoch": 1.2280851725209823,
      "grad_norm": 0.24713343381881714,
      "learning_rate": 3.859574137395089e-06,
      "loss": 0.0484,
      "step": 15803
    },
    {
      "epoch": 1.228162884675163,
      "grad_norm": 0.7615013122558594,
      "learning_rate": 3.859185576624184e-06,
      "loss": 0.4543,
      "step": 15804
    },
    {
      "epoch": 1.2282405968293442,
      "grad_norm": 0.9559177756309509,
      "learning_rate": 3.85879701585328e-06,
      "loss": 0.265,
      "step": 15805
    },
    {
      "epoch": 1.228318308983525,
      "grad_norm": 0.28813469409942627,
      "learning_rate": 3.858408455082375e-06,
      "loss": 0.1113,
      "step": 15806
    },
    {
      "epoch": 1.2283960211377059,
      "grad_norm": 0.12326295673847198,
      "learning_rate": 3.858019894311471e-06,
      "loss": 0.0391,
      "step": 15807
    },
    {
      "epoch": 1.228473733291887,
      "grad_norm": 0.3565253019332886,
      "learning_rate": 3.8576313335405664e-06,
      "loss": 0.0539,
      "step": 15808
    },
    {
      "epoch": 1.2285514454460678,
      "grad_norm": 1.0249162912368774,
      "learning_rate": 3.857242772769661e-06,
      "loss": 0.173,
      "step": 15809
    },
    {
      "epoch": 1.2286291576002486,
      "grad_norm": 0.7524594068527222,
      "learning_rate": 3.856854211998756e-06,
      "loss": 0.3142,
      "step": 15810
    },
    {
      "epoch": 1.2287068697544297,
      "grad_norm": 0.06280969083309174,
      "learning_rate": 3.856465651227852e-06,
      "loss": 0.0255,
      "step": 15811
    },
    {
      "epoch": 1.2287845819086105,
      "grad_norm": 0.6700693964958191,
      "learning_rate": 3.856077090456948e-06,
      "loss": 0.5088,
      "step": 15812
    },
    {
      "epoch": 1.2288622940627913,
      "grad_norm": 0.8243558406829834,
      "learning_rate": 3.855688529686043e-06,
      "loss": 0.1769,
      "step": 15813
    },
    {
      "epoch": 1.2289400062169724,
      "grad_norm": 0.32532644271850586,
      "learning_rate": 3.855299968915139e-06,
      "loss": 0.1732,
      "step": 15814
    },
    {
      "epoch": 1.2290177183711533,
      "grad_norm": 0.0999387577176094,
      "learning_rate": 3.854911408144234e-06,
      "loss": 0.033,
      "step": 15815
    },
    {
      "epoch": 1.229095430525334,
      "grad_norm": 0.2551496624946594,
      "learning_rate": 3.8545228473733294e-06,
      "loss": 0.1309,
      "step": 15816
    },
    {
      "epoch": 1.2291731426795152,
      "grad_norm": 0.43036171793937683,
      "learning_rate": 3.854134286602425e-06,
      "loss": 0.1249,
      "step": 15817
    },
    {
      "epoch": 1.229250854833696,
      "grad_norm": 0.2574048936367035,
      "learning_rate": 3.85374572583152e-06,
      "loss": 0.0753,
      "step": 15818
    },
    {
      "epoch": 1.2293285669878768,
      "grad_norm": 0.14590975642204285,
      "learning_rate": 3.853357165060615e-06,
      "loss": 0.052,
      "step": 15819
    },
    {
      "epoch": 1.229406279142058,
      "grad_norm": 0.7468312382698059,
      "learning_rate": 3.852968604289711e-06,
      "loss": 0.2185,
      "step": 15820
    },
    {
      "epoch": 1.2294839912962388,
      "grad_norm": 0.36642202734947205,
      "learning_rate": 3.852580043518807e-06,
      "loss": 0.2412,
      "step": 15821
    },
    {
      "epoch": 1.2295617034504196,
      "grad_norm": 0.30208784341812134,
      "learning_rate": 3.8521914827479025e-06,
      "loss": 0.0554,
      "step": 15822
    },
    {
      "epoch": 1.2296394156046007,
      "grad_norm": 0.5583130717277527,
      "learning_rate": 3.8518029219769975e-06,
      "loss": 0.661,
      "step": 15823
    },
    {
      "epoch": 1.2297171277587815,
      "grad_norm": 0.9871811270713806,
      "learning_rate": 3.851414361206092e-06,
      "loss": 0.2193,
      "step": 15824
    },
    {
      "epoch": 1.2297948399129623,
      "grad_norm": 0.29110202193260193,
      "learning_rate": 3.851025800435188e-06,
      "loss": 0.0559,
      "step": 15825
    },
    {
      "epoch": 1.2298725520671434,
      "grad_norm": 0.3394000232219696,
      "learning_rate": 3.850637239664284e-06,
      "loss": 0.1709,
      "step": 15826
    },
    {
      "epoch": 1.2299502642213243,
      "grad_norm": 1.100435733795166,
      "learning_rate": 3.850248678893379e-06,
      "loss": 0.507,
      "step": 15827
    },
    {
      "epoch": 1.230027976375505,
      "grad_norm": 0.20369921624660492,
      "learning_rate": 3.849860118122475e-06,
      "loss": 0.0637,
      "step": 15828
    },
    {
      "epoch": 1.2301056885296862,
      "grad_norm": 0.1573389768600464,
      "learning_rate": 3.84947155735157e-06,
      "loss": 0.0796,
      "step": 15829
    },
    {
      "epoch": 1.230183400683867,
      "grad_norm": 0.3875393867492676,
      "learning_rate": 3.8490829965806655e-06,
      "loss": 0.0586,
      "step": 15830
    },
    {
      "epoch": 1.2302611128380478,
      "grad_norm": 0.6018229126930237,
      "learning_rate": 3.848694435809761e-06,
      "loss": 0.0948,
      "step": 15831
    },
    {
      "epoch": 1.230338824992229,
      "grad_norm": 0.30402860045433044,
      "learning_rate": 3.848305875038856e-06,
      "loss": 0.2402,
      "step": 15832
    },
    {
      "epoch": 1.2304165371464098,
      "grad_norm": 0.4611656963825226,
      "learning_rate": 3.847917314267951e-06,
      "loss": 0.1221,
      "step": 15833
    },
    {
      "epoch": 1.2304942493005906,
      "grad_norm": 0.5474940538406372,
      "learning_rate": 3.847528753497047e-06,
      "loss": 0.1435,
      "step": 15834
    },
    {
      "epoch": 1.2305719614547714,
      "grad_norm": 0.46381399035453796,
      "learning_rate": 3.847140192726143e-06,
      "loss": 0.186,
      "step": 15835
    },
    {
      "epoch": 1.2306496736089525,
      "grad_norm": 0.37626639008522034,
      "learning_rate": 3.846751631955239e-06,
      "loss": 0.0484,
      "step": 15836
    },
    {
      "epoch": 1.2307273857631333,
      "grad_norm": 0.44401320815086365,
      "learning_rate": 3.8463630711843335e-06,
      "loss": 0.1099,
      "step": 15837
    },
    {
      "epoch": 1.2308050979173142,
      "grad_norm": 0.6461100578308105,
      "learning_rate": 3.8459745104134285e-06,
      "loss": 0.2857,
      "step": 15838
    },
    {
      "epoch": 1.2308828100714952,
      "grad_norm": 0.2140171229839325,
      "learning_rate": 3.845585949642524e-06,
      "loss": 0.0874,
      "step": 15839
    },
    {
      "epoch": 1.230960522225676,
      "grad_norm": 0.48799535632133484,
      "learning_rate": 3.84519738887162e-06,
      "loss": 0.0236,
      "step": 15840
    },
    {
      "epoch": 1.231038234379857,
      "grad_norm": 0.2964247763156891,
      "learning_rate": 3.844808828100715e-06,
      "loss": 0.0196,
      "step": 15841
    },
    {
      "epoch": 1.231115946534038,
      "grad_norm": 0.4361898601055145,
      "learning_rate": 3.844420267329811e-06,
      "loss": 0.2325,
      "step": 15842
    },
    {
      "epoch": 1.2311936586882188,
      "grad_norm": 0.2556036114692688,
      "learning_rate": 3.844031706558906e-06,
      "loss": 0.0934,
      "step": 15843
    },
    {
      "epoch": 1.2312713708423997,
      "grad_norm": 0.46971359848976135,
      "learning_rate": 3.843643145788002e-06,
      "loss": 0.2182,
      "step": 15844
    },
    {
      "epoch": 1.2313490829965807,
      "grad_norm": 0.1937745213508606,
      "learning_rate": 3.843254585017097e-06,
      "loss": 0.0782,
      "step": 15845
    },
    {
      "epoch": 1.2314267951507616,
      "grad_norm": 0.23355619609355927,
      "learning_rate": 3.842866024246192e-06,
      "loss": 0.0854,
      "step": 15846
    },
    {
      "epoch": 1.2315045073049424,
      "grad_norm": 0.5326928496360779,
      "learning_rate": 3.842477463475287e-06,
      "loss": 0.1037,
      "step": 15847
    },
    {
      "epoch": 1.2315822194591235,
      "grad_norm": 0.26657500863075256,
      "learning_rate": 3.842088902704383e-06,
      "loss": 0.1324,
      "step": 15848
    },
    {
      "epoch": 1.2316599316133043,
      "grad_norm": 0.18726930022239685,
      "learning_rate": 3.841700341933479e-06,
      "loss": 0.0471,
      "step": 15849
    },
    {
      "epoch": 1.2317376437674852,
      "grad_norm": 0.38461244106292725,
      "learning_rate": 3.841311781162575e-06,
      "loss": 0.0627,
      "step": 15850
    },
    {
      "epoch": 1.2318153559216662,
      "grad_norm": 0.18527023494243622,
      "learning_rate": 3.84092322039167e-06,
      "loss": 0.0927,
      "step": 15851
    },
    {
      "epoch": 1.231893068075847,
      "grad_norm": 1.1570078134536743,
      "learning_rate": 3.8405346596207646e-06,
      "loss": 0.2835,
      "step": 15852
    },
    {
      "epoch": 1.231970780230028,
      "grad_norm": 0.2130049467086792,
      "learning_rate": 3.84014609884986e-06,
      "loss": 0.034,
      "step": 15853
    },
    {
      "epoch": 1.2320484923842088,
      "grad_norm": 0.5092553496360779,
      "learning_rate": 3.839757538078956e-06,
      "loss": 0.202,
      "step": 15854
    },
    {
      "epoch": 1.2321262045383898,
      "grad_norm": 0.4104129374027252,
      "learning_rate": 3.839368977308051e-06,
      "loss": 0.1479,
      "step": 15855
    },
    {
      "epoch": 1.2322039166925707,
      "grad_norm": 0.3047129809856415,
      "learning_rate": 3.838980416537147e-06,
      "loss": 0.109,
      "step": 15856
    },
    {
      "epoch": 1.2322816288467515,
      "grad_norm": 0.1723957508802414,
      "learning_rate": 3.838591855766242e-06,
      "loss": 0.0714,
      "step": 15857
    },
    {
      "epoch": 1.2323593410009326,
      "grad_norm": 0.8318326473236084,
      "learning_rate": 3.838203294995338e-06,
      "loss": 0.289,
      "step": 15858
    },
    {
      "epoch": 1.2324370531551134,
      "grad_norm": 0.32024717330932617,
      "learning_rate": 3.8378147342244334e-06,
      "loss": 0.1283,
      "step": 15859
    },
    {
      "epoch": 1.2325147653092943,
      "grad_norm": 0.47190046310424805,
      "learning_rate": 3.837426173453528e-06,
      "loss": 0.0593,
      "step": 15860
    },
    {
      "epoch": 1.2325924774634753,
      "grad_norm": 0.8272761702537537,
      "learning_rate": 3.837037612682623e-06,
      "loss": 0.6305,
      "step": 15861
    },
    {
      "epoch": 1.2326701896176562,
      "grad_norm": 0.40432342886924744,
      "learning_rate": 3.836649051911719e-06,
      "loss": 0.0869,
      "step": 15862
    },
    {
      "epoch": 1.232747901771837,
      "grad_norm": 1.1697564125061035,
      "learning_rate": 3.836260491140815e-06,
      "loss": 0.4018,
      "step": 15863
    },
    {
      "epoch": 1.232825613926018,
      "grad_norm": 0.17289383709430695,
      "learning_rate": 3.83587193036991e-06,
      "loss": 0.05,
      "step": 15864
    },
    {
      "epoch": 1.232903326080199,
      "grad_norm": 0.6484968066215515,
      "learning_rate": 3.835483369599006e-06,
      "loss": 0.3181,
      "step": 15865
    },
    {
      "epoch": 1.2329810382343798,
      "grad_norm": 0.7058776021003723,
      "learning_rate": 3.835094808828101e-06,
      "loss": 0.319,
      "step": 15866
    },
    {
      "epoch": 1.2330587503885608,
      "grad_norm": 0.3529677093029022,
      "learning_rate": 3.8347062480571964e-06,
      "loss": 0.0805,
      "step": 15867
    },
    {
      "epoch": 1.2331364625427417,
      "grad_norm": 0.30489209294319153,
      "learning_rate": 3.834317687286292e-06,
      "loss": 0.0387,
      "step": 15868
    },
    {
      "epoch": 1.2332141746969225,
      "grad_norm": 0.4424295723438263,
      "learning_rate": 3.833929126515387e-06,
      "loss": 0.1014,
      "step": 15869
    },
    {
      "epoch": 1.2332918868511036,
      "grad_norm": 0.32680949568748474,
      "learning_rate": 3.833540565744483e-06,
      "loss": 0.0464,
      "step": 15870
    },
    {
      "epoch": 1.2333695990052844,
      "grad_norm": 0.22811706364154816,
      "learning_rate": 3.833152004973578e-06,
      "loss": 0.0339,
      "step": 15871
    },
    {
      "epoch": 1.2334473111594653,
      "grad_norm": 0.5098631978034973,
      "learning_rate": 3.832763444202674e-06,
      "loss": 0.0397,
      "step": 15872
    },
    {
      "epoch": 1.2335250233136463,
      "grad_norm": 0.9706804752349854,
      "learning_rate": 3.8323748834317695e-06,
      "loss": 0.2167,
      "step": 15873
    },
    {
      "epoch": 1.2336027354678272,
      "grad_norm": 0.3689040243625641,
      "learning_rate": 3.8319863226608645e-06,
      "loss": 0.0968,
      "step": 15874
    },
    {
      "epoch": 1.233680447622008,
      "grad_norm": 1.4747426509857178,
      "learning_rate": 3.831597761889959e-06,
      "loss": 0.642,
      "step": 15875
    },
    {
      "epoch": 1.233758159776189,
      "grad_norm": 0.41470104455947876,
      "learning_rate": 3.831209201119055e-06,
      "loss": 0.1089,
      "step": 15876
    },
    {
      "epoch": 1.23383587193037,
      "grad_norm": 0.547307550907135,
      "learning_rate": 3.830820640348151e-06,
      "loss": 0.1011,
      "step": 15877
    },
    {
      "epoch": 1.2339135840845508,
      "grad_norm": 0.7380857467651367,
      "learning_rate": 3.830432079577246e-06,
      "loss": 0.1813,
      "step": 15878
    },
    {
      "epoch": 1.2339912962387318,
      "grad_norm": 0.4226195216178894,
      "learning_rate": 3.830043518806342e-06,
      "loss": 0.162,
      "step": 15879
    },
    {
      "epoch": 1.2340690083929127,
      "grad_norm": 0.4531564712524414,
      "learning_rate": 3.829654958035437e-06,
      "loss": 0.1938,
      "step": 15880
    },
    {
      "epoch": 1.2341467205470935,
      "grad_norm": 0.7898530960083008,
      "learning_rate": 3.8292663972645325e-06,
      "loss": 0.2049,
      "step": 15881
    },
    {
      "epoch": 1.2342244327012746,
      "grad_norm": 0.4943917691707611,
      "learning_rate": 3.828877836493628e-06,
      "loss": 0.2186,
      "step": 15882
    },
    {
      "epoch": 1.2343021448554554,
      "grad_norm": 0.21940277516841888,
      "learning_rate": 3.828489275722723e-06,
      "loss": 0.0296,
      "step": 15883
    },
    {
      "epoch": 1.2343798570096363,
      "grad_norm": 0.4649145007133484,
      "learning_rate": 3.828100714951819e-06,
      "loss": 0.0505,
      "step": 15884
    },
    {
      "epoch": 1.2344575691638173,
      "grad_norm": 0.5153585076332092,
      "learning_rate": 3.827712154180914e-06,
      "loss": 0.307,
      "step": 15885
    },
    {
      "epoch": 1.2345352813179982,
      "grad_norm": 0.5886164903640747,
      "learning_rate": 3.82732359341001e-06,
      "loss": 0.322,
      "step": 15886
    },
    {
      "epoch": 1.234612993472179,
      "grad_norm": 0.36106929183006287,
      "learning_rate": 3.826935032639106e-06,
      "loss": 0.053,
      "step": 15887
    },
    {
      "epoch": 1.23469070562636,
      "grad_norm": 0.7958093285560608,
      "learning_rate": 3.8265464718682005e-06,
      "loss": 0.2016,
      "step": 15888
    },
    {
      "epoch": 1.234768417780541,
      "grad_norm": 0.3329508602619171,
      "learning_rate": 3.8261579110972955e-06,
      "loss": 0.1664,
      "step": 15889
    },
    {
      "epoch": 1.2348461299347218,
      "grad_norm": 0.22330714762210846,
      "learning_rate": 3.825769350326391e-06,
      "loss": 0.0888,
      "step": 15890
    },
    {
      "epoch": 1.2349238420889028,
      "grad_norm": 0.8303514122962952,
      "learning_rate": 3.825380789555487e-06,
      "loss": 0.2907,
      "step": 15891
    },
    {
      "epoch": 1.2350015542430837,
      "grad_norm": 0.4086708426475525,
      "learning_rate": 3.824992228784582e-06,
      "loss": 0.2863,
      "step": 15892
    },
    {
      "epoch": 1.2350792663972645,
      "grad_norm": 0.7154238820075989,
      "learning_rate": 3.824603668013678e-06,
      "loss": 0.1304,
      "step": 15893
    },
    {
      "epoch": 1.2351569785514454,
      "grad_norm": 0.39223966002464294,
      "learning_rate": 3.824215107242773e-06,
      "loss": 0.137,
      "step": 15894
    },
    {
      "epoch": 1.2352346907056264,
      "grad_norm": 0.8738694787025452,
      "learning_rate": 3.823826546471869e-06,
      "loss": 0.2715,
      "step": 15895
    },
    {
      "epoch": 1.2353124028598073,
      "grad_norm": 0.7646122574806213,
      "learning_rate": 3.823437985700964e-06,
      "loss": 0.5082,
      "step": 15896
    },
    {
      "epoch": 1.235390115013988,
      "grad_norm": 1.0956223011016846,
      "learning_rate": 3.823049424930059e-06,
      "loss": 0.2984,
      "step": 15897
    },
    {
      "epoch": 1.2354678271681692,
      "grad_norm": 0.6906693577766418,
      "learning_rate": 3.822660864159155e-06,
      "loss": 0.3514,
      "step": 15898
    },
    {
      "epoch": 1.23554553932235,
      "grad_norm": 0.3738439381122589,
      "learning_rate": 3.82227230338825e-06,
      "loss": 0.093,
      "step": 15899
    },
    {
      "epoch": 1.2356232514765308,
      "grad_norm": 0.7228444218635559,
      "learning_rate": 3.821883742617346e-06,
      "loss": 0.1152,
      "step": 15900
    },
    {
      "epoch": 1.235700963630712,
      "grad_norm": 0.47202274203300476,
      "learning_rate": 3.821495181846442e-06,
      "loss": 0.1468,
      "step": 15901
    },
    {
      "epoch": 1.2357786757848928,
      "grad_norm": 0.23192156851291656,
      "learning_rate": 3.821106621075537e-06,
      "loss": 0.0671,
      "step": 15902
    },
    {
      "epoch": 1.2358563879390736,
      "grad_norm": 0.3777088224887848,
      "learning_rate": 3.8207180603046316e-06,
      "loss": 0.0918,
      "step": 15903
    },
    {
      "epoch": 1.2359341000932547,
      "grad_norm": 0.6452435255050659,
      "learning_rate": 3.820329499533727e-06,
      "loss": 0.3727,
      "step": 15904
    },
    {
      "epoch": 1.2360118122474355,
      "grad_norm": 0.31682178378105164,
      "learning_rate": 3.819940938762823e-06,
      "loss": 0.0738,
      "step": 15905
    },
    {
      "epoch": 1.2360895244016163,
      "grad_norm": 0.11221452802419662,
      "learning_rate": 3.819552377991918e-06,
      "loss": 0.0452,
      "step": 15906
    },
    {
      "epoch": 1.2361672365557974,
      "grad_norm": 0.4618995785713196,
      "learning_rate": 3.819163817221014e-06,
      "loss": 0.2062,
      "step": 15907
    },
    {
      "epoch": 1.2362449487099783,
      "grad_norm": 0.6125074625015259,
      "learning_rate": 3.818775256450109e-06,
      "loss": 0.3907,
      "step": 15908
    },
    {
      "epoch": 1.236322660864159,
      "grad_norm": 0.5941895246505737,
      "learning_rate": 3.818386695679205e-06,
      "loss": 0.1803,
      "step": 15909
    },
    {
      "epoch": 1.2364003730183402,
      "grad_norm": 0.43376925587654114,
      "learning_rate": 3.8179981349083005e-06,
      "loss": 0.055,
      "step": 15910
    },
    {
      "epoch": 1.236478085172521,
      "grad_norm": 0.7125939726829529,
      "learning_rate": 3.817609574137395e-06,
      "loss": 0.2769,
      "step": 15911
    },
    {
      "epoch": 1.2365557973267018,
      "grad_norm": 0.9218385219573975,
      "learning_rate": 3.817221013366491e-06,
      "loss": 0.0968,
      "step": 15912
    },
    {
      "epoch": 1.2366335094808827,
      "grad_norm": 0.6289271116256714,
      "learning_rate": 3.816832452595586e-06,
      "loss": 0.4267,
      "step": 15913
    },
    {
      "epoch": 1.2367112216350638,
      "grad_norm": 0.22417135536670685,
      "learning_rate": 3.816443891824682e-06,
      "loss": 0.094,
      "step": 15914
    },
    {
      "epoch": 1.2367889337892446,
      "grad_norm": 0.692162811756134,
      "learning_rate": 3.816055331053778e-06,
      "loss": 0.2217,
      "step": 15915
    },
    {
      "epoch": 1.2368666459434254,
      "grad_norm": 0.16717217862606049,
      "learning_rate": 3.815666770282873e-06,
      "loss": 0.0295,
      "step": 15916
    },
    {
      "epoch": 1.2369443580976065,
      "grad_norm": 0.2669714391231537,
      "learning_rate": 3.815278209511968e-06,
      "loss": 0.0716,
      "step": 15917
    },
    {
      "epoch": 1.2370220702517873,
      "grad_norm": 0.5935717821121216,
      "learning_rate": 3.8148896487410634e-06,
      "loss": 0.2573,
      "step": 15918
    },
    {
      "epoch": 1.2370997824059682,
      "grad_norm": 0.04337206482887268,
      "learning_rate": 3.814501087970159e-06,
      "loss": 0.0222,
      "step": 15919
    },
    {
      "epoch": 1.2371774945601492,
      "grad_norm": 0.43316221237182617,
      "learning_rate": 3.814112527199254e-06,
      "loss": 0.1707,
      "step": 15920
    },
    {
      "epoch": 1.23725520671433,
      "grad_norm": 0.1759319007396698,
      "learning_rate": 3.81372396642835e-06,
      "loss": 0.0378,
      "step": 15921
    },
    {
      "epoch": 1.237332918868511,
      "grad_norm": 0.20882083475589752,
      "learning_rate": 3.813335405657445e-06,
      "loss": 0.0634,
      "step": 15922
    },
    {
      "epoch": 1.237410631022692,
      "grad_norm": 0.21604742109775543,
      "learning_rate": 3.8129468448865403e-06,
      "loss": 0.1223,
      "step": 15923
    },
    {
      "epoch": 1.2374883431768728,
      "grad_norm": 0.22623637318611145,
      "learning_rate": 3.812558284115636e-06,
      "loss": 0.1081,
      "step": 15924
    },
    {
      "epoch": 1.2375660553310537,
      "grad_norm": 0.20846261084079742,
      "learning_rate": 3.8121697233447315e-06,
      "loss": 0.0656,
      "step": 15925
    },
    {
      "epoch": 1.2376437674852347,
      "grad_norm": 0.38145366311073303,
      "learning_rate": 3.8117811625738273e-06,
      "loss": 0.2707,
      "step": 15926
    },
    {
      "epoch": 1.2377214796394156,
      "grad_norm": 0.08991138637065887,
      "learning_rate": 3.8113926018029222e-06,
      "loss": 0.0254,
      "step": 15927
    },
    {
      "epoch": 1.2377991917935964,
      "grad_norm": 0.4740733802318573,
      "learning_rate": 3.8110040410320176e-06,
      "loss": 0.1831,
      "step": 15928
    },
    {
      "epoch": 1.2378769039477775,
      "grad_norm": 0.39775407314300537,
      "learning_rate": 3.8106154802611134e-06,
      "loss": 0.2022,
      "step": 15929
    },
    {
      "epoch": 1.2379546161019583,
      "grad_norm": 1.7178205251693726,
      "learning_rate": 3.8102269194902088e-06,
      "loss": 0.3587,
      "step": 15930
    },
    {
      "epoch": 1.2380323282561392,
      "grad_norm": 0.18181467056274414,
      "learning_rate": 3.8098383587193037e-06,
      "loss": 0.0802,
      "step": 15931
    },
    {
      "epoch": 1.2381100404103202,
      "grad_norm": 0.41068992018699646,
      "learning_rate": 3.8094497979483995e-06,
      "loss": 0.273,
      "step": 15932
    },
    {
      "epoch": 1.238187752564501,
      "grad_norm": 0.6441950798034668,
      "learning_rate": 3.809061237177495e-06,
      "loss": 0.2392,
      "step": 15933
    },
    {
      "epoch": 1.238265464718682,
      "grad_norm": 0.3405616581439972,
      "learning_rate": 3.8086726764065903e-06,
      "loss": 0.105,
      "step": 15934
    },
    {
      "epoch": 1.238343176872863,
      "grad_norm": 0.7286766767501831,
      "learning_rate": 3.808284115635686e-06,
      "loss": 0.0605,
      "step": 15935
    },
    {
      "epoch": 1.2384208890270438,
      "grad_norm": 0.6979524493217468,
      "learning_rate": 3.807895554864781e-06,
      "loss": 0.6994,
      "step": 15936
    },
    {
      "epoch": 1.2384986011812247,
      "grad_norm": 1.3842015266418457,
      "learning_rate": 3.8075069940938764e-06,
      "loss": 0.2865,
      "step": 15937
    },
    {
      "epoch": 1.2385763133354057,
      "grad_norm": 0.53363037109375,
      "learning_rate": 3.807118433322972e-06,
      "loss": 0.0391,
      "step": 15938
    },
    {
      "epoch": 1.2386540254895866,
      "grad_norm": 0.41000986099243164,
      "learning_rate": 3.8067298725520675e-06,
      "loss": 0.0617,
      "step": 15939
    },
    {
      "epoch": 1.2387317376437674,
      "grad_norm": 0.43298208713531494,
      "learning_rate": 3.8063413117811625e-06,
      "loss": 0.1041,
      "step": 15940
    },
    {
      "epoch": 1.2388094497979485,
      "grad_norm": 0.706316351890564,
      "learning_rate": 3.8059527510102583e-06,
      "loss": 0.0844,
      "step": 15941
    },
    {
      "epoch": 1.2388871619521293,
      "grad_norm": 0.16343264281749725,
      "learning_rate": 3.8055641902393537e-06,
      "loss": 0.0216,
      "step": 15942
    },
    {
      "epoch": 1.2389648741063102,
      "grad_norm": 0.6394110918045044,
      "learning_rate": 3.8051756294684495e-06,
      "loss": 0.4176,
      "step": 15943
    },
    {
      "epoch": 1.2390425862604912,
      "grad_norm": 0.5620396137237549,
      "learning_rate": 3.804787068697545e-06,
      "loss": 0.1886,
      "step": 15944
    },
    {
      "epoch": 1.239120298414672,
      "grad_norm": 0.5388169884681702,
      "learning_rate": 3.8043985079266398e-06,
      "loss": 0.1089,
      "step": 15945
    },
    {
      "epoch": 1.239198010568853,
      "grad_norm": 0.5240424275398254,
      "learning_rate": 3.8040099471557356e-06,
      "loss": 0.3088,
      "step": 15946
    },
    {
      "epoch": 1.239275722723034,
      "grad_norm": 0.2808590233325958,
      "learning_rate": 3.803621386384831e-06,
      "loss": 0.1282,
      "step": 15947
    },
    {
      "epoch": 1.2393534348772148,
      "grad_norm": 0.2012467235326767,
      "learning_rate": 3.8032328256139263e-06,
      "loss": 0.0361,
      "step": 15948
    },
    {
      "epoch": 1.2394311470313957,
      "grad_norm": 0.30492067337036133,
      "learning_rate": 3.802844264843022e-06,
      "loss": 0.0576,
      "step": 15949
    },
    {
      "epoch": 1.2395088591855767,
      "grad_norm": 0.26752379536628723,
      "learning_rate": 3.802455704072117e-06,
      "loss": 0.0226,
      "step": 15950
    },
    {
      "epoch": 1.2395865713397576,
      "grad_norm": 0.2901967167854309,
      "learning_rate": 3.8020671433012125e-06,
      "loss": 0.1265,
      "step": 15951
    },
    {
      "epoch": 1.2396642834939384,
      "grad_norm": 0.7590345144271851,
      "learning_rate": 3.8016785825303082e-06,
      "loss": 0.2382,
      "step": 15952
    },
    {
      "epoch": 1.2397419956481195,
      "grad_norm": 0.40958571434020996,
      "learning_rate": 3.8012900217594036e-06,
      "loss": 0.1215,
      "step": 15953
    },
    {
      "epoch": 1.2398197078023003,
      "grad_norm": 0.3060055375099182,
      "learning_rate": 3.8009014609884986e-06,
      "loss": 0.0716,
      "step": 15954
    },
    {
      "epoch": 1.2398974199564812,
      "grad_norm": 0.2775486409664154,
      "learning_rate": 3.8005129002175944e-06,
      "loss": 0.0524,
      "step": 15955
    },
    {
      "epoch": 1.239975132110662,
      "grad_norm": 0.40113139152526855,
      "learning_rate": 3.8001243394466897e-06,
      "loss": 0.0794,
      "step": 15956
    },
    {
      "epoch": 1.240052844264843,
      "grad_norm": 0.7772877216339111,
      "learning_rate": 3.7997357786757855e-06,
      "loss": 0.125,
      "step": 15957
    },
    {
      "epoch": 1.240130556419024,
      "grad_norm": 0.11358541995286942,
      "learning_rate": 3.799347217904881e-06,
      "loss": 0.0079,
      "step": 15958
    },
    {
      "epoch": 1.2402082685732048,
      "grad_norm": 0.46177712082862854,
      "learning_rate": 3.798958657133976e-06,
      "loss": 0.0887,
      "step": 15959
    },
    {
      "epoch": 1.2402859807273858,
      "grad_norm": 0.17707380652427673,
      "learning_rate": 3.7985700963630717e-06,
      "loss": 0.0234,
      "step": 15960
    },
    {
      "epoch": 1.2403636928815667,
      "grad_norm": 0.7056546211242676,
      "learning_rate": 3.798181535592167e-06,
      "loss": 0.2117,
      "step": 15961
    },
    {
      "epoch": 1.2404414050357475,
      "grad_norm": 0.17198824882507324,
      "learning_rate": 3.797792974821262e-06,
      "loss": 0.0385,
      "step": 15962
    },
    {
      "epoch": 1.2405191171899286,
      "grad_norm": 0.5370339751243591,
      "learning_rate": 3.7974044140503578e-06,
      "loss": 0.275,
      "step": 15963
    },
    {
      "epoch": 1.2405968293441094,
      "grad_norm": 0.23232433199882507,
      "learning_rate": 3.797015853279453e-06,
      "loss": 0.0578,
      "step": 15964
    },
    {
      "epoch": 1.2406745414982903,
      "grad_norm": 0.1279022991657257,
      "learning_rate": 3.7966272925085485e-06,
      "loss": 0.1772,
      "step": 15965
    },
    {
      "epoch": 1.2407522536524713,
      "grad_norm": 0.4391647279262543,
      "learning_rate": 3.7962387317376443e-06,
      "loss": 0.1014,
      "step": 15966
    },
    {
      "epoch": 1.2408299658066522,
      "grad_norm": 0.48224663734436035,
      "learning_rate": 3.7958501709667393e-06,
      "loss": 0.2648,
      "step": 15967
    },
    {
      "epoch": 1.240907677960833,
      "grad_norm": 0.6710216999053955,
      "learning_rate": 3.7954616101958346e-06,
      "loss": 0.3089,
      "step": 15968
    },
    {
      "epoch": 1.240985390115014,
      "grad_norm": 0.9027460217475891,
      "learning_rate": 3.7950730494249304e-06,
      "loss": 0.5372,
      "step": 15969
    },
    {
      "epoch": 1.241063102269195,
      "grad_norm": 0.49973541498184204,
      "learning_rate": 3.794684488654026e-06,
      "loss": 0.1148,
      "step": 15970
    },
    {
      "epoch": 1.2411408144233758,
      "grad_norm": 0.3149569034576416,
      "learning_rate": 3.7942959278831208e-06,
      "loss": 0.0784,
      "step": 15971
    },
    {
      "epoch": 1.2412185265775568,
      "grad_norm": 0.6930220127105713,
      "learning_rate": 3.7939073671122166e-06,
      "loss": 0.2671,
      "step": 15972
    },
    {
      "epoch": 1.2412962387317377,
      "grad_norm": 0.5057494044303894,
      "learning_rate": 3.793518806341312e-06,
      "loss": 0.2787,
      "step": 15973
    },
    {
      "epoch": 1.2413739508859185,
      "grad_norm": 0.37412914633750916,
      "learning_rate": 3.7931302455704077e-06,
      "loss": 0.026,
      "step": 15974
    },
    {
      "epoch": 1.2414516630400994,
      "grad_norm": 0.2344008982181549,
      "learning_rate": 3.792741684799503e-06,
      "loss": 0.1274,
      "step": 15975
    },
    {
      "epoch": 1.2415293751942804,
      "grad_norm": 0.5144969820976257,
      "learning_rate": 3.792353124028598e-06,
      "loss": 0.1683,
      "step": 15976
    },
    {
      "epoch": 1.2416070873484613,
      "grad_norm": 0.18656103312969208,
      "learning_rate": 3.791964563257694e-06,
      "loss": 0.0593,
      "step": 15977
    },
    {
      "epoch": 1.241684799502642,
      "grad_norm": 1.0123038291931152,
      "learning_rate": 3.7915760024867892e-06,
      "loss": 0.538,
      "step": 15978
    },
    {
      "epoch": 1.2417625116568232,
      "grad_norm": 0.17207974195480347,
      "learning_rate": 3.7911874417158846e-06,
      "loss": 0.0707,
      "step": 15979
    },
    {
      "epoch": 1.241840223811004,
      "grad_norm": 1.5197150707244873,
      "learning_rate": 3.7907988809449804e-06,
      "loss": 0.633,
      "step": 15980
    },
    {
      "epoch": 1.2419179359651848,
      "grad_norm": 0.2560971677303314,
      "learning_rate": 3.7904103201740753e-06,
      "loss": 0.0613,
      "step": 15981
    },
    {
      "epoch": 1.241995648119366,
      "grad_norm": 0.3588773012161255,
      "learning_rate": 3.7900217594031707e-06,
      "loss": 0.0991,
      "step": 15982
    },
    {
      "epoch": 1.2420733602735468,
      "grad_norm": 0.6478620767593384,
      "learning_rate": 3.7896331986322665e-06,
      "loss": 0.2607,
      "step": 15983
    },
    {
      "epoch": 1.2421510724277276,
      "grad_norm": 0.44223693013191223,
      "learning_rate": 3.789244637861362e-06,
      "loss": 0.1854,
      "step": 15984
    },
    {
      "epoch": 1.2422287845819087,
      "grad_norm": 0.21700386703014374,
      "learning_rate": 3.788856077090457e-06,
      "loss": 0.0422,
      "step": 15985
    },
    {
      "epoch": 1.2423064967360895,
      "grad_norm": 0.5357879996299744,
      "learning_rate": 3.7884675163195526e-06,
      "loss": 0.1931,
      "step": 15986
    },
    {
      "epoch": 1.2423842088902703,
      "grad_norm": 1.445685863494873,
      "learning_rate": 3.788078955548648e-06,
      "loss": 0.2442,
      "step": 15987
    },
    {
      "epoch": 1.2424619210444514,
      "grad_norm": 0.1593388468027115,
      "learning_rate": 3.787690394777744e-06,
      "loss": 0.0388,
      "step": 15988
    },
    {
      "epoch": 1.2425396331986323,
      "grad_norm": 0.38660186529159546,
      "learning_rate": 3.787301834006839e-06,
      "loss": 0.1812,
      "step": 15989
    },
    {
      "epoch": 1.242617345352813,
      "grad_norm": 0.6953399181365967,
      "learning_rate": 3.786913273235934e-06,
      "loss": 0.25,
      "step": 15990
    },
    {
      "epoch": 1.2426950575069942,
      "grad_norm": 0.5990491509437561,
      "learning_rate": 3.78652471246503e-06,
      "loss": 0.3817,
      "step": 15991
    },
    {
      "epoch": 1.242772769661175,
      "grad_norm": 0.4358191192150116,
      "learning_rate": 3.7861361516941253e-06,
      "loss": 0.0741,
      "step": 15992
    },
    {
      "epoch": 1.2428504818153558,
      "grad_norm": 0.33709821105003357,
      "learning_rate": 3.7857475909232207e-06,
      "loss": 0.0585,
      "step": 15993
    },
    {
      "epoch": 1.242928193969537,
      "grad_norm": 0.24720734357833862,
      "learning_rate": 3.7853590301523165e-06,
      "loss": 0.056,
      "step": 15994
    },
    {
      "epoch": 1.2430059061237178,
      "grad_norm": 0.46566227078437805,
      "learning_rate": 3.7849704693814114e-06,
      "loss": 0.055,
      "step": 15995
    },
    {
      "epoch": 1.2430836182778986,
      "grad_norm": 0.4324204623699188,
      "learning_rate": 3.784581908610507e-06,
      "loss": 0.152,
      "step": 15996
    },
    {
      "epoch": 1.2431613304320797,
      "grad_norm": 0.8252202272415161,
      "learning_rate": 3.7841933478396026e-06,
      "loss": 0.1202,
      "step": 15997
    },
    {
      "epoch": 1.2432390425862605,
      "grad_norm": 0.5966752171516418,
      "learning_rate": 3.783804787068698e-06,
      "loss": 0.1142,
      "step": 15998
    },
    {
      "epoch": 1.2433167547404413,
      "grad_norm": 0.3671084940433502,
      "learning_rate": 3.783416226297793e-06,
      "loss": 0.1656,
      "step": 15999
    },
    {
      "epoch": 1.2433944668946224,
      "grad_norm": 0.17085862159729004,
      "learning_rate": 3.7830276655268887e-06,
      "loss": 0.0736,
      "step": 16000
    },
    {
      "epoch": 1.2434721790488033,
      "grad_norm": 0.29721227288246155,
      "learning_rate": 3.782639104755984e-06,
      "loss": 0.0679,
      "step": 16001
    },
    {
      "epoch": 1.243549891202984,
      "grad_norm": 0.16835041344165802,
      "learning_rate": 3.78225054398508e-06,
      "loss": 0.0189,
      "step": 16002
    },
    {
      "epoch": 1.2436276033571652,
      "grad_norm": 0.4864465892314911,
      "learning_rate": 3.7818619832141752e-06,
      "loss": 0.3572,
      "step": 16003
    },
    {
      "epoch": 1.243705315511346,
      "grad_norm": 0.9138994216918945,
      "learning_rate": 3.78147342244327e-06,
      "loss": 0.1222,
      "step": 16004
    },
    {
      "epoch": 1.2437830276655268,
      "grad_norm": 0.4781266748905182,
      "learning_rate": 3.781084861672366e-06,
      "loss": 0.225,
      "step": 16005
    },
    {
      "epoch": 1.243860739819708,
      "grad_norm": 0.15403269231319427,
      "learning_rate": 3.7806963009014614e-06,
      "loss": 0.0249,
      "step": 16006
    },
    {
      "epoch": 1.2439384519738887,
      "grad_norm": 0.24262449145317078,
      "learning_rate": 3.7803077401305567e-06,
      "loss": 0.0273,
      "step": 16007
    },
    {
      "epoch": 1.2440161641280696,
      "grad_norm": 0.4449632465839386,
      "learning_rate": 3.7799191793596525e-06,
      "loss": 0.0299,
      "step": 16008
    },
    {
      "epoch": 1.2440938762822507,
      "grad_norm": 0.7155775427818298,
      "learning_rate": 3.7795306185887475e-06,
      "loss": 0.1407,
      "step": 16009
    },
    {
      "epoch": 1.2441715884364315,
      "grad_norm": 0.5017245411872864,
      "learning_rate": 3.779142057817843e-06,
      "loss": 0.2053,
      "step": 16010
    },
    {
      "epoch": 1.2442493005906123,
      "grad_norm": 0.6084980368614197,
      "learning_rate": 3.7787534970469387e-06,
      "loss": 0.4185,
      "step": 16011
    },
    {
      "epoch": 1.2443270127447934,
      "grad_norm": 0.5498896837234497,
      "learning_rate": 3.778364936276034e-06,
      "loss": 0.3228,
      "step": 16012
    },
    {
      "epoch": 1.2444047248989742,
      "grad_norm": 0.20104841887950897,
      "learning_rate": 3.777976375505129e-06,
      "loss": 0.0301,
      "step": 16013
    },
    {
      "epoch": 1.244482437053155,
      "grad_norm": 0.3657169044017792,
      "learning_rate": 3.7775878147342248e-06,
      "loss": 0.5439,
      "step": 16014
    },
    {
      "epoch": 1.244560149207336,
      "grad_norm": 0.12456437200307846,
      "learning_rate": 3.77719925396332e-06,
      "loss": 0.0538,
      "step": 16015
    },
    {
      "epoch": 1.244637861361517,
      "grad_norm": 0.24651649594306946,
      "learning_rate": 3.7768106931924155e-06,
      "loss": 0.0636,
      "step": 16016
    },
    {
      "epoch": 1.2447155735156978,
      "grad_norm": 0.1746414452791214,
      "learning_rate": 3.7764221324215113e-06,
      "loss": 0.0178,
      "step": 16017
    },
    {
      "epoch": 1.2447932856698787,
      "grad_norm": 0.22412718832492828,
      "learning_rate": 3.7760335716506063e-06,
      "loss": 0.0559,
      "step": 16018
    },
    {
      "epoch": 1.2448709978240597,
      "grad_norm": 0.6868150234222412,
      "learning_rate": 3.775645010879702e-06,
      "loss": 0.1556,
      "step": 16019
    },
    {
      "epoch": 1.2449487099782406,
      "grad_norm": 0.19592635333538055,
      "learning_rate": 3.7752564501087974e-06,
      "loss": 0.0414,
      "step": 16020
    },
    {
      "epoch": 1.2450264221324214,
      "grad_norm": 0.41033124923706055,
      "learning_rate": 3.774867889337893e-06,
      "loss": 0.1334,
      "step": 16021
    },
    {
      "epoch": 1.2451041342866025,
      "grad_norm": 0.24884139001369476,
      "learning_rate": 3.774479328566988e-06,
      "loss": 0.095,
      "step": 16022
    },
    {
      "epoch": 1.2451818464407833,
      "grad_norm": 0.4661427438259125,
      "learning_rate": 3.7740907677960836e-06,
      "loss": 0.1267,
      "step": 16023
    },
    {
      "epoch": 1.2452595585949642,
      "grad_norm": 0.18986690044403076,
      "learning_rate": 3.773702207025179e-06,
      "loss": 0.0526,
      "step": 16024
    },
    {
      "epoch": 1.2453372707491452,
      "grad_norm": 0.20826634764671326,
      "learning_rate": 3.7733136462542747e-06,
      "loss": 0.1309,
      "step": 16025
    },
    {
      "epoch": 1.245414982903326,
      "grad_norm": 0.18957865238189697,
      "learning_rate": 3.7729250854833697e-06,
      "loss": 0.0224,
      "step": 16026
    },
    {
      "epoch": 1.245492695057507,
      "grad_norm": 0.4675954282283783,
      "learning_rate": 3.772536524712465e-06,
      "loss": 0.1343,
      "step": 16027
    },
    {
      "epoch": 1.245570407211688,
      "grad_norm": 0.33171331882476807,
      "learning_rate": 3.772147963941561e-06,
      "loss": 0.1169,
      "step": 16028
    },
    {
      "epoch": 1.2456481193658688,
      "grad_norm": 0.7505068778991699,
      "learning_rate": 3.7717594031706562e-06,
      "loss": 0.4673,
      "step": 16029
    },
    {
      "epoch": 1.2457258315200497,
      "grad_norm": 0.3218318819999695,
      "learning_rate": 3.771370842399751e-06,
      "loss": 0.1646,
      "step": 16030
    },
    {
      "epoch": 1.2458035436742307,
      "grad_norm": 0.633805513381958,
      "learning_rate": 3.770982281628847e-06,
      "loss": 0.6896,
      "step": 16031
    },
    {
      "epoch": 1.2458812558284116,
      "grad_norm": 0.7876388430595398,
      "learning_rate": 3.7705937208579423e-06,
      "loss": 0.1852,
      "step": 16032
    },
    {
      "epoch": 1.2459589679825924,
      "grad_norm": 0.7244792580604553,
      "learning_rate": 3.770205160087038e-06,
      "loss": 0.1555,
      "step": 16033
    },
    {
      "epoch": 1.2460366801367733,
      "grad_norm": 5.6601152420043945,
      "learning_rate": 3.7698165993161335e-06,
      "loss": 0.9336,
      "step": 16034
    },
    {
      "epoch": 1.2461143922909543,
      "grad_norm": 0.18532772362232208,
      "learning_rate": 3.7694280385452285e-06,
      "loss": 0.1286,
      "step": 16035
    },
    {
      "epoch": 1.2461921044451352,
      "grad_norm": 0.4962770938873291,
      "learning_rate": 3.7690394777743243e-06,
      "loss": 0.2466,
      "step": 16036
    },
    {
      "epoch": 1.246269816599316,
      "grad_norm": 0.12122324854135513,
      "learning_rate": 3.7686509170034196e-06,
      "loss": 0.0262,
      "step": 16037
    },
    {
      "epoch": 1.246347528753497,
      "grad_norm": 0.38131242990493774,
      "learning_rate": 3.768262356232515e-06,
      "loss": 0.1877,
      "step": 16038
    },
    {
      "epoch": 1.246425240907678,
      "grad_norm": 0.5650874376296997,
      "learning_rate": 3.767873795461611e-06,
      "loss": 0.2218,
      "step": 16039
    },
    {
      "epoch": 1.2465029530618588,
      "grad_norm": 0.395677387714386,
      "learning_rate": 3.7674852346907058e-06,
      "loss": 0.0459,
      "step": 16040
    },
    {
      "epoch": 1.2465806652160398,
      "grad_norm": 0.45075562596321106,
      "learning_rate": 3.767096673919801e-06,
      "loss": 0.1676,
      "step": 16041
    },
    {
      "epoch": 1.2466583773702207,
      "grad_norm": 0.7727674841880798,
      "learning_rate": 3.766708113148897e-06,
      "loss": 0.7461,
      "step": 16042
    },
    {
      "epoch": 1.2467360895244015,
      "grad_norm": 0.2652856409549713,
      "learning_rate": 3.7663195523779923e-06,
      "loss": 0.0262,
      "step": 16043
    },
    {
      "epoch": 1.2468138016785826,
      "grad_norm": 0.5331559777259827,
      "learning_rate": 3.7659309916070872e-06,
      "loss": 0.2352,
      "step": 16044
    },
    {
      "epoch": 1.2468915138327634,
      "grad_norm": 0.3344183564186096,
      "learning_rate": 3.765542430836183e-06,
      "loss": 0.0801,
      "step": 16045
    },
    {
      "epoch": 1.2469692259869443,
      "grad_norm": 0.5397510528564453,
      "learning_rate": 3.7651538700652784e-06,
      "loss": 0.4798,
      "step": 16046
    },
    {
      "epoch": 1.2470469381411253,
      "grad_norm": 0.3748696744441986,
      "learning_rate": 3.764765309294374e-06,
      "loss": 0.1867,
      "step": 16047
    },
    {
      "epoch": 1.2471246502953062,
      "grad_norm": 0.28963762521743774,
      "learning_rate": 3.7643767485234696e-06,
      "loss": 0.0791,
      "step": 16048
    },
    {
      "epoch": 1.247202362449487,
      "grad_norm": 0.10801369696855545,
      "learning_rate": 3.7639881877525645e-06,
      "loss": 0.0186,
      "step": 16049
    },
    {
      "epoch": 1.247280074603668,
      "grad_norm": 0.44499748945236206,
      "learning_rate": 3.7635996269816603e-06,
      "loss": 0.1856,
      "step": 16050
    },
    {
      "epoch": 1.247357786757849,
      "grad_norm": 0.13418951630592346,
      "learning_rate": 3.7632110662107557e-06,
      "loss": 0.0194,
      "step": 16051
    },
    {
      "epoch": 1.2474354989120298,
      "grad_norm": 0.7020623087882996,
      "learning_rate": 3.762822505439851e-06,
      "loss": 0.2162,
      "step": 16052
    },
    {
      "epoch": 1.2475132110662108,
      "grad_norm": 0.3416838049888611,
      "learning_rate": 3.762433944668947e-06,
      "loss": 0.264,
      "step": 16053
    },
    {
      "epoch": 1.2475909232203917,
      "grad_norm": 0.5071671009063721,
      "learning_rate": 3.762045383898042e-06,
      "loss": 0.1201,
      "step": 16054
    },
    {
      "epoch": 1.2476686353745725,
      "grad_norm": 0.3023887574672699,
      "learning_rate": 3.761656823127137e-06,
      "loss": 0.1355,
      "step": 16055
    },
    {
      "epoch": 1.2477463475287536,
      "grad_norm": 0.44223323464393616,
      "learning_rate": 3.761268262356233e-06,
      "loss": 0.1438,
      "step": 16056
    },
    {
      "epoch": 1.2478240596829344,
      "grad_norm": 0.47622591257095337,
      "learning_rate": 3.7608797015853284e-06,
      "loss": 0.0596,
      "step": 16057
    },
    {
      "epoch": 1.2479017718371153,
      "grad_norm": 0.14278408885002136,
      "learning_rate": 3.7604911408144233e-06,
      "loss": 0.0245,
      "step": 16058
    },
    {
      "epoch": 1.2479794839912963,
      "grad_norm": 0.3543843626976013,
      "learning_rate": 3.760102580043519e-06,
      "loss": 0.1393,
      "step": 16059
    },
    {
      "epoch": 1.2480571961454772,
      "grad_norm": 0.3989425599575043,
      "learning_rate": 3.7597140192726145e-06,
      "loss": 0.0893,
      "step": 16060
    },
    {
      "epoch": 1.248134908299658,
      "grad_norm": 0.5221758484840393,
      "learning_rate": 3.75932545850171e-06,
      "loss": 0.1436,
      "step": 16061
    },
    {
      "epoch": 1.248212620453839,
      "grad_norm": 0.6796210408210754,
      "learning_rate": 3.7589368977308057e-06,
      "loss": 0.6814,
      "step": 16062
    },
    {
      "epoch": 1.24829033260802,
      "grad_norm": 0.5061790943145752,
      "learning_rate": 3.7585483369599006e-06,
      "loss": 0.1526,
      "step": 16063
    },
    {
      "epoch": 1.2483680447622008,
      "grad_norm": 0.15257105231285095,
      "learning_rate": 3.7581597761889964e-06,
      "loss": 0.0227,
      "step": 16064
    },
    {
      "epoch": 1.2484457569163818,
      "grad_norm": 0.6783819198608398,
      "learning_rate": 3.7577712154180918e-06,
      "loss": 0.2647,
      "step": 16065
    },
    {
      "epoch": 1.2485234690705627,
      "grad_norm": 0.41707107424736023,
      "learning_rate": 3.757382654647187e-06,
      "loss": 0.2056,
      "step": 16066
    },
    {
      "epoch": 1.2486011812247435,
      "grad_norm": 0.7754527926445007,
      "learning_rate": 3.756994093876283e-06,
      "loss": 0.1961,
      "step": 16067
    },
    {
      "epoch": 1.2486788933789246,
      "grad_norm": 0.8656104803085327,
      "learning_rate": 3.756605533105378e-06,
      "loss": 0.4139,
      "step": 16068
    },
    {
      "epoch": 1.2487566055331054,
      "grad_norm": 0.5273576974868774,
      "learning_rate": 3.7562169723344733e-06,
      "loss": 0.2122,
      "step": 16069
    },
    {
      "epoch": 1.2488343176872863,
      "grad_norm": 0.48722949624061584,
      "learning_rate": 3.755828411563569e-06,
      "loss": 0.1827,
      "step": 16070
    },
    {
      "epoch": 1.2489120298414673,
      "grad_norm": 0.30504539608955383,
      "learning_rate": 3.7554398507926644e-06,
      "loss": 0.0477,
      "step": 16071
    },
    {
      "epoch": 1.2489897419956482,
      "grad_norm": 0.5492797493934631,
      "learning_rate": 3.7550512900217594e-06,
      "loss": 0.4745,
      "step": 16072
    },
    {
      "epoch": 1.249067454149829,
      "grad_norm": 0.4312902092933655,
      "learning_rate": 3.754662729250855e-06,
      "loss": 0.124,
      "step": 16073
    },
    {
      "epoch": 1.24914516630401,
      "grad_norm": 0.26834022998809814,
      "learning_rate": 3.7542741684799506e-06,
      "loss": 0.0469,
      "step": 16074
    },
    {
      "epoch": 1.249222878458191,
      "grad_norm": 0.5711110234260559,
      "learning_rate": 3.753885607709046e-06,
      "loss": 0.0788,
      "step": 16075
    },
    {
      "epoch": 1.2493005906123718,
      "grad_norm": 1.0834299325942993,
      "learning_rate": 3.7534970469381417e-06,
      "loss": 0.535,
      "step": 16076
    },
    {
      "epoch": 1.2493783027665526,
      "grad_norm": 0.6643171310424805,
      "learning_rate": 3.7531084861672367e-06,
      "loss": 0.0806,
      "step": 16077
    },
    {
      "epoch": 1.2494560149207337,
      "grad_norm": 0.8991466760635376,
      "learning_rate": 3.7527199253963325e-06,
      "loss": 0.4521,
      "step": 16078
    },
    {
      "epoch": 1.2495337270749145,
      "grad_norm": 0.4748627245426178,
      "learning_rate": 3.752331364625428e-06,
      "loss": 0.2494,
      "step": 16079
    },
    {
      "epoch": 1.2496114392290953,
      "grad_norm": 0.30058130621910095,
      "learning_rate": 3.7519428038545232e-06,
      "loss": 0.1676,
      "step": 16080
    },
    {
      "epoch": 1.2496891513832764,
      "grad_norm": 0.20014651119709015,
      "learning_rate": 3.751554243083619e-06,
      "loss": 0.0315,
      "step": 16081
    },
    {
      "epoch": 1.2497668635374573,
      "grad_norm": 0.14899177849292755,
      "learning_rate": 3.751165682312714e-06,
      "loss": 0.0201,
      "step": 16082
    },
    {
      "epoch": 1.249844575691638,
      "grad_norm": 0.8924736380577087,
      "learning_rate": 3.7507771215418093e-06,
      "loss": 0.3529,
      "step": 16083
    },
    {
      "epoch": 1.2499222878458192,
      "grad_norm": 0.31687694787979126,
      "learning_rate": 3.750388560770905e-06,
      "loss": 0.3289,
      "step": 16084
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.3454227149486542,
      "learning_rate": 3.7500000000000005e-06,
      "loss": 0.1338,
      "step": 16085
    },
    {
      "epoch": 1.2500777121541808,
      "grad_norm": 0.09086698293685913,
      "learning_rate": 3.7496114392290955e-06,
      "loss": 0.0093,
      "step": 16086
    },
    {
      "epoch": 1.250155424308362,
      "grad_norm": 0.1414971500635147,
      "learning_rate": 3.7492228784581913e-06,
      "loss": 0.0192,
      "step": 16087
    },
    {
      "epoch": 1.2502331364625427,
      "grad_norm": 0.4734797775745392,
      "learning_rate": 3.7488343176872866e-06,
      "loss": 0.1351,
      "step": 16088
    },
    {
      "epoch": 1.2503108486167236,
      "grad_norm": 1.0118387937545776,
      "learning_rate": 3.7484457569163816e-06,
      "loss": 0.6673,
      "step": 16089
    },
    {
      "epoch": 1.2503885607709044,
      "grad_norm": 0.3686717450618744,
      "learning_rate": 3.7480571961454774e-06,
      "loss": 0.1038,
      "step": 16090
    },
    {
      "epoch": 1.2504662729250855,
      "grad_norm": 0.21084563434123993,
      "learning_rate": 3.7476686353745728e-06,
      "loss": 0.1569,
      "step": 16091
    },
    {
      "epoch": 1.2505439850792663,
      "grad_norm": 0.18952910602092743,
      "learning_rate": 3.747280074603668e-06,
      "loss": 0.1123,
      "step": 16092
    },
    {
      "epoch": 1.2506216972334472,
      "grad_norm": 0.15381260216236115,
      "learning_rate": 3.746891513832764e-06,
      "loss": 0.0127,
      "step": 16093
    },
    {
      "epoch": 1.2506994093876282,
      "grad_norm": 0.26856499910354614,
      "learning_rate": 3.746502953061859e-06,
      "loss": 0.0674,
      "step": 16094
    },
    {
      "epoch": 1.250777121541809,
      "grad_norm": 0.45300185680389404,
      "learning_rate": 3.7461143922909547e-06,
      "loss": 0.1402,
      "step": 16095
    },
    {
      "epoch": 1.25085483369599,
      "grad_norm": 0.5707677602767944,
      "learning_rate": 3.74572583152005e-06,
      "loss": 0.1703,
      "step": 16096
    },
    {
      "epoch": 1.250932545850171,
      "grad_norm": 2.4970498085021973,
      "learning_rate": 3.7453372707491454e-06,
      "loss": 0.4492,
      "step": 16097
    },
    {
      "epoch": 1.2510102580043518,
      "grad_norm": 0.6255019903182983,
      "learning_rate": 3.7449487099782412e-06,
      "loss": 0.2691,
      "step": 16098
    },
    {
      "epoch": 1.2510879701585327,
      "grad_norm": 0.35029762983322144,
      "learning_rate": 3.744560149207336e-06,
      "loss": 0.0942,
      "step": 16099
    },
    {
      "epoch": 1.2511656823127137,
      "grad_norm": 0.507758378982544,
      "learning_rate": 3.7441715884364315e-06,
      "loss": 0.27,
      "step": 16100
    },
    {
      "epoch": 1.2512433944668946,
      "grad_norm": 0.1886453479528427,
      "learning_rate": 3.7437830276655273e-06,
      "loss": 0.0417,
      "step": 16101
    },
    {
      "epoch": 1.2513211066210754,
      "grad_norm": 0.25780972838401794,
      "learning_rate": 3.7433944668946227e-06,
      "loss": 0.0375,
      "step": 16102
    },
    {
      "epoch": 1.2513988187752565,
      "grad_norm": 0.25770246982574463,
      "learning_rate": 3.7430059061237177e-06,
      "loss": 0.0442,
      "step": 16103
    },
    {
      "epoch": 1.2514765309294373,
      "grad_norm": 0.7509999871253967,
      "learning_rate": 3.7426173453528135e-06,
      "loss": 0.0624,
      "step": 16104
    },
    {
      "epoch": 1.2515542430836182,
      "grad_norm": 1.0554707050323486,
      "learning_rate": 3.742228784581909e-06,
      "loss": 0.2518,
      "step": 16105
    },
    {
      "epoch": 1.2516319552377992,
      "grad_norm": 0.0371999517083168,
      "learning_rate": 3.741840223811004e-06,
      "loss": 0.0051,
      "step": 16106
    },
    {
      "epoch": 1.25170966739198,
      "grad_norm": 0.8005420565605164,
      "learning_rate": 3.7414516630401e-06,
      "loss": 0.7347,
      "step": 16107
    },
    {
      "epoch": 1.251787379546161,
      "grad_norm": 0.17613822221755981,
      "learning_rate": 3.741063102269195e-06,
      "loss": 0.0214,
      "step": 16108
    },
    {
      "epoch": 1.251865091700342,
      "grad_norm": 0.1439451426267624,
      "learning_rate": 3.7406745414982907e-06,
      "loss": 0.0315,
      "step": 16109
    },
    {
      "epoch": 1.2519428038545228,
      "grad_norm": 0.33827096223831177,
      "learning_rate": 3.740285980727386e-06,
      "loss": 0.1058,
      "step": 16110
    },
    {
      "epoch": 1.2520205160087037,
      "grad_norm": 0.19413194060325623,
      "learning_rate": 3.7398974199564815e-06,
      "loss": 0.0623,
      "step": 16111
    },
    {
      "epoch": 1.2520982281628847,
      "grad_norm": 0.7704207897186279,
      "learning_rate": 3.7395088591855773e-06,
      "loss": 0.477,
      "step": 16112
    },
    {
      "epoch": 1.2521759403170656,
      "grad_norm": 0.11840081959962845,
      "learning_rate": 3.7391202984146722e-06,
      "loss": 0.0511,
      "step": 16113
    },
    {
      "epoch": 1.2522536524712464,
      "grad_norm": 0.21060438454151154,
      "learning_rate": 3.7387317376437676e-06,
      "loss": 0.0135,
      "step": 16114
    },
    {
      "epoch": 1.2523313646254275,
      "grad_norm": 0.3180293142795563,
      "learning_rate": 3.7383431768728634e-06,
      "loss": 0.3272,
      "step": 16115
    },
    {
      "epoch": 1.2524090767796083,
      "grad_norm": 0.13509291410446167,
      "learning_rate": 3.7379546161019588e-06,
      "loss": 0.0593,
      "step": 16116
    },
    {
      "epoch": 1.2524867889337892,
      "grad_norm": 0.8112946152687073,
      "learning_rate": 3.7375660553310537e-06,
      "loss": 0.6627,
      "step": 16117
    },
    {
      "epoch": 1.2525645010879702,
      "grad_norm": 0.7016428709030151,
      "learning_rate": 3.7371774945601495e-06,
      "loss": 0.2004,
      "step": 16118
    },
    {
      "epoch": 1.252642213242151,
      "grad_norm": 0.2491750568151474,
      "learning_rate": 3.736788933789245e-06,
      "loss": 0.045,
      "step": 16119
    },
    {
      "epoch": 1.252719925396332,
      "grad_norm": 0.14450392127037048,
      "learning_rate": 3.7364003730183403e-06,
      "loss": 0.0395,
      "step": 16120
    },
    {
      "epoch": 1.252797637550513,
      "grad_norm": 0.17426277697086334,
      "learning_rate": 3.736011812247436e-06,
      "loss": 0.0432,
      "step": 16121
    },
    {
      "epoch": 1.2528753497046938,
      "grad_norm": 0.3665342330932617,
      "learning_rate": 3.735623251476531e-06,
      "loss": 0.2178,
      "step": 16122
    },
    {
      "epoch": 1.2529530618588747,
      "grad_norm": 0.3556099534034729,
      "learning_rate": 3.735234690705627e-06,
      "loss": 0.0443,
      "step": 16123
    },
    {
      "epoch": 1.2530307740130557,
      "grad_norm": 0.6097651720046997,
      "learning_rate": 3.734846129934722e-06,
      "loss": 0.2034,
      "step": 16124
    },
    {
      "epoch": 1.2531084861672366,
      "grad_norm": 0.7013853192329407,
      "learning_rate": 3.7344575691638176e-06,
      "loss": 0.5642,
      "step": 16125
    },
    {
      "epoch": 1.2531861983214174,
      "grad_norm": 0.14142945408821106,
      "learning_rate": 3.7340690083929134e-06,
      "loss": 0.0104,
      "step": 16126
    },
    {
      "epoch": 1.2532639104755985,
      "grad_norm": 0.6818057894706726,
      "learning_rate": 3.7336804476220083e-06,
      "loss": 0.4637,
      "step": 16127
    },
    {
      "epoch": 1.2533416226297793,
      "grad_norm": 0.6539938449859619,
      "learning_rate": 3.7332918868511037e-06,
      "loss": 0.225,
      "step": 16128
    },
    {
      "epoch": 1.2534193347839602,
      "grad_norm": 0.34406015276908875,
      "learning_rate": 3.7329033260801995e-06,
      "loss": 0.1614,
      "step": 16129
    },
    {
      "epoch": 1.2534970469381412,
      "grad_norm": 0.7846060395240784,
      "learning_rate": 3.732514765309295e-06,
      "loss": 0.7855,
      "step": 16130
    },
    {
      "epoch": 1.253574759092322,
      "grad_norm": 0.7866862416267395,
      "learning_rate": 3.73212620453839e-06,
      "loss": 0.2687,
      "step": 16131
    },
    {
      "epoch": 1.253652471246503,
      "grad_norm": 0.8597371578216553,
      "learning_rate": 3.7317376437674856e-06,
      "loss": 0.2657,
      "step": 16132
    },
    {
      "epoch": 1.253730183400684,
      "grad_norm": 0.7863361239433289,
      "learning_rate": 3.731349082996581e-06,
      "loss": 0.2562,
      "step": 16133
    },
    {
      "epoch": 1.2538078955548648,
      "grad_norm": 1.0222972631454468,
      "learning_rate": 3.7309605222256764e-06,
      "loss": 0.6961,
      "step": 16134
    },
    {
      "epoch": 1.2538856077090457,
      "grad_norm": 0.45390647649765015,
      "learning_rate": 3.730571961454772e-06,
      "loss": 0.0696,
      "step": 16135
    },
    {
      "epoch": 1.2539633198632267,
      "grad_norm": 0.3536246716976166,
      "learning_rate": 3.730183400683867e-06,
      "loss": 0.1099,
      "step": 16136
    },
    {
      "epoch": 1.2540410320174076,
      "grad_norm": 0.6992138028144836,
      "learning_rate": 3.7297948399129625e-06,
      "loss": 0.3747,
      "step": 16137
    },
    {
      "epoch": 1.2541187441715884,
      "grad_norm": 0.15347254276275635,
      "learning_rate": 3.7294062791420583e-06,
      "loss": 0.0559,
      "step": 16138
    },
    {
      "epoch": 1.2541964563257695,
      "grad_norm": 0.3547450304031372,
      "learning_rate": 3.7290177183711536e-06,
      "loss": 0.1103,
      "step": 16139
    },
    {
      "epoch": 1.2542741684799503,
      "grad_norm": 0.21438314020633698,
      "learning_rate": 3.7286291576002494e-06,
      "loss": 0.1038,
      "step": 16140
    },
    {
      "epoch": 1.2543518806341312,
      "grad_norm": 0.21794700622558594,
      "learning_rate": 3.7282405968293444e-06,
      "loss": 0.0273,
      "step": 16141
    },
    {
      "epoch": 1.254429592788312,
      "grad_norm": 0.7557331323623657,
      "learning_rate": 3.7278520360584398e-06,
      "loss": 0.2651,
      "step": 16142
    },
    {
      "epoch": 1.254507304942493,
      "grad_norm": 0.3013114035129547,
      "learning_rate": 3.7274634752875356e-06,
      "loss": 0.0435,
      "step": 16143
    },
    {
      "epoch": 1.254585017096674,
      "grad_norm": 0.3557254672050476,
      "learning_rate": 3.727074914516631e-06,
      "loss": 0.0892,
      "step": 16144
    },
    {
      "epoch": 1.2546627292508548,
      "grad_norm": 0.16132983565330505,
      "learning_rate": 3.726686353745726e-06,
      "loss": 0.0586,
      "step": 16145
    },
    {
      "epoch": 1.2547404414050358,
      "grad_norm": 0.5697903037071228,
      "learning_rate": 3.7262977929748217e-06,
      "loss": 0.0739,
      "step": 16146
    },
    {
      "epoch": 1.2548181535592167,
      "grad_norm": 0.7536656856536865,
      "learning_rate": 3.725909232203917e-06,
      "loss": 0.3405,
      "step": 16147
    },
    {
      "epoch": 1.2548958657133975,
      "grad_norm": 2.3894875049591064,
      "learning_rate": 3.7255206714330124e-06,
      "loss": 0.6022,
      "step": 16148
    },
    {
      "epoch": 1.2549735778675786,
      "grad_norm": 0.5480166077613831,
      "learning_rate": 3.725132110662108e-06,
      "loss": 0.1202,
      "step": 16149
    },
    {
      "epoch": 1.2550512900217594,
      "grad_norm": 0.3653755784034729,
      "learning_rate": 3.724743549891203e-06,
      "loss": 0.1304,
      "step": 16150
    },
    {
      "epoch": 1.2551290021759403,
      "grad_norm": 0.6826158761978149,
      "learning_rate": 3.7243549891202985e-06,
      "loss": 0.1219,
      "step": 16151
    },
    {
      "epoch": 1.255206714330121,
      "grad_norm": 0.7783101201057434,
      "learning_rate": 3.7239664283493943e-06,
      "loss": 0.406,
      "step": 16152
    },
    {
      "epoch": 1.2552844264843022,
      "grad_norm": 0.268664687871933,
      "learning_rate": 3.7235778675784893e-06,
      "loss": 0.054,
      "step": 16153
    },
    {
      "epoch": 1.255362138638483,
      "grad_norm": 0.37405455112457275,
      "learning_rate": 3.723189306807585e-06,
      "loss": 0.1001,
      "step": 16154
    },
    {
      "epoch": 1.2554398507926638,
      "grad_norm": 0.18953783810138702,
      "learning_rate": 3.7228007460366805e-06,
      "loss": 0.0312,
      "step": 16155
    },
    {
      "epoch": 1.255517562946845,
      "grad_norm": 0.46416711807250977,
      "learning_rate": 3.722412185265776e-06,
      "loss": 0.0964,
      "step": 16156
    },
    {
      "epoch": 1.2555952751010258,
      "grad_norm": 0.9100532531738281,
      "learning_rate": 3.7220236244948716e-06,
      "loss": 0.3777,
      "step": 16157
    },
    {
      "epoch": 1.2556729872552066,
      "grad_norm": 0.24008266627788544,
      "learning_rate": 3.7216350637239666e-06,
      "loss": 0.0591,
      "step": 16158
    },
    {
      "epoch": 1.2557506994093877,
      "grad_norm": 0.5402787923812866,
      "learning_rate": 3.721246502953062e-06,
      "loss": 0.3962,
      "step": 16159
    },
    {
      "epoch": 1.2558284115635685,
      "grad_norm": 0.2793005704879761,
      "learning_rate": 3.7208579421821578e-06,
      "loss": 0.1077,
      "step": 16160
    },
    {
      "epoch": 1.2559061237177493,
      "grad_norm": 0.5210620164871216,
      "learning_rate": 3.720469381411253e-06,
      "loss": 0.0888,
      "step": 16161
    },
    {
      "epoch": 1.2559838358719304,
      "grad_norm": 0.198180690407753,
      "learning_rate": 3.720080820640348e-06,
      "loss": 0.0134,
      "step": 16162
    },
    {
      "epoch": 1.2560615480261113,
      "grad_norm": 0.6158397793769836,
      "learning_rate": 3.719692259869444e-06,
      "loss": 0.1323,
      "step": 16163
    },
    {
      "epoch": 1.256139260180292,
      "grad_norm": 0.7382529377937317,
      "learning_rate": 3.7193036990985392e-06,
      "loss": 0.0708,
      "step": 16164
    },
    {
      "epoch": 1.2562169723344732,
      "grad_norm": 0.22701871395111084,
      "learning_rate": 3.7189151383276346e-06,
      "loss": 0.0565,
      "step": 16165
    },
    {
      "epoch": 1.256294684488654,
      "grad_norm": 0.4954301416873932,
      "learning_rate": 3.7185265775567304e-06,
      "loss": 0.1028,
      "step": 16166
    },
    {
      "epoch": 1.2563723966428348,
      "grad_norm": 0.3248370289802551,
      "learning_rate": 3.7181380167858254e-06,
      "loss": 0.1461,
      "step": 16167
    },
    {
      "epoch": 1.256450108797016,
      "grad_norm": 0.25220662355422974,
      "learning_rate": 3.7177494560149207e-06,
      "loss": 0.0796,
      "step": 16168
    },
    {
      "epoch": 1.2565278209511967,
      "grad_norm": 0.45431527495384216,
      "learning_rate": 3.7173608952440165e-06,
      "loss": 0.188,
      "step": 16169
    },
    {
      "epoch": 1.2566055331053776,
      "grad_norm": 0.33902230858802795,
      "learning_rate": 3.716972334473112e-06,
      "loss": 0.0614,
      "step": 16170
    },
    {
      "epoch": 1.2566832452595587,
      "grad_norm": 0.2295777052640915,
      "learning_rate": 3.7165837737022077e-06,
      "loss": 0.1058,
      "step": 16171
    },
    {
      "epoch": 1.2567609574137395,
      "grad_norm": 0.23253531754016876,
      "learning_rate": 3.7161952129313027e-06,
      "loss": 0.0556,
      "step": 16172
    },
    {
      "epoch": 1.2568386695679203,
      "grad_norm": 0.17517247796058655,
      "learning_rate": 3.715806652160398e-06,
      "loss": 0.0557,
      "step": 16173
    },
    {
      "epoch": 1.2569163817221014,
      "grad_norm": 0.30556726455688477,
      "learning_rate": 3.715418091389494e-06,
      "loss": 0.1257,
      "step": 16174
    },
    {
      "epoch": 1.2569940938762822,
      "grad_norm": 0.13760647177696228,
      "learning_rate": 3.715029530618589e-06,
      "loss": 0.0401,
      "step": 16175
    },
    {
      "epoch": 1.257071806030463,
      "grad_norm": 0.21377001702785492,
      "learning_rate": 3.714640969847684e-06,
      "loss": 0.0822,
      "step": 16176
    },
    {
      "epoch": 1.2571495181846442,
      "grad_norm": 0.32242897152900696,
      "learning_rate": 3.71425240907678e-06,
      "loss": 0.1337,
      "step": 16177
    },
    {
      "epoch": 1.257227230338825,
      "grad_norm": 0.6295796036720276,
      "learning_rate": 3.7138638483058753e-06,
      "loss": 0.1228,
      "step": 16178
    },
    {
      "epoch": 1.2573049424930058,
      "grad_norm": 0.14594127237796783,
      "learning_rate": 3.7134752875349707e-06,
      "loss": 0.0457,
      "step": 16179
    },
    {
      "epoch": 1.257382654647187,
      "grad_norm": 0.44335415959358215,
      "learning_rate": 3.7130867267640665e-06,
      "loss": 0.1159,
      "step": 16180
    },
    {
      "epoch": 1.2574603668013677,
      "grad_norm": 0.6012243032455444,
      "learning_rate": 3.7126981659931614e-06,
      "loss": 0.2435,
      "step": 16181
    },
    {
      "epoch": 1.2575380789555486,
      "grad_norm": 1.0784127712249756,
      "learning_rate": 3.712309605222257e-06,
      "loss": 0.3568,
      "step": 16182
    },
    {
      "epoch": 1.2576157911097297,
      "grad_norm": 0.2738111913204193,
      "learning_rate": 3.7119210444513526e-06,
      "loss": 0.0826,
      "step": 16183
    },
    {
      "epoch": 1.2576935032639105,
      "grad_norm": 0.173334538936615,
      "learning_rate": 3.711532483680448e-06,
      "loss": 0.0502,
      "step": 16184
    },
    {
      "epoch": 1.2577712154180913,
      "grad_norm": 0.8957527279853821,
      "learning_rate": 3.7111439229095438e-06,
      "loss": 0.3826,
      "step": 16185
    },
    {
      "epoch": 1.2578489275722724,
      "grad_norm": 0.5632747411727905,
      "learning_rate": 3.7107553621386387e-06,
      "loss": 0.5688,
      "step": 16186
    },
    {
      "epoch": 1.2579266397264532,
      "grad_norm": 0.22358685731887817,
      "learning_rate": 3.710366801367734e-06,
      "loss": 0.1077,
      "step": 16187
    },
    {
      "epoch": 1.258004351880634,
      "grad_norm": 0.20713575184345245,
      "learning_rate": 3.70997824059683e-06,
      "loss": 0.1063,
      "step": 16188
    },
    {
      "epoch": 1.2580820640348152,
      "grad_norm": 0.659397542476654,
      "learning_rate": 3.7095896798259253e-06,
      "loss": 0.1091,
      "step": 16189
    },
    {
      "epoch": 1.258159776188996,
      "grad_norm": 0.14710016548633575,
      "learning_rate": 3.7092011190550202e-06,
      "loss": 0.0217,
      "step": 16190
    },
    {
      "epoch": 1.2582374883431768,
      "grad_norm": 0.2324647605419159,
      "learning_rate": 3.708812558284116e-06,
      "loss": 0.0338,
      "step": 16191
    },
    {
      "epoch": 1.258315200497358,
      "grad_norm": 0.4095633625984192,
      "learning_rate": 3.7084239975132114e-06,
      "loss": 0.0811,
      "step": 16192
    },
    {
      "epoch": 1.2583929126515387,
      "grad_norm": 0.21329471468925476,
      "learning_rate": 3.7080354367423068e-06,
      "loss": 0.099,
      "step": 16193
    },
    {
      "epoch": 1.2584706248057196,
      "grad_norm": 0.19165679812431335,
      "learning_rate": 3.7076468759714026e-06,
      "loss": 0.0175,
      "step": 16194
    },
    {
      "epoch": 1.2585483369599006,
      "grad_norm": 0.5660510063171387,
      "learning_rate": 3.7072583152004975e-06,
      "loss": 0.0848,
      "step": 16195
    },
    {
      "epoch": 1.2586260491140815,
      "grad_norm": 0.8356900811195374,
      "learning_rate": 3.706869754429593e-06,
      "loss": 0.1024,
      "step": 16196
    },
    {
      "epoch": 1.2587037612682623,
      "grad_norm": 0.23472073674201965,
      "learning_rate": 3.7064811936586887e-06,
      "loss": 0.054,
      "step": 16197
    },
    {
      "epoch": 1.2587814734224434,
      "grad_norm": 0.32285821437835693,
      "learning_rate": 3.706092632887784e-06,
      "loss": 0.1436,
      "step": 16198
    },
    {
      "epoch": 1.2588591855766242,
      "grad_norm": 0.41211608052253723,
      "learning_rate": 3.70570407211688e-06,
      "loss": 0.1409,
      "step": 16199
    },
    {
      "epoch": 1.258936897730805,
      "grad_norm": 0.7780632376670837,
      "learning_rate": 3.705315511345975e-06,
      "loss": 0.3739,
      "step": 16200
    },
    {
      "epoch": 1.2590146098849861,
      "grad_norm": 0.8004890084266663,
      "learning_rate": 3.70492695057507e-06,
      "loss": 0.5565,
      "step": 16201
    },
    {
      "epoch": 1.259092322039167,
      "grad_norm": 0.41405656933784485,
      "learning_rate": 3.704538389804166e-06,
      "loss": 0.2871,
      "step": 16202
    },
    {
      "epoch": 1.2591700341933478,
      "grad_norm": 0.45995283126831055,
      "learning_rate": 3.7041498290332613e-06,
      "loss": 0.4881,
      "step": 16203
    },
    {
      "epoch": 1.2592477463475287,
      "grad_norm": 0.33830368518829346,
      "learning_rate": 3.7037612682623563e-06,
      "loss": 0.0373,
      "step": 16204
    },
    {
      "epoch": 1.2593254585017097,
      "grad_norm": 0.3667619824409485,
      "learning_rate": 3.703372707491452e-06,
      "loss": 0.0745,
      "step": 16205
    },
    {
      "epoch": 1.2594031706558906,
      "grad_norm": 0.1505022644996643,
      "learning_rate": 3.7029841467205475e-06,
      "loss": 0.0274,
      "step": 16206
    },
    {
      "epoch": 1.2594808828100714,
      "grad_norm": 0.2768770754337311,
      "learning_rate": 3.702595585949643e-06,
      "loss": 0.1044,
      "step": 16207
    },
    {
      "epoch": 1.2595585949642525,
      "grad_norm": 0.5414431095123291,
      "learning_rate": 3.7022070251787386e-06,
      "loss": 0.1266,
      "step": 16208
    },
    {
      "epoch": 1.2596363071184333,
      "grad_norm": 0.3635554015636444,
      "learning_rate": 3.7018184644078336e-06,
      "loss": 0.1371,
      "step": 16209
    },
    {
      "epoch": 1.2597140192726142,
      "grad_norm": 0.7211425304412842,
      "learning_rate": 3.701429903636929e-06,
      "loss": 0.3131,
      "step": 16210
    },
    {
      "epoch": 1.259791731426795,
      "grad_norm": 0.1334225833415985,
      "learning_rate": 3.7010413428660248e-06,
      "loss": 0.0284,
      "step": 16211
    },
    {
      "epoch": 1.259869443580976,
      "grad_norm": 0.28202128410339355,
      "learning_rate": 3.7006527820951197e-06,
      "loss": 0.1043,
      "step": 16212
    },
    {
      "epoch": 1.259947155735157,
      "grad_norm": 0.6444180011749268,
      "learning_rate": 3.700264221324215e-06,
      "loss": 0.1747,
      "step": 16213
    },
    {
      "epoch": 1.2600248678893378,
      "grad_norm": 0.08599940687417984,
      "learning_rate": 3.699875660553311e-06,
      "loss": 0.0714,
      "step": 16214
    },
    {
      "epoch": 1.2601025800435188,
      "grad_norm": 0.16644424200057983,
      "learning_rate": 3.6994870997824062e-06,
      "loss": 0.0692,
      "step": 16215
    },
    {
      "epoch": 1.2601802921976997,
      "grad_norm": 0.37861236929893494,
      "learning_rate": 3.699098539011502e-06,
      "loss": 0.1468,
      "step": 16216
    },
    {
      "epoch": 1.2602580043518805,
      "grad_norm": 0.8950545787811279,
      "learning_rate": 3.698709978240597e-06,
      "loss": 0.3228,
      "step": 16217
    },
    {
      "epoch": 1.2603357165060616,
      "grad_norm": 0.20243632793426514,
      "learning_rate": 3.6983214174696924e-06,
      "loss": 0.0798,
      "step": 16218
    },
    {
      "epoch": 1.2604134286602424,
      "grad_norm": 1.7560272216796875,
      "learning_rate": 3.697932856698788e-06,
      "loss": 0.2603,
      "step": 16219
    },
    {
      "epoch": 1.2604911408144233,
      "grad_norm": 0.15899045765399933,
      "learning_rate": 3.6975442959278835e-06,
      "loss": 0.028,
      "step": 16220
    },
    {
      "epoch": 1.2605688529686043,
      "grad_norm": 0.5889159440994263,
      "learning_rate": 3.6971557351569785e-06,
      "loss": 0.1284,
      "step": 16221
    },
    {
      "epoch": 1.2606465651227852,
      "grad_norm": 0.7359494566917419,
      "learning_rate": 3.6967671743860743e-06,
      "loss": 0.1834,
      "step": 16222
    },
    {
      "epoch": 1.260724277276966,
      "grad_norm": 0.4324321448802948,
      "learning_rate": 3.6963786136151697e-06,
      "loss": 0.2489,
      "step": 16223
    },
    {
      "epoch": 1.260801989431147,
      "grad_norm": 0.5018312931060791,
      "learning_rate": 3.695990052844265e-06,
      "loss": 0.0564,
      "step": 16224
    },
    {
      "epoch": 1.260879701585328,
      "grad_norm": 0.41509363055229187,
      "learning_rate": 3.695601492073361e-06,
      "loss": 0.1885,
      "step": 16225
    },
    {
      "epoch": 1.2609574137395088,
      "grad_norm": 0.37680041790008545,
      "learning_rate": 3.6952129313024558e-06,
      "loss": 0.4515,
      "step": 16226
    },
    {
      "epoch": 1.2610351258936898,
      "grad_norm": 0.19594278931617737,
      "learning_rate": 3.694824370531551e-06,
      "loss": 0.0135,
      "step": 16227
    },
    {
      "epoch": 1.2611128380478707,
      "grad_norm": 0.18302974104881287,
      "learning_rate": 3.694435809760647e-06,
      "loss": 0.0377,
      "step": 16228
    },
    {
      "epoch": 1.2611905502020515,
      "grad_norm": 0.22471414506435394,
      "learning_rate": 3.6940472489897423e-06,
      "loss": 0.0513,
      "step": 16229
    },
    {
      "epoch": 1.2612682623562326,
      "grad_norm": 0.2603672444820404,
      "learning_rate": 3.693658688218838e-06,
      "loss": 0.0769,
      "step": 16230
    },
    {
      "epoch": 1.2613459745104134,
      "grad_norm": 0.3834015130996704,
      "learning_rate": 3.693270127447933e-06,
      "loss": 0.1408,
      "step": 16231
    },
    {
      "epoch": 1.2614236866645943,
      "grad_norm": 0.4454164505004883,
      "learning_rate": 3.6928815666770284e-06,
      "loss": 0.1645,
      "step": 16232
    },
    {
      "epoch": 1.2615013988187753,
      "grad_norm": 0.2413499504327774,
      "learning_rate": 3.6924930059061242e-06,
      "loss": 0.0395,
      "step": 16233
    },
    {
      "epoch": 1.2615791109729562,
      "grad_norm": 0.361055463552475,
      "learning_rate": 3.6921044451352196e-06,
      "loss": 0.2361,
      "step": 16234
    },
    {
      "epoch": 1.261656823127137,
      "grad_norm": 0.5890079736709595,
      "learning_rate": 3.6917158843643146e-06,
      "loss": 0.3369,
      "step": 16235
    },
    {
      "epoch": 1.261734535281318,
      "grad_norm": 0.32525527477264404,
      "learning_rate": 3.6913273235934104e-06,
      "loss": 0.0873,
      "step": 16236
    },
    {
      "epoch": 1.261812247435499,
      "grad_norm": 0.5901840925216675,
      "learning_rate": 3.6909387628225057e-06,
      "loss": 0.4151,
      "step": 16237
    },
    {
      "epoch": 1.2618899595896798,
      "grad_norm": 0.40938085317611694,
      "learning_rate": 3.690550202051601e-06,
      "loss": 0.0915,
      "step": 16238
    },
    {
      "epoch": 1.2619676717438608,
      "grad_norm": 0.4332522749900818,
      "learning_rate": 3.690161641280697e-06,
      "loss": 0.1098,
      "step": 16239
    },
    {
      "epoch": 1.2620453838980417,
      "grad_norm": 0.38749197125434875,
      "learning_rate": 3.689773080509792e-06,
      "loss": 0.1378,
      "step": 16240
    },
    {
      "epoch": 1.2621230960522225,
      "grad_norm": 0.16599291563034058,
      "learning_rate": 3.6893845197388872e-06,
      "loss": 0.0467,
      "step": 16241
    },
    {
      "epoch": 1.2622008082064036,
      "grad_norm": 0.3873051106929779,
      "learning_rate": 3.688995958967983e-06,
      "loss": 0.1032,
      "step": 16242
    },
    {
      "epoch": 1.2622785203605844,
      "grad_norm": 0.23221267759799957,
      "learning_rate": 3.6886073981970784e-06,
      "loss": 0.0321,
      "step": 16243
    },
    {
      "epoch": 1.2623562325147653,
      "grad_norm": 0.20923487842082977,
      "learning_rate": 3.6882188374261733e-06,
      "loss": 0.0506,
      "step": 16244
    },
    {
      "epoch": 1.2624339446689463,
      "grad_norm": 0.5024717450141907,
      "learning_rate": 3.687830276655269e-06,
      "loss": 0.1263,
      "step": 16245
    },
    {
      "epoch": 1.2625116568231272,
      "grad_norm": 0.4107247292995453,
      "learning_rate": 3.6874417158843645e-06,
      "loss": 0.0301,
      "step": 16246
    },
    {
      "epoch": 1.262589368977308,
      "grad_norm": 0.24791619181632996,
      "learning_rate": 3.6870531551134603e-06,
      "loss": 0.0769,
      "step": 16247
    },
    {
      "epoch": 1.262667081131489,
      "grad_norm": 0.4691069722175598,
      "learning_rate": 3.6866645943425557e-06,
      "loss": 0.3557,
      "step": 16248
    },
    {
      "epoch": 1.26274479328567,
      "grad_norm": 0.5996125936508179,
      "learning_rate": 3.6862760335716506e-06,
      "loss": 0.1261,
      "step": 16249
    },
    {
      "epoch": 1.2628225054398508,
      "grad_norm": 0.26524096727371216,
      "learning_rate": 3.6858874728007464e-06,
      "loss": 0.0721,
      "step": 16250
    },
    {
      "epoch": 1.2629002175940318,
      "grad_norm": 0.8753035068511963,
      "learning_rate": 3.685498912029842e-06,
      "loss": 0.7023,
      "step": 16251
    },
    {
      "epoch": 1.2629779297482127,
      "grad_norm": 0.8148524165153503,
      "learning_rate": 3.685110351258937e-06,
      "loss": 0.5341,
      "step": 16252
    },
    {
      "epoch": 1.2630556419023935,
      "grad_norm": 0.6807262301445007,
      "learning_rate": 3.684721790488033e-06,
      "loss": 0.1851,
      "step": 16253
    },
    {
      "epoch": 1.2631333540565746,
      "grad_norm": 0.011764812283217907,
      "learning_rate": 3.684333229717128e-06,
      "loss": 0.0005,
      "step": 16254
    },
    {
      "epoch": 1.2632110662107554,
      "grad_norm": 0.17892394959926605,
      "learning_rate": 3.6839446689462233e-06,
      "loss": 0.0479,
      "step": 16255
    },
    {
      "epoch": 1.2632887783649362,
      "grad_norm": 0.9194183349609375,
      "learning_rate": 3.683556108175319e-06,
      "loss": 0.5898,
      "step": 16256
    },
    {
      "epoch": 1.2633664905191173,
      "grad_norm": 0.4539000391960144,
      "learning_rate": 3.6831675474044145e-06,
      "loss": 0.1108,
      "step": 16257
    },
    {
      "epoch": 1.2634442026732982,
      "grad_norm": 0.3963659107685089,
      "learning_rate": 3.6827789866335094e-06,
      "loss": 0.0299,
      "step": 16258
    },
    {
      "epoch": 1.263521914827479,
      "grad_norm": 0.12341228872537613,
      "learning_rate": 3.6823904258626052e-06,
      "loss": 0.0389,
      "step": 16259
    },
    {
      "epoch": 1.26359962698166,
      "grad_norm": 0.10518646240234375,
      "learning_rate": 3.6820018650917006e-06,
      "loss": 0.0178,
      "step": 16260
    },
    {
      "epoch": 1.263677339135841,
      "grad_norm": 0.1470121294260025,
      "learning_rate": 3.6816133043207964e-06,
      "loss": 0.0418,
      "step": 16261
    },
    {
      "epoch": 1.2637550512900217,
      "grad_norm": 0.22821111977100372,
      "learning_rate": 3.6812247435498918e-06,
      "loss": 0.0855,
      "step": 16262
    },
    {
      "epoch": 1.2638327634442028,
      "grad_norm": 0.2920902669429779,
      "learning_rate": 3.6808361827789867e-06,
      "loss": 0.0938,
      "step": 16263
    },
    {
      "epoch": 1.2639104755983837,
      "grad_norm": 0.48991313576698303,
      "learning_rate": 3.6804476220080825e-06,
      "loss": 0.0709,
      "step": 16264
    },
    {
      "epoch": 1.2639881877525645,
      "grad_norm": 0.4017171859741211,
      "learning_rate": 3.680059061237178e-06,
      "loss": 0.3928,
      "step": 16265
    },
    {
      "epoch": 1.2640658999067453,
      "grad_norm": 0.5568904280662537,
      "learning_rate": 3.6796705004662732e-06,
      "loss": 0.5347,
      "step": 16266
    },
    {
      "epoch": 1.2641436120609264,
      "grad_norm": 0.5370156168937683,
      "learning_rate": 3.679281939695369e-06,
      "loss": 0.197,
      "step": 16267
    },
    {
      "epoch": 1.2642213242151072,
      "grad_norm": 0.5789390206336975,
      "learning_rate": 3.678893378924464e-06,
      "loss": 0.0847,
      "step": 16268
    },
    {
      "epoch": 1.264299036369288,
      "grad_norm": 0.36865973472595215,
      "learning_rate": 3.6785048181535594e-06,
      "loss": 0.2213,
      "step": 16269
    },
    {
      "epoch": 1.2643767485234692,
      "grad_norm": 1.1436702013015747,
      "learning_rate": 3.678116257382655e-06,
      "loss": 0.5161,
      "step": 16270
    },
    {
      "epoch": 1.26445446067765,
      "grad_norm": 0.4240230917930603,
      "learning_rate": 3.6777276966117505e-06,
      "loss": 0.0563,
      "step": 16271
    },
    {
      "epoch": 1.2645321728318308,
      "grad_norm": 0.6784217953681946,
      "learning_rate": 3.6773391358408455e-06,
      "loss": 0.1762,
      "step": 16272
    },
    {
      "epoch": 1.2646098849860117,
      "grad_norm": 0.09701666980981827,
      "learning_rate": 3.6769505750699413e-06,
      "loss": 0.0094,
      "step": 16273
    },
    {
      "epoch": 1.2646875971401927,
      "grad_norm": 0.06950044631958008,
      "learning_rate": 3.6765620142990367e-06,
      "loss": 0.0143,
      "step": 16274
    },
    {
      "epoch": 1.2647653092943736,
      "grad_norm": 0.4107380211353302,
      "learning_rate": 3.6761734535281325e-06,
      "loss": 0.1373,
      "step": 16275
    },
    {
      "epoch": 1.2648430214485544,
      "grad_norm": 0.4243776798248291,
      "learning_rate": 3.6757848927572274e-06,
      "loss": 0.1106,
      "step": 16276
    },
    {
      "epoch": 1.2649207336027355,
      "grad_norm": 0.22511664032936096,
      "learning_rate": 3.6753963319863228e-06,
      "loss": 0.0424,
      "step": 16277
    },
    {
      "epoch": 1.2649984457569163,
      "grad_norm": 1.1857236623764038,
      "learning_rate": 3.6750077712154186e-06,
      "loss": 0.417,
      "step": 16278
    },
    {
      "epoch": 1.2650761579110972,
      "grad_norm": 1.0801531076431274,
      "learning_rate": 3.674619210444514e-06,
      "loss": 0.8358,
      "step": 16279
    },
    {
      "epoch": 1.2651538700652782,
      "grad_norm": 0.4100216031074524,
      "learning_rate": 3.674230649673609e-06,
      "loss": 0.0879,
      "step": 16280
    },
    {
      "epoch": 1.265231582219459,
      "grad_norm": 0.8093627095222473,
      "learning_rate": 3.6738420889027047e-06,
      "loss": 0.1085,
      "step": 16281
    },
    {
      "epoch": 1.26530929437364,
      "grad_norm": 0.5741718411445618,
      "learning_rate": 3.6734535281318e-06,
      "loss": 0.1029,
      "step": 16282
    },
    {
      "epoch": 1.265387006527821,
      "grad_norm": 0.3109647333621979,
      "learning_rate": 3.6730649673608954e-06,
      "loss": 0.0542,
      "step": 16283
    },
    {
      "epoch": 1.2654647186820018,
      "grad_norm": 0.5036970376968384,
      "learning_rate": 3.6726764065899912e-06,
      "loss": 0.3897,
      "step": 16284
    },
    {
      "epoch": 1.2655424308361827,
      "grad_norm": 1.1791781187057495,
      "learning_rate": 3.672287845819086e-06,
      "loss": 0.2031,
      "step": 16285
    },
    {
      "epoch": 1.2656201429903637,
      "grad_norm": 0.2553730309009552,
      "learning_rate": 3.6718992850481816e-06,
      "loss": 0.0539,
      "step": 16286
    },
    {
      "epoch": 1.2656978551445446,
      "grad_norm": 0.13085196912288666,
      "learning_rate": 3.6715107242772774e-06,
      "loss": 0.0266,
      "step": 16287
    },
    {
      "epoch": 1.2657755672987254,
      "grad_norm": 0.170676589012146,
      "learning_rate": 3.6711221635063727e-06,
      "loss": 0.0429,
      "step": 16288
    },
    {
      "epoch": 1.2658532794529065,
      "grad_norm": 0.2412051558494568,
      "learning_rate": 3.6707336027354677e-06,
      "loss": 0.1342,
      "step": 16289
    },
    {
      "epoch": 1.2659309916070873,
      "grad_norm": 0.7027235627174377,
      "learning_rate": 3.6703450419645635e-06,
      "loss": 0.2645,
      "step": 16290
    },
    {
      "epoch": 1.2660087037612682,
      "grad_norm": 0.14385010302066803,
      "learning_rate": 3.669956481193659e-06,
      "loss": 0.0603,
      "step": 16291
    },
    {
      "epoch": 1.2660864159154492,
      "grad_norm": 0.35371965169906616,
      "learning_rate": 3.6695679204227546e-06,
      "loss": 0.581,
      "step": 16292
    },
    {
      "epoch": 1.26616412806963,
      "grad_norm": 0.36314645409584045,
      "learning_rate": 3.66917935965185e-06,
      "loss": 0.0911,
      "step": 16293
    },
    {
      "epoch": 1.266241840223811,
      "grad_norm": 0.3697221875190735,
      "learning_rate": 3.668790798880945e-06,
      "loss": 0.0996,
      "step": 16294
    },
    {
      "epoch": 1.266319552377992,
      "grad_norm": 0.08256635814905167,
      "learning_rate": 3.6684022381100408e-06,
      "loss": 0.0152,
      "step": 16295
    },
    {
      "epoch": 1.2663972645321728,
      "grad_norm": 0.36382541060447693,
      "learning_rate": 3.668013677339136e-06,
      "loss": 0.061,
      "step": 16296
    },
    {
      "epoch": 1.2664749766863537,
      "grad_norm": 0.29246455430984497,
      "learning_rate": 3.6676251165682315e-06,
      "loss": 0.073,
      "step": 16297
    },
    {
      "epoch": 1.2665526888405347,
      "grad_norm": 0.17853547632694244,
      "learning_rate": 3.6672365557973273e-06,
      "loss": 0.0206,
      "step": 16298
    },
    {
      "epoch": 1.2666304009947156,
      "grad_norm": 0.6211717128753662,
      "learning_rate": 3.6668479950264223e-06,
      "loss": 0.255,
      "step": 16299
    },
    {
      "epoch": 1.2667081131488964,
      "grad_norm": 0.8275171518325806,
      "learning_rate": 3.6664594342555176e-06,
      "loss": 0.6216,
      "step": 16300
    },
    {
      "epoch": 1.2667858253030775,
      "grad_norm": 0.33318597078323364,
      "learning_rate": 3.6660708734846134e-06,
      "loss": 0.1076,
      "step": 16301
    },
    {
      "epoch": 1.2668635374572583,
      "grad_norm": 0.477975070476532,
      "learning_rate": 3.665682312713709e-06,
      "loss": 0.0589,
      "step": 16302
    },
    {
      "epoch": 1.2669412496114392,
      "grad_norm": 0.46798816323280334,
      "learning_rate": 3.6652937519428038e-06,
      "loss": 0.072,
      "step": 16303
    },
    {
      "epoch": 1.2670189617656202,
      "grad_norm": 0.7098281979560852,
      "learning_rate": 3.6649051911718996e-06,
      "loss": 0.2277,
      "step": 16304
    },
    {
      "epoch": 1.267096673919801,
      "grad_norm": 0.48453816771507263,
      "learning_rate": 3.664516630400995e-06,
      "loss": 0.0275,
      "step": 16305
    },
    {
      "epoch": 1.267174386073982,
      "grad_norm": 0.9395413994789124,
      "learning_rate": 3.6641280696300907e-06,
      "loss": 0.3543,
      "step": 16306
    },
    {
      "epoch": 1.267252098228163,
      "grad_norm": 0.45168864727020264,
      "learning_rate": 3.663739508859186e-06,
      "loss": 0.0675,
      "step": 16307
    },
    {
      "epoch": 1.2673298103823438,
      "grad_norm": 0.43826058506965637,
      "learning_rate": 3.663350948088281e-06,
      "loss": 0.0386,
      "step": 16308
    },
    {
      "epoch": 1.2674075225365247,
      "grad_norm": 0.3098667860031128,
      "learning_rate": 3.662962387317377e-06,
      "loss": 0.1794,
      "step": 16309
    },
    {
      "epoch": 1.2674852346907057,
      "grad_norm": 0.49057260155677795,
      "learning_rate": 3.6625738265464722e-06,
      "loss": 0.1138,
      "step": 16310
    },
    {
      "epoch": 1.2675629468448866,
      "grad_norm": 0.15219898521900177,
      "learning_rate": 3.6621852657755676e-06,
      "loss": 0.0342,
      "step": 16311
    },
    {
      "epoch": 1.2676406589990674,
      "grad_norm": 0.3738479018211365,
      "learning_rate": 3.6617967050046634e-06,
      "loss": 0.1545,
      "step": 16312
    },
    {
      "epoch": 1.2677183711532485,
      "grad_norm": 0.7313231229782104,
      "learning_rate": 3.6614081442337583e-06,
      "loss": 0.307,
      "step": 16313
    },
    {
      "epoch": 1.2677960833074293,
      "grad_norm": 0.4355800747871399,
      "learning_rate": 3.6610195834628537e-06,
      "loss": 0.0494,
      "step": 16314
    },
    {
      "epoch": 1.2678737954616102,
      "grad_norm": 0.3069492280483246,
      "learning_rate": 3.6606310226919495e-06,
      "loss": 0.2388,
      "step": 16315
    },
    {
      "epoch": 1.2679515076157912,
      "grad_norm": 0.49056610465049744,
      "learning_rate": 3.660242461921045e-06,
      "loss": 0.1056,
      "step": 16316
    },
    {
      "epoch": 1.268029219769972,
      "grad_norm": 0.49210554361343384,
      "learning_rate": 3.65985390115014e-06,
      "loss": 0.2681,
      "step": 16317
    },
    {
      "epoch": 1.268106931924153,
      "grad_norm": 0.4189505875110626,
      "learning_rate": 3.6594653403792356e-06,
      "loss": 0.0506,
      "step": 16318
    },
    {
      "epoch": 1.268184644078334,
      "grad_norm": 0.4984724819660187,
      "learning_rate": 3.659076779608331e-06,
      "loss": 0.0359,
      "step": 16319
    },
    {
      "epoch": 1.2682623562325148,
      "grad_norm": 1.0444751977920532,
      "learning_rate": 3.6586882188374264e-06,
      "loss": 0.2991,
      "step": 16320
    },
    {
      "epoch": 1.2683400683866957,
      "grad_norm": 0.38553890585899353,
      "learning_rate": 3.658299658066522e-06,
      "loss": 0.1542,
      "step": 16321
    },
    {
      "epoch": 1.2684177805408767,
      "grad_norm": 0.30099156498908997,
      "learning_rate": 3.657911097295617e-06,
      "loss": 0.107,
      "step": 16322
    },
    {
      "epoch": 1.2684954926950576,
      "grad_norm": 0.36211442947387695,
      "learning_rate": 3.657522536524713e-06,
      "loss": 0.1102,
      "step": 16323
    },
    {
      "epoch": 1.2685732048492384,
      "grad_norm": 0.5557754039764404,
      "learning_rate": 3.6571339757538083e-06,
      "loss": 0.211,
      "step": 16324
    },
    {
      "epoch": 1.2686509170034193,
      "grad_norm": 0.4747951030731201,
      "learning_rate": 3.6567454149829037e-06,
      "loss": 0.1287,
      "step": 16325
    },
    {
      "epoch": 1.2687286291576003,
      "grad_norm": 0.2770179808139801,
      "learning_rate": 3.6563568542119995e-06,
      "loss": 0.0363,
      "step": 16326
    },
    {
      "epoch": 1.2688063413117812,
      "grad_norm": 0.6315241456031799,
      "learning_rate": 3.6559682934410944e-06,
      "loss": 0.4621,
      "step": 16327
    },
    {
      "epoch": 1.268884053465962,
      "grad_norm": 0.36685749888420105,
      "learning_rate": 3.6555797326701898e-06,
      "loss": 0.2176,
      "step": 16328
    },
    {
      "epoch": 1.268961765620143,
      "grad_norm": 0.33653149008750916,
      "learning_rate": 3.6551911718992856e-06,
      "loss": 0.1858,
      "step": 16329
    },
    {
      "epoch": 1.269039477774324,
      "grad_norm": 0.2696044445037842,
      "learning_rate": 3.654802611128381e-06,
      "loss": 0.129,
      "step": 16330
    },
    {
      "epoch": 1.2691171899285048,
      "grad_norm": 0.7517848014831543,
      "learning_rate": 3.654414050357476e-06,
      "loss": 0.2708,
      "step": 16331
    },
    {
      "epoch": 1.2691949020826856,
      "grad_norm": 0.3388752043247223,
      "learning_rate": 3.6540254895865717e-06,
      "loss": 0.0422,
      "step": 16332
    },
    {
      "epoch": 1.2692726142368667,
      "grad_norm": 0.09517974406480789,
      "learning_rate": 3.653636928815667e-06,
      "loss": 0.0159,
      "step": 16333
    },
    {
      "epoch": 1.2693503263910475,
      "grad_norm": 0.939719557762146,
      "learning_rate": 3.6532483680447624e-06,
      "loss": 0.6972,
      "step": 16334
    },
    {
      "epoch": 1.2694280385452283,
      "grad_norm": 0.2151927351951599,
      "learning_rate": 3.652859807273858e-06,
      "loss": 0.1387,
      "step": 16335
    },
    {
      "epoch": 1.2695057506994094,
      "grad_norm": 0.681803286075592,
      "learning_rate": 3.652471246502953e-06,
      "loss": 0.3088,
      "step": 16336
    },
    {
      "epoch": 1.2695834628535902,
      "grad_norm": 0.32044199109077454,
      "learning_rate": 3.652082685732049e-06,
      "loss": 0.1192,
      "step": 16337
    },
    {
      "epoch": 1.269661175007771,
      "grad_norm": 0.13354113698005676,
      "learning_rate": 3.6516941249611444e-06,
      "loss": 0.0449,
      "step": 16338
    },
    {
      "epoch": 1.2697388871619522,
      "grad_norm": 0.3576592803001404,
      "learning_rate": 3.6513055641902393e-06,
      "loss": 0.1469,
      "step": 16339
    },
    {
      "epoch": 1.269816599316133,
      "grad_norm": 0.38051506876945496,
      "learning_rate": 3.650917003419335e-06,
      "loss": 0.0831,
      "step": 16340
    },
    {
      "epoch": 1.2698943114703138,
      "grad_norm": 0.4347328543663025,
      "learning_rate": 3.6505284426484305e-06,
      "loss": 0.4436,
      "step": 16341
    },
    {
      "epoch": 1.269972023624495,
      "grad_norm": 0.5840463638305664,
      "learning_rate": 3.650139881877526e-06,
      "loss": 0.1134,
      "step": 16342
    },
    {
      "epoch": 1.2700497357786757,
      "grad_norm": 0.16616639494895935,
      "learning_rate": 3.6497513211066217e-06,
      "loss": 0.0214,
      "step": 16343
    },
    {
      "epoch": 1.2701274479328566,
      "grad_norm": 0.12623482942581177,
      "learning_rate": 3.6493627603357166e-06,
      "loss": 0.0137,
      "step": 16344
    },
    {
      "epoch": 1.2702051600870377,
      "grad_norm": 1.3023384809494019,
      "learning_rate": 3.648974199564812e-06,
      "loss": 0.1972,
      "step": 16345
    },
    {
      "epoch": 1.2702828722412185,
      "grad_norm": 0.60039222240448,
      "learning_rate": 3.6485856387939078e-06,
      "loss": 0.1868,
      "step": 16346
    },
    {
      "epoch": 1.2703605843953993,
      "grad_norm": 0.7258077263832092,
      "learning_rate": 3.648197078023003e-06,
      "loss": 0.4642,
      "step": 16347
    },
    {
      "epoch": 1.2704382965495804,
      "grad_norm": 0.43615174293518066,
      "learning_rate": 3.647808517252098e-06,
      "loss": 0.1015,
      "step": 16348
    },
    {
      "epoch": 1.2705160087037612,
      "grad_norm": 1.263268232345581,
      "learning_rate": 3.647419956481194e-06,
      "loss": 1.0684,
      "step": 16349
    },
    {
      "epoch": 1.270593720857942,
      "grad_norm": 0.13340969383716583,
      "learning_rate": 3.6470313957102893e-06,
      "loss": 0.0172,
      "step": 16350
    },
    {
      "epoch": 1.2706714330121232,
      "grad_norm": 0.23154392838478088,
      "learning_rate": 3.646642834939385e-06,
      "loss": 0.1022,
      "step": 16351
    },
    {
      "epoch": 1.270749145166304,
      "grad_norm": 0.1263149082660675,
      "learning_rate": 3.6462542741684804e-06,
      "loss": 0.0213,
      "step": 16352
    },
    {
      "epoch": 1.2708268573204848,
      "grad_norm": 0.7834914326667786,
      "learning_rate": 3.6458657133975754e-06,
      "loss": 0.2781,
      "step": 16353
    },
    {
      "epoch": 1.270904569474666,
      "grad_norm": 0.31224876642227173,
      "learning_rate": 3.645477152626671e-06,
      "loss": 0.0993,
      "step": 16354
    },
    {
      "epoch": 1.2709822816288467,
      "grad_norm": 0.5545544028282166,
      "learning_rate": 3.6450885918557666e-06,
      "loss": 0.3541,
      "step": 16355
    },
    {
      "epoch": 1.2710599937830276,
      "grad_norm": 0.22404080629348755,
      "learning_rate": 3.644700031084862e-06,
      "loss": 0.0312,
      "step": 16356
    },
    {
      "epoch": 1.2711377059372087,
      "grad_norm": 0.7638459801673889,
      "learning_rate": 3.6443114703139577e-06,
      "loss": 0.2591,
      "step": 16357
    },
    {
      "epoch": 1.2712154180913895,
      "grad_norm": 0.5887609720230103,
      "learning_rate": 3.6439229095430527e-06,
      "loss": 0.4666,
      "step": 16358
    },
    {
      "epoch": 1.2712931302455703,
      "grad_norm": 0.25797444581985474,
      "learning_rate": 3.643534348772148e-06,
      "loss": 0.0789,
      "step": 16359
    },
    {
      "epoch": 1.2713708423997514,
      "grad_norm": 0.4050302803516388,
      "learning_rate": 3.643145788001244e-06,
      "loss": 0.0407,
      "step": 16360
    },
    {
      "epoch": 1.2714485545539322,
      "grad_norm": 0.45120444893836975,
      "learning_rate": 3.6427572272303392e-06,
      "loss": 0.1431,
      "step": 16361
    },
    {
      "epoch": 1.271526266708113,
      "grad_norm": 0.497377872467041,
      "learning_rate": 3.642368666459434e-06,
      "loss": 0.2355,
      "step": 16362
    },
    {
      "epoch": 1.2716039788622941,
      "grad_norm": 0.35335004329681396,
      "learning_rate": 3.64198010568853e-06,
      "loss": 0.2459,
      "step": 16363
    },
    {
      "epoch": 1.271681691016475,
      "grad_norm": 0.6496044993400574,
      "learning_rate": 3.6415915449176253e-06,
      "loss": 0.2859,
      "step": 16364
    },
    {
      "epoch": 1.2717594031706558,
      "grad_norm": 0.17031311988830566,
      "learning_rate": 3.6412029841467207e-06,
      "loss": 0.0659,
      "step": 16365
    },
    {
      "epoch": 1.271837115324837,
      "grad_norm": 0.14097556471824646,
      "learning_rate": 3.6408144233758165e-06,
      "loss": 0.0707,
      "step": 16366
    },
    {
      "epoch": 1.2719148274790177,
      "grad_norm": 0.45841726660728455,
      "learning_rate": 3.6404258626049115e-06,
      "loss": 0.1759,
      "step": 16367
    },
    {
      "epoch": 1.2719925396331986,
      "grad_norm": 0.42023390531539917,
      "learning_rate": 3.6400373018340073e-06,
      "loss": 0.2701,
      "step": 16368
    },
    {
      "epoch": 1.2720702517873796,
      "grad_norm": 0.09519222378730774,
      "learning_rate": 3.6396487410631026e-06,
      "loss": 0.0205,
      "step": 16369
    },
    {
      "epoch": 1.2721479639415605,
      "grad_norm": 0.26862573623657227,
      "learning_rate": 3.639260180292198e-06,
      "loss": 0.0819,
      "step": 16370
    },
    {
      "epoch": 1.2722256760957413,
      "grad_norm": 0.2686583697795868,
      "learning_rate": 3.638871619521294e-06,
      "loss": 0.04,
      "step": 16371
    },
    {
      "epoch": 1.2723033882499224,
      "grad_norm": 0.5583156943321228,
      "learning_rate": 3.6384830587503887e-06,
      "loss": 0.2044,
      "step": 16372
    },
    {
      "epoch": 1.2723811004041032,
      "grad_norm": 0.3335270881652832,
      "learning_rate": 3.638094497979484e-06,
      "loss": 0.2413,
      "step": 16373
    },
    {
      "epoch": 1.272458812558284,
      "grad_norm": 0.3869796097278595,
      "learning_rate": 3.63770593720858e-06,
      "loss": 0.1435,
      "step": 16374
    },
    {
      "epoch": 1.2725365247124651,
      "grad_norm": 0.21317042410373688,
      "learning_rate": 3.6373173764376753e-06,
      "loss": 0.0335,
      "step": 16375
    },
    {
      "epoch": 1.272614236866646,
      "grad_norm": 0.4225711524486542,
      "learning_rate": 3.6369288156667702e-06,
      "loss": 0.1514,
      "step": 16376
    },
    {
      "epoch": 1.2726919490208268,
      "grad_norm": 0.40972039103507996,
      "learning_rate": 3.636540254895866e-06,
      "loss": 0.328,
      "step": 16377
    },
    {
      "epoch": 1.272769661175008,
      "grad_norm": 0.41579127311706543,
      "learning_rate": 3.6361516941249614e-06,
      "loss": 0.1994,
      "step": 16378
    },
    {
      "epoch": 1.2728473733291887,
      "grad_norm": 0.6460142731666565,
      "learning_rate": 3.6357631333540568e-06,
      "loss": 0.268,
      "step": 16379
    },
    {
      "epoch": 1.2729250854833696,
      "grad_norm": 0.11811473965644836,
      "learning_rate": 3.6353745725831526e-06,
      "loss": 0.0211,
      "step": 16380
    },
    {
      "epoch": 1.2730027976375506,
      "grad_norm": 0.7153736352920532,
      "learning_rate": 3.6349860118122475e-06,
      "loss": 0.4231,
      "step": 16381
    },
    {
      "epoch": 1.2730805097917315,
      "grad_norm": 0.2032933235168457,
      "learning_rate": 3.6345974510413433e-06,
      "loss": 0.0625,
      "step": 16382
    },
    {
      "epoch": 1.2731582219459123,
      "grad_norm": 0.14100289344787598,
      "learning_rate": 3.6342088902704387e-06,
      "loss": 0.0291,
      "step": 16383
    },
    {
      "epoch": 1.2732359341000934,
      "grad_norm": 0.6524907350540161,
      "learning_rate": 3.633820329499534e-06,
      "loss": 0.2808,
      "step": 16384
    },
    {
      "epoch": 1.2733136462542742,
      "grad_norm": 0.8794283270835876,
      "learning_rate": 3.63343176872863e-06,
      "loss": 0.3689,
      "step": 16385
    },
    {
      "epoch": 1.273391358408455,
      "grad_norm": 0.8158752918243408,
      "learning_rate": 3.633043207957725e-06,
      "loss": 0.1814,
      "step": 16386
    },
    {
      "epoch": 1.273469070562636,
      "grad_norm": 0.7923423051834106,
      "learning_rate": 3.63265464718682e-06,
      "loss": 0.3584,
      "step": 16387
    },
    {
      "epoch": 1.273546782716817,
      "grad_norm": 1.0551109313964844,
      "learning_rate": 3.632266086415916e-06,
      "loss": 0.7132,
      "step": 16388
    },
    {
      "epoch": 1.2736244948709978,
      "grad_norm": 0.3087681531906128,
      "learning_rate": 3.6318775256450114e-06,
      "loss": 0.1427,
      "step": 16389
    },
    {
      "epoch": 1.2737022070251787,
      "grad_norm": 0.8829779624938965,
      "learning_rate": 3.6314889648741063e-06,
      "loss": 0.3135,
      "step": 16390
    },
    {
      "epoch": 1.2737799191793597,
      "grad_norm": 0.2726247012615204,
      "learning_rate": 3.631100404103202e-06,
      "loss": 0.0894,
      "step": 16391
    },
    {
      "epoch": 1.2738576313335406,
      "grad_norm": 0.9773882627487183,
      "learning_rate": 3.6307118433322975e-06,
      "loss": 0.2973,
      "step": 16392
    },
    {
      "epoch": 1.2739353434877214,
      "grad_norm": 0.47166040539741516,
      "learning_rate": 3.630323282561393e-06,
      "loss": 0.1699,
      "step": 16393
    },
    {
      "epoch": 1.2740130556419023,
      "grad_norm": 0.3537473678588867,
      "learning_rate": 3.6299347217904887e-06,
      "loss": 0.1066,
      "step": 16394
    },
    {
      "epoch": 1.2740907677960833,
      "grad_norm": 0.19648528099060059,
      "learning_rate": 3.6295461610195836e-06,
      "loss": 0.0729,
      "step": 16395
    },
    {
      "epoch": 1.2741684799502642,
      "grad_norm": 0.26512014865875244,
      "learning_rate": 3.629157600248679e-06,
      "loss": 0.1009,
      "step": 16396
    },
    {
      "epoch": 1.274246192104445,
      "grad_norm": 0.6364597678184509,
      "learning_rate": 3.6287690394777748e-06,
      "loss": 0.2944,
      "step": 16397
    },
    {
      "epoch": 1.274323904258626,
      "grad_norm": 0.6354999542236328,
      "learning_rate": 3.62838047870687e-06,
      "loss": 0.4442,
      "step": 16398
    },
    {
      "epoch": 1.274401616412807,
      "grad_norm": 0.23744428157806396,
      "learning_rate": 3.6279919179359655e-06,
      "loss": 0.0824,
      "step": 16399
    },
    {
      "epoch": 1.2744793285669878,
      "grad_norm": 0.6831156611442566,
      "learning_rate": 3.627603357165061e-06,
      "loss": 0.6153,
      "step": 16400
    },
    {
      "epoch": 1.2745570407211688,
      "grad_norm": 0.177659809589386,
      "learning_rate": 3.6272147963941563e-06,
      "loss": 0.0496,
      "step": 16401
    },
    {
      "epoch": 1.2746347528753497,
      "grad_norm": 0.5416343808174133,
      "learning_rate": 3.626826235623252e-06,
      "loss": 0.0643,
      "step": 16402
    },
    {
      "epoch": 1.2747124650295305,
      "grad_norm": 0.388871967792511,
      "learning_rate": 3.626437674852347e-06,
      "loss": 0.0741,
      "step": 16403
    },
    {
      "epoch": 1.2747901771837116,
      "grad_norm": 0.48983660340309143,
      "learning_rate": 3.6260491140814424e-06,
      "loss": 0.1811,
      "step": 16404
    },
    {
      "epoch": 1.2748678893378924,
      "grad_norm": 0.20627205073833466,
      "learning_rate": 3.625660553310538e-06,
      "loss": 0.048,
      "step": 16405
    },
    {
      "epoch": 1.2749456014920733,
      "grad_norm": 0.49484995007514954,
      "learning_rate": 3.6252719925396336e-06,
      "loss": 0.0691,
      "step": 16406
    },
    {
      "epoch": 1.2750233136462543,
      "grad_norm": 0.4162222445011139,
      "learning_rate": 3.6248834317687285e-06,
      "loss": 0.0987,
      "step": 16407
    },
    {
      "epoch": 1.2751010258004352,
      "grad_norm": 0.6905429363250732,
      "learning_rate": 3.6244948709978243e-06,
      "loss": 0.1746,
      "step": 16408
    },
    {
      "epoch": 1.275178737954616,
      "grad_norm": 0.35146161913871765,
      "learning_rate": 3.6241063102269197e-06,
      "loss": 0.1269,
      "step": 16409
    },
    {
      "epoch": 1.275256450108797,
      "grad_norm": 1.066057801246643,
      "learning_rate": 3.623717749456015e-06,
      "loss": 0.3533,
      "step": 16410
    },
    {
      "epoch": 1.275334162262978,
      "grad_norm": 0.6959438920021057,
      "learning_rate": 3.623329188685111e-06,
      "loss": 0.3246,
      "step": 16411
    },
    {
      "epoch": 1.2754118744171588,
      "grad_norm": 0.46546539664268494,
      "learning_rate": 3.622940627914206e-06,
      "loss": 0.1952,
      "step": 16412
    },
    {
      "epoch": 1.2754895865713398,
      "grad_norm": 0.6552659869194031,
      "learning_rate": 3.6225520671433016e-06,
      "loss": 0.2386,
      "step": 16413
    },
    {
      "epoch": 1.2755672987255207,
      "grad_norm": 0.44185635447502136,
      "learning_rate": 3.622163506372397e-06,
      "loss": 0.086,
      "step": 16414
    },
    {
      "epoch": 1.2756450108797015,
      "grad_norm": 0.13642960786819458,
      "learning_rate": 3.6217749456014923e-06,
      "loss": 0.0565,
      "step": 16415
    },
    {
      "epoch": 1.2757227230338826,
      "grad_norm": 0.19651389122009277,
      "learning_rate": 3.621386384830588e-06,
      "loss": 0.0546,
      "step": 16416
    },
    {
      "epoch": 1.2758004351880634,
      "grad_norm": 0.9787493348121643,
      "learning_rate": 3.620997824059683e-06,
      "loss": 0.6202,
      "step": 16417
    },
    {
      "epoch": 1.2758781473422443,
      "grad_norm": 0.35157909989356995,
      "learning_rate": 3.6206092632887785e-06,
      "loss": 0.084,
      "step": 16418
    },
    {
      "epoch": 1.2759558594964253,
      "grad_norm": 0.5772266983985901,
      "learning_rate": 3.6202207025178743e-06,
      "loss": 0.3684,
      "step": 16419
    },
    {
      "epoch": 1.2760335716506062,
      "grad_norm": 0.9318435788154602,
      "learning_rate": 3.6198321417469696e-06,
      "loss": 0.5033,
      "step": 16420
    },
    {
      "epoch": 1.276111283804787,
      "grad_norm": 0.8172619938850403,
      "learning_rate": 3.6194435809760646e-06,
      "loss": 0.424,
      "step": 16421
    },
    {
      "epoch": 1.276188995958968,
      "grad_norm": 0.4733497202396393,
      "learning_rate": 3.6190550202051604e-06,
      "loss": 0.1965,
      "step": 16422
    },
    {
      "epoch": 1.276266708113149,
      "grad_norm": 0.08851202577352524,
      "learning_rate": 3.6186664594342557e-06,
      "loss": 0.0279,
      "step": 16423
    },
    {
      "epoch": 1.2763444202673297,
      "grad_norm": 0.09065929800271988,
      "learning_rate": 3.618277898663351e-06,
      "loss": 0.0383,
      "step": 16424
    },
    {
      "epoch": 1.2764221324215108,
      "grad_norm": 0.07773120701313019,
      "learning_rate": 3.617889337892447e-06,
      "loss": 0.0072,
      "step": 16425
    },
    {
      "epoch": 1.2764998445756917,
      "grad_norm": 0.10656628012657166,
      "learning_rate": 3.617500777121542e-06,
      "loss": 0.0178,
      "step": 16426
    },
    {
      "epoch": 1.2765775567298725,
      "grad_norm": 0.3048357665538788,
      "learning_rate": 3.6171122163506377e-06,
      "loss": 0.0702,
      "step": 16427
    },
    {
      "epoch": 1.2766552688840536,
      "grad_norm": 0.9073754549026489,
      "learning_rate": 3.616723655579733e-06,
      "loss": 0.6169,
      "step": 16428
    },
    {
      "epoch": 1.2767329810382344,
      "grad_norm": 0.596037745475769,
      "learning_rate": 3.6163350948088284e-06,
      "loss": 0.2734,
      "step": 16429
    },
    {
      "epoch": 1.2768106931924152,
      "grad_norm": 0.100078284740448,
      "learning_rate": 3.615946534037924e-06,
      "loss": 0.0208,
      "step": 16430
    },
    {
      "epoch": 1.2768884053465963,
      "grad_norm": 0.24579639732837677,
      "learning_rate": 3.615557973267019e-06,
      "loss": 0.0551,
      "step": 16431
    },
    {
      "epoch": 1.2769661175007772,
      "grad_norm": 0.40128016471862793,
      "learning_rate": 3.6151694124961145e-06,
      "loss": 0.2821,
      "step": 16432
    },
    {
      "epoch": 1.277043829654958,
      "grad_norm": 0.3431648313999176,
      "learning_rate": 3.6147808517252103e-06,
      "loss": 0.1148,
      "step": 16433
    },
    {
      "epoch": 1.277121541809139,
      "grad_norm": 0.09171497076749802,
      "learning_rate": 3.6143922909543057e-06,
      "loss": 0.0232,
      "step": 16434
    },
    {
      "epoch": 1.27719925396332,
      "grad_norm": 0.12678001821041107,
      "learning_rate": 3.6140037301834007e-06,
      "loss": 0.0158,
      "step": 16435
    },
    {
      "epoch": 1.2772769661175007,
      "grad_norm": 0.22717781364917755,
      "learning_rate": 3.6136151694124964e-06,
      "loss": 0.1057,
      "step": 16436
    },
    {
      "epoch": 1.2773546782716818,
      "grad_norm": 1.2528764009475708,
      "learning_rate": 3.613226608641592e-06,
      "loss": 0.5724,
      "step": 16437
    },
    {
      "epoch": 1.2774323904258627,
      "grad_norm": 0.07863824814558029,
      "learning_rate": 3.612838047870687e-06,
      "loss": 0.0159,
      "step": 16438
    },
    {
      "epoch": 1.2775101025800435,
      "grad_norm": 0.16635790467262268,
      "learning_rate": 3.612449487099783e-06,
      "loss": 0.0228,
      "step": 16439
    },
    {
      "epoch": 1.2775878147342246,
      "grad_norm": 0.6123108267784119,
      "learning_rate": 3.612060926328878e-06,
      "loss": 0.5826,
      "step": 16440
    },
    {
      "epoch": 1.2776655268884054,
      "grad_norm": 0.5119875073432922,
      "learning_rate": 3.6116723655579733e-06,
      "loss": 0.2097,
      "step": 16441
    },
    {
      "epoch": 1.2777432390425862,
      "grad_norm": 0.33691123127937317,
      "learning_rate": 3.611283804787069e-06,
      "loss": 0.2541,
      "step": 16442
    },
    {
      "epoch": 1.2778209511967673,
      "grad_norm": 0.39898666739463806,
      "learning_rate": 3.6108952440161645e-06,
      "loss": 0.1621,
      "step": 16443
    },
    {
      "epoch": 1.2778986633509481,
      "grad_norm": 0.40161213278770447,
      "learning_rate": 3.6105066832452603e-06,
      "loss": 0.1492,
      "step": 16444
    },
    {
      "epoch": 1.277976375505129,
      "grad_norm": 0.971591055393219,
      "learning_rate": 3.6101181224743552e-06,
      "loss": 0.1542,
      "step": 16445
    },
    {
      "epoch": 1.2780540876593098,
      "grad_norm": 0.41106387972831726,
      "learning_rate": 3.6097295617034506e-06,
      "loss": 0.0406,
      "step": 16446
    },
    {
      "epoch": 1.278131799813491,
      "grad_norm": 0.4497198164463043,
      "learning_rate": 3.6093410009325464e-06,
      "loss": 0.3776,
      "step": 16447
    },
    {
      "epoch": 1.2782095119676717,
      "grad_norm": 0.6213901042938232,
      "learning_rate": 3.6089524401616418e-06,
      "loss": 0.7656,
      "step": 16448
    },
    {
      "epoch": 1.2782872241218526,
      "grad_norm": 0.5923426151275635,
      "learning_rate": 3.6085638793907367e-06,
      "loss": 0.3102,
      "step": 16449
    },
    {
      "epoch": 1.2783649362760336,
      "grad_norm": 0.23679238557815552,
      "learning_rate": 3.6081753186198325e-06,
      "loss": 0.3886,
      "step": 16450
    },
    {
      "epoch": 1.2784426484302145,
      "grad_norm": 0.2768065929412842,
      "learning_rate": 3.607786757848928e-06,
      "loss": 0.2934,
      "step": 16451
    },
    {
      "epoch": 1.2785203605843953,
      "grad_norm": 0.8737415671348572,
      "learning_rate": 3.6073981970780233e-06,
      "loss": 0.217,
      "step": 16452
    },
    {
      "epoch": 1.2785980727385762,
      "grad_norm": 0.058144696056842804,
      "learning_rate": 3.607009636307119e-06,
      "loss": 0.0193,
      "step": 16453
    },
    {
      "epoch": 1.2786757848927572,
      "grad_norm": 0.19318488240242004,
      "learning_rate": 3.606621075536214e-06,
      "loss": 0.0531,
      "step": 16454
    },
    {
      "epoch": 1.278753497046938,
      "grad_norm": 0.507387101650238,
      "learning_rate": 3.6062325147653094e-06,
      "loss": 0.1576,
      "step": 16455
    },
    {
      "epoch": 1.278831209201119,
      "grad_norm": 0.8200289607048035,
      "learning_rate": 3.605843953994405e-06,
      "loss": 0.5266,
      "step": 16456
    },
    {
      "epoch": 1.2789089213553,
      "grad_norm": 0.22871015965938568,
      "learning_rate": 3.6054553932235006e-06,
      "loss": 0.0658,
      "step": 16457
    },
    {
      "epoch": 1.2789866335094808,
      "grad_norm": 0.23765702545642853,
      "learning_rate": 3.605066832452596e-06,
      "loss": 0.1344,
      "step": 16458
    },
    {
      "epoch": 1.2790643456636617,
      "grad_norm": 2.478031873703003,
      "learning_rate": 3.6046782716816913e-06,
      "loss": 0.0999,
      "step": 16459
    },
    {
      "epoch": 1.2791420578178427,
      "grad_norm": 0.897320568561554,
      "learning_rate": 3.6042897109107867e-06,
      "loss": 0.1545,
      "step": 16460
    },
    {
      "epoch": 1.2792197699720236,
      "grad_norm": 0.7675759792327881,
      "learning_rate": 3.6039011501398825e-06,
      "loss": 0.2323,
      "step": 16461
    },
    {
      "epoch": 1.2792974821262044,
      "grad_norm": 0.11753964424133301,
      "learning_rate": 3.6035125893689774e-06,
      "loss": 0.0367,
      "step": 16462
    },
    {
      "epoch": 1.2793751942803855,
      "grad_norm": 0.3227274417877197,
      "learning_rate": 3.603124028598073e-06,
      "loss": 0.1145,
      "step": 16463
    },
    {
      "epoch": 1.2794529064345663,
      "grad_norm": 0.7121145725250244,
      "learning_rate": 3.6027354678271686e-06,
      "loss": 0.2974,
      "step": 16464
    },
    {
      "epoch": 1.2795306185887472,
      "grad_norm": 0.39646729826927185,
      "learning_rate": 3.602346907056264e-06,
      "loss": 0.3263,
      "step": 16465
    },
    {
      "epoch": 1.2796083307429282,
      "grad_norm": 1.1125962734222412,
      "learning_rate": 3.601958346285359e-06,
      "loss": 0.4925,
      "step": 16466
    },
    {
      "epoch": 1.279686042897109,
      "grad_norm": 0.4524984359741211,
      "learning_rate": 3.6015697855144547e-06,
      "loss": 0.1902,
      "step": 16467
    },
    {
      "epoch": 1.27976375505129,
      "grad_norm": 0.18944619596004486,
      "learning_rate": 3.60118122474355e-06,
      "loss": 0.0064,
      "step": 16468
    },
    {
      "epoch": 1.279841467205471,
      "grad_norm": 0.16099323332309723,
      "learning_rate": 3.6007926639726455e-06,
      "loss": 0.0448,
      "step": 16469
    },
    {
      "epoch": 1.2799191793596518,
      "grad_norm": 0.10754203051328659,
      "learning_rate": 3.6004041032017413e-06,
      "loss": 0.0184,
      "step": 16470
    },
    {
      "epoch": 1.2799968915138327,
      "grad_norm": 0.39917677640914917,
      "learning_rate": 3.600015542430836e-06,
      "loss": 0.0903,
      "step": 16471
    },
    {
      "epoch": 1.2800746036680137,
      "grad_norm": 0.09925036132335663,
      "learning_rate": 3.599626981659932e-06,
      "loss": 0.0206,
      "step": 16472
    },
    {
      "epoch": 1.2801523158221946,
      "grad_norm": 0.37486058473587036,
      "learning_rate": 3.5992384208890274e-06,
      "loss": 0.1184,
      "step": 16473
    },
    {
      "epoch": 1.2802300279763754,
      "grad_norm": 0.6555625200271606,
      "learning_rate": 3.5988498601181228e-06,
      "loss": 0.3534,
      "step": 16474
    },
    {
      "epoch": 1.2803077401305565,
      "grad_norm": 1.0888574123382568,
      "learning_rate": 3.5984612993472185e-06,
      "loss": 0.4279,
      "step": 16475
    },
    {
      "epoch": 1.2803854522847373,
      "grad_norm": 0.1801018863916397,
      "learning_rate": 3.5980727385763135e-06,
      "loss": 0.0166,
      "step": 16476
    },
    {
      "epoch": 1.2804631644389182,
      "grad_norm": 0.6010670065879822,
      "learning_rate": 3.597684177805409e-06,
      "loss": 0.0701,
      "step": 16477
    },
    {
      "epoch": 1.2805408765930992,
      "grad_norm": 0.3995157778263092,
      "learning_rate": 3.5972956170345047e-06,
      "loss": 0.2466,
      "step": 16478
    },
    {
      "epoch": 1.28061858874728,
      "grad_norm": 0.32775381207466125,
      "learning_rate": 3.5969070562636e-06,
      "loss": 0.144,
      "step": 16479
    },
    {
      "epoch": 1.280696300901461,
      "grad_norm": 0.19285818934440613,
      "learning_rate": 3.596518495492695e-06,
      "loss": 0.0308,
      "step": 16480
    },
    {
      "epoch": 1.280774013055642,
      "grad_norm": 1.0811054706573486,
      "learning_rate": 3.596129934721791e-06,
      "loss": 0.4361,
      "step": 16481
    },
    {
      "epoch": 1.2808517252098228,
      "grad_norm": 0.19782058894634247,
      "learning_rate": 3.595741373950886e-06,
      "loss": 0.0276,
      "step": 16482
    },
    {
      "epoch": 1.2809294373640037,
      "grad_norm": 0.29211363196372986,
      "learning_rate": 3.5953528131799815e-06,
      "loss": 0.1248,
      "step": 16483
    },
    {
      "epoch": 1.2810071495181847,
      "grad_norm": 0.19000589847564697,
      "learning_rate": 3.5949642524090773e-06,
      "loss": 0.0536,
      "step": 16484
    },
    {
      "epoch": 1.2810848616723656,
      "grad_norm": 0.3895557224750519,
      "learning_rate": 3.5945756916381723e-06,
      "loss": 0.1154,
      "step": 16485
    },
    {
      "epoch": 1.2811625738265464,
      "grad_norm": 0.3531247675418854,
      "learning_rate": 3.5941871308672677e-06,
      "loss": 0.0866,
      "step": 16486
    },
    {
      "epoch": 1.2812402859807275,
      "grad_norm": 0.48745208978652954,
      "learning_rate": 3.5937985700963635e-06,
      "loss": 0.1252,
      "step": 16487
    },
    {
      "epoch": 1.2813179981349083,
      "grad_norm": 0.3978743255138397,
      "learning_rate": 3.593410009325459e-06,
      "loss": 0.0282,
      "step": 16488
    },
    {
      "epoch": 1.2813957102890892,
      "grad_norm": 0.48103970289230347,
      "learning_rate": 3.5930214485545546e-06,
      "loss": 0.2113,
      "step": 16489
    },
    {
      "epoch": 1.2814734224432702,
      "grad_norm": 0.29185062646865845,
      "learning_rate": 3.5926328877836496e-06,
      "loss": 0.1941,
      "step": 16490
    },
    {
      "epoch": 1.281551134597451,
      "grad_norm": 0.15813618898391724,
      "learning_rate": 3.592244327012745e-06,
      "loss": 0.0933,
      "step": 16491
    },
    {
      "epoch": 1.281628846751632,
      "grad_norm": 0.07821560651063919,
      "learning_rate": 3.5918557662418407e-06,
      "loss": 0.0148,
      "step": 16492
    },
    {
      "epoch": 1.281706558905813,
      "grad_norm": 0.49032166600227356,
      "learning_rate": 3.591467205470936e-06,
      "loss": 0.1312,
      "step": 16493
    },
    {
      "epoch": 1.2817842710599938,
      "grad_norm": 0.6603084802627563,
      "learning_rate": 3.591078644700031e-06,
      "loss": 0.323,
      "step": 16494
    },
    {
      "epoch": 1.2818619832141747,
      "grad_norm": 0.23413558304309845,
      "learning_rate": 3.590690083929127e-06,
      "loss": 0.0466,
      "step": 16495
    },
    {
      "epoch": 1.2819396953683557,
      "grad_norm": 0.22042874991893768,
      "learning_rate": 3.5903015231582222e-06,
      "loss": 0.1319,
      "step": 16496
    },
    {
      "epoch": 1.2820174075225366,
      "grad_norm": 0.5282816290855408,
      "learning_rate": 3.5899129623873176e-06,
      "loss": 0.098,
      "step": 16497
    },
    {
      "epoch": 1.2820951196767174,
      "grad_norm": 0.2148241251707077,
      "learning_rate": 3.5895244016164134e-06,
      "loss": 0.0987,
      "step": 16498
    },
    {
      "epoch": 1.2821728318308985,
      "grad_norm": 0.3910660743713379,
      "learning_rate": 3.5891358408455084e-06,
      "loss": 0.0758,
      "step": 16499
    },
    {
      "epoch": 1.2822505439850793,
      "grad_norm": 0.17776024341583252,
      "learning_rate": 3.5887472800746037e-06,
      "loss": 0.0639,
      "step": 16500
    },
    {
      "epoch": 1.2823282561392602,
      "grad_norm": 0.4848150610923767,
      "learning_rate": 3.5883587193036995e-06,
      "loss": 0.5067,
      "step": 16501
    },
    {
      "epoch": 1.2824059682934412,
      "grad_norm": 0.4895201027393341,
      "learning_rate": 3.587970158532795e-06,
      "loss": 0.1528,
      "step": 16502
    },
    {
      "epoch": 1.282483680447622,
      "grad_norm": 0.31303828954696655,
      "learning_rate": 3.5875815977618907e-06,
      "loss": 0.1084,
      "step": 16503
    },
    {
      "epoch": 1.282561392601803,
      "grad_norm": 0.08836372196674347,
      "learning_rate": 3.5871930369909856e-06,
      "loss": 0.0054,
      "step": 16504
    },
    {
      "epoch": 1.282639104755984,
      "grad_norm": 0.7370178699493408,
      "learning_rate": 3.586804476220081e-06,
      "loss": 0.182,
      "step": 16505
    },
    {
      "epoch": 1.2827168169101648,
      "grad_norm": 0.3018011748790741,
      "learning_rate": 3.586415915449177e-06,
      "loss": 0.1033,
      "step": 16506
    },
    {
      "epoch": 1.2827945290643457,
      "grad_norm": 0.7054464817047119,
      "learning_rate": 3.586027354678272e-06,
      "loss": 0.1877,
      "step": 16507
    },
    {
      "epoch": 1.2828722412185265,
      "grad_norm": 0.25509604811668396,
      "learning_rate": 3.585638793907367e-06,
      "loss": 0.0337,
      "step": 16508
    },
    {
      "epoch": 1.2829499533727076,
      "grad_norm": 0.10332095623016357,
      "learning_rate": 3.585250233136463e-06,
      "loss": 0.0164,
      "step": 16509
    },
    {
      "epoch": 1.2830276655268884,
      "grad_norm": 0.5367190837860107,
      "learning_rate": 3.5848616723655583e-06,
      "loss": 0.0931,
      "step": 16510
    },
    {
      "epoch": 1.2831053776810692,
      "grad_norm": 0.20057536661624908,
      "learning_rate": 3.5844731115946537e-06,
      "loss": 0.0608,
      "step": 16511
    },
    {
      "epoch": 1.2831830898352503,
      "grad_norm": 0.5940393805503845,
      "learning_rate": 3.5840845508237495e-06,
      "loss": 0.6181,
      "step": 16512
    },
    {
      "epoch": 1.2832608019894312,
      "grad_norm": 0.5135785937309265,
      "learning_rate": 3.5836959900528444e-06,
      "loss": 0.2683,
      "step": 16513
    },
    {
      "epoch": 1.283338514143612,
      "grad_norm": 0.44046980142593384,
      "learning_rate": 3.58330742928194e-06,
      "loss": 0.1291,
      "step": 16514
    },
    {
      "epoch": 1.2834162262977928,
      "grad_norm": 0.5786062479019165,
      "learning_rate": 3.5829188685110356e-06,
      "loss": 0.2609,
      "step": 16515
    },
    {
      "epoch": 1.283493938451974,
      "grad_norm": 0.23354500532150269,
      "learning_rate": 3.582530307740131e-06,
      "loss": 0.0064,
      "step": 16516
    },
    {
      "epoch": 1.2835716506061547,
      "grad_norm": 0.3459903597831726,
      "learning_rate": 3.582141746969226e-06,
      "loss": 0.1412,
      "step": 16517
    },
    {
      "epoch": 1.2836493627603356,
      "grad_norm": 0.38313132524490356,
      "learning_rate": 3.5817531861983217e-06,
      "loss": 0.0607,
      "step": 16518
    },
    {
      "epoch": 1.2837270749145167,
      "grad_norm": 0.9891546964645386,
      "learning_rate": 3.581364625427417e-06,
      "loss": 0.5652,
      "step": 16519
    },
    {
      "epoch": 1.2838047870686975,
      "grad_norm": 0.3855911195278168,
      "learning_rate": 3.580976064656513e-06,
      "loss": 0.2169,
      "step": 16520
    },
    {
      "epoch": 1.2838824992228783,
      "grad_norm": 0.18150083720684052,
      "learning_rate": 3.5805875038856083e-06,
      "loss": 0.0522,
      "step": 16521
    },
    {
      "epoch": 1.2839602113770594,
      "grad_norm": 0.3499721884727478,
      "learning_rate": 3.580198943114703e-06,
      "loss": 0.2106,
      "step": 16522
    },
    {
      "epoch": 1.2840379235312402,
      "grad_norm": 0.33507952094078064,
      "learning_rate": 3.579810382343799e-06,
      "loss": 0.2045,
      "step": 16523
    },
    {
      "epoch": 1.284115635685421,
      "grad_norm": 0.4336344003677368,
      "learning_rate": 3.5794218215728944e-06,
      "loss": 0.3536,
      "step": 16524
    },
    {
      "epoch": 1.2841933478396022,
      "grad_norm": 1.057469129562378,
      "learning_rate": 3.5790332608019893e-06,
      "loss": 0.4356,
      "step": 16525
    },
    {
      "epoch": 1.284271059993783,
      "grad_norm": 0.5265023112297058,
      "learning_rate": 3.578644700031085e-06,
      "loss": 0.1142,
      "step": 16526
    },
    {
      "epoch": 1.2843487721479638,
      "grad_norm": 0.15558162331581116,
      "learning_rate": 3.5782561392601805e-06,
      "loss": 0.0406,
      "step": 16527
    },
    {
      "epoch": 1.284426484302145,
      "grad_norm": 0.38038185238838196,
      "learning_rate": 3.577867578489276e-06,
      "loss": 0.1347,
      "step": 16528
    },
    {
      "epoch": 1.2845041964563257,
      "grad_norm": 0.09838321805000305,
      "learning_rate": 3.5774790177183717e-06,
      "loss": 0.0068,
      "step": 16529
    },
    {
      "epoch": 1.2845819086105066,
      "grad_norm": 0.14306892454624176,
      "learning_rate": 3.5770904569474666e-06,
      "loss": 0.0448,
      "step": 16530
    },
    {
      "epoch": 1.2846596207646876,
      "grad_norm": 0.5634369254112244,
      "learning_rate": 3.576701896176562e-06,
      "loss": 0.0905,
      "step": 16531
    },
    {
      "epoch": 1.2847373329188685,
      "grad_norm": 0.9846920967102051,
      "learning_rate": 3.576313335405658e-06,
      "loss": 0.3003,
      "step": 16532
    },
    {
      "epoch": 1.2848150450730493,
      "grad_norm": 0.5059093236923218,
      "learning_rate": 3.575924774634753e-06,
      "loss": 0.248,
      "step": 16533
    },
    {
      "epoch": 1.2848927572272304,
      "grad_norm": 0.5492762327194214,
      "learning_rate": 3.575536213863849e-06,
      "loss": 0.2605,
      "step": 16534
    },
    {
      "epoch": 1.2849704693814112,
      "grad_norm": 0.17249979078769684,
      "learning_rate": 3.575147653092944e-06,
      "loss": 0.033,
      "step": 16535
    },
    {
      "epoch": 1.285048181535592,
      "grad_norm": 0.1026509553194046,
      "learning_rate": 3.5747590923220393e-06,
      "loss": 0.0244,
      "step": 16536
    },
    {
      "epoch": 1.2851258936897731,
      "grad_norm": 0.09003840386867523,
      "learning_rate": 3.574370531551135e-06,
      "loss": 0.0096,
      "step": 16537
    },
    {
      "epoch": 1.285203605843954,
      "grad_norm": 0.12106731534004211,
      "learning_rate": 3.5739819707802305e-06,
      "loss": 0.0142,
      "step": 16538
    },
    {
      "epoch": 1.2852813179981348,
      "grad_norm": 0.5736124515533447,
      "learning_rate": 3.5735934100093254e-06,
      "loss": 0.2026,
      "step": 16539
    },
    {
      "epoch": 1.285359030152316,
      "grad_norm": 0.2442219853401184,
      "learning_rate": 3.573204849238421e-06,
      "loss": 0.0763,
      "step": 16540
    },
    {
      "epoch": 1.2854367423064967,
      "grad_norm": 0.5730792284011841,
      "learning_rate": 3.5728162884675166e-06,
      "loss": 0.1313,
      "step": 16541
    },
    {
      "epoch": 1.2855144544606776,
      "grad_norm": 0.2354222983121872,
      "learning_rate": 3.572427727696612e-06,
      "loss": 0.0059,
      "step": 16542
    },
    {
      "epoch": 1.2855921666148586,
      "grad_norm": 0.26441794633865356,
      "learning_rate": 3.5720391669257077e-06,
      "loss": 0.0903,
      "step": 16543
    },
    {
      "epoch": 1.2856698787690395,
      "grad_norm": 0.612908661365509,
      "learning_rate": 3.5716506061548027e-06,
      "loss": 0.3524,
      "step": 16544
    },
    {
      "epoch": 1.2857475909232203,
      "grad_norm": 0.6012987494468689,
      "learning_rate": 3.571262045383898e-06,
      "loss": 0.1313,
      "step": 16545
    },
    {
      "epoch": 1.2858253030774014,
      "grad_norm": 0.2782273590564728,
      "learning_rate": 3.570873484612994e-06,
      "loss": 0.1438,
      "step": 16546
    },
    {
      "epoch": 1.2859030152315822,
      "grad_norm": 0.6850395202636719,
      "learning_rate": 3.5704849238420892e-06,
      "loss": 0.2582,
      "step": 16547
    },
    {
      "epoch": 1.285980727385763,
      "grad_norm": 0.7827582359313965,
      "learning_rate": 3.570096363071185e-06,
      "loss": 0.2257,
      "step": 16548
    },
    {
      "epoch": 1.2860584395399441,
      "grad_norm": 0.589759886264801,
      "learning_rate": 3.56970780230028e-06,
      "loss": 0.4875,
      "step": 16549
    },
    {
      "epoch": 1.286136151694125,
      "grad_norm": 0.4565048813819885,
      "learning_rate": 3.5693192415293754e-06,
      "loss": 0.1242,
      "step": 16550
    },
    {
      "epoch": 1.2862138638483058,
      "grad_norm": 0.7803730964660645,
      "learning_rate": 3.568930680758471e-06,
      "loss": 0.1169,
      "step": 16551
    },
    {
      "epoch": 1.286291576002487,
      "grad_norm": 1.3972728252410889,
      "learning_rate": 3.5685421199875665e-06,
      "loss": 0.5274,
      "step": 16552
    },
    {
      "epoch": 1.2863692881566677,
      "grad_norm": 0.286424458026886,
      "learning_rate": 3.5681535592166615e-06,
      "loss": 0.1489,
      "step": 16553
    },
    {
      "epoch": 1.2864470003108486,
      "grad_norm": 0.5600355267524719,
      "learning_rate": 3.5677649984457573e-06,
      "loss": 0.185,
      "step": 16554
    },
    {
      "epoch": 1.2865247124650296,
      "grad_norm": 0.8754147887229919,
      "learning_rate": 3.5673764376748526e-06,
      "loss": 0.2399,
      "step": 16555
    },
    {
      "epoch": 1.2866024246192105,
      "grad_norm": 1.5562665462493896,
      "learning_rate": 3.566987876903948e-06,
      "loss": 0.3658,
      "step": 16556
    },
    {
      "epoch": 1.2866801367733913,
      "grad_norm": 0.4174898862838745,
      "learning_rate": 3.566599316133044e-06,
      "loss": 0.0887,
      "step": 16557
    },
    {
      "epoch": 1.2867578489275724,
      "grad_norm": 0.27997514605522156,
      "learning_rate": 3.5662107553621388e-06,
      "loss": 0.123,
      "step": 16558
    },
    {
      "epoch": 1.2868355610817532,
      "grad_norm": 1.1718024015426636,
      "learning_rate": 3.565822194591234e-06,
      "loss": 0.5896,
      "step": 16559
    },
    {
      "epoch": 1.286913273235934,
      "grad_norm": 0.789556086063385,
      "learning_rate": 3.56543363382033e-06,
      "loss": 0.272,
      "step": 16560
    },
    {
      "epoch": 1.2869909853901151,
      "grad_norm": 1.5624573230743408,
      "learning_rate": 3.5650450730494253e-06,
      "loss": 0.276,
      "step": 16561
    },
    {
      "epoch": 1.287068697544296,
      "grad_norm": 0.2657938599586487,
      "learning_rate": 3.5646565122785203e-06,
      "loss": 0.0747,
      "step": 16562
    },
    {
      "epoch": 1.2871464096984768,
      "grad_norm": 0.7689111232757568,
      "learning_rate": 3.564267951507616e-06,
      "loss": 0.3598,
      "step": 16563
    },
    {
      "epoch": 1.2872241218526579,
      "grad_norm": 0.21598130464553833,
      "learning_rate": 3.5638793907367114e-06,
      "loss": 0.0518,
      "step": 16564
    },
    {
      "epoch": 1.2873018340068387,
      "grad_norm": 0.2107807993888855,
      "learning_rate": 3.5634908299658072e-06,
      "loss": 0.0268,
      "step": 16565
    },
    {
      "epoch": 1.2873795461610196,
      "grad_norm": 0.41267213225364685,
      "learning_rate": 3.5631022691949026e-06,
      "loss": 0.0587,
      "step": 16566
    },
    {
      "epoch": 1.2874572583152004,
      "grad_norm": 0.624674916267395,
      "learning_rate": 3.5627137084239976e-06,
      "loss": 0.5848,
      "step": 16567
    },
    {
      "epoch": 1.2875349704693815,
      "grad_norm": 0.5472097396850586,
      "learning_rate": 3.5623251476530933e-06,
      "loss": 0.17,
      "step": 16568
    },
    {
      "epoch": 1.2876126826235623,
      "grad_norm": 0.5146068930625916,
      "learning_rate": 3.5619365868821887e-06,
      "loss": 0.24,
      "step": 16569
    },
    {
      "epoch": 1.2876903947777432,
      "grad_norm": 0.14430953562259674,
      "learning_rate": 3.561548026111284e-06,
      "loss": 0.0464,
      "step": 16570
    },
    {
      "epoch": 1.2877681069319242,
      "grad_norm": 0.3170233964920044,
      "learning_rate": 3.56115946534038e-06,
      "loss": 0.069,
      "step": 16571
    },
    {
      "epoch": 1.287845819086105,
      "grad_norm": 0.12311332672834396,
      "learning_rate": 3.560770904569475e-06,
      "loss": 0.0238,
      "step": 16572
    },
    {
      "epoch": 1.287923531240286,
      "grad_norm": 0.1945338398218155,
      "learning_rate": 3.5603823437985702e-06,
      "loss": 0.0361,
      "step": 16573
    },
    {
      "epoch": 1.288001243394467,
      "grad_norm": 0.3812733590602875,
      "learning_rate": 3.559993783027666e-06,
      "loss": 0.1082,
      "step": 16574
    },
    {
      "epoch": 1.2880789555486478,
      "grad_norm": 0.32238316535949707,
      "learning_rate": 3.5596052222567614e-06,
      "loss": 0.1256,
      "step": 16575
    },
    {
      "epoch": 1.2881566677028287,
      "grad_norm": 0.7002503871917725,
      "learning_rate": 3.5592166614858563e-06,
      "loss": 0.7737,
      "step": 16576
    },
    {
      "epoch": 1.2882343798570095,
      "grad_norm": 0.10520412772893906,
      "learning_rate": 3.558828100714952e-06,
      "loss": 0.0182,
      "step": 16577
    },
    {
      "epoch": 1.2883120920111906,
      "grad_norm": 0.5908414125442505,
      "learning_rate": 3.5584395399440475e-06,
      "loss": 0.1774,
      "step": 16578
    },
    {
      "epoch": 1.2883898041653714,
      "grad_norm": 0.179704487323761,
      "learning_rate": 3.5580509791731433e-06,
      "loss": 0.0122,
      "step": 16579
    },
    {
      "epoch": 1.2884675163195523,
      "grad_norm": 0.16564635932445526,
      "learning_rate": 3.5576624184022387e-06,
      "loss": 0.0282,
      "step": 16580
    },
    {
      "epoch": 1.2885452284737333,
      "grad_norm": 0.3023412227630615,
      "learning_rate": 3.5572738576313336e-06,
      "loss": 0.0888,
      "step": 16581
    },
    {
      "epoch": 1.2886229406279142,
      "grad_norm": 0.20772910118103027,
      "learning_rate": 3.5568852968604294e-06,
      "loss": 0.0505,
      "step": 16582
    },
    {
      "epoch": 1.288700652782095,
      "grad_norm": 1.031301498413086,
      "learning_rate": 3.556496736089525e-06,
      "loss": 0.8076,
      "step": 16583
    },
    {
      "epoch": 1.288778364936276,
      "grad_norm": 0.25517985224723816,
      "learning_rate": 3.55610817531862e-06,
      "loss": 0.0484,
      "step": 16584
    },
    {
      "epoch": 1.288856077090457,
      "grad_norm": 0.8466101884841919,
      "learning_rate": 3.5557196145477155e-06,
      "loss": 0.1285,
      "step": 16585
    },
    {
      "epoch": 1.2889337892446378,
      "grad_norm": 0.46135860681533813,
      "learning_rate": 3.555331053776811e-06,
      "loss": 0.2425,
      "step": 16586
    },
    {
      "epoch": 1.2890115013988188,
      "grad_norm": 0.40252330899238586,
      "learning_rate": 3.5549424930059063e-06,
      "loss": 0.1812,
      "step": 16587
    },
    {
      "epoch": 1.2890892135529997,
      "grad_norm": 0.8353424668312073,
      "learning_rate": 3.554553932235002e-06,
      "loss": 0.1695,
      "step": 16588
    },
    {
      "epoch": 1.2891669257071805,
      "grad_norm": 0.5679643750190735,
      "learning_rate": 3.554165371464097e-06,
      "loss": 0.4438,
      "step": 16589
    },
    {
      "epoch": 1.2892446378613616,
      "grad_norm": 0.7955193519592285,
      "learning_rate": 3.5537768106931924e-06,
      "loss": 0.1533,
      "step": 16590
    },
    {
      "epoch": 1.2893223500155424,
      "grad_norm": 0.3081498444080353,
      "learning_rate": 3.553388249922288e-06,
      "loss": 0.0967,
      "step": 16591
    },
    {
      "epoch": 1.2894000621697232,
      "grad_norm": 0.36675581336021423,
      "learning_rate": 3.5529996891513836e-06,
      "loss": 0.1157,
      "step": 16592
    },
    {
      "epoch": 1.2894777743239043,
      "grad_norm": 0.24285531044006348,
      "learning_rate": 3.5526111283804785e-06,
      "loss": 0.0466,
      "step": 16593
    },
    {
      "epoch": 1.2895554864780852,
      "grad_norm": 0.7852088212966919,
      "learning_rate": 3.5522225676095743e-06,
      "loss": 0.3148,
      "step": 16594
    },
    {
      "epoch": 1.289633198632266,
      "grad_norm": 0.5972611308097839,
      "learning_rate": 3.5518340068386697e-06,
      "loss": 0.3058,
      "step": 16595
    },
    {
      "epoch": 1.289710910786447,
      "grad_norm": 0.8776503801345825,
      "learning_rate": 3.5514454460677655e-06,
      "loss": 0.4567,
      "step": 16596
    },
    {
      "epoch": 1.289788622940628,
      "grad_norm": 0.37584254145622253,
      "learning_rate": 3.551056885296861e-06,
      "loss": 0.1399,
      "step": 16597
    },
    {
      "epoch": 1.2898663350948087,
      "grad_norm": 0.15892735123634338,
      "learning_rate": 3.550668324525956e-06,
      "loss": 0.0461,
      "step": 16598
    },
    {
      "epoch": 1.2899440472489898,
      "grad_norm": 1.013687014579773,
      "learning_rate": 3.5502797637550516e-06,
      "loss": 0.4045,
      "step": 16599
    },
    {
      "epoch": 1.2900217594031707,
      "grad_norm": 0.04336248338222504,
      "learning_rate": 3.549891202984147e-06,
      "loss": 0.0076,
      "step": 16600
    },
    {
      "epoch": 1.2900994715573515,
      "grad_norm": 0.1726786345243454,
      "learning_rate": 3.5495026422132424e-06,
      "loss": 0.0425,
      "step": 16601
    },
    {
      "epoch": 1.2901771837115326,
      "grad_norm": 0.8152015209197998,
      "learning_rate": 3.549114081442338e-06,
      "loss": 0.23,
      "step": 16602
    },
    {
      "epoch": 1.2902548958657134,
      "grad_norm": 0.49896275997161865,
      "learning_rate": 3.548725520671433e-06,
      "loss": 0.0987,
      "step": 16603
    },
    {
      "epoch": 1.2903326080198942,
      "grad_norm": 0.6172124743461609,
      "learning_rate": 3.5483369599005285e-06,
      "loss": 0.1297,
      "step": 16604
    },
    {
      "epoch": 1.2904103201740753,
      "grad_norm": 0.82539302110672,
      "learning_rate": 3.5479483991296243e-06,
      "loss": 0.5579,
      "step": 16605
    },
    {
      "epoch": 1.2904880323282562,
      "grad_norm": 0.1433013379573822,
      "learning_rate": 3.5475598383587196e-06,
      "loss": 0.0272,
      "step": 16606
    },
    {
      "epoch": 1.290565744482437,
      "grad_norm": 0.3831177353858948,
      "learning_rate": 3.5471712775878146e-06,
      "loss": 0.1777,
      "step": 16607
    },
    {
      "epoch": 1.290643456636618,
      "grad_norm": 0.3968639671802521,
      "learning_rate": 3.5467827168169104e-06,
      "loss": 0.1048,
      "step": 16608
    },
    {
      "epoch": 1.290721168790799,
      "grad_norm": 0.49938321113586426,
      "learning_rate": 3.5463941560460058e-06,
      "loss": 0.2358,
      "step": 16609
    },
    {
      "epoch": 1.2907988809449797,
      "grad_norm": 0.44301846623420715,
      "learning_rate": 3.5460055952751016e-06,
      "loss": 0.2087,
      "step": 16610
    },
    {
      "epoch": 1.2908765930991608,
      "grad_norm": 0.38705042004585266,
      "learning_rate": 3.545617034504197e-06,
      "loss": 0.1,
      "step": 16611
    },
    {
      "epoch": 1.2909543052533416,
      "grad_norm": 0.3805820941925049,
      "learning_rate": 3.545228473733292e-06,
      "loss": 0.0634,
      "step": 16612
    },
    {
      "epoch": 1.2910320174075225,
      "grad_norm": 1.4832836389541626,
      "learning_rate": 3.5448399129623877e-06,
      "loss": 0.3816,
      "step": 16613
    },
    {
      "epoch": 1.2911097295617036,
      "grad_norm": 0.634118378162384,
      "learning_rate": 3.544451352191483e-06,
      "loss": 0.174,
      "step": 16614
    },
    {
      "epoch": 1.2911874417158844,
      "grad_norm": 0.7294240593910217,
      "learning_rate": 3.5440627914205784e-06,
      "loss": 0.4957,
      "step": 16615
    },
    {
      "epoch": 1.2912651538700652,
      "grad_norm": 0.7712975144386292,
      "learning_rate": 3.5436742306496742e-06,
      "loss": 0.4086,
      "step": 16616
    },
    {
      "epoch": 1.2913428660242463,
      "grad_norm": 0.3308822810649872,
      "learning_rate": 3.543285669878769e-06,
      "loss": 0.1115,
      "step": 16617
    },
    {
      "epoch": 1.2914205781784271,
      "grad_norm": 0.3018092215061188,
      "learning_rate": 3.5428971091078646e-06,
      "loss": 0.0733,
      "step": 16618
    },
    {
      "epoch": 1.291498290332608,
      "grad_norm": 0.22247140109539032,
      "learning_rate": 3.5425085483369603e-06,
      "loss": 0.0504,
      "step": 16619
    },
    {
      "epoch": 1.291576002486789,
      "grad_norm": 0.35803431272506714,
      "learning_rate": 3.5421199875660557e-06,
      "loss": 0.0807,
      "step": 16620
    },
    {
      "epoch": 1.29165371464097,
      "grad_norm": 0.422911137342453,
      "learning_rate": 3.5417314267951507e-06,
      "loss": 0.2509,
      "step": 16621
    },
    {
      "epoch": 1.2917314267951507,
      "grad_norm": 0.23466238379478455,
      "learning_rate": 3.5413428660242465e-06,
      "loss": 0.0543,
      "step": 16622
    },
    {
      "epoch": 1.2918091389493318,
      "grad_norm": 0.19101767241954803,
      "learning_rate": 3.540954305253342e-06,
      "loss": 0.0654,
      "step": 16623
    },
    {
      "epoch": 1.2918868511035126,
      "grad_norm": 0.4529842734336853,
      "learning_rate": 3.5405657444824376e-06,
      "loss": 0.1501,
      "step": 16624
    },
    {
      "epoch": 1.2919645632576935,
      "grad_norm": 1.5442442893981934,
      "learning_rate": 3.540177183711533e-06,
      "loss": 0.3469,
      "step": 16625
    },
    {
      "epoch": 1.2920422754118746,
      "grad_norm": 0.6738947033882141,
      "learning_rate": 3.539788622940628e-06,
      "loss": 0.372,
      "step": 16626
    },
    {
      "epoch": 1.2921199875660554,
      "grad_norm": 0.4346432685852051,
      "learning_rate": 3.5394000621697238e-06,
      "loss": 0.301,
      "step": 16627
    },
    {
      "epoch": 1.2921976997202362,
      "grad_norm": 0.2530789375305176,
      "learning_rate": 3.539011501398819e-06,
      "loss": 0.0681,
      "step": 16628
    },
    {
      "epoch": 1.292275411874417,
      "grad_norm": 0.513922929763794,
      "learning_rate": 3.5386229406279145e-06,
      "loss": 0.3671,
      "step": 16629
    },
    {
      "epoch": 1.2923531240285981,
      "grad_norm": 0.313681423664093,
      "learning_rate": 3.5382343798570103e-06,
      "loss": 0.0463,
      "step": 16630
    },
    {
      "epoch": 1.292430836182779,
      "grad_norm": 0.2802726924419403,
      "learning_rate": 3.5378458190861053e-06,
      "loss": 0.1117,
      "step": 16631
    },
    {
      "epoch": 1.2925085483369598,
      "grad_norm": 0.24334189295768738,
      "learning_rate": 3.5374572583152006e-06,
      "loss": 0.0211,
      "step": 16632
    },
    {
      "epoch": 1.292586260491141,
      "grad_norm": 0.6593729257583618,
      "learning_rate": 3.5370686975442964e-06,
      "loss": 0.48,
      "step": 16633
    },
    {
      "epoch": 1.2926639726453217,
      "grad_norm": 0.23742203414440155,
      "learning_rate": 3.536680136773392e-06,
      "loss": 0.0487,
      "step": 16634
    },
    {
      "epoch": 1.2927416847995026,
      "grad_norm": 0.3817366063594818,
      "learning_rate": 3.5362915760024867e-06,
      "loss": 0.0573,
      "step": 16635
    },
    {
      "epoch": 1.2928193969536834,
      "grad_norm": 1.2154111862182617,
      "learning_rate": 3.5359030152315825e-06,
      "loss": 0.2735,
      "step": 16636
    },
    {
      "epoch": 1.2928971091078645,
      "grad_norm": 0.22811920940876007,
      "learning_rate": 3.535514454460678e-06,
      "loss": 0.1183,
      "step": 16637
    },
    {
      "epoch": 1.2929748212620453,
      "grad_norm": 0.39665305614471436,
      "learning_rate": 3.5351258936897733e-06,
      "loss": 0.093,
      "step": 16638
    },
    {
      "epoch": 1.2930525334162262,
      "grad_norm": 0.4750387370586395,
      "learning_rate": 3.534737332918869e-06,
      "loss": 0.101,
      "step": 16639
    },
    {
      "epoch": 1.2931302455704072,
      "grad_norm": 0.2203831970691681,
      "learning_rate": 3.534348772147964e-06,
      "loss": 0.0614,
      "step": 16640
    },
    {
      "epoch": 1.293207957724588,
      "grad_norm": 0.4707120954990387,
      "learning_rate": 3.53396021137706e-06,
      "loss": 0.193,
      "step": 16641
    },
    {
      "epoch": 1.293285669878769,
      "grad_norm": 0.22915716469287872,
      "learning_rate": 3.533571650606155e-06,
      "loss": 0.1383,
      "step": 16642
    },
    {
      "epoch": 1.29336338203295,
      "grad_norm": 0.616220235824585,
      "learning_rate": 3.5331830898352506e-06,
      "loss": 0.1441,
      "step": 16643
    },
    {
      "epoch": 1.2934410941871308,
      "grad_norm": 0.3038506805896759,
      "learning_rate": 3.5327945290643464e-06,
      "loss": 0.0988,
      "step": 16644
    },
    {
      "epoch": 1.2935188063413117,
      "grad_norm": 0.6621074676513672,
      "learning_rate": 3.5324059682934413e-06,
      "loss": 0.1867,
      "step": 16645
    },
    {
      "epoch": 1.2935965184954927,
      "grad_norm": 0.30018001794815063,
      "learning_rate": 3.5320174075225367e-06,
      "loss": 0.0537,
      "step": 16646
    },
    {
      "epoch": 1.2936742306496736,
      "grad_norm": 0.38130897283554077,
      "learning_rate": 3.5316288467516325e-06,
      "loss": 0.2635,
      "step": 16647
    },
    {
      "epoch": 1.2937519428038544,
      "grad_norm": 0.38129445910453796,
      "learning_rate": 3.5312402859807274e-06,
      "loss": 0.0768,
      "step": 16648
    },
    {
      "epoch": 1.2938296549580355,
      "grad_norm": 0.6092393398284912,
      "learning_rate": 3.530851725209823e-06,
      "loss": 0.1715,
      "step": 16649
    },
    {
      "epoch": 1.2939073671122163,
      "grad_norm": 0.20706036686897278,
      "learning_rate": 3.5304631644389186e-06,
      "loss": 0.0194,
      "step": 16650
    },
    {
      "epoch": 1.2939850792663972,
      "grad_norm": 0.45115938782691956,
      "learning_rate": 3.530074603668014e-06,
      "loss": 0.0498,
      "step": 16651
    },
    {
      "epoch": 1.2940627914205782,
      "grad_norm": 1.3756797313690186,
      "learning_rate": 3.529686042897109e-06,
      "loss": 0.3313,
      "step": 16652
    },
    {
      "epoch": 1.294140503574759,
      "grad_norm": 0.8774465918540955,
      "learning_rate": 3.5292974821262047e-06,
      "loss": 0.2973,
      "step": 16653
    },
    {
      "epoch": 1.29421821572894,
      "grad_norm": 0.13272704184055328,
      "learning_rate": 3.5289089213553e-06,
      "loss": 0.023,
      "step": 16654
    },
    {
      "epoch": 1.294295927883121,
      "grad_norm": 0.23432117700576782,
      "learning_rate": 3.528520360584396e-06,
      "loss": 0.1192,
      "step": 16655
    },
    {
      "epoch": 1.2943736400373018,
      "grad_norm": 0.8391152620315552,
      "learning_rate": 3.5281317998134913e-06,
      "loss": 0.5187,
      "step": 16656
    },
    {
      "epoch": 1.2944513521914827,
      "grad_norm": 0.32313084602355957,
      "learning_rate": 3.5277432390425862e-06,
      "loss": 0.057,
      "step": 16657
    },
    {
      "epoch": 1.2945290643456637,
      "grad_norm": 0.4510069787502289,
      "learning_rate": 3.527354678271682e-06,
      "loss": 0.2419,
      "step": 16658
    },
    {
      "epoch": 1.2946067764998446,
      "grad_norm": 0.6831346154212952,
      "learning_rate": 3.5269661175007774e-06,
      "loss": 0.1274,
      "step": 16659
    },
    {
      "epoch": 1.2946844886540254,
      "grad_norm": 0.7981308102607727,
      "learning_rate": 3.5265775567298728e-06,
      "loss": 0.1792,
      "step": 16660
    },
    {
      "epoch": 1.2947622008082065,
      "grad_norm": 0.5489811897277832,
      "learning_rate": 3.5261889959589686e-06,
      "loss": 0.182,
      "step": 16661
    },
    {
      "epoch": 1.2948399129623873,
      "grad_norm": 0.33128926157951355,
      "learning_rate": 3.5258004351880635e-06,
      "loss": 0.1484,
      "step": 16662
    },
    {
      "epoch": 1.2949176251165682,
      "grad_norm": 0.545541524887085,
      "learning_rate": 3.525411874417159e-06,
      "loss": 0.1344,
      "step": 16663
    },
    {
      "epoch": 1.2949953372707492,
      "grad_norm": 0.21748676896095276,
      "learning_rate": 3.5250233136462547e-06,
      "loss": 0.1169,
      "step": 16664
    },
    {
      "epoch": 1.29507304942493,
      "grad_norm": 0.6385874152183533,
      "learning_rate": 3.52463475287535e-06,
      "loss": 0.1485,
      "step": 16665
    },
    {
      "epoch": 1.295150761579111,
      "grad_norm": 0.3956874907016754,
      "learning_rate": 3.524246192104445e-06,
      "loss": 0.1223,
      "step": 16666
    },
    {
      "epoch": 1.295228473733292,
      "grad_norm": 0.3331837058067322,
      "learning_rate": 3.523857631333541e-06,
      "loss": 0.1613,
      "step": 16667
    },
    {
      "epoch": 1.2953061858874728,
      "grad_norm": 0.7529119253158569,
      "learning_rate": 3.523469070562636e-06,
      "loss": 0.1449,
      "step": 16668
    },
    {
      "epoch": 1.2953838980416537,
      "grad_norm": 0.1954224854707718,
      "learning_rate": 3.5230805097917316e-06,
      "loss": 0.0508,
      "step": 16669
    },
    {
      "epoch": 1.2954616101958347,
      "grad_norm": 0.20667248964309692,
      "learning_rate": 3.5226919490208274e-06,
      "loss": 0.0428,
      "step": 16670
    },
    {
      "epoch": 1.2955393223500156,
      "grad_norm": 0.6003671884536743,
      "learning_rate": 3.5223033882499223e-06,
      "loss": 0.2048,
      "step": 16671
    },
    {
      "epoch": 1.2956170345041964,
      "grad_norm": 0.8620174527168274,
      "learning_rate": 3.521914827479018e-06,
      "loss": 0.1544,
      "step": 16672
    },
    {
      "epoch": 1.2956947466583775,
      "grad_norm": 1.0750893354415894,
      "learning_rate": 3.5215262667081135e-06,
      "loss": 0.322,
      "step": 16673
    },
    {
      "epoch": 1.2957724588125583,
      "grad_norm": 1.1395207643508911,
      "learning_rate": 3.521137705937209e-06,
      "loss": 0.2909,
      "step": 16674
    },
    {
      "epoch": 1.2958501709667392,
      "grad_norm": 0.21453121304512024,
      "learning_rate": 3.5207491451663046e-06,
      "loss": 0.0355,
      "step": 16675
    },
    {
      "epoch": 1.2959278831209202,
      "grad_norm": 0.30235907435417175,
      "learning_rate": 3.5203605843953996e-06,
      "loss": 0.0624,
      "step": 16676
    },
    {
      "epoch": 1.296005595275101,
      "grad_norm": 0.34324026107788086,
      "learning_rate": 3.519972023624495e-06,
      "loss": 0.124,
      "step": 16677
    },
    {
      "epoch": 1.296083307429282,
      "grad_norm": 0.47720304131507874,
      "learning_rate": 3.5195834628535908e-06,
      "loss": 0.3775,
      "step": 16678
    },
    {
      "epoch": 1.296161019583463,
      "grad_norm": 0.937557578086853,
      "learning_rate": 3.519194902082686e-06,
      "loss": 0.5,
      "step": 16679
    },
    {
      "epoch": 1.2962387317376438,
      "grad_norm": 0.30652210116386414,
      "learning_rate": 3.518806341311781e-06,
      "loss": 0.0669,
      "step": 16680
    },
    {
      "epoch": 1.2963164438918247,
      "grad_norm": 1.1523393392562866,
      "learning_rate": 3.518417780540877e-06,
      "loss": 0.523,
      "step": 16681
    },
    {
      "epoch": 1.2963941560460057,
      "grad_norm": 0.12488853931427002,
      "learning_rate": 3.5180292197699723e-06,
      "loss": 0.0686,
      "step": 16682
    },
    {
      "epoch": 1.2964718682001866,
      "grad_norm": 0.6076939105987549,
      "learning_rate": 3.5176406589990676e-06,
      "loss": 0.387,
      "step": 16683
    },
    {
      "epoch": 1.2965495803543674,
      "grad_norm": 0.9961205720901489,
      "learning_rate": 3.5172520982281634e-06,
      "loss": 0.2548,
      "step": 16684
    },
    {
      "epoch": 1.2966272925085485,
      "grad_norm": 0.6858890056610107,
      "learning_rate": 3.5168635374572584e-06,
      "loss": 0.4009,
      "step": 16685
    },
    {
      "epoch": 1.2967050046627293,
      "grad_norm": 0.5598865151405334,
      "learning_rate": 3.516474976686354e-06,
      "loss": 0.4231,
      "step": 16686
    },
    {
      "epoch": 1.2967827168169102,
      "grad_norm": 0.17432858049869537,
      "learning_rate": 3.5160864159154495e-06,
      "loss": 0.0112,
      "step": 16687
    },
    {
      "epoch": 1.2968604289710912,
      "grad_norm": 0.30006012320518494,
      "learning_rate": 3.515697855144545e-06,
      "loss": 0.0706,
      "step": 16688
    },
    {
      "epoch": 1.296938141125272,
      "grad_norm": 0.7861815094947815,
      "learning_rate": 3.5153092943736407e-06,
      "loss": 0.3034,
      "step": 16689
    },
    {
      "epoch": 1.297015853279453,
      "grad_norm": 0.2496834695339203,
      "learning_rate": 3.5149207336027357e-06,
      "loss": 0.0704,
      "step": 16690
    },
    {
      "epoch": 1.2970935654336337,
      "grad_norm": 0.5413576364517212,
      "learning_rate": 3.514532172831831e-06,
      "loss": 0.1061,
      "step": 16691
    },
    {
      "epoch": 1.2971712775878148,
      "grad_norm": 0.46939709782600403,
      "learning_rate": 3.514143612060927e-06,
      "loss": 0.1062,
      "step": 16692
    },
    {
      "epoch": 1.2972489897419957,
      "grad_norm": 0.16008104383945465,
      "learning_rate": 3.513755051290022e-06,
      "loss": 0.0841,
      "step": 16693
    },
    {
      "epoch": 1.2973267018961765,
      "grad_norm": 0.29811781644821167,
      "learning_rate": 3.513366490519117e-06,
      "loss": 0.0677,
      "step": 16694
    },
    {
      "epoch": 1.2974044140503576,
      "grad_norm": 0.18190403282642365,
      "learning_rate": 3.512977929748213e-06,
      "loss": 0.0576,
      "step": 16695
    },
    {
      "epoch": 1.2974821262045384,
      "grad_norm": 0.08442970365285873,
      "learning_rate": 3.5125893689773083e-06,
      "loss": 0.0104,
      "step": 16696
    },
    {
      "epoch": 1.2975598383587192,
      "grad_norm": 0.4185495674610138,
      "learning_rate": 3.5122008082064037e-06,
      "loss": 0.0915,
      "step": 16697
    },
    {
      "epoch": 1.2976375505129,
      "grad_norm": 0.3083569407463074,
      "learning_rate": 3.5118122474354995e-06,
      "loss": 0.1842,
      "step": 16698
    },
    {
      "epoch": 1.2977152626670811,
      "grad_norm": 0.21727509796619415,
      "learning_rate": 3.5114236866645944e-06,
      "loss": 0.1196,
      "step": 16699
    },
    {
      "epoch": 1.297792974821262,
      "grad_norm": 0.5400844812393188,
      "learning_rate": 3.5110351258936902e-06,
      "loss": 0.177,
      "step": 16700
    },
    {
      "epoch": 1.2978706869754428,
      "grad_norm": 0.2931175231933594,
      "learning_rate": 3.5106465651227856e-06,
      "loss": 0.0625,
      "step": 16701
    },
    {
      "epoch": 1.297948399129624,
      "grad_norm": 0.1695684790611267,
      "learning_rate": 3.510258004351881e-06,
      "loss": 0.0359,
      "step": 16702
    },
    {
      "epoch": 1.2980261112838047,
      "grad_norm": 0.2627686858177185,
      "learning_rate": 3.509869443580977e-06,
      "loss": 0.1526,
      "step": 16703
    },
    {
      "epoch": 1.2981038234379856,
      "grad_norm": 0.26162204146385193,
      "learning_rate": 3.5094808828100717e-06,
      "loss": 0.075,
      "step": 16704
    },
    {
      "epoch": 1.2981815355921666,
      "grad_norm": 1.0048458576202393,
      "learning_rate": 3.509092322039167e-06,
      "loss": 0.6073,
      "step": 16705
    },
    {
      "epoch": 1.2982592477463475,
      "grad_norm": 0.41137608885765076,
      "learning_rate": 3.508703761268263e-06,
      "loss": 0.1461,
      "step": 16706
    },
    {
      "epoch": 1.2983369599005283,
      "grad_norm": 0.4299335777759552,
      "learning_rate": 3.5083152004973583e-06,
      "loss": 0.2092,
      "step": 16707
    },
    {
      "epoch": 1.2984146720547094,
      "grad_norm": 0.5806194543838501,
      "learning_rate": 3.5079266397264532e-06,
      "loss": 0.1623,
      "step": 16708
    },
    {
      "epoch": 1.2984923842088902,
      "grad_norm": 0.2883366644382477,
      "learning_rate": 3.507538078955549e-06,
      "loss": 0.1435,
      "step": 16709
    },
    {
      "epoch": 1.298570096363071,
      "grad_norm": 0.5551546812057495,
      "learning_rate": 3.5071495181846444e-06,
      "loss": 0.1731,
      "step": 16710
    },
    {
      "epoch": 1.2986478085172521,
      "grad_norm": 0.08295902609825134,
      "learning_rate": 3.5067609574137398e-06,
      "loss": 0.0301,
      "step": 16711
    },
    {
      "epoch": 1.298725520671433,
      "grad_norm": 0.5023822784423828,
      "learning_rate": 3.506372396642835e-06,
      "loss": 0.16,
      "step": 16712
    },
    {
      "epoch": 1.2988032328256138,
      "grad_norm": 0.15609882771968842,
      "learning_rate": 3.5059838358719305e-06,
      "loss": 0.1779,
      "step": 16713
    },
    {
      "epoch": 1.298880944979795,
      "grad_norm": 0.7078410387039185,
      "learning_rate": 3.505595275101026e-06,
      "loss": 0.5328,
      "step": 16714
    },
    {
      "epoch": 1.2989586571339757,
      "grad_norm": 0.2597237527370453,
      "learning_rate": 3.5052067143301217e-06,
      "loss": 0.1214,
      "step": 16715
    },
    {
      "epoch": 1.2990363692881566,
      "grad_norm": 0.5818918943405151,
      "learning_rate": 3.5048181535592166e-06,
      "loss": 0.3661,
      "step": 16716
    },
    {
      "epoch": 1.2991140814423376,
      "grad_norm": 0.12428311258554459,
      "learning_rate": 3.5044295927883124e-06,
      "loss": 0.0263,
      "step": 16717
    },
    {
      "epoch": 1.2991917935965185,
      "grad_norm": 0.4331306219100952,
      "learning_rate": 3.504041032017408e-06,
      "loss": 0.4711,
      "step": 16718
    },
    {
      "epoch": 1.2992695057506993,
      "grad_norm": 0.5803636312484741,
      "learning_rate": 3.503652471246503e-06,
      "loss": 0.1206,
      "step": 16719
    },
    {
      "epoch": 1.2993472179048804,
      "grad_norm": 0.05284849926829338,
      "learning_rate": 3.503263910475599e-06,
      "loss": 0.0067,
      "step": 16720
    },
    {
      "epoch": 1.2994249300590612,
      "grad_norm": 0.7250220775604248,
      "learning_rate": 3.502875349704694e-06,
      "loss": 0.2945,
      "step": 16721
    },
    {
      "epoch": 1.299502642213242,
      "grad_norm": 0.11747363954782486,
      "learning_rate": 3.5024867889337893e-06,
      "loss": 0.0547,
      "step": 16722
    },
    {
      "epoch": 1.2995803543674231,
      "grad_norm": 0.5605684518814087,
      "learning_rate": 3.502098228162885e-06,
      "loss": 0.245,
      "step": 16723
    },
    {
      "epoch": 1.299658066521604,
      "grad_norm": 0.6123246550559998,
      "learning_rate": 3.5017096673919805e-06,
      "loss": 0.2694,
      "step": 16724
    },
    {
      "epoch": 1.2997357786757848,
      "grad_norm": 0.7994200587272644,
      "learning_rate": 3.5013211066210754e-06,
      "loss": 1.0077,
      "step": 16725
    },
    {
      "epoch": 1.299813490829966,
      "grad_norm": 0.203607439994812,
      "learning_rate": 3.5009325458501712e-06,
      "loss": 0.1037,
      "step": 16726
    },
    {
      "epoch": 1.2998912029841467,
      "grad_norm": 0.28863245248794556,
      "learning_rate": 3.5005439850792666e-06,
      "loss": 0.0732,
      "step": 16727
    },
    {
      "epoch": 1.2999689151383276,
      "grad_norm": 0.1867632120847702,
      "learning_rate": 3.500155424308362e-06,
      "loss": 0.1624,
      "step": 16728
    },
    {
      "epoch": 1.3000466272925086,
      "grad_norm": 0.10794465243816376,
      "learning_rate": 3.4997668635374578e-06,
      "loss": 0.0363,
      "step": 16729
    },
    {
      "epoch": 1.3001243394466895,
      "grad_norm": 0.6246359348297119,
      "learning_rate": 3.4993783027665527e-06,
      "loss": 0.4154,
      "step": 16730
    },
    {
      "epoch": 1.3002020516008703,
      "grad_norm": 0.1670437455177307,
      "learning_rate": 3.4989897419956485e-06,
      "loss": 0.0871,
      "step": 16731
    },
    {
      "epoch": 1.3002797637550514,
      "grad_norm": 1.2690613269805908,
      "learning_rate": 3.498601181224744e-06,
      "loss": 0.7777,
      "step": 16732
    },
    {
      "epoch": 1.3003574759092322,
      "grad_norm": 0.5419760346412659,
      "learning_rate": 3.4982126204538393e-06,
      "loss": 0.5129,
      "step": 16733
    },
    {
      "epoch": 1.300435188063413,
      "grad_norm": 0.7401657700538635,
      "learning_rate": 3.497824059682935e-06,
      "loss": 0.2276,
      "step": 16734
    },
    {
      "epoch": 1.3005129002175941,
      "grad_norm": 0.45900511741638184,
      "learning_rate": 3.49743549891203e-06,
      "loss": 0.2152,
      "step": 16735
    },
    {
      "epoch": 1.300590612371775,
      "grad_norm": 0.44061464071273804,
      "learning_rate": 3.4970469381411254e-06,
      "loss": 0.0584,
      "step": 16736
    },
    {
      "epoch": 1.3006683245259558,
      "grad_norm": 0.3930022716522217,
      "learning_rate": 3.496658377370221e-06,
      "loss": 0.0509,
      "step": 16737
    },
    {
      "epoch": 1.3007460366801369,
      "grad_norm": 0.3502236306667328,
      "learning_rate": 3.4962698165993165e-06,
      "loss": 0.1871,
      "step": 16738
    },
    {
      "epoch": 1.3008237488343177,
      "grad_norm": 0.3453529477119446,
      "learning_rate": 3.4958812558284115e-06,
      "loss": 0.033,
      "step": 16739
    },
    {
      "epoch": 1.3009014609884986,
      "grad_norm": 0.414619505405426,
      "learning_rate": 3.4954926950575073e-06,
      "loss": 0.1102,
      "step": 16740
    },
    {
      "epoch": 1.3009791731426796,
      "grad_norm": 0.19284987449645996,
      "learning_rate": 3.4951041342866027e-06,
      "loss": 0.061,
      "step": 16741
    },
    {
      "epoch": 1.3010568852968605,
      "grad_norm": 0.3031081259250641,
      "learning_rate": 3.494715573515698e-06,
      "loss": 0.0438,
      "step": 16742
    },
    {
      "epoch": 1.3011345974510413,
      "grad_norm": 0.30115699768066406,
      "learning_rate": 3.494327012744794e-06,
      "loss": 0.0405,
      "step": 16743
    },
    {
      "epoch": 1.3012123096052224,
      "grad_norm": 0.4126052260398865,
      "learning_rate": 3.4939384519738888e-06,
      "loss": 0.1348,
      "step": 16744
    },
    {
      "epoch": 1.3012900217594032,
      "grad_norm": 0.20428341627120972,
      "learning_rate": 3.493549891202984e-06,
      "loss": 0.0807,
      "step": 16745
    },
    {
      "epoch": 1.301367733913584,
      "grad_norm": 0.574680745601654,
      "learning_rate": 3.49316133043208e-06,
      "loss": 0.2177,
      "step": 16746
    },
    {
      "epoch": 1.3014454460677651,
      "grad_norm": 0.4833446145057678,
      "learning_rate": 3.4927727696611753e-06,
      "loss": 0.1772,
      "step": 16747
    },
    {
      "epoch": 1.301523158221946,
      "grad_norm": 0.541994035243988,
      "learning_rate": 3.492384208890271e-06,
      "loss": 0.2166,
      "step": 16748
    },
    {
      "epoch": 1.3016008703761268,
      "grad_norm": 0.21002233028411865,
      "learning_rate": 3.491995648119366e-06,
      "loss": 0.0421,
      "step": 16749
    },
    {
      "epoch": 1.3016785825303077,
      "grad_norm": 0.4633040130138397,
      "learning_rate": 3.4916070873484615e-06,
      "loss": 0.4043,
      "step": 16750
    },
    {
      "epoch": 1.3017562946844887,
      "grad_norm": 0.33088546991348267,
      "learning_rate": 3.4912185265775572e-06,
      "loss": 0.0557,
      "step": 16751
    },
    {
      "epoch": 1.3018340068386696,
      "grad_norm": 0.8505454063415527,
      "learning_rate": 3.4908299658066526e-06,
      "loss": 0.2493,
      "step": 16752
    },
    {
      "epoch": 1.3019117189928504,
      "grad_norm": 0.09942468255758286,
      "learning_rate": 3.4904414050357476e-06,
      "loss": 0.0102,
      "step": 16753
    },
    {
      "epoch": 1.3019894311470315,
      "grad_norm": 0.5804359912872314,
      "learning_rate": 3.4900528442648434e-06,
      "loss": 0.3418,
      "step": 16754
    },
    {
      "epoch": 1.3020671433012123,
      "grad_norm": 0.1751692146062851,
      "learning_rate": 3.4896642834939387e-06,
      "loss": 0.0641,
      "step": 16755
    },
    {
      "epoch": 1.3021448554553932,
      "grad_norm": 0.5583059191703796,
      "learning_rate": 3.489275722723034e-06,
      "loss": 0.3641,
      "step": 16756
    },
    {
      "epoch": 1.302222567609574,
      "grad_norm": 0.4819437265396118,
      "learning_rate": 3.48888716195213e-06,
      "loss": 0.0865,
      "step": 16757
    },
    {
      "epoch": 1.302300279763755,
      "grad_norm": 0.3410758674144745,
      "learning_rate": 3.488498601181225e-06,
      "loss": 0.048,
      "step": 16758
    },
    {
      "epoch": 1.302377991917936,
      "grad_norm": 0.1991366744041443,
      "learning_rate": 3.4881100404103202e-06,
      "loss": 0.0184,
      "step": 16759
    },
    {
      "epoch": 1.3024557040721167,
      "grad_norm": 0.833978533744812,
      "learning_rate": 3.487721479639416e-06,
      "loss": 0.3132,
      "step": 16760
    },
    {
      "epoch": 1.3025334162262978,
      "grad_norm": 0.45432233810424805,
      "learning_rate": 3.4873329188685114e-06,
      "loss": 0.1364,
      "step": 16761
    },
    {
      "epoch": 1.3026111283804787,
      "grad_norm": 0.4708389937877655,
      "learning_rate": 3.486944358097607e-06,
      "loss": 0.2173,
      "step": 16762
    },
    {
      "epoch": 1.3026888405346595,
      "grad_norm": 0.4400957226753235,
      "learning_rate": 3.486555797326702e-06,
      "loss": 0.1216,
      "step": 16763
    },
    {
      "epoch": 1.3027665526888406,
      "grad_norm": 0.23444201052188873,
      "learning_rate": 3.4861672365557975e-06,
      "loss": 0.3538,
      "step": 16764
    },
    {
      "epoch": 1.3028442648430214,
      "grad_norm": 0.41653621196746826,
      "learning_rate": 3.4857786757848933e-06,
      "loss": 0.1372,
      "step": 16765
    },
    {
      "epoch": 1.3029219769972022,
      "grad_norm": 0.3804362416267395,
      "learning_rate": 3.4853901150139887e-06,
      "loss": 0.1885,
      "step": 16766
    },
    {
      "epoch": 1.3029996891513833,
      "grad_norm": 0.29999271035194397,
      "learning_rate": 3.4850015542430836e-06,
      "loss": 0.1108,
      "step": 16767
    },
    {
      "epoch": 1.3030774013055642,
      "grad_norm": 0.6197724938392639,
      "learning_rate": 3.4846129934721794e-06,
      "loss": 0.2502,
      "step": 16768
    },
    {
      "epoch": 1.303155113459745,
      "grad_norm": 0.3706604838371277,
      "learning_rate": 3.484224432701275e-06,
      "loss": 0.0431,
      "step": 16769
    },
    {
      "epoch": 1.303232825613926,
      "grad_norm": 0.34732306003570557,
      "learning_rate": 3.48383587193037e-06,
      "loss": 0.0401,
      "step": 16770
    },
    {
      "epoch": 1.303310537768107,
      "grad_norm": 0.9066873788833618,
      "learning_rate": 3.483447311159466e-06,
      "loss": 0.1765,
      "step": 16771
    },
    {
      "epoch": 1.3033882499222877,
      "grad_norm": 1.1750811338424683,
      "learning_rate": 3.483058750388561e-06,
      "loss": 0.1986,
      "step": 16772
    },
    {
      "epoch": 1.3034659620764688,
      "grad_norm": 0.5790347456932068,
      "learning_rate": 3.4826701896176563e-06,
      "loss": 0.1478,
      "step": 16773
    },
    {
      "epoch": 1.3035436742306497,
      "grad_norm": 1.402541160583496,
      "learning_rate": 3.482281628846752e-06,
      "loss": 0.3419,
      "step": 16774
    },
    {
      "epoch": 1.3036213863848305,
      "grad_norm": 0.7034114599227905,
      "learning_rate": 3.481893068075847e-06,
      "loss": 0.1713,
      "step": 16775
    },
    {
      "epoch": 1.3036990985390116,
      "grad_norm": 0.19970935583114624,
      "learning_rate": 3.481504507304943e-06,
      "loss": 0.0421,
      "step": 16776
    },
    {
      "epoch": 1.3037768106931924,
      "grad_norm": 0.3868217468261719,
      "learning_rate": 3.4811159465340382e-06,
      "loss": 0.0964,
      "step": 16777
    },
    {
      "epoch": 1.3038545228473732,
      "grad_norm": 0.5811923146247864,
      "learning_rate": 3.4807273857631336e-06,
      "loss": 0.1385,
      "step": 16778
    },
    {
      "epoch": 1.3039322350015543,
      "grad_norm": 0.7474890947341919,
      "learning_rate": 3.4803388249922294e-06,
      "loss": 0.2685,
      "step": 16779
    },
    {
      "epoch": 1.3040099471557351,
      "grad_norm": 0.12021663784980774,
      "learning_rate": 3.4799502642213243e-06,
      "loss": 0.0164,
      "step": 16780
    },
    {
      "epoch": 1.304087659309916,
      "grad_norm": 1.0208932161331177,
      "learning_rate": 3.4795617034504197e-06,
      "loss": 0.1988,
      "step": 16781
    },
    {
      "epoch": 1.304165371464097,
      "grad_norm": 0.594937264919281,
      "learning_rate": 3.4791731426795155e-06,
      "loss": 0.7057,
      "step": 16782
    },
    {
      "epoch": 1.304243083618278,
      "grad_norm": 0.2854020893573761,
      "learning_rate": 3.478784581908611e-06,
      "loss": 0.0755,
      "step": 16783
    },
    {
      "epoch": 1.3043207957724587,
      "grad_norm": 0.49851351976394653,
      "learning_rate": 3.478396021137706e-06,
      "loss": 0.1005,
      "step": 16784
    },
    {
      "epoch": 1.3043985079266398,
      "grad_norm": 0.1003933697938919,
      "learning_rate": 3.4780074603668016e-06,
      "loss": 0.0213,
      "step": 16785
    },
    {
      "epoch": 1.3044762200808206,
      "grad_norm": 0.6843127608299255,
      "learning_rate": 3.477618899595897e-06,
      "loss": 0.3326,
      "step": 16786
    },
    {
      "epoch": 1.3045539322350015,
      "grad_norm": 0.3530731499195099,
      "learning_rate": 3.4772303388249924e-06,
      "loss": 0.1189,
      "step": 16787
    },
    {
      "epoch": 1.3046316443891826,
      "grad_norm": 0.7192667722702026,
      "learning_rate": 3.476841778054088e-06,
      "loss": 0.3551,
      "step": 16788
    },
    {
      "epoch": 1.3047093565433634,
      "grad_norm": 0.037331435829401016,
      "learning_rate": 3.476453217283183e-06,
      "loss": 0.0021,
      "step": 16789
    },
    {
      "epoch": 1.3047870686975442,
      "grad_norm": 0.19290265440940857,
      "learning_rate": 3.4760646565122785e-06,
      "loss": 0.0453,
      "step": 16790
    },
    {
      "epoch": 1.3048647808517253,
      "grad_norm": 0.6767470240592957,
      "learning_rate": 3.4756760957413743e-06,
      "loss": 0.4137,
      "step": 16791
    },
    {
      "epoch": 1.3049424930059061,
      "grad_norm": 0.2799721956253052,
      "learning_rate": 3.4752875349704697e-06,
      "loss": 0.0944,
      "step": 16792
    },
    {
      "epoch": 1.305020205160087,
      "grad_norm": 0.45609790086746216,
      "learning_rate": 3.4748989741995655e-06,
      "loss": 0.1137,
      "step": 16793
    },
    {
      "epoch": 1.305097917314268,
      "grad_norm": 0.35118040442466736,
      "learning_rate": 3.4745104134286604e-06,
      "loss": 0.128,
      "step": 16794
    },
    {
      "epoch": 1.305175629468449,
      "grad_norm": 0.16758780181407928,
      "learning_rate": 3.474121852657756e-06,
      "loss": 0.0565,
      "step": 16795
    },
    {
      "epoch": 1.3052533416226297,
      "grad_norm": 0.17482741177082062,
      "learning_rate": 3.4737332918868516e-06,
      "loss": 0.0372,
      "step": 16796
    },
    {
      "epoch": 1.3053310537768108,
      "grad_norm": 0.7113494277000427,
      "learning_rate": 3.473344731115947e-06,
      "loss": 0.2193,
      "step": 16797
    },
    {
      "epoch": 1.3054087659309916,
      "grad_norm": 0.13795484602451324,
      "learning_rate": 3.472956170345042e-06,
      "loss": 0.0547,
      "step": 16798
    },
    {
      "epoch": 1.3054864780851725,
      "grad_norm": 0.4292915165424347,
      "learning_rate": 3.4725676095741377e-06,
      "loss": 0.073,
      "step": 16799
    },
    {
      "epoch": 1.3055641902393536,
      "grad_norm": 0.333126038312912,
      "learning_rate": 3.472179048803233e-06,
      "loss": 0.0951,
      "step": 16800
    },
    {
      "epoch": 1.3056419023935344,
      "grad_norm": 0.5513487458229065,
      "learning_rate": 3.4717904880323285e-06,
      "loss": 0.08,
      "step": 16801
    },
    {
      "epoch": 1.3057196145477152,
      "grad_norm": 0.7475078701972961,
      "learning_rate": 3.4714019272614242e-06,
      "loss": 0.536,
      "step": 16802
    },
    {
      "epoch": 1.3057973267018963,
      "grad_norm": 0.5431796312332153,
      "learning_rate": 3.471013366490519e-06,
      "loss": 0.1259,
      "step": 16803
    },
    {
      "epoch": 1.3058750388560771,
      "grad_norm": 0.24149172008037567,
      "learning_rate": 3.4706248057196146e-06,
      "loss": 0.0983,
      "step": 16804
    },
    {
      "epoch": 1.305952751010258,
      "grad_norm": 0.18372319638729095,
      "learning_rate": 3.4702362449487104e-06,
      "loss": 0.0102,
      "step": 16805
    },
    {
      "epoch": 1.306030463164439,
      "grad_norm": 1.1500160694122314,
      "learning_rate": 3.4698476841778057e-06,
      "loss": 0.2269,
      "step": 16806
    },
    {
      "epoch": 1.30610817531862,
      "grad_norm": 1.1329855918884277,
      "learning_rate": 3.4694591234069015e-06,
      "loss": 0.5917,
      "step": 16807
    },
    {
      "epoch": 1.3061858874728007,
      "grad_norm": 0.27709224820137024,
      "learning_rate": 3.4690705626359965e-06,
      "loss": 0.0769,
      "step": 16808
    },
    {
      "epoch": 1.3062635996269818,
      "grad_norm": 0.5671128034591675,
      "learning_rate": 3.468682001865092e-06,
      "loss": 0.1527,
      "step": 16809
    },
    {
      "epoch": 1.3063413117811626,
      "grad_norm": 0.29708191752433777,
      "learning_rate": 3.4682934410941877e-06,
      "loss": 0.0955,
      "step": 16810
    },
    {
      "epoch": 1.3064190239353435,
      "grad_norm": 0.39642980694770813,
      "learning_rate": 3.467904880323283e-06,
      "loss": 0.1024,
      "step": 16811
    },
    {
      "epoch": 1.3064967360895243,
      "grad_norm": 0.27715301513671875,
      "learning_rate": 3.467516319552378e-06,
      "loss": 0.2003,
      "step": 16812
    },
    {
      "epoch": 1.3065744482437054,
      "grad_norm": 0.08267001062631607,
      "learning_rate": 3.4671277587814738e-06,
      "loss": 0.0278,
      "step": 16813
    },
    {
      "epoch": 1.3066521603978862,
      "grad_norm": 0.23221877217292786,
      "learning_rate": 3.466739198010569e-06,
      "loss": 0.0432,
      "step": 16814
    },
    {
      "epoch": 1.306729872552067,
      "grad_norm": 0.28847622871398926,
      "learning_rate": 3.4663506372396645e-06,
      "loss": 0.0741,
      "step": 16815
    },
    {
      "epoch": 1.3068075847062481,
      "grad_norm": 0.5274712443351746,
      "learning_rate": 3.4659620764687603e-06,
      "loss": 0.2305,
      "step": 16816
    },
    {
      "epoch": 1.306885296860429,
      "grad_norm": 0.21640396118164062,
      "learning_rate": 3.4655735156978553e-06,
      "loss": 0.0179,
      "step": 16817
    },
    {
      "epoch": 1.3069630090146098,
      "grad_norm": 0.12835223972797394,
      "learning_rate": 3.4651849549269506e-06,
      "loss": 0.0184,
      "step": 16818
    },
    {
      "epoch": 1.3070407211687907,
      "grad_norm": 0.182185098528862,
      "learning_rate": 3.4647963941560464e-06,
      "loss": 0.0431,
      "step": 16819
    },
    {
      "epoch": 1.3071184333229717,
      "grad_norm": 0.825054407119751,
      "learning_rate": 3.464407833385142e-06,
      "loss": 0.2397,
      "step": 16820
    },
    {
      "epoch": 1.3071961454771526,
      "grad_norm": 0.25944629311561584,
      "learning_rate": 3.4640192726142376e-06,
      "loss": 0.1211,
      "step": 16821
    },
    {
      "epoch": 1.3072738576313334,
      "grad_norm": 0.5966250896453857,
      "learning_rate": 3.4636307118433326e-06,
      "loss": 0.098,
      "step": 16822
    },
    {
      "epoch": 1.3073515697855145,
      "grad_norm": 0.8336222171783447,
      "learning_rate": 3.463242151072428e-06,
      "loss": 0.4246,
      "step": 16823
    },
    {
      "epoch": 1.3074292819396953,
      "grad_norm": 0.6029846668243408,
      "learning_rate": 3.4628535903015237e-06,
      "loss": 0.1787,
      "step": 16824
    },
    {
      "epoch": 1.3075069940938762,
      "grad_norm": 0.11741907894611359,
      "learning_rate": 3.462465029530619e-06,
      "loss": 0.0416,
      "step": 16825
    },
    {
      "epoch": 1.3075847062480572,
      "grad_norm": 0.2583217918872833,
      "learning_rate": 3.462076468759714e-06,
      "loss": 0.032,
      "step": 16826
    },
    {
      "epoch": 1.307662418402238,
      "grad_norm": 0.46601876616477966,
      "learning_rate": 3.46168790798881e-06,
      "loss": 0.1913,
      "step": 16827
    },
    {
      "epoch": 1.307740130556419,
      "grad_norm": 0.768413782119751,
      "learning_rate": 3.4612993472179052e-06,
      "loss": 0.2566,
      "step": 16828
    },
    {
      "epoch": 1.3078178427106,
      "grad_norm": 0.4390588104724884,
      "learning_rate": 3.4609107864470006e-06,
      "loss": 0.1247,
      "step": 16829
    },
    {
      "epoch": 1.3078955548647808,
      "grad_norm": 0.9910737872123718,
      "learning_rate": 3.4605222256760964e-06,
      "loss": 0.1732,
      "step": 16830
    },
    {
      "epoch": 1.3079732670189617,
      "grad_norm": 0.6198020577430725,
      "learning_rate": 3.4601336649051913e-06,
      "loss": 0.2177,
      "step": 16831
    },
    {
      "epoch": 1.3080509791731427,
      "grad_norm": 0.186904639005661,
      "learning_rate": 3.4597451041342867e-06,
      "loss": 0.0322,
      "step": 16832
    },
    {
      "epoch": 1.3081286913273236,
      "grad_norm": 0.366896390914917,
      "learning_rate": 3.4593565433633825e-06,
      "loss": 0.0336,
      "step": 16833
    },
    {
      "epoch": 1.3082064034815044,
      "grad_norm": 0.34571611881256104,
      "learning_rate": 3.458967982592478e-06,
      "loss": 0.2758,
      "step": 16834
    },
    {
      "epoch": 1.3082841156356855,
      "grad_norm": 1.1536203622817993,
      "learning_rate": 3.458579421821573e-06,
      "loss": 0.3676,
      "step": 16835
    },
    {
      "epoch": 1.3083618277898663,
      "grad_norm": 0.3309820890426636,
      "learning_rate": 3.4581908610506686e-06,
      "loss": 0.0877,
      "step": 16836
    },
    {
      "epoch": 1.3084395399440472,
      "grad_norm": 0.9456847310066223,
      "learning_rate": 3.457802300279764e-06,
      "loss": 0.4889,
      "step": 16837
    },
    {
      "epoch": 1.3085172520982282,
      "grad_norm": 0.6961067318916321,
      "learning_rate": 3.45741373950886e-06,
      "loss": 0.1298,
      "step": 16838
    },
    {
      "epoch": 1.308594964252409,
      "grad_norm": 1.5950127840042114,
      "learning_rate": 3.4570251787379548e-06,
      "loss": 0.4348,
      "step": 16839
    },
    {
      "epoch": 1.30867267640659,
      "grad_norm": 0.20804297924041748,
      "learning_rate": 3.45663661796705e-06,
      "loss": 0.0434,
      "step": 16840
    },
    {
      "epoch": 1.308750388560771,
      "grad_norm": 0.642537534236908,
      "learning_rate": 3.456248057196146e-06,
      "loss": 0.0954,
      "step": 16841
    },
    {
      "epoch": 1.3088281007149518,
      "grad_norm": 0.16748040914535522,
      "learning_rate": 3.4558594964252413e-06,
      "loss": 0.0256,
      "step": 16842
    },
    {
      "epoch": 1.3089058128691327,
      "grad_norm": 0.5328969955444336,
      "learning_rate": 3.4554709356543362e-06,
      "loss": 0.106,
      "step": 16843
    },
    {
      "epoch": 1.3089835250233137,
      "grad_norm": 0.7099739909172058,
      "learning_rate": 3.455082374883432e-06,
      "loss": 0.5242,
      "step": 16844
    },
    {
      "epoch": 1.3090612371774946,
      "grad_norm": 0.46682748198509216,
      "learning_rate": 3.4546938141125274e-06,
      "loss": 0.2732,
      "step": 16845
    },
    {
      "epoch": 1.3091389493316754,
      "grad_norm": 0.4831491708755493,
      "learning_rate": 3.454305253341623e-06,
      "loss": 0.168,
      "step": 16846
    },
    {
      "epoch": 1.3092166614858565,
      "grad_norm": 0.3153012692928314,
      "learning_rate": 3.4539166925707186e-06,
      "loss": 0.0919,
      "step": 16847
    },
    {
      "epoch": 1.3092943736400373,
      "grad_norm": 0.619552731513977,
      "learning_rate": 3.4535281317998135e-06,
      "loss": 0.2442,
      "step": 16848
    },
    {
      "epoch": 1.3093720857942182,
      "grad_norm": 0.25192132592201233,
      "learning_rate": 3.453139571028909e-06,
      "loss": 0.1795,
      "step": 16849
    },
    {
      "epoch": 1.3094497979483992,
      "grad_norm": 0.08541221171617508,
      "learning_rate": 3.4527510102580047e-06,
      "loss": 0.0076,
      "step": 16850
    },
    {
      "epoch": 1.30952751010258,
      "grad_norm": 0.7293798327445984,
      "learning_rate": 3.4523624494871e-06,
      "loss": 0.3099,
      "step": 16851
    },
    {
      "epoch": 1.309605222256761,
      "grad_norm": 0.4216316342353821,
      "learning_rate": 3.451973888716196e-06,
      "loss": 0.1326,
      "step": 16852
    },
    {
      "epoch": 1.309682934410942,
      "grad_norm": 0.9694523811340332,
      "learning_rate": 3.451585327945291e-06,
      "loss": 0.3465,
      "step": 16853
    },
    {
      "epoch": 1.3097606465651228,
      "grad_norm": 0.532405436038971,
      "learning_rate": 3.451196767174386e-06,
      "loss": 0.4975,
      "step": 16854
    },
    {
      "epoch": 1.3098383587193037,
      "grad_norm": 1.6134167909622192,
      "learning_rate": 3.450808206403482e-06,
      "loss": 0.5321,
      "step": 16855
    },
    {
      "epoch": 1.3099160708734847,
      "grad_norm": 0.28615278005599976,
      "learning_rate": 3.4504196456325774e-06,
      "loss": 0.0654,
      "step": 16856
    },
    {
      "epoch": 1.3099937830276656,
      "grad_norm": 0.1710725873708725,
      "learning_rate": 3.4500310848616723e-06,
      "loss": 0.0261,
      "step": 16857
    },
    {
      "epoch": 1.3100714951818464,
      "grad_norm": 0.4010685980319977,
      "learning_rate": 3.449642524090768e-06,
      "loss": 0.1258,
      "step": 16858
    },
    {
      "epoch": 1.3101492073360275,
      "grad_norm": 0.9293270707130432,
      "learning_rate": 3.4492539633198635e-06,
      "loss": 0.1947,
      "step": 16859
    },
    {
      "epoch": 1.3102269194902083,
      "grad_norm": 0.28661856055259705,
      "learning_rate": 3.448865402548959e-06,
      "loss": 0.0892,
      "step": 16860
    },
    {
      "epoch": 1.3103046316443892,
      "grad_norm": 0.36073026061058044,
      "learning_rate": 3.4484768417780547e-06,
      "loss": 0.1042,
      "step": 16861
    },
    {
      "epoch": 1.3103823437985702,
      "grad_norm": 1.0256386995315552,
      "learning_rate": 3.4480882810071496e-06,
      "loss": 0.4537,
      "step": 16862
    },
    {
      "epoch": 1.310460055952751,
      "grad_norm": 0.4599830210208893,
      "learning_rate": 3.447699720236245e-06,
      "loss": 0.1039,
      "step": 16863
    },
    {
      "epoch": 1.310537768106932,
      "grad_norm": 0.16155239939689636,
      "learning_rate": 3.4473111594653408e-06,
      "loss": 0.0513,
      "step": 16864
    },
    {
      "epoch": 1.310615480261113,
      "grad_norm": 0.5729836821556091,
      "learning_rate": 3.446922598694436e-06,
      "loss": 0.1319,
      "step": 16865
    },
    {
      "epoch": 1.3106931924152938,
      "grad_norm": 1.0743751525878906,
      "learning_rate": 3.446534037923531e-06,
      "loss": 0.3821,
      "step": 16866
    },
    {
      "epoch": 1.3107709045694746,
      "grad_norm": 1.172919511795044,
      "learning_rate": 3.446145477152627e-06,
      "loss": 0.1432,
      "step": 16867
    },
    {
      "epoch": 1.3108486167236557,
      "grad_norm": 0.5483376979827881,
      "learning_rate": 3.4457569163817223e-06,
      "loss": 0.2177,
      "step": 16868
    },
    {
      "epoch": 1.3109263288778366,
      "grad_norm": 0.5653639435768127,
      "learning_rate": 3.445368355610818e-06,
      "loss": 0.2051,
      "step": 16869
    },
    {
      "epoch": 1.3110040410320174,
      "grad_norm": 0.09813495725393295,
      "learning_rate": 3.4449797948399134e-06,
      "loss": 0.0085,
      "step": 16870
    },
    {
      "epoch": 1.3110817531861982,
      "grad_norm": 0.6638761758804321,
      "learning_rate": 3.4445912340690084e-06,
      "loss": 0.3445,
      "step": 16871
    },
    {
      "epoch": 1.3111594653403793,
      "grad_norm": 1.0628085136413574,
      "learning_rate": 3.444202673298104e-06,
      "loss": 0.369,
      "step": 16872
    },
    {
      "epoch": 1.3112371774945601,
      "grad_norm": 0.44797247648239136,
      "learning_rate": 3.4438141125271996e-06,
      "loss": 0.1614,
      "step": 16873
    },
    {
      "epoch": 1.311314889648741,
      "grad_norm": 0.335379421710968,
      "learning_rate": 3.443425551756295e-06,
      "loss": 0.1835,
      "step": 16874
    },
    {
      "epoch": 1.311392601802922,
      "grad_norm": 0.9508482217788696,
      "learning_rate": 3.4430369909853907e-06,
      "loss": 0.2846,
      "step": 16875
    },
    {
      "epoch": 1.311470313957103,
      "grad_norm": 0.6106630563735962,
      "learning_rate": 3.4426484302144857e-06,
      "loss": 0.1546,
      "step": 16876
    },
    {
      "epoch": 1.3115480261112837,
      "grad_norm": 0.622535228729248,
      "learning_rate": 3.442259869443581e-06,
      "loss": 0.1104,
      "step": 16877
    },
    {
      "epoch": 1.3116257382654646,
      "grad_norm": 0.22308345139026642,
      "learning_rate": 3.441871308672677e-06,
      "loss": 0.0298,
      "step": 16878
    },
    {
      "epoch": 1.3117034504196456,
      "grad_norm": 0.7044826745986938,
      "learning_rate": 3.4414827479017722e-06,
      "loss": 0.4127,
      "step": 16879
    },
    {
      "epoch": 1.3117811625738265,
      "grad_norm": 0.9541951417922974,
      "learning_rate": 3.441094187130867e-06,
      "loss": 0.9338,
      "step": 16880
    },
    {
      "epoch": 1.3118588747280073,
      "grad_norm": 0.5365710258483887,
      "learning_rate": 3.440705626359963e-06,
      "loss": 0.0807,
      "step": 16881
    },
    {
      "epoch": 1.3119365868821884,
      "grad_norm": 0.12214162945747375,
      "learning_rate": 3.4403170655890583e-06,
      "loss": 0.0416,
      "step": 16882
    },
    {
      "epoch": 1.3120142990363692,
      "grad_norm": 0.274687260389328,
      "learning_rate": 3.439928504818154e-06,
      "loss": 0.0435,
      "step": 16883
    },
    {
      "epoch": 1.31209201119055,
      "grad_norm": 1.0848510265350342,
      "learning_rate": 3.4395399440472495e-06,
      "loss": 0.6172,
      "step": 16884
    },
    {
      "epoch": 1.3121697233447311,
      "grad_norm": 0.8110758066177368,
      "learning_rate": 3.4391513832763445e-06,
      "loss": 0.293,
      "step": 16885
    },
    {
      "epoch": 1.312247435498912,
      "grad_norm": 0.2882901728153229,
      "learning_rate": 3.4387628225054403e-06,
      "loss": 0.1164,
      "step": 16886
    },
    {
      "epoch": 1.3123251476530928,
      "grad_norm": 0.36683788895606995,
      "learning_rate": 3.4383742617345356e-06,
      "loss": 0.1577,
      "step": 16887
    },
    {
      "epoch": 1.312402859807274,
      "grad_norm": 0.45852065086364746,
      "learning_rate": 3.437985700963631e-06,
      "loss": 0.0659,
      "step": 16888
    },
    {
      "epoch": 1.3124805719614547,
      "grad_norm": 0.4513826072216034,
      "learning_rate": 3.437597140192727e-06,
      "loss": 0.2729,
      "step": 16889
    },
    {
      "epoch": 1.3125582841156356,
      "grad_norm": 0.7393766641616821,
      "learning_rate": 3.4372085794218218e-06,
      "loss": 0.3093,
      "step": 16890
    },
    {
      "epoch": 1.3126359962698166,
      "grad_norm": 0.2830554246902466,
      "learning_rate": 3.436820018650917e-06,
      "loss": 0.0948,
      "step": 16891
    },
    {
      "epoch": 1.3127137084239975,
      "grad_norm": 0.7444990873336792,
      "learning_rate": 3.436431457880013e-06,
      "loss": 0.0539,
      "step": 16892
    },
    {
      "epoch": 1.3127914205781783,
      "grad_norm": 0.6451340913772583,
      "learning_rate": 3.4360428971091083e-06,
      "loss": 0.1309,
      "step": 16893
    },
    {
      "epoch": 1.3128691327323594,
      "grad_norm": 0.4524061381816864,
      "learning_rate": 3.4356543363382033e-06,
      "loss": 0.1119,
      "step": 16894
    },
    {
      "epoch": 1.3129468448865402,
      "grad_norm": 0.947387158870697,
      "learning_rate": 3.435265775567299e-06,
      "loss": 0.4327,
      "step": 16895
    },
    {
      "epoch": 1.313024557040721,
      "grad_norm": 0.2314993441104889,
      "learning_rate": 3.4348772147963944e-06,
      "loss": 0.1156,
      "step": 16896
    },
    {
      "epoch": 1.3131022691949021,
      "grad_norm": 0.03565135598182678,
      "learning_rate": 3.4344886540254902e-06,
      "loss": 0.0022,
      "step": 16897
    },
    {
      "epoch": 1.313179981349083,
      "grad_norm": 0.18539774417877197,
      "learning_rate": 3.434100093254585e-06,
      "loss": 0.0325,
      "step": 16898
    },
    {
      "epoch": 1.3132576935032638,
      "grad_norm": 0.5997502207756042,
      "learning_rate": 3.4337115324836805e-06,
      "loss": 0.3005,
      "step": 16899
    },
    {
      "epoch": 1.3133354056574449,
      "grad_norm": 0.6337724924087524,
      "learning_rate": 3.4333229717127763e-06,
      "loss": 0.1227,
      "step": 16900
    },
    {
      "epoch": 1.3134131178116257,
      "grad_norm": 0.2245711237192154,
      "learning_rate": 3.4329344109418717e-06,
      "loss": 0.0911,
      "step": 16901
    },
    {
      "epoch": 1.3134908299658066,
      "grad_norm": 0.4240673780441284,
      "learning_rate": 3.4325458501709667e-06,
      "loss": 0.1315,
      "step": 16902
    },
    {
      "epoch": 1.3135685421199876,
      "grad_norm": 0.11431150138378143,
      "learning_rate": 3.4321572894000625e-06,
      "loss": 0.0138,
      "step": 16903
    },
    {
      "epoch": 1.3136462542741685,
      "grad_norm": 0.6072284579277039,
      "learning_rate": 3.431768728629158e-06,
      "loss": 0.1506,
      "step": 16904
    },
    {
      "epoch": 1.3137239664283493,
      "grad_norm": 0.41322627663612366,
      "learning_rate": 3.431380167858253e-06,
      "loss": 0.1699,
      "step": 16905
    },
    {
      "epoch": 1.3138016785825304,
      "grad_norm": 0.44125068187713623,
      "learning_rate": 3.430991607087349e-06,
      "loss": 0.1586,
      "step": 16906
    },
    {
      "epoch": 1.3138793907367112,
      "grad_norm": 0.5650606155395508,
      "learning_rate": 3.430603046316444e-06,
      "loss": 0.1687,
      "step": 16907
    },
    {
      "epoch": 1.313957102890892,
      "grad_norm": 0.4883568584918976,
      "learning_rate": 3.4302144855455393e-06,
      "loss": 0.2472,
      "step": 16908
    },
    {
      "epoch": 1.3140348150450731,
      "grad_norm": 0.3768368363380432,
      "learning_rate": 3.429825924774635e-06,
      "loss": 0.1892,
      "step": 16909
    },
    {
      "epoch": 1.314112527199254,
      "grad_norm": 1.9727306365966797,
      "learning_rate": 3.4294373640037305e-06,
      "loss": 0.7259,
      "step": 16910
    },
    {
      "epoch": 1.3141902393534348,
      "grad_norm": 1.1531697511672974,
      "learning_rate": 3.4290488032328254e-06,
      "loss": 0.5057,
      "step": 16911
    },
    {
      "epoch": 1.3142679515076159,
      "grad_norm": 0.49454501271247864,
      "learning_rate": 3.4286602424619212e-06,
      "loss": 0.2184,
      "step": 16912
    },
    {
      "epoch": 1.3143456636617967,
      "grad_norm": 0.6944743990898132,
      "learning_rate": 3.4282716816910166e-06,
      "loss": 0.1403,
      "step": 16913
    },
    {
      "epoch": 1.3144233758159776,
      "grad_norm": 1.2177132368087769,
      "learning_rate": 3.4278831209201124e-06,
      "loss": 0.3571,
      "step": 16914
    },
    {
      "epoch": 1.3145010879701586,
      "grad_norm": 0.26878151297569275,
      "learning_rate": 3.4274945601492078e-06,
      "loss": 0.0306,
      "step": 16915
    },
    {
      "epoch": 1.3145788001243395,
      "grad_norm": 0.1920263022184372,
      "learning_rate": 3.4271059993783027e-06,
      "loss": 0.0611,
      "step": 16916
    },
    {
      "epoch": 1.3146565122785203,
      "grad_norm": 0.33369025588035583,
      "learning_rate": 3.4267174386073985e-06,
      "loss": 0.1814,
      "step": 16917
    },
    {
      "epoch": 1.3147342244327014,
      "grad_norm": 0.5654825568199158,
      "learning_rate": 3.426328877836494e-06,
      "loss": 0.1569,
      "step": 16918
    },
    {
      "epoch": 1.3148119365868822,
      "grad_norm": 0.9863064885139465,
      "learning_rate": 3.4259403170655893e-06,
      "loss": 0.5829,
      "step": 16919
    },
    {
      "epoch": 1.314889648741063,
      "grad_norm": 0.8849462866783142,
      "learning_rate": 3.425551756294685e-06,
      "loss": 0.1685,
      "step": 16920
    },
    {
      "epoch": 1.3149673608952441,
      "grad_norm": 0.3503960371017456,
      "learning_rate": 3.42516319552378e-06,
      "loss": 0.0465,
      "step": 16921
    },
    {
      "epoch": 1.315045073049425,
      "grad_norm": 0.8068253993988037,
      "learning_rate": 3.4247746347528754e-06,
      "loss": 0.239,
      "step": 16922
    },
    {
      "epoch": 1.3151227852036058,
      "grad_norm": 0.5157313346862793,
      "learning_rate": 3.424386073981971e-06,
      "loss": 0.2657,
      "step": 16923
    },
    {
      "epoch": 1.3152004973577869,
      "grad_norm": 0.5140416622161865,
      "learning_rate": 3.4239975132110666e-06,
      "loss": 0.1216,
      "step": 16924
    },
    {
      "epoch": 1.3152782095119677,
      "grad_norm": 0.4335702657699585,
      "learning_rate": 3.4236089524401615e-06,
      "loss": 0.1539,
      "step": 16925
    },
    {
      "epoch": 1.3153559216661486,
      "grad_norm": 0.5656306147575378,
      "learning_rate": 3.4232203916692573e-06,
      "loss": 0.4095,
      "step": 16926
    },
    {
      "epoch": 1.3154336338203296,
      "grad_norm": 0.7400168776512146,
      "learning_rate": 3.4228318308983527e-06,
      "loss": 0.1235,
      "step": 16927
    },
    {
      "epoch": 1.3155113459745105,
      "grad_norm": 0.12421462684869766,
      "learning_rate": 3.4224432701274485e-06,
      "loss": 0.0226,
      "step": 16928
    },
    {
      "epoch": 1.3155890581286913,
      "grad_norm": 1.2030237913131714,
      "learning_rate": 3.422054709356544e-06,
      "loss": 0.8842,
      "step": 16929
    },
    {
      "epoch": 1.3156667702828724,
      "grad_norm": 0.1390528678894043,
      "learning_rate": 3.421666148585639e-06,
      "loss": 0.0503,
      "step": 16930
    },
    {
      "epoch": 1.3157444824370532,
      "grad_norm": 0.5067083835601807,
      "learning_rate": 3.4212775878147346e-06,
      "loss": 0.1638,
      "step": 16931
    },
    {
      "epoch": 1.315822194591234,
      "grad_norm": 0.6930183172225952,
      "learning_rate": 3.42088902704383e-06,
      "loss": 0.2081,
      "step": 16932
    },
    {
      "epoch": 1.315899906745415,
      "grad_norm": 0.6341906785964966,
      "learning_rate": 3.4205004662729254e-06,
      "loss": 0.1778,
      "step": 16933
    },
    {
      "epoch": 1.315977618899596,
      "grad_norm": 0.49220260977745056,
      "learning_rate": 3.420111905502021e-06,
      "loss": 0.4072,
      "step": 16934
    },
    {
      "epoch": 1.3160553310537768,
      "grad_norm": 0.48551544547080994,
      "learning_rate": 3.419723344731116e-06,
      "loss": 0.1991,
      "step": 16935
    },
    {
      "epoch": 1.3161330432079577,
      "grad_norm": 0.5925964117050171,
      "learning_rate": 3.4193347839602115e-06,
      "loss": 0.0778,
      "step": 16936
    },
    {
      "epoch": 1.3162107553621387,
      "grad_norm": 0.44523492455482483,
      "learning_rate": 3.4189462231893073e-06,
      "loss": 0.5778,
      "step": 16937
    },
    {
      "epoch": 1.3162884675163196,
      "grad_norm": 0.5726593732833862,
      "learning_rate": 3.4185576624184026e-06,
      "loss": 0.5245,
      "step": 16938
    },
    {
      "epoch": 1.3163661796705004,
      "grad_norm": 0.5659628510475159,
      "learning_rate": 3.4181691016474976e-06,
      "loss": 0.3213,
      "step": 16939
    },
    {
      "epoch": 1.3164438918246812,
      "grad_norm": 0.6074077486991882,
      "learning_rate": 3.4177805408765934e-06,
      "loss": 0.2117,
      "step": 16940
    },
    {
      "epoch": 1.3165216039788623,
      "grad_norm": 0.16854353249073029,
      "learning_rate": 3.4173919801056888e-06,
      "loss": 0.0445,
      "step": 16941
    },
    {
      "epoch": 1.3165993161330432,
      "grad_norm": 0.7084355354309082,
      "learning_rate": 3.417003419334784e-06,
      "loss": 0.2708,
      "step": 16942
    },
    {
      "epoch": 1.316677028287224,
      "grad_norm": 0.33147549629211426,
      "learning_rate": 3.41661485856388e-06,
      "loss": 0.2168,
      "step": 16943
    },
    {
      "epoch": 1.316754740441405,
      "grad_norm": 0.7991582751274109,
      "learning_rate": 3.416226297792975e-06,
      "loss": 0.9026,
      "step": 16944
    },
    {
      "epoch": 1.316832452595586,
      "grad_norm": 1.3546251058578491,
      "learning_rate": 3.4158377370220707e-06,
      "loss": 0.5819,
      "step": 16945
    },
    {
      "epoch": 1.3169101647497667,
      "grad_norm": 0.10220102965831757,
      "learning_rate": 3.415449176251166e-06,
      "loss": 0.0174,
      "step": 16946
    },
    {
      "epoch": 1.3169878769039478,
      "grad_norm": 0.8223029375076294,
      "learning_rate": 3.4150606154802614e-06,
      "loss": 0.3069,
      "step": 16947
    },
    {
      "epoch": 1.3170655890581286,
      "grad_norm": 0.6568841934204102,
      "learning_rate": 3.4146720547093572e-06,
      "loss": 0.0816,
      "step": 16948
    },
    {
      "epoch": 1.3171433012123095,
      "grad_norm": 0.5976148843765259,
      "learning_rate": 3.414283493938452e-06,
      "loss": 0.2842,
      "step": 16949
    },
    {
      "epoch": 1.3172210133664906,
      "grad_norm": 0.8544638752937317,
      "learning_rate": 3.4138949331675475e-06,
      "loss": 0.5503,
      "step": 16950
    },
    {
      "epoch": 1.3172987255206714,
      "grad_norm": 0.6913056969642639,
      "learning_rate": 3.4135063723966433e-06,
      "loss": 0.1089,
      "step": 16951
    },
    {
      "epoch": 1.3173764376748522,
      "grad_norm": 0.3357585370540619,
      "learning_rate": 3.4131178116257387e-06,
      "loss": 0.1667,
      "step": 16952
    },
    {
      "epoch": 1.3174541498290333,
      "grad_norm": 0.640924870967865,
      "learning_rate": 3.4127292508548337e-06,
      "loss": 0.448,
      "step": 16953
    },
    {
      "epoch": 1.3175318619832141,
      "grad_norm": 0.3915145993232727,
      "learning_rate": 3.4123406900839295e-06,
      "loss": 0.1034,
      "step": 16954
    },
    {
      "epoch": 1.317609574137395,
      "grad_norm": 0.2536715269088745,
      "learning_rate": 3.411952129313025e-06,
      "loss": 0.0876,
      "step": 16955
    },
    {
      "epoch": 1.317687286291576,
      "grad_norm": 1.2405465841293335,
      "learning_rate": 3.41156356854212e-06,
      "loss": 0.3521,
      "step": 16956
    },
    {
      "epoch": 1.317764998445757,
      "grad_norm": 1.052423119544983,
      "learning_rate": 3.411175007771216e-06,
      "loss": 0.3963,
      "step": 16957
    },
    {
      "epoch": 1.3178427105999377,
      "grad_norm": 0.13748995959758759,
      "learning_rate": 3.410786447000311e-06,
      "loss": 0.0409,
      "step": 16958
    },
    {
      "epoch": 1.3179204227541188,
      "grad_norm": 0.7066802978515625,
      "learning_rate": 3.4103978862294068e-06,
      "loss": 0.785,
      "step": 16959
    },
    {
      "epoch": 1.3179981349082996,
      "grad_norm": 0.5957511067390442,
      "learning_rate": 3.410009325458502e-06,
      "loss": 0.243,
      "step": 16960
    },
    {
      "epoch": 1.3180758470624805,
      "grad_norm": 0.25650784373283386,
      "learning_rate": 3.409620764687597e-06,
      "loss": 0.0535,
      "step": 16961
    },
    {
      "epoch": 1.3181535592166616,
      "grad_norm": 0.1772405207157135,
      "learning_rate": 3.409232203916693e-06,
      "loss": 0.0292,
      "step": 16962
    },
    {
      "epoch": 1.3182312713708424,
      "grad_norm": 0.1769857257604599,
      "learning_rate": 3.4088436431457882e-06,
      "loss": 0.0628,
      "step": 16963
    },
    {
      "epoch": 1.3183089835250232,
      "grad_norm": 1.0662569999694824,
      "learning_rate": 3.4084550823748836e-06,
      "loss": 0.254,
      "step": 16964
    },
    {
      "epoch": 1.3183866956792043,
      "grad_norm": 0.34991952776908875,
      "learning_rate": 3.4080665216039794e-06,
      "loss": 0.1128,
      "step": 16965
    },
    {
      "epoch": 1.3184644078333851,
      "grad_norm": 0.2657449543476105,
      "learning_rate": 3.4076779608330744e-06,
      "loss": 0.0643,
      "step": 16966
    },
    {
      "epoch": 1.318542119987566,
      "grad_norm": 0.3041204512119293,
      "learning_rate": 3.4072894000621697e-06,
      "loss": 0.1305,
      "step": 16967
    },
    {
      "epoch": 1.318619832141747,
      "grad_norm": 0.11439617723226547,
      "learning_rate": 3.4069008392912655e-06,
      "loss": 0.0324,
      "step": 16968
    },
    {
      "epoch": 1.318697544295928,
      "grad_norm": 0.16100157797336578,
      "learning_rate": 3.406512278520361e-06,
      "loss": 0.0745,
      "step": 16969
    },
    {
      "epoch": 1.3187752564501087,
      "grad_norm": 2.3719608783721924,
      "learning_rate": 3.406123717749456e-06,
      "loss": 0.5329,
      "step": 16970
    },
    {
      "epoch": 1.3188529686042898,
      "grad_norm": 0.5961911678314209,
      "learning_rate": 3.4057351569785517e-06,
      "loss": 0.2904,
      "step": 16971
    },
    {
      "epoch": 1.3189306807584706,
      "grad_norm": 0.12107478827238083,
      "learning_rate": 3.405346596207647e-06,
      "loss": 0.0721,
      "step": 16972
    },
    {
      "epoch": 1.3190083929126515,
      "grad_norm": 0.3296411335468292,
      "learning_rate": 3.404958035436743e-06,
      "loss": 0.262,
      "step": 16973
    },
    {
      "epoch": 1.3190861050668325,
      "grad_norm": 0.3007671535015106,
      "learning_rate": 3.404569474665838e-06,
      "loss": 0.032,
      "step": 16974
    },
    {
      "epoch": 1.3191638172210134,
      "grad_norm": 0.8227444887161255,
      "learning_rate": 3.404180913894933e-06,
      "loss": 0.4022,
      "step": 16975
    },
    {
      "epoch": 1.3192415293751942,
      "grad_norm": 0.11192677170038223,
      "learning_rate": 3.403792353124029e-06,
      "loss": 0.0241,
      "step": 16976
    },
    {
      "epoch": 1.3193192415293753,
      "grad_norm": 1.0267328023910522,
      "learning_rate": 3.4034037923531243e-06,
      "loss": 0.4786,
      "step": 16977
    },
    {
      "epoch": 1.3193969536835561,
      "grad_norm": 0.26875147223472595,
      "learning_rate": 3.4030152315822197e-06,
      "loss": 0.0501,
      "step": 16978
    },
    {
      "epoch": 1.319474665837737,
      "grad_norm": 0.4775247871875763,
      "learning_rate": 3.4026266708113155e-06,
      "loss": 0.2381,
      "step": 16979
    },
    {
      "epoch": 1.319552377991918,
      "grad_norm": 0.38097694516181946,
      "learning_rate": 3.4022381100404104e-06,
      "loss": 0.2554,
      "step": 16980
    },
    {
      "epoch": 1.3196300901460989,
      "grad_norm": 0.32077741622924805,
      "learning_rate": 3.401849549269506e-06,
      "loss": 0.0681,
      "step": 16981
    },
    {
      "epoch": 1.3197078023002797,
      "grad_norm": 0.4175476133823395,
      "learning_rate": 3.4014609884986016e-06,
      "loss": 0.1619,
      "step": 16982
    },
    {
      "epoch": 1.3197855144544608,
      "grad_norm": 0.2631354033946991,
      "learning_rate": 3.401072427727697e-06,
      "loss": 0.0401,
      "step": 16983
    },
    {
      "epoch": 1.3198632266086416,
      "grad_norm": 0.6837894320487976,
      "learning_rate": 3.400683866956792e-06,
      "loss": 0.2106,
      "step": 16984
    },
    {
      "epoch": 1.3199409387628225,
      "grad_norm": 0.35704702138900757,
      "learning_rate": 3.4002953061858877e-06,
      "loss": 0.6383,
      "step": 16985
    },
    {
      "epoch": 1.3200186509170035,
      "grad_norm": 0.6047110557556152,
      "learning_rate": 3.399906745414983e-06,
      "loss": 0.1637,
      "step": 16986
    },
    {
      "epoch": 1.3200963630711844,
      "grad_norm": 0.4131743311882019,
      "learning_rate": 3.3995181846440785e-06,
      "loss": 0.1808,
      "step": 16987
    },
    {
      "epoch": 1.3201740752253652,
      "grad_norm": 1.0249857902526855,
      "learning_rate": 3.3991296238731743e-06,
      "loss": 0.2467,
      "step": 16988
    },
    {
      "epoch": 1.3202517873795463,
      "grad_norm": 0.2595043480396271,
      "learning_rate": 3.3987410631022692e-06,
      "loss": 0.166,
      "step": 16989
    },
    {
      "epoch": 1.3203294995337271,
      "grad_norm": 0.49845993518829346,
      "learning_rate": 3.398352502331365e-06,
      "loss": 0.2179,
      "step": 16990
    },
    {
      "epoch": 1.320407211687908,
      "grad_norm": 0.846502959728241,
      "learning_rate": 3.3979639415604604e-06,
      "loss": 0.1617,
      "step": 16991
    },
    {
      "epoch": 1.3204849238420888,
      "grad_norm": 0.6657382249832153,
      "learning_rate": 3.3975753807895558e-06,
      "loss": 0.3015,
      "step": 16992
    },
    {
      "epoch": 1.3205626359962699,
      "grad_norm": 0.25407978892326355,
      "learning_rate": 3.3971868200186516e-06,
      "loss": 0.0989,
      "step": 16993
    },
    {
      "epoch": 1.3206403481504507,
      "grad_norm": 0.5395436882972717,
      "learning_rate": 3.3967982592477465e-06,
      "loss": 0.2882,
      "step": 16994
    },
    {
      "epoch": 1.3207180603046316,
      "grad_norm": 0.3414759337902069,
      "learning_rate": 3.396409698476842e-06,
      "loss": 0.0765,
      "step": 16995
    },
    {
      "epoch": 1.3207957724588126,
      "grad_norm": 0.36981645226478577,
      "learning_rate": 3.3960211377059377e-06,
      "loss": 0.0857,
      "step": 16996
    },
    {
      "epoch": 1.3208734846129935,
      "grad_norm": 0.2856220006942749,
      "learning_rate": 3.395632576935033e-06,
      "loss": 0.0414,
      "step": 16997
    },
    {
      "epoch": 1.3209511967671743,
      "grad_norm": 0.5965586304664612,
      "learning_rate": 3.395244016164128e-06,
      "loss": 0.1921,
      "step": 16998
    },
    {
      "epoch": 1.3210289089213554,
      "grad_norm": 0.08069170266389847,
      "learning_rate": 3.394855455393224e-06,
      "loss": 0.0079,
      "step": 16999
    },
    {
      "epoch": 1.3211066210755362,
      "grad_norm": 0.2361195981502533,
      "learning_rate": 3.394466894622319e-06,
      "loss": 0.1271,
      "step": 17000
    },
    {
      "epoch": 1.321184333229717,
      "grad_norm": 0.1885031759738922,
      "learning_rate": 3.3940783338514145e-06,
      "loss": 0.0412,
      "step": 17001
    },
    {
      "epoch": 1.321262045383898,
      "grad_norm": 0.4893038272857666,
      "learning_rate": 3.3936897730805103e-06,
      "loss": 0.1636,
      "step": 17002
    },
    {
      "epoch": 1.321339757538079,
      "grad_norm": 0.870525062084198,
      "learning_rate": 3.3933012123096053e-06,
      "loss": 0.2862,
      "step": 17003
    },
    {
      "epoch": 1.3214174696922598,
      "grad_norm": 0.7409388422966003,
      "learning_rate": 3.392912651538701e-06,
      "loss": 0.8341,
      "step": 17004
    },
    {
      "epoch": 1.3214951818464407,
      "grad_norm": 0.7721127867698669,
      "learning_rate": 3.3925240907677965e-06,
      "loss": 0.1516,
      "step": 17005
    },
    {
      "epoch": 1.3215728940006217,
      "grad_norm": 0.5520579218864441,
      "learning_rate": 3.392135529996892e-06,
      "loss": 0.5215,
      "step": 17006
    },
    {
      "epoch": 1.3216506061548026,
      "grad_norm": 0.38966190814971924,
      "learning_rate": 3.3917469692259876e-06,
      "loss": 0.2036,
      "step": 17007
    },
    {
      "epoch": 1.3217283183089834,
      "grad_norm": 0.4708899259567261,
      "learning_rate": 3.3913584084550826e-06,
      "loss": 0.4037,
      "step": 17008
    },
    {
      "epoch": 1.3218060304631645,
      "grad_norm": 0.5196009278297424,
      "learning_rate": 3.390969847684178e-06,
      "loss": 0.397,
      "step": 17009
    },
    {
      "epoch": 1.3218837426173453,
      "grad_norm": 0.43238532543182373,
      "learning_rate": 3.3905812869132738e-06,
      "loss": 0.1201,
      "step": 17010
    },
    {
      "epoch": 1.3219614547715262,
      "grad_norm": 0.09728419035673141,
      "learning_rate": 3.390192726142369e-06,
      "loss": 0.0265,
      "step": 17011
    },
    {
      "epoch": 1.3220391669257072,
      "grad_norm": 1.26638662815094,
      "learning_rate": 3.389804165371464e-06,
      "loss": 0.2007,
      "step": 17012
    },
    {
      "epoch": 1.322116879079888,
      "grad_norm": 0.6648180484771729,
      "learning_rate": 3.38941560460056e-06,
      "loss": 0.3312,
      "step": 17013
    },
    {
      "epoch": 1.322194591234069,
      "grad_norm": 0.5209568738937378,
      "learning_rate": 3.3890270438296552e-06,
      "loss": 0.1527,
      "step": 17014
    },
    {
      "epoch": 1.32227230338825,
      "grad_norm": 0.5799612402915955,
      "learning_rate": 3.3886384830587506e-06,
      "loss": 0.3264,
      "step": 17015
    },
    {
      "epoch": 1.3223500155424308,
      "grad_norm": 0.2464042454957962,
      "learning_rate": 3.3882499222878464e-06,
      "loss": 0.0818,
      "step": 17016
    },
    {
      "epoch": 1.3224277276966117,
      "grad_norm": 0.11427164077758789,
      "learning_rate": 3.3878613615169414e-06,
      "loss": 0.0648,
      "step": 17017
    },
    {
      "epoch": 1.3225054398507927,
      "grad_norm": 0.45066770911216736,
      "learning_rate": 3.3874728007460367e-06,
      "loss": 0.233,
      "step": 17018
    },
    {
      "epoch": 1.3225831520049736,
      "grad_norm": 0.14449980854988098,
      "learning_rate": 3.3870842399751325e-06,
      "loss": 0.0129,
      "step": 17019
    },
    {
      "epoch": 1.3226608641591544,
      "grad_norm": 0.535897970199585,
      "learning_rate": 3.386695679204228e-06,
      "loss": 0.0663,
      "step": 17020
    },
    {
      "epoch": 1.3227385763133355,
      "grad_norm": 0.15451504290103912,
      "learning_rate": 3.3863071184333233e-06,
      "loss": 0.0384,
      "step": 17021
    },
    {
      "epoch": 1.3228162884675163,
      "grad_norm": 0.35384583473205566,
      "learning_rate": 3.3859185576624187e-06,
      "loss": 0.0588,
      "step": 17022
    },
    {
      "epoch": 1.3228940006216972,
      "grad_norm": 0.6218676567077637,
      "learning_rate": 3.385529996891514e-06,
      "loss": 0.0611,
      "step": 17023
    },
    {
      "epoch": 1.3229717127758782,
      "grad_norm": 0.5679535269737244,
      "learning_rate": 3.38514143612061e-06,
      "loss": 0.3355,
      "step": 17024
    },
    {
      "epoch": 1.323049424930059,
      "grad_norm": 0.285637229681015,
      "learning_rate": 3.3847528753497048e-06,
      "loss": 0.0523,
      "step": 17025
    },
    {
      "epoch": 1.32312713708424,
      "grad_norm": 0.5942549109458923,
      "learning_rate": 3.3843643145788e-06,
      "loss": 0.4167,
      "step": 17026
    },
    {
      "epoch": 1.323204849238421,
      "grad_norm": 0.2709857225418091,
      "learning_rate": 3.383975753807896e-06,
      "loss": 0.0568,
      "step": 17027
    },
    {
      "epoch": 1.3232825613926018,
      "grad_norm": 0.7554972171783447,
      "learning_rate": 3.3835871930369913e-06,
      "loss": 0.266,
      "step": 17028
    },
    {
      "epoch": 1.3233602735467827,
      "grad_norm": 0.7083678841590881,
      "learning_rate": 3.3831986322660863e-06,
      "loss": 0.3268,
      "step": 17029
    },
    {
      "epoch": 1.3234379857009637,
      "grad_norm": 0.561773955821991,
      "learning_rate": 3.382810071495182e-06,
      "loss": 0.1859,
      "step": 17030
    },
    {
      "epoch": 1.3235156978551446,
      "grad_norm": 0.4908922016620636,
      "learning_rate": 3.3824215107242774e-06,
      "loss": 0.155,
      "step": 17031
    },
    {
      "epoch": 1.3235934100093254,
      "grad_norm": 0.3496969938278198,
      "learning_rate": 3.382032949953373e-06,
      "loss": 0.0716,
      "step": 17032
    },
    {
      "epoch": 1.3236711221635065,
      "grad_norm": 0.2134423404932022,
      "learning_rate": 3.3816443891824686e-06,
      "loss": 0.2142,
      "step": 17033
    },
    {
      "epoch": 1.3237488343176873,
      "grad_norm": 0.4702342748641968,
      "learning_rate": 3.3812558284115636e-06,
      "loss": 0.2643,
      "step": 17034
    },
    {
      "epoch": 1.3238265464718681,
      "grad_norm": 0.36472204327583313,
      "learning_rate": 3.3808672676406594e-06,
      "loss": 0.0837,
      "step": 17035
    },
    {
      "epoch": 1.3239042586260492,
      "grad_norm": 2.9865565299987793,
      "learning_rate": 3.3804787068697547e-06,
      "loss": 0.7455,
      "step": 17036
    },
    {
      "epoch": 1.32398197078023,
      "grad_norm": 0.1123935878276825,
      "learning_rate": 3.38009014609885e-06,
      "loss": 0.0389,
      "step": 17037
    },
    {
      "epoch": 1.324059682934411,
      "grad_norm": 0.36729055643081665,
      "learning_rate": 3.379701585327946e-06,
      "loss": 0.0581,
      "step": 17038
    },
    {
      "epoch": 1.324137395088592,
      "grad_norm": 0.08129556477069855,
      "learning_rate": 3.379313024557041e-06,
      "loss": 0.0077,
      "step": 17039
    },
    {
      "epoch": 1.3242151072427728,
      "grad_norm": 0.22644704580307007,
      "learning_rate": 3.3789244637861362e-06,
      "loss": 0.0631,
      "step": 17040
    },
    {
      "epoch": 1.3242928193969536,
      "grad_norm": 0.3359346389770508,
      "learning_rate": 3.378535903015232e-06,
      "loss": 0.1315,
      "step": 17041
    },
    {
      "epoch": 1.3243705315511347,
      "grad_norm": 0.18552733957767487,
      "learning_rate": 3.3781473422443274e-06,
      "loss": 0.0808,
      "step": 17042
    },
    {
      "epoch": 1.3244482437053156,
      "grad_norm": 0.4981713891029358,
      "learning_rate": 3.3777587814734223e-06,
      "loss": 0.044,
      "step": 17043
    },
    {
      "epoch": 1.3245259558594964,
      "grad_norm": 0.43985873460769653,
      "learning_rate": 3.377370220702518e-06,
      "loss": 0.126,
      "step": 17044
    },
    {
      "epoch": 1.3246036680136775,
      "grad_norm": 0.7118507027626038,
      "learning_rate": 3.3769816599316135e-06,
      "loss": 0.1838,
      "step": 17045
    },
    {
      "epoch": 1.3246813801678583,
      "grad_norm": 0.5415508151054382,
      "learning_rate": 3.376593099160709e-06,
      "loss": 0.1595,
      "step": 17046
    },
    {
      "epoch": 1.3247590923220391,
      "grad_norm": 0.40979066491127014,
      "learning_rate": 3.3762045383898047e-06,
      "loss": 0.1166,
      "step": 17047
    },
    {
      "epoch": 1.3248368044762202,
      "grad_norm": 0.9744977355003357,
      "learning_rate": 3.3758159776188996e-06,
      "loss": 0.5905,
      "step": 17048
    },
    {
      "epoch": 1.324914516630401,
      "grad_norm": 0.4271353781223297,
      "learning_rate": 3.3754274168479954e-06,
      "loss": 0.2602,
      "step": 17049
    },
    {
      "epoch": 1.324992228784582,
      "grad_norm": 0.4599427580833435,
      "learning_rate": 3.375038856077091e-06,
      "loss": 0.218,
      "step": 17050
    },
    {
      "epoch": 1.325069940938763,
      "grad_norm": 0.974819540977478,
      "learning_rate": 3.374650295306186e-06,
      "loss": 0.8402,
      "step": 17051
    },
    {
      "epoch": 1.3251476530929438,
      "grad_norm": 0.4152064919471741,
      "learning_rate": 3.374261734535282e-06,
      "loss": 0.0493,
      "step": 17052
    },
    {
      "epoch": 1.3252253652471246,
      "grad_norm": 0.3237603008747101,
      "learning_rate": 3.373873173764377e-06,
      "loss": 0.1741,
      "step": 17053
    },
    {
      "epoch": 1.3253030774013055,
      "grad_norm": 0.25077757239341736,
      "learning_rate": 3.3734846129934723e-06,
      "loss": 0.0887,
      "step": 17054
    },
    {
      "epoch": 1.3253807895554865,
      "grad_norm": 0.2891608476638794,
      "learning_rate": 3.373096052222568e-06,
      "loss": 0.1019,
      "step": 17055
    },
    {
      "epoch": 1.3254585017096674,
      "grad_norm": 0.20863531529903412,
      "learning_rate": 3.3727074914516635e-06,
      "loss": 0.0275,
      "step": 17056
    },
    {
      "epoch": 1.3255362138638482,
      "grad_norm": 0.6600054502487183,
      "learning_rate": 3.3723189306807584e-06,
      "loss": 0.236,
      "step": 17057
    },
    {
      "epoch": 1.3256139260180293,
      "grad_norm": 0.4841257929801941,
      "learning_rate": 3.3719303699098542e-06,
      "loss": 0.2245,
      "step": 17058
    },
    {
      "epoch": 1.3256916381722101,
      "grad_norm": 0.09133172035217285,
      "learning_rate": 3.3715418091389496e-06,
      "loss": 0.0103,
      "step": 17059
    },
    {
      "epoch": 1.325769350326391,
      "grad_norm": 0.35891303420066833,
      "learning_rate": 3.371153248368045e-06,
      "loss": 0.0705,
      "step": 17060
    },
    {
      "epoch": 1.3258470624805718,
      "grad_norm": 0.36695122718811035,
      "learning_rate": 3.3707646875971408e-06,
      "loss": 0.0389,
      "step": 17061
    },
    {
      "epoch": 1.325924774634753,
      "grad_norm": 0.34349682927131653,
      "learning_rate": 3.3703761268262357e-06,
      "loss": 0.1861,
      "step": 17062
    },
    {
      "epoch": 1.3260024867889337,
      "grad_norm": 0.29726019501686096,
      "learning_rate": 3.369987566055331e-06,
      "loss": 0.1061,
      "step": 17063
    },
    {
      "epoch": 1.3260801989431146,
      "grad_norm": 0.23407429456710815,
      "learning_rate": 3.369599005284427e-06,
      "loss": 0.1193,
      "step": 17064
    },
    {
      "epoch": 1.3261579110972956,
      "grad_norm": 0.7518267631530762,
      "learning_rate": 3.3692104445135222e-06,
      "loss": 0.5267,
      "step": 17065
    },
    {
      "epoch": 1.3262356232514765,
      "grad_norm": 0.29048672318458557,
      "learning_rate": 3.368821883742618e-06,
      "loss": 0.0534,
      "step": 17066
    },
    {
      "epoch": 1.3263133354056573,
      "grad_norm": 0.19766968488693237,
      "learning_rate": 3.368433322971713e-06,
      "loss": 0.0236,
      "step": 17067
    },
    {
      "epoch": 1.3263910475598384,
      "grad_norm": 0.4697475731372833,
      "learning_rate": 3.3680447622008084e-06,
      "loss": 0.2023,
      "step": 17068
    },
    {
      "epoch": 1.3264687597140192,
      "grad_norm": 0.5216740369796753,
      "learning_rate": 3.367656201429904e-06,
      "loss": 0.4608,
      "step": 17069
    },
    {
      "epoch": 1.3265464718682,
      "grad_norm": 0.39877763390541077,
      "learning_rate": 3.3672676406589995e-06,
      "loss": 0.2085,
      "step": 17070
    },
    {
      "epoch": 1.3266241840223811,
      "grad_norm": 0.369710236787796,
      "learning_rate": 3.3668790798880945e-06,
      "loss": 0.0727,
      "step": 17071
    },
    {
      "epoch": 1.326701896176562,
      "grad_norm": 0.7631890177726746,
      "learning_rate": 3.3664905191171903e-06,
      "loss": 0.4802,
      "step": 17072
    },
    {
      "epoch": 1.3267796083307428,
      "grad_norm": 0.41424351930618286,
      "learning_rate": 3.3661019583462857e-06,
      "loss": 0.1233,
      "step": 17073
    },
    {
      "epoch": 1.3268573204849239,
      "grad_norm": 0.4526374638080597,
      "learning_rate": 3.365713397575381e-06,
      "loss": 0.2499,
      "step": 17074
    },
    {
      "epoch": 1.3269350326391047,
      "grad_norm": 0.22658148407936096,
      "learning_rate": 3.365324836804477e-06,
      "loss": 0.0626,
      "step": 17075
    },
    {
      "epoch": 1.3270127447932856,
      "grad_norm": 0.9576351046562195,
      "learning_rate": 3.3649362760335718e-06,
      "loss": 0.2261,
      "step": 17076
    },
    {
      "epoch": 1.3270904569474666,
      "grad_norm": 0.31720343232154846,
      "learning_rate": 3.364547715262667e-06,
      "loss": 0.1145,
      "step": 17077
    },
    {
      "epoch": 1.3271681691016475,
      "grad_norm": 0.761112630367279,
      "learning_rate": 3.364159154491763e-06,
      "loss": 0.3863,
      "step": 17078
    },
    {
      "epoch": 1.3272458812558283,
      "grad_norm": 0.1544249802827835,
      "learning_rate": 3.3637705937208583e-06,
      "loss": 0.1297,
      "step": 17079
    },
    {
      "epoch": 1.3273235934100094,
      "grad_norm": 0.21501366794109344,
      "learning_rate": 3.363382032949954e-06,
      "loss": 0.1167,
      "step": 17080
    },
    {
      "epoch": 1.3274013055641902,
      "grad_norm": 0.3629007935523987,
      "learning_rate": 3.362993472179049e-06,
      "loss": 0.1063,
      "step": 17081
    },
    {
      "epoch": 1.327479017718371,
      "grad_norm": 0.21814663708209991,
      "learning_rate": 3.3626049114081444e-06,
      "loss": 0.0541,
      "step": 17082
    },
    {
      "epoch": 1.3275567298725521,
      "grad_norm": 0.1297082006931305,
      "learning_rate": 3.3622163506372402e-06,
      "loss": 0.0202,
      "step": 17083
    },
    {
      "epoch": 1.327634442026733,
      "grad_norm": 0.132249116897583,
      "learning_rate": 3.3618277898663356e-06,
      "loss": 0.013,
      "step": 17084
    },
    {
      "epoch": 1.3277121541809138,
      "grad_norm": 0.12935000658035278,
      "learning_rate": 3.3614392290954306e-06,
      "loss": 0.0338,
      "step": 17085
    },
    {
      "epoch": 1.3277898663350949,
      "grad_norm": 0.35889846086502075,
      "learning_rate": 3.3610506683245264e-06,
      "loss": 0.0426,
      "step": 17086
    },
    {
      "epoch": 1.3278675784892757,
      "grad_norm": 0.22549588978290558,
      "learning_rate": 3.3606621075536217e-06,
      "loss": 0.0899,
      "step": 17087
    },
    {
      "epoch": 1.3279452906434566,
      "grad_norm": 0.7901039719581604,
      "learning_rate": 3.3602735467827167e-06,
      "loss": 0.3928,
      "step": 17088
    },
    {
      "epoch": 1.3280230027976376,
      "grad_norm": 0.22793585062026978,
      "learning_rate": 3.3598849860118125e-06,
      "loss": 0.0256,
      "step": 17089
    },
    {
      "epoch": 1.3281007149518185,
      "grad_norm": 0.34823310375213623,
      "learning_rate": 3.359496425240908e-06,
      "loss": 0.0927,
      "step": 17090
    },
    {
      "epoch": 1.3281784271059993,
      "grad_norm": 1.6734036207199097,
      "learning_rate": 3.3591078644700032e-06,
      "loss": 0.6846,
      "step": 17091
    },
    {
      "epoch": 1.3282561392601804,
      "grad_norm": 0.7414144277572632,
      "learning_rate": 3.358719303699099e-06,
      "loss": 0.1628,
      "step": 17092
    },
    {
      "epoch": 1.3283338514143612,
      "grad_norm": 0.7705550193786621,
      "learning_rate": 3.358330742928194e-06,
      "loss": 0.0896,
      "step": 17093
    },
    {
      "epoch": 1.328411563568542,
      "grad_norm": 0.40954864025115967,
      "learning_rate": 3.3579421821572893e-06,
      "loss": 0.1635,
      "step": 17094
    },
    {
      "epoch": 1.3284892757227231,
      "grad_norm": 0.3504701256752014,
      "learning_rate": 3.357553621386385e-06,
      "loss": 0.0637,
      "step": 17095
    },
    {
      "epoch": 1.328566987876904,
      "grad_norm": 0.14441920816898346,
      "learning_rate": 3.3571650606154805e-06,
      "loss": 0.0365,
      "step": 17096
    },
    {
      "epoch": 1.3286447000310848,
      "grad_norm": 1.6720553636550903,
      "learning_rate": 3.3567764998445763e-06,
      "loss": 0.2764,
      "step": 17097
    },
    {
      "epoch": 1.3287224121852659,
      "grad_norm": 0.8759509921073914,
      "learning_rate": 3.3563879390736713e-06,
      "loss": 0.2457,
      "step": 17098
    },
    {
      "epoch": 1.3288001243394467,
      "grad_norm": 0.2833836078643799,
      "learning_rate": 3.3559993783027666e-06,
      "loss": 0.1243,
      "step": 17099
    },
    {
      "epoch": 1.3288778364936276,
      "grad_norm": 0.6992053985595703,
      "learning_rate": 3.3556108175318624e-06,
      "loss": 0.1917,
      "step": 17100
    },
    {
      "epoch": 1.3289555486478086,
      "grad_norm": 0.33964037895202637,
      "learning_rate": 3.355222256760958e-06,
      "loss": 0.0726,
      "step": 17101
    },
    {
      "epoch": 1.3290332608019895,
      "grad_norm": 0.5430479645729065,
      "learning_rate": 3.3548336959900528e-06,
      "loss": 0.4078,
      "step": 17102
    },
    {
      "epoch": 1.3291109729561703,
      "grad_norm": 0.6632535457611084,
      "learning_rate": 3.3544451352191486e-06,
      "loss": 0.1848,
      "step": 17103
    },
    {
      "epoch": 1.3291886851103514,
      "grad_norm": 0.255386084318161,
      "learning_rate": 3.354056574448244e-06,
      "loss": 0.0478,
      "step": 17104
    },
    {
      "epoch": 1.3292663972645322,
      "grad_norm": 0.8339828252792358,
      "learning_rate": 3.3536680136773393e-06,
      "loss": 0.337,
      "step": 17105
    },
    {
      "epoch": 1.329344109418713,
      "grad_norm": 0.6942064762115479,
      "learning_rate": 3.353279452906435e-06,
      "loss": 0.4151,
      "step": 17106
    },
    {
      "epoch": 1.3294218215728941,
      "grad_norm": 0.5135304927825928,
      "learning_rate": 3.35289089213553e-06,
      "loss": 0.267,
      "step": 17107
    },
    {
      "epoch": 1.329499533727075,
      "grad_norm": 0.37387704849243164,
      "learning_rate": 3.3525023313646254e-06,
      "loss": 0.0277,
      "step": 17108
    },
    {
      "epoch": 1.3295772458812558,
      "grad_norm": 0.7254086136817932,
      "learning_rate": 3.3521137705937212e-06,
      "loss": 0.3388,
      "step": 17109
    },
    {
      "epoch": 1.3296549580354369,
      "grad_norm": 0.8705756664276123,
      "learning_rate": 3.3517252098228166e-06,
      "loss": 0.5265,
      "step": 17110
    },
    {
      "epoch": 1.3297326701896177,
      "grad_norm": 0.72337806224823,
      "learning_rate": 3.3513366490519124e-06,
      "loss": 0.1715,
      "step": 17111
    },
    {
      "epoch": 1.3298103823437986,
      "grad_norm": 0.22579731047153473,
      "learning_rate": 3.3509480882810073e-06,
      "loss": 0.0505,
      "step": 17112
    },
    {
      "epoch": 1.3298880944979796,
      "grad_norm": 0.14601586759090424,
      "learning_rate": 3.3505595275101027e-06,
      "loss": 0.0353,
      "step": 17113
    },
    {
      "epoch": 1.3299658066521605,
      "grad_norm": 0.4052606523036957,
      "learning_rate": 3.3501709667391985e-06,
      "loss": 0.1136,
      "step": 17114
    },
    {
      "epoch": 1.3300435188063413,
      "grad_norm": 0.3387538492679596,
      "learning_rate": 3.349782405968294e-06,
      "loss": 0.1867,
      "step": 17115
    },
    {
      "epoch": 1.3301212309605221,
      "grad_norm": 0.4026186168193817,
      "learning_rate": 3.349393845197389e-06,
      "loss": 0.2301,
      "step": 17116
    },
    {
      "epoch": 1.3301989431147032,
      "grad_norm": 0.3041553199291229,
      "learning_rate": 3.3490052844264846e-06,
      "loss": 0.0318,
      "step": 17117
    },
    {
      "epoch": 1.330276655268884,
      "grad_norm": 0.34614381194114685,
      "learning_rate": 3.34861672365558e-06,
      "loss": 0.0583,
      "step": 17118
    },
    {
      "epoch": 1.330354367423065,
      "grad_norm": 0.4917564392089844,
      "learning_rate": 3.3482281628846754e-06,
      "loss": 0.0949,
      "step": 17119
    },
    {
      "epoch": 1.330432079577246,
      "grad_norm": 0.30271029472351074,
      "learning_rate": 3.347839602113771e-06,
      "loss": 0.0675,
      "step": 17120
    },
    {
      "epoch": 1.3305097917314268,
      "grad_norm": 0.34839072823524475,
      "learning_rate": 3.347451041342866e-06,
      "loss": 0.1647,
      "step": 17121
    },
    {
      "epoch": 1.3305875038856076,
      "grad_norm": 0.5223745703697205,
      "learning_rate": 3.3470624805719615e-06,
      "loss": 0.5054,
      "step": 17122
    },
    {
      "epoch": 1.3306652160397885,
      "grad_norm": 0.6928603053092957,
      "learning_rate": 3.3466739198010573e-06,
      "loss": 0.1702,
      "step": 17123
    },
    {
      "epoch": 1.3307429281939696,
      "grad_norm": 1.0047903060913086,
      "learning_rate": 3.3462853590301527e-06,
      "loss": 0.2415,
      "step": 17124
    },
    {
      "epoch": 1.3308206403481504,
      "grad_norm": 0.5289711356163025,
      "learning_rate": 3.3458967982592485e-06,
      "loss": 0.6199,
      "step": 17125
    },
    {
      "epoch": 1.3308983525023312,
      "grad_norm": 0.42014336585998535,
      "learning_rate": 3.3455082374883434e-06,
      "loss": 0.2528,
      "step": 17126
    },
    {
      "epoch": 1.3309760646565123,
      "grad_norm": 0.6258330941200256,
      "learning_rate": 3.3451196767174388e-06,
      "loss": 0.2105,
      "step": 17127
    },
    {
      "epoch": 1.3310537768106931,
      "grad_norm": 0.3526369333267212,
      "learning_rate": 3.3447311159465346e-06,
      "loss": 0.1131,
      "step": 17128
    },
    {
      "epoch": 1.331131488964874,
      "grad_norm": 0.35029637813568115,
      "learning_rate": 3.34434255517563e-06,
      "loss": 0.0899,
      "step": 17129
    },
    {
      "epoch": 1.331209201119055,
      "grad_norm": 0.3776838481426239,
      "learning_rate": 3.343953994404725e-06,
      "loss": 0.2585,
      "step": 17130
    },
    {
      "epoch": 1.331286913273236,
      "grad_norm": 0.07909617573022842,
      "learning_rate": 3.3435654336338207e-06,
      "loss": 0.0065,
      "step": 17131
    },
    {
      "epoch": 1.3313646254274167,
      "grad_norm": 0.49784865975379944,
      "learning_rate": 3.343176872862916e-06,
      "loss": 0.2596,
      "step": 17132
    },
    {
      "epoch": 1.3314423375815978,
      "grad_norm": 0.35532575845718384,
      "learning_rate": 3.3427883120920114e-06,
      "loss": 0.0722,
      "step": 17133
    },
    {
      "epoch": 1.3315200497357786,
      "grad_norm": 0.4552748501300812,
      "learning_rate": 3.3423997513211072e-06,
      "loss": 0.2372,
      "step": 17134
    },
    {
      "epoch": 1.3315977618899595,
      "grad_norm": 0.5993589162826538,
      "learning_rate": 3.342011190550202e-06,
      "loss": 0.0673,
      "step": 17135
    },
    {
      "epoch": 1.3316754740441406,
      "grad_norm": 0.3102283775806427,
      "learning_rate": 3.3416226297792976e-06,
      "loss": 0.2166,
      "step": 17136
    },
    {
      "epoch": 1.3317531861983214,
      "grad_norm": 0.5390304327011108,
      "learning_rate": 3.3412340690083934e-06,
      "loss": 0.1332,
      "step": 17137
    },
    {
      "epoch": 1.3318308983525022,
      "grad_norm": 0.7603944540023804,
      "learning_rate": 3.3408455082374887e-06,
      "loss": 0.1162,
      "step": 17138
    },
    {
      "epoch": 1.3319086105066833,
      "grad_norm": 1.0075290203094482,
      "learning_rate": 3.3404569474665837e-06,
      "loss": 0.166,
      "step": 17139
    },
    {
      "epoch": 1.3319863226608641,
      "grad_norm": 0.16260483860969543,
      "learning_rate": 3.3400683866956795e-06,
      "loss": 0.0323,
      "step": 17140
    },
    {
      "epoch": 1.332064034815045,
      "grad_norm": 0.6197603940963745,
      "learning_rate": 3.339679825924775e-06,
      "loss": 0.1168,
      "step": 17141
    },
    {
      "epoch": 1.332141746969226,
      "grad_norm": 0.11056818068027496,
      "learning_rate": 3.3392912651538707e-06,
      "loss": 0.0083,
      "step": 17142
    },
    {
      "epoch": 1.332219459123407,
      "grad_norm": 0.7030312418937683,
      "learning_rate": 3.338902704382966e-06,
      "loss": 0.2026,
      "step": 17143
    },
    {
      "epoch": 1.3322971712775877,
      "grad_norm": 0.30696815252304077,
      "learning_rate": 3.338514143612061e-06,
      "loss": 0.0617,
      "step": 17144
    },
    {
      "epoch": 1.3323748834317688,
      "grad_norm": 0.49677714705467224,
      "learning_rate": 3.3381255828411568e-06,
      "loss": 0.201,
      "step": 17145
    },
    {
      "epoch": 1.3324525955859496,
      "grad_norm": 0.48421913385391235,
      "learning_rate": 3.337737022070252e-06,
      "loss": 0.2206,
      "step": 17146
    },
    {
      "epoch": 1.3325303077401305,
      "grad_norm": 0.25815868377685547,
      "learning_rate": 3.3373484612993475e-06,
      "loss": 0.0629,
      "step": 17147
    },
    {
      "epoch": 1.3326080198943115,
      "grad_norm": 0.1557963490486145,
      "learning_rate": 3.336959900528443e-06,
      "loss": 0.0091,
      "step": 17148
    },
    {
      "epoch": 1.3326857320484924,
      "grad_norm": 0.9873592257499695,
      "learning_rate": 3.3365713397575383e-06,
      "loss": 0.7763,
      "step": 17149
    },
    {
      "epoch": 1.3327634442026732,
      "grad_norm": 1.3625831604003906,
      "learning_rate": 3.3361827789866336e-06,
      "loss": 0.228,
      "step": 17150
    },
    {
      "epoch": 1.3328411563568543,
      "grad_norm": 0.9132062196731567,
      "learning_rate": 3.3357942182157294e-06,
      "loss": 0.2822,
      "step": 17151
    },
    {
      "epoch": 1.3329188685110351,
      "grad_norm": 0.29508382081985474,
      "learning_rate": 3.3354056574448244e-06,
      "loss": 0.0694,
      "step": 17152
    },
    {
      "epoch": 1.332996580665216,
      "grad_norm": 0.3288421928882599,
      "learning_rate": 3.3350170966739198e-06,
      "loss": 0.0369,
      "step": 17153
    },
    {
      "epoch": 1.333074292819397,
      "grad_norm": 0.1841026246547699,
      "learning_rate": 3.3346285359030156e-06,
      "loss": 0.0447,
      "step": 17154
    },
    {
      "epoch": 1.3331520049735779,
      "grad_norm": 0.33470696210861206,
      "learning_rate": 3.334239975132111e-06,
      "loss": 0.1219,
      "step": 17155
    },
    {
      "epoch": 1.3332297171277587,
      "grad_norm": 1.107463002204895,
      "learning_rate": 3.3338514143612067e-06,
      "loss": 0.8237,
      "step": 17156
    },
    {
      "epoch": 1.3333074292819398,
      "grad_norm": 0.18709279596805573,
      "learning_rate": 3.3334628535903017e-06,
      "loss": 0.0796,
      "step": 17157
    },
    {
      "epoch": 1.3333851414361206,
      "grad_norm": 0.5573485493659973,
      "learning_rate": 3.333074292819397e-06,
      "loss": 0.3018,
      "step": 17158
    },
    {
      "epoch": 1.3334628535903015,
      "grad_norm": 0.3723474442958832,
      "learning_rate": 3.332685732048493e-06,
      "loss": 0.0458,
      "step": 17159
    },
    {
      "epoch": 1.3335405657444825,
      "grad_norm": 0.6185267567634583,
      "learning_rate": 3.3322971712775882e-06,
      "loss": 0.1834,
      "step": 17160
    },
    {
      "epoch": 1.3336182778986634,
      "grad_norm": 0.5196426510810852,
      "learning_rate": 3.331908610506683e-06,
      "loss": 0.183,
      "step": 17161
    },
    {
      "epoch": 1.3336959900528442,
      "grad_norm": 0.1522144079208374,
      "learning_rate": 3.331520049735779e-06,
      "loss": 0.0478,
      "step": 17162
    },
    {
      "epoch": 1.3337737022070253,
      "grad_norm": 1.1002446413040161,
      "learning_rate": 3.3311314889648743e-06,
      "loss": 0.4845,
      "step": 17163
    },
    {
      "epoch": 1.3338514143612061,
      "grad_norm": 0.17281240224838257,
      "learning_rate": 3.3307429281939697e-06,
      "loss": 0.0329,
      "step": 17164
    },
    {
      "epoch": 1.333929126515387,
      "grad_norm": 0.42771533131599426,
      "learning_rate": 3.3303543674230655e-06,
      "loss": 0.0746,
      "step": 17165
    },
    {
      "epoch": 1.334006838669568,
      "grad_norm": 0.08735845237970352,
      "learning_rate": 3.3299658066521605e-06,
      "loss": 0.0099,
      "step": 17166
    },
    {
      "epoch": 1.3340845508237489,
      "grad_norm": 0.4969101548194885,
      "learning_rate": 3.329577245881256e-06,
      "loss": 0.2466,
      "step": 17167
    },
    {
      "epoch": 1.3341622629779297,
      "grad_norm": 0.43095627427101135,
      "learning_rate": 3.3291886851103516e-06,
      "loss": 0.1706,
      "step": 17168
    },
    {
      "epoch": 1.3342399751321108,
      "grad_norm": 0.7348421812057495,
      "learning_rate": 3.328800124339447e-06,
      "loss": 0.1885,
      "step": 17169
    },
    {
      "epoch": 1.3343176872862916,
      "grad_norm": 0.835023820400238,
      "learning_rate": 3.328411563568543e-06,
      "loss": 0.34,
      "step": 17170
    },
    {
      "epoch": 1.3343953994404725,
      "grad_norm": 0.19473043084144592,
      "learning_rate": 3.3280230027976377e-06,
      "loss": 0.021,
      "step": 17171
    },
    {
      "epoch": 1.3344731115946535,
      "grad_norm": 0.2240932434797287,
      "learning_rate": 3.327634442026733e-06,
      "loss": 0.0978,
      "step": 17172
    },
    {
      "epoch": 1.3345508237488344,
      "grad_norm": 0.2679736018180847,
      "learning_rate": 3.327245881255829e-06,
      "loss": 0.0912,
      "step": 17173
    },
    {
      "epoch": 1.3346285359030152,
      "grad_norm": 0.5738173723220825,
      "learning_rate": 3.3268573204849243e-06,
      "loss": 0.2057,
      "step": 17174
    },
    {
      "epoch": 1.334706248057196,
      "grad_norm": 0.6000897884368896,
      "learning_rate": 3.3264687597140192e-06,
      "loss": 0.1383,
      "step": 17175
    },
    {
      "epoch": 1.3347839602113771,
      "grad_norm": 0.2591548562049866,
      "learning_rate": 3.326080198943115e-06,
      "loss": 0.0931,
      "step": 17176
    },
    {
      "epoch": 1.334861672365558,
      "grad_norm": 0.18874713778495789,
      "learning_rate": 3.3256916381722104e-06,
      "loss": 0.0416,
      "step": 17177
    },
    {
      "epoch": 1.3349393845197388,
      "grad_norm": 0.9264563918113708,
      "learning_rate": 3.3253030774013058e-06,
      "loss": 0.346,
      "step": 17178
    },
    {
      "epoch": 1.3350170966739199,
      "grad_norm": 2.3600215911865234,
      "learning_rate": 3.3249145166304016e-06,
      "loss": 0.6362,
      "step": 17179
    },
    {
      "epoch": 1.3350948088281007,
      "grad_norm": 0.5175670981407166,
      "learning_rate": 3.3245259558594965e-06,
      "loss": 0.2771,
      "step": 17180
    },
    {
      "epoch": 1.3351725209822816,
      "grad_norm": 0.23216338455677032,
      "learning_rate": 3.324137395088592e-06,
      "loss": 0.0339,
      "step": 17181
    },
    {
      "epoch": 1.3352502331364624,
      "grad_norm": 0.8212926983833313,
      "learning_rate": 3.3237488343176877e-06,
      "loss": 0.6625,
      "step": 17182
    },
    {
      "epoch": 1.3353279452906435,
      "grad_norm": 0.2383164018392563,
      "learning_rate": 3.323360273546783e-06,
      "loss": 0.0861,
      "step": 17183
    },
    {
      "epoch": 1.3354056574448243,
      "grad_norm": 0.3565138578414917,
      "learning_rate": 3.322971712775878e-06,
      "loss": 0.1768,
      "step": 17184
    },
    {
      "epoch": 1.3354833695990052,
      "grad_norm": 0.4553108215332031,
      "learning_rate": 3.322583152004974e-06,
      "loss": 0.0898,
      "step": 17185
    },
    {
      "epoch": 1.3355610817531862,
      "grad_norm": 1.1587200164794922,
      "learning_rate": 3.322194591234069e-06,
      "loss": 0.2347,
      "step": 17186
    },
    {
      "epoch": 1.335638793907367,
      "grad_norm": 0.14750148355960846,
      "learning_rate": 3.321806030463165e-06,
      "loss": 0.0599,
      "step": 17187
    },
    {
      "epoch": 1.335716506061548,
      "grad_norm": 1.0843770503997803,
      "learning_rate": 3.3214174696922604e-06,
      "loss": 0.2698,
      "step": 17188
    },
    {
      "epoch": 1.335794218215729,
      "grad_norm": 0.9084516763687134,
      "learning_rate": 3.3210289089213553e-06,
      "loss": 0.3677,
      "step": 17189
    },
    {
      "epoch": 1.3358719303699098,
      "grad_norm": 0.5125631093978882,
      "learning_rate": 3.320640348150451e-06,
      "loss": 0.1393,
      "step": 17190
    },
    {
      "epoch": 1.3359496425240907,
      "grad_norm": 0.22100651264190674,
      "learning_rate": 3.3202517873795465e-06,
      "loss": 0.0163,
      "step": 17191
    },
    {
      "epoch": 1.3360273546782717,
      "grad_norm": 0.7386924624443054,
      "learning_rate": 3.319863226608642e-06,
      "loss": 0.1539,
      "step": 17192
    },
    {
      "epoch": 1.3361050668324526,
      "grad_norm": 0.2747558355331421,
      "learning_rate": 3.3194746658377377e-06,
      "loss": 0.1004,
      "step": 17193
    },
    {
      "epoch": 1.3361827789866334,
      "grad_norm": 0.7447587847709656,
      "learning_rate": 3.3190861050668326e-06,
      "loss": 0.3601,
      "step": 17194
    },
    {
      "epoch": 1.3362604911408145,
      "grad_norm": 0.5755348205566406,
      "learning_rate": 3.318697544295928e-06,
      "loss": 0.2407,
      "step": 17195
    },
    {
      "epoch": 1.3363382032949953,
      "grad_norm": 0.7861016988754272,
      "learning_rate": 3.3183089835250238e-06,
      "loss": 0.5471,
      "step": 17196
    },
    {
      "epoch": 1.3364159154491762,
      "grad_norm": 0.2108047604560852,
      "learning_rate": 3.317920422754119e-06,
      "loss": 0.1062,
      "step": 17197
    },
    {
      "epoch": 1.3364936276033572,
      "grad_norm": 1.3346800804138184,
      "learning_rate": 3.317531861983214e-06,
      "loss": 0.3483,
      "step": 17198
    },
    {
      "epoch": 1.336571339757538,
      "grad_norm": 0.7161082029342651,
      "learning_rate": 3.31714330121231e-06,
      "loss": 0.2703,
      "step": 17199
    },
    {
      "epoch": 1.336649051911719,
      "grad_norm": 0.4137602746486664,
      "learning_rate": 3.3167547404414053e-06,
      "loss": 0.3299,
      "step": 17200
    },
    {
      "epoch": 1.3367267640659,
      "grad_norm": 0.35610631108283997,
      "learning_rate": 3.316366179670501e-06,
      "loss": 0.0257,
      "step": 17201
    },
    {
      "epoch": 1.3368044762200808,
      "grad_norm": 0.30887895822525024,
      "learning_rate": 3.3159776188995964e-06,
      "loss": 0.1362,
      "step": 17202
    },
    {
      "epoch": 1.3368821883742616,
      "grad_norm": 0.39023473858833313,
      "learning_rate": 3.3155890581286914e-06,
      "loss": 0.1794,
      "step": 17203
    },
    {
      "epoch": 1.3369599005284427,
      "grad_norm": 0.7231765985488892,
      "learning_rate": 3.315200497357787e-06,
      "loss": 0.2097,
      "step": 17204
    },
    {
      "epoch": 1.3370376126826236,
      "grad_norm": 0.7746161222457886,
      "learning_rate": 3.3148119365868826e-06,
      "loss": 0.3633,
      "step": 17205
    },
    {
      "epoch": 1.3371153248368044,
      "grad_norm": 0.1038040891289711,
      "learning_rate": 3.314423375815978e-06,
      "loss": 0.0724,
      "step": 17206
    },
    {
      "epoch": 1.3371930369909855,
      "grad_norm": 0.22821208834648132,
      "learning_rate": 3.3140348150450737e-06,
      "loss": 0.0643,
      "step": 17207
    },
    {
      "epoch": 1.3372707491451663,
      "grad_norm": 0.49803510308265686,
      "learning_rate": 3.3136462542741687e-06,
      "loss": 0.0443,
      "step": 17208
    },
    {
      "epoch": 1.3373484612993471,
      "grad_norm": 0.6716719269752502,
      "learning_rate": 3.313257693503264e-06,
      "loss": 0.1887,
      "step": 17209
    },
    {
      "epoch": 1.3374261734535282,
      "grad_norm": 0.6207318305969238,
      "learning_rate": 3.31286913273236e-06,
      "loss": 0.1062,
      "step": 17210
    },
    {
      "epoch": 1.337503885607709,
      "grad_norm": 0.17466139793395996,
      "learning_rate": 3.312480571961455e-06,
      "loss": 0.0761,
      "step": 17211
    },
    {
      "epoch": 1.33758159776189,
      "grad_norm": 0.323756605386734,
      "learning_rate": 3.31209201119055e-06,
      "loss": 0.0769,
      "step": 17212
    },
    {
      "epoch": 1.337659309916071,
      "grad_norm": 0.720601499080658,
      "learning_rate": 3.311703450419646e-06,
      "loss": 0.3176,
      "step": 17213
    },
    {
      "epoch": 1.3377370220702518,
      "grad_norm": 1.5595043897628784,
      "learning_rate": 3.3113148896487413e-06,
      "loss": 0.7248,
      "step": 17214
    },
    {
      "epoch": 1.3378147342244326,
      "grad_norm": 0.25095683336257935,
      "learning_rate": 3.3109263288778363e-06,
      "loss": 0.0653,
      "step": 17215
    },
    {
      "epoch": 1.3378924463786137,
      "grad_norm": 0.6243221163749695,
      "learning_rate": 3.310537768106932e-06,
      "loss": 0.5277,
      "step": 17216
    },
    {
      "epoch": 1.3379701585327946,
      "grad_norm": 0.6256465911865234,
      "learning_rate": 3.3101492073360275e-06,
      "loss": 0.5575,
      "step": 17217
    },
    {
      "epoch": 1.3380478706869754,
      "grad_norm": 0.5728206038475037,
      "learning_rate": 3.3097606465651233e-06,
      "loss": 0.2906,
      "step": 17218
    },
    {
      "epoch": 1.3381255828411565,
      "grad_norm": 0.3544800877571106,
      "learning_rate": 3.3093720857942186e-06,
      "loss": 0.231,
      "step": 17219
    },
    {
      "epoch": 1.3382032949953373,
      "grad_norm": 0.2242242693901062,
      "learning_rate": 3.3089835250233136e-06,
      "loss": 0.0353,
      "step": 17220
    },
    {
      "epoch": 1.3382810071495181,
      "grad_norm": 1.2333669662475586,
      "learning_rate": 3.3085949642524094e-06,
      "loss": 0.7054,
      "step": 17221
    },
    {
      "epoch": 1.3383587193036992,
      "grad_norm": 0.20805206894874573,
      "learning_rate": 3.3082064034815047e-06,
      "loss": 0.0539,
      "step": 17222
    },
    {
      "epoch": 1.33843643145788,
      "grad_norm": 1.0365099906921387,
      "learning_rate": 3.3078178427106e-06,
      "loss": 0.7327,
      "step": 17223
    },
    {
      "epoch": 1.338514143612061,
      "grad_norm": 1.4484925270080566,
      "learning_rate": 3.307429281939696e-06,
      "loss": 0.7974,
      "step": 17224
    },
    {
      "epoch": 1.338591855766242,
      "grad_norm": 1.0016331672668457,
      "learning_rate": 3.307040721168791e-06,
      "loss": 0.379,
      "step": 17225
    },
    {
      "epoch": 1.3386695679204228,
      "grad_norm": 0.5270508527755737,
      "learning_rate": 3.3066521603978862e-06,
      "loss": 0.1753,
      "step": 17226
    },
    {
      "epoch": 1.3387472800746036,
      "grad_norm": 0.5519809126853943,
      "learning_rate": 3.306263599626982e-06,
      "loss": 0.3179,
      "step": 17227
    },
    {
      "epoch": 1.3388249922287847,
      "grad_norm": 0.46095404028892517,
      "learning_rate": 3.3058750388560774e-06,
      "loss": 0.1915,
      "step": 17228
    },
    {
      "epoch": 1.3389027043829655,
      "grad_norm": 0.08026240020990372,
      "learning_rate": 3.3054864780851724e-06,
      "loss": 0.0058,
      "step": 17229
    },
    {
      "epoch": 1.3389804165371464,
      "grad_norm": 0.3457367420196533,
      "learning_rate": 3.305097917314268e-06,
      "loss": 0.1015,
      "step": 17230
    },
    {
      "epoch": 1.3390581286913275,
      "grad_norm": 0.19459497928619385,
      "learning_rate": 3.3047093565433635e-06,
      "loss": 0.0659,
      "step": 17231
    },
    {
      "epoch": 1.3391358408455083,
      "grad_norm": 0.2197837084531784,
      "learning_rate": 3.3043207957724593e-06,
      "loss": 0.0765,
      "step": 17232
    },
    {
      "epoch": 1.3392135529996891,
      "grad_norm": 0.4738224744796753,
      "learning_rate": 3.3039322350015547e-06,
      "loss": 0.1022,
      "step": 17233
    },
    {
      "epoch": 1.3392912651538702,
      "grad_norm": 1.744428277015686,
      "learning_rate": 3.3035436742306497e-06,
      "loss": 0.3759,
      "step": 17234
    },
    {
      "epoch": 1.339368977308051,
      "grad_norm": 0.20386765897274017,
      "learning_rate": 3.3031551134597454e-06,
      "loss": 0.0696,
      "step": 17235
    },
    {
      "epoch": 1.3394466894622319,
      "grad_norm": 0.6892499327659607,
      "learning_rate": 3.302766552688841e-06,
      "loss": 0.3566,
      "step": 17236
    },
    {
      "epoch": 1.3395244016164127,
      "grad_norm": 0.20418451726436615,
      "learning_rate": 3.302377991917936e-06,
      "loss": 0.1475,
      "step": 17237
    },
    {
      "epoch": 1.3396021137705938,
      "grad_norm": 0.553564190864563,
      "learning_rate": 3.301989431147032e-06,
      "loss": 0.1065,
      "step": 17238
    },
    {
      "epoch": 1.3396798259247746,
      "grad_norm": 0.9268279075622559,
      "learning_rate": 3.301600870376127e-06,
      "loss": 0.4398,
      "step": 17239
    },
    {
      "epoch": 1.3397575380789555,
      "grad_norm": 0.20212307572364807,
      "learning_rate": 3.3012123096052223e-06,
      "loss": 0.0231,
      "step": 17240
    },
    {
      "epoch": 1.3398352502331365,
      "grad_norm": 0.49528229236602783,
      "learning_rate": 3.300823748834318e-06,
      "loss": 0.2189,
      "step": 17241
    },
    {
      "epoch": 1.3399129623873174,
      "grad_norm": 0.26870352029800415,
      "learning_rate": 3.3004351880634135e-06,
      "loss": 0.0549,
      "step": 17242
    },
    {
      "epoch": 1.3399906745414982,
      "grad_norm": 0.43116915225982666,
      "learning_rate": 3.3000466272925084e-06,
      "loss": 0.1271,
      "step": 17243
    },
    {
      "epoch": 1.340068386695679,
      "grad_norm": 0.537388265132904,
      "learning_rate": 3.2996580665216042e-06,
      "loss": 0.2634,
      "step": 17244
    },
    {
      "epoch": 1.3401460988498601,
      "grad_norm": 0.1077691912651062,
      "learning_rate": 3.2992695057506996e-06,
      "loss": 0.0089,
      "step": 17245
    },
    {
      "epoch": 1.340223811004041,
      "grad_norm": 0.544567883014679,
      "learning_rate": 3.2988809449797954e-06,
      "loss": 0.1323,
      "step": 17246
    },
    {
      "epoch": 1.3403015231582218,
      "grad_norm": 0.4020734429359436,
      "learning_rate": 3.2984923842088908e-06,
      "loss": 0.0942,
      "step": 17247
    },
    {
      "epoch": 1.3403792353124029,
      "grad_norm": 0.7259082794189453,
      "learning_rate": 3.2981038234379857e-06,
      "loss": 0.1392,
      "step": 17248
    },
    {
      "epoch": 1.3404569474665837,
      "grad_norm": 0.8986479043960571,
      "learning_rate": 3.2977152626670815e-06,
      "loss": 0.2747,
      "step": 17249
    },
    {
      "epoch": 1.3405346596207646,
      "grad_norm": 0.34096771478652954,
      "learning_rate": 3.297326701896177e-06,
      "loss": 0.0643,
      "step": 17250
    },
    {
      "epoch": 1.3406123717749456,
      "grad_norm": 0.9394345879554749,
      "learning_rate": 3.2969381411252723e-06,
      "loss": 0.1343,
      "step": 17251
    },
    {
      "epoch": 1.3406900839291265,
      "grad_norm": 0.3380054831504822,
      "learning_rate": 3.296549580354368e-06,
      "loss": 0.165,
      "step": 17252
    },
    {
      "epoch": 1.3407677960833073,
      "grad_norm": 0.3032923936843872,
      "learning_rate": 3.296161019583463e-06,
      "loss": 0.0795,
      "step": 17253
    },
    {
      "epoch": 1.3408455082374884,
      "grad_norm": 0.6633684635162354,
      "learning_rate": 3.2957724588125584e-06,
      "loss": 0.1356,
      "step": 17254
    },
    {
      "epoch": 1.3409232203916692,
      "grad_norm": 0.4062468111515045,
      "learning_rate": 3.295383898041654e-06,
      "loss": 0.109,
      "step": 17255
    },
    {
      "epoch": 1.34100093254585,
      "grad_norm": 0.6962404847145081,
      "learning_rate": 3.2949953372707496e-06,
      "loss": 0.5076,
      "step": 17256
    },
    {
      "epoch": 1.3410786447000311,
      "grad_norm": 0.7517317533493042,
      "learning_rate": 3.2946067764998445e-06,
      "loss": 0.1233,
      "step": 17257
    },
    {
      "epoch": 1.341156356854212,
      "grad_norm": 0.11971314251422882,
      "learning_rate": 3.2942182157289403e-06,
      "loss": 0.0096,
      "step": 17258
    },
    {
      "epoch": 1.3412340690083928,
      "grad_norm": 0.43248555064201355,
      "learning_rate": 3.2938296549580357e-06,
      "loss": 0.23,
      "step": 17259
    },
    {
      "epoch": 1.3413117811625739,
      "grad_norm": 0.5296991467475891,
      "learning_rate": 3.293441094187131e-06,
      "loss": 0.2047,
      "step": 17260
    },
    {
      "epoch": 1.3413894933167547,
      "grad_norm": 0.5957105159759521,
      "learning_rate": 3.293052533416227e-06,
      "loss": 0.0847,
      "step": 17261
    },
    {
      "epoch": 1.3414672054709356,
      "grad_norm": 0.28649285435676575,
      "learning_rate": 3.292663972645322e-06,
      "loss": 0.1177,
      "step": 17262
    },
    {
      "epoch": 1.3415449176251166,
      "grad_norm": 0.5530475974082947,
      "learning_rate": 3.2922754118744176e-06,
      "loss": 0.2725,
      "step": 17263
    },
    {
      "epoch": 1.3416226297792975,
      "grad_norm": 0.7571917176246643,
      "learning_rate": 3.291886851103513e-06,
      "loss": 0.4976,
      "step": 17264
    },
    {
      "epoch": 1.3417003419334783,
      "grad_norm": 0.500215470790863,
      "learning_rate": 3.2914982903326083e-06,
      "loss": 0.3686,
      "step": 17265
    },
    {
      "epoch": 1.3417780540876594,
      "grad_norm": 0.8178199529647827,
      "learning_rate": 3.291109729561704e-06,
      "loss": 0.3027,
      "step": 17266
    },
    {
      "epoch": 1.3418557662418402,
      "grad_norm": 0.6072492003440857,
      "learning_rate": 3.290721168790799e-06,
      "loss": 0.3878,
      "step": 17267
    },
    {
      "epoch": 1.341933478396021,
      "grad_norm": 0.5192723870277405,
      "learning_rate": 3.2903326080198945e-06,
      "loss": 0.2373,
      "step": 17268
    },
    {
      "epoch": 1.3420111905502021,
      "grad_norm": 0.6282238364219666,
      "learning_rate": 3.2899440472489903e-06,
      "loss": 0.153,
      "step": 17269
    },
    {
      "epoch": 1.342088902704383,
      "grad_norm": 0.2346356362104416,
      "learning_rate": 3.2895554864780856e-06,
      "loss": 0.0363,
      "step": 17270
    },
    {
      "epoch": 1.3421666148585638,
      "grad_norm": 0.32483401894569397,
      "learning_rate": 3.2891669257071806e-06,
      "loss": 0.2452,
      "step": 17271
    },
    {
      "epoch": 1.3422443270127449,
      "grad_norm": 0.6197910308837891,
      "learning_rate": 3.2887783649362764e-06,
      "loss": 0.2368,
      "step": 17272
    },
    {
      "epoch": 1.3423220391669257,
      "grad_norm": 0.5435342192649841,
      "learning_rate": 3.2883898041653718e-06,
      "loss": 0.1822,
      "step": 17273
    },
    {
      "epoch": 1.3423997513211066,
      "grad_norm": 0.20948909223079681,
      "learning_rate": 3.2880012433944667e-06,
      "loss": 0.0415,
      "step": 17274
    },
    {
      "epoch": 1.3424774634752876,
      "grad_norm": 0.15076707303524017,
      "learning_rate": 3.2876126826235625e-06,
      "loss": 0.0355,
      "step": 17275
    },
    {
      "epoch": 1.3425551756294685,
      "grad_norm": 0.18431435525417328,
      "learning_rate": 3.287224121852658e-06,
      "loss": 0.0947,
      "step": 17276
    },
    {
      "epoch": 1.3426328877836493,
      "grad_norm": 1.1745643615722656,
      "learning_rate": 3.2868355610817537e-06,
      "loss": 0.4394,
      "step": 17277
    },
    {
      "epoch": 1.3427105999378304,
      "grad_norm": 0.5197188258171082,
      "learning_rate": 3.286447000310849e-06,
      "loss": 0.207,
      "step": 17278
    },
    {
      "epoch": 1.3427883120920112,
      "grad_norm": 0.7779521942138672,
      "learning_rate": 3.286058439539944e-06,
      "loss": 0.3317,
      "step": 17279
    },
    {
      "epoch": 1.342866024246192,
      "grad_norm": 1.7665224075317383,
      "learning_rate": 3.28566987876904e-06,
      "loss": 0.524,
      "step": 17280
    },
    {
      "epoch": 1.3429437364003731,
      "grad_norm": 0.8706109523773193,
      "learning_rate": 3.285281317998135e-06,
      "loss": 0.4091,
      "step": 17281
    },
    {
      "epoch": 1.343021448554554,
      "grad_norm": 0.4336916506290436,
      "learning_rate": 3.2848927572272305e-06,
      "loss": 0.1387,
      "step": 17282
    },
    {
      "epoch": 1.3430991607087348,
      "grad_norm": 0.5982396006584167,
      "learning_rate": 3.2845041964563263e-06,
      "loss": 0.1856,
      "step": 17283
    },
    {
      "epoch": 1.3431768728629159,
      "grad_norm": 0.5070821642875671,
      "learning_rate": 3.2841156356854213e-06,
      "loss": 0.149,
      "step": 17284
    },
    {
      "epoch": 1.3432545850170967,
      "grad_norm": 0.2600661516189575,
      "learning_rate": 3.2837270749145167e-06,
      "loss": 0.0392,
      "step": 17285
    },
    {
      "epoch": 1.3433322971712776,
      "grad_norm": 0.2900756895542145,
      "learning_rate": 3.2833385141436125e-06,
      "loss": 0.0263,
      "step": 17286
    },
    {
      "epoch": 1.3434100093254586,
      "grad_norm": 0.6822608709335327,
      "learning_rate": 3.282949953372708e-06,
      "loss": 0.1853,
      "step": 17287
    },
    {
      "epoch": 1.3434877214796395,
      "grad_norm": 0.6714391708374023,
      "learning_rate": 3.2825613926018028e-06,
      "loss": 0.1374,
      "step": 17288
    },
    {
      "epoch": 1.3435654336338203,
      "grad_norm": 0.586067259311676,
      "learning_rate": 3.2821728318308986e-06,
      "loss": 0.2116,
      "step": 17289
    },
    {
      "epoch": 1.3436431457880014,
      "grad_norm": 1.0166352987289429,
      "learning_rate": 3.281784271059994e-06,
      "loss": 0.2332,
      "step": 17290
    },
    {
      "epoch": 1.3437208579421822,
      "grad_norm": 0.28299111127853394,
      "learning_rate": 3.2813957102890893e-06,
      "loss": 0.0625,
      "step": 17291
    },
    {
      "epoch": 1.343798570096363,
      "grad_norm": 0.2585189640522003,
      "learning_rate": 3.281007149518185e-06,
      "loss": 0.101,
      "step": 17292
    },
    {
      "epoch": 1.3438762822505441,
      "grad_norm": 0.4757183790206909,
      "learning_rate": 3.28061858874728e-06,
      "loss": 0.2388,
      "step": 17293
    },
    {
      "epoch": 1.343953994404725,
      "grad_norm": 0.2903035581111908,
      "learning_rate": 3.280230027976376e-06,
      "loss": 0.0799,
      "step": 17294
    },
    {
      "epoch": 1.3440317065589058,
      "grad_norm": 0.2249726951122284,
      "learning_rate": 3.2798414672054712e-06,
      "loss": 0.1248,
      "step": 17295
    },
    {
      "epoch": 1.3441094187130866,
      "grad_norm": 0.6257321238517761,
      "learning_rate": 3.2794529064345666e-06,
      "loss": 0.5866,
      "step": 17296
    },
    {
      "epoch": 1.3441871308672677,
      "grad_norm": 0.23808740079402924,
      "learning_rate": 3.2790643456636624e-06,
      "loss": 0.0337,
      "step": 17297
    },
    {
      "epoch": 1.3442648430214486,
      "grad_norm": 1.3827849626541138,
      "learning_rate": 3.2786757848927574e-06,
      "loss": 0.3509,
      "step": 17298
    },
    {
      "epoch": 1.3443425551756294,
      "grad_norm": 0.10503958910703659,
      "learning_rate": 3.2782872241218527e-06,
      "loss": 0.0109,
      "step": 17299
    },
    {
      "epoch": 1.3444202673298105,
      "grad_norm": 0.14869335293769836,
      "learning_rate": 3.2778986633509485e-06,
      "loss": 0.0259,
      "step": 17300
    },
    {
      "epoch": 1.3444979794839913,
      "grad_norm": 0.48393014073371887,
      "learning_rate": 3.277510102580044e-06,
      "loss": 0.1615,
      "step": 17301
    },
    {
      "epoch": 1.3445756916381721,
      "grad_norm": 0.24202243983745575,
      "learning_rate": 3.277121541809139e-06,
      "loss": 0.077,
      "step": 17302
    },
    {
      "epoch": 1.344653403792353,
      "grad_norm": 2.088381767272949,
      "learning_rate": 3.2767329810382346e-06,
      "loss": 0.443,
      "step": 17303
    },
    {
      "epoch": 1.344731115946534,
      "grad_norm": 0.4833007752895355,
      "learning_rate": 3.27634442026733e-06,
      "loss": 0.0918,
      "step": 17304
    },
    {
      "epoch": 1.344808828100715,
      "grad_norm": 0.3215945065021515,
      "learning_rate": 3.2759558594964254e-06,
      "loss": 0.244,
      "step": 17305
    },
    {
      "epoch": 1.3448865402548957,
      "grad_norm": 0.4666202664375305,
      "learning_rate": 3.275567298725521e-06,
      "loss": 0.2077,
      "step": 17306
    },
    {
      "epoch": 1.3449642524090768,
      "grad_norm": 0.2752229571342468,
      "learning_rate": 3.275178737954616e-06,
      "loss": 0.0429,
      "step": 17307
    },
    {
      "epoch": 1.3450419645632576,
      "grad_norm": 1.064422607421875,
      "learning_rate": 3.274790177183712e-06,
      "loss": 0.2503,
      "step": 17308
    },
    {
      "epoch": 1.3451196767174385,
      "grad_norm": 0.35815468430519104,
      "learning_rate": 3.2744016164128073e-06,
      "loss": 0.0982,
      "step": 17309
    },
    {
      "epoch": 1.3451973888716195,
      "grad_norm": 0.4201001226902008,
      "learning_rate": 3.2740130556419027e-06,
      "loss": 0.1985,
      "step": 17310
    },
    {
      "epoch": 1.3452751010258004,
      "grad_norm": 0.49150195717811584,
      "learning_rate": 3.2736244948709985e-06,
      "loss": 0.5356,
      "step": 17311
    },
    {
      "epoch": 1.3453528131799812,
      "grad_norm": 0.23216292262077332,
      "learning_rate": 3.2732359341000934e-06,
      "loss": 0.0487,
      "step": 17312
    },
    {
      "epoch": 1.3454305253341623,
      "grad_norm": 0.16570612788200378,
      "learning_rate": 3.272847373329189e-06,
      "loss": 0.0139,
      "step": 17313
    },
    {
      "epoch": 1.3455082374883431,
      "grad_norm": 0.7378596067428589,
      "learning_rate": 3.2724588125582846e-06,
      "loss": 0.2961,
      "step": 17314
    },
    {
      "epoch": 1.345585949642524,
      "grad_norm": 0.3802723288536072,
      "learning_rate": 3.27207025178738e-06,
      "loss": 0.1734,
      "step": 17315
    },
    {
      "epoch": 1.345663661796705,
      "grad_norm": 0.5814210176467896,
      "learning_rate": 3.271681691016475e-06,
      "loss": 0.1856,
      "step": 17316
    },
    {
      "epoch": 1.3457413739508859,
      "grad_norm": 0.8442211151123047,
      "learning_rate": 3.2712931302455707e-06,
      "loss": 0.1733,
      "step": 17317
    },
    {
      "epoch": 1.3458190861050667,
      "grad_norm": 0.30348914861679077,
      "learning_rate": 3.270904569474666e-06,
      "loss": 0.0987,
      "step": 17318
    },
    {
      "epoch": 1.3458967982592478,
      "grad_norm": 0.4462471306324005,
      "learning_rate": 3.2705160087037615e-06,
      "loss": 0.1711,
      "step": 17319
    },
    {
      "epoch": 1.3459745104134286,
      "grad_norm": 0.2853953242301941,
      "learning_rate": 3.2701274479328573e-06,
      "loss": 0.1242,
      "step": 17320
    },
    {
      "epoch": 1.3460522225676095,
      "grad_norm": 0.5178805589675903,
      "learning_rate": 3.269738887161952e-06,
      "loss": 0.2261,
      "step": 17321
    },
    {
      "epoch": 1.3461299347217905,
      "grad_norm": 0.7386461496353149,
      "learning_rate": 3.269350326391048e-06,
      "loss": 0.1616,
      "step": 17322
    },
    {
      "epoch": 1.3462076468759714,
      "grad_norm": 0.5424702763557434,
      "learning_rate": 3.2689617656201434e-06,
      "loss": 0.1343,
      "step": 17323
    },
    {
      "epoch": 1.3462853590301522,
      "grad_norm": 0.19620734453201294,
      "learning_rate": 3.2685732048492388e-06,
      "loss": 0.0567,
      "step": 17324
    },
    {
      "epoch": 1.3463630711843333,
      "grad_norm": 0.4684765934944153,
      "learning_rate": 3.2681846440783346e-06,
      "loss": 0.1225,
      "step": 17325
    },
    {
      "epoch": 1.3464407833385141,
      "grad_norm": 0.36563438177108765,
      "learning_rate": 3.2677960833074295e-06,
      "loss": 0.1587,
      "step": 17326
    },
    {
      "epoch": 1.346518495492695,
      "grad_norm": 0.5404767394065857,
      "learning_rate": 3.267407522536525e-06,
      "loss": 0.1258,
      "step": 17327
    },
    {
      "epoch": 1.346596207646876,
      "grad_norm": 0.06339611858129501,
      "learning_rate": 3.2670189617656207e-06,
      "loss": 0.0119,
      "step": 17328
    },
    {
      "epoch": 1.3466739198010569,
      "grad_norm": 0.15490710735321045,
      "learning_rate": 3.266630400994716e-06,
      "loss": 0.0349,
      "step": 17329
    },
    {
      "epoch": 1.3467516319552377,
      "grad_norm": 0.7522722482681274,
      "learning_rate": 3.266241840223811e-06,
      "loss": 0.1436,
      "step": 17330
    },
    {
      "epoch": 1.3468293441094188,
      "grad_norm": 0.37997710704803467,
      "learning_rate": 3.265853279452907e-06,
      "loss": 0.1533,
      "step": 17331
    },
    {
      "epoch": 1.3469070562635996,
      "grad_norm": 0.18400779366493225,
      "learning_rate": 3.265464718682002e-06,
      "loss": 0.0518,
      "step": 17332
    },
    {
      "epoch": 1.3469847684177805,
      "grad_norm": 0.297904908657074,
      "learning_rate": 3.2650761579110975e-06,
      "loss": 0.074,
      "step": 17333
    },
    {
      "epoch": 1.3470624805719615,
      "grad_norm": 0.4201652407646179,
      "learning_rate": 3.264687597140193e-06,
      "loss": 0.1216,
      "step": 17334
    },
    {
      "epoch": 1.3471401927261424,
      "grad_norm": 0.34374263882637024,
      "learning_rate": 3.2642990363692883e-06,
      "loss": 0.1345,
      "step": 17335
    },
    {
      "epoch": 1.3472179048803232,
      "grad_norm": 1.883902668952942,
      "learning_rate": 3.2639104755983837e-06,
      "loss": 0.1319,
      "step": 17336
    },
    {
      "epoch": 1.3472956170345043,
      "grad_norm": 0.21072101593017578,
      "learning_rate": 3.2635219148274795e-06,
      "loss": 0.0393,
      "step": 17337
    },
    {
      "epoch": 1.3473733291886851,
      "grad_norm": 0.9234227538108826,
      "learning_rate": 3.2631333540565744e-06,
      "loss": 0.4517,
      "step": 17338
    },
    {
      "epoch": 1.347451041342866,
      "grad_norm": 0.8694682121276855,
      "learning_rate": 3.26274479328567e-06,
      "loss": 0.2693,
      "step": 17339
    },
    {
      "epoch": 1.347528753497047,
      "grad_norm": 0.3375311493873596,
      "learning_rate": 3.2623562325147656e-06,
      "loss": 0.1587,
      "step": 17340
    },
    {
      "epoch": 1.3476064656512279,
      "grad_norm": 0.9300264716148376,
      "learning_rate": 3.261967671743861e-06,
      "loss": 0.4514,
      "step": 17341
    },
    {
      "epoch": 1.3476841778054087,
      "grad_norm": 0.49540451169013977,
      "learning_rate": 3.2615791109729567e-06,
      "loss": 0.0973,
      "step": 17342
    },
    {
      "epoch": 1.3477618899595898,
      "grad_norm": 0.6045413613319397,
      "learning_rate": 3.2611905502020517e-06,
      "loss": 0.1564,
      "step": 17343
    },
    {
      "epoch": 1.3478396021137706,
      "grad_norm": 0.2106822431087494,
      "learning_rate": 3.260801989431147e-06,
      "loss": 0.0184,
      "step": 17344
    },
    {
      "epoch": 1.3479173142679515,
      "grad_norm": 0.23843804001808167,
      "learning_rate": 3.260413428660243e-06,
      "loss": 0.0821,
      "step": 17345
    },
    {
      "epoch": 1.3479950264221325,
      "grad_norm": 0.8120678663253784,
      "learning_rate": 3.2600248678893382e-06,
      "loss": 0.2361,
      "step": 17346
    },
    {
      "epoch": 1.3480727385763134,
      "grad_norm": 0.41464680433273315,
      "learning_rate": 3.259636307118433e-06,
      "loss": 0.1075,
      "step": 17347
    },
    {
      "epoch": 1.3481504507304942,
      "grad_norm": 0.5666393041610718,
      "learning_rate": 3.259247746347529e-06,
      "loss": 0.3398,
      "step": 17348
    },
    {
      "epoch": 1.3482281628846753,
      "grad_norm": 0.28076857328414917,
      "learning_rate": 3.2588591855766244e-06,
      "loss": 0.0507,
      "step": 17349
    },
    {
      "epoch": 1.3483058750388561,
      "grad_norm": 0.4146244525909424,
      "learning_rate": 3.2584706248057197e-06,
      "loss": 0.0292,
      "step": 17350
    },
    {
      "epoch": 1.348383587193037,
      "grad_norm": 0.41275689005851746,
      "learning_rate": 3.2580820640348155e-06,
      "loss": 0.1488,
      "step": 17351
    },
    {
      "epoch": 1.348461299347218,
      "grad_norm": 0.1776360720396042,
      "learning_rate": 3.2576935032639105e-06,
      "loss": 0.0489,
      "step": 17352
    },
    {
      "epoch": 1.3485390115013989,
      "grad_norm": 0.7022871375083923,
      "learning_rate": 3.2573049424930063e-06,
      "loss": 0.2413,
      "step": 17353
    },
    {
      "epoch": 1.3486167236555797,
      "grad_norm": 0.5894480347633362,
      "learning_rate": 3.2569163817221016e-06,
      "loss": 0.2647,
      "step": 17354
    },
    {
      "epoch": 1.3486944358097608,
      "grad_norm": 0.23456603288650513,
      "learning_rate": 3.256527820951197e-06,
      "loss": 0.1674,
      "step": 17355
    },
    {
      "epoch": 1.3487721479639416,
      "grad_norm": 1.0354011058807373,
      "learning_rate": 3.256139260180293e-06,
      "loss": 0.2335,
      "step": 17356
    },
    {
      "epoch": 1.3488498601181225,
      "grad_norm": 0.47718045115470886,
      "learning_rate": 3.2557506994093878e-06,
      "loss": 0.199,
      "step": 17357
    },
    {
      "epoch": 1.3489275722723033,
      "grad_norm": 0.24079233407974243,
      "learning_rate": 3.255362138638483e-06,
      "loss": 0.0616,
      "step": 17358
    },
    {
      "epoch": 1.3490052844264844,
      "grad_norm": 0.6956862807273865,
      "learning_rate": 3.254973577867579e-06,
      "loss": 0.1662,
      "step": 17359
    },
    {
      "epoch": 1.3490829965806652,
      "grad_norm": 0.5771599411964417,
      "learning_rate": 3.2545850170966743e-06,
      "loss": 0.1473,
      "step": 17360
    },
    {
      "epoch": 1.349160708734846,
      "grad_norm": 0.07623019814491272,
      "learning_rate": 3.2541964563257693e-06,
      "loss": 0.0187,
      "step": 17361
    },
    {
      "epoch": 1.3492384208890271,
      "grad_norm": 0.29733654856681824,
      "learning_rate": 3.253807895554865e-06,
      "loss": 0.035,
      "step": 17362
    },
    {
      "epoch": 1.349316133043208,
      "grad_norm": 0.7478824853897095,
      "learning_rate": 3.2534193347839604e-06,
      "loss": 0.2117,
      "step": 17363
    },
    {
      "epoch": 1.3493938451973888,
      "grad_norm": 0.4040868878364563,
      "learning_rate": 3.253030774013056e-06,
      "loss": 0.111,
      "step": 17364
    },
    {
      "epoch": 1.3494715573515697,
      "grad_norm": 0.04929199814796448,
      "learning_rate": 3.2526422132421516e-06,
      "loss": 0.008,
      "step": 17365
    },
    {
      "epoch": 1.3495492695057507,
      "grad_norm": 0.12635113298892975,
      "learning_rate": 3.2522536524712466e-06,
      "loss": 0.0388,
      "step": 17366
    },
    {
      "epoch": 1.3496269816599316,
      "grad_norm": 0.42375731468200684,
      "learning_rate": 3.251865091700342e-06,
      "loss": 0.3245,
      "step": 17367
    },
    {
      "epoch": 1.3497046938141124,
      "grad_norm": 0.48039841651916504,
      "learning_rate": 3.2514765309294377e-06,
      "loss": 0.184,
      "step": 17368
    },
    {
      "epoch": 1.3497824059682935,
      "grad_norm": 0.2512498199939728,
      "learning_rate": 3.251087970158533e-06,
      "loss": 0.0892,
      "step": 17369
    },
    {
      "epoch": 1.3498601181224743,
      "grad_norm": 0.43311694264411926,
      "learning_rate": 3.250699409387629e-06,
      "loss": 0.1005,
      "step": 17370
    },
    {
      "epoch": 1.3499378302766551,
      "grad_norm": 0.5433488488197327,
      "learning_rate": 3.250310848616724e-06,
      "loss": 0.1196,
      "step": 17371
    },
    {
      "epoch": 1.3500155424308362,
      "grad_norm": 0.7743754982948303,
      "learning_rate": 3.2499222878458192e-06,
      "loss": 0.2262,
      "step": 17372
    },
    {
      "epoch": 1.350093254585017,
      "grad_norm": 0.4386560916900635,
      "learning_rate": 3.249533727074915e-06,
      "loss": 0.1717,
      "step": 17373
    },
    {
      "epoch": 1.350170966739198,
      "grad_norm": 0.38855308294296265,
      "learning_rate": 3.2491451663040104e-06,
      "loss": 0.1364,
      "step": 17374
    },
    {
      "epoch": 1.350248678893379,
      "grad_norm": 1.1926531791687012,
      "learning_rate": 3.2487566055331053e-06,
      "loss": 0.7061,
      "step": 17375
    },
    {
      "epoch": 1.3503263910475598,
      "grad_norm": 0.1740764081478119,
      "learning_rate": 3.248368044762201e-06,
      "loss": 0.0398,
      "step": 17376
    },
    {
      "epoch": 1.3504041032017406,
      "grad_norm": 0.46579763293266296,
      "learning_rate": 3.2479794839912965e-06,
      "loss": 0.1547,
      "step": 17377
    },
    {
      "epoch": 1.3504818153559217,
      "grad_norm": 0.6355983018875122,
      "learning_rate": 3.247590923220392e-06,
      "loss": 0.1309,
      "step": 17378
    },
    {
      "epoch": 1.3505595275101026,
      "grad_norm": 0.4401637315750122,
      "learning_rate": 3.2472023624494877e-06,
      "loss": 0.1005,
      "step": 17379
    },
    {
      "epoch": 1.3506372396642834,
      "grad_norm": 0.7427908778190613,
      "learning_rate": 3.2468138016785826e-06,
      "loss": 0.2284,
      "step": 17380
    },
    {
      "epoch": 1.3507149518184645,
      "grad_norm": 0.2660819888114929,
      "learning_rate": 3.246425240907678e-06,
      "loss": 0.0729,
      "step": 17381
    },
    {
      "epoch": 1.3507926639726453,
      "grad_norm": 0.9916806221008301,
      "learning_rate": 3.246036680136774e-06,
      "loss": 0.2288,
      "step": 17382
    },
    {
      "epoch": 1.3508703761268261,
      "grad_norm": 1.0366015434265137,
      "learning_rate": 3.245648119365869e-06,
      "loss": 0.293,
      "step": 17383
    },
    {
      "epoch": 1.3509480882810072,
      "grad_norm": 0.244665265083313,
      "learning_rate": 3.245259558594965e-06,
      "loss": 0.0302,
      "step": 17384
    },
    {
      "epoch": 1.351025800435188,
      "grad_norm": 0.4488193690776825,
      "learning_rate": 3.24487099782406e-06,
      "loss": 0.0817,
      "step": 17385
    },
    {
      "epoch": 1.351103512589369,
      "grad_norm": 0.4504983723163605,
      "learning_rate": 3.2444824370531553e-06,
      "loss": 0.0593,
      "step": 17386
    },
    {
      "epoch": 1.35118122474355,
      "grad_norm": 0.4117617607116699,
      "learning_rate": 3.244093876282251e-06,
      "loss": 0.1596,
      "step": 17387
    },
    {
      "epoch": 1.3512589368977308,
      "grad_norm": 0.2166735827922821,
      "learning_rate": 3.2437053155113465e-06,
      "loss": 0.1492,
      "step": 17388
    },
    {
      "epoch": 1.3513366490519116,
      "grad_norm": 0.27819639444351196,
      "learning_rate": 3.2433167547404414e-06,
      "loss": 0.0395,
      "step": 17389
    },
    {
      "epoch": 1.3514143612060927,
      "grad_norm": 0.5580477118492126,
      "learning_rate": 3.242928193969537e-06,
      "loss": 0.1015,
      "step": 17390
    },
    {
      "epoch": 1.3514920733602735,
      "grad_norm": 3.3134706020355225,
      "learning_rate": 3.2425396331986326e-06,
      "loss": 0.2385,
      "step": 17391
    },
    {
      "epoch": 1.3515697855144544,
      "grad_norm": 0.5742586851119995,
      "learning_rate": 3.242151072427728e-06,
      "loss": 0.2706,
      "step": 17392
    },
    {
      "epoch": 1.3516474976686355,
      "grad_norm": 0.7360082864761353,
      "learning_rate": 3.2417625116568237e-06,
      "loss": 0.3173,
      "step": 17393
    },
    {
      "epoch": 1.3517252098228163,
      "grad_norm": 0.5682575702667236,
      "learning_rate": 3.2413739508859187e-06,
      "loss": 0.108,
      "step": 17394
    },
    {
      "epoch": 1.3518029219769971,
      "grad_norm": 0.6156299114227295,
      "learning_rate": 3.240985390115014e-06,
      "loss": 0.2097,
      "step": 17395
    },
    {
      "epoch": 1.3518806341311782,
      "grad_norm": 0.787516176700592,
      "learning_rate": 3.24059682934411e-06,
      "loss": 0.1805,
      "step": 17396
    },
    {
      "epoch": 1.351958346285359,
      "grad_norm": 0.3707181215286255,
      "learning_rate": 3.2402082685732052e-06,
      "loss": 0.0718,
      "step": 17397
    },
    {
      "epoch": 1.35203605843954,
      "grad_norm": 0.16004720330238342,
      "learning_rate": 3.2398197078023006e-06,
      "loss": 0.0545,
      "step": 17398
    },
    {
      "epoch": 1.352113770593721,
      "grad_norm": 0.19434575736522675,
      "learning_rate": 3.239431147031396e-06,
      "loss": 0.1103,
      "step": 17399
    },
    {
      "epoch": 1.3521914827479018,
      "grad_norm": 0.17102168500423431,
      "learning_rate": 3.2390425862604914e-06,
      "loss": 0.0562,
      "step": 17400
    },
    {
      "epoch": 1.3522691949020826,
      "grad_norm": 0.5373273491859436,
      "learning_rate": 3.238654025489587e-06,
      "loss": 0.1141,
      "step": 17401
    },
    {
      "epoch": 1.3523469070562637,
      "grad_norm": 1.343400478363037,
      "learning_rate": 3.238265464718682e-06,
      "loss": 0.2164,
      "step": 17402
    },
    {
      "epoch": 1.3524246192104445,
      "grad_norm": 0.35135212540626526,
      "learning_rate": 3.2378769039477775e-06,
      "loss": 0.1871,
      "step": 17403
    },
    {
      "epoch": 1.3525023313646254,
      "grad_norm": 0.4297504127025604,
      "learning_rate": 3.2374883431768733e-06,
      "loss": 0.4609,
      "step": 17404
    },
    {
      "epoch": 1.3525800435188065,
      "grad_norm": 0.2632620334625244,
      "learning_rate": 3.2370997824059686e-06,
      "loss": 0.0371,
      "step": 17405
    },
    {
      "epoch": 1.3526577556729873,
      "grad_norm": 0.2818809151649475,
      "learning_rate": 3.2367112216350636e-06,
      "loss": 0.1283,
      "step": 17406
    },
    {
      "epoch": 1.3527354678271681,
      "grad_norm": 0.3764317035675049,
      "learning_rate": 3.2363226608641594e-06,
      "loss": 0.0728,
      "step": 17407
    },
    {
      "epoch": 1.3528131799813492,
      "grad_norm": 0.2700166702270508,
      "learning_rate": 3.2359341000932548e-06,
      "loss": 0.046,
      "step": 17408
    },
    {
      "epoch": 1.35289089213553,
      "grad_norm": 1.021881103515625,
      "learning_rate": 3.23554553932235e-06,
      "loss": 0.6668,
      "step": 17409
    },
    {
      "epoch": 1.3529686042897109,
      "grad_norm": 0.22759541869163513,
      "learning_rate": 3.235156978551446e-06,
      "loss": 0.0794,
      "step": 17410
    },
    {
      "epoch": 1.353046316443892,
      "grad_norm": 0.4579254388809204,
      "learning_rate": 3.234768417780541e-06,
      "loss": 0.2434,
      "step": 17411
    },
    {
      "epoch": 1.3531240285980728,
      "grad_norm": 0.08750688284635544,
      "learning_rate": 3.2343798570096363e-06,
      "loss": 0.0273,
      "step": 17412
    },
    {
      "epoch": 1.3532017407522536,
      "grad_norm": 0.5722271203994751,
      "learning_rate": 3.233991296238732e-06,
      "loss": 0.3218,
      "step": 17413
    },
    {
      "epoch": 1.3532794529064347,
      "grad_norm": 0.5165507793426514,
      "learning_rate": 3.2336027354678274e-06,
      "loss": 0.039,
      "step": 17414
    },
    {
      "epoch": 1.3533571650606155,
      "grad_norm": 0.5681131482124329,
      "learning_rate": 3.2332141746969232e-06,
      "loss": 0.1549,
      "step": 17415
    },
    {
      "epoch": 1.3534348772147964,
      "grad_norm": 0.35018348693847656,
      "learning_rate": 3.232825613926018e-06,
      "loss": 0.0732,
      "step": 17416
    },
    {
      "epoch": 1.3535125893689772,
      "grad_norm": 0.2052648365497589,
      "learning_rate": 3.2324370531551136e-06,
      "loss": 0.0593,
      "step": 17417
    },
    {
      "epoch": 1.3535903015231583,
      "grad_norm": 0.9022657871246338,
      "learning_rate": 3.2320484923842093e-06,
      "loss": 0.4469,
      "step": 17418
    },
    {
      "epoch": 1.3536680136773391,
      "grad_norm": 0.6209923624992371,
      "learning_rate": 3.2316599316133047e-06,
      "loss": 0.0919,
      "step": 17419
    },
    {
      "epoch": 1.35374572583152,
      "grad_norm": 0.0103384330868721,
      "learning_rate": 3.2312713708423997e-06,
      "loss": 0.0005,
      "step": 17420
    },
    {
      "epoch": 1.353823437985701,
      "grad_norm": 0.3383679687976837,
      "learning_rate": 3.2308828100714955e-06,
      "loss": 0.0873,
      "step": 17421
    },
    {
      "epoch": 1.3539011501398819,
      "grad_norm": 0.8062659502029419,
      "learning_rate": 3.230494249300591e-06,
      "loss": 0.3748,
      "step": 17422
    },
    {
      "epoch": 1.3539788622940627,
      "grad_norm": 0.45076149702072144,
      "learning_rate": 3.2301056885296862e-06,
      "loss": 0.0834,
      "step": 17423
    },
    {
      "epoch": 1.3540565744482438,
      "grad_norm": 0.32763415575027466,
      "learning_rate": 3.229717127758782e-06,
      "loss": 0.1229,
      "step": 17424
    },
    {
      "epoch": 1.3541342866024246,
      "grad_norm": 0.8063057661056519,
      "learning_rate": 3.229328566987877e-06,
      "loss": 0.2039,
      "step": 17425
    },
    {
      "epoch": 1.3542119987566055,
      "grad_norm": 0.6942418813705444,
      "learning_rate": 3.2289400062169723e-06,
      "loss": 0.3514,
      "step": 17426
    },
    {
      "epoch": 1.3542897109107863,
      "grad_norm": 0.32519933581352234,
      "learning_rate": 3.228551445446068e-06,
      "loss": 0.1604,
      "step": 17427
    },
    {
      "epoch": 1.3543674230649674,
      "grad_norm": 0.6416012644767761,
      "learning_rate": 3.2281628846751635e-06,
      "loss": 0.4172,
      "step": 17428
    },
    {
      "epoch": 1.3544451352191482,
      "grad_norm": 0.19993257522583008,
      "learning_rate": 3.2277743239042593e-06,
      "loss": 0.0341,
      "step": 17429
    },
    {
      "epoch": 1.354522847373329,
      "grad_norm": 0.4109501540660858,
      "learning_rate": 3.2273857631333543e-06,
      "loss": 0.3938,
      "step": 17430
    },
    {
      "epoch": 1.3546005595275101,
      "grad_norm": 0.6613949537277222,
      "learning_rate": 3.2269972023624496e-06,
      "loss": 0.2627,
      "step": 17431
    },
    {
      "epoch": 1.354678271681691,
      "grad_norm": 1.2321916818618774,
      "learning_rate": 3.2266086415915454e-06,
      "loss": 0.5606,
      "step": 17432
    },
    {
      "epoch": 1.3547559838358718,
      "grad_norm": 1.1203653812408447,
      "learning_rate": 3.226220080820641e-06,
      "loss": 0.271,
      "step": 17433
    },
    {
      "epoch": 1.3548336959900529,
      "grad_norm": 0.1311488002538681,
      "learning_rate": 3.2258315200497357e-06,
      "loss": 0.0349,
      "step": 17434
    },
    {
      "epoch": 1.3549114081442337,
      "grad_norm": 0.37292495369911194,
      "learning_rate": 3.2254429592788315e-06,
      "loss": 0.1053,
      "step": 17435
    },
    {
      "epoch": 1.3549891202984146,
      "grad_norm": 0.8125675320625305,
      "learning_rate": 3.225054398507927e-06,
      "loss": 0.0935,
      "step": 17436
    },
    {
      "epoch": 1.3550668324525956,
      "grad_norm": 0.40840426087379456,
      "learning_rate": 3.2246658377370223e-06,
      "loss": 0.0512,
      "step": 17437
    },
    {
      "epoch": 1.3551445446067765,
      "grad_norm": 0.6877942681312561,
      "learning_rate": 3.224277276966118e-06,
      "loss": 0.2356,
      "step": 17438
    },
    {
      "epoch": 1.3552222567609573,
      "grad_norm": 0.5748534202575684,
      "learning_rate": 3.223888716195213e-06,
      "loss": 0.2088,
      "step": 17439
    },
    {
      "epoch": 1.3552999689151384,
      "grad_norm": 0.21612586081027985,
      "learning_rate": 3.2235001554243084e-06,
      "loss": 0.0405,
      "step": 17440
    },
    {
      "epoch": 1.3553776810693192,
      "grad_norm": 0.24127604067325592,
      "learning_rate": 3.223111594653404e-06,
      "loss": 0.1227,
      "step": 17441
    },
    {
      "epoch": 1.3554553932235,
      "grad_norm": 0.82882159948349,
      "learning_rate": 3.2227230338824996e-06,
      "loss": 0.2744,
      "step": 17442
    },
    {
      "epoch": 1.3555331053776811,
      "grad_norm": 0.12999604642391205,
      "learning_rate": 3.2223344731115945e-06,
      "loss": 0.0331,
      "step": 17443
    },
    {
      "epoch": 1.355610817531862,
      "grad_norm": 0.9378710985183716,
      "learning_rate": 3.2219459123406903e-06,
      "loss": 0.3457,
      "step": 17444
    },
    {
      "epoch": 1.3556885296860428,
      "grad_norm": 0.2640005946159363,
      "learning_rate": 3.2215573515697857e-06,
      "loss": 0.0709,
      "step": 17445
    },
    {
      "epoch": 1.3557662418402239,
      "grad_norm": 0.145898699760437,
      "learning_rate": 3.2211687907988815e-06,
      "loss": 0.0451,
      "step": 17446
    },
    {
      "epoch": 1.3558439539944047,
      "grad_norm": 0.44591572880744934,
      "learning_rate": 3.220780230027977e-06,
      "loss": 0.1983,
      "step": 17447
    },
    {
      "epoch": 1.3559216661485856,
      "grad_norm": 0.24333025515079498,
      "learning_rate": 3.220391669257072e-06,
      "loss": 0.0224,
      "step": 17448
    },
    {
      "epoch": 1.3559993783027666,
      "grad_norm": 0.5545148253440857,
      "learning_rate": 3.2200031084861676e-06,
      "loss": 0.0798,
      "step": 17449
    },
    {
      "epoch": 1.3560770904569475,
      "grad_norm": 0.5078973770141602,
      "learning_rate": 3.219614547715263e-06,
      "loss": 0.1401,
      "step": 17450
    },
    {
      "epoch": 1.3561548026111283,
      "grad_norm": 0.4109639823436737,
      "learning_rate": 3.2192259869443584e-06,
      "loss": 0.1492,
      "step": 17451
    },
    {
      "epoch": 1.3562325147653094,
      "grad_norm": 0.9687609672546387,
      "learning_rate": 3.218837426173454e-06,
      "loss": 0.3889,
      "step": 17452
    },
    {
      "epoch": 1.3563102269194902,
      "grad_norm": 0.5690397024154663,
      "learning_rate": 3.218448865402549e-06,
      "loss": 0.3134,
      "step": 17453
    },
    {
      "epoch": 1.356387939073671,
      "grad_norm": 0.07020339369773865,
      "learning_rate": 3.2180603046316445e-06,
      "loss": 0.0084,
      "step": 17454
    },
    {
      "epoch": 1.3564656512278521,
      "grad_norm": 0.47511017322540283,
      "learning_rate": 3.2176717438607403e-06,
      "loss": 0.2252,
      "step": 17455
    },
    {
      "epoch": 1.356543363382033,
      "grad_norm": 0.27044498920440674,
      "learning_rate": 3.2172831830898357e-06,
      "loss": 0.0371,
      "step": 17456
    },
    {
      "epoch": 1.3566210755362138,
      "grad_norm": 0.28909191489219666,
      "learning_rate": 3.2168946223189306e-06,
      "loss": 0.1287,
      "step": 17457
    },
    {
      "epoch": 1.3566987876903949,
      "grad_norm": 0.20544975996017456,
      "learning_rate": 3.2165060615480264e-06,
      "loss": 0.1893,
      "step": 17458
    },
    {
      "epoch": 1.3567764998445757,
      "grad_norm": 0.41795629262924194,
      "learning_rate": 3.2161175007771218e-06,
      "loss": 0.1473,
      "step": 17459
    },
    {
      "epoch": 1.3568542119987566,
      "grad_norm": 0.605988085269928,
      "learning_rate": 3.2157289400062176e-06,
      "loss": 0.4915,
      "step": 17460
    },
    {
      "epoch": 1.3569319241529376,
      "grad_norm": 0.4349486231803894,
      "learning_rate": 3.2153403792353125e-06,
      "loss": 0.3754,
      "step": 17461
    },
    {
      "epoch": 1.3570096363071185,
      "grad_norm": 0.5040532946586609,
      "learning_rate": 3.214951818464408e-06,
      "loss": 0.0659,
      "step": 17462
    },
    {
      "epoch": 1.3570873484612993,
      "grad_norm": 0.32358092069625854,
      "learning_rate": 3.2145632576935037e-06,
      "loss": 0.0491,
      "step": 17463
    },
    {
      "epoch": 1.3571650606154804,
      "grad_norm": 0.2401900291442871,
      "learning_rate": 3.214174696922599e-06,
      "loss": 0.0613,
      "step": 17464
    },
    {
      "epoch": 1.3572427727696612,
      "grad_norm": 0.6470292210578918,
      "learning_rate": 3.213786136151694e-06,
      "loss": 0.4072,
      "step": 17465
    },
    {
      "epoch": 1.357320484923842,
      "grad_norm": 1.2866922616958618,
      "learning_rate": 3.21339757538079e-06,
      "loss": 0.3392,
      "step": 17466
    },
    {
      "epoch": 1.3573981970780231,
      "grad_norm": 0.34302178025245667,
      "learning_rate": 3.213009014609885e-06,
      "loss": 0.0577,
      "step": 17467
    },
    {
      "epoch": 1.357475909232204,
      "grad_norm": 0.27948835492134094,
      "learning_rate": 3.2126204538389806e-06,
      "loss": 0.0976,
      "step": 17468
    },
    {
      "epoch": 1.3575536213863848,
      "grad_norm": 0.8830345869064331,
      "learning_rate": 3.2122318930680764e-06,
      "loss": 0.1027,
      "step": 17469
    },
    {
      "epoch": 1.3576313335405659,
      "grad_norm": 0.14701299369335175,
      "learning_rate": 3.2118433322971713e-06,
      "loss": 0.0495,
      "step": 17470
    },
    {
      "epoch": 1.3577090456947467,
      "grad_norm": 1.2585630416870117,
      "learning_rate": 3.2114547715262667e-06,
      "loss": 0.6116,
      "step": 17471
    },
    {
      "epoch": 1.3577867578489276,
      "grad_norm": 0.5941742062568665,
      "learning_rate": 3.2110662107553625e-06,
      "loss": 0.2521,
      "step": 17472
    },
    {
      "epoch": 1.3578644700031086,
      "grad_norm": 0.6145800352096558,
      "learning_rate": 3.210677649984458e-06,
      "loss": 0.1984,
      "step": 17473
    },
    {
      "epoch": 1.3579421821572895,
      "grad_norm": 0.6008205413818359,
      "learning_rate": 3.2102890892135536e-06,
      "loss": 0.4857,
      "step": 17474
    },
    {
      "epoch": 1.3580198943114703,
      "grad_norm": 0.41115081310272217,
      "learning_rate": 3.2099005284426486e-06,
      "loss": 0.1918,
      "step": 17475
    },
    {
      "epoch": 1.3580976064656514,
      "grad_norm": 0.2891876995563507,
      "learning_rate": 3.209511967671744e-06,
      "loss": 0.1709,
      "step": 17476
    },
    {
      "epoch": 1.3581753186198322,
      "grad_norm": 0.3065643310546875,
      "learning_rate": 3.2091234069008398e-06,
      "loss": 0.0566,
      "step": 17477
    },
    {
      "epoch": 1.358253030774013,
      "grad_norm": 0.608397364616394,
      "learning_rate": 3.208734846129935e-06,
      "loss": 0.1523,
      "step": 17478
    },
    {
      "epoch": 1.358330742928194,
      "grad_norm": 0.2204512655735016,
      "learning_rate": 3.20834628535903e-06,
      "loss": 0.0221,
      "step": 17479
    },
    {
      "epoch": 1.358408455082375,
      "grad_norm": 0.8520246744155884,
      "learning_rate": 3.207957724588126e-06,
      "loss": 0.186,
      "step": 17480
    },
    {
      "epoch": 1.3584861672365558,
      "grad_norm": 1.0374974012374878,
      "learning_rate": 3.2075691638172213e-06,
      "loss": 0.2829,
      "step": 17481
    },
    {
      "epoch": 1.3585638793907366,
      "grad_norm": 0.6085254549980164,
      "learning_rate": 3.2071806030463166e-06,
      "loss": 0.0749,
      "step": 17482
    },
    {
      "epoch": 1.3586415915449177,
      "grad_norm": 0.36021173000335693,
      "learning_rate": 3.2067920422754124e-06,
      "loss": 0.0939,
      "step": 17483
    },
    {
      "epoch": 1.3587193036990985,
      "grad_norm": 0.17973598837852478,
      "learning_rate": 3.2064034815045074e-06,
      "loss": 0.0957,
      "step": 17484
    },
    {
      "epoch": 1.3587970158532794,
      "grad_norm": 0.40430188179016113,
      "learning_rate": 3.2060149207336027e-06,
      "loss": 0.1502,
      "step": 17485
    },
    {
      "epoch": 1.3588747280074602,
      "grad_norm": 0.4411989450454712,
      "learning_rate": 3.2056263599626985e-06,
      "loss": 0.2617,
      "step": 17486
    },
    {
      "epoch": 1.3589524401616413,
      "grad_norm": 0.21309173107147217,
      "learning_rate": 3.205237799191794e-06,
      "loss": 0.0722,
      "step": 17487
    },
    {
      "epoch": 1.3590301523158221,
      "grad_norm": 0.0893959030508995,
      "learning_rate": 3.204849238420889e-06,
      "loss": 0.0048,
      "step": 17488
    },
    {
      "epoch": 1.359107864470003,
      "grad_norm": 0.09892105311155319,
      "learning_rate": 3.2044606776499847e-06,
      "loss": 0.0125,
      "step": 17489
    },
    {
      "epoch": 1.359185576624184,
      "grad_norm": 0.8655734062194824,
      "learning_rate": 3.20407211687908e-06,
      "loss": 0.2967,
      "step": 17490
    },
    {
      "epoch": 1.3592632887783649,
      "grad_norm": 0.3687977194786072,
      "learning_rate": 3.203683556108176e-06,
      "loss": 0.0859,
      "step": 17491
    },
    {
      "epoch": 1.3593410009325457,
      "grad_norm": 0.5182501077651978,
      "learning_rate": 3.203294995337271e-06,
      "loss": 0.467,
      "step": 17492
    },
    {
      "epoch": 1.3594187130867268,
      "grad_norm": 0.12033945322036743,
      "learning_rate": 3.202906434566366e-06,
      "loss": 0.0268,
      "step": 17493
    },
    {
      "epoch": 1.3594964252409076,
      "grad_norm": 0.6243577003479004,
      "learning_rate": 3.202517873795462e-06,
      "loss": 0.4199,
      "step": 17494
    },
    {
      "epoch": 1.3595741373950885,
      "grad_norm": 0.594897449016571,
      "learning_rate": 3.2021293130245573e-06,
      "loss": 0.2366,
      "step": 17495
    },
    {
      "epoch": 1.3596518495492695,
      "grad_norm": 0.2675262689590454,
      "learning_rate": 3.2017407522536527e-06,
      "loss": 0.0669,
      "step": 17496
    },
    {
      "epoch": 1.3597295617034504,
      "grad_norm": 0.4517667293548584,
      "learning_rate": 3.2013521914827485e-06,
      "loss": 0.1195,
      "step": 17497
    },
    {
      "epoch": 1.3598072738576312,
      "grad_norm": 0.16229508817195892,
      "learning_rate": 3.2009636307118434e-06,
      "loss": 0.0281,
      "step": 17498
    },
    {
      "epoch": 1.3598849860118123,
      "grad_norm": 0.03056497685611248,
      "learning_rate": 3.200575069940939e-06,
      "loss": 0.0009,
      "step": 17499
    },
    {
      "epoch": 1.3599626981659931,
      "grad_norm": 0.7163001894950867,
      "learning_rate": 3.2001865091700346e-06,
      "loss": 0.3466,
      "step": 17500
    },
    {
      "epoch": 1.360040410320174,
      "grad_norm": 0.39918363094329834,
      "learning_rate": 3.19979794839913e-06,
      "loss": 0.3138,
      "step": 17501
    },
    {
      "epoch": 1.360118122474355,
      "grad_norm": 0.3607359826564789,
      "learning_rate": 3.199409387628225e-06,
      "loss": 0.1629,
      "step": 17502
    },
    {
      "epoch": 1.3601958346285359,
      "grad_norm": 0.5423916578292847,
      "learning_rate": 3.1990208268573207e-06,
      "loss": 0.1025,
      "step": 17503
    },
    {
      "epoch": 1.3602735467827167,
      "grad_norm": 0.3721027374267578,
      "learning_rate": 3.198632266086416e-06,
      "loss": 0.0352,
      "step": 17504
    },
    {
      "epoch": 1.3603512589368978,
      "grad_norm": 0.43554118275642395,
      "learning_rate": 3.198243705315512e-06,
      "loss": 0.1412,
      "step": 17505
    },
    {
      "epoch": 1.3604289710910786,
      "grad_norm": 0.43695735931396484,
      "learning_rate": 3.1978551445446073e-06,
      "loss": 0.1591,
      "step": 17506
    },
    {
      "epoch": 1.3605066832452595,
      "grad_norm": 0.35980382561683655,
      "learning_rate": 3.1974665837737022e-06,
      "loss": 0.0983,
      "step": 17507
    },
    {
      "epoch": 1.3605843953994405,
      "grad_norm": 0.5511015057563782,
      "learning_rate": 3.197078023002798e-06,
      "loss": 0.1699,
      "step": 17508
    },
    {
      "epoch": 1.3606621075536214,
      "grad_norm": 1.170240879058838,
      "learning_rate": 3.1966894622318934e-06,
      "loss": 0.2312,
      "step": 17509
    },
    {
      "epoch": 1.3607398197078022,
      "grad_norm": 0.3137781620025635,
      "learning_rate": 3.1963009014609888e-06,
      "loss": 0.1452,
      "step": 17510
    },
    {
      "epoch": 1.3608175318619833,
      "grad_norm": 0.22423085570335388,
      "learning_rate": 3.1959123406900846e-06,
      "loss": 0.021,
      "step": 17511
    },
    {
      "epoch": 1.3608952440161641,
      "grad_norm": 0.4124014973640442,
      "learning_rate": 3.1955237799191795e-06,
      "loss": 0.0995,
      "step": 17512
    },
    {
      "epoch": 1.360972956170345,
      "grad_norm": 0.20123782753944397,
      "learning_rate": 3.195135219148275e-06,
      "loss": 0.0651,
      "step": 17513
    },
    {
      "epoch": 1.361050668324526,
      "grad_norm": 0.46589186787605286,
      "learning_rate": 3.1947466583773707e-06,
      "loss": 0.1603,
      "step": 17514
    },
    {
      "epoch": 1.3611283804787069,
      "grad_norm": 0.7625158429145813,
      "learning_rate": 3.194358097606466e-06,
      "loss": 0.4046,
      "step": 17515
    },
    {
      "epoch": 1.3612060926328877,
      "grad_norm": 0.73615962266922,
      "learning_rate": 3.193969536835561e-06,
      "loss": 0.4403,
      "step": 17516
    },
    {
      "epoch": 1.3612838047870688,
      "grad_norm": 0.9680888652801514,
      "learning_rate": 3.193580976064657e-06,
      "loss": 0.5113,
      "step": 17517
    },
    {
      "epoch": 1.3613615169412496,
      "grad_norm": 0.12297167629003525,
      "learning_rate": 3.193192415293752e-06,
      "loss": 0.015,
      "step": 17518
    },
    {
      "epoch": 1.3614392290954305,
      "grad_norm": 0.3136158883571625,
      "learning_rate": 3.192803854522848e-06,
      "loss": 0.2159,
      "step": 17519
    },
    {
      "epoch": 1.3615169412496115,
      "grad_norm": 0.5361651182174683,
      "learning_rate": 3.1924152937519434e-06,
      "loss": 0.1729,
      "step": 17520
    },
    {
      "epoch": 1.3615946534037924,
      "grad_norm": 0.24397021532058716,
      "learning_rate": 3.1920267329810383e-06,
      "loss": 0.1342,
      "step": 17521
    },
    {
      "epoch": 1.3616723655579732,
      "grad_norm": 0.3290349841117859,
      "learning_rate": 3.191638172210134e-06,
      "loss": 0.1162,
      "step": 17522
    },
    {
      "epoch": 1.3617500777121543,
      "grad_norm": 0.8378466367721558,
      "learning_rate": 3.1912496114392295e-06,
      "loss": 0.3749,
      "step": 17523
    },
    {
      "epoch": 1.3618277898663351,
      "grad_norm": 0.15232722461223602,
      "learning_rate": 3.1908610506683244e-06,
      "loss": 0.0467,
      "step": 17524
    },
    {
      "epoch": 1.361905502020516,
      "grad_norm": 0.6174165606498718,
      "learning_rate": 3.1904724898974202e-06,
      "loss": 0.408,
      "step": 17525
    },
    {
      "epoch": 1.361983214174697,
      "grad_norm": 0.4480074644088745,
      "learning_rate": 3.1900839291265156e-06,
      "loss": 0.0886,
      "step": 17526
    },
    {
      "epoch": 1.3620609263288779,
      "grad_norm": 0.6420558094978333,
      "learning_rate": 3.189695368355611e-06,
      "loss": 0.6334,
      "step": 17527
    },
    {
      "epoch": 1.3621386384830587,
      "grad_norm": 0.06326299160718918,
      "learning_rate": 3.1893068075847068e-06,
      "loss": 0.0088,
      "step": 17528
    },
    {
      "epoch": 1.3622163506372398,
      "grad_norm": 0.1987321525812149,
      "learning_rate": 3.1889182468138017e-06,
      "loss": 0.0804,
      "step": 17529
    },
    {
      "epoch": 1.3622940627914206,
      "grad_norm": 0.4527680277824402,
      "learning_rate": 3.188529686042897e-06,
      "loss": 0.2555,
      "step": 17530
    },
    {
      "epoch": 1.3623717749456015,
      "grad_norm": 0.6548981070518494,
      "learning_rate": 3.188141125271993e-06,
      "loss": 0.2483,
      "step": 17531
    },
    {
      "epoch": 1.3624494870997825,
      "grad_norm": 0.9611808657646179,
      "learning_rate": 3.1877525645010883e-06,
      "loss": 0.4241,
      "step": 17532
    },
    {
      "epoch": 1.3625271992539634,
      "grad_norm": 0.37447988986968994,
      "learning_rate": 3.187364003730183e-06,
      "loss": 0.1081,
      "step": 17533
    },
    {
      "epoch": 1.3626049114081442,
      "grad_norm": 0.30445557832717896,
      "learning_rate": 3.186975442959279e-06,
      "loss": 0.0511,
      "step": 17534
    },
    {
      "epoch": 1.3626826235623253,
      "grad_norm": 0.5358864665031433,
      "learning_rate": 3.1865868821883744e-06,
      "loss": 0.2178,
      "step": 17535
    },
    {
      "epoch": 1.3627603357165061,
      "grad_norm": 0.42573049664497375,
      "learning_rate": 3.18619832141747e-06,
      "loss": 0.3351,
      "step": 17536
    },
    {
      "epoch": 1.362838047870687,
      "grad_norm": 0.2261473387479782,
      "learning_rate": 3.1858097606465655e-06,
      "loss": 0.0578,
      "step": 17537
    },
    {
      "epoch": 1.3629157600248678,
      "grad_norm": 0.7532678842544556,
      "learning_rate": 3.1854211998756605e-06,
      "loss": 0.092,
      "step": 17538
    },
    {
      "epoch": 1.3629934721790489,
      "grad_norm": 0.6865310072898865,
      "learning_rate": 3.1850326391047563e-06,
      "loss": 0.224,
      "step": 17539
    },
    {
      "epoch": 1.3630711843332297,
      "grad_norm": 0.5765166878700256,
      "learning_rate": 3.1846440783338517e-06,
      "loss": 0.2387,
      "step": 17540
    },
    {
      "epoch": 1.3631488964874106,
      "grad_norm": 0.7021477222442627,
      "learning_rate": 3.184255517562947e-06,
      "loss": 0.4307,
      "step": 17541
    },
    {
      "epoch": 1.3632266086415916,
      "grad_norm": 0.41287699341773987,
      "learning_rate": 3.183866956792043e-06,
      "loss": 0.139,
      "step": 17542
    },
    {
      "epoch": 1.3633043207957725,
      "grad_norm": 0.4615499973297119,
      "learning_rate": 3.1834783960211378e-06,
      "loss": 0.2564,
      "step": 17543
    },
    {
      "epoch": 1.3633820329499533,
      "grad_norm": 0.5205059051513672,
      "learning_rate": 3.183089835250233e-06,
      "loss": 0.2311,
      "step": 17544
    },
    {
      "epoch": 1.3634597451041344,
      "grad_norm": 0.4553547501564026,
      "learning_rate": 3.182701274479329e-06,
      "loss": 0.2297,
      "step": 17545
    },
    {
      "epoch": 1.3635374572583152,
      "grad_norm": 0.46060478687286377,
      "learning_rate": 3.1823127137084243e-06,
      "loss": 0.0344,
      "step": 17546
    },
    {
      "epoch": 1.363615169412496,
      "grad_norm": 0.9106272459030151,
      "learning_rate": 3.1819241529375193e-06,
      "loss": 0.3527,
      "step": 17547
    },
    {
      "epoch": 1.363692881566677,
      "grad_norm": 0.5446528792381287,
      "learning_rate": 3.181535592166615e-06,
      "loss": 0.4485,
      "step": 17548
    },
    {
      "epoch": 1.363770593720858,
      "grad_norm": 0.4145370125770569,
      "learning_rate": 3.1811470313957105e-06,
      "loss": 0.1713,
      "step": 17549
    },
    {
      "epoch": 1.3638483058750388,
      "grad_norm": 0.16921940445899963,
      "learning_rate": 3.1807584706248062e-06,
      "loss": 0.0473,
      "step": 17550
    },
    {
      "epoch": 1.3639260180292196,
      "grad_norm": 0.5870689153671265,
      "learning_rate": 3.1803699098539016e-06,
      "loss": 0.1174,
      "step": 17551
    },
    {
      "epoch": 1.3640037301834007,
      "grad_norm": 0.9706511497497559,
      "learning_rate": 3.1799813490829966e-06,
      "loss": 0.3598,
      "step": 17552
    },
    {
      "epoch": 1.3640814423375816,
      "grad_norm": 0.2910521924495697,
      "learning_rate": 3.1795927883120924e-06,
      "loss": 0.1057,
      "step": 17553
    },
    {
      "epoch": 1.3641591544917624,
      "grad_norm": 1.022608995437622,
      "learning_rate": 3.1792042275411877e-06,
      "loss": 0.3454,
      "step": 17554
    },
    {
      "epoch": 1.3642368666459435,
      "grad_norm": 0.10549761354923248,
      "learning_rate": 3.178815666770283e-06,
      "loss": 0.0137,
      "step": 17555
    },
    {
      "epoch": 1.3643145788001243,
      "grad_norm": 0.4587847888469696,
      "learning_rate": 3.178427105999379e-06,
      "loss": 0.1581,
      "step": 17556
    },
    {
      "epoch": 1.3643922909543051,
      "grad_norm": 0.21915927529335022,
      "learning_rate": 3.178038545228474e-06,
      "loss": 0.0555,
      "step": 17557
    },
    {
      "epoch": 1.3644700031084862,
      "grad_norm": 0.2135743945837021,
      "learning_rate": 3.1776499844575692e-06,
      "loss": 0.0337,
      "step": 17558
    },
    {
      "epoch": 1.364547715262667,
      "grad_norm": 0.5599758625030518,
      "learning_rate": 3.177261423686665e-06,
      "loss": 0.2709,
      "step": 17559
    },
    {
      "epoch": 1.364625427416848,
      "grad_norm": 0.8069887757301331,
      "learning_rate": 3.1768728629157604e-06,
      "loss": 0.3408,
      "step": 17560
    },
    {
      "epoch": 1.364703139571029,
      "grad_norm": 1.021843671798706,
      "learning_rate": 3.1764843021448554e-06,
      "loss": 0.2122,
      "step": 17561
    },
    {
      "epoch": 1.3647808517252098,
      "grad_norm": 0.3019593358039856,
      "learning_rate": 3.176095741373951e-06,
      "loss": 0.0427,
      "step": 17562
    },
    {
      "epoch": 1.3648585638793906,
      "grad_norm": 0.4133765399456024,
      "learning_rate": 3.1757071806030465e-06,
      "loss": 0.0992,
      "step": 17563
    },
    {
      "epoch": 1.3649362760335717,
      "grad_norm": 0.4114156663417816,
      "learning_rate": 3.175318619832142e-06,
      "loss": 0.0302,
      "step": 17564
    },
    {
      "epoch": 1.3650139881877525,
      "grad_norm": 0.3792959451675415,
      "learning_rate": 3.1749300590612377e-06,
      "loss": 0.0809,
      "step": 17565
    },
    {
      "epoch": 1.3650917003419334,
      "grad_norm": 0.42901483178138733,
      "learning_rate": 3.1745414982903326e-06,
      "loss": 0.1731,
      "step": 17566
    },
    {
      "epoch": 1.3651694124961145,
      "grad_norm": 0.43346479535102844,
      "learning_rate": 3.1741529375194284e-06,
      "loss": 0.5216,
      "step": 17567
    },
    {
      "epoch": 1.3652471246502953,
      "grad_norm": 0.24990183115005493,
      "learning_rate": 3.173764376748524e-06,
      "loss": 0.0532,
      "step": 17568
    },
    {
      "epoch": 1.3653248368044761,
      "grad_norm": 0.3234160542488098,
      "learning_rate": 3.173375815977619e-06,
      "loss": 0.0737,
      "step": 17569
    },
    {
      "epoch": 1.3654025489586572,
      "grad_norm": 0.33044108748435974,
      "learning_rate": 3.172987255206715e-06,
      "loss": 0.1134,
      "step": 17570
    },
    {
      "epoch": 1.365480261112838,
      "grad_norm": 0.410048246383667,
      "learning_rate": 3.17259869443581e-06,
      "loss": 0.0764,
      "step": 17571
    },
    {
      "epoch": 1.3655579732670189,
      "grad_norm": 0.36551815271377563,
      "learning_rate": 3.1722101336649053e-06,
      "loss": 0.216,
      "step": 17572
    },
    {
      "epoch": 1.3656356854212,
      "grad_norm": 0.2225208282470703,
      "learning_rate": 3.171821572894001e-06,
      "loss": 0.0736,
      "step": 17573
    },
    {
      "epoch": 1.3657133975753808,
      "grad_norm": 0.2360069751739502,
      "learning_rate": 3.1714330121230965e-06,
      "loss": 0.0289,
      "step": 17574
    },
    {
      "epoch": 1.3657911097295616,
      "grad_norm": 0.05349080264568329,
      "learning_rate": 3.1710444513521914e-06,
      "loss": 0.0113,
      "step": 17575
    },
    {
      "epoch": 1.3658688218837427,
      "grad_norm": 0.1620538979768753,
      "learning_rate": 3.1706558905812872e-06,
      "loss": 0.0495,
      "step": 17576
    },
    {
      "epoch": 1.3659465340379235,
      "grad_norm": 0.3454408347606659,
      "learning_rate": 3.1702673298103826e-06,
      "loss": 0.0981,
      "step": 17577
    },
    {
      "epoch": 1.3660242461921044,
      "grad_norm": 1.2322559356689453,
      "learning_rate": 3.169878769039478e-06,
      "loss": 0.1225,
      "step": 17578
    },
    {
      "epoch": 1.3661019583462854,
      "grad_norm": 0.37644919753074646,
      "learning_rate": 3.1694902082685738e-06,
      "loss": 0.1705,
      "step": 17579
    },
    {
      "epoch": 1.3661796705004663,
      "grad_norm": 0.6027153730392456,
      "learning_rate": 3.1691016474976687e-06,
      "loss": 0.1459,
      "step": 17580
    },
    {
      "epoch": 1.3662573826546471,
      "grad_norm": 0.3264842629432678,
      "learning_rate": 3.1687130867267645e-06,
      "loss": 0.1196,
      "step": 17581
    },
    {
      "epoch": 1.3663350948088282,
      "grad_norm": 1.7931169271469116,
      "learning_rate": 3.16832452595586e-06,
      "loss": 0.4277,
      "step": 17582
    },
    {
      "epoch": 1.366412806963009,
      "grad_norm": 0.15933728218078613,
      "learning_rate": 3.1679359651849553e-06,
      "loss": 0.0253,
      "step": 17583
    },
    {
      "epoch": 1.3664905191171899,
      "grad_norm": 0.3414944112300873,
      "learning_rate": 3.1675474044140506e-06,
      "loss": 0.0553,
      "step": 17584
    },
    {
      "epoch": 1.366568231271371,
      "grad_norm": 0.8503850698471069,
      "learning_rate": 3.167158843643146e-06,
      "loss": 0.1038,
      "step": 17585
    },
    {
      "epoch": 1.3666459434255518,
      "grad_norm": 1.80307137966156,
      "learning_rate": 3.1667702828722414e-06,
      "loss": 0.504,
      "step": 17586
    },
    {
      "epoch": 1.3667236555797326,
      "grad_norm": 0.12758460640907288,
      "learning_rate": 3.166381722101337e-06,
      "loss": 0.0166,
      "step": 17587
    },
    {
      "epoch": 1.3668013677339137,
      "grad_norm": 0.7651334404945374,
      "learning_rate": 3.165993161330432e-06,
      "loss": 0.3052,
      "step": 17588
    },
    {
      "epoch": 1.3668790798880945,
      "grad_norm": 0.45947566628456116,
      "learning_rate": 3.1656046005595275e-06,
      "loss": 0.2806,
      "step": 17589
    },
    {
      "epoch": 1.3669567920422754,
      "grad_norm": 0.48018142580986023,
      "learning_rate": 3.1652160397886233e-06,
      "loss": 0.5852,
      "step": 17590
    },
    {
      "epoch": 1.3670345041964564,
      "grad_norm": 0.7806193828582764,
      "learning_rate": 3.1648274790177187e-06,
      "loss": 0.2024,
      "step": 17591
    },
    {
      "epoch": 1.3671122163506373,
      "grad_norm": 1.0062121152877808,
      "learning_rate": 3.1644389182468136e-06,
      "loss": 0.3829,
      "step": 17592
    },
    {
      "epoch": 1.3671899285048181,
      "grad_norm": 0.23635846376419067,
      "learning_rate": 3.1640503574759094e-06,
      "loss": 0.1688,
      "step": 17593
    },
    {
      "epoch": 1.3672676406589992,
      "grad_norm": 0.3949984014034271,
      "learning_rate": 3.163661796705005e-06,
      "loss": 0.1227,
      "step": 17594
    },
    {
      "epoch": 1.36734535281318,
      "grad_norm": 1.6278167963027954,
      "learning_rate": 3.1632732359341006e-06,
      "loss": 0.7855,
      "step": 17595
    },
    {
      "epoch": 1.3674230649673609,
      "grad_norm": 0.44185125827789307,
      "learning_rate": 3.162884675163196e-06,
      "loss": 0.1121,
      "step": 17596
    },
    {
      "epoch": 1.367500777121542,
      "grad_norm": 0.6518602967262268,
      "learning_rate": 3.162496114392291e-06,
      "loss": 0.1177,
      "step": 17597
    },
    {
      "epoch": 1.3675784892757228,
      "grad_norm": 0.6050528883934021,
      "learning_rate": 3.1621075536213867e-06,
      "loss": 0.304,
      "step": 17598
    },
    {
      "epoch": 1.3676562014299036,
      "grad_norm": 1.6063183546066284,
      "learning_rate": 3.161718992850482e-06,
      "loss": 0.8287,
      "step": 17599
    },
    {
      "epoch": 1.3677339135840845,
      "grad_norm": 1.0581382513046265,
      "learning_rate": 3.1613304320795775e-06,
      "loss": 0.4185,
      "step": 17600
    },
    {
      "epoch": 1.3678116257382655,
      "grad_norm": 0.7600545287132263,
      "learning_rate": 3.1609418713086732e-06,
      "loss": 0.2155,
      "step": 17601
    },
    {
      "epoch": 1.3678893378924464,
      "grad_norm": 0.5552482008934021,
      "learning_rate": 3.160553310537768e-06,
      "loss": 0.218,
      "step": 17602
    },
    {
      "epoch": 1.3679670500466272,
      "grad_norm": 0.5750049352645874,
      "learning_rate": 3.1601647497668636e-06,
      "loss": 0.1686,
      "step": 17603
    },
    {
      "epoch": 1.3680447622008083,
      "grad_norm": 0.3867284655570984,
      "learning_rate": 3.1597761889959594e-06,
      "loss": 0.1297,
      "step": 17604
    },
    {
      "epoch": 1.3681224743549891,
      "grad_norm": 0.28210416436195374,
      "learning_rate": 3.1593876282250547e-06,
      "loss": 0.1144,
      "step": 17605
    },
    {
      "epoch": 1.36820018650917,
      "grad_norm": 1.5993776321411133,
      "learning_rate": 3.1589990674541497e-06,
      "loss": 0.1441,
      "step": 17606
    },
    {
      "epoch": 1.3682778986633508,
      "grad_norm": 0.7761923670768738,
      "learning_rate": 3.1586105066832455e-06,
      "loss": 0.2145,
      "step": 17607
    },
    {
      "epoch": 1.3683556108175319,
      "grad_norm": 0.5646780729293823,
      "learning_rate": 3.158221945912341e-06,
      "loss": 0.1881,
      "step": 17608
    },
    {
      "epoch": 1.3684333229717127,
      "grad_norm": 1.8154133558273315,
      "learning_rate": 3.1578333851414362e-06,
      "loss": 0.262,
      "step": 17609
    },
    {
      "epoch": 1.3685110351258936,
      "grad_norm": 0.8561258912086487,
      "learning_rate": 3.157444824370532e-06,
      "loss": 0.3917,
      "step": 17610
    },
    {
      "epoch": 1.3685887472800746,
      "grad_norm": 0.5397606492042542,
      "learning_rate": 3.157056263599627e-06,
      "loss": 0.1365,
      "step": 17611
    },
    {
      "epoch": 1.3686664594342555,
      "grad_norm": 0.4707415997982025,
      "learning_rate": 3.1566677028287228e-06,
      "loss": 0.1547,
      "step": 17612
    },
    {
      "epoch": 1.3687441715884363,
      "grad_norm": 0.164085254073143,
      "learning_rate": 3.156279142057818e-06,
      "loss": 0.0132,
      "step": 17613
    },
    {
      "epoch": 1.3688218837426174,
      "grad_norm": 0.8360099196434021,
      "learning_rate": 3.1558905812869135e-06,
      "loss": 0.35,
      "step": 17614
    },
    {
      "epoch": 1.3688995958967982,
      "grad_norm": 0.6884249448776245,
      "learning_rate": 3.1555020205160093e-06,
      "loss": 0.204,
      "step": 17615
    },
    {
      "epoch": 1.368977308050979,
      "grad_norm": 0.1566837579011917,
      "learning_rate": 3.1551134597451043e-06,
      "loss": 0.0412,
      "step": 17616
    },
    {
      "epoch": 1.3690550202051601,
      "grad_norm": 0.588595986366272,
      "learning_rate": 3.1547248989741996e-06,
      "loss": 0.1535,
      "step": 17617
    },
    {
      "epoch": 1.369132732359341,
      "grad_norm": 0.18557479977607727,
      "learning_rate": 3.1543363382032954e-06,
      "loss": 0.0297,
      "step": 17618
    },
    {
      "epoch": 1.3692104445135218,
      "grad_norm": 0.11856292188167572,
      "learning_rate": 3.153947777432391e-06,
      "loss": 0.0156,
      "step": 17619
    },
    {
      "epoch": 1.3692881566677029,
      "grad_norm": 1.048836350440979,
      "learning_rate": 3.1535592166614858e-06,
      "loss": 0.1294,
      "step": 17620
    },
    {
      "epoch": 1.3693658688218837,
      "grad_norm": 0.5280758142471313,
      "learning_rate": 3.1531706558905816e-06,
      "loss": 0.1404,
      "step": 17621
    },
    {
      "epoch": 1.3694435809760646,
      "grad_norm": 0.747271716594696,
      "learning_rate": 3.152782095119677e-06,
      "loss": 0.1679,
      "step": 17622
    },
    {
      "epoch": 1.3695212931302456,
      "grad_norm": 0.5128760933876038,
      "learning_rate": 3.1523935343487723e-06,
      "loss": 0.2878,
      "step": 17623
    },
    {
      "epoch": 1.3695990052844265,
      "grad_norm": 0.5312418341636658,
      "learning_rate": 3.152004973577868e-06,
      "loss": 0.1976,
      "step": 17624
    },
    {
      "epoch": 1.3696767174386073,
      "grad_norm": 0.4149421155452728,
      "learning_rate": 3.151616412806963e-06,
      "loss": 0.1665,
      "step": 17625
    },
    {
      "epoch": 1.3697544295927884,
      "grad_norm": 0.5011897087097168,
      "learning_rate": 3.151227852036059e-06,
      "loss": 0.1379,
      "step": 17626
    },
    {
      "epoch": 1.3698321417469692,
      "grad_norm": 1.7251485586166382,
      "learning_rate": 3.1508392912651542e-06,
      "loss": 1.0738,
      "step": 17627
    },
    {
      "epoch": 1.36990985390115,
      "grad_norm": 0.14283394813537598,
      "learning_rate": 3.1504507304942496e-06,
      "loss": 0.0589,
      "step": 17628
    },
    {
      "epoch": 1.3699875660553311,
      "grad_norm": 0.012921817600727081,
      "learning_rate": 3.1500621697233454e-06,
      "loss": 0.0007,
      "step": 17629
    },
    {
      "epoch": 1.370065278209512,
      "grad_norm": 0.574276864528656,
      "learning_rate": 3.1496736089524403e-06,
      "loss": 0.1321,
      "step": 17630
    },
    {
      "epoch": 1.3701429903636928,
      "grad_norm": 0.2078789621591568,
      "learning_rate": 3.1492850481815357e-06,
      "loss": 0.0233,
      "step": 17631
    },
    {
      "epoch": 1.3702207025178739,
      "grad_norm": 0.34682154655456543,
      "learning_rate": 3.1488964874106315e-06,
      "loss": 0.1231,
      "step": 17632
    },
    {
      "epoch": 1.3702984146720547,
      "grad_norm": 0.27701908349990845,
      "learning_rate": 3.148507926639727e-06,
      "loss": 0.0889,
      "step": 17633
    },
    {
      "epoch": 1.3703761268262356,
      "grad_norm": 0.5137583017349243,
      "learning_rate": 3.148119365868822e-06,
      "loss": 0.2652,
      "step": 17634
    },
    {
      "epoch": 1.3704538389804166,
      "grad_norm": 0.12330308556556702,
      "learning_rate": 3.1477308050979176e-06,
      "loss": 0.0573,
      "step": 17635
    },
    {
      "epoch": 1.3705315511345975,
      "grad_norm": 0.39372262358665466,
      "learning_rate": 3.147342244327013e-06,
      "loss": 0.0321,
      "step": 17636
    },
    {
      "epoch": 1.3706092632887783,
      "grad_norm": 0.49482154846191406,
      "learning_rate": 3.1469536835561084e-06,
      "loss": 0.2503,
      "step": 17637
    },
    {
      "epoch": 1.3706869754429594,
      "grad_norm": 0.22467772662639618,
      "learning_rate": 3.146565122785204e-06,
      "loss": 0.0329,
      "step": 17638
    },
    {
      "epoch": 1.3707646875971402,
      "grad_norm": 0.3026247024536133,
      "learning_rate": 3.146176562014299e-06,
      "loss": 0.0576,
      "step": 17639
    },
    {
      "epoch": 1.370842399751321,
      "grad_norm": 0.8434218764305115,
      "learning_rate": 3.1457880012433945e-06,
      "loss": 0.4798,
      "step": 17640
    },
    {
      "epoch": 1.3709201119055021,
      "grad_norm": 0.3236078917980194,
      "learning_rate": 3.1453994404724903e-06,
      "loss": 0.1208,
      "step": 17641
    },
    {
      "epoch": 1.370997824059683,
      "grad_norm": 0.38392174243927,
      "learning_rate": 3.1450108797015857e-06,
      "loss": 0.0391,
      "step": 17642
    },
    {
      "epoch": 1.3710755362138638,
      "grad_norm": 0.4720258116722107,
      "learning_rate": 3.1446223189306815e-06,
      "loss": 0.2338,
      "step": 17643
    },
    {
      "epoch": 1.3711532483680449,
      "grad_norm": 0.17975011467933655,
      "learning_rate": 3.1442337581597764e-06,
      "loss": 0.0372,
      "step": 17644
    },
    {
      "epoch": 1.3712309605222257,
      "grad_norm": 0.5144373178482056,
      "learning_rate": 3.143845197388872e-06,
      "loss": 0.128,
      "step": 17645
    },
    {
      "epoch": 1.3713086726764065,
      "grad_norm": 0.36304253339767456,
      "learning_rate": 3.1434566366179676e-06,
      "loss": 0.0486,
      "step": 17646
    },
    {
      "epoch": 1.3713863848305876,
      "grad_norm": 0.446055144071579,
      "learning_rate": 3.1430680758470625e-06,
      "loss": 0.0996,
      "step": 17647
    },
    {
      "epoch": 1.3714640969847685,
      "grad_norm": 0.5479896664619446,
      "learning_rate": 3.142679515076158e-06,
      "loss": 0.1594,
      "step": 17648
    },
    {
      "epoch": 1.3715418091389493,
      "grad_norm": 0.7494809627532959,
      "learning_rate": 3.1422909543052537e-06,
      "loss": 0.1173,
      "step": 17649
    },
    {
      "epoch": 1.3716195212931304,
      "grad_norm": 0.7912878394126892,
      "learning_rate": 3.141902393534349e-06,
      "loss": 0.4434,
      "step": 17650
    },
    {
      "epoch": 1.3716972334473112,
      "grad_norm": 0.9205114841461182,
      "learning_rate": 3.141513832763444e-06,
      "loss": 0.1657,
      "step": 17651
    },
    {
      "epoch": 1.371774945601492,
      "grad_norm": 0.24711942672729492,
      "learning_rate": 3.14112527199254e-06,
      "loss": 0.0731,
      "step": 17652
    },
    {
      "epoch": 1.371852657755673,
      "grad_norm": 0.5796021223068237,
      "learning_rate": 3.140736711221635e-06,
      "loss": 0.2065,
      "step": 17653
    },
    {
      "epoch": 1.371930369909854,
      "grad_norm": 0.17612193524837494,
      "learning_rate": 3.1403481504507306e-06,
      "loss": 0.0419,
      "step": 17654
    },
    {
      "epoch": 1.3720080820640348,
      "grad_norm": 0.8182016015052795,
      "learning_rate": 3.1399595896798264e-06,
      "loss": 0.5974,
      "step": 17655
    },
    {
      "epoch": 1.3720857942182159,
      "grad_norm": 0.2626000642776489,
      "learning_rate": 3.1395710289089213e-06,
      "loss": 0.1671,
      "step": 17656
    },
    {
      "epoch": 1.3721635063723967,
      "grad_norm": 0.4251094460487366,
      "learning_rate": 3.139182468138017e-06,
      "loss": 0.0669,
      "step": 17657
    },
    {
      "epoch": 1.3722412185265775,
      "grad_norm": 0.8882678747177124,
      "learning_rate": 3.1387939073671125e-06,
      "loss": 0.4825,
      "step": 17658
    },
    {
      "epoch": 1.3723189306807586,
      "grad_norm": 0.7104638814926147,
      "learning_rate": 3.138405346596208e-06,
      "loss": 0.0921,
      "step": 17659
    },
    {
      "epoch": 1.3723966428349395,
      "grad_norm": 0.539019763469696,
      "learning_rate": 3.1380167858253037e-06,
      "loss": 0.2451,
      "step": 17660
    },
    {
      "epoch": 1.3724743549891203,
      "grad_norm": 0.8219770193099976,
      "learning_rate": 3.1376282250543986e-06,
      "loss": 0.2725,
      "step": 17661
    },
    {
      "epoch": 1.3725520671433011,
      "grad_norm": 0.11759188771247864,
      "learning_rate": 3.137239664283494e-06,
      "loss": 0.0507,
      "step": 17662
    },
    {
      "epoch": 1.3726297792974822,
      "grad_norm": 0.22666236758232117,
      "learning_rate": 3.1368511035125898e-06,
      "loss": 0.0659,
      "step": 17663
    },
    {
      "epoch": 1.372707491451663,
      "grad_norm": 0.3451274037361145,
      "learning_rate": 3.136462542741685e-06,
      "loss": 0.0728,
      "step": 17664
    },
    {
      "epoch": 1.3727852036058439,
      "grad_norm": 0.035024065524339676,
      "learning_rate": 3.13607398197078e-06,
      "loss": 0.0038,
      "step": 17665
    },
    {
      "epoch": 1.372862915760025,
      "grad_norm": 0.45773908495903015,
      "learning_rate": 3.135685421199876e-06,
      "loss": 0.2173,
      "step": 17666
    },
    {
      "epoch": 1.3729406279142058,
      "grad_norm": 0.5728700757026672,
      "learning_rate": 3.1352968604289713e-06,
      "loss": 0.0479,
      "step": 17667
    },
    {
      "epoch": 1.3730183400683866,
      "grad_norm": 0.4105454981327057,
      "learning_rate": 3.1349082996580666e-06,
      "loss": 0.7603,
      "step": 17668
    },
    {
      "epoch": 1.3730960522225675,
      "grad_norm": 0.14553865790367126,
      "learning_rate": 3.1345197388871624e-06,
      "loss": 0.0161,
      "step": 17669
    },
    {
      "epoch": 1.3731737643767485,
      "grad_norm": 0.6038981676101685,
      "learning_rate": 3.1341311781162574e-06,
      "loss": 0.0564,
      "step": 17670
    },
    {
      "epoch": 1.3732514765309294,
      "grad_norm": 0.23447178304195404,
      "learning_rate": 3.133742617345353e-06,
      "loss": 0.0504,
      "step": 17671
    },
    {
      "epoch": 1.3733291886851102,
      "grad_norm": 0.366610586643219,
      "learning_rate": 3.1333540565744486e-06,
      "loss": 0.0925,
      "step": 17672
    },
    {
      "epoch": 1.3734069008392913,
      "grad_norm": 1.313686728477478,
      "learning_rate": 3.132965495803544e-06,
      "loss": 0.1963,
      "step": 17673
    },
    {
      "epoch": 1.3734846129934721,
      "grad_norm": 1.3173290491104126,
      "learning_rate": 3.1325769350326397e-06,
      "loss": 0.4073,
      "step": 17674
    },
    {
      "epoch": 1.373562325147653,
      "grad_norm": 0.3965320885181427,
      "learning_rate": 3.1321883742617347e-06,
      "loss": 0.1045,
      "step": 17675
    },
    {
      "epoch": 1.373640037301834,
      "grad_norm": 0.6055499315261841,
      "learning_rate": 3.13179981349083e-06,
      "loss": 0.2271,
      "step": 17676
    },
    {
      "epoch": 1.3737177494560149,
      "grad_norm": 0.4608314335346222,
      "learning_rate": 3.131411252719926e-06,
      "loss": 0.2286,
      "step": 17677
    },
    {
      "epoch": 1.3737954616101957,
      "grad_norm": 0.788953959941864,
      "learning_rate": 3.1310226919490212e-06,
      "loss": 0.2903,
      "step": 17678
    },
    {
      "epoch": 1.3738731737643768,
      "grad_norm": 0.9280715584754944,
      "learning_rate": 3.130634131178116e-06,
      "loss": 0.4325,
      "step": 17679
    },
    {
      "epoch": 1.3739508859185576,
      "grad_norm": 0.5605387687683105,
      "learning_rate": 3.130245570407212e-06,
      "loss": 0.518,
      "step": 17680
    },
    {
      "epoch": 1.3740285980727385,
      "grad_norm": 0.29957398772239685,
      "learning_rate": 3.1298570096363073e-06,
      "loss": 0.1204,
      "step": 17681
    },
    {
      "epoch": 1.3741063102269195,
      "grad_norm": 0.2832735776901245,
      "learning_rate": 3.1294684488654027e-06,
      "loss": 0.1023,
      "step": 17682
    },
    {
      "epoch": 1.3741840223811004,
      "grad_norm": 0.16980120539665222,
      "learning_rate": 3.1290798880944985e-06,
      "loss": 0.0476,
      "step": 17683
    },
    {
      "epoch": 1.3742617345352812,
      "grad_norm": 0.6360021829605103,
      "learning_rate": 3.1286913273235935e-06,
      "loss": 0.227,
      "step": 17684
    },
    {
      "epoch": 1.3743394466894623,
      "grad_norm": 0.4620842933654785,
      "learning_rate": 3.128302766552689e-06,
      "loss": 0.1575,
      "step": 17685
    },
    {
      "epoch": 1.3744171588436431,
      "grad_norm": 2.0781853199005127,
      "learning_rate": 3.1279142057817846e-06,
      "loss": 0.3276,
      "step": 17686
    },
    {
      "epoch": 1.374494870997824,
      "grad_norm": 0.3370606005191803,
      "learning_rate": 3.12752564501088e-06,
      "loss": 0.0453,
      "step": 17687
    },
    {
      "epoch": 1.374572583152005,
      "grad_norm": 0.7321478128433228,
      "learning_rate": 3.127137084239976e-06,
      "loss": 0.8873,
      "step": 17688
    },
    {
      "epoch": 1.3746502953061859,
      "grad_norm": 0.46612364053726196,
      "learning_rate": 3.1267485234690708e-06,
      "loss": 0.0689,
      "step": 17689
    },
    {
      "epoch": 1.3747280074603667,
      "grad_norm": 0.5539593696594238,
      "learning_rate": 3.126359962698166e-06,
      "loss": 0.1361,
      "step": 17690
    },
    {
      "epoch": 1.3748057196145478,
      "grad_norm": 0.4958711862564087,
      "learning_rate": 3.125971401927262e-06,
      "loss": 0.0784,
      "step": 17691
    },
    {
      "epoch": 1.3748834317687286,
      "grad_norm": 0.9565982222557068,
      "learning_rate": 3.1255828411563573e-06,
      "loss": 0.3914,
      "step": 17692
    },
    {
      "epoch": 1.3749611439229095,
      "grad_norm": 0.6823838949203491,
      "learning_rate": 3.1251942803854523e-06,
      "loss": 0.3443,
      "step": 17693
    },
    {
      "epoch": 1.3750388560770905,
      "grad_norm": 0.5341809988021851,
      "learning_rate": 3.124805719614548e-06,
      "loss": 0.3288,
      "step": 17694
    },
    {
      "epoch": 1.3751165682312714,
      "grad_norm": 0.37136310338974,
      "learning_rate": 3.1244171588436434e-06,
      "loss": 0.1127,
      "step": 17695
    },
    {
      "epoch": 1.3751942803854522,
      "grad_norm": 0.2855953574180603,
      "learning_rate": 3.124028598072739e-06,
      "loss": 0.04,
      "step": 17696
    },
    {
      "epoch": 1.3752719925396333,
      "grad_norm": 0.8750301599502563,
      "learning_rate": 3.1236400373018346e-06,
      "loss": 0.1494,
      "step": 17697
    },
    {
      "epoch": 1.3753497046938141,
      "grad_norm": 0.6921635270118713,
      "learning_rate": 3.1232514765309295e-06,
      "loss": 0.3261,
      "step": 17698
    },
    {
      "epoch": 1.375427416847995,
      "grad_norm": 0.4280672073364258,
      "learning_rate": 3.122862915760025e-06,
      "loss": 0.12,
      "step": 17699
    },
    {
      "epoch": 1.375505129002176,
      "grad_norm": 0.35794129967689514,
      "learning_rate": 3.1224743549891207e-06,
      "loss": 0.1766,
      "step": 17700
    },
    {
      "epoch": 1.3755828411563569,
      "grad_norm": 0.3068448007106781,
      "learning_rate": 3.122085794218216e-06,
      "loss": 0.2223,
      "step": 17701
    },
    {
      "epoch": 1.3756605533105377,
      "grad_norm": 0.31288760900497437,
      "learning_rate": 3.121697233447312e-06,
      "loss": 0.0573,
      "step": 17702
    },
    {
      "epoch": 1.3757382654647188,
      "grad_norm": 0.962448000907898,
      "learning_rate": 3.121308672676407e-06,
      "loss": 0.2994,
      "step": 17703
    },
    {
      "epoch": 1.3758159776188996,
      "grad_norm": 0.9126975536346436,
      "learning_rate": 3.120920111905502e-06,
      "loss": 0.3373,
      "step": 17704
    },
    {
      "epoch": 1.3758936897730805,
      "grad_norm": 1.0563234090805054,
      "learning_rate": 3.120531551134598e-06,
      "loss": 0.4307,
      "step": 17705
    },
    {
      "epoch": 1.3759714019272615,
      "grad_norm": 0.21570953726768494,
      "learning_rate": 3.1201429903636934e-06,
      "loss": 0.0709,
      "step": 17706
    },
    {
      "epoch": 1.3760491140814424,
      "grad_norm": 0.7420740723609924,
      "learning_rate": 3.1197544295927883e-06,
      "loss": 0.1798,
      "step": 17707
    },
    {
      "epoch": 1.3761268262356232,
      "grad_norm": 0.29410192370414734,
      "learning_rate": 3.119365868821884e-06,
      "loss": 0.0463,
      "step": 17708
    },
    {
      "epoch": 1.3762045383898043,
      "grad_norm": 0.19579677283763885,
      "learning_rate": 3.1189773080509795e-06,
      "loss": 0.0251,
      "step": 17709
    },
    {
      "epoch": 1.3762822505439851,
      "grad_norm": 0.7090964913368225,
      "learning_rate": 3.118588747280075e-06,
      "loss": 0.1567,
      "step": 17710
    },
    {
      "epoch": 1.376359962698166,
      "grad_norm": 0.9641480445861816,
      "learning_rate": 3.1182001865091702e-06,
      "loss": 0.5118,
      "step": 17711
    },
    {
      "epoch": 1.376437674852347,
      "grad_norm": 0.1798735409975052,
      "learning_rate": 3.1178116257382656e-06,
      "loss": 0.0473,
      "step": 17712
    },
    {
      "epoch": 1.3765153870065279,
      "grad_norm": 0.27552106976509094,
      "learning_rate": 3.117423064967361e-06,
      "loss": 0.052,
      "step": 17713
    },
    {
      "epoch": 1.3765930991607087,
      "grad_norm": 0.11573156714439392,
      "learning_rate": 3.1170345041964568e-06,
      "loss": 0.0147,
      "step": 17714
    },
    {
      "epoch": 1.3766708113148898,
      "grad_norm": 0.212584987282753,
      "learning_rate": 3.1166459434255517e-06,
      "loss": 0.0522,
      "step": 17715
    },
    {
      "epoch": 1.3767485234690706,
      "grad_norm": 0.2769908905029297,
      "learning_rate": 3.116257382654647e-06,
      "loss": 0.0968,
      "step": 17716
    },
    {
      "epoch": 1.3768262356232515,
      "grad_norm": 0.4458602964878082,
      "learning_rate": 3.115868821883743e-06,
      "loss": 0.3123,
      "step": 17717
    },
    {
      "epoch": 1.3769039477774325,
      "grad_norm": 0.8536044359207153,
      "learning_rate": 3.1154802611128383e-06,
      "loss": 0.3919,
      "step": 17718
    },
    {
      "epoch": 1.3769816599316134,
      "grad_norm": 1.2971280813217163,
      "learning_rate": 3.115091700341934e-06,
      "loss": 0.1244,
      "step": 17719
    },
    {
      "epoch": 1.3770593720857942,
      "grad_norm": 0.11186502128839493,
      "learning_rate": 3.114703139571029e-06,
      "loss": 0.0102,
      "step": 17720
    },
    {
      "epoch": 1.377137084239975,
      "grad_norm": 0.43531474471092224,
      "learning_rate": 3.1143145788001244e-06,
      "loss": 0.2647,
      "step": 17721
    },
    {
      "epoch": 1.3772147963941561,
      "grad_norm": 0.8256705403327942,
      "learning_rate": 3.11392601802922e-06,
      "loss": 0.224,
      "step": 17722
    },
    {
      "epoch": 1.377292508548337,
      "grad_norm": 0.8765354752540588,
      "learning_rate": 3.1135374572583156e-06,
      "loss": 0.359,
      "step": 17723
    },
    {
      "epoch": 1.3773702207025178,
      "grad_norm": 0.5900105237960815,
      "learning_rate": 3.1131488964874105e-06,
      "loss": 0.4215,
      "step": 17724
    },
    {
      "epoch": 1.3774479328566989,
      "grad_norm": 0.18941570818424225,
      "learning_rate": 3.1127603357165063e-06,
      "loss": 0.0546,
      "step": 17725
    },
    {
      "epoch": 1.3775256450108797,
      "grad_norm": 0.4786391258239746,
      "learning_rate": 3.1123717749456017e-06,
      "loss": 0.1878,
      "step": 17726
    },
    {
      "epoch": 1.3776033571650605,
      "grad_norm": 0.8149970173835754,
      "learning_rate": 3.111983214174697e-06,
      "loss": 0.3123,
      "step": 17727
    },
    {
      "epoch": 1.3776810693192414,
      "grad_norm": 1.0966302156448364,
      "learning_rate": 3.111594653403793e-06,
      "loss": 0.2178,
      "step": 17728
    },
    {
      "epoch": 1.3777587814734225,
      "grad_norm": 0.10507828742265701,
      "learning_rate": 3.111206092632888e-06,
      "loss": 0.0266,
      "step": 17729
    },
    {
      "epoch": 1.3778364936276033,
      "grad_norm": 0.8095917701721191,
      "learning_rate": 3.110817531861983e-06,
      "loss": 0.3872,
      "step": 17730
    },
    {
      "epoch": 1.3779142057817841,
      "grad_norm": 0.3059472441673279,
      "learning_rate": 3.110428971091079e-06,
      "loss": 0.2987,
      "step": 17731
    },
    {
      "epoch": 1.3779919179359652,
      "grad_norm": 0.5964221954345703,
      "learning_rate": 3.1100404103201744e-06,
      "loss": 0.1949,
      "step": 17732
    },
    {
      "epoch": 1.378069630090146,
      "grad_norm": 0.8282630443572998,
      "learning_rate": 3.10965184954927e-06,
      "loss": 0.1994,
      "step": 17733
    },
    {
      "epoch": 1.378147342244327,
      "grad_norm": 0.345247358083725,
      "learning_rate": 3.109263288778365e-06,
      "loss": 0.0447,
      "step": 17734
    },
    {
      "epoch": 1.378225054398508,
      "grad_norm": 1.4570188522338867,
      "learning_rate": 3.1088747280074605e-06,
      "loss": 0.3191,
      "step": 17735
    },
    {
      "epoch": 1.3783027665526888,
      "grad_norm": 1.4196721315383911,
      "learning_rate": 3.1084861672365563e-06,
      "loss": 0.5613,
      "step": 17736
    },
    {
      "epoch": 1.3783804787068696,
      "grad_norm": 0.4817144274711609,
      "learning_rate": 3.1080976064656516e-06,
      "loss": 0.5022,
      "step": 17737
    },
    {
      "epoch": 1.3784581908610507,
      "grad_norm": 0.1349266916513443,
      "learning_rate": 3.1077090456947466e-06,
      "loss": 0.037,
      "step": 17738
    },
    {
      "epoch": 1.3785359030152315,
      "grad_norm": 0.8848069906234741,
      "learning_rate": 3.1073204849238424e-06,
      "loss": 0.2108,
      "step": 17739
    },
    {
      "epoch": 1.3786136151694124,
      "grad_norm": 0.0504269041121006,
      "learning_rate": 3.1069319241529378e-06,
      "loss": 0.0168,
      "step": 17740
    },
    {
      "epoch": 1.3786913273235935,
      "grad_norm": 0.6257048845291138,
      "learning_rate": 3.106543363382033e-06,
      "loss": 0.381,
      "step": 17741
    },
    {
      "epoch": 1.3787690394777743,
      "grad_norm": 0.22177943587303162,
      "learning_rate": 3.106154802611129e-06,
      "loss": 0.0419,
      "step": 17742
    },
    {
      "epoch": 1.3788467516319551,
      "grad_norm": 0.7760800123214722,
      "learning_rate": 3.105766241840224e-06,
      "loss": 0.1682,
      "step": 17743
    },
    {
      "epoch": 1.3789244637861362,
      "grad_norm": 0.1558050811290741,
      "learning_rate": 3.1053776810693193e-06,
      "loss": 0.0207,
      "step": 17744
    },
    {
      "epoch": 1.379002175940317,
      "grad_norm": 0.4390101730823517,
      "learning_rate": 3.104989120298415e-06,
      "loss": 0.1209,
      "step": 17745
    },
    {
      "epoch": 1.3790798880944979,
      "grad_norm": 1.5228278636932373,
      "learning_rate": 3.1046005595275104e-06,
      "loss": 0.3392,
      "step": 17746
    },
    {
      "epoch": 1.379157600248679,
      "grad_norm": 0.9641876816749573,
      "learning_rate": 3.1042119987566062e-06,
      "loss": 0.4114,
      "step": 17747
    },
    {
      "epoch": 1.3792353124028598,
      "grad_norm": 0.5333797335624695,
      "learning_rate": 3.103823437985701e-06,
      "loss": 0.1323,
      "step": 17748
    },
    {
      "epoch": 1.3793130245570406,
      "grad_norm": 0.9446377158164978,
      "learning_rate": 3.1034348772147965e-06,
      "loss": 0.3382,
      "step": 17749
    },
    {
      "epoch": 1.3793907367112217,
      "grad_norm": 0.2992376387119293,
      "learning_rate": 3.1030463164438923e-06,
      "loss": 0.1852,
      "step": 17750
    },
    {
      "epoch": 1.3794684488654025,
      "grad_norm": 0.23577222228050232,
      "learning_rate": 3.1026577556729877e-06,
      "loss": 0.0542,
      "step": 17751
    },
    {
      "epoch": 1.3795461610195834,
      "grad_norm": 0.4553184509277344,
      "learning_rate": 3.1022691949020827e-06,
      "loss": 0.2685,
      "step": 17752
    },
    {
      "epoch": 1.3796238731737644,
      "grad_norm": 0.43065962195396423,
      "learning_rate": 3.1018806341311785e-06,
      "loss": 0.345,
      "step": 17753
    },
    {
      "epoch": 1.3797015853279453,
      "grad_norm": 0.32589665055274963,
      "learning_rate": 3.101492073360274e-06,
      "loss": 0.1507,
      "step": 17754
    },
    {
      "epoch": 1.3797792974821261,
      "grad_norm": 2.456254005432129,
      "learning_rate": 3.101103512589369e-06,
      "loss": 0.3194,
      "step": 17755
    },
    {
      "epoch": 1.3798570096363072,
      "grad_norm": 0.758567750453949,
      "learning_rate": 3.100714951818465e-06,
      "loss": 0.5488,
      "step": 17756
    },
    {
      "epoch": 1.379934721790488,
      "grad_norm": 0.3435373902320862,
      "learning_rate": 3.10032639104756e-06,
      "loss": 0.1235,
      "step": 17757
    },
    {
      "epoch": 1.3800124339446689,
      "grad_norm": 1.5071607828140259,
      "learning_rate": 3.0999378302766553e-06,
      "loss": 0.374,
      "step": 17758
    },
    {
      "epoch": 1.38009014609885,
      "grad_norm": 0.4372505843639374,
      "learning_rate": 3.099549269505751e-06,
      "loss": 0.1423,
      "step": 17759
    },
    {
      "epoch": 1.3801678582530308,
      "grad_norm": 0.3477029800415039,
      "learning_rate": 3.0991607087348465e-06,
      "loss": 0.0359,
      "step": 17760
    },
    {
      "epoch": 1.3802455704072116,
      "grad_norm": 2.5529091358184814,
      "learning_rate": 3.0987721479639414e-06,
      "loss": 0.5305,
      "step": 17761
    },
    {
      "epoch": 1.3803232825613927,
      "grad_norm": 0.13101154565811157,
      "learning_rate": 3.0983835871930372e-06,
      "loss": 0.061,
      "step": 17762
    },
    {
      "epoch": 1.3804009947155735,
      "grad_norm": 0.3155107796192169,
      "learning_rate": 3.0979950264221326e-06,
      "loss": 0.0337,
      "step": 17763
    },
    {
      "epoch": 1.3804787068697544,
      "grad_norm": 0.11358597874641418,
      "learning_rate": 3.0976064656512284e-06,
      "loss": 0.0371,
      "step": 17764
    },
    {
      "epoch": 1.3805564190239354,
      "grad_norm": 0.3968057334423065,
      "learning_rate": 3.0972179048803238e-06,
      "loss": 0.2641,
      "step": 17765
    },
    {
      "epoch": 1.3806341311781163,
      "grad_norm": 0.10770189017057419,
      "learning_rate": 3.0968293441094187e-06,
      "loss": 0.0148,
      "step": 17766
    },
    {
      "epoch": 1.3807118433322971,
      "grad_norm": 0.1821460723876953,
      "learning_rate": 3.0964407833385145e-06,
      "loss": 0.0246,
      "step": 17767
    },
    {
      "epoch": 1.3807895554864782,
      "grad_norm": 0.39434102177619934,
      "learning_rate": 3.09605222256761e-06,
      "loss": 0.0446,
      "step": 17768
    },
    {
      "epoch": 1.380867267640659,
      "grad_norm": 0.6942510604858398,
      "learning_rate": 3.0956636617967053e-06,
      "loss": 0.3044,
      "step": 17769
    },
    {
      "epoch": 1.3809449797948399,
      "grad_norm": 0.5102834701538086,
      "learning_rate": 3.095275101025801e-06,
      "loss": 0.4978,
      "step": 17770
    },
    {
      "epoch": 1.381022691949021,
      "grad_norm": 0.17067144811153412,
      "learning_rate": 3.094886540254896e-06,
      "loss": 0.0643,
      "step": 17771
    },
    {
      "epoch": 1.3811004041032018,
      "grad_norm": 0.5453538298606873,
      "learning_rate": 3.0944979794839914e-06,
      "loss": 0.0404,
      "step": 17772
    },
    {
      "epoch": 1.3811781162573826,
      "grad_norm": 0.4234665334224701,
      "learning_rate": 3.094109418713087e-06,
      "loss": 0.0877,
      "step": 17773
    },
    {
      "epoch": 1.3812558284115637,
      "grad_norm": 0.25549185276031494,
      "learning_rate": 3.093720857942182e-06,
      "loss": 0.1085,
      "step": 17774
    },
    {
      "epoch": 1.3813335405657445,
      "grad_norm": 0.3168947696685791,
      "learning_rate": 3.0933322971712775e-06,
      "loss": 0.2207,
      "step": 17775
    },
    {
      "epoch": 1.3814112527199254,
      "grad_norm": 0.7455312609672546,
      "learning_rate": 3.0929437364003733e-06,
      "loss": 0.2911,
      "step": 17776
    },
    {
      "epoch": 1.3814889648741064,
      "grad_norm": 0.7145853638648987,
      "learning_rate": 3.0925551756294687e-06,
      "loss": 0.2355,
      "step": 17777
    },
    {
      "epoch": 1.3815666770282873,
      "grad_norm": 0.10708378255367279,
      "learning_rate": 3.0921666148585645e-06,
      "loss": 0.0046,
      "step": 17778
    },
    {
      "epoch": 1.3816443891824681,
      "grad_norm": 0.7529550194740295,
      "learning_rate": 3.0917780540876594e-06,
      "loss": 0.1881,
      "step": 17779
    },
    {
      "epoch": 1.3817221013366492,
      "grad_norm": 0.7369290590286255,
      "learning_rate": 3.091389493316755e-06,
      "loss": 0.156,
      "step": 17780
    },
    {
      "epoch": 1.38179981349083,
      "grad_norm": 0.6216925382614136,
      "learning_rate": 3.0910009325458506e-06,
      "loss": 0.5352,
      "step": 17781
    },
    {
      "epoch": 1.3818775256450109,
      "grad_norm": 0.7176289558410645,
      "learning_rate": 3.090612371774946e-06,
      "loss": 0.3167,
      "step": 17782
    },
    {
      "epoch": 1.3819552377991917,
      "grad_norm": 0.2280065268278122,
      "learning_rate": 3.090223811004041e-06,
      "loss": 0.1164,
      "step": 17783
    },
    {
      "epoch": 1.3820329499533728,
      "grad_norm": 0.16902773082256317,
      "learning_rate": 3.0898352502331367e-06,
      "loss": 0.0458,
      "step": 17784
    },
    {
      "epoch": 1.3821106621075536,
      "grad_norm": 0.22276467084884644,
      "learning_rate": 3.089446689462232e-06,
      "loss": 0.0716,
      "step": 17785
    },
    {
      "epoch": 1.3821883742617345,
      "grad_norm": 0.35397765040397644,
      "learning_rate": 3.0890581286913275e-06,
      "loss": 0.0323,
      "step": 17786
    },
    {
      "epoch": 1.3822660864159155,
      "grad_norm": 0.3518577218055725,
      "learning_rate": 3.0886695679204233e-06,
      "loss": 0.0702,
      "step": 17787
    },
    {
      "epoch": 1.3823437985700964,
      "grad_norm": 2.0673327445983887,
      "learning_rate": 3.0882810071495182e-06,
      "loss": 0.2221,
      "step": 17788
    },
    {
      "epoch": 1.3824215107242772,
      "grad_norm": 0.3123890459537506,
      "learning_rate": 3.0878924463786136e-06,
      "loss": 0.0646,
      "step": 17789
    },
    {
      "epoch": 1.382499222878458,
      "grad_norm": 0.3618353605270386,
      "learning_rate": 3.0875038856077094e-06,
      "loss": 0.0457,
      "step": 17790
    },
    {
      "epoch": 1.3825769350326391,
      "grad_norm": 0.5213184356689453,
      "learning_rate": 3.0871153248368048e-06,
      "loss": 0.1851,
      "step": 17791
    },
    {
      "epoch": 1.38265464718682,
      "grad_norm": 0.22387461364269257,
      "learning_rate": 3.0867267640658997e-06,
      "loss": 0.0432,
      "step": 17792
    },
    {
      "epoch": 1.3827323593410008,
      "grad_norm": 0.6015987992286682,
      "learning_rate": 3.0863382032949955e-06,
      "loss": 0.1018,
      "step": 17793
    },
    {
      "epoch": 1.3828100714951819,
      "grad_norm": 0.49057143926620483,
      "learning_rate": 3.085949642524091e-06,
      "loss": 0.1659,
      "step": 17794
    },
    {
      "epoch": 1.3828877836493627,
      "grad_norm": 0.5564212799072266,
      "learning_rate": 3.0855610817531867e-06,
      "loss": 0.2261,
      "step": 17795
    },
    {
      "epoch": 1.3829654958035436,
      "grad_norm": 0.49664607644081116,
      "learning_rate": 3.085172520982282e-06,
      "loss": 0.2075,
      "step": 17796
    },
    {
      "epoch": 1.3830432079577246,
      "grad_norm": 0.8039836883544922,
      "learning_rate": 3.084783960211377e-06,
      "loss": 0.3453,
      "step": 17797
    },
    {
      "epoch": 1.3831209201119055,
      "grad_norm": 0.6738854646682739,
      "learning_rate": 3.084395399440473e-06,
      "loss": 0.3463,
      "step": 17798
    },
    {
      "epoch": 1.3831986322660863,
      "grad_norm": 0.39187660813331604,
      "learning_rate": 3.084006838669568e-06,
      "loss": 0.1903,
      "step": 17799
    },
    {
      "epoch": 1.3832763444202674,
      "grad_norm": 0.36827772855758667,
      "learning_rate": 3.0836182778986635e-06,
      "loss": 0.1501,
      "step": 17800
    },
    {
      "epoch": 1.3833540565744482,
      "grad_norm": 0.36613908410072327,
      "learning_rate": 3.0832297171277593e-06,
      "loss": 0.2984,
      "step": 17801
    },
    {
      "epoch": 1.383431768728629,
      "grad_norm": 0.41540762782096863,
      "learning_rate": 3.0828411563568543e-06,
      "loss": 0.0698,
      "step": 17802
    },
    {
      "epoch": 1.3835094808828101,
      "grad_norm": 0.26017147302627563,
      "learning_rate": 3.0824525955859497e-06,
      "loss": 0.0649,
      "step": 17803
    },
    {
      "epoch": 1.383587193036991,
      "grad_norm": 0.7983658313751221,
      "learning_rate": 3.0820640348150455e-06,
      "loss": 0.3394,
      "step": 17804
    },
    {
      "epoch": 1.3836649051911718,
      "grad_norm": 0.32498183846473694,
      "learning_rate": 3.081675474044141e-06,
      "loss": 0.0828,
      "step": 17805
    },
    {
      "epoch": 1.3837426173453529,
      "grad_norm": 0.2952449321746826,
      "learning_rate": 3.0812869132732358e-06,
      "loss": 0.0929,
      "step": 17806
    },
    {
      "epoch": 1.3838203294995337,
      "grad_norm": 0.4274122714996338,
      "learning_rate": 3.0808983525023316e-06,
      "loss": 0.1292,
      "step": 17807
    },
    {
      "epoch": 1.3838980416537146,
      "grad_norm": 1.2205352783203125,
      "learning_rate": 3.080509791731427e-06,
      "loss": 0.2126,
      "step": 17808
    },
    {
      "epoch": 1.3839757538078956,
      "grad_norm": 0.3857397437095642,
      "learning_rate": 3.0801212309605228e-06,
      "loss": 0.1373,
      "step": 17809
    },
    {
      "epoch": 1.3840534659620765,
      "grad_norm": 0.376889705657959,
      "learning_rate": 3.079732670189618e-06,
      "loss": 0.1521,
      "step": 17810
    },
    {
      "epoch": 1.3841311781162573,
      "grad_norm": 0.652645468711853,
      "learning_rate": 3.079344109418713e-06,
      "loss": 0.5635,
      "step": 17811
    },
    {
      "epoch": 1.3842088902704384,
      "grad_norm": 0.6636486649513245,
      "learning_rate": 3.078955548647809e-06,
      "loss": 0.2228,
      "step": 17812
    },
    {
      "epoch": 1.3842866024246192,
      "grad_norm": 0.09578388929367065,
      "learning_rate": 3.0785669878769042e-06,
      "loss": 0.0091,
      "step": 17813
    },
    {
      "epoch": 1.3843643145788,
      "grad_norm": 0.2021971493959427,
      "learning_rate": 3.0781784271059996e-06,
      "loss": 0.1138,
      "step": 17814
    },
    {
      "epoch": 1.3844420267329811,
      "grad_norm": 0.12488088756799698,
      "learning_rate": 3.0777898663350954e-06,
      "loss": 0.0181,
      "step": 17815
    },
    {
      "epoch": 1.384519738887162,
      "grad_norm": 0.24022254347801208,
      "learning_rate": 3.0774013055641904e-06,
      "loss": 0.0964,
      "step": 17816
    },
    {
      "epoch": 1.3845974510413428,
      "grad_norm": 0.7907291054725647,
      "learning_rate": 3.0770127447932857e-06,
      "loss": 0.5092,
      "step": 17817
    },
    {
      "epoch": 1.3846751631955239,
      "grad_norm": 0.19071055948734283,
      "learning_rate": 3.0766241840223815e-06,
      "loss": 0.0644,
      "step": 17818
    },
    {
      "epoch": 1.3847528753497047,
      "grad_norm": 0.807052731513977,
      "learning_rate": 3.076235623251477e-06,
      "loss": 0.5688,
      "step": 17819
    },
    {
      "epoch": 1.3848305875038855,
      "grad_norm": 0.4492148756980896,
      "learning_rate": 3.075847062480572e-06,
      "loss": 0.2557,
      "step": 17820
    },
    {
      "epoch": 1.3849082996580666,
      "grad_norm": 0.8052101135253906,
      "learning_rate": 3.0754585017096677e-06,
      "loss": 0.395,
      "step": 17821
    },
    {
      "epoch": 1.3849860118122475,
      "grad_norm": 0.5507542490959167,
      "learning_rate": 3.075069940938763e-06,
      "loss": 0.1463,
      "step": 17822
    },
    {
      "epoch": 1.3850637239664283,
      "grad_norm": 0.12924447655677795,
      "learning_rate": 3.074681380167859e-06,
      "loss": 0.0238,
      "step": 17823
    },
    {
      "epoch": 1.3851414361206094,
      "grad_norm": 0.2363279014825821,
      "learning_rate": 3.074292819396954e-06,
      "loss": 0.073,
      "step": 17824
    },
    {
      "epoch": 1.3852191482747902,
      "grad_norm": 0.7700581550598145,
      "learning_rate": 3.073904258626049e-06,
      "loss": 0.4377,
      "step": 17825
    },
    {
      "epoch": 1.385296860428971,
      "grad_norm": 0.9256923198699951,
      "learning_rate": 3.073515697855145e-06,
      "loss": 0.1474,
      "step": 17826
    },
    {
      "epoch": 1.385374572583152,
      "grad_norm": 0.3649168610572815,
      "learning_rate": 3.0731271370842403e-06,
      "loss": 0.5632,
      "step": 17827
    },
    {
      "epoch": 1.385452284737333,
      "grad_norm": 0.7317184805870056,
      "learning_rate": 3.0727385763133357e-06,
      "loss": 0.6757,
      "step": 17828
    },
    {
      "epoch": 1.3855299968915138,
      "grad_norm": 1.0276790857315063,
      "learning_rate": 3.0723500155424315e-06,
      "loss": 0.3304,
      "step": 17829
    },
    {
      "epoch": 1.3856077090456949,
      "grad_norm": 0.2038497030735016,
      "learning_rate": 3.0719614547715264e-06,
      "loss": 0.0363,
      "step": 17830
    },
    {
      "epoch": 1.3856854211998757,
      "grad_norm": 1.273738145828247,
      "learning_rate": 3.071572894000622e-06,
      "loss": 0.6375,
      "step": 17831
    },
    {
      "epoch": 1.3857631333540565,
      "grad_norm": 0.30206573009490967,
      "learning_rate": 3.0711843332297176e-06,
      "loss": 0.0383,
      "step": 17832
    },
    {
      "epoch": 1.3858408455082376,
      "grad_norm": 0.5178585648536682,
      "learning_rate": 3.070795772458813e-06,
      "loss": 0.0256,
      "step": 17833
    },
    {
      "epoch": 1.3859185576624184,
      "grad_norm": 0.4509413242340088,
      "learning_rate": 3.070407211687908e-06,
      "loss": 0.2624,
      "step": 17834
    },
    {
      "epoch": 1.3859962698165993,
      "grad_norm": 0.7907109260559082,
      "learning_rate": 3.0700186509170037e-06,
      "loss": 0.4784,
      "step": 17835
    },
    {
      "epoch": 1.3860739819707804,
      "grad_norm": 0.666053295135498,
      "learning_rate": 3.069630090146099e-06,
      "loss": 0.1056,
      "step": 17836
    },
    {
      "epoch": 1.3861516941249612,
      "grad_norm": 0.20315703749656677,
      "learning_rate": 3.069241529375194e-06,
      "loss": 0.0283,
      "step": 17837
    },
    {
      "epoch": 1.386229406279142,
      "grad_norm": 0.3882182836532593,
      "learning_rate": 3.06885296860429e-06,
      "loss": 0.0602,
      "step": 17838
    },
    {
      "epoch": 1.386307118433323,
      "grad_norm": 0.21597211062908173,
      "learning_rate": 3.0684644078333852e-06,
      "loss": 0.0767,
      "step": 17839
    },
    {
      "epoch": 1.386384830587504,
      "grad_norm": 0.259835809469223,
      "learning_rate": 3.068075847062481e-06,
      "loss": 0.0608,
      "step": 17840
    },
    {
      "epoch": 1.3864625427416848,
      "grad_norm": 0.7539674043655396,
      "learning_rate": 3.0676872862915764e-06,
      "loss": 0.0703,
      "step": 17841
    },
    {
      "epoch": 1.3865402548958656,
      "grad_norm": 0.725554883480072,
      "learning_rate": 3.0672987255206713e-06,
      "loss": 0.3862,
      "step": 17842
    },
    {
      "epoch": 1.3866179670500467,
      "grad_norm": 0.32453835010528564,
      "learning_rate": 3.066910164749767e-06,
      "loss": 0.0636,
      "step": 17843
    },
    {
      "epoch": 1.3866956792042275,
      "grad_norm": 0.3590356111526489,
      "learning_rate": 3.0665216039788625e-06,
      "loss": 0.1793,
      "step": 17844
    },
    {
      "epoch": 1.3867733913584084,
      "grad_norm": 0.40553751587867737,
      "learning_rate": 3.066133043207958e-06,
      "loss": 0.1774,
      "step": 17845
    },
    {
      "epoch": 1.3868511035125894,
      "grad_norm": 0.820205807685852,
      "learning_rate": 3.0657444824370537e-06,
      "loss": 0.4479,
      "step": 17846
    },
    {
      "epoch": 1.3869288156667703,
      "grad_norm": 0.4151870608329773,
      "learning_rate": 3.0653559216661486e-06,
      "loss": 0.0327,
      "step": 17847
    },
    {
      "epoch": 1.3870065278209511,
      "grad_norm": 0.609835147857666,
      "learning_rate": 3.064967360895244e-06,
      "loss": 0.1234,
      "step": 17848
    },
    {
      "epoch": 1.3870842399751322,
      "grad_norm": 1.025542140007019,
      "learning_rate": 3.06457880012434e-06,
      "loss": 0.4738,
      "step": 17849
    },
    {
      "epoch": 1.387161952129313,
      "grad_norm": 0.5632118582725525,
      "learning_rate": 3.064190239353435e-06,
      "loss": 0.1379,
      "step": 17850
    },
    {
      "epoch": 1.3872396642834939,
      "grad_norm": 0.09614762663841248,
      "learning_rate": 3.06380167858253e-06,
      "loss": 0.0391,
      "step": 17851
    },
    {
      "epoch": 1.3873173764376747,
      "grad_norm": 0.4747205078601837,
      "learning_rate": 3.063413117811626e-06,
      "loss": 0.1762,
      "step": 17852
    },
    {
      "epoch": 1.3873950885918558,
      "grad_norm": 0.47853991389274597,
      "learning_rate": 3.0630245570407213e-06,
      "loss": 0.1879,
      "step": 17853
    },
    {
      "epoch": 1.3874728007460366,
      "grad_norm": 0.3325095474720001,
      "learning_rate": 3.062635996269817e-06,
      "loss": 0.098,
      "step": 17854
    },
    {
      "epoch": 1.3875505129002175,
      "grad_norm": 0.4495164752006531,
      "learning_rate": 3.0622474354989125e-06,
      "loss": 0.0677,
      "step": 17855
    },
    {
      "epoch": 1.3876282250543985,
      "grad_norm": 0.307453453540802,
      "learning_rate": 3.0618588747280074e-06,
      "loss": 0.0588,
      "step": 17856
    },
    {
      "epoch": 1.3877059372085794,
      "grad_norm": 0.6632341742515564,
      "learning_rate": 3.0614703139571032e-06,
      "loss": 0.2213,
      "step": 17857
    },
    {
      "epoch": 1.3877836493627602,
      "grad_norm": 0.47855401039123535,
      "learning_rate": 3.0610817531861986e-06,
      "loss": 0.2285,
      "step": 17858
    },
    {
      "epoch": 1.3878613615169413,
      "grad_norm": 0.6121782660484314,
      "learning_rate": 3.060693192415294e-06,
      "loss": 0.0427,
      "step": 17859
    },
    {
      "epoch": 1.3879390736711221,
      "grad_norm": 0.806668221950531,
      "learning_rate": 3.0603046316443898e-06,
      "loss": 0.9936,
      "step": 17860
    },
    {
      "epoch": 1.388016785825303,
      "grad_norm": 0.5372586250305176,
      "learning_rate": 3.0599160708734847e-06,
      "loss": 0.1951,
      "step": 17861
    },
    {
      "epoch": 1.388094497979484,
      "grad_norm": 0.36847877502441406,
      "learning_rate": 3.05952751010258e-06,
      "loss": 0.1229,
      "step": 17862
    },
    {
      "epoch": 1.3881722101336649,
      "grad_norm": 0.12981899082660675,
      "learning_rate": 3.059138949331676e-06,
      "loss": 0.0568,
      "step": 17863
    },
    {
      "epoch": 1.3882499222878457,
      "grad_norm": 0.3912845551967621,
      "learning_rate": 3.0587503885607712e-06,
      "loss": 0.0749,
      "step": 17864
    },
    {
      "epoch": 1.3883276344420268,
      "grad_norm": 0.12326736748218536,
      "learning_rate": 3.058361827789866e-06,
      "loss": 0.0176,
      "step": 17865
    },
    {
      "epoch": 1.3884053465962076,
      "grad_norm": 0.24890242516994476,
      "learning_rate": 3.057973267018962e-06,
      "loss": 0.0468,
      "step": 17866
    },
    {
      "epoch": 1.3884830587503885,
      "grad_norm": 0.4082935154438019,
      "learning_rate": 3.0575847062480574e-06,
      "loss": 0.0928,
      "step": 17867
    },
    {
      "epoch": 1.3885607709045695,
      "grad_norm": 0.0944499596953392,
      "learning_rate": 3.0571961454771527e-06,
      "loss": 0.0187,
      "step": 17868
    },
    {
      "epoch": 1.3886384830587504,
      "grad_norm": 0.06477312743663788,
      "learning_rate": 3.0568075847062485e-06,
      "loss": 0.0096,
      "step": 17869
    },
    {
      "epoch": 1.3887161952129312,
      "grad_norm": 0.15016670525074005,
      "learning_rate": 3.0564190239353435e-06,
      "loss": 0.0379,
      "step": 17870
    },
    {
      "epoch": 1.3887939073671123,
      "grad_norm": 0.9199911952018738,
      "learning_rate": 3.0560304631644393e-06,
      "loss": 0.2418,
      "step": 17871
    },
    {
      "epoch": 1.3888716195212931,
      "grad_norm": 0.12195028364658356,
      "learning_rate": 3.0556419023935347e-06,
      "loss": 0.0114,
      "step": 17872
    },
    {
      "epoch": 1.388949331675474,
      "grad_norm": 0.3330751955509186,
      "learning_rate": 3.05525334162263e-06,
      "loss": 0.0541,
      "step": 17873
    },
    {
      "epoch": 1.389027043829655,
      "grad_norm": 2.5488569736480713,
      "learning_rate": 3.054864780851726e-06,
      "loss": 0.712,
      "step": 17874
    },
    {
      "epoch": 1.3891047559838359,
      "grad_norm": 0.09491130709648132,
      "learning_rate": 3.0544762200808208e-06,
      "loss": 0.0084,
      "step": 17875
    },
    {
      "epoch": 1.3891824681380167,
      "grad_norm": 0.7050428986549377,
      "learning_rate": 3.054087659309916e-06,
      "loss": 0.2265,
      "step": 17876
    },
    {
      "epoch": 1.3892601802921978,
      "grad_norm": 0.26172128319740295,
      "learning_rate": 3.053699098539012e-06,
      "loss": 0.0629,
      "step": 17877
    },
    {
      "epoch": 1.3893378924463786,
      "grad_norm": 0.7731926441192627,
      "learning_rate": 3.0533105377681073e-06,
      "loss": 0.1524,
      "step": 17878
    },
    {
      "epoch": 1.3894156046005595,
      "grad_norm": 0.31086811423301697,
      "learning_rate": 3.0529219769972023e-06,
      "loss": 0.1261,
      "step": 17879
    },
    {
      "epoch": 1.3894933167547405,
      "grad_norm": 0.1897512674331665,
      "learning_rate": 3.052533416226298e-06,
      "loss": 0.0375,
      "step": 17880
    },
    {
      "epoch": 1.3895710289089214,
      "grad_norm": 0.29164183139801025,
      "learning_rate": 3.0521448554553934e-06,
      "loss": 0.1098,
      "step": 17881
    },
    {
      "epoch": 1.3896487410631022,
      "grad_norm": 0.37609946727752686,
      "learning_rate": 3.051756294684489e-06,
      "loss": 0.0406,
      "step": 17882
    },
    {
      "epoch": 1.3897264532172833,
      "grad_norm": 0.46696484088897705,
      "learning_rate": 3.0513677339135846e-06,
      "loss": 0.1763,
      "step": 17883
    },
    {
      "epoch": 1.3898041653714641,
      "grad_norm": 0.5499690771102905,
      "learning_rate": 3.0509791731426796e-06,
      "loss": 0.0414,
      "step": 17884
    },
    {
      "epoch": 1.389881877525645,
      "grad_norm": 0.2746318578720093,
      "learning_rate": 3.0505906123717754e-06,
      "loss": 0.2443,
      "step": 17885
    },
    {
      "epoch": 1.389959589679826,
      "grad_norm": 0.1754913181066513,
      "learning_rate": 3.0502020516008707e-06,
      "loss": 0.0585,
      "step": 17886
    },
    {
      "epoch": 1.3900373018340069,
      "grad_norm": 0.8012224435806274,
      "learning_rate": 3.049813490829966e-06,
      "loss": 0.376,
      "step": 17887
    },
    {
      "epoch": 1.3901150139881877,
      "grad_norm": 0.1743858903646469,
      "learning_rate": 3.049424930059062e-06,
      "loss": 0.0352,
      "step": 17888
    },
    {
      "epoch": 1.3901927261423688,
      "grad_norm": 1.440781831741333,
      "learning_rate": 3.049036369288157e-06,
      "loss": 0.0934,
      "step": 17889
    },
    {
      "epoch": 1.3902704382965496,
      "grad_norm": 0.4994374215602875,
      "learning_rate": 3.0486478085172522e-06,
      "loss": 0.1585,
      "step": 17890
    },
    {
      "epoch": 1.3903481504507305,
      "grad_norm": 0.43179312348365784,
      "learning_rate": 3.048259247746348e-06,
      "loss": 0.0516,
      "step": 17891
    },
    {
      "epoch": 1.3904258626049115,
      "grad_norm": 0.16157008707523346,
      "learning_rate": 3.0478706869754434e-06,
      "loss": 0.032,
      "step": 17892
    },
    {
      "epoch": 1.3905035747590924,
      "grad_norm": 0.6791033744812012,
      "learning_rate": 3.0474821262045383e-06,
      "loss": 0.761,
      "step": 17893
    },
    {
      "epoch": 1.3905812869132732,
      "grad_norm": 0.22773589193820953,
      "learning_rate": 3.047093565433634e-06,
      "loss": 0.0192,
      "step": 17894
    },
    {
      "epoch": 1.3906589990674543,
      "grad_norm": 0.5487794280052185,
      "learning_rate": 3.0467050046627295e-06,
      "loss": 0.2834,
      "step": 17895
    },
    {
      "epoch": 1.3907367112216351,
      "grad_norm": 0.18532872200012207,
      "learning_rate": 3.046316443891825e-06,
      "loss": 0.0827,
      "step": 17896
    },
    {
      "epoch": 1.390814423375816,
      "grad_norm": 0.1137477457523346,
      "learning_rate": 3.0459278831209203e-06,
      "loss": 0.0382,
      "step": 17897
    },
    {
      "epoch": 1.390892135529997,
      "grad_norm": 0.635949969291687,
      "learning_rate": 3.0455393223500156e-06,
      "loss": 0.0794,
      "step": 17898
    },
    {
      "epoch": 1.3909698476841779,
      "grad_norm": 0.5560109615325928,
      "learning_rate": 3.0451507615791114e-06,
      "loss": 0.1371,
      "step": 17899
    },
    {
      "epoch": 1.3910475598383587,
      "grad_norm": 0.2579823434352875,
      "learning_rate": 3.044762200808207e-06,
      "loss": 0.0201,
      "step": 17900
    },
    {
      "epoch": 1.3911252719925398,
      "grad_norm": 0.6308144927024841,
      "learning_rate": 3.0443736400373018e-06,
      "loss": 0.3462,
      "step": 17901
    },
    {
      "epoch": 1.3912029841467206,
      "grad_norm": 0.45665329694747925,
      "learning_rate": 3.0439850792663976e-06,
      "loss": 0.0977,
      "step": 17902
    },
    {
      "epoch": 1.3912806963009015,
      "grad_norm": 0.11870730668306351,
      "learning_rate": 3.043596518495493e-06,
      "loss": 0.0241,
      "step": 17903
    },
    {
      "epoch": 1.3913584084550823,
      "grad_norm": 0.6363855004310608,
      "learning_rate": 3.0432079577245883e-06,
      "loss": 0.2081,
      "step": 17904
    },
    {
      "epoch": 1.3914361206092634,
      "grad_norm": 0.48875969648361206,
      "learning_rate": 3.042819396953684e-06,
      "loss": 0.1218,
      "step": 17905
    },
    {
      "epoch": 1.3915138327634442,
      "grad_norm": 0.6147977709770203,
      "learning_rate": 3.042430836182779e-06,
      "loss": 0.3398,
      "step": 17906
    },
    {
      "epoch": 1.391591544917625,
      "grad_norm": 0.4401071071624756,
      "learning_rate": 3.0420422754118744e-06,
      "loss": 0.3627,
      "step": 17907
    },
    {
      "epoch": 1.391669257071806,
      "grad_norm": 0.3921754062175751,
      "learning_rate": 3.0416537146409702e-06,
      "loss": 0.2014,
      "step": 17908
    },
    {
      "epoch": 1.391746969225987,
      "grad_norm": 0.28692108392715454,
      "learning_rate": 3.0412651538700656e-06,
      "loss": 0.0482,
      "step": 17909
    },
    {
      "epoch": 1.3918246813801678,
      "grad_norm": 0.522657036781311,
      "learning_rate": 3.0408765930991605e-06,
      "loss": 0.252,
      "step": 17910
    },
    {
      "epoch": 1.3919023935343486,
      "grad_norm": 0.37972211837768555,
      "learning_rate": 3.0404880323282563e-06,
      "loss": 0.1364,
      "step": 17911
    },
    {
      "epoch": 1.3919801056885297,
      "grad_norm": 0.34091055393218994,
      "learning_rate": 3.0400994715573517e-06,
      "loss": 0.2289,
      "step": 17912
    },
    {
      "epoch": 1.3920578178427105,
      "grad_norm": 0.5607226490974426,
      "learning_rate": 3.039710910786447e-06,
      "loss": 0.2702,
      "step": 17913
    },
    {
      "epoch": 1.3921355299968914,
      "grad_norm": 0.09559229761362076,
      "learning_rate": 3.039322350015543e-06,
      "loss": 0.0195,
      "step": 17914
    },
    {
      "epoch": 1.3922132421510724,
      "grad_norm": 0.6623988151550293,
      "learning_rate": 3.038933789244638e-06,
      "loss": 0.1948,
      "step": 17915
    },
    {
      "epoch": 1.3922909543052533,
      "grad_norm": 0.2982798218727112,
      "learning_rate": 3.0385452284737336e-06,
      "loss": 0.0406,
      "step": 17916
    },
    {
      "epoch": 1.3923686664594341,
      "grad_norm": 0.17035320401191711,
      "learning_rate": 3.038156667702829e-06,
      "loss": 0.0286,
      "step": 17917
    },
    {
      "epoch": 1.3924463786136152,
      "grad_norm": 0.8140637874603271,
      "learning_rate": 3.0377681069319244e-06,
      "loss": 0.4029,
      "step": 17918
    },
    {
      "epoch": 1.392524090767796,
      "grad_norm": 0.9965636134147644,
      "learning_rate": 3.03737954616102e-06,
      "loss": 0.4457,
      "step": 17919
    },
    {
      "epoch": 1.3926018029219769,
      "grad_norm": 0.6412548422813416,
      "learning_rate": 3.036990985390115e-06,
      "loss": 0.1117,
      "step": 17920
    },
    {
      "epoch": 1.392679515076158,
      "grad_norm": 0.31918373703956604,
      "learning_rate": 3.0366024246192105e-06,
      "loss": 0.0968,
      "step": 17921
    },
    {
      "epoch": 1.3927572272303388,
      "grad_norm": 0.5453991889953613,
      "learning_rate": 3.0362138638483063e-06,
      "loss": 0.2281,
      "step": 17922
    },
    {
      "epoch": 1.3928349393845196,
      "grad_norm": 0.3035350441932678,
      "learning_rate": 3.0358253030774017e-06,
      "loss": 0.1237,
      "step": 17923
    },
    {
      "epoch": 1.3929126515387007,
      "grad_norm": 0.621877908706665,
      "learning_rate": 3.0354367423064966e-06,
      "loss": 0.1889,
      "step": 17924
    },
    {
      "epoch": 1.3929903636928815,
      "grad_norm": 0.7083656191825867,
      "learning_rate": 3.0350481815355924e-06,
      "loss": 0.4964,
      "step": 17925
    },
    {
      "epoch": 1.3930680758470624,
      "grad_norm": 0.35719841718673706,
      "learning_rate": 3.0346596207646878e-06,
      "loss": 0.206,
      "step": 17926
    },
    {
      "epoch": 1.3931457880012434,
      "grad_norm": 0.6844309568405151,
      "learning_rate": 3.034271059993783e-06,
      "loss": 0.1021,
      "step": 17927
    },
    {
      "epoch": 1.3932235001554243,
      "grad_norm": 0.44651469588279724,
      "learning_rate": 3.033882499222879e-06,
      "loss": 0.1259,
      "step": 17928
    },
    {
      "epoch": 1.3933012123096051,
      "grad_norm": 0.2689032256603241,
      "learning_rate": 3.033493938451974e-06,
      "loss": 0.1457,
      "step": 17929
    },
    {
      "epoch": 1.3933789244637862,
      "grad_norm": 0.35219740867614746,
      "learning_rate": 3.0331053776810697e-06,
      "loss": 0.3576,
      "step": 17930
    },
    {
      "epoch": 1.393456636617967,
      "grad_norm": 0.4310012757778168,
      "learning_rate": 3.032716816910165e-06,
      "loss": 0.2819,
      "step": 17931
    },
    {
      "epoch": 1.3935343487721479,
      "grad_norm": 0.32560351490974426,
      "learning_rate": 3.0323282561392604e-06,
      "loss": 0.0992,
      "step": 17932
    },
    {
      "epoch": 1.393612060926329,
      "grad_norm": 0.36400118470191956,
      "learning_rate": 3.0319396953683562e-06,
      "loss": 0.3567,
      "step": 17933
    },
    {
      "epoch": 1.3936897730805098,
      "grad_norm": 0.8994418382644653,
      "learning_rate": 3.031551134597451e-06,
      "loss": 0.3728,
      "step": 17934
    },
    {
      "epoch": 1.3937674852346906,
      "grad_norm": 0.16377294063568115,
      "learning_rate": 3.0311625738265466e-06,
      "loss": 0.0311,
      "step": 17935
    },
    {
      "epoch": 1.3938451973888717,
      "grad_norm": 0.49293309450149536,
      "learning_rate": 3.0307740130556424e-06,
      "loss": 0.0577,
      "step": 17936
    },
    {
      "epoch": 1.3939229095430525,
      "grad_norm": 0.5425679087638855,
      "learning_rate": 3.0303854522847377e-06,
      "loss": 0.1474,
      "step": 17937
    },
    {
      "epoch": 1.3940006216972334,
      "grad_norm": 0.33720895648002625,
      "learning_rate": 3.0299968915138327e-06,
      "loss": 0.1259,
      "step": 17938
    },
    {
      "epoch": 1.3940783338514144,
      "grad_norm": 0.25289660692214966,
      "learning_rate": 3.0296083307429285e-06,
      "loss": 0.0244,
      "step": 17939
    },
    {
      "epoch": 1.3941560460055953,
      "grad_norm": 0.1699448972940445,
      "learning_rate": 3.029219769972024e-06,
      "loss": 0.0406,
      "step": 17940
    },
    {
      "epoch": 1.3942337581597761,
      "grad_norm": 0.6721175312995911,
      "learning_rate": 3.0288312092011192e-06,
      "loss": 0.176,
      "step": 17941
    },
    {
      "epoch": 1.3943114703139572,
      "grad_norm": 2.015103340148926,
      "learning_rate": 3.028442648430215e-06,
      "loss": 0.4566,
      "step": 17942
    },
    {
      "epoch": 1.394389182468138,
      "grad_norm": 0.6436741352081299,
      "learning_rate": 3.02805408765931e-06,
      "loss": 0.5015,
      "step": 17943
    },
    {
      "epoch": 1.3944668946223189,
      "grad_norm": 0.04966505244374275,
      "learning_rate": 3.0276655268884058e-06,
      "loss": 0.0033,
      "step": 17944
    },
    {
      "epoch": 1.3945446067765,
      "grad_norm": 0.7515060305595398,
      "learning_rate": 3.027276966117501e-06,
      "loss": 0.6017,
      "step": 17945
    },
    {
      "epoch": 1.3946223189306808,
      "grad_norm": 0.21114780008792877,
      "learning_rate": 3.0268884053465965e-06,
      "loss": 0.0368,
      "step": 17946
    },
    {
      "epoch": 1.3947000310848616,
      "grad_norm": 0.47144708037376404,
      "learning_rate": 3.0264998445756923e-06,
      "loss": 0.0978,
      "step": 17947
    },
    {
      "epoch": 1.3947777432390427,
      "grad_norm": 0.8139753937721252,
      "learning_rate": 3.0261112838047873e-06,
      "loss": 0.1582,
      "step": 17948
    },
    {
      "epoch": 1.3948554553932235,
      "grad_norm": 0.5201879143714905,
      "learning_rate": 3.0257227230338826e-06,
      "loss": 0.1705,
      "step": 17949
    },
    {
      "epoch": 1.3949331675474044,
      "grad_norm": 0.9161908030509949,
      "learning_rate": 3.0253341622629784e-06,
      "loss": 0.2645,
      "step": 17950
    },
    {
      "epoch": 1.3950108797015854,
      "grad_norm": 0.6399526000022888,
      "learning_rate": 3.024945601492074e-06,
      "loss": 0.1974,
      "step": 17951
    },
    {
      "epoch": 1.3950885918557663,
      "grad_norm": 0.4113190770149231,
      "learning_rate": 3.0245570407211688e-06,
      "loss": 0.1398,
      "step": 17952
    },
    {
      "epoch": 1.3951663040099471,
      "grad_norm": 0.8392627835273743,
      "learning_rate": 3.0241684799502646e-06,
      "loss": 0.8296,
      "step": 17953
    },
    {
      "epoch": 1.3952440161641282,
      "grad_norm": 0.2868327796459198,
      "learning_rate": 3.02377991917936e-06,
      "loss": 0.1753,
      "step": 17954
    },
    {
      "epoch": 1.395321728318309,
      "grad_norm": 0.2990139424800873,
      "learning_rate": 3.0233913584084553e-06,
      "loss": 0.1223,
      "step": 17955
    },
    {
      "epoch": 1.3953994404724899,
      "grad_norm": 0.42470312118530273,
      "learning_rate": 3.023002797637551e-06,
      "loss": 0.0699,
      "step": 17956
    },
    {
      "epoch": 1.395477152626671,
      "grad_norm": 0.5948404669761658,
      "learning_rate": 3.022614236866646e-06,
      "loss": 0.4027,
      "step": 17957
    },
    {
      "epoch": 1.3955548647808518,
      "grad_norm": 0.5579461455345154,
      "learning_rate": 3.0222256760957414e-06,
      "loss": 0.2187,
      "step": 17958
    },
    {
      "epoch": 1.3956325769350326,
      "grad_norm": 0.4599457383155823,
      "learning_rate": 3.0218371153248372e-06,
      "loss": 0.0978,
      "step": 17959
    },
    {
      "epoch": 1.3957102890892137,
      "grad_norm": 0.17155298590660095,
      "learning_rate": 3.021448554553932e-06,
      "loss": 0.0891,
      "step": 17960
    },
    {
      "epoch": 1.3957880012433945,
      "grad_norm": 0.33083614706993103,
      "learning_rate": 3.021059993783028e-06,
      "loss": 0.1327,
      "step": 17961
    },
    {
      "epoch": 1.3958657133975754,
      "grad_norm": 0.10939503461122513,
      "learning_rate": 3.0206714330121233e-06,
      "loss": 0.0299,
      "step": 17962
    },
    {
      "epoch": 1.3959434255517562,
      "grad_norm": 0.05912221595644951,
      "learning_rate": 3.0202828722412187e-06,
      "loss": 0.0116,
      "step": 17963
    },
    {
      "epoch": 1.3960211377059373,
      "grad_norm": 0.4910411238670349,
      "learning_rate": 3.0198943114703145e-06,
      "loss": 0.1753,
      "step": 17964
    },
    {
      "epoch": 1.3960988498601181,
      "grad_norm": 0.47408559918403625,
      "learning_rate": 3.0195057506994095e-06,
      "loss": 0.1788,
      "step": 17965
    },
    {
      "epoch": 1.396176562014299,
      "grad_norm": 0.730705201625824,
      "learning_rate": 3.019117189928505e-06,
      "loss": 0.2722,
      "step": 17966
    },
    {
      "epoch": 1.39625427416848,
      "grad_norm": 0.45427972078323364,
      "learning_rate": 3.0187286291576006e-06,
      "loss": 0.3559,
      "step": 17967
    },
    {
      "epoch": 1.3963319863226609,
      "grad_norm": 0.8071334958076477,
      "learning_rate": 3.018340068386696e-06,
      "loss": 0.0845,
      "step": 17968
    },
    {
      "epoch": 1.3964096984768417,
      "grad_norm": 0.49852287769317627,
      "learning_rate": 3.017951507615791e-06,
      "loss": 0.2349,
      "step": 17969
    },
    {
      "epoch": 1.3964874106310228,
      "grad_norm": 0.19877733290195465,
      "learning_rate": 3.0175629468448867e-06,
      "loss": 0.08,
      "step": 17970
    },
    {
      "epoch": 1.3965651227852036,
      "grad_norm": 0.3136468827724457,
      "learning_rate": 3.017174386073982e-06,
      "loss": 0.1056,
      "step": 17971
    },
    {
      "epoch": 1.3966428349393845,
      "grad_norm": 0.7618898153305054,
      "learning_rate": 3.0167858253030775e-06,
      "loss": 0.1231,
      "step": 17972
    },
    {
      "epoch": 1.3967205470935653,
      "grad_norm": 0.594966471195221,
      "learning_rate": 3.0163972645321733e-06,
      "loss": 0.1663,
      "step": 17973
    },
    {
      "epoch": 1.3967982592477464,
      "grad_norm": 1.1856651306152344,
      "learning_rate": 3.0160087037612682e-06,
      "loss": 0.5308,
      "step": 17974
    },
    {
      "epoch": 1.3968759714019272,
      "grad_norm": 0.47572460770606995,
      "learning_rate": 3.015620142990364e-06,
      "loss": 0.1298,
      "step": 17975
    },
    {
      "epoch": 1.396953683556108,
      "grad_norm": 0.0843687355518341,
      "learning_rate": 3.0152315822194594e-06,
      "loss": 0.0071,
      "step": 17976
    },
    {
      "epoch": 1.3970313957102891,
      "grad_norm": 0.5373319387435913,
      "learning_rate": 3.0148430214485548e-06,
      "loss": 0.1349,
      "step": 17977
    },
    {
      "epoch": 1.39710910786447,
      "grad_norm": 0.29590287804603577,
      "learning_rate": 3.0144544606776506e-06,
      "loss": 0.0797,
      "step": 17978
    },
    {
      "epoch": 1.3971868200186508,
      "grad_norm": 0.7587238550186157,
      "learning_rate": 3.0140658999067455e-06,
      "loss": 0.4316,
      "step": 17979
    },
    {
      "epoch": 1.3972645321728319,
      "grad_norm": 0.0735267624258995,
      "learning_rate": 3.013677339135841e-06,
      "loss": 0.0233,
      "step": 17980
    },
    {
      "epoch": 1.3973422443270127,
      "grad_norm": 1.339158535003662,
      "learning_rate": 3.0132887783649367e-06,
      "loss": 0.4403,
      "step": 17981
    },
    {
      "epoch": 1.3974199564811935,
      "grad_norm": 0.17362655699253082,
      "learning_rate": 3.012900217594032e-06,
      "loss": 0.0309,
      "step": 17982
    },
    {
      "epoch": 1.3974976686353746,
      "grad_norm": 0.42093127965927124,
      "learning_rate": 3.012511656823127e-06,
      "loss": 0.2116,
      "step": 17983
    },
    {
      "epoch": 1.3975753807895555,
      "grad_norm": 0.3314675986766815,
      "learning_rate": 3.012123096052223e-06,
      "loss": 0.0471,
      "step": 17984
    },
    {
      "epoch": 1.3976530929437363,
      "grad_norm": 0.11099360883235931,
      "learning_rate": 3.011734535281318e-06,
      "loss": 0.0207,
      "step": 17985
    },
    {
      "epoch": 1.3977308050979174,
      "grad_norm": 0.3685249090194702,
      "learning_rate": 3.0113459745104136e-06,
      "loss": 0.0998,
      "step": 17986
    },
    {
      "epoch": 1.3978085172520982,
      "grad_norm": 0.45070093870162964,
      "learning_rate": 3.0109574137395094e-06,
      "loss": 0.2319,
      "step": 17987
    },
    {
      "epoch": 1.397886229406279,
      "grad_norm": 0.7704607248306274,
      "learning_rate": 3.0105688529686043e-06,
      "loss": 0.2374,
      "step": 17988
    },
    {
      "epoch": 1.39796394156046,
      "grad_norm": 0.3245655298233032,
      "learning_rate": 3.0101802921976997e-06,
      "loss": 0.1807,
      "step": 17989
    },
    {
      "epoch": 1.398041653714641,
      "grad_norm": 1.33957040309906,
      "learning_rate": 3.0097917314267955e-06,
      "loss": 0.1966,
      "step": 17990
    },
    {
      "epoch": 1.3981193658688218,
      "grad_norm": 0.4384934604167938,
      "learning_rate": 3.009403170655891e-06,
      "loss": 0.0749,
      "step": 17991
    },
    {
      "epoch": 1.3981970780230029,
      "grad_norm": 1.1380600929260254,
      "learning_rate": 3.0090146098849867e-06,
      "loss": 0.2897,
      "step": 17992
    },
    {
      "epoch": 1.3982747901771837,
      "grad_norm": 0.4349937438964844,
      "learning_rate": 3.0086260491140816e-06,
      "loss": 0.1178,
      "step": 17993
    },
    {
      "epoch": 1.3983525023313645,
      "grad_norm": 0.4113816022872925,
      "learning_rate": 3.008237488343177e-06,
      "loss": 0.5414,
      "step": 17994
    },
    {
      "epoch": 1.3984302144855456,
      "grad_norm": 0.3081117570400238,
      "learning_rate": 3.0078489275722728e-06,
      "loss": 0.1786,
      "step": 17995
    },
    {
      "epoch": 1.3985079266397265,
      "grad_norm": 0.3374890089035034,
      "learning_rate": 3.007460366801368e-06,
      "loss": 0.0668,
      "step": 17996
    },
    {
      "epoch": 1.3985856387939073,
      "grad_norm": 0.35284537076950073,
      "learning_rate": 3.007071806030463e-06,
      "loss": 0.2372,
      "step": 17997
    },
    {
      "epoch": 1.3986633509480884,
      "grad_norm": 0.4226340353488922,
      "learning_rate": 3.006683245259559e-06,
      "loss": 0.2827,
      "step": 17998
    },
    {
      "epoch": 1.3987410631022692,
      "grad_norm": 0.3133372962474823,
      "learning_rate": 3.0062946844886543e-06,
      "loss": 0.0866,
      "step": 17999
    },
    {
      "epoch": 1.39881877525645,
      "grad_norm": 0.6005140542984009,
      "learning_rate": 3.0059061237177496e-06,
      "loss": 0.0656,
      "step": 18000
    },
    {
      "epoch": 1.398896487410631,
      "grad_norm": 0.6072406768798828,
      "learning_rate": 3.0055175629468454e-06,
      "loss": 0.0617,
      "step": 18001
    },
    {
      "epoch": 1.398974199564812,
      "grad_norm": 0.32442623376846313,
      "learning_rate": 3.0051290021759404e-06,
      "loss": 0.1048,
      "step": 18002
    },
    {
      "epoch": 1.3990519117189928,
      "grad_norm": 0.2671820819377899,
      "learning_rate": 3.0047404414050358e-06,
      "loss": 0.1033,
      "step": 18003
    },
    {
      "epoch": 1.3991296238731739,
      "grad_norm": 0.4154628813266754,
      "learning_rate": 3.0043518806341316e-06,
      "loss": 0.6033,
      "step": 18004
    },
    {
      "epoch": 1.3992073360273547,
      "grad_norm": 4.924197673797607,
      "learning_rate": 3.003963319863227e-06,
      "loss": 3.0595,
      "step": 18005
    },
    {
      "epoch": 1.3992850481815355,
      "grad_norm": 0.590644896030426,
      "learning_rate": 3.0035747590923227e-06,
      "loss": 0.427,
      "step": 18006
    },
    {
      "epoch": 1.3993627603357166,
      "grad_norm": 0.16349871456623077,
      "learning_rate": 3.0031861983214177e-06,
      "loss": 0.0289,
      "step": 18007
    },
    {
      "epoch": 1.3994404724898974,
      "grad_norm": 0.38411393761634827,
      "learning_rate": 3.002797637550513e-06,
      "loss": 0.0884,
      "step": 18008
    },
    {
      "epoch": 1.3995181846440783,
      "grad_norm": 0.2151094675064087,
      "learning_rate": 3.002409076779609e-06,
      "loss": 0.084,
      "step": 18009
    },
    {
      "epoch": 1.3995958967982594,
      "grad_norm": 0.30835995078086853,
      "learning_rate": 3.0020205160087042e-06,
      "loss": 0.161,
      "step": 18010
    },
    {
      "epoch": 1.3996736089524402,
      "grad_norm": 0.28444093465805054,
      "learning_rate": 3.001631955237799e-06,
      "loss": 0.0383,
      "step": 18011
    },
    {
      "epoch": 1.399751321106621,
      "grad_norm": 0.28911155462265015,
      "learning_rate": 3.001243394466895e-06,
      "loss": 0.0464,
      "step": 18012
    },
    {
      "epoch": 1.399829033260802,
      "grad_norm": 0.3071433901786804,
      "learning_rate": 3.0008548336959903e-06,
      "loss": 0.1638,
      "step": 18013
    },
    {
      "epoch": 1.399906745414983,
      "grad_norm": 0.8151443600654602,
      "learning_rate": 3.0004662729250857e-06,
      "loss": 0.2209,
      "step": 18014
    },
    {
      "epoch": 1.3999844575691638,
      "grad_norm": 0.2534393072128296,
      "learning_rate": 3.0000777121541815e-06,
      "loss": 0.0499,
      "step": 18015
    },
    {
      "epoch": 1.4000621697233449,
      "grad_norm": 0.3314985930919647,
      "learning_rate": 2.9996891513832765e-06,
      "loss": 0.0715,
      "step": 18016
    },
    {
      "epoch": 1.4001398818775257,
      "grad_norm": 1.150140643119812,
      "learning_rate": 2.999300590612372e-06,
      "loss": 0.1925,
      "step": 18017
    },
    {
      "epoch": 1.4002175940317065,
      "grad_norm": 0.44708701968193054,
      "learning_rate": 2.9989120298414676e-06,
      "loss": 0.65,
      "step": 18018
    },
    {
      "epoch": 1.4002953061858876,
      "grad_norm": 1.1082175970077515,
      "learning_rate": 2.998523469070563e-06,
      "loss": 0.6581,
      "step": 18019
    },
    {
      "epoch": 1.4003730183400684,
      "grad_norm": 0.06569550186395645,
      "learning_rate": 2.9981349082996584e-06,
      "loss": 0.0106,
      "step": 18020
    },
    {
      "epoch": 1.4004507304942493,
      "grad_norm": 0.0685427263379097,
      "learning_rate": 2.9977463475287537e-06,
      "loss": 0.0203,
      "step": 18021
    },
    {
      "epoch": 1.4005284426484303,
      "grad_norm": 0.3420690894126892,
      "learning_rate": 2.997357786757849e-06,
      "loss": 0.0761,
      "step": 18022
    },
    {
      "epoch": 1.4006061548026112,
      "grad_norm": 0.44877564907073975,
      "learning_rate": 2.996969225986945e-06,
      "loss": 0.0911,
      "step": 18023
    },
    {
      "epoch": 1.400683866956792,
      "grad_norm": 0.7116667032241821,
      "learning_rate": 2.99658066521604e-06,
      "loss": 0.7419,
      "step": 18024
    },
    {
      "epoch": 1.4007615791109729,
      "grad_norm": 0.5212646722793579,
      "learning_rate": 2.9961921044451352e-06,
      "loss": 0.1893,
      "step": 18025
    },
    {
      "epoch": 1.400839291265154,
      "grad_norm": 0.43085673451423645,
      "learning_rate": 2.995803543674231e-06,
      "loss": 0.1591,
      "step": 18026
    },
    {
      "epoch": 1.4009170034193348,
      "grad_norm": 0.8268032670021057,
      "learning_rate": 2.9954149829033264e-06,
      "loss": 0.4336,
      "step": 18027
    },
    {
      "epoch": 1.4009947155735156,
      "grad_norm": 0.24846595525741577,
      "learning_rate": 2.9950264221324214e-06,
      "loss": 0.101,
      "step": 18028
    },
    {
      "epoch": 1.4010724277276967,
      "grad_norm": 0.38198867440223694,
      "learning_rate": 2.994637861361517e-06,
      "loss": 0.1167,
      "step": 18029
    },
    {
      "epoch": 1.4011501398818775,
      "grad_norm": 0.11012604832649231,
      "learning_rate": 2.9942493005906125e-06,
      "loss": 0.0097,
      "step": 18030
    },
    {
      "epoch": 1.4012278520360584,
      "grad_norm": 0.29212334752082825,
      "learning_rate": 2.993860739819708e-06,
      "loss": 0.0558,
      "step": 18031
    },
    {
      "epoch": 1.4013055641902392,
      "grad_norm": 0.6651459336280823,
      "learning_rate": 2.9934721790488037e-06,
      "loss": 0.2278,
      "step": 18032
    },
    {
      "epoch": 1.4013832763444203,
      "grad_norm": 0.3168894648551941,
      "learning_rate": 2.9930836182778987e-06,
      "loss": 0.0439,
      "step": 18033
    },
    {
      "epoch": 1.4014609884986011,
      "grad_norm": 0.7055875062942505,
      "learning_rate": 2.992695057506994e-06,
      "loss": 0.118,
      "step": 18034
    },
    {
      "epoch": 1.401538700652782,
      "grad_norm": 0.23069153726100922,
      "learning_rate": 2.99230649673609e-06,
      "loss": 0.0404,
      "step": 18035
    },
    {
      "epoch": 1.401616412806963,
      "grad_norm": 0.3277183175086975,
      "learning_rate": 2.991917935965185e-06,
      "loss": 0.1706,
      "step": 18036
    },
    {
      "epoch": 1.4016941249611439,
      "grad_norm": 0.014220310375094414,
      "learning_rate": 2.991529375194281e-06,
      "loss": 0.0007,
      "step": 18037
    },
    {
      "epoch": 1.4017718371153247,
      "grad_norm": 0.3120383620262146,
      "learning_rate": 2.991140814423376e-06,
      "loss": 0.1749,
      "step": 18038
    },
    {
      "epoch": 1.4018495492695058,
      "grad_norm": 0.6595560908317566,
      "learning_rate": 2.9907522536524713e-06,
      "loss": 0.2493,
      "step": 18039
    },
    {
      "epoch": 1.4019272614236866,
      "grad_norm": 0.643782377243042,
      "learning_rate": 2.990363692881567e-06,
      "loss": 0.198,
      "step": 18040
    },
    {
      "epoch": 1.4020049735778675,
      "grad_norm": 0.9737823605537415,
      "learning_rate": 2.9899751321106625e-06,
      "loss": 0.1246,
      "step": 18041
    },
    {
      "epoch": 1.4020826857320485,
      "grad_norm": 0.4087112843990326,
      "learning_rate": 2.9895865713397574e-06,
      "loss": 0.2354,
      "step": 18042
    },
    {
      "epoch": 1.4021603978862294,
      "grad_norm": 0.49360060691833496,
      "learning_rate": 2.9891980105688532e-06,
      "loss": 0.1123,
      "step": 18043
    },
    {
      "epoch": 1.4022381100404102,
      "grad_norm": 0.4704397916793823,
      "learning_rate": 2.9888094497979486e-06,
      "loss": 0.1071,
      "step": 18044
    },
    {
      "epoch": 1.4023158221945913,
      "grad_norm": 0.6287607550621033,
      "learning_rate": 2.988420889027044e-06,
      "loss": 0.2005,
      "step": 18045
    },
    {
      "epoch": 1.4023935343487721,
      "grad_norm": 0.10544812679290771,
      "learning_rate": 2.9880323282561398e-06,
      "loss": 0.0276,
      "step": 18046
    },
    {
      "epoch": 1.402471246502953,
      "grad_norm": 0.7624006867408752,
      "learning_rate": 2.9876437674852347e-06,
      "loss": 0.1121,
      "step": 18047
    },
    {
      "epoch": 1.402548958657134,
      "grad_norm": 0.8255311846733093,
      "learning_rate": 2.98725520671433e-06,
      "loss": 0.2047,
      "step": 18048
    },
    {
      "epoch": 1.4026266708113149,
      "grad_norm": 0.22132864594459534,
      "learning_rate": 2.986866645943426e-06,
      "loss": 0.0252,
      "step": 18049
    },
    {
      "epoch": 1.4027043829654957,
      "grad_norm": 0.6024606823921204,
      "learning_rate": 2.9864780851725213e-06,
      "loss": 0.2158,
      "step": 18050
    },
    {
      "epoch": 1.4027820951196768,
      "grad_norm": 0.6106705665588379,
      "learning_rate": 2.986089524401617e-06,
      "loss": 0.3094,
      "step": 18051
    },
    {
      "epoch": 1.4028598072738576,
      "grad_norm": 2.0160369873046875,
      "learning_rate": 2.985700963630712e-06,
      "loss": 0.3275,
      "step": 18052
    },
    {
      "epoch": 1.4029375194280385,
      "grad_norm": 0.14191687107086182,
      "learning_rate": 2.9853124028598074e-06,
      "loss": 0.0333,
      "step": 18053
    },
    {
      "epoch": 1.4030152315822195,
      "grad_norm": 0.23450875282287598,
      "learning_rate": 2.984923842088903e-06,
      "loss": 0.0494,
      "step": 18054
    },
    {
      "epoch": 1.4030929437364004,
      "grad_norm": 0.34779781103134155,
      "learning_rate": 2.9845352813179986e-06,
      "loss": 0.0576,
      "step": 18055
    },
    {
      "epoch": 1.4031706558905812,
      "grad_norm": 0.27103301882743835,
      "learning_rate": 2.9841467205470935e-06,
      "loss": 0.0834,
      "step": 18056
    },
    {
      "epoch": 1.4032483680447623,
      "grad_norm": 0.7775918245315552,
      "learning_rate": 2.9837581597761893e-06,
      "loss": 0.2654,
      "step": 18057
    },
    {
      "epoch": 1.4033260801989431,
      "grad_norm": 0.8158887028694153,
      "learning_rate": 2.9833695990052847e-06,
      "loss": 0.0856,
      "step": 18058
    },
    {
      "epoch": 1.403403792353124,
      "grad_norm": 0.44496920704841614,
      "learning_rate": 2.98298103823438e-06,
      "loss": 0.5692,
      "step": 18059
    },
    {
      "epoch": 1.403481504507305,
      "grad_norm": 0.22319307923316956,
      "learning_rate": 2.982592477463476e-06,
      "loss": 0.0332,
      "step": 18060
    },
    {
      "epoch": 1.4035592166614859,
      "grad_norm": 0.49782025814056396,
      "learning_rate": 2.982203916692571e-06,
      "loss": 0.6025,
      "step": 18061
    },
    {
      "epoch": 1.4036369288156667,
      "grad_norm": 0.2362229973077774,
      "learning_rate": 2.981815355921666e-06,
      "loss": 0.0347,
      "step": 18062
    },
    {
      "epoch": 1.4037146409698478,
      "grad_norm": 0.664010763168335,
      "learning_rate": 2.981426795150762e-06,
      "loss": 0.1954,
      "step": 18063
    },
    {
      "epoch": 1.4037923531240286,
      "grad_norm": 0.3760473430156708,
      "learning_rate": 2.9810382343798573e-06,
      "loss": 0.0842,
      "step": 18064
    },
    {
      "epoch": 1.4038700652782095,
      "grad_norm": 0.22489498555660248,
      "learning_rate": 2.9806496736089523e-06,
      "loss": 0.021,
      "step": 18065
    },
    {
      "epoch": 1.4039477774323905,
      "grad_norm": 2.109210252761841,
      "learning_rate": 2.980261112838048e-06,
      "loss": 0.358,
      "step": 18066
    },
    {
      "epoch": 1.4040254895865714,
      "grad_norm": 0.3101440668106079,
      "learning_rate": 2.9798725520671435e-06,
      "loss": 0.0517,
      "step": 18067
    },
    {
      "epoch": 1.4041032017407522,
      "grad_norm": 0.5203269720077515,
      "learning_rate": 2.9794839912962393e-06,
      "loss": 0.1416,
      "step": 18068
    },
    {
      "epoch": 1.4041809138949333,
      "grad_norm": 0.2849682867527008,
      "learning_rate": 2.9790954305253346e-06,
      "loss": 0.1512,
      "step": 18069
    },
    {
      "epoch": 1.4042586260491141,
      "grad_norm": 0.3862346112728119,
      "learning_rate": 2.9787068697544296e-06,
      "loss": 0.0682,
      "step": 18070
    },
    {
      "epoch": 1.404336338203295,
      "grad_norm": 0.7628145813941956,
      "learning_rate": 2.9783183089835254e-06,
      "loss": 0.6945,
      "step": 18071
    },
    {
      "epoch": 1.404414050357476,
      "grad_norm": 0.23178811371326447,
      "learning_rate": 2.9779297482126208e-06,
      "loss": 0.0193,
      "step": 18072
    },
    {
      "epoch": 1.4044917625116569,
      "grad_norm": 0.32678744196891785,
      "learning_rate": 2.977541187441716e-06,
      "loss": 0.1311,
      "step": 18073
    },
    {
      "epoch": 1.4045694746658377,
      "grad_norm": 0.5941359400749207,
      "learning_rate": 2.977152626670812e-06,
      "loss": 0.2954,
      "step": 18074
    },
    {
      "epoch": 1.4046471868200188,
      "grad_norm": 0.40122929215431213,
      "learning_rate": 2.976764065899907e-06,
      "loss": 0.1186,
      "step": 18075
    },
    {
      "epoch": 1.4047248989741996,
      "grad_norm": 0.33897820115089417,
      "learning_rate": 2.9763755051290022e-06,
      "loss": 0.0763,
      "step": 18076
    },
    {
      "epoch": 1.4048026111283805,
      "grad_norm": 0.6768779158592224,
      "learning_rate": 2.975986944358098e-06,
      "loss": 0.1483,
      "step": 18077
    },
    {
      "epoch": 1.4048803232825615,
      "grad_norm": 0.4303878843784332,
      "learning_rate": 2.9755983835871934e-06,
      "loss": 0.1011,
      "step": 18078
    },
    {
      "epoch": 1.4049580354367424,
      "grad_norm": 0.5746809244155884,
      "learning_rate": 2.9752098228162884e-06,
      "loss": 0.4051,
      "step": 18079
    },
    {
      "epoch": 1.4050357475909232,
      "grad_norm": 0.48575469851493835,
      "learning_rate": 2.974821262045384e-06,
      "loss": 0.044,
      "step": 18080
    },
    {
      "epoch": 1.4051134597451043,
      "grad_norm": 0.1897677481174469,
      "learning_rate": 2.9744327012744795e-06,
      "loss": 0.0538,
      "step": 18081
    },
    {
      "epoch": 1.405191171899285,
      "grad_norm": 0.27980470657348633,
      "learning_rate": 2.9740441405035753e-06,
      "loss": 0.1046,
      "step": 18082
    },
    {
      "epoch": 1.405268884053466,
      "grad_norm": 0.6894399523735046,
      "learning_rate": 2.9736555797326707e-06,
      "loss": 0.1839,
      "step": 18083
    },
    {
      "epoch": 1.405346596207647,
      "grad_norm": 1.139000654220581,
      "learning_rate": 2.9732670189617657e-06,
      "loss": 0.3371,
      "step": 18084
    },
    {
      "epoch": 1.4054243083618279,
      "grad_norm": 0.4679091274738312,
      "learning_rate": 2.9728784581908615e-06,
      "loss": 0.6191,
      "step": 18085
    },
    {
      "epoch": 1.4055020205160087,
      "grad_norm": 0.17402879893779755,
      "learning_rate": 2.972489897419957e-06,
      "loss": 0.0294,
      "step": 18086
    },
    {
      "epoch": 1.4055797326701895,
      "grad_norm": 0.9727376103401184,
      "learning_rate": 2.9721013366490518e-06,
      "loss": 0.2991,
      "step": 18087
    },
    {
      "epoch": 1.4056574448243706,
      "grad_norm": 1.0754382610321045,
      "learning_rate": 2.9717127758781476e-06,
      "loss": 0.4381,
      "step": 18088
    },
    {
      "epoch": 1.4057351569785514,
      "grad_norm": 0.8539831042289734,
      "learning_rate": 2.971324215107243e-06,
      "loss": 0.1286,
      "step": 18089
    },
    {
      "epoch": 1.4058128691327323,
      "grad_norm": 0.3782465159893036,
      "learning_rate": 2.9709356543363383e-06,
      "loss": 0.1204,
      "step": 18090
    },
    {
      "epoch": 1.4058905812869134,
      "grad_norm": 0.21206100285053253,
      "learning_rate": 2.970547093565434e-06,
      "loss": 0.0267,
      "step": 18091
    },
    {
      "epoch": 1.4059682934410942,
      "grad_norm": 0.6089532375335693,
      "learning_rate": 2.970158532794529e-06,
      "loss": 0.1696,
      "step": 18092
    },
    {
      "epoch": 1.406046005595275,
      "grad_norm": 0.7846524119377136,
      "learning_rate": 2.9697699720236244e-06,
      "loss": 0.1875,
      "step": 18093
    },
    {
      "epoch": 1.4061237177494559,
      "grad_norm": 0.24356234073638916,
      "learning_rate": 2.9693814112527202e-06,
      "loss": 0.1238,
      "step": 18094
    },
    {
      "epoch": 1.406201429903637,
      "grad_norm": 1.9596400260925293,
      "learning_rate": 2.9689928504818156e-06,
      "loss": 0.7783,
      "step": 18095
    },
    {
      "epoch": 1.4062791420578178,
      "grad_norm": 0.4157353639602661,
      "learning_rate": 2.9686042897109114e-06,
      "loss": 0.1534,
      "step": 18096
    },
    {
      "epoch": 1.4063568542119986,
      "grad_norm": 0.1099167913198471,
      "learning_rate": 2.9682157289400064e-06,
      "loss": 0.023,
      "step": 18097
    },
    {
      "epoch": 1.4064345663661797,
      "grad_norm": 0.511041522026062,
      "learning_rate": 2.9678271681691017e-06,
      "loss": 0.3381,
      "step": 18098
    },
    {
      "epoch": 1.4065122785203605,
      "grad_norm": 0.44044938683509827,
      "learning_rate": 2.9674386073981975e-06,
      "loss": 0.456,
      "step": 18099
    },
    {
      "epoch": 1.4065899906745414,
      "grad_norm": 0.5857731103897095,
      "learning_rate": 2.967050046627293e-06,
      "loss": 0.5414,
      "step": 18100
    },
    {
      "epoch": 1.4066677028287224,
      "grad_norm": 0.5082346200942993,
      "learning_rate": 2.966661485856388e-06,
      "loss": 0.3164,
      "step": 18101
    },
    {
      "epoch": 1.4067454149829033,
      "grad_norm": 0.6739513278007507,
      "learning_rate": 2.9662729250854836e-06,
      "loss": 0.1443,
      "step": 18102
    },
    {
      "epoch": 1.4068231271370841,
      "grad_norm": 0.3273468017578125,
      "learning_rate": 2.965884364314579e-06,
      "loss": 0.1663,
      "step": 18103
    },
    {
      "epoch": 1.4069008392912652,
      "grad_norm": 0.20365822315216064,
      "learning_rate": 2.9654958035436744e-06,
      "loss": 0.0147,
      "step": 18104
    },
    {
      "epoch": 1.406978551445446,
      "grad_norm": 1.0016955137252808,
      "learning_rate": 2.96510724277277e-06,
      "loss": 0.4209,
      "step": 18105
    },
    {
      "epoch": 1.4070562635996269,
      "grad_norm": 0.5044521689414978,
      "learning_rate": 2.964718682001865e-06,
      "loss": 0.0721,
      "step": 18106
    },
    {
      "epoch": 1.407133975753808,
      "grad_norm": 0.1401035189628601,
      "learning_rate": 2.9643301212309605e-06,
      "loss": 0.0589,
      "step": 18107
    },
    {
      "epoch": 1.4072116879079888,
      "grad_norm": 0.3835049867630005,
      "learning_rate": 2.9639415604600563e-06,
      "loss": 0.1066,
      "step": 18108
    },
    {
      "epoch": 1.4072894000621696,
      "grad_norm": 0.07672303169965744,
      "learning_rate": 2.9635529996891517e-06,
      "loss": 0.0154,
      "step": 18109
    },
    {
      "epoch": 1.4073671122163507,
      "grad_norm": 0.1439792960882187,
      "learning_rate": 2.9631644389182466e-06,
      "loss": 0.0171,
      "step": 18110
    },
    {
      "epoch": 1.4074448243705315,
      "grad_norm": 0.3767731189727783,
      "learning_rate": 2.9627758781473424e-06,
      "loss": 0.1084,
      "step": 18111
    },
    {
      "epoch": 1.4075225365247124,
      "grad_norm": 0.15137742459774017,
      "learning_rate": 2.962387317376438e-06,
      "loss": 0.0421,
      "step": 18112
    },
    {
      "epoch": 1.4076002486788934,
      "grad_norm": 0.7722730040550232,
      "learning_rate": 2.9619987566055336e-06,
      "loss": 0.1224,
      "step": 18113
    },
    {
      "epoch": 1.4076779608330743,
      "grad_norm": 0.13426324725151062,
      "learning_rate": 2.961610195834629e-06,
      "loss": 0.0613,
      "step": 18114
    },
    {
      "epoch": 1.4077556729872551,
      "grad_norm": 0.30924731492996216,
      "learning_rate": 2.961221635063724e-06,
      "loss": 0.0907,
      "step": 18115
    },
    {
      "epoch": 1.4078333851414362,
      "grad_norm": 0.7056389451026917,
      "learning_rate": 2.9608330742928197e-06,
      "loss": 0.3284,
      "step": 18116
    },
    {
      "epoch": 1.407911097295617,
      "grad_norm": 0.9243276715278625,
      "learning_rate": 2.960444513521915e-06,
      "loss": 0.9652,
      "step": 18117
    },
    {
      "epoch": 1.4079888094497979,
      "grad_norm": 0.4131266176700592,
      "learning_rate": 2.9600559527510105e-06,
      "loss": 0.1029,
      "step": 18118
    },
    {
      "epoch": 1.408066521603979,
      "grad_norm": 0.24584868550300598,
      "learning_rate": 2.9596673919801063e-06,
      "loss": 0.0834,
      "step": 18119
    },
    {
      "epoch": 1.4081442337581598,
      "grad_norm": 0.8044934868812561,
      "learning_rate": 2.959278831209201e-06,
      "loss": 0.1705,
      "step": 18120
    },
    {
      "epoch": 1.4082219459123406,
      "grad_norm": 0.48021650314331055,
      "learning_rate": 2.9588902704382966e-06,
      "loss": 0.2668,
      "step": 18121
    },
    {
      "epoch": 1.4082996580665217,
      "grad_norm": 0.44512805342674255,
      "learning_rate": 2.9585017096673924e-06,
      "loss": 0.3404,
      "step": 18122
    },
    {
      "epoch": 1.4083773702207025,
      "grad_norm": 0.15722152590751648,
      "learning_rate": 2.9581131488964878e-06,
      "loss": 0.0277,
      "step": 18123
    },
    {
      "epoch": 1.4084550823748834,
      "grad_norm": 0.7603903412818909,
      "learning_rate": 2.9577245881255827e-06,
      "loss": 0.1552,
      "step": 18124
    },
    {
      "epoch": 1.4085327945290644,
      "grad_norm": 0.3124036490917206,
      "learning_rate": 2.9573360273546785e-06,
      "loss": 0.4354,
      "step": 18125
    },
    {
      "epoch": 1.4086105066832453,
      "grad_norm": 0.25407013297080994,
      "learning_rate": 2.956947466583774e-06,
      "loss": 0.1165,
      "step": 18126
    },
    {
      "epoch": 1.4086882188374261,
      "grad_norm": 0.9031689763069153,
      "learning_rate": 2.9565589058128697e-06,
      "loss": 0.3034,
      "step": 18127
    },
    {
      "epoch": 1.4087659309916072,
      "grad_norm": 0.8496978878974915,
      "learning_rate": 2.956170345041965e-06,
      "loss": 0.0882,
      "step": 18128
    },
    {
      "epoch": 1.408843643145788,
      "grad_norm": 0.8254690766334534,
      "learning_rate": 2.95578178427106e-06,
      "loss": 0.5106,
      "step": 18129
    },
    {
      "epoch": 1.4089213552999689,
      "grad_norm": 0.9936169385910034,
      "learning_rate": 2.955393223500156e-06,
      "loss": 0.3251,
      "step": 18130
    },
    {
      "epoch": 1.40899906745415,
      "grad_norm": 0.2579157054424286,
      "learning_rate": 2.955004662729251e-06,
      "loss": 0.1421,
      "step": 18131
    },
    {
      "epoch": 1.4090767796083308,
      "grad_norm": 0.48096632957458496,
      "learning_rate": 2.9546161019583465e-06,
      "loss": 0.5388,
      "step": 18132
    },
    {
      "epoch": 1.4091544917625116,
      "grad_norm": 0.7492139935493469,
      "learning_rate": 2.9542275411874423e-06,
      "loss": 0.5401,
      "step": 18133
    },
    {
      "epoch": 1.4092322039166927,
      "grad_norm": 0.5537819862365723,
      "learning_rate": 2.9538389804165373e-06,
      "loss": 0.6218,
      "step": 18134
    },
    {
      "epoch": 1.4093099160708735,
      "grad_norm": 0.20602300763130188,
      "learning_rate": 2.9534504196456327e-06,
      "loss": 0.0865,
      "step": 18135
    },
    {
      "epoch": 1.4093876282250544,
      "grad_norm": 1.1183446645736694,
      "learning_rate": 2.9530618588747285e-06,
      "loss": 0.4667,
      "step": 18136
    },
    {
      "epoch": 1.4094653403792354,
      "grad_norm": 0.3103838860988617,
      "learning_rate": 2.952673298103824e-06,
      "loss": 0.0826,
      "step": 18137
    },
    {
      "epoch": 1.4095430525334163,
      "grad_norm": 0.48007190227508545,
      "learning_rate": 2.9522847373329188e-06,
      "loss": 0.2945,
      "step": 18138
    },
    {
      "epoch": 1.4096207646875971,
      "grad_norm": 0.4747416377067566,
      "learning_rate": 2.9518961765620146e-06,
      "loss": 0.2727,
      "step": 18139
    },
    {
      "epoch": 1.4096984768417782,
      "grad_norm": 1.4660024642944336,
      "learning_rate": 2.95150761579111e-06,
      "loss": 0.3646,
      "step": 18140
    },
    {
      "epoch": 1.409776188995959,
      "grad_norm": 0.7340928316116333,
      "learning_rate": 2.9511190550202053e-06,
      "loss": 0.1307,
      "step": 18141
    },
    {
      "epoch": 1.4098539011501399,
      "grad_norm": 0.42181602120399475,
      "learning_rate": 2.950730494249301e-06,
      "loss": 0.0618,
      "step": 18142
    },
    {
      "epoch": 1.409931613304321,
      "grad_norm": 0.2158837914466858,
      "learning_rate": 2.950341933478396e-06,
      "loss": 0.0565,
      "step": 18143
    },
    {
      "epoch": 1.4100093254585018,
      "grad_norm": 0.5731122493743896,
      "learning_rate": 2.949953372707492e-06,
      "loss": 0.1749,
      "step": 18144
    },
    {
      "epoch": 1.4100870376126826,
      "grad_norm": 0.14541743695735931,
      "learning_rate": 2.9495648119365872e-06,
      "loss": 0.0136,
      "step": 18145
    },
    {
      "epoch": 1.4101647497668635,
      "grad_norm": 0.23156628012657166,
      "learning_rate": 2.9491762511656826e-06,
      "loss": 0.0219,
      "step": 18146
    },
    {
      "epoch": 1.4102424619210445,
      "grad_norm": 0.30031153559684753,
      "learning_rate": 2.948787690394778e-06,
      "loss": 0.0815,
      "step": 18147
    },
    {
      "epoch": 1.4103201740752254,
      "grad_norm": 0.6785681247711182,
      "learning_rate": 2.9483991296238734e-06,
      "loss": 0.0644,
      "step": 18148
    },
    {
      "epoch": 1.4103978862294062,
      "grad_norm": 0.7330092787742615,
      "learning_rate": 2.9480105688529687e-06,
      "loss": 0.2809,
      "step": 18149
    },
    {
      "epoch": 1.4104755983835873,
      "grad_norm": 0.2960878610610962,
      "learning_rate": 2.9476220080820645e-06,
      "loss": 0.0466,
      "step": 18150
    },
    {
      "epoch": 1.4105533105377681,
      "grad_norm": 0.15217140316963196,
      "learning_rate": 2.9472334473111595e-06,
      "loss": 0.0159,
      "step": 18151
    },
    {
      "epoch": 1.410631022691949,
      "grad_norm": 0.5728352069854736,
      "learning_rate": 2.946844886540255e-06,
      "loss": 0.1794,
      "step": 18152
    },
    {
      "epoch": 1.4107087348461298,
      "grad_norm": 0.23758602142333984,
      "learning_rate": 2.9464563257693506e-06,
      "loss": 0.0681,
      "step": 18153
    },
    {
      "epoch": 1.4107864470003109,
      "grad_norm": 0.4144122302532196,
      "learning_rate": 2.946067764998446e-06,
      "loss": 0.0674,
      "step": 18154
    },
    {
      "epoch": 1.4108641591544917,
      "grad_norm": 0.747061550617218,
      "learning_rate": 2.945679204227541e-06,
      "loss": 0.6574,
      "step": 18155
    },
    {
      "epoch": 1.4109418713086725,
      "grad_norm": 0.6196208596229553,
      "learning_rate": 2.9452906434566368e-06,
      "loss": 0.3024,
      "step": 18156
    },
    {
      "epoch": 1.4110195834628536,
      "grad_norm": 0.10637164115905762,
      "learning_rate": 2.944902082685732e-06,
      "loss": 0.0341,
      "step": 18157
    },
    {
      "epoch": 1.4110972956170345,
      "grad_norm": 0.30545562505722046,
      "learning_rate": 2.944513521914828e-06,
      "loss": 0.1092,
      "step": 18158
    },
    {
      "epoch": 1.4111750077712153,
      "grad_norm": 1.006428599357605,
      "learning_rate": 2.9441249611439233e-06,
      "loss": 0.4913,
      "step": 18159
    },
    {
      "epoch": 1.4112527199253964,
      "grad_norm": 0.5431953072547913,
      "learning_rate": 2.9437364003730183e-06,
      "loss": 0.5662,
      "step": 18160
    },
    {
      "epoch": 1.4113304320795772,
      "grad_norm": 0.6191220879554749,
      "learning_rate": 2.943347839602114e-06,
      "loss": 0.6104,
      "step": 18161
    },
    {
      "epoch": 1.411408144233758,
      "grad_norm": 0.3269858956336975,
      "learning_rate": 2.9429592788312094e-06,
      "loss": 0.1422,
      "step": 18162
    },
    {
      "epoch": 1.411485856387939,
      "grad_norm": 0.28281643986701965,
      "learning_rate": 2.942570718060305e-06,
      "loss": 0.0834,
      "step": 18163
    },
    {
      "epoch": 1.41156356854212,
      "grad_norm": 0.7395737767219543,
      "learning_rate": 2.9421821572894006e-06,
      "loss": 0.0408,
      "step": 18164
    },
    {
      "epoch": 1.4116412806963008,
      "grad_norm": 0.18109995126724243,
      "learning_rate": 2.9417935965184956e-06,
      "loss": 0.042,
      "step": 18165
    },
    {
      "epoch": 1.4117189928504819,
      "grad_norm": 0.6024125814437866,
      "learning_rate": 2.941405035747591e-06,
      "loss": 0.0971,
      "step": 18166
    },
    {
      "epoch": 1.4117967050046627,
      "grad_norm": 0.16746993362903595,
      "learning_rate": 2.9410164749766867e-06,
      "loss": 0.0467,
      "step": 18167
    },
    {
      "epoch": 1.4118744171588435,
      "grad_norm": 0.040349800139665604,
      "learning_rate": 2.940627914205782e-06,
      "loss": 0.0068,
      "step": 18168
    },
    {
      "epoch": 1.4119521293130246,
      "grad_norm": 0.09768757969141006,
      "learning_rate": 2.940239353434877e-06,
      "loss": 0.0204,
      "step": 18169
    },
    {
      "epoch": 1.4120298414672054,
      "grad_norm": 0.6344221234321594,
      "learning_rate": 2.939850792663973e-06,
      "loss": 0.2031,
      "step": 18170
    },
    {
      "epoch": 1.4121075536213863,
      "grad_norm": 0.3443296551704407,
      "learning_rate": 2.9394622318930682e-06,
      "loss": 0.2094,
      "step": 18171
    },
    {
      "epoch": 1.4121852657755674,
      "grad_norm": 0.7158508896827698,
      "learning_rate": 2.939073671122164e-06,
      "loss": 0.1978,
      "step": 18172
    },
    {
      "epoch": 1.4122629779297482,
      "grad_norm": 0.21916162967681885,
      "learning_rate": 2.9386851103512594e-06,
      "loss": 0.0417,
      "step": 18173
    },
    {
      "epoch": 1.412340690083929,
      "grad_norm": 0.2957862317562103,
      "learning_rate": 2.9382965495803543e-06,
      "loss": 0.0395,
      "step": 18174
    },
    {
      "epoch": 1.41241840223811,
      "grad_norm": 0.7298255562782288,
      "learning_rate": 2.93790798880945e-06,
      "loss": 0.3963,
      "step": 18175
    },
    {
      "epoch": 1.412496114392291,
      "grad_norm": 0.22472448647022247,
      "learning_rate": 2.9375194280385455e-06,
      "loss": 0.0356,
      "step": 18176
    },
    {
      "epoch": 1.4125738265464718,
      "grad_norm": 0.27467888593673706,
      "learning_rate": 2.937130867267641e-06,
      "loss": 0.0382,
      "step": 18177
    },
    {
      "epoch": 1.4126515387006529,
      "grad_norm": 0.33322206139564514,
      "learning_rate": 2.9367423064967367e-06,
      "loss": 0.0708,
      "step": 18178
    },
    {
      "epoch": 1.4127292508548337,
      "grad_norm": 0.4854067265987396,
      "learning_rate": 2.9363537457258316e-06,
      "loss": 0.0637,
      "step": 18179
    },
    {
      "epoch": 1.4128069630090145,
      "grad_norm": 0.6917986273765564,
      "learning_rate": 2.935965184954927e-06,
      "loss": 0.3334,
      "step": 18180
    },
    {
      "epoch": 1.4128846751631956,
      "grad_norm": 0.23821020126342773,
      "learning_rate": 2.935576624184023e-06,
      "loss": 0.0724,
      "step": 18181
    },
    {
      "epoch": 1.4129623873173764,
      "grad_norm": 0.4040343463420868,
      "learning_rate": 2.935188063413118e-06,
      "loss": 0.0737,
      "step": 18182
    },
    {
      "epoch": 1.4130400994715573,
      "grad_norm": 1.0757290124893188,
      "learning_rate": 2.934799502642213e-06,
      "loss": 0.3486,
      "step": 18183
    },
    {
      "epoch": 1.4131178116257384,
      "grad_norm": 0.3674798905849457,
      "learning_rate": 2.934410941871309e-06,
      "loss": 0.0966,
      "step": 18184
    },
    {
      "epoch": 1.4131955237799192,
      "grad_norm": 0.7159333229064941,
      "learning_rate": 2.9340223811004043e-06,
      "loss": 0.2757,
      "step": 18185
    },
    {
      "epoch": 1.4132732359341,
      "grad_norm": 0.7817009091377258,
      "learning_rate": 2.9336338203294997e-06,
      "loss": 0.2881,
      "step": 18186
    },
    {
      "epoch": 1.413350948088281,
      "grad_norm": 0.211355522274971,
      "learning_rate": 2.9332452595585955e-06,
      "loss": 0.0306,
      "step": 18187
    },
    {
      "epoch": 1.413428660242462,
      "grad_norm": 0.7075680494308472,
      "learning_rate": 2.9328566987876904e-06,
      "loss": 0.3688,
      "step": 18188
    },
    {
      "epoch": 1.4135063723966428,
      "grad_norm": 0.17153355479240417,
      "learning_rate": 2.932468138016786e-06,
      "loss": 0.025,
      "step": 18189
    },
    {
      "epoch": 1.4135840845508238,
      "grad_norm": 0.7222134470939636,
      "learning_rate": 2.9320795772458816e-06,
      "loss": 0.152,
      "step": 18190
    },
    {
      "epoch": 1.4136617967050047,
      "grad_norm": 3.9452176094055176,
      "learning_rate": 2.931691016474977e-06,
      "loss": 0.8254,
      "step": 18191
    },
    {
      "epoch": 1.4137395088591855,
      "grad_norm": 0.06258261203765869,
      "learning_rate": 2.9313024557040727e-06,
      "loss": 0.0119,
      "step": 18192
    },
    {
      "epoch": 1.4138172210133666,
      "grad_norm": 0.3862065374851227,
      "learning_rate": 2.9309138949331677e-06,
      "loss": 0.0647,
      "step": 18193
    },
    {
      "epoch": 1.4138949331675474,
      "grad_norm": 0.07671447843313217,
      "learning_rate": 2.930525334162263e-06,
      "loss": 0.0151,
      "step": 18194
    },
    {
      "epoch": 1.4139726453217283,
      "grad_norm": 0.5144354104995728,
      "learning_rate": 2.930136773391359e-06,
      "loss": 0.1673,
      "step": 18195
    },
    {
      "epoch": 1.4140503574759093,
      "grad_norm": 0.43722769618034363,
      "learning_rate": 2.9297482126204542e-06,
      "loss": 0.1199,
      "step": 18196
    },
    {
      "epoch": 1.4141280696300902,
      "grad_norm": 0.4922696352005005,
      "learning_rate": 2.929359651849549e-06,
      "loss": 0.1588,
      "step": 18197
    },
    {
      "epoch": 1.414205781784271,
      "grad_norm": 0.27073660492897034,
      "learning_rate": 2.928971091078645e-06,
      "loss": 0.0715,
      "step": 18198
    },
    {
      "epoch": 1.414283493938452,
      "grad_norm": 0.44974714517593384,
      "learning_rate": 2.9285825303077404e-06,
      "loss": 0.2539,
      "step": 18199
    },
    {
      "epoch": 1.414361206092633,
      "grad_norm": 0.3307948410511017,
      "learning_rate": 2.9281939695368357e-06,
      "loss": 0.1494,
      "step": 18200
    },
    {
      "epoch": 1.4144389182468138,
      "grad_norm": 0.6733311414718628,
      "learning_rate": 2.9278054087659315e-06,
      "loss": 0.3702,
      "step": 18201
    },
    {
      "epoch": 1.4145166304009948,
      "grad_norm": 0.4888620972633362,
      "learning_rate": 2.9274168479950265e-06,
      "loss": 0.1595,
      "step": 18202
    },
    {
      "epoch": 1.4145943425551757,
      "grad_norm": 0.6346556544303894,
      "learning_rate": 2.9270282872241223e-06,
      "loss": 0.2521,
      "step": 18203
    },
    {
      "epoch": 1.4146720547093565,
      "grad_norm": 0.7654832005500793,
      "learning_rate": 2.9266397264532176e-06,
      "loss": 0.3325,
      "step": 18204
    },
    {
      "epoch": 1.4147497668635376,
      "grad_norm": 0.12848684191703796,
      "learning_rate": 2.926251165682313e-06,
      "loss": 0.0277,
      "step": 18205
    },
    {
      "epoch": 1.4148274790177184,
      "grad_norm": 0.6720291376113892,
      "learning_rate": 2.925862604911409e-06,
      "loss": 0.3168,
      "step": 18206
    },
    {
      "epoch": 1.4149051911718993,
      "grad_norm": 0.2434735894203186,
      "learning_rate": 2.9254740441405038e-06,
      "loss": 0.1107,
      "step": 18207
    },
    {
      "epoch": 1.4149829033260801,
      "grad_norm": 0.6636645197868347,
      "learning_rate": 2.925085483369599e-06,
      "loss": 0.2893,
      "step": 18208
    },
    {
      "epoch": 1.4150606154802612,
      "grad_norm": 0.6224380731582642,
      "learning_rate": 2.924696922598695e-06,
      "loss": 0.1839,
      "step": 18209
    },
    {
      "epoch": 1.415138327634442,
      "grad_norm": 0.6829429268836975,
      "learning_rate": 2.92430836182779e-06,
      "loss": 0.3071,
      "step": 18210
    },
    {
      "epoch": 1.4152160397886229,
      "grad_norm": 0.3907619118690491,
      "learning_rate": 2.9239198010568853e-06,
      "loss": 0.3583,
      "step": 18211
    },
    {
      "epoch": 1.415293751942804,
      "grad_norm": 0.016389604657888412,
      "learning_rate": 2.923531240285981e-06,
      "loss": 0.0004,
      "step": 18212
    },
    {
      "epoch": 1.4153714640969848,
      "grad_norm": 0.8729456067085266,
      "learning_rate": 2.9231426795150764e-06,
      "loss": 0.1747,
      "step": 18213
    },
    {
      "epoch": 1.4154491762511656,
      "grad_norm": 0.34354498982429504,
      "learning_rate": 2.9227541187441714e-06,
      "loss": 0.0773,
      "step": 18214
    },
    {
      "epoch": 1.4155268884053465,
      "grad_norm": 0.4412819743156433,
      "learning_rate": 2.922365557973267e-06,
      "loss": 0.238,
      "step": 18215
    },
    {
      "epoch": 1.4156046005595275,
      "grad_norm": 0.6697381138801575,
      "learning_rate": 2.9219769972023626e-06,
      "loss": 0.2515,
      "step": 18216
    },
    {
      "epoch": 1.4156823127137084,
      "grad_norm": 1.521601915359497,
      "learning_rate": 2.921588436431458e-06,
      "loss": 0.5049,
      "step": 18217
    },
    {
      "epoch": 1.4157600248678892,
      "grad_norm": 0.6111921072006226,
      "learning_rate": 2.9211998756605537e-06,
      "loss": 0.691,
      "step": 18218
    },
    {
      "epoch": 1.4158377370220703,
      "grad_norm": 0.2456510066986084,
      "learning_rate": 2.9208113148896487e-06,
      "loss": 0.0571,
      "step": 18219
    },
    {
      "epoch": 1.4159154491762511,
      "grad_norm": 0.1661979705095291,
      "learning_rate": 2.9204227541187445e-06,
      "loss": 0.0442,
      "step": 18220
    },
    {
      "epoch": 1.415993161330432,
      "grad_norm": 0.2775003910064697,
      "learning_rate": 2.92003419334784e-06,
      "loss": 0.0583,
      "step": 18221
    },
    {
      "epoch": 1.416070873484613,
      "grad_norm": 0.31319311261177063,
      "learning_rate": 2.9196456325769352e-06,
      "loss": 0.2281,
      "step": 18222
    },
    {
      "epoch": 1.4161485856387939,
      "grad_norm": 0.36606937646865845,
      "learning_rate": 2.919257071806031e-06,
      "loss": 0.197,
      "step": 18223
    },
    {
      "epoch": 1.4162262977929747,
      "grad_norm": 1.1424739360809326,
      "learning_rate": 2.918868511035126e-06,
      "loss": 0.3995,
      "step": 18224
    },
    {
      "epoch": 1.4163040099471558,
      "grad_norm": 0.4493125081062317,
      "learning_rate": 2.9184799502642213e-06,
      "loss": 0.3416,
      "step": 18225
    },
    {
      "epoch": 1.4163817221013366,
      "grad_norm": 0.7462398409843445,
      "learning_rate": 2.918091389493317e-06,
      "loss": 0.089,
      "step": 18226
    },
    {
      "epoch": 1.4164594342555175,
      "grad_norm": 0.6731734871864319,
      "learning_rate": 2.9177028287224125e-06,
      "loss": 0.19,
      "step": 18227
    },
    {
      "epoch": 1.4165371464096985,
      "grad_norm": 0.08669421076774597,
      "learning_rate": 2.9173142679515075e-06,
      "loss": 0.0074,
      "step": 18228
    },
    {
      "epoch": 1.4166148585638794,
      "grad_norm": 0.9690966010093689,
      "learning_rate": 2.9169257071806033e-06,
      "loss": 0.1143,
      "step": 18229
    },
    {
      "epoch": 1.4166925707180602,
      "grad_norm": 0.40727177262306213,
      "learning_rate": 2.9165371464096986e-06,
      "loss": 0.1306,
      "step": 18230
    },
    {
      "epoch": 1.4167702828722413,
      "grad_norm": 0.5271175503730774,
      "learning_rate": 2.916148585638794e-06,
      "loss": 0.2183,
      "step": 18231
    },
    {
      "epoch": 1.4168479950264221,
      "grad_norm": 0.9270771741867065,
      "learning_rate": 2.91576002486789e-06,
      "loss": 0.4549,
      "step": 18232
    },
    {
      "epoch": 1.416925707180603,
      "grad_norm": 0.1007240042090416,
      "learning_rate": 2.9153714640969847e-06,
      "loss": 0.015,
      "step": 18233
    },
    {
      "epoch": 1.417003419334784,
      "grad_norm": 0.4365922510623932,
      "learning_rate": 2.9149829033260805e-06,
      "loss": 0.0402,
      "step": 18234
    },
    {
      "epoch": 1.4170811314889649,
      "grad_norm": 0.2767946422100067,
      "learning_rate": 2.914594342555176e-06,
      "loss": 0.1358,
      "step": 18235
    },
    {
      "epoch": 1.4171588436431457,
      "grad_norm": 0.7699387669563293,
      "learning_rate": 2.9142057817842713e-06,
      "loss": 0.402,
      "step": 18236
    },
    {
      "epoch": 1.4172365557973268,
      "grad_norm": 0.3963078558444977,
      "learning_rate": 2.913817221013367e-06,
      "loss": 0.1302,
      "step": 18237
    },
    {
      "epoch": 1.4173142679515076,
      "grad_norm": 0.7247369885444641,
      "learning_rate": 2.913428660242462e-06,
      "loss": 0.1651,
      "step": 18238
    },
    {
      "epoch": 1.4173919801056885,
      "grad_norm": 0.0999656468629837,
      "learning_rate": 2.9130400994715574e-06,
      "loss": 0.0189,
      "step": 18239
    },
    {
      "epoch": 1.4174696922598695,
      "grad_norm": 0.6253836154937744,
      "learning_rate": 2.912651538700653e-06,
      "loss": 0.255,
      "step": 18240
    },
    {
      "epoch": 1.4175474044140504,
      "grad_norm": 0.3788813054561615,
      "learning_rate": 2.9122629779297486e-06,
      "loss": 0.2725,
      "step": 18241
    },
    {
      "epoch": 1.4176251165682312,
      "grad_norm": 0.25596439838409424,
      "learning_rate": 2.9118744171588435e-06,
      "loss": 0.133,
      "step": 18242
    },
    {
      "epoch": 1.4177028287224123,
      "grad_norm": 0.9761208891868591,
      "learning_rate": 2.9114858563879393e-06,
      "loss": 0.2906,
      "step": 18243
    },
    {
      "epoch": 1.417780540876593,
      "grad_norm": 0.22669218480587006,
      "learning_rate": 2.9110972956170347e-06,
      "loss": 0.0233,
      "step": 18244
    },
    {
      "epoch": 1.417858253030774,
      "grad_norm": 0.42313849925994873,
      "learning_rate": 2.91070873484613e-06,
      "loss": 0.1264,
      "step": 18245
    },
    {
      "epoch": 1.417935965184955,
      "grad_norm": 0.5466538667678833,
      "learning_rate": 2.910320174075226e-06,
      "loss": 0.167,
      "step": 18246
    },
    {
      "epoch": 1.4180136773391359,
      "grad_norm": 0.3881720304489136,
      "learning_rate": 2.909931613304321e-06,
      "loss": 0.0357,
      "step": 18247
    },
    {
      "epoch": 1.4180913894933167,
      "grad_norm": 0.17745837569236755,
      "learning_rate": 2.9095430525334166e-06,
      "loss": 0.0233,
      "step": 18248
    },
    {
      "epoch": 1.4181691016474978,
      "grad_norm": 0.373220831155777,
      "learning_rate": 2.909154491762512e-06,
      "loss": 0.0829,
      "step": 18249
    },
    {
      "epoch": 1.4182468138016786,
      "grad_norm": 0.5533081293106079,
      "learning_rate": 2.9087659309916074e-06,
      "loss": 0.4134,
      "step": 18250
    },
    {
      "epoch": 1.4183245259558594,
      "grad_norm": 0.49934980273246765,
      "learning_rate": 2.908377370220703e-06,
      "loss": 0.3335,
      "step": 18251
    },
    {
      "epoch": 1.4184022381100405,
      "grad_norm": 0.5795907378196716,
      "learning_rate": 2.907988809449798e-06,
      "loss": 0.0723,
      "step": 18252
    },
    {
      "epoch": 1.4184799502642214,
      "grad_norm": 0.6384589672088623,
      "learning_rate": 2.9076002486788935e-06,
      "loss": 0.0828,
      "step": 18253
    },
    {
      "epoch": 1.4185576624184022,
      "grad_norm": 0.1747933328151703,
      "learning_rate": 2.9072116879079893e-06,
      "loss": 0.0451,
      "step": 18254
    },
    {
      "epoch": 1.4186353745725833,
      "grad_norm": 0.12402734160423279,
      "learning_rate": 2.9068231271370847e-06,
      "loss": 0.0268,
      "step": 18255
    },
    {
      "epoch": 1.418713086726764,
      "grad_norm": 0.5583061575889587,
      "learning_rate": 2.9064345663661796e-06,
      "loss": 0.1575,
      "step": 18256
    },
    {
      "epoch": 1.418790798880945,
      "grad_norm": 0.41879263520240784,
      "learning_rate": 2.9060460055952754e-06,
      "loss": 0.2426,
      "step": 18257
    },
    {
      "epoch": 1.418868511035126,
      "grad_norm": 0.21466098725795746,
      "learning_rate": 2.9056574448243708e-06,
      "loss": 0.0739,
      "step": 18258
    },
    {
      "epoch": 1.4189462231893069,
      "grad_norm": 0.6549906134605408,
      "learning_rate": 2.905268884053466e-06,
      "loss": 0.3732,
      "step": 18259
    },
    {
      "epoch": 1.4190239353434877,
      "grad_norm": 0.42936381697654724,
      "learning_rate": 2.904880323282562e-06,
      "loss": 0.0365,
      "step": 18260
    },
    {
      "epoch": 1.4191016474976688,
      "grad_norm": 0.7091911435127258,
      "learning_rate": 2.904491762511657e-06,
      "loss": 0.3652,
      "step": 18261
    },
    {
      "epoch": 1.4191793596518496,
      "grad_norm": 0.14157634973526,
      "learning_rate": 2.9041032017407523e-06,
      "loss": 0.0214,
      "step": 18262
    },
    {
      "epoch": 1.4192570718060304,
      "grad_norm": 0.2217588871717453,
      "learning_rate": 2.903714640969848e-06,
      "loss": 0.0587,
      "step": 18263
    },
    {
      "epoch": 1.4193347839602115,
      "grad_norm": 0.3065871298313141,
      "learning_rate": 2.9033260801989434e-06,
      "loss": 0.0619,
      "step": 18264
    },
    {
      "epoch": 1.4194124961143924,
      "grad_norm": 0.6186712384223938,
      "learning_rate": 2.9029375194280392e-06,
      "loss": 0.2231,
      "step": 18265
    },
    {
      "epoch": 1.4194902082685732,
      "grad_norm": 0.32003146409988403,
      "learning_rate": 2.902548958657134e-06,
      "loss": 0.3141,
      "step": 18266
    },
    {
      "epoch": 1.419567920422754,
      "grad_norm": 0.3837968409061432,
      "learning_rate": 2.9021603978862296e-06,
      "loss": 0.2627,
      "step": 18267
    },
    {
      "epoch": 1.419645632576935,
      "grad_norm": 0.46568405628204346,
      "learning_rate": 2.9017718371153254e-06,
      "loss": 0.1561,
      "step": 18268
    },
    {
      "epoch": 1.419723344731116,
      "grad_norm": 1.059838891029358,
      "learning_rate": 2.9013832763444207e-06,
      "loss": 0.1389,
      "step": 18269
    },
    {
      "epoch": 1.4198010568852968,
      "grad_norm": 0.42848578095436096,
      "learning_rate": 2.9009947155735157e-06,
      "loss": 0.1866,
      "step": 18270
    },
    {
      "epoch": 1.4198787690394779,
      "grad_norm": 0.2900252342224121,
      "learning_rate": 2.9006061548026115e-06,
      "loss": 0.1967,
      "step": 18271
    },
    {
      "epoch": 1.4199564811936587,
      "grad_norm": 0.2926822602748871,
      "learning_rate": 2.900217594031707e-06,
      "loss": 0.0495,
      "step": 18272
    },
    {
      "epoch": 1.4200341933478395,
      "grad_norm": 0.5034606456756592,
      "learning_rate": 2.899829033260802e-06,
      "loss": 0.1785,
      "step": 18273
    },
    {
      "epoch": 1.4201119055020204,
      "grad_norm": 0.3242313265800476,
      "learning_rate": 2.8994404724898976e-06,
      "loss": 0.0491,
      "step": 18274
    },
    {
      "epoch": 1.4201896176562014,
      "grad_norm": 1.1430909633636475,
      "learning_rate": 2.899051911718993e-06,
      "loss": 0.1651,
      "step": 18275
    },
    {
      "epoch": 1.4202673298103823,
      "grad_norm": 0.44326719641685486,
      "learning_rate": 2.8986633509480883e-06,
      "loss": 0.14,
      "step": 18276
    },
    {
      "epoch": 1.4203450419645631,
      "grad_norm": 0.04326562583446503,
      "learning_rate": 2.898274790177184e-06,
      "loss": 0.0041,
      "step": 18277
    },
    {
      "epoch": 1.4204227541187442,
      "grad_norm": 0.3308073878288269,
      "learning_rate": 2.897886229406279e-06,
      "loss": 0.4429,
      "step": 18278
    },
    {
      "epoch": 1.420500466272925,
      "grad_norm": 0.1968218982219696,
      "learning_rate": 2.897497668635375e-06,
      "loss": 0.0548,
      "step": 18279
    },
    {
      "epoch": 1.4205781784271059,
      "grad_norm": 0.3571462631225586,
      "learning_rate": 2.8971091078644703e-06,
      "loss": 0.2171,
      "step": 18280
    },
    {
      "epoch": 1.420655890581287,
      "grad_norm": 1.0713549852371216,
      "learning_rate": 2.8967205470935656e-06,
      "loss": 0.1116,
      "step": 18281
    },
    {
      "epoch": 1.4207336027354678,
      "grad_norm": 0.40797629952430725,
      "learning_rate": 2.8963319863226614e-06,
      "loss": 0.0947,
      "step": 18282
    },
    {
      "epoch": 1.4208113148896486,
      "grad_norm": 0.14977799355983734,
      "learning_rate": 2.8959434255517564e-06,
      "loss": 0.0228,
      "step": 18283
    },
    {
      "epoch": 1.4208890270438297,
      "grad_norm": 0.548547089099884,
      "learning_rate": 2.8955548647808517e-06,
      "loss": 0.3878,
      "step": 18284
    },
    {
      "epoch": 1.4209667391980105,
      "grad_norm": 0.43559345602989197,
      "learning_rate": 2.8951663040099475e-06,
      "loss": 0.26,
      "step": 18285
    },
    {
      "epoch": 1.4210444513521914,
      "grad_norm": 0.7431022524833679,
      "learning_rate": 2.894777743239043e-06,
      "loss": 0.2725,
      "step": 18286
    },
    {
      "epoch": 1.4211221635063724,
      "grad_norm": 0.5823781490325928,
      "learning_rate": 2.894389182468138e-06,
      "loss": 0.1644,
      "step": 18287
    },
    {
      "epoch": 1.4211998756605533,
      "grad_norm": 0.6670634746551514,
      "learning_rate": 2.8940006216972337e-06,
      "loss": 0.3353,
      "step": 18288
    },
    {
      "epoch": 1.4212775878147341,
      "grad_norm": 0.2912854552268982,
      "learning_rate": 2.893612060926329e-06,
      "loss": 0.1253,
      "step": 18289
    },
    {
      "epoch": 1.4213552999689152,
      "grad_norm": 0.39379432797431946,
      "learning_rate": 2.8932235001554244e-06,
      "loss": 0.2515,
      "step": 18290
    },
    {
      "epoch": 1.421433012123096,
      "grad_norm": 1.4400149583816528,
      "learning_rate": 2.89283493938452e-06,
      "loss": 0.2941,
      "step": 18291
    },
    {
      "epoch": 1.4215107242772769,
      "grad_norm": 0.2261105477809906,
      "learning_rate": 2.892446378613615e-06,
      "loss": 0.1235,
      "step": 18292
    },
    {
      "epoch": 1.421588436431458,
      "grad_norm": 0.6446362733840942,
      "learning_rate": 2.892057817842711e-06,
      "loss": 0.1928,
      "step": 18293
    },
    {
      "epoch": 1.4216661485856388,
      "grad_norm": 0.9241419434547424,
      "learning_rate": 2.8916692570718063e-06,
      "loss": 0.0558,
      "step": 18294
    },
    {
      "epoch": 1.4217438607398196,
      "grad_norm": 0.23606128990650177,
      "learning_rate": 2.8912806963009017e-06,
      "loss": 0.069,
      "step": 18295
    },
    {
      "epoch": 1.4218215728940007,
      "grad_norm": 0.14882193505764008,
      "learning_rate": 2.8908921355299975e-06,
      "loss": 0.0398,
      "step": 18296
    },
    {
      "epoch": 1.4218992850481815,
      "grad_norm": 0.45558834075927734,
      "learning_rate": 2.8905035747590924e-06,
      "loss": 0.0791,
      "step": 18297
    },
    {
      "epoch": 1.4219769972023624,
      "grad_norm": 0.23944002389907837,
      "learning_rate": 2.890115013988188e-06,
      "loss": 0.0507,
      "step": 18298
    },
    {
      "epoch": 1.4220547093565434,
      "grad_norm": 0.8895247578620911,
      "learning_rate": 2.8897264532172836e-06,
      "loss": 0.0589,
      "step": 18299
    },
    {
      "epoch": 1.4221324215107243,
      "grad_norm": 0.5231444835662842,
      "learning_rate": 2.889337892446379e-06,
      "loss": 0.1789,
      "step": 18300
    },
    {
      "epoch": 1.4222101336649051,
      "grad_norm": 0.2959842383861542,
      "learning_rate": 2.888949331675474e-06,
      "loss": 0.142,
      "step": 18301
    },
    {
      "epoch": 1.4222878458190862,
      "grad_norm": 0.8991644978523254,
      "learning_rate": 2.8885607709045697e-06,
      "loss": 0.2122,
      "step": 18302
    },
    {
      "epoch": 1.422365557973267,
      "grad_norm": 0.20315752923488617,
      "learning_rate": 2.888172210133665e-06,
      "loss": 0.0683,
      "step": 18303
    },
    {
      "epoch": 1.4224432701274479,
      "grad_norm": 0.8171770572662354,
      "learning_rate": 2.8877836493627605e-06,
      "loss": 0.3337,
      "step": 18304
    },
    {
      "epoch": 1.422520982281629,
      "grad_norm": 0.4975310266017914,
      "learning_rate": 2.8873950885918563e-06,
      "loss": 0.3068,
      "step": 18305
    },
    {
      "epoch": 1.4225986944358098,
      "grad_norm": 0.5840200185775757,
      "learning_rate": 2.8870065278209512e-06,
      "loss": 0.048,
      "step": 18306
    },
    {
      "epoch": 1.4226764065899906,
      "grad_norm": 0.15963146090507507,
      "learning_rate": 2.8866179670500466e-06,
      "loss": 0.0239,
      "step": 18307
    },
    {
      "epoch": 1.4227541187441717,
      "grad_norm": 0.4313110113143921,
      "learning_rate": 2.8862294062791424e-06,
      "loss": 0.0818,
      "step": 18308
    },
    {
      "epoch": 1.4228318308983525,
      "grad_norm": 0.7030147910118103,
      "learning_rate": 2.8858408455082378e-06,
      "loss": 0.0801,
      "step": 18309
    },
    {
      "epoch": 1.4229095430525334,
      "grad_norm": 0.19844195246696472,
      "learning_rate": 2.8854522847373336e-06,
      "loss": 0.0225,
      "step": 18310
    },
    {
      "epoch": 1.4229872552067144,
      "grad_norm": 0.5300121307373047,
      "learning_rate": 2.8850637239664285e-06,
      "loss": 0.1911,
      "step": 18311
    },
    {
      "epoch": 1.4230649673608953,
      "grad_norm": 0.6318712830543518,
      "learning_rate": 2.884675163195524e-06,
      "loss": 0.1109,
      "step": 18312
    },
    {
      "epoch": 1.4231426795150761,
      "grad_norm": 0.6944303512573242,
      "learning_rate": 2.8842866024246197e-06,
      "loss": 0.6576,
      "step": 18313
    },
    {
      "epoch": 1.4232203916692572,
      "grad_norm": 0.464964359998703,
      "learning_rate": 2.883898041653715e-06,
      "loss": 0.126,
      "step": 18314
    },
    {
      "epoch": 1.423298103823438,
      "grad_norm": 0.6847813725471497,
      "learning_rate": 2.88350948088281e-06,
      "loss": 0.2016,
      "step": 18315
    },
    {
      "epoch": 1.4233758159776189,
      "grad_norm": 0.11133281141519547,
      "learning_rate": 2.883120920111906e-06,
      "loss": 0.0444,
      "step": 18316
    },
    {
      "epoch": 1.4234535281318,
      "grad_norm": 0.5734806656837463,
      "learning_rate": 2.882732359341001e-06,
      "loss": 0.2403,
      "step": 18317
    },
    {
      "epoch": 1.4235312402859808,
      "grad_norm": 0.8256723284721375,
      "learning_rate": 2.8823437985700966e-06,
      "loss": 0.361,
      "step": 18318
    },
    {
      "epoch": 1.4236089524401616,
      "grad_norm": 0.4426615238189697,
      "learning_rate": 2.8819552377991924e-06,
      "loss": 0.0963,
      "step": 18319
    },
    {
      "epoch": 1.4236866645943427,
      "grad_norm": 0.6630975604057312,
      "learning_rate": 2.8815666770282873e-06,
      "loss": 0.4403,
      "step": 18320
    },
    {
      "epoch": 1.4237643767485235,
      "grad_norm": 0.17671184241771698,
      "learning_rate": 2.8811781162573827e-06,
      "loss": 0.0558,
      "step": 18321
    },
    {
      "epoch": 1.4238420889027044,
      "grad_norm": 0.28236690163612366,
      "learning_rate": 2.8807895554864785e-06,
      "loss": 0.0462,
      "step": 18322
    },
    {
      "epoch": 1.4239198010568854,
      "grad_norm": 0.7761963605880737,
      "learning_rate": 2.880400994715574e-06,
      "loss": 0.6807,
      "step": 18323
    },
    {
      "epoch": 1.4239975132110663,
      "grad_norm": 0.24942946434020996,
      "learning_rate": 2.8800124339446696e-06,
      "loss": 0.1309,
      "step": 18324
    },
    {
      "epoch": 1.424075225365247,
      "grad_norm": 0.4183748662471771,
      "learning_rate": 2.8796238731737646e-06,
      "loss": 0.2297,
      "step": 18325
    },
    {
      "epoch": 1.4241529375194282,
      "grad_norm": 1.133575677871704,
      "learning_rate": 2.87923531240286e-06,
      "loss": 0.6027,
      "step": 18326
    },
    {
      "epoch": 1.424230649673609,
      "grad_norm": 0.7105227708816528,
      "learning_rate": 2.8788467516319558e-06,
      "loss": 0.331,
      "step": 18327
    },
    {
      "epoch": 1.4243083618277899,
      "grad_norm": 0.1680431365966797,
      "learning_rate": 2.878458190861051e-06,
      "loss": 0.0477,
      "step": 18328
    },
    {
      "epoch": 1.4243860739819707,
      "grad_norm": 0.3982337415218353,
      "learning_rate": 2.878069630090146e-06,
      "loss": 0.0801,
      "step": 18329
    },
    {
      "epoch": 1.4244637861361518,
      "grad_norm": 0.28088751435279846,
      "learning_rate": 2.877681069319242e-06,
      "loss": 0.074,
      "step": 18330
    },
    {
      "epoch": 1.4245414982903326,
      "grad_norm": 1.168718695640564,
      "learning_rate": 2.8772925085483373e-06,
      "loss": 0.6838,
      "step": 18331
    },
    {
      "epoch": 1.4246192104445135,
      "grad_norm": 0.40485870838165283,
      "learning_rate": 2.8769039477774326e-06,
      "loss": 0.044,
      "step": 18332
    },
    {
      "epoch": 1.4246969225986945,
      "grad_norm": 0.6111722588539124,
      "learning_rate": 2.876515387006528e-06,
      "loss": 0.2754,
      "step": 18333
    },
    {
      "epoch": 1.4247746347528754,
      "grad_norm": 0.43198955059051514,
      "learning_rate": 2.8761268262356234e-06,
      "loss": 0.1258,
      "step": 18334
    },
    {
      "epoch": 1.4248523469070562,
      "grad_norm": 0.5593680143356323,
      "learning_rate": 2.8757382654647188e-06,
      "loss": 0.089,
      "step": 18335
    },
    {
      "epoch": 1.424930059061237,
      "grad_norm": 0.31937000155448914,
      "learning_rate": 2.8753497046938145e-06,
      "loss": 0.2381,
      "step": 18336
    },
    {
      "epoch": 1.425007771215418,
      "grad_norm": 0.21745936572551727,
      "learning_rate": 2.8749611439229095e-06,
      "loss": 0.0888,
      "step": 18337
    },
    {
      "epoch": 1.425085483369599,
      "grad_norm": 0.30868422985076904,
      "learning_rate": 2.874572583152005e-06,
      "loss": 0.1323,
      "step": 18338
    },
    {
      "epoch": 1.4251631955237798,
      "grad_norm": 0.31983262300491333,
      "learning_rate": 2.8741840223811007e-06,
      "loss": 0.1616,
      "step": 18339
    },
    {
      "epoch": 1.4252409076779609,
      "grad_norm": 0.5515018105506897,
      "learning_rate": 2.873795461610196e-06,
      "loss": 0.1542,
      "step": 18340
    },
    {
      "epoch": 1.4253186198321417,
      "grad_norm": 0.640531063079834,
      "learning_rate": 2.873406900839292e-06,
      "loss": 0.1654,
      "step": 18341
    },
    {
      "epoch": 1.4253963319863225,
      "grad_norm": 0.8269743919372559,
      "learning_rate": 2.8730183400683868e-06,
      "loss": 0.453,
      "step": 18342
    },
    {
      "epoch": 1.4254740441405036,
      "grad_norm": 0.6958982348442078,
      "learning_rate": 2.872629779297482e-06,
      "loss": 0.119,
      "step": 18343
    },
    {
      "epoch": 1.4255517562946844,
      "grad_norm": 0.204171821475029,
      "learning_rate": 2.872241218526578e-06,
      "loss": 0.0232,
      "step": 18344
    },
    {
      "epoch": 1.4256294684488653,
      "grad_norm": 0.11710663884878159,
      "learning_rate": 2.8718526577556733e-06,
      "loss": 0.0272,
      "step": 18345
    },
    {
      "epoch": 1.4257071806030464,
      "grad_norm": 0.3704669773578644,
      "learning_rate": 2.8714640969847683e-06,
      "loss": 0.1029,
      "step": 18346
    },
    {
      "epoch": 1.4257848927572272,
      "grad_norm": 0.5304305553436279,
      "learning_rate": 2.871075536213864e-06,
      "loss": 0.1066,
      "step": 18347
    },
    {
      "epoch": 1.425862604911408,
      "grad_norm": 0.09854387491941452,
      "learning_rate": 2.8706869754429595e-06,
      "loss": 0.0208,
      "step": 18348
    },
    {
      "epoch": 1.425940317065589,
      "grad_norm": 0.3912694454193115,
      "learning_rate": 2.870298414672055e-06,
      "loss": 0.0664,
      "step": 18349
    },
    {
      "epoch": 1.42601802921977,
      "grad_norm": 0.5846235752105713,
      "learning_rate": 2.8699098539011506e-06,
      "loss": 0.2411,
      "step": 18350
    },
    {
      "epoch": 1.4260957413739508,
      "grad_norm": 0.21867914497852325,
      "learning_rate": 2.8695212931302456e-06,
      "loss": 0.0688,
      "step": 18351
    },
    {
      "epoch": 1.4261734535281319,
      "grad_norm": 0.539309561252594,
      "learning_rate": 2.869132732359341e-06,
      "loss": 0.1106,
      "step": 18352
    },
    {
      "epoch": 1.4262511656823127,
      "grad_norm": 0.6701509356498718,
      "learning_rate": 2.8687441715884367e-06,
      "loss": 0.078,
      "step": 18353
    },
    {
      "epoch": 1.4263288778364935,
      "grad_norm": 0.40215831995010376,
      "learning_rate": 2.868355610817532e-06,
      "loss": 0.1835,
      "step": 18354
    },
    {
      "epoch": 1.4264065899906746,
      "grad_norm": 0.15630990266799927,
      "learning_rate": 2.867967050046628e-06,
      "loss": 0.0159,
      "step": 18355
    },
    {
      "epoch": 1.4264843021448554,
      "grad_norm": 0.7829857468605042,
      "learning_rate": 2.867578489275723e-06,
      "loss": 0.1188,
      "step": 18356
    },
    {
      "epoch": 1.4265620142990363,
      "grad_norm": 0.7499034404754639,
      "learning_rate": 2.8671899285048182e-06,
      "loss": 0.2391,
      "step": 18357
    },
    {
      "epoch": 1.4266397264532173,
      "grad_norm": 1.0777745246887207,
      "learning_rate": 2.866801367733914e-06,
      "loss": 0.3677,
      "step": 18358
    },
    {
      "epoch": 1.4267174386073982,
      "grad_norm": 0.16070285439491272,
      "learning_rate": 2.8664128069630094e-06,
      "loss": 0.0153,
      "step": 18359
    },
    {
      "epoch": 1.426795150761579,
      "grad_norm": 0.3637908101081848,
      "learning_rate": 2.8660242461921044e-06,
      "loss": 0.1246,
      "step": 18360
    },
    {
      "epoch": 1.42687286291576,
      "grad_norm": 0.1589113175868988,
      "learning_rate": 2.8656356854212e-06,
      "loss": 0.0356,
      "step": 18361
    },
    {
      "epoch": 1.426950575069941,
      "grad_norm": 1.2168142795562744,
      "learning_rate": 2.8652471246502955e-06,
      "loss": 0.1764,
      "step": 18362
    },
    {
      "epoch": 1.4270282872241218,
      "grad_norm": 0.7104515433311462,
      "learning_rate": 2.864858563879391e-06,
      "loss": 0.0805,
      "step": 18363
    },
    {
      "epoch": 1.4271059993783028,
      "grad_norm": 1.7141528129577637,
      "learning_rate": 2.8644700031084867e-06,
      "loss": 0.4487,
      "step": 18364
    },
    {
      "epoch": 1.4271837115324837,
      "grad_norm": 0.46391361951828003,
      "learning_rate": 2.8640814423375816e-06,
      "loss": 0.1959,
      "step": 18365
    },
    {
      "epoch": 1.4272614236866645,
      "grad_norm": 0.18564704060554504,
      "learning_rate": 2.863692881566677e-06,
      "loss": 0.0593,
      "step": 18366
    },
    {
      "epoch": 1.4273391358408456,
      "grad_norm": 0.5865375399589539,
      "learning_rate": 2.863304320795773e-06,
      "loss": 0.168,
      "step": 18367
    },
    {
      "epoch": 1.4274168479950264,
      "grad_norm": 0.6268024444580078,
      "learning_rate": 2.862915760024868e-06,
      "loss": 0.7448,
      "step": 18368
    },
    {
      "epoch": 1.4274945601492073,
      "grad_norm": 0.24059633910655975,
      "learning_rate": 2.862527199253964e-06,
      "loss": 0.0853,
      "step": 18369
    },
    {
      "epoch": 1.4275722723033883,
      "grad_norm": 1.0934559106826782,
      "learning_rate": 2.862138638483059e-06,
      "loss": 0.2339,
      "step": 18370
    },
    {
      "epoch": 1.4276499844575692,
      "grad_norm": 0.1674818992614746,
      "learning_rate": 2.8617500777121543e-06,
      "loss": 0.0192,
      "step": 18371
    },
    {
      "epoch": 1.42772769661175,
      "grad_norm": 0.49558308720588684,
      "learning_rate": 2.86136151694125e-06,
      "loss": 0.1025,
      "step": 18372
    },
    {
      "epoch": 1.427805408765931,
      "grad_norm": 0.23211783170700073,
      "learning_rate": 2.8609729561703455e-06,
      "loss": 0.0285,
      "step": 18373
    },
    {
      "epoch": 1.427883120920112,
      "grad_norm": 0.5447869896888733,
      "learning_rate": 2.8605843953994404e-06,
      "loss": 0.6322,
      "step": 18374
    },
    {
      "epoch": 1.4279608330742928,
      "grad_norm": 0.2272423505783081,
      "learning_rate": 2.8601958346285362e-06,
      "loss": 0.024,
      "step": 18375
    },
    {
      "epoch": 1.4280385452284738,
      "grad_norm": 0.9704553484916687,
      "learning_rate": 2.8598072738576316e-06,
      "loss": 0.6295,
      "step": 18376
    },
    {
      "epoch": 1.4281162573826547,
      "grad_norm": 0.337014764547348,
      "learning_rate": 2.859418713086727e-06,
      "loss": 0.1298,
      "step": 18377
    },
    {
      "epoch": 1.4281939695368355,
      "grad_norm": 0.5314249992370605,
      "learning_rate": 2.8590301523158228e-06,
      "loss": 0.2347,
      "step": 18378
    },
    {
      "epoch": 1.4282716816910166,
      "grad_norm": 0.2236064076423645,
      "learning_rate": 2.8586415915449177e-06,
      "loss": 0.0404,
      "step": 18379
    },
    {
      "epoch": 1.4283493938451974,
      "grad_norm": 0.577218770980835,
      "learning_rate": 2.858253030774013e-06,
      "loss": 0.0844,
      "step": 18380
    },
    {
      "epoch": 1.4284271059993783,
      "grad_norm": 0.32172444462776184,
      "learning_rate": 2.857864470003109e-06,
      "loss": 0.083,
      "step": 18381
    },
    {
      "epoch": 1.4285048181535593,
      "grad_norm": 0.6953834295272827,
      "learning_rate": 2.8574759092322043e-06,
      "loss": 0.3505,
      "step": 18382
    },
    {
      "epoch": 1.4285825303077402,
      "grad_norm": 0.2504923641681671,
      "learning_rate": 2.857087348461299e-06,
      "loss": 0.0561,
      "step": 18383
    },
    {
      "epoch": 1.428660242461921,
      "grad_norm": 0.24297849833965302,
      "learning_rate": 2.856698787690395e-06,
      "loss": 0.0622,
      "step": 18384
    },
    {
      "epoch": 1.428737954616102,
      "grad_norm": 0.41214820742607117,
      "learning_rate": 2.8563102269194904e-06,
      "loss": 0.3637,
      "step": 18385
    },
    {
      "epoch": 1.428815666770283,
      "grad_norm": 0.41757985949516296,
      "learning_rate": 2.855921666148586e-06,
      "loss": 0.1556,
      "step": 18386
    },
    {
      "epoch": 1.4288933789244638,
      "grad_norm": 0.9208474159240723,
      "learning_rate": 2.8555331053776815e-06,
      "loss": 0.0946,
      "step": 18387
    },
    {
      "epoch": 1.4289710910786446,
      "grad_norm": 0.572418212890625,
      "learning_rate": 2.8551445446067765e-06,
      "loss": 0.1115,
      "step": 18388
    },
    {
      "epoch": 1.4290488032328257,
      "grad_norm": 0.3514510691165924,
      "learning_rate": 2.8547559838358723e-06,
      "loss": 0.2925,
      "step": 18389
    },
    {
      "epoch": 1.4291265153870065,
      "grad_norm": 1.0538580417633057,
      "learning_rate": 2.8543674230649677e-06,
      "loss": 0.2297,
      "step": 18390
    },
    {
      "epoch": 1.4292042275411874,
      "grad_norm": 0.7887632846832275,
      "learning_rate": 2.853978862294063e-06,
      "loss": 0.4959,
      "step": 18391
    },
    {
      "epoch": 1.4292819396953684,
      "grad_norm": 1.1454110145568848,
      "learning_rate": 2.853590301523159e-06,
      "loss": 0.2742,
      "step": 18392
    },
    {
      "epoch": 1.4293596518495493,
      "grad_norm": 1.1077830791473389,
      "learning_rate": 2.853201740752254e-06,
      "loss": 0.78,
      "step": 18393
    },
    {
      "epoch": 1.4294373640037301,
      "grad_norm": 0.49360162019729614,
      "learning_rate": 2.852813179981349e-06,
      "loss": 0.1147,
      "step": 18394
    },
    {
      "epoch": 1.4295150761579112,
      "grad_norm": 1.0437285900115967,
      "learning_rate": 2.852424619210445e-06,
      "loss": 0.2884,
      "step": 18395
    },
    {
      "epoch": 1.429592788312092,
      "grad_norm": 1.3277177810668945,
      "learning_rate": 2.8520360584395403e-06,
      "loss": 0.239,
      "step": 18396
    },
    {
      "epoch": 1.4296705004662729,
      "grad_norm": 0.22141408920288086,
      "learning_rate": 2.8516474976686353e-06,
      "loss": 0.0302,
      "step": 18397
    },
    {
      "epoch": 1.4297482126204537,
      "grad_norm": 0.4160069525241852,
      "learning_rate": 2.851258936897731e-06,
      "loss": 0.2158,
      "step": 18398
    },
    {
      "epoch": 1.4298259247746348,
      "grad_norm": 0.5252904295921326,
      "learning_rate": 2.8508703761268265e-06,
      "loss": 0.087,
      "step": 18399
    },
    {
      "epoch": 1.4299036369288156,
      "grad_norm": 0.24921812117099762,
      "learning_rate": 2.8504818153559222e-06,
      "loss": 0.0331,
      "step": 18400
    },
    {
      "epoch": 1.4299813490829965,
      "grad_norm": 0.5240489840507507,
      "learning_rate": 2.850093254585017e-06,
      "loss": 0.0628,
      "step": 18401
    },
    {
      "epoch": 1.4300590612371775,
      "grad_norm": 0.35648536682128906,
      "learning_rate": 2.8497046938141126e-06,
      "loss": 0.1802,
      "step": 18402
    },
    {
      "epoch": 1.4301367733913584,
      "grad_norm": 0.22048921883106232,
      "learning_rate": 2.8493161330432084e-06,
      "loss": 0.0276,
      "step": 18403
    },
    {
      "epoch": 1.4302144855455392,
      "grad_norm": 1.1094690561294556,
      "learning_rate": 2.8489275722723037e-06,
      "loss": 0.7944,
      "step": 18404
    },
    {
      "epoch": 1.4302921976997203,
      "grad_norm": 0.5748421549797058,
      "learning_rate": 2.8485390115013987e-06,
      "loss": 0.0858,
      "step": 18405
    },
    {
      "epoch": 1.4303699098539011,
      "grad_norm": 0.7959393858909607,
      "learning_rate": 2.8481504507304945e-06,
      "loss": 0.5434,
      "step": 18406
    },
    {
      "epoch": 1.430447622008082,
      "grad_norm": 0.27675941586494446,
      "learning_rate": 2.84776188995959e-06,
      "loss": 0.0265,
      "step": 18407
    },
    {
      "epoch": 1.430525334162263,
      "grad_norm": 0.4446471035480499,
      "learning_rate": 2.8473733291886852e-06,
      "loss": 0.1781,
      "step": 18408
    },
    {
      "epoch": 1.4306030463164439,
      "grad_norm": 0.4515703320503235,
      "learning_rate": 2.846984768417781e-06,
      "loss": 0.1502,
      "step": 18409
    },
    {
      "epoch": 1.4306807584706247,
      "grad_norm": 0.22976939380168915,
      "learning_rate": 2.846596207646876e-06,
      "loss": 0.0955,
      "step": 18410
    },
    {
      "epoch": 1.4307584706248058,
      "grad_norm": 0.6965500116348267,
      "learning_rate": 2.8462076468759714e-06,
      "loss": 0.4242,
      "step": 18411
    },
    {
      "epoch": 1.4308361827789866,
      "grad_norm": 0.7145752310752869,
      "learning_rate": 2.845819086105067e-06,
      "loss": 0.2188,
      "step": 18412
    },
    {
      "epoch": 1.4309138949331675,
      "grad_norm": 1.1163737773895264,
      "learning_rate": 2.8454305253341625e-06,
      "loss": 0.3155,
      "step": 18413
    },
    {
      "epoch": 1.4309916070873485,
      "grad_norm": 1.2386037111282349,
      "learning_rate": 2.8450419645632575e-06,
      "loss": 0.3735,
      "step": 18414
    },
    {
      "epoch": 1.4310693192415294,
      "grad_norm": 0.7444354891777039,
      "learning_rate": 2.8446534037923533e-06,
      "loss": 0.6699,
      "step": 18415
    },
    {
      "epoch": 1.4311470313957102,
      "grad_norm": 0.3442595899105072,
      "learning_rate": 2.8442648430214486e-06,
      "loss": 0.0485,
      "step": 18416
    },
    {
      "epoch": 1.4312247435498913,
      "grad_norm": 0.2266458123922348,
      "learning_rate": 2.8438762822505444e-06,
      "loss": 0.0265,
      "step": 18417
    },
    {
      "epoch": 1.431302455704072,
      "grad_norm": 0.19904285669326782,
      "learning_rate": 2.84348772147964e-06,
      "loss": 0.0191,
      "step": 18418
    },
    {
      "epoch": 1.431380167858253,
      "grad_norm": 0.4764368236064911,
      "learning_rate": 2.8430991607087348e-06,
      "loss": 0.132,
      "step": 18419
    },
    {
      "epoch": 1.431457880012434,
      "grad_norm": 0.9967825412750244,
      "learning_rate": 2.8427105999378306e-06,
      "loss": 0.5779,
      "step": 18420
    },
    {
      "epoch": 1.4315355921666149,
      "grad_norm": 0.7192093729972839,
      "learning_rate": 2.842322039166926e-06,
      "loss": 0.2977,
      "step": 18421
    },
    {
      "epoch": 1.4316133043207957,
      "grad_norm": 0.42011114954948425,
      "learning_rate": 2.8419334783960213e-06,
      "loss": 0.1398,
      "step": 18422
    },
    {
      "epoch": 1.4316910164749768,
      "grad_norm": 0.20225974917411804,
      "learning_rate": 2.841544917625117e-06,
      "loss": 0.0409,
      "step": 18423
    },
    {
      "epoch": 1.4317687286291576,
      "grad_norm": 0.2213548868894577,
      "learning_rate": 2.841156356854212e-06,
      "loss": 0.1203,
      "step": 18424
    },
    {
      "epoch": 1.4318464407833384,
      "grad_norm": 0.246576189994812,
      "learning_rate": 2.8407677960833074e-06,
      "loss": 0.0299,
      "step": 18425
    },
    {
      "epoch": 1.4319241529375195,
      "grad_norm": 0.42181897163391113,
      "learning_rate": 2.8403792353124032e-06,
      "loss": 0.1267,
      "step": 18426
    },
    {
      "epoch": 1.4320018650917004,
      "grad_norm": 0.26735198497772217,
      "learning_rate": 2.8399906745414986e-06,
      "loss": 0.0449,
      "step": 18427
    },
    {
      "epoch": 1.4320795772458812,
      "grad_norm": 0.4320801794528961,
      "learning_rate": 2.8396021137705935e-06,
      "loss": 0.283,
      "step": 18428
    },
    {
      "epoch": 1.4321572894000623,
      "grad_norm": 0.5791259407997131,
      "learning_rate": 2.8392135529996893e-06,
      "loss": 0.3686,
      "step": 18429
    },
    {
      "epoch": 1.432235001554243,
      "grad_norm": 0.3781225383281708,
      "learning_rate": 2.8388249922287847e-06,
      "loss": 0.078,
      "step": 18430
    },
    {
      "epoch": 1.432312713708424,
      "grad_norm": 0.1604907065629959,
      "learning_rate": 2.8384364314578805e-06,
      "loss": 0.0635,
      "step": 18431
    },
    {
      "epoch": 1.432390425862605,
      "grad_norm": 0.32701122760772705,
      "learning_rate": 2.838047870686976e-06,
      "loss": 0.2417,
      "step": 18432
    },
    {
      "epoch": 1.4324681380167859,
      "grad_norm": 0.8547056317329407,
      "learning_rate": 2.837659309916071e-06,
      "loss": 0.196,
      "step": 18433
    },
    {
      "epoch": 1.4325458501709667,
      "grad_norm": 0.6490962505340576,
      "learning_rate": 2.8372707491451666e-06,
      "loss": 0.2741,
      "step": 18434
    },
    {
      "epoch": 1.4326235623251478,
      "grad_norm": 0.5233495831489563,
      "learning_rate": 2.836882188374262e-06,
      "loss": 0.1676,
      "step": 18435
    },
    {
      "epoch": 1.4327012744793286,
      "grad_norm": 0.290921151638031,
      "learning_rate": 2.8364936276033574e-06,
      "loss": 0.0994,
      "step": 18436
    },
    {
      "epoch": 1.4327789866335094,
      "grad_norm": 0.37835752964019775,
      "learning_rate": 2.836105066832453e-06,
      "loss": 0.1704,
      "step": 18437
    },
    {
      "epoch": 1.4328566987876905,
      "grad_norm": 0.6407514810562134,
      "learning_rate": 2.835716506061548e-06,
      "loss": 0.2213,
      "step": 18438
    },
    {
      "epoch": 1.4329344109418714,
      "grad_norm": 0.34947213530540466,
      "learning_rate": 2.8353279452906435e-06,
      "loss": 0.1148,
      "step": 18439
    },
    {
      "epoch": 1.4330121230960522,
      "grad_norm": 0.5951077342033386,
      "learning_rate": 2.8349393845197393e-06,
      "loss": 0.1856,
      "step": 18440
    },
    {
      "epoch": 1.4330898352502333,
      "grad_norm": 0.08018602430820465,
      "learning_rate": 2.8345508237488347e-06,
      "loss": 0.0135,
      "step": 18441
    },
    {
      "epoch": 1.433167547404414,
      "grad_norm": 0.2947777807712555,
      "learning_rate": 2.8341622629779296e-06,
      "loss": 0.0659,
      "step": 18442
    },
    {
      "epoch": 1.433245259558595,
      "grad_norm": 0.5116762518882751,
      "learning_rate": 2.8337737022070254e-06,
      "loss": 0.2198,
      "step": 18443
    },
    {
      "epoch": 1.433322971712776,
      "grad_norm": 0.48359036445617676,
      "learning_rate": 2.833385141436121e-06,
      "loss": 0.1486,
      "step": 18444
    },
    {
      "epoch": 1.4334006838669568,
      "grad_norm": 0.8275707364082336,
      "learning_rate": 2.8329965806652166e-06,
      "loss": 0.2905,
      "step": 18445
    },
    {
      "epoch": 1.4334783960211377,
      "grad_norm": 0.4402042329311371,
      "learning_rate": 2.832608019894312e-06,
      "loss": 0.0585,
      "step": 18446
    },
    {
      "epoch": 1.4335561081753188,
      "grad_norm": 0.4712660014629364,
      "learning_rate": 2.832219459123407e-06,
      "loss": 0.3044,
      "step": 18447
    },
    {
      "epoch": 1.4336338203294996,
      "grad_norm": 0.33460813760757446,
      "learning_rate": 2.8318308983525027e-06,
      "loss": 0.1787,
      "step": 18448
    },
    {
      "epoch": 1.4337115324836804,
      "grad_norm": 0.694111168384552,
      "learning_rate": 2.831442337581598e-06,
      "loss": 0.2594,
      "step": 18449
    },
    {
      "epoch": 1.4337892446378613,
      "grad_norm": 0.4780879318714142,
      "learning_rate": 2.8310537768106935e-06,
      "loss": 0.3396,
      "step": 18450
    },
    {
      "epoch": 1.4338669567920423,
      "grad_norm": 0.3777743875980377,
      "learning_rate": 2.8306652160397893e-06,
      "loss": 0.1186,
      "step": 18451
    },
    {
      "epoch": 1.4339446689462232,
      "grad_norm": 0.2133706957101822,
      "learning_rate": 2.830276655268884e-06,
      "loss": 0.1232,
      "step": 18452
    },
    {
      "epoch": 1.434022381100404,
      "grad_norm": 0.29552948474884033,
      "learning_rate": 2.8298880944979796e-06,
      "loss": 0.1254,
      "step": 18453
    },
    {
      "epoch": 1.434100093254585,
      "grad_norm": 0.6216522455215454,
      "learning_rate": 2.8294995337270754e-06,
      "loss": 0.4416,
      "step": 18454
    },
    {
      "epoch": 1.434177805408766,
      "grad_norm": 0.8477897047996521,
      "learning_rate": 2.8291109729561707e-06,
      "loss": 0.3537,
      "step": 18455
    },
    {
      "epoch": 1.4342555175629468,
      "grad_norm": 0.21300627291202545,
      "learning_rate": 2.8287224121852657e-06,
      "loss": 0.0427,
      "step": 18456
    },
    {
      "epoch": 1.4343332297171276,
      "grad_norm": 0.2584306299686432,
      "learning_rate": 2.8283338514143615e-06,
      "loss": 0.1134,
      "step": 18457
    },
    {
      "epoch": 1.4344109418713087,
      "grad_norm": 0.46199584007263184,
      "learning_rate": 2.827945290643457e-06,
      "loss": 0.3038,
      "step": 18458
    },
    {
      "epoch": 1.4344886540254895,
      "grad_norm": 0.9857048392295837,
      "learning_rate": 2.8275567298725522e-06,
      "loss": 0.6696,
      "step": 18459
    },
    {
      "epoch": 1.4345663661796704,
      "grad_norm": 1.3764653205871582,
      "learning_rate": 2.8271681691016476e-06,
      "loss": 0.4267,
      "step": 18460
    },
    {
      "epoch": 1.4346440783338514,
      "grad_norm": 0.9197960495948792,
      "learning_rate": 2.826779608330743e-06,
      "loss": 0.2858,
      "step": 18461
    },
    {
      "epoch": 1.4347217904880323,
      "grad_norm": 0.13266156613826752,
      "learning_rate": 2.8263910475598388e-06,
      "loss": 0.0566,
      "step": 18462
    },
    {
      "epoch": 1.4347995026422131,
      "grad_norm": 0.34503525495529175,
      "learning_rate": 2.826002486788934e-06,
      "loss": 0.112,
      "step": 18463
    },
    {
      "epoch": 1.4348772147963942,
      "grad_norm": 1.2986068725585938,
      "learning_rate": 2.825613926018029e-06,
      "loss": 0.1119,
      "step": 18464
    },
    {
      "epoch": 1.434954926950575,
      "grad_norm": 0.29630303382873535,
      "learning_rate": 2.825225365247125e-06,
      "loss": 0.1118,
      "step": 18465
    },
    {
      "epoch": 1.4350326391047559,
      "grad_norm": 0.7791620492935181,
      "learning_rate": 2.8248368044762203e-06,
      "loss": 0.8228,
      "step": 18466
    },
    {
      "epoch": 1.435110351258937,
      "grad_norm": 1.0084601640701294,
      "learning_rate": 2.8244482437053156e-06,
      "loss": 0.1505,
      "step": 18467
    },
    {
      "epoch": 1.4351880634131178,
      "grad_norm": 0.5675405263900757,
      "learning_rate": 2.8240596829344114e-06,
      "loss": 0.2571,
      "step": 18468
    },
    {
      "epoch": 1.4352657755672986,
      "grad_norm": 0.20436273515224457,
      "learning_rate": 2.8236711221635064e-06,
      "loss": 0.0781,
      "step": 18469
    },
    {
      "epoch": 1.4353434877214797,
      "grad_norm": 0.5750385522842407,
      "learning_rate": 2.8232825613926018e-06,
      "loss": 0.1329,
      "step": 18470
    },
    {
      "epoch": 1.4354211998756605,
      "grad_norm": 0.3134958744049072,
      "learning_rate": 2.8228940006216976e-06,
      "loss": 0.1056,
      "step": 18471
    },
    {
      "epoch": 1.4354989120298414,
      "grad_norm": 0.4662523865699768,
      "learning_rate": 2.822505439850793e-06,
      "loss": 0.3692,
      "step": 18472
    },
    {
      "epoch": 1.4355766241840224,
      "grad_norm": 0.8310388922691345,
      "learning_rate": 2.822116879079888e-06,
      "loss": 0.5032,
      "step": 18473
    },
    {
      "epoch": 1.4356543363382033,
      "grad_norm": 0.18983662128448486,
      "learning_rate": 2.8217283183089837e-06,
      "loss": 0.0107,
      "step": 18474
    },
    {
      "epoch": 1.4357320484923841,
      "grad_norm": 0.7782297134399414,
      "learning_rate": 2.821339757538079e-06,
      "loss": 0.2088,
      "step": 18475
    },
    {
      "epoch": 1.4358097606465652,
      "grad_norm": 0.34059658646583557,
      "learning_rate": 2.820951196767175e-06,
      "loss": 0.0398,
      "step": 18476
    },
    {
      "epoch": 1.435887472800746,
      "grad_norm": 0.688702404499054,
      "learning_rate": 2.8205626359962702e-06,
      "loss": 0.281,
      "step": 18477
    },
    {
      "epoch": 1.4359651849549269,
      "grad_norm": 0.6804066300392151,
      "learning_rate": 2.820174075225365e-06,
      "loss": 0.3783,
      "step": 18478
    },
    {
      "epoch": 1.436042897109108,
      "grad_norm": 0.40856805443763733,
      "learning_rate": 2.819785514454461e-06,
      "loss": 0.108,
      "step": 18479
    },
    {
      "epoch": 1.4361206092632888,
      "grad_norm": 0.22172166407108307,
      "learning_rate": 2.8193969536835563e-06,
      "loss": 0.0776,
      "step": 18480
    },
    {
      "epoch": 1.4361983214174696,
      "grad_norm": 1.4510389566421509,
      "learning_rate": 2.8190083929126517e-06,
      "loss": 0.7436,
      "step": 18481
    },
    {
      "epoch": 1.4362760335716507,
      "grad_norm": 0.2538619041442871,
      "learning_rate": 2.8186198321417475e-06,
      "loss": 0.0765,
      "step": 18482
    },
    {
      "epoch": 1.4363537457258315,
      "grad_norm": 0.3240777552127838,
      "learning_rate": 2.8182312713708425e-06,
      "loss": 0.203,
      "step": 18483
    },
    {
      "epoch": 1.4364314578800124,
      "grad_norm": 0.5289881229400635,
      "learning_rate": 2.817842710599938e-06,
      "loss": 0.1197,
      "step": 18484
    },
    {
      "epoch": 1.4365091700341934,
      "grad_norm": 0.5100187063217163,
      "learning_rate": 2.8174541498290336e-06,
      "loss": 0.0784,
      "step": 18485
    },
    {
      "epoch": 1.4365868821883743,
      "grad_norm": 0.5662156939506531,
      "learning_rate": 2.817065589058129e-06,
      "loss": 0.3742,
      "step": 18486
    },
    {
      "epoch": 1.4366645943425551,
      "grad_norm": 0.2820049226284027,
      "learning_rate": 2.816677028287224e-06,
      "loss": 0.0372,
      "step": 18487
    },
    {
      "epoch": 1.4367423064967362,
      "grad_norm": 0.22474278509616852,
      "learning_rate": 2.8162884675163198e-06,
      "loss": 0.0395,
      "step": 18488
    },
    {
      "epoch": 1.436820018650917,
      "grad_norm": 0.39493313431739807,
      "learning_rate": 2.815899906745415e-06,
      "loss": 0.0746,
      "step": 18489
    },
    {
      "epoch": 1.4368977308050979,
      "grad_norm": 0.6702767610549927,
      "learning_rate": 2.8155113459745105e-06,
      "loss": 0.1601,
      "step": 18490
    },
    {
      "epoch": 1.436975442959279,
      "grad_norm": 0.5702344179153442,
      "learning_rate": 2.8151227852036063e-06,
      "loss": 0.0904,
      "step": 18491
    },
    {
      "epoch": 1.4370531551134598,
      "grad_norm": 0.42678725719451904,
      "learning_rate": 2.8147342244327013e-06,
      "loss": 0.0812,
      "step": 18492
    },
    {
      "epoch": 1.4371308672676406,
      "grad_norm": 0.7938453555107117,
      "learning_rate": 2.814345663661797e-06,
      "loss": 0.665,
      "step": 18493
    },
    {
      "epoch": 1.4372085794218217,
      "grad_norm": 0.36809849739074707,
      "learning_rate": 2.8139571028908924e-06,
      "loss": 0.2506,
      "step": 18494
    },
    {
      "epoch": 1.4372862915760025,
      "grad_norm": 0.7954253554344177,
      "learning_rate": 2.813568542119988e-06,
      "loss": 0.5313,
      "step": 18495
    },
    {
      "epoch": 1.4373640037301834,
      "grad_norm": 0.46173718571662903,
      "learning_rate": 2.8131799813490836e-06,
      "loss": 0.2136,
      "step": 18496
    },
    {
      "epoch": 1.4374417158843644,
      "grad_norm": 1.0009089708328247,
      "learning_rate": 2.8127914205781785e-06,
      "loss": 0.4409,
      "step": 18497
    },
    {
      "epoch": 1.4375194280385453,
      "grad_norm": 0.34094610810279846,
      "learning_rate": 2.812402859807274e-06,
      "loss": 0.1728,
      "step": 18498
    },
    {
      "epoch": 1.437597140192726,
      "grad_norm": 0.7248721718788147,
      "learning_rate": 2.8120142990363697e-06,
      "loss": 0.2544,
      "step": 18499
    },
    {
      "epoch": 1.4376748523469072,
      "grad_norm": 0.7422907948493958,
      "learning_rate": 2.811625738265465e-06,
      "loss": 0.1952,
      "step": 18500
    },
    {
      "epoch": 1.437752564501088,
      "grad_norm": 0.8713192343711853,
      "learning_rate": 2.81123717749456e-06,
      "loss": 0.1433,
      "step": 18501
    },
    {
      "epoch": 1.4378302766552689,
      "grad_norm": 0.6421017646789551,
      "learning_rate": 2.810848616723656e-06,
      "loss": 0.1421,
      "step": 18502
    },
    {
      "epoch": 1.43790798880945,
      "grad_norm": 1.0212247371673584,
      "learning_rate": 2.810460055952751e-06,
      "loss": 0.3255,
      "step": 18503
    },
    {
      "epoch": 1.4379857009636308,
      "grad_norm": 0.6799357533454895,
      "learning_rate": 2.8100714951818466e-06,
      "loss": 0.0829,
      "step": 18504
    },
    {
      "epoch": 1.4380634131178116,
      "grad_norm": 0.17642386257648468,
      "learning_rate": 2.8096829344109424e-06,
      "loss": 0.0408,
      "step": 18505
    },
    {
      "epoch": 1.4381411252719927,
      "grad_norm": 0.7533049583435059,
      "learning_rate": 2.8092943736400373e-06,
      "loss": 0.1148,
      "step": 18506
    },
    {
      "epoch": 1.4382188374261735,
      "grad_norm": 0.3967309594154358,
      "learning_rate": 2.808905812869133e-06,
      "loss": 0.2184,
      "step": 18507
    },
    {
      "epoch": 1.4382965495803544,
      "grad_norm": 0.7829234004020691,
      "learning_rate": 2.8085172520982285e-06,
      "loss": 0.2819,
      "step": 18508
    },
    {
      "epoch": 1.4383742617345354,
      "grad_norm": 0.5389058589935303,
      "learning_rate": 2.808128691327324e-06,
      "loss": 0.2084,
      "step": 18509
    },
    {
      "epoch": 1.4384519738887163,
      "grad_norm": 0.7156599760055542,
      "learning_rate": 2.8077401305564197e-06,
      "loss": 0.3435,
      "step": 18510
    },
    {
      "epoch": 1.438529686042897,
      "grad_norm": 0.17994731664657593,
      "learning_rate": 2.8073515697855146e-06,
      "loss": 0.0617,
      "step": 18511
    },
    {
      "epoch": 1.438607398197078,
      "grad_norm": 0.5144193768501282,
      "learning_rate": 2.80696300901461e-06,
      "loss": 0.2087,
      "step": 18512
    },
    {
      "epoch": 1.438685110351259,
      "grad_norm": 0.10325421392917633,
      "learning_rate": 2.8065744482437058e-06,
      "loss": 0.021,
      "step": 18513
    },
    {
      "epoch": 1.4387628225054399,
      "grad_norm": 0.5785227417945862,
      "learning_rate": 2.806185887472801e-06,
      "loss": 0.1625,
      "step": 18514
    },
    {
      "epoch": 1.4388405346596207,
      "grad_norm": 0.8312650322914124,
      "learning_rate": 2.805797326701896e-06,
      "loss": 0.252,
      "step": 18515
    },
    {
      "epoch": 1.4389182468138018,
      "grad_norm": 0.8417990803718567,
      "learning_rate": 2.805408765930992e-06,
      "loss": 0.3872,
      "step": 18516
    },
    {
      "epoch": 1.4389959589679826,
      "grad_norm": 0.5629364252090454,
      "learning_rate": 2.8050202051600873e-06,
      "loss": 0.1741,
      "step": 18517
    },
    {
      "epoch": 1.4390736711221634,
      "grad_norm": 0.5063857436180115,
      "learning_rate": 2.8046316443891827e-06,
      "loss": 0.0861,
      "step": 18518
    },
    {
      "epoch": 1.4391513832763443,
      "grad_norm": 0.42040878534317017,
      "learning_rate": 2.8042430836182784e-06,
      "loss": 0.2646,
      "step": 18519
    },
    {
      "epoch": 1.4392290954305254,
      "grad_norm": 1.0995148420333862,
      "learning_rate": 2.8038545228473734e-06,
      "loss": 0.4815,
      "step": 18520
    },
    {
      "epoch": 1.4393068075847062,
      "grad_norm": 0.509093701839447,
      "learning_rate": 2.803465962076469e-06,
      "loss": 0.1906,
      "step": 18521
    },
    {
      "epoch": 1.439384519738887,
      "grad_norm": 0.29047244787216187,
      "learning_rate": 2.8030774013055646e-06,
      "loss": 0.3221,
      "step": 18522
    },
    {
      "epoch": 1.439462231893068,
      "grad_norm": 0.865763247013092,
      "learning_rate": 2.8026888405346595e-06,
      "loss": 0.312,
      "step": 18523
    },
    {
      "epoch": 1.439539944047249,
      "grad_norm": 0.2565159499645233,
      "learning_rate": 2.8023002797637553e-06,
      "loss": 0.0913,
      "step": 18524
    },
    {
      "epoch": 1.4396176562014298,
      "grad_norm": 0.21092142164707184,
      "learning_rate": 2.8019117189928507e-06,
      "loss": 0.04,
      "step": 18525
    },
    {
      "epoch": 1.4396953683556108,
      "grad_norm": 0.5349989533424377,
      "learning_rate": 2.801523158221946e-06,
      "loss": 0.113,
      "step": 18526
    },
    {
      "epoch": 1.4397730805097917,
      "grad_norm": 0.4057359993457794,
      "learning_rate": 2.801134597451042e-06,
      "loss": 0.0966,
      "step": 18527
    },
    {
      "epoch": 1.4398507926639725,
      "grad_norm": 0.7836673259735107,
      "learning_rate": 2.800746036680137e-06,
      "loss": 0.2274,
      "step": 18528
    },
    {
      "epoch": 1.4399285048181536,
      "grad_norm": 0.7265959978103638,
      "learning_rate": 2.800357475909232e-06,
      "loss": 0.3121,
      "step": 18529
    },
    {
      "epoch": 1.4400062169723344,
      "grad_norm": 0.5499865412712097,
      "learning_rate": 2.799968915138328e-06,
      "loss": 0.173,
      "step": 18530
    },
    {
      "epoch": 1.4400839291265153,
      "grad_norm": 0.1471518576145172,
      "learning_rate": 2.7995803543674234e-06,
      "loss": 0.042,
      "step": 18531
    },
    {
      "epoch": 1.4401616412806963,
      "grad_norm": 0.6667487621307373,
      "learning_rate": 2.7991917935965183e-06,
      "loss": 0.2558,
      "step": 18532
    },
    {
      "epoch": 1.4402393534348772,
      "grad_norm": 0.2874693274497986,
      "learning_rate": 2.798803232825614e-06,
      "loss": 0.0342,
      "step": 18533
    },
    {
      "epoch": 1.440317065589058,
      "grad_norm": 0.4259587824344635,
      "learning_rate": 2.7984146720547095e-06,
      "loss": 0.1015,
      "step": 18534
    },
    {
      "epoch": 1.440394777743239,
      "grad_norm": 0.9685226082801819,
      "learning_rate": 2.798026111283805e-06,
      "loss": 0.4264,
      "step": 18535
    },
    {
      "epoch": 1.44047248989742,
      "grad_norm": 0.3546837270259857,
      "learning_rate": 2.7976375505129006e-06,
      "loss": 0.1681,
      "step": 18536
    },
    {
      "epoch": 1.4405502020516008,
      "grad_norm": 0.6610205173492432,
      "learning_rate": 2.7972489897419956e-06,
      "loss": 0.5242,
      "step": 18537
    },
    {
      "epoch": 1.4406279142057818,
      "grad_norm": 0.2286434918642044,
      "learning_rate": 2.7968604289710914e-06,
      "loss": 0.0299,
      "step": 18538
    },
    {
      "epoch": 1.4407056263599627,
      "grad_norm": 2.2903671264648438,
      "learning_rate": 2.7964718682001868e-06,
      "loss": 0.1964,
      "step": 18539
    },
    {
      "epoch": 1.4407833385141435,
      "grad_norm": 0.15503673255443573,
      "learning_rate": 2.796083307429282e-06,
      "loss": 0.02,
      "step": 18540
    },
    {
      "epoch": 1.4408610506683246,
      "grad_norm": 0.43012505769729614,
      "learning_rate": 2.795694746658378e-06,
      "loss": 0.0788,
      "step": 18541
    },
    {
      "epoch": 1.4409387628225054,
      "grad_norm": 0.13423369824886322,
      "learning_rate": 2.795306185887473e-06,
      "loss": 0.0481,
      "step": 18542
    },
    {
      "epoch": 1.4410164749766863,
      "grad_norm": 0.5077365040779114,
      "learning_rate": 2.7949176251165683e-06,
      "loss": 0.5125,
      "step": 18543
    },
    {
      "epoch": 1.4410941871308673,
      "grad_norm": 0.3522476255893707,
      "learning_rate": 2.794529064345664e-06,
      "loss": 0.0795,
      "step": 18544
    },
    {
      "epoch": 1.4411718992850482,
      "grad_norm": 1.2346974611282349,
      "learning_rate": 2.7941405035747594e-06,
      "loss": 0.249,
      "step": 18545
    },
    {
      "epoch": 1.441249611439229,
      "grad_norm": 0.4786376655101776,
      "learning_rate": 2.7937519428038544e-06,
      "loss": 0.3614,
      "step": 18546
    },
    {
      "epoch": 1.44132732359341,
      "grad_norm": 0.24663035571575165,
      "learning_rate": 2.79336338203295e-06,
      "loss": 0.0748,
      "step": 18547
    },
    {
      "epoch": 1.441405035747591,
      "grad_norm": 0.6697821617126465,
      "learning_rate": 2.7929748212620455e-06,
      "loss": 0.1654,
      "step": 18548
    },
    {
      "epoch": 1.4414827479017718,
      "grad_norm": 0.4334715008735657,
      "learning_rate": 2.792586260491141e-06,
      "loss": 0.0885,
      "step": 18549
    },
    {
      "epoch": 1.4415604600559528,
      "grad_norm": 0.9657827615737915,
      "learning_rate": 2.7921976997202367e-06,
      "loss": 0.0784,
      "step": 18550
    },
    {
      "epoch": 1.4416381722101337,
      "grad_norm": 0.5313297510147095,
      "learning_rate": 2.7918091389493317e-06,
      "loss": 0.2263,
      "step": 18551
    },
    {
      "epoch": 1.4417158843643145,
      "grad_norm": 1.04973566532135,
      "learning_rate": 2.7914205781784275e-06,
      "loss": 0.3555,
      "step": 18552
    },
    {
      "epoch": 1.4417935965184956,
      "grad_norm": 0.8177127242088318,
      "learning_rate": 2.791032017407523e-06,
      "loss": 0.3407,
      "step": 18553
    },
    {
      "epoch": 1.4418713086726764,
      "grad_norm": 0.5788792967796326,
      "learning_rate": 2.790643456636618e-06,
      "loss": 0.2582,
      "step": 18554
    },
    {
      "epoch": 1.4419490208268573,
      "grad_norm": 0.3723248243331909,
      "learning_rate": 2.790254895865714e-06,
      "loss": 0.4677,
      "step": 18555
    },
    {
      "epoch": 1.4420267329810383,
      "grad_norm": 0.6108993291854858,
      "learning_rate": 2.789866335094809e-06,
      "loss": 0.2416,
      "step": 18556
    },
    {
      "epoch": 1.4421044451352192,
      "grad_norm": 0.19288691878318787,
      "learning_rate": 2.7894777743239043e-06,
      "loss": 0.0799,
      "step": 18557
    },
    {
      "epoch": 1.4421821572894,
      "grad_norm": 0.8804296851158142,
      "learning_rate": 2.789089213553e-06,
      "loss": 0.3693,
      "step": 18558
    },
    {
      "epoch": 1.442259869443581,
      "grad_norm": 0.39328303933143616,
      "learning_rate": 2.7887006527820955e-06,
      "loss": 0.0924,
      "step": 18559
    },
    {
      "epoch": 1.442337581597762,
      "grad_norm": 0.6440390944480896,
      "learning_rate": 2.7883120920111904e-06,
      "loss": 0.2839,
      "step": 18560
    },
    {
      "epoch": 1.4424152937519428,
      "grad_norm": 0.49452894926071167,
      "learning_rate": 2.7879235312402862e-06,
      "loss": 0.4937,
      "step": 18561
    },
    {
      "epoch": 1.4424930059061238,
      "grad_norm": 0.42571449279785156,
      "learning_rate": 2.7875349704693816e-06,
      "loss": 0.0838,
      "step": 18562
    },
    {
      "epoch": 1.4425707180603047,
      "grad_norm": 0.9198188185691833,
      "learning_rate": 2.787146409698477e-06,
      "loss": 0.4648,
      "step": 18563
    },
    {
      "epoch": 1.4426484302144855,
      "grad_norm": 0.9349355697631836,
      "learning_rate": 2.7867578489275728e-06,
      "loss": 0.2572,
      "step": 18564
    },
    {
      "epoch": 1.4427261423686666,
      "grad_norm": 0.12815749645233154,
      "learning_rate": 2.7863692881566677e-06,
      "loss": 0.0332,
      "step": 18565
    },
    {
      "epoch": 1.4428038545228474,
      "grad_norm": 0.7531100511550903,
      "learning_rate": 2.785980727385763e-06,
      "loss": 0.2368,
      "step": 18566
    },
    {
      "epoch": 1.4428815666770283,
      "grad_norm": 0.44953641295433044,
      "learning_rate": 2.785592166614859e-06,
      "loss": 0.2775,
      "step": 18567
    },
    {
      "epoch": 1.4429592788312093,
      "grad_norm": 0.6433892250061035,
      "learning_rate": 2.7852036058439543e-06,
      "loss": 0.392,
      "step": 18568
    },
    {
      "epoch": 1.4430369909853902,
      "grad_norm": 0.13547611236572266,
      "learning_rate": 2.78481504507305e-06,
      "loss": 0.0077,
      "step": 18569
    },
    {
      "epoch": 1.443114703139571,
      "grad_norm": 0.6933578848838806,
      "learning_rate": 2.784426484302145e-06,
      "loss": 0.4013,
      "step": 18570
    },
    {
      "epoch": 1.4431924152937519,
      "grad_norm": 0.3122250437736511,
      "learning_rate": 2.7840379235312404e-06,
      "loss": 0.0697,
      "step": 18571
    },
    {
      "epoch": 1.443270127447933,
      "grad_norm": 0.4320002794265747,
      "learning_rate": 2.783649362760336e-06,
      "loss": 0.2486,
      "step": 18572
    },
    {
      "epoch": 1.4433478396021138,
      "grad_norm": 0.1226058229804039,
      "learning_rate": 2.7832608019894316e-06,
      "loss": 0.0177,
      "step": 18573
    },
    {
      "epoch": 1.4434255517562946,
      "grad_norm": 0.10428541153669357,
      "learning_rate": 2.7828722412185265e-06,
      "loss": 0.0304,
      "step": 18574
    },
    {
      "epoch": 1.4435032639104757,
      "grad_norm": 0.05933789908885956,
      "learning_rate": 2.7824836804476223e-06,
      "loss": 0.0051,
      "step": 18575
    },
    {
      "epoch": 1.4435809760646565,
      "grad_norm": 0.42352038621902466,
      "learning_rate": 2.7820951196767177e-06,
      "loss": 0.1368,
      "step": 18576
    },
    {
      "epoch": 1.4436586882188374,
      "grad_norm": 0.2137550711631775,
      "learning_rate": 2.781706558905813e-06,
      "loss": 0.0497,
      "step": 18577
    },
    {
      "epoch": 1.4437364003730182,
      "grad_norm": 0.19663242995738983,
      "learning_rate": 2.781317998134909e-06,
      "loss": 0.0481,
      "step": 18578
    },
    {
      "epoch": 1.4438141125271993,
      "grad_norm": 0.3594581186771393,
      "learning_rate": 2.780929437364004e-06,
      "loss": 0.0383,
      "step": 18579
    },
    {
      "epoch": 1.44389182468138,
      "grad_norm": 0.3169806897640228,
      "learning_rate": 2.780540876593099e-06,
      "loss": 0.0457,
      "step": 18580
    },
    {
      "epoch": 1.443969536835561,
      "grad_norm": 0.7529349327087402,
      "learning_rate": 2.780152315822195e-06,
      "loss": 0.1441,
      "step": 18581
    },
    {
      "epoch": 1.444047248989742,
      "grad_norm": 0.6277664303779602,
      "learning_rate": 2.7797637550512904e-06,
      "loss": 0.3296,
      "step": 18582
    },
    {
      "epoch": 1.4441249611439229,
      "grad_norm": 0.3151858150959015,
      "learning_rate": 2.7793751942803857e-06,
      "loss": 0.067,
      "step": 18583
    },
    {
      "epoch": 1.4442026732981037,
      "grad_norm": 0.26455527544021606,
      "learning_rate": 2.778986633509481e-06,
      "loss": 0.2164,
      "step": 18584
    },
    {
      "epoch": 1.4442803854522848,
      "grad_norm": 0.35145652294158936,
      "learning_rate": 2.7785980727385765e-06,
      "loss": 0.1893,
      "step": 18585
    },
    {
      "epoch": 1.4443580976064656,
      "grad_norm": 0.2690449655056,
      "learning_rate": 2.7782095119676723e-06,
      "loss": 0.1144,
      "step": 18586
    },
    {
      "epoch": 1.4444358097606464,
      "grad_norm": 0.49452662467956543,
      "learning_rate": 2.7778209511967672e-06,
      "loss": 0.1562,
      "step": 18587
    },
    {
      "epoch": 1.4445135219148275,
      "grad_norm": 0.8839042782783508,
      "learning_rate": 2.7774323904258626e-06,
      "loss": 0.2703,
      "step": 18588
    },
    {
      "epoch": 1.4445912340690084,
      "grad_norm": 0.6369678378105164,
      "learning_rate": 2.7770438296549584e-06,
      "loss": 0.3577,
      "step": 18589
    },
    {
      "epoch": 1.4446689462231892,
      "grad_norm": 0.30837953090667725,
      "learning_rate": 2.7766552688840538e-06,
      "loss": 0.0389,
      "step": 18590
    },
    {
      "epoch": 1.4447466583773703,
      "grad_norm": 0.4190812408924103,
      "learning_rate": 2.7762667081131487e-06,
      "loss": 0.2207,
      "step": 18591
    },
    {
      "epoch": 1.444824370531551,
      "grad_norm": 0.28503578901290894,
      "learning_rate": 2.7758781473422445e-06,
      "loss": 0.0432,
      "step": 18592
    },
    {
      "epoch": 1.444902082685732,
      "grad_norm": 0.6598913073539734,
      "learning_rate": 2.77548958657134e-06,
      "loss": 0.5218,
      "step": 18593
    },
    {
      "epoch": 1.444979794839913,
      "grad_norm": 1.1696984767913818,
      "learning_rate": 2.7751010258004353e-06,
      "loss": 0.1005,
      "step": 18594
    },
    {
      "epoch": 1.4450575069940939,
      "grad_norm": 0.2183992862701416,
      "learning_rate": 2.774712465029531e-06,
      "loss": 0.0415,
      "step": 18595
    },
    {
      "epoch": 1.4451352191482747,
      "grad_norm": 0.412434458732605,
      "learning_rate": 2.774323904258626e-06,
      "loss": 0.0933,
      "step": 18596
    },
    {
      "epoch": 1.4452129313024558,
      "grad_norm": 1.0647207498550415,
      "learning_rate": 2.773935343487722e-06,
      "loss": 0.4022,
      "step": 18597
    },
    {
      "epoch": 1.4452906434566366,
      "grad_norm": 0.8818567991256714,
      "learning_rate": 2.773546782716817e-06,
      "loss": 0.3659,
      "step": 18598
    },
    {
      "epoch": 1.4453683556108174,
      "grad_norm": 0.4694642424583435,
      "learning_rate": 2.7731582219459125e-06,
      "loss": 0.2904,
      "step": 18599
    },
    {
      "epoch": 1.4454460677649985,
      "grad_norm": 0.5571526288986206,
      "learning_rate": 2.7727696611750083e-06,
      "loss": 0.1676,
      "step": 18600
    },
    {
      "epoch": 1.4455237799191794,
      "grad_norm": 0.44799813628196716,
      "learning_rate": 2.7723811004041033e-06,
      "loss": 0.0674,
      "step": 18601
    },
    {
      "epoch": 1.4456014920733602,
      "grad_norm": 0.4982312023639679,
      "learning_rate": 2.7719925396331987e-06,
      "loss": 0.1632,
      "step": 18602
    },
    {
      "epoch": 1.4456792042275413,
      "grad_norm": 0.45949408411979675,
      "learning_rate": 2.7716039788622945e-06,
      "loss": 0.1482,
      "step": 18603
    },
    {
      "epoch": 1.445756916381722,
      "grad_norm": 0.884149432182312,
      "learning_rate": 2.77121541809139e-06,
      "loss": 0.3446,
      "step": 18604
    },
    {
      "epoch": 1.445834628535903,
      "grad_norm": 0.12504738569259644,
      "learning_rate": 2.7708268573204848e-06,
      "loss": 0.0444,
      "step": 18605
    },
    {
      "epoch": 1.445912340690084,
      "grad_norm": 1.5428723096847534,
      "learning_rate": 2.7704382965495806e-06,
      "loss": 0.1666,
      "step": 18606
    },
    {
      "epoch": 1.4459900528442649,
      "grad_norm": 0.3702598512172699,
      "learning_rate": 2.770049735778676e-06,
      "loss": 0.0736,
      "step": 18607
    },
    {
      "epoch": 1.4460677649984457,
      "grad_norm": 0.3352512717247009,
      "learning_rate": 2.7696611750077713e-06,
      "loss": 0.058,
      "step": 18608
    },
    {
      "epoch": 1.4461454771526268,
      "grad_norm": 0.20041929185390472,
      "learning_rate": 2.769272614236867e-06,
      "loss": 0.0358,
      "step": 18609
    },
    {
      "epoch": 1.4462231893068076,
      "grad_norm": 0.30606260895729065,
      "learning_rate": 2.768884053465962e-06,
      "loss": 0.1774,
      "step": 18610
    },
    {
      "epoch": 1.4463009014609884,
      "grad_norm": 0.41527098417282104,
      "learning_rate": 2.7684954926950574e-06,
      "loss": 0.2842,
      "step": 18611
    },
    {
      "epoch": 1.4463786136151695,
      "grad_norm": 1.0141242742538452,
      "learning_rate": 2.7681069319241532e-06,
      "loss": 0.1234,
      "step": 18612
    },
    {
      "epoch": 1.4464563257693503,
      "grad_norm": 0.2714408040046692,
      "learning_rate": 2.7677183711532486e-06,
      "loss": 0.0226,
      "step": 18613
    },
    {
      "epoch": 1.4465340379235312,
      "grad_norm": 0.8762124180793762,
      "learning_rate": 2.7673298103823444e-06,
      "loss": 0.4025,
      "step": 18614
    },
    {
      "epoch": 1.4466117500777123,
      "grad_norm": 0.29629191756248474,
      "learning_rate": 2.7669412496114394e-06,
      "loss": 0.0282,
      "step": 18615
    },
    {
      "epoch": 1.446689462231893,
      "grad_norm": 0.5070215463638306,
      "learning_rate": 2.7665526888405347e-06,
      "loss": 0.1471,
      "step": 18616
    },
    {
      "epoch": 1.446767174386074,
      "grad_norm": 0.14454896748065948,
      "learning_rate": 2.7661641280696305e-06,
      "loss": 0.026,
      "step": 18617
    },
    {
      "epoch": 1.446844886540255,
      "grad_norm": 1.1677688360214233,
      "learning_rate": 2.765775567298726e-06,
      "loss": 0.5021,
      "step": 18618
    },
    {
      "epoch": 1.4469225986944358,
      "grad_norm": 0.11122293025255203,
      "learning_rate": 2.765387006527821e-06,
      "loss": 0.0192,
      "step": 18619
    },
    {
      "epoch": 1.4470003108486167,
      "grad_norm": 0.45604875683784485,
      "learning_rate": 2.7649984457569167e-06,
      "loss": 0.6395,
      "step": 18620
    },
    {
      "epoch": 1.4470780230027978,
      "grad_norm": 0.3848174512386322,
      "learning_rate": 2.764609884986012e-06,
      "loss": 0.1998,
      "step": 18621
    },
    {
      "epoch": 1.4471557351569786,
      "grad_norm": 9.5885591506958,
      "learning_rate": 2.7642213242151074e-06,
      "loss": 3.2296,
      "step": 18622
    },
    {
      "epoch": 1.4472334473111594,
      "grad_norm": 0.9482513070106506,
      "learning_rate": 2.763832763444203e-06,
      "loss": 0.5029,
      "step": 18623
    },
    {
      "epoch": 1.4473111594653405,
      "grad_norm": 4.301455974578857,
      "learning_rate": 2.763444202673298e-06,
      "loss": 0.9401,
      "step": 18624
    },
    {
      "epoch": 1.4473888716195213,
      "grad_norm": 0.41397982835769653,
      "learning_rate": 2.7630556419023935e-06,
      "loss": 0.4512,
      "step": 18625
    },
    {
      "epoch": 1.4474665837737022,
      "grad_norm": 0.9340576529502869,
      "learning_rate": 2.7626670811314893e-06,
      "loss": 0.1588,
      "step": 18626
    },
    {
      "epoch": 1.4475442959278833,
      "grad_norm": 0.1469324380159378,
      "learning_rate": 2.7622785203605847e-06,
      "loss": 0.0163,
      "step": 18627
    },
    {
      "epoch": 1.447622008082064,
      "grad_norm": 0.36507758498191833,
      "learning_rate": 2.7618899595896805e-06,
      "loss": 0.0955,
      "step": 18628
    },
    {
      "epoch": 1.447699720236245,
      "grad_norm": 0.48780322074890137,
      "learning_rate": 2.7615013988187754e-06,
      "loss": 0.1939,
      "step": 18629
    },
    {
      "epoch": 1.447777432390426,
      "grad_norm": 0.6671086549758911,
      "learning_rate": 2.761112838047871e-06,
      "loss": 0.0955,
      "step": 18630
    },
    {
      "epoch": 1.4478551445446068,
      "grad_norm": 0.2618139088153839,
      "learning_rate": 2.7607242772769666e-06,
      "loss": 0.0844,
      "step": 18631
    },
    {
      "epoch": 1.4479328566987877,
      "grad_norm": 0.6067234873771667,
      "learning_rate": 2.760335716506062e-06,
      "loss": 0.1591,
      "step": 18632
    },
    {
      "epoch": 1.4480105688529685,
      "grad_norm": 0.4053105115890503,
      "learning_rate": 2.759947155735157e-06,
      "loss": 0.0858,
      "step": 18633
    },
    {
      "epoch": 1.4480882810071496,
      "grad_norm": 0.5799776911735535,
      "learning_rate": 2.7595585949642527e-06,
      "loss": 0.2698,
      "step": 18634
    },
    {
      "epoch": 1.4481659931613304,
      "grad_norm": 0.38120582699775696,
      "learning_rate": 2.759170034193348e-06,
      "loss": 0.0837,
      "step": 18635
    },
    {
      "epoch": 1.4482437053155113,
      "grad_norm": 0.3074764013290405,
      "learning_rate": 2.7587814734224435e-06,
      "loss": 0.151,
      "step": 18636
    },
    {
      "epoch": 1.4483214174696923,
      "grad_norm": 0.23979206383228302,
      "learning_rate": 2.7583929126515393e-06,
      "loss": 0.1714,
      "step": 18637
    },
    {
      "epoch": 1.4483991296238732,
      "grad_norm": 0.3657815158367157,
      "learning_rate": 2.7580043518806342e-06,
      "loss": 0.152,
      "step": 18638
    },
    {
      "epoch": 1.448476841778054,
      "grad_norm": 0.4620662331581116,
      "learning_rate": 2.7576157911097296e-06,
      "loss": 0.1861,
      "step": 18639
    },
    {
      "epoch": 1.4485545539322349,
      "grad_norm": 0.32874032855033875,
      "learning_rate": 2.7572272303388254e-06,
      "loss": 0.0294,
      "step": 18640
    },
    {
      "epoch": 1.448632266086416,
      "grad_norm": 0.7537972927093506,
      "learning_rate": 2.7568386695679208e-06,
      "loss": 0.3733,
      "step": 18641
    },
    {
      "epoch": 1.4487099782405968,
      "grad_norm": 1.1868518590927124,
      "learning_rate": 2.7564501087970166e-06,
      "loss": 0.2489,
      "step": 18642
    },
    {
      "epoch": 1.4487876903947776,
      "grad_norm": 0.7169753313064575,
      "learning_rate": 2.7560615480261115e-06,
      "loss": 0.1677,
      "step": 18643
    },
    {
      "epoch": 1.4488654025489587,
      "grad_norm": 0.434533953666687,
      "learning_rate": 2.755672987255207e-06,
      "loss": 0.099,
      "step": 18644
    },
    {
      "epoch": 1.4489431147031395,
      "grad_norm": 0.3732374906539917,
      "learning_rate": 2.7552844264843027e-06,
      "loss": 0.1149,
      "step": 18645
    },
    {
      "epoch": 1.4490208268573204,
      "grad_norm": 0.6615986824035645,
      "learning_rate": 2.7548958657133976e-06,
      "loss": 0.3074,
      "step": 18646
    },
    {
      "epoch": 1.4490985390115014,
      "grad_norm": 0.8198770880699158,
      "learning_rate": 2.754507304942493e-06,
      "loss": 0.3524,
      "step": 18647
    },
    {
      "epoch": 1.4491762511656823,
      "grad_norm": 0.28809884190559387,
      "learning_rate": 2.754118744171589e-06,
      "loss": 0.0303,
      "step": 18648
    },
    {
      "epoch": 1.4492539633198631,
      "grad_norm": 0.587878942489624,
      "learning_rate": 2.753730183400684e-06,
      "loss": 0.1971,
      "step": 18649
    },
    {
      "epoch": 1.4493316754740442,
      "grad_norm": 0.5773198008537292,
      "learning_rate": 2.753341622629779e-06,
      "loss": 0.1242,
      "step": 18650
    },
    {
      "epoch": 1.449409387628225,
      "grad_norm": 0.20139764249324799,
      "learning_rate": 2.752953061858875e-06,
      "loss": 0.015,
      "step": 18651
    },
    {
      "epoch": 1.4494870997824059,
      "grad_norm": 0.512685239315033,
      "learning_rate": 2.7525645010879703e-06,
      "loss": 0.7442,
      "step": 18652
    },
    {
      "epoch": 1.449564811936587,
      "grad_norm": 0.5958513617515564,
      "learning_rate": 2.7521759403170657e-06,
      "loss": 0.0599,
      "step": 18653
    },
    {
      "epoch": 1.4496425240907678,
      "grad_norm": 0.8545406460762024,
      "learning_rate": 2.7517873795461615e-06,
      "loss": 0.3121,
      "step": 18654
    },
    {
      "epoch": 1.4497202362449486,
      "grad_norm": 0.5265942811965942,
      "learning_rate": 2.7513988187752564e-06,
      "loss": 0.2077,
      "step": 18655
    },
    {
      "epoch": 1.4497979483991297,
      "grad_norm": 0.9654244184494019,
      "learning_rate": 2.751010258004352e-06,
      "loss": 0.4374,
      "step": 18656
    },
    {
      "epoch": 1.4498756605533105,
      "grad_norm": 0.7221872210502625,
      "learning_rate": 2.7506216972334476e-06,
      "loss": 0.4104,
      "step": 18657
    },
    {
      "epoch": 1.4499533727074914,
      "grad_norm": 1.0004122257232666,
      "learning_rate": 2.750233136462543e-06,
      "loss": 0.3455,
      "step": 18658
    },
    {
      "epoch": 1.4500310848616724,
      "grad_norm": 2.5649170875549316,
      "learning_rate": 2.7498445756916388e-06,
      "loss": 0.631,
      "step": 18659
    },
    {
      "epoch": 1.4501087970158533,
      "grad_norm": 0.36872759461402893,
      "learning_rate": 2.7494560149207337e-06,
      "loss": 0.0678,
      "step": 18660
    },
    {
      "epoch": 1.450186509170034,
      "grad_norm": 1.3449002504348755,
      "learning_rate": 2.749067454149829e-06,
      "loss": 0.5312,
      "step": 18661
    },
    {
      "epoch": 1.4502642213242152,
      "grad_norm": 0.40244433283805847,
      "learning_rate": 2.748678893378925e-06,
      "loss": 0.1053,
      "step": 18662
    },
    {
      "epoch": 1.450341933478396,
      "grad_norm": 0.29410409927368164,
      "learning_rate": 2.7482903326080202e-06,
      "loss": 0.0588,
      "step": 18663
    },
    {
      "epoch": 1.4504196456325769,
      "grad_norm": 0.4126705527305603,
      "learning_rate": 2.747901771837115e-06,
      "loss": 0.0753,
      "step": 18664
    },
    {
      "epoch": 1.450497357786758,
      "grad_norm": 0.8402007818222046,
      "learning_rate": 2.747513211066211e-06,
      "loss": 0.3687,
      "step": 18665
    },
    {
      "epoch": 1.4505750699409388,
      "grad_norm": 1.7654333114624023,
      "learning_rate": 2.7471246502953064e-06,
      "loss": 0.427,
      "step": 18666
    },
    {
      "epoch": 1.4506527820951196,
      "grad_norm": 0.5782641172409058,
      "learning_rate": 2.7467360895244017e-06,
      "loss": 0.1369,
      "step": 18667
    },
    {
      "epoch": 1.4507304942493007,
      "grad_norm": 0.5011165142059326,
      "learning_rate": 2.7463475287534975e-06,
      "loss": 0.2642,
      "step": 18668
    },
    {
      "epoch": 1.4508082064034815,
      "grad_norm": 0.30513796210289,
      "learning_rate": 2.7459589679825925e-06,
      "loss": 0.0967,
      "step": 18669
    },
    {
      "epoch": 1.4508859185576624,
      "grad_norm": 0.23865407705307007,
      "learning_rate": 2.745570407211688e-06,
      "loss": 0.0458,
      "step": 18670
    },
    {
      "epoch": 1.4509636307118434,
      "grad_norm": 0.3761691153049469,
      "learning_rate": 2.7451818464407837e-06,
      "loss": 0.0794,
      "step": 18671
    },
    {
      "epoch": 1.4510413428660243,
      "grad_norm": 0.5695059895515442,
      "learning_rate": 2.744793285669879e-06,
      "loss": 0.0921,
      "step": 18672
    },
    {
      "epoch": 1.451119055020205,
      "grad_norm": 0.407895028591156,
      "learning_rate": 2.744404724898975e-06,
      "loss": 0.2689,
      "step": 18673
    },
    {
      "epoch": 1.4511967671743862,
      "grad_norm": 0.8102689385414124,
      "learning_rate": 2.7440161641280698e-06,
      "loss": 0.56,
      "step": 18674
    },
    {
      "epoch": 1.451274479328567,
      "grad_norm": 1.0056713819503784,
      "learning_rate": 2.743627603357165e-06,
      "loss": 0.2382,
      "step": 18675
    },
    {
      "epoch": 1.4513521914827479,
      "grad_norm": 0.7846274971961975,
      "learning_rate": 2.743239042586261e-06,
      "loss": 0.1914,
      "step": 18676
    },
    {
      "epoch": 1.451429903636929,
      "grad_norm": 0.6218088269233704,
      "learning_rate": 2.7428504818153563e-06,
      "loss": 0.2567,
      "step": 18677
    },
    {
      "epoch": 1.4515076157911098,
      "grad_norm": 0.6806085705757141,
      "learning_rate": 2.7424619210444513e-06,
      "loss": 0.0758,
      "step": 18678
    },
    {
      "epoch": 1.4515853279452906,
      "grad_norm": 0.16227051615715027,
      "learning_rate": 2.742073360273547e-06,
      "loss": 0.032,
      "step": 18679
    },
    {
      "epoch": 1.4516630400994717,
      "grad_norm": 0.7757323980331421,
      "learning_rate": 2.7416847995026424e-06,
      "loss": 0.2182,
      "step": 18680
    },
    {
      "epoch": 1.4517407522536525,
      "grad_norm": 0.8532763123512268,
      "learning_rate": 2.741296238731738e-06,
      "loss": 0.2686,
      "step": 18681
    },
    {
      "epoch": 1.4518184644078334,
      "grad_norm": 0.35284197330474854,
      "learning_rate": 2.7409076779608336e-06,
      "loss": 0.1009,
      "step": 18682
    },
    {
      "epoch": 1.4518961765620144,
      "grad_norm": 0.41112497448921204,
      "learning_rate": 2.7405191171899286e-06,
      "loss": 0.195,
      "step": 18683
    },
    {
      "epoch": 1.4519738887161953,
      "grad_norm": 0.21247228980064392,
      "learning_rate": 2.740130556419024e-06,
      "loss": 0.0437,
      "step": 18684
    },
    {
      "epoch": 1.452051600870376,
      "grad_norm": 1.2602821588516235,
      "learning_rate": 2.7397419956481197e-06,
      "loss": 0.3341,
      "step": 18685
    },
    {
      "epoch": 1.4521293130245572,
      "grad_norm": 0.6652107238769531,
      "learning_rate": 2.739353434877215e-06,
      "loss": 0.1666,
      "step": 18686
    },
    {
      "epoch": 1.452207025178738,
      "grad_norm": 1.0469508171081543,
      "learning_rate": 2.73896487410631e-06,
      "loss": 0.463,
      "step": 18687
    },
    {
      "epoch": 1.4522847373329189,
      "grad_norm": 0.782490611076355,
      "learning_rate": 2.738576313335406e-06,
      "loss": 0.1425,
      "step": 18688
    },
    {
      "epoch": 1.4523624494871,
      "grad_norm": 0.5324830412864685,
      "learning_rate": 2.7381877525645012e-06,
      "loss": 0.1716,
      "step": 18689
    },
    {
      "epoch": 1.4524401616412808,
      "grad_norm": 1.0653976202011108,
      "learning_rate": 2.737799191793597e-06,
      "loss": 0.054,
      "step": 18690
    },
    {
      "epoch": 1.4525178737954616,
      "grad_norm": 0.540339469909668,
      "learning_rate": 2.7374106310226924e-06,
      "loss": 0.1147,
      "step": 18691
    },
    {
      "epoch": 1.4525955859496424,
      "grad_norm": 0.7361922860145569,
      "learning_rate": 2.7370220702517873e-06,
      "loss": 0.3091,
      "step": 18692
    },
    {
      "epoch": 1.4526732981038235,
      "grad_norm": 0.11607453227043152,
      "learning_rate": 2.736633509480883e-06,
      "loss": 0.0359,
      "step": 18693
    },
    {
      "epoch": 1.4527510102580043,
      "grad_norm": 0.8636339902877808,
      "learning_rate": 2.7362449487099785e-06,
      "loss": 0.3366,
      "step": 18694
    },
    {
      "epoch": 1.4528287224121852,
      "grad_norm": 0.7437629699707031,
      "learning_rate": 2.735856387939074e-06,
      "loss": 0.2884,
      "step": 18695
    },
    {
      "epoch": 1.4529064345663663,
      "grad_norm": 0.5660157799720764,
      "learning_rate": 2.7354678271681697e-06,
      "loss": 0.2344,
      "step": 18696
    },
    {
      "epoch": 1.452984146720547,
      "grad_norm": 0.5089339017868042,
      "learning_rate": 2.7350792663972646e-06,
      "loss": 0.2248,
      "step": 18697
    },
    {
      "epoch": 1.453061858874728,
      "grad_norm": 0.6663084030151367,
      "learning_rate": 2.73469070562636e-06,
      "loss": 0.2844,
      "step": 18698
    },
    {
      "epoch": 1.4531395710289088,
      "grad_norm": 0.31866827607154846,
      "learning_rate": 2.734302144855456e-06,
      "loss": 0.0147,
      "step": 18699
    },
    {
      "epoch": 1.4532172831830898,
      "grad_norm": 0.14773468673229218,
      "learning_rate": 2.733913584084551e-06,
      "loss": 0.0876,
      "step": 18700
    },
    {
      "epoch": 1.4532949953372707,
      "grad_norm": 0.85627281665802,
      "learning_rate": 2.733525023313646e-06,
      "loss": 0.1333,
      "step": 18701
    },
    {
      "epoch": 1.4533727074914515,
      "grad_norm": 0.566892683506012,
      "learning_rate": 2.733136462542742e-06,
      "loss": 0.1951,
      "step": 18702
    },
    {
      "epoch": 1.4534504196456326,
      "grad_norm": 0.9212883114814758,
      "learning_rate": 2.7327479017718373e-06,
      "loss": 0.2974,
      "step": 18703
    },
    {
      "epoch": 1.4535281317998134,
      "grad_norm": 0.2589908540248871,
      "learning_rate": 2.732359341000933e-06,
      "loss": 0.1045,
      "step": 18704
    },
    {
      "epoch": 1.4536058439539943,
      "grad_norm": 0.5382182002067566,
      "learning_rate": 2.7319707802300285e-06,
      "loss": 0.1905,
      "step": 18705
    },
    {
      "epoch": 1.4536835561081753,
      "grad_norm": 0.7706303000450134,
      "learning_rate": 2.7315822194591234e-06,
      "loss": 0.2562,
      "step": 18706
    },
    {
      "epoch": 1.4537612682623562,
      "grad_norm": 0.5849355459213257,
      "learning_rate": 2.7311936586882192e-06,
      "loss": 0.1011,
      "step": 18707
    },
    {
      "epoch": 1.453838980416537,
      "grad_norm": 0.5178838968276978,
      "learning_rate": 2.7308050979173146e-06,
      "loss": 0.1435,
      "step": 18708
    },
    {
      "epoch": 1.453916692570718,
      "grad_norm": 0.6896300911903381,
      "learning_rate": 2.73041653714641e-06,
      "loss": 0.1473,
      "step": 18709
    },
    {
      "epoch": 1.453994404724899,
      "grad_norm": 0.7592267990112305,
      "learning_rate": 2.7300279763755053e-06,
      "loss": 0.2131,
      "step": 18710
    },
    {
      "epoch": 1.4540721168790798,
      "grad_norm": 0.15873944759368896,
      "learning_rate": 2.7296394156046007e-06,
      "loss": 0.0173,
      "step": 18711
    },
    {
      "epoch": 1.4541498290332608,
      "grad_norm": 0.9041695594787598,
      "learning_rate": 2.729250854833696e-06,
      "loss": 0.2735,
      "step": 18712
    },
    {
      "epoch": 1.4542275411874417,
      "grad_norm": 1.3732393980026245,
      "learning_rate": 2.728862294062792e-06,
      "loss": 0.2908,
      "step": 18713
    },
    {
      "epoch": 1.4543052533416225,
      "grad_norm": 0.5181708335876465,
      "learning_rate": 2.728473733291887e-06,
      "loss": 0.2355,
      "step": 18714
    },
    {
      "epoch": 1.4543829654958036,
      "grad_norm": 0.3665400445461273,
      "learning_rate": 2.728085172520982e-06,
      "loss": 0.0801,
      "step": 18715
    },
    {
      "epoch": 1.4544606776499844,
      "grad_norm": 1.4749611616134644,
      "learning_rate": 2.727696611750078e-06,
      "loss": 0.1979,
      "step": 18716
    },
    {
      "epoch": 1.4545383898041653,
      "grad_norm": 0.7012948989868164,
      "learning_rate": 2.7273080509791734e-06,
      "loss": 0.2677,
      "step": 18717
    },
    {
      "epoch": 1.4546161019583463,
      "grad_norm": 0.5279958248138428,
      "learning_rate": 2.726919490208269e-06,
      "loss": 0.3433,
      "step": 18718
    },
    {
      "epoch": 1.4546938141125272,
      "grad_norm": 0.09033096581697464,
      "learning_rate": 2.726530929437364e-06,
      "loss": 0.0079,
      "step": 18719
    },
    {
      "epoch": 1.454771526266708,
      "grad_norm": 0.13388951122760773,
      "learning_rate": 2.7261423686664595e-06,
      "loss": 0.0177,
      "step": 18720
    },
    {
      "epoch": 1.454849238420889,
      "grad_norm": 0.20194096863269806,
      "learning_rate": 2.7257538078955553e-06,
      "loss": 0.098,
      "step": 18721
    },
    {
      "epoch": 1.45492695057507,
      "grad_norm": 0.7050637006759644,
      "learning_rate": 2.7253652471246507e-06,
      "loss": 0.2543,
      "step": 18722
    },
    {
      "epoch": 1.4550046627292508,
      "grad_norm": 0.7267723083496094,
      "learning_rate": 2.7249766863537456e-06,
      "loss": 0.1913,
      "step": 18723
    },
    {
      "epoch": 1.4550823748834318,
      "grad_norm": 0.42435014247894287,
      "learning_rate": 2.7245881255828414e-06,
      "loss": 0.3533,
      "step": 18724
    },
    {
      "epoch": 1.4551600870376127,
      "grad_norm": 0.4174710512161255,
      "learning_rate": 2.7241995648119368e-06,
      "loss": 0.2645,
      "step": 18725
    },
    {
      "epoch": 1.4552377991917935,
      "grad_norm": 0.6651229858398438,
      "learning_rate": 2.723811004041032e-06,
      "loss": 0.4003,
      "step": 18726
    },
    {
      "epoch": 1.4553155113459746,
      "grad_norm": 0.6416362524032593,
      "learning_rate": 2.723422443270128e-06,
      "loss": 0.5449,
      "step": 18727
    },
    {
      "epoch": 1.4553932235001554,
      "grad_norm": 0.7338389754295349,
      "learning_rate": 2.723033882499223e-06,
      "loss": 0.1393,
      "step": 18728
    },
    {
      "epoch": 1.4554709356543363,
      "grad_norm": 0.4302201271057129,
      "learning_rate": 2.7226453217283183e-06,
      "loss": 0.1038,
      "step": 18729
    },
    {
      "epoch": 1.4555486478085173,
      "grad_norm": 0.08558878302574158,
      "learning_rate": 2.722256760957414e-06,
      "loss": 0.0713,
      "step": 18730
    },
    {
      "epoch": 1.4556263599626982,
      "grad_norm": 0.8597960472106934,
      "learning_rate": 2.7218682001865094e-06,
      "loss": 0.2971,
      "step": 18731
    },
    {
      "epoch": 1.455704072116879,
      "grad_norm": 0.18798625469207764,
      "learning_rate": 2.7214796394156044e-06,
      "loss": 0.0094,
      "step": 18732
    },
    {
      "epoch": 1.45578178427106,
      "grad_norm": 0.7175751328468323,
      "learning_rate": 2.7210910786447e-06,
      "loss": 0.1857,
      "step": 18733
    },
    {
      "epoch": 1.455859496425241,
      "grad_norm": 0.9223309755325317,
      "learning_rate": 2.7207025178737956e-06,
      "loss": 0.1527,
      "step": 18734
    },
    {
      "epoch": 1.4559372085794218,
      "grad_norm": 0.8536098003387451,
      "learning_rate": 2.7203139571028914e-06,
      "loss": 0.5636,
      "step": 18735
    },
    {
      "epoch": 1.4560149207336028,
      "grad_norm": 0.1971970945596695,
      "learning_rate": 2.7199253963319867e-06,
      "loss": 0.0287,
      "step": 18736
    },
    {
      "epoch": 1.4560926328877837,
      "grad_norm": 0.1266145408153534,
      "learning_rate": 2.7195368355610817e-06,
      "loss": 0.0385,
      "step": 18737
    },
    {
      "epoch": 1.4561703450419645,
      "grad_norm": 0.08629761636257172,
      "learning_rate": 2.7191482747901775e-06,
      "loss": 0.0645,
      "step": 18738
    },
    {
      "epoch": 1.4562480571961456,
      "grad_norm": 0.3676249086856842,
      "learning_rate": 2.718759714019273e-06,
      "loss": 0.061,
      "step": 18739
    },
    {
      "epoch": 1.4563257693503264,
      "grad_norm": 0.9163079857826233,
      "learning_rate": 2.7183711532483682e-06,
      "loss": 0.1922,
      "step": 18740
    },
    {
      "epoch": 1.4564034815045073,
      "grad_norm": 0.8062396049499512,
      "learning_rate": 2.717982592477464e-06,
      "loss": 0.1608,
      "step": 18741
    },
    {
      "epoch": 1.4564811936586883,
      "grad_norm": 0.390129029750824,
      "learning_rate": 2.717594031706559e-06,
      "loss": 0.0462,
      "step": 18742
    },
    {
      "epoch": 1.4565589058128692,
      "grad_norm": 0.6079869866371155,
      "learning_rate": 2.7172054709356543e-06,
      "loss": 0.3994,
      "step": 18743
    },
    {
      "epoch": 1.45663661796705,
      "grad_norm": 0.3726273477077484,
      "learning_rate": 2.71681691016475e-06,
      "loss": 0.1745,
      "step": 18744
    },
    {
      "epoch": 1.456714330121231,
      "grad_norm": 0.26336053013801575,
      "learning_rate": 2.7164283493938455e-06,
      "loss": 0.1226,
      "step": 18745
    },
    {
      "epoch": 1.456792042275412,
      "grad_norm": 0.16713528335094452,
      "learning_rate": 2.7160397886229405e-06,
      "loss": 0.0231,
      "step": 18746
    },
    {
      "epoch": 1.4568697544295928,
      "grad_norm": 0.8310995101928711,
      "learning_rate": 2.7156512278520363e-06,
      "loss": 0.3533,
      "step": 18747
    },
    {
      "epoch": 1.4569474665837738,
      "grad_norm": 0.7107505798339844,
      "learning_rate": 2.7152626670811316e-06,
      "loss": 0.1378,
      "step": 18748
    },
    {
      "epoch": 1.4570251787379547,
      "grad_norm": 0.3459492325782776,
      "learning_rate": 2.7148741063102274e-06,
      "loss": 0.1281,
      "step": 18749
    },
    {
      "epoch": 1.4571028908921355,
      "grad_norm": 0.8023995757102966,
      "learning_rate": 2.714485545539323e-06,
      "loss": 0.1938,
      "step": 18750
    },
    {
      "epoch": 1.4571806030463166,
      "grad_norm": 0.3022189438343048,
      "learning_rate": 2.7140969847684178e-06,
      "loss": 0.087,
      "step": 18751
    },
    {
      "epoch": 1.4572583152004974,
      "grad_norm": 0.1695297360420227,
      "learning_rate": 2.7137084239975136e-06,
      "loss": 0.0192,
      "step": 18752
    },
    {
      "epoch": 1.4573360273546783,
      "grad_norm": 0.5219981670379639,
      "learning_rate": 2.713319863226609e-06,
      "loss": 0.1487,
      "step": 18753
    },
    {
      "epoch": 1.457413739508859,
      "grad_norm": 0.2947896718978882,
      "learning_rate": 2.7129313024557043e-06,
      "loss": 0.0551,
      "step": 18754
    },
    {
      "epoch": 1.4574914516630402,
      "grad_norm": 0.3068511188030243,
      "learning_rate": 2.7125427416848e-06,
      "loss": 0.1025,
      "step": 18755
    },
    {
      "epoch": 1.457569163817221,
      "grad_norm": 0.7857229709625244,
      "learning_rate": 2.712154180913895e-06,
      "loss": 0.0961,
      "step": 18756
    },
    {
      "epoch": 1.4576468759714019,
      "grad_norm": 0.7849127650260925,
      "learning_rate": 2.7117656201429904e-06,
      "loss": 0.6259,
      "step": 18757
    },
    {
      "epoch": 1.457724588125583,
      "grad_norm": 0.44206950068473816,
      "learning_rate": 2.7113770593720862e-06,
      "loss": 0.1494,
      "step": 18758
    },
    {
      "epoch": 1.4578023002797638,
      "grad_norm": 0.12077779322862625,
      "learning_rate": 2.7109884986011816e-06,
      "loss": 0.0212,
      "step": 18759
    },
    {
      "epoch": 1.4578800124339446,
      "grad_norm": 0.32301539182662964,
      "learning_rate": 2.7105999378302765e-06,
      "loss": 0.1376,
      "step": 18760
    },
    {
      "epoch": 1.4579577245881254,
      "grad_norm": 0.29745379090309143,
      "learning_rate": 2.7102113770593723e-06,
      "loss": 0.0584,
      "step": 18761
    },
    {
      "epoch": 1.4580354367423065,
      "grad_norm": 0.5603252053260803,
      "learning_rate": 2.7098228162884677e-06,
      "loss": 0.1375,
      "step": 18762
    },
    {
      "epoch": 1.4581131488964874,
      "grad_norm": 1.413027286529541,
      "learning_rate": 2.709434255517563e-06,
      "loss": 0.3538,
      "step": 18763
    },
    {
      "epoch": 1.4581908610506682,
      "grad_norm": 0.347970187664032,
      "learning_rate": 2.709045694746659e-06,
      "loss": 0.0953,
      "step": 18764
    },
    {
      "epoch": 1.4582685732048493,
      "grad_norm": 0.07553388923406601,
      "learning_rate": 2.708657133975754e-06,
      "loss": 0.0098,
      "step": 18765
    },
    {
      "epoch": 1.45834628535903,
      "grad_norm": 0.6523948907852173,
      "learning_rate": 2.7082685732048496e-06,
      "loss": 0.1258,
      "step": 18766
    },
    {
      "epoch": 1.458423997513211,
      "grad_norm": 0.20574744045734406,
      "learning_rate": 2.707880012433945e-06,
      "loss": 0.0263,
      "step": 18767
    },
    {
      "epoch": 1.458501709667392,
      "grad_norm": 0.19455178081989288,
      "learning_rate": 2.7074914516630404e-06,
      "loss": 0.0873,
      "step": 18768
    },
    {
      "epoch": 1.4585794218215729,
      "grad_norm": 0.3802182674407959,
      "learning_rate": 2.707102890892136e-06,
      "loss": 0.1491,
      "step": 18769
    },
    {
      "epoch": 1.4586571339757537,
      "grad_norm": 0.6848205327987671,
      "learning_rate": 2.706714330121231e-06,
      "loss": 0.0957,
      "step": 18770
    },
    {
      "epoch": 1.4587348461299348,
      "grad_norm": 0.514590322971344,
      "learning_rate": 2.7063257693503265e-06,
      "loss": 0.1386,
      "step": 18771
    },
    {
      "epoch": 1.4588125582841156,
      "grad_norm": 0.4350152611732483,
      "learning_rate": 2.7059372085794223e-06,
      "loss": 0.1613,
      "step": 18772
    },
    {
      "epoch": 1.4588902704382964,
      "grad_norm": 0.16393016278743744,
      "learning_rate": 2.7055486478085172e-06,
      "loss": 0.0463,
      "step": 18773
    },
    {
      "epoch": 1.4589679825924775,
      "grad_norm": 0.028723130002617836,
      "learning_rate": 2.7051600870376126e-06,
      "loss": 0.0112,
      "step": 18774
    },
    {
      "epoch": 1.4590456947466584,
      "grad_norm": 0.42961186170578003,
      "learning_rate": 2.7047715262667084e-06,
      "loss": 0.2497,
      "step": 18775
    },
    {
      "epoch": 1.4591234069008392,
      "grad_norm": 0.25294598937034607,
      "learning_rate": 2.7043829654958038e-06,
      "loss": 0.026,
      "step": 18776
    },
    {
      "epoch": 1.4592011190550203,
      "grad_norm": 0.9598341584205627,
      "learning_rate": 2.7039944047248987e-06,
      "loss": 0.3726,
      "step": 18777
    },
    {
      "epoch": 1.459278831209201,
      "grad_norm": 0.27608349919319153,
      "learning_rate": 2.7036058439539945e-06,
      "loss": 0.2065,
      "step": 18778
    },
    {
      "epoch": 1.459356543363382,
      "grad_norm": 0.6645340919494629,
      "learning_rate": 2.70321728318309e-06,
      "loss": 0.1541,
      "step": 18779
    },
    {
      "epoch": 1.459434255517563,
      "grad_norm": 0.8839220404624939,
      "learning_rate": 2.7028287224121857e-06,
      "loss": 0.874,
      "step": 18780
    },
    {
      "epoch": 1.4595119676717438,
      "grad_norm": 0.38565292954444885,
      "learning_rate": 2.702440161641281e-06,
      "loss": 0.0634,
      "step": 18781
    },
    {
      "epoch": 1.4595896798259247,
      "grad_norm": 0.6646755933761597,
      "learning_rate": 2.702051600870376e-06,
      "loss": 0.218,
      "step": 18782
    },
    {
      "epoch": 1.4596673919801058,
      "grad_norm": 0.5214321613311768,
      "learning_rate": 2.701663040099472e-06,
      "loss": 0.2382,
      "step": 18783
    },
    {
      "epoch": 1.4597451041342866,
      "grad_norm": 0.6685793399810791,
      "learning_rate": 2.701274479328567e-06,
      "loss": 0.1044,
      "step": 18784
    },
    {
      "epoch": 1.4598228162884674,
      "grad_norm": 0.34287989139556885,
      "learning_rate": 2.7008859185576626e-06,
      "loss": 0.0353,
      "step": 18785
    },
    {
      "epoch": 1.4599005284426485,
      "grad_norm": 1.059643030166626,
      "learning_rate": 2.7004973577867584e-06,
      "loss": 0.2182,
      "step": 18786
    },
    {
      "epoch": 1.4599782405968293,
      "grad_norm": 0.8949606418609619,
      "learning_rate": 2.7001087970158533e-06,
      "loss": 0.2856,
      "step": 18787
    },
    {
      "epoch": 1.4600559527510102,
      "grad_norm": 0.6091241836547852,
      "learning_rate": 2.6997202362449487e-06,
      "loss": 0.1388,
      "step": 18788
    },
    {
      "epoch": 1.4601336649051913,
      "grad_norm": 0.3633449077606201,
      "learning_rate": 2.6993316754740445e-06,
      "loss": 0.067,
      "step": 18789
    },
    {
      "epoch": 1.460211377059372,
      "grad_norm": 0.9056064486503601,
      "learning_rate": 2.69894311470314e-06,
      "loss": 0.3743,
      "step": 18790
    },
    {
      "epoch": 1.460289089213553,
      "grad_norm": 0.14195412397384644,
      "learning_rate": 2.698554553932235e-06,
      "loss": 0.0219,
      "step": 18791
    },
    {
      "epoch": 1.460366801367734,
      "grad_norm": 0.10239122807979584,
      "learning_rate": 2.6981659931613306e-06,
      "loss": 0.0133,
      "step": 18792
    },
    {
      "epoch": 1.4604445135219148,
      "grad_norm": 0.1105940043926239,
      "learning_rate": 2.697777432390426e-06,
      "loss": 0.0428,
      "step": 18793
    },
    {
      "epoch": 1.4605222256760957,
      "grad_norm": 0.532884418964386,
      "learning_rate": 2.6973888716195218e-06,
      "loss": 0.1121,
      "step": 18794
    },
    {
      "epoch": 1.4605999378302768,
      "grad_norm": 0.11917703598737717,
      "learning_rate": 2.697000310848617e-06,
      "loss": 0.0274,
      "step": 18795
    },
    {
      "epoch": 1.4606776499844576,
      "grad_norm": 0.6637170314788818,
      "learning_rate": 2.696611750077712e-06,
      "loss": 0.2144,
      "step": 18796
    },
    {
      "epoch": 1.4607553621386384,
      "grad_norm": 0.35794201493263245,
      "learning_rate": 2.696223189306808e-06,
      "loss": 0.102,
      "step": 18797
    },
    {
      "epoch": 1.4608330742928195,
      "grad_norm": 0.5474088788032532,
      "learning_rate": 2.6958346285359033e-06,
      "loss": 0.1581,
      "step": 18798
    },
    {
      "epoch": 1.4609107864470003,
      "grad_norm": 0.633589506149292,
      "learning_rate": 2.6954460677649986e-06,
      "loss": 0.1637,
      "step": 18799
    },
    {
      "epoch": 1.4609884986011812,
      "grad_norm": 0.6109955310821533,
      "learning_rate": 2.6950575069940944e-06,
      "loss": 0.2348,
      "step": 18800
    },
    {
      "epoch": 1.4610662107553622,
      "grad_norm": 0.3059253692626953,
      "learning_rate": 2.6946689462231894e-06,
      "loss": 0.0483,
      "step": 18801
    },
    {
      "epoch": 1.461143922909543,
      "grad_norm": 1.0486117601394653,
      "learning_rate": 2.6942803854522848e-06,
      "loss": 0.336,
      "step": 18802
    },
    {
      "epoch": 1.461221635063724,
      "grad_norm": 0.9058777093887329,
      "learning_rate": 2.6938918246813806e-06,
      "loss": 0.3078,
      "step": 18803
    },
    {
      "epoch": 1.461299347217905,
      "grad_norm": 0.2442585825920105,
      "learning_rate": 2.693503263910476e-06,
      "loss": 0.0831,
      "step": 18804
    },
    {
      "epoch": 1.4613770593720858,
      "grad_norm": 0.017978617921471596,
      "learning_rate": 2.693114703139571e-06,
      "loss": 0.0005,
      "step": 18805
    },
    {
      "epoch": 1.4614547715262667,
      "grad_norm": 0.6068833470344543,
      "learning_rate": 2.6927261423686667e-06,
      "loss": 0.2858,
      "step": 18806
    },
    {
      "epoch": 1.4615324836804477,
      "grad_norm": 0.6366113424301147,
      "learning_rate": 2.692337581597762e-06,
      "loss": 0.263,
      "step": 18807
    },
    {
      "epoch": 1.4616101958346286,
      "grad_norm": 0.46239444613456726,
      "learning_rate": 2.6919490208268574e-06,
      "loss": 0.3325,
      "step": 18808
    },
    {
      "epoch": 1.4616879079888094,
      "grad_norm": 0.0938078910112381,
      "learning_rate": 2.6915604600559532e-06,
      "loss": 0.0102,
      "step": 18809
    },
    {
      "epoch": 1.4617656201429905,
      "grad_norm": 0.565604567527771,
      "learning_rate": 2.691171899285048e-06,
      "loss": 0.1127,
      "step": 18810
    },
    {
      "epoch": 1.4618433322971713,
      "grad_norm": 0.9381994605064392,
      "learning_rate": 2.690783338514144e-06,
      "loss": 0.635,
      "step": 18811
    },
    {
      "epoch": 1.4619210444513522,
      "grad_norm": 0.5475971102714539,
      "learning_rate": 2.6903947777432393e-06,
      "loss": 0.0839,
      "step": 18812
    },
    {
      "epoch": 1.461998756605533,
      "grad_norm": 0.24665436148643494,
      "learning_rate": 2.6900062169723347e-06,
      "loss": 0.1021,
      "step": 18813
    },
    {
      "epoch": 1.462076468759714,
      "grad_norm": 0.626850962638855,
      "learning_rate": 2.6896176562014305e-06,
      "loss": 0.2288,
      "step": 18814
    },
    {
      "epoch": 1.462154180913895,
      "grad_norm": 0.7211658954620361,
      "learning_rate": 2.6892290954305255e-06,
      "loss": 0.2864,
      "step": 18815
    },
    {
      "epoch": 1.4622318930680758,
      "grad_norm": 0.7641986012458801,
      "learning_rate": 2.688840534659621e-06,
      "loss": 0.5756,
      "step": 18816
    },
    {
      "epoch": 1.4623096052222568,
      "grad_norm": 0.16443641483783722,
      "learning_rate": 2.6884519738887166e-06,
      "loss": 0.051,
      "step": 18817
    },
    {
      "epoch": 1.4623873173764377,
      "grad_norm": 0.4053753912448883,
      "learning_rate": 2.688063413117812e-06,
      "loss": 0.1544,
      "step": 18818
    },
    {
      "epoch": 1.4624650295306185,
      "grad_norm": 0.7563161849975586,
      "learning_rate": 2.687674852346907e-06,
      "loss": 0.4406,
      "step": 18819
    },
    {
      "epoch": 1.4625427416847996,
      "grad_norm": 0.32549819350242615,
      "learning_rate": 2.6872862915760027e-06,
      "loss": 0.1281,
      "step": 18820
    },
    {
      "epoch": 1.4626204538389804,
      "grad_norm": 0.18645122647285461,
      "learning_rate": 2.686897730805098e-06,
      "loss": 0.0154,
      "step": 18821
    },
    {
      "epoch": 1.4626981659931613,
      "grad_norm": 0.157764732837677,
      "learning_rate": 2.6865091700341935e-06,
      "loss": 0.0617,
      "step": 18822
    },
    {
      "epoch": 1.4627758781473421,
      "grad_norm": 0.28065916895866394,
      "learning_rate": 2.6861206092632893e-06,
      "loss": 0.0718,
      "step": 18823
    },
    {
      "epoch": 1.4628535903015232,
      "grad_norm": 0.6017179489135742,
      "learning_rate": 2.6857320484923842e-06,
      "loss": 0.2677,
      "step": 18824
    },
    {
      "epoch": 1.462931302455704,
      "grad_norm": 0.1977832168340683,
      "learning_rate": 2.68534348772148e-06,
      "loss": 0.0217,
      "step": 18825
    },
    {
      "epoch": 1.4630090146098849,
      "grad_norm": 0.9644368290901184,
      "learning_rate": 2.6849549269505754e-06,
      "loss": 0.1617,
      "step": 18826
    },
    {
      "epoch": 1.463086726764066,
      "grad_norm": 0.4655434489250183,
      "learning_rate": 2.6845663661796708e-06,
      "loss": 0.2122,
      "step": 18827
    },
    {
      "epoch": 1.4631644389182468,
      "grad_norm": 0.936051070690155,
      "learning_rate": 2.6841778054087666e-06,
      "loss": 0.4793,
      "step": 18828
    },
    {
      "epoch": 1.4632421510724276,
      "grad_norm": 0.8436470031738281,
      "learning_rate": 2.6837892446378615e-06,
      "loss": 0.2561,
      "step": 18829
    },
    {
      "epoch": 1.4633198632266087,
      "grad_norm": 0.2996211349964142,
      "learning_rate": 2.683400683866957e-06,
      "loss": 0.099,
      "step": 18830
    },
    {
      "epoch": 1.4633975753807895,
      "grad_norm": 0.3679237365722656,
      "learning_rate": 2.6830121230960527e-06,
      "loss": 0.0906,
      "step": 18831
    },
    {
      "epoch": 1.4634752875349704,
      "grad_norm": 0.5760825276374817,
      "learning_rate": 2.682623562325148e-06,
      "loss": 0.1532,
      "step": 18832
    },
    {
      "epoch": 1.4635529996891514,
      "grad_norm": 0.8727854490280151,
      "learning_rate": 2.682235001554243e-06,
      "loss": 0.1922,
      "step": 18833
    },
    {
      "epoch": 1.4636307118433323,
      "grad_norm": 0.5834989547729492,
      "learning_rate": 2.681846440783339e-06,
      "loss": 0.094,
      "step": 18834
    },
    {
      "epoch": 1.463708423997513,
      "grad_norm": 0.5322912931442261,
      "learning_rate": 2.681457880012434e-06,
      "loss": 0.1966,
      "step": 18835
    },
    {
      "epoch": 1.4637861361516942,
      "grad_norm": 0.648173451423645,
      "learning_rate": 2.681069319241529e-06,
      "loss": 0.1531,
      "step": 18836
    },
    {
      "epoch": 1.463863848305875,
      "grad_norm": 0.5227220058441162,
      "learning_rate": 2.680680758470625e-06,
      "loss": 0.2346,
      "step": 18837
    },
    {
      "epoch": 1.4639415604600559,
      "grad_norm": 0.6481703519821167,
      "learning_rate": 2.6802921976997203e-06,
      "loss": 0.1158,
      "step": 18838
    },
    {
      "epoch": 1.464019272614237,
      "grad_norm": 0.5090927481651306,
      "learning_rate": 2.6799036369288157e-06,
      "loss": 0.1364,
      "step": 18839
    },
    {
      "epoch": 1.4640969847684178,
      "grad_norm": 1.0736116170883179,
      "learning_rate": 2.6795150761579115e-06,
      "loss": 0.2538,
      "step": 18840
    },
    {
      "epoch": 1.4641746969225986,
      "grad_norm": 1.7701443433761597,
      "learning_rate": 2.6791265153870064e-06,
      "loss": 0.969,
      "step": 18841
    },
    {
      "epoch": 1.4642524090767797,
      "grad_norm": 0.5387629866600037,
      "learning_rate": 2.6787379546161022e-06,
      "loss": 0.1703,
      "step": 18842
    },
    {
      "epoch": 1.4643301212309605,
      "grad_norm": 0.4041396975517273,
      "learning_rate": 2.6783493938451976e-06,
      "loss": 0.0803,
      "step": 18843
    },
    {
      "epoch": 1.4644078333851414,
      "grad_norm": 0.5605584383010864,
      "learning_rate": 2.677960833074293e-06,
      "loss": 0.1245,
      "step": 18844
    },
    {
      "epoch": 1.4644855455393224,
      "grad_norm": 0.3043425679206848,
      "learning_rate": 2.6775722723033888e-06,
      "loss": 0.0466,
      "step": 18845
    },
    {
      "epoch": 1.4645632576935033,
      "grad_norm": 0.3860444128513336,
      "learning_rate": 2.6771837115324837e-06,
      "loss": 0.3182,
      "step": 18846
    },
    {
      "epoch": 1.464640969847684,
      "grad_norm": 0.9059572219848633,
      "learning_rate": 2.676795150761579e-06,
      "loss": 0.259,
      "step": 18847
    },
    {
      "epoch": 1.4647186820018652,
      "grad_norm": 0.6006823182106018,
      "learning_rate": 2.676406589990675e-06,
      "loss": 0.4324,
      "step": 18848
    },
    {
      "epoch": 1.464796394156046,
      "grad_norm": 1.5219908952713013,
      "learning_rate": 2.6760180292197703e-06,
      "loss": 0.7852,
      "step": 18849
    },
    {
      "epoch": 1.4648741063102269,
      "grad_norm": 0.36865776777267456,
      "learning_rate": 2.6756294684488652e-06,
      "loss": 0.092,
      "step": 18850
    },
    {
      "epoch": 1.464951818464408,
      "grad_norm": 0.7566176056861877,
      "learning_rate": 2.675240907677961e-06,
      "loss": 0.1119,
      "step": 18851
    },
    {
      "epoch": 1.4650295306185888,
      "grad_norm": 0.7067875862121582,
      "learning_rate": 2.6748523469070564e-06,
      "loss": 0.2742,
      "step": 18852
    },
    {
      "epoch": 1.4651072427727696,
      "grad_norm": 0.2737836539745331,
      "learning_rate": 2.6744637861361518e-06,
      "loss": 0.1078,
      "step": 18853
    },
    {
      "epoch": 1.4651849549269507,
      "grad_norm": 0.4419103264808655,
      "learning_rate": 2.6740752253652476e-06,
      "loss": 0.0873,
      "step": 18854
    },
    {
      "epoch": 1.4652626670811315,
      "grad_norm": 0.544750988483429,
      "learning_rate": 2.6736866645943425e-06,
      "loss": 0.3773,
      "step": 18855
    },
    {
      "epoch": 1.4653403792353124,
      "grad_norm": 0.7320532202720642,
      "learning_rate": 2.6732981038234383e-06,
      "loss": 0.6557,
      "step": 18856
    },
    {
      "epoch": 1.4654180913894934,
      "grad_norm": 0.8816774487495422,
      "learning_rate": 2.6729095430525337e-06,
      "loss": 0.4406,
      "step": 18857
    },
    {
      "epoch": 1.4654958035436743,
      "grad_norm": 0.7546245455741882,
      "learning_rate": 2.672520982281629e-06,
      "loss": 0.3554,
      "step": 18858
    },
    {
      "epoch": 1.465573515697855,
      "grad_norm": 0.33803486824035645,
      "learning_rate": 2.672132421510725e-06,
      "loss": 0.1009,
      "step": 18859
    },
    {
      "epoch": 1.4656512278520362,
      "grad_norm": 0.7434790134429932,
      "learning_rate": 2.67174386073982e-06,
      "loss": 0.3858,
      "step": 18860
    },
    {
      "epoch": 1.465728940006217,
      "grad_norm": 0.07761231809854507,
      "learning_rate": 2.671355299968915e-06,
      "loss": 0.003,
      "step": 18861
    },
    {
      "epoch": 1.4658066521603978,
      "grad_norm": 0.3726487457752228,
      "learning_rate": 2.670966739198011e-06,
      "loss": 0.0789,
      "step": 18862
    },
    {
      "epoch": 1.465884364314579,
      "grad_norm": 0.4178151786327362,
      "learning_rate": 2.6705781784271063e-06,
      "loss": 0.1001,
      "step": 18863
    },
    {
      "epoch": 1.4659620764687598,
      "grad_norm": 0.9347189664840698,
      "learning_rate": 2.6701896176562013e-06,
      "loss": 0.5912,
      "step": 18864
    },
    {
      "epoch": 1.4660397886229406,
      "grad_norm": 0.7087839245796204,
      "learning_rate": 2.669801056885297e-06,
      "loss": 0.106,
      "step": 18865
    },
    {
      "epoch": 1.4661175007771217,
      "grad_norm": 0.26117271184921265,
      "learning_rate": 2.6694124961143925e-06,
      "loss": 0.0802,
      "step": 18866
    },
    {
      "epoch": 1.4661952129313025,
      "grad_norm": 0.7306501865386963,
      "learning_rate": 2.669023935343488e-06,
      "loss": 0.5193,
      "step": 18867
    },
    {
      "epoch": 1.4662729250854833,
      "grad_norm": 0.6152728796005249,
      "learning_rate": 2.6686353745725836e-06,
      "loss": 0.161,
      "step": 18868
    },
    {
      "epoch": 1.4663506372396644,
      "grad_norm": 0.35996925830841064,
      "learning_rate": 2.6682468138016786e-06,
      "loss": 0.1275,
      "step": 18869
    },
    {
      "epoch": 1.4664283493938453,
      "grad_norm": 0.20842857658863068,
      "learning_rate": 2.6678582530307744e-06,
      "loss": 0.0546,
      "step": 18870
    },
    {
      "epoch": 1.466506061548026,
      "grad_norm": 0.423718124628067,
      "learning_rate": 2.6674696922598698e-06,
      "loss": 0.1377,
      "step": 18871
    },
    {
      "epoch": 1.4665837737022072,
      "grad_norm": 0.6055570840835571,
      "learning_rate": 2.667081131488965e-06,
      "loss": 0.0669,
      "step": 18872
    },
    {
      "epoch": 1.466661485856388,
      "grad_norm": 0.7835801839828491,
      "learning_rate": 2.666692570718061e-06,
      "loss": 0.145,
      "step": 18873
    },
    {
      "epoch": 1.4667391980105688,
      "grad_norm": 0.3430039882659912,
      "learning_rate": 2.666304009947156e-06,
      "loss": 0.1377,
      "step": 18874
    },
    {
      "epoch": 1.4668169101647497,
      "grad_norm": 0.7564131617546082,
      "learning_rate": 2.6659154491762512e-06,
      "loss": 0.3164,
      "step": 18875
    },
    {
      "epoch": 1.4668946223189308,
      "grad_norm": 0.7952903509140015,
      "learning_rate": 2.665526888405347e-06,
      "loss": 0.4592,
      "step": 18876
    },
    {
      "epoch": 1.4669723344731116,
      "grad_norm": 1.2128976583480835,
      "learning_rate": 2.6651383276344424e-06,
      "loss": 0.487,
      "step": 18877
    },
    {
      "epoch": 1.4670500466272924,
      "grad_norm": 0.68880295753479,
      "learning_rate": 2.6647497668635374e-06,
      "loss": 0.2373,
      "step": 18878
    },
    {
      "epoch": 1.4671277587814735,
      "grad_norm": 0.6857619285583496,
      "learning_rate": 2.664361206092633e-06,
      "loss": 0.1803,
      "step": 18879
    },
    {
      "epoch": 1.4672054709356543,
      "grad_norm": 0.42931950092315674,
      "learning_rate": 2.6639726453217285e-06,
      "loss": 0.1283,
      "step": 18880
    },
    {
      "epoch": 1.4672831830898352,
      "grad_norm": 0.6119033098220825,
      "learning_rate": 2.663584084550824e-06,
      "loss": 0.1132,
      "step": 18881
    },
    {
      "epoch": 1.467360895244016,
      "grad_norm": 0.556677520275116,
      "learning_rate": 2.6631955237799197e-06,
      "loss": 0.1953,
      "step": 18882
    },
    {
      "epoch": 1.467438607398197,
      "grad_norm": 0.3849811255931854,
      "learning_rate": 2.6628069630090147e-06,
      "loss": 0.0689,
      "step": 18883
    },
    {
      "epoch": 1.467516319552378,
      "grad_norm": 0.20400775969028473,
      "learning_rate": 2.66241840223811e-06,
      "loss": 0.0462,
      "step": 18884
    },
    {
      "epoch": 1.4675940317065588,
      "grad_norm": 0.3493843972682953,
      "learning_rate": 2.662029841467206e-06,
      "loss": 0.1442,
      "step": 18885
    },
    {
      "epoch": 1.4676717438607398,
      "grad_norm": 0.3224613070487976,
      "learning_rate": 2.661641280696301e-06,
      "loss": 0.0698,
      "step": 18886
    },
    {
      "epoch": 1.4677494560149207,
      "grad_norm": 0.35202673077583313,
      "learning_rate": 2.661252719925397e-06,
      "loss": 0.0947,
      "step": 18887
    },
    {
      "epoch": 1.4678271681691015,
      "grad_norm": 0.28825461864471436,
      "learning_rate": 2.660864159154492e-06,
      "loss": 0.3157,
      "step": 18888
    },
    {
      "epoch": 1.4679048803232826,
      "grad_norm": 0.2202601283788681,
      "learning_rate": 2.6604755983835873e-06,
      "loss": 0.0824,
      "step": 18889
    },
    {
      "epoch": 1.4679825924774634,
      "grad_norm": 0.6917481422424316,
      "learning_rate": 2.660087037612683e-06,
      "loss": 0.4272,
      "step": 18890
    },
    {
      "epoch": 1.4680603046316443,
      "grad_norm": 1.0233317613601685,
      "learning_rate": 2.6596984768417785e-06,
      "loss": 0.4391,
      "step": 18891
    },
    {
      "epoch": 1.4681380167858253,
      "grad_norm": 0.6166906356811523,
      "learning_rate": 2.6593099160708734e-06,
      "loss": 0.0991,
      "step": 18892
    },
    {
      "epoch": 1.4682157289400062,
      "grad_norm": 0.8392289280891418,
      "learning_rate": 2.6589213552999692e-06,
      "loss": 0.2019,
      "step": 18893
    },
    {
      "epoch": 1.468293441094187,
      "grad_norm": 0.2843184173107147,
      "learning_rate": 2.6585327945290646e-06,
      "loss": 0.1846,
      "step": 18894
    },
    {
      "epoch": 1.468371153248368,
      "grad_norm": 0.1591099500656128,
      "learning_rate": 2.65814423375816e-06,
      "loss": 0.041,
      "step": 18895
    },
    {
      "epoch": 1.468448865402549,
      "grad_norm": 0.6128180027008057,
      "learning_rate": 2.6577556729872554e-06,
      "loss": 0.2465,
      "step": 18896
    },
    {
      "epoch": 1.4685265775567298,
      "grad_norm": 0.45584291219711304,
      "learning_rate": 2.6573671122163507e-06,
      "loss": 0.356,
      "step": 18897
    },
    {
      "epoch": 1.4686042897109108,
      "grad_norm": 0.457080602645874,
      "learning_rate": 2.656978551445446e-06,
      "loss": 0.1639,
      "step": 18898
    },
    {
      "epoch": 1.4686820018650917,
      "grad_norm": 0.2223794013261795,
      "learning_rate": 2.656589990674542e-06,
      "loss": 0.0467,
      "step": 18899
    },
    {
      "epoch": 1.4687597140192725,
      "grad_norm": 0.5782762169837952,
      "learning_rate": 2.656201429903637e-06,
      "loss": 0.4391,
      "step": 18900
    },
    {
      "epoch": 1.4688374261734536,
      "grad_norm": 0.2901014983654022,
      "learning_rate": 2.6558128691327326e-06,
      "loss": 0.0671,
      "step": 18901
    },
    {
      "epoch": 1.4689151383276344,
      "grad_norm": 0.25154972076416016,
      "learning_rate": 2.655424308361828e-06,
      "loss": 0.1551,
      "step": 18902
    },
    {
      "epoch": 1.4689928504818153,
      "grad_norm": 1.037711262702942,
      "learning_rate": 2.6550357475909234e-06,
      "loss": 0.1932,
      "step": 18903
    },
    {
      "epoch": 1.4690705626359963,
      "grad_norm": 0.3589829206466675,
      "learning_rate": 2.654647186820019e-06,
      "loss": 0.1376,
      "step": 18904
    },
    {
      "epoch": 1.4691482747901772,
      "grad_norm": 0.11123406141996384,
      "learning_rate": 2.654258626049114e-06,
      "loss": 0.0192,
      "step": 18905
    },
    {
      "epoch": 1.469225986944358,
      "grad_norm": 0.49295976758003235,
      "learning_rate": 2.6538700652782095e-06,
      "loss": 0.2185,
      "step": 18906
    },
    {
      "epoch": 1.469303699098539,
      "grad_norm": 0.9647932052612305,
      "learning_rate": 2.6534815045073053e-06,
      "loss": 0.4565,
      "step": 18907
    },
    {
      "epoch": 1.46938141125272,
      "grad_norm": 0.9102855920791626,
      "learning_rate": 2.6530929437364007e-06,
      "loss": 0.2652,
      "step": 18908
    },
    {
      "epoch": 1.4694591234069008,
      "grad_norm": 0.3525048792362213,
      "learning_rate": 2.6527043829654956e-06,
      "loss": 0.0795,
      "step": 18909
    },
    {
      "epoch": 1.4695368355610818,
      "grad_norm": 0.6940573453903198,
      "learning_rate": 2.6523158221945914e-06,
      "loss": 0.2704,
      "step": 18910
    },
    {
      "epoch": 1.4696145477152627,
      "grad_norm": 0.29255765676498413,
      "learning_rate": 2.651927261423687e-06,
      "loss": 0.1471,
      "step": 18911
    },
    {
      "epoch": 1.4696922598694435,
      "grad_norm": 0.45826753973960876,
      "learning_rate": 2.651538700652782e-06,
      "loss": 0.0597,
      "step": 18912
    },
    {
      "epoch": 1.4697699720236246,
      "grad_norm": 0.384064644575119,
      "learning_rate": 2.651150139881878e-06,
      "loss": 0.2571,
      "step": 18913
    },
    {
      "epoch": 1.4698476841778054,
      "grad_norm": 0.28491175174713135,
      "learning_rate": 2.650761579110973e-06,
      "loss": 0.0368,
      "step": 18914
    },
    {
      "epoch": 1.4699253963319863,
      "grad_norm": 0.1946670114994049,
      "learning_rate": 2.6503730183400683e-06,
      "loss": 0.0151,
      "step": 18915
    },
    {
      "epoch": 1.4700031084861673,
      "grad_norm": 0.3557559847831726,
      "learning_rate": 2.649984457569164e-06,
      "loss": 0.1627,
      "step": 18916
    },
    {
      "epoch": 1.4700808206403482,
      "grad_norm": 0.36552658677101135,
      "learning_rate": 2.6495958967982595e-06,
      "loss": 0.1109,
      "step": 18917
    },
    {
      "epoch": 1.470158532794529,
      "grad_norm": 0.4741860032081604,
      "learning_rate": 2.6492073360273553e-06,
      "loss": 0.208,
      "step": 18918
    },
    {
      "epoch": 1.47023624494871,
      "grad_norm": 0.4571252167224884,
      "learning_rate": 2.64881877525645e-06,
      "loss": 0.0944,
      "step": 18919
    },
    {
      "epoch": 1.470313957102891,
      "grad_norm": 0.2572237253189087,
      "learning_rate": 2.6484302144855456e-06,
      "loss": 0.0643,
      "step": 18920
    },
    {
      "epoch": 1.4703916692570718,
      "grad_norm": 0.17044515907764435,
      "learning_rate": 2.6480416537146414e-06,
      "loss": 0.0526,
      "step": 18921
    },
    {
      "epoch": 1.4704693814112528,
      "grad_norm": 0.587424635887146,
      "learning_rate": 2.6476530929437368e-06,
      "loss": 0.3738,
      "step": 18922
    },
    {
      "epoch": 1.4705470935654337,
      "grad_norm": 0.2127552181482315,
      "learning_rate": 2.6472645321728317e-06,
      "loss": 0.0632,
      "step": 18923
    },
    {
      "epoch": 1.4706248057196145,
      "grad_norm": 0.4139648377895355,
      "learning_rate": 2.6468759714019275e-06,
      "loss": 0.1095,
      "step": 18924
    },
    {
      "epoch": 1.4707025178737956,
      "grad_norm": 0.40970003604888916,
      "learning_rate": 2.646487410631023e-06,
      "loss": 0.1691,
      "step": 18925
    },
    {
      "epoch": 1.4707802300279764,
      "grad_norm": 0.2669156491756439,
      "learning_rate": 2.6460988498601182e-06,
      "loss": 0.0425,
      "step": 18926
    },
    {
      "epoch": 1.4708579421821573,
      "grad_norm": 0.30999723076820374,
      "learning_rate": 2.645710289089214e-06,
      "loss": 0.1276,
      "step": 18927
    },
    {
      "epoch": 1.4709356543363383,
      "grad_norm": 0.20120272040367126,
      "learning_rate": 2.645321728318309e-06,
      "loss": 0.0302,
      "step": 18928
    },
    {
      "epoch": 1.4710133664905192,
      "grad_norm": 0.6032028794288635,
      "learning_rate": 2.6449331675474044e-06,
      "loss": 0.1953,
      "step": 18929
    },
    {
      "epoch": 1.4710910786447,
      "grad_norm": 0.30906936526298523,
      "learning_rate": 2.6445446067765e-06,
      "loss": 0.0526,
      "step": 18930
    },
    {
      "epoch": 1.471168790798881,
      "grad_norm": 0.5457752346992493,
      "learning_rate": 2.6441560460055955e-06,
      "loss": 0.112,
      "step": 18931
    },
    {
      "epoch": 1.471246502953062,
      "grad_norm": 0.11367782205343246,
      "learning_rate": 2.6437674852346913e-06,
      "loss": 0.0025,
      "step": 18932
    },
    {
      "epoch": 1.4713242151072428,
      "grad_norm": 0.5682514309883118,
      "learning_rate": 2.6433789244637863e-06,
      "loss": 0.2027,
      "step": 18933
    },
    {
      "epoch": 1.4714019272614238,
      "grad_norm": 0.4309028089046478,
      "learning_rate": 2.6429903636928817e-06,
      "loss": 0.1021,
      "step": 18934
    },
    {
      "epoch": 1.4714796394156047,
      "grad_norm": 0.7846651673316956,
      "learning_rate": 2.6426018029219775e-06,
      "loss": 0.1955,
      "step": 18935
    },
    {
      "epoch": 1.4715573515697855,
      "grad_norm": 0.6089192628860474,
      "learning_rate": 2.642213242151073e-06,
      "loss": 0.1303,
      "step": 18936
    },
    {
      "epoch": 1.4716350637239664,
      "grad_norm": 0.4241580069065094,
      "learning_rate": 2.6418246813801678e-06,
      "loss": 0.1316,
      "step": 18937
    },
    {
      "epoch": 1.4717127758781474,
      "grad_norm": 0.7562456130981445,
      "learning_rate": 2.6414361206092636e-06,
      "loss": 0.3973,
      "step": 18938
    },
    {
      "epoch": 1.4717904880323283,
      "grad_norm": 0.1558646708726883,
      "learning_rate": 2.641047559838359e-06,
      "loss": 0.164,
      "step": 18939
    },
    {
      "epoch": 1.471868200186509,
      "grad_norm": 0.852796196937561,
      "learning_rate": 2.6406589990674543e-06,
      "loss": 0.6959,
      "step": 18940
    },
    {
      "epoch": 1.4719459123406902,
      "grad_norm": 0.39569205045700073,
      "learning_rate": 2.64027043829655e-06,
      "loss": 0.0992,
      "step": 18941
    },
    {
      "epoch": 1.472023624494871,
      "grad_norm": 0.5373672246932983,
      "learning_rate": 2.639881877525645e-06,
      "loss": 0.2359,
      "step": 18942
    },
    {
      "epoch": 1.4721013366490519,
      "grad_norm": 0.3633520007133484,
      "learning_rate": 2.6394933167547404e-06,
      "loss": 0.1252,
      "step": 18943
    },
    {
      "epoch": 1.4721790488032327,
      "grad_norm": 0.7167565226554871,
      "learning_rate": 2.6391047559838362e-06,
      "loss": 0.2901,
      "step": 18944
    },
    {
      "epoch": 1.4722567609574138,
      "grad_norm": 0.6274176836013794,
      "learning_rate": 2.6387161952129316e-06,
      "loss": 0.116,
      "step": 18945
    },
    {
      "epoch": 1.4723344731115946,
      "grad_norm": 0.3929400146007538,
      "learning_rate": 2.6383276344420274e-06,
      "loss": 0.1636,
      "step": 18946
    },
    {
      "epoch": 1.4724121852657754,
      "grad_norm": 1.6061654090881348,
      "learning_rate": 2.6379390736711224e-06,
      "loss": 0.6361,
      "step": 18947
    },
    {
      "epoch": 1.4724898974199565,
      "grad_norm": 0.43933945894241333,
      "learning_rate": 2.6375505129002177e-06,
      "loss": 0.071,
      "step": 18948
    },
    {
      "epoch": 1.4725676095741373,
      "grad_norm": 0.4252270460128784,
      "learning_rate": 2.6371619521293135e-06,
      "loss": 0.2446,
      "step": 18949
    },
    {
      "epoch": 1.4726453217283182,
      "grad_norm": 0.22745870053768158,
      "learning_rate": 2.636773391358409e-06,
      "loss": 0.0146,
      "step": 18950
    },
    {
      "epoch": 1.4727230338824993,
      "grad_norm": 0.977532148361206,
      "learning_rate": 2.636384830587504e-06,
      "loss": 0.3545,
      "step": 18951
    },
    {
      "epoch": 1.47280074603668,
      "grad_norm": 0.3436689078807831,
      "learning_rate": 2.6359962698165996e-06,
      "loss": 0.0271,
      "step": 18952
    },
    {
      "epoch": 1.472878458190861,
      "grad_norm": 0.37831950187683105,
      "learning_rate": 2.635607709045695e-06,
      "loss": 0.3119,
      "step": 18953
    },
    {
      "epoch": 1.472956170345042,
      "grad_norm": 0.1365967094898224,
      "learning_rate": 2.6352191482747904e-06,
      "loss": 0.0369,
      "step": 18954
    },
    {
      "epoch": 1.4730338824992228,
      "grad_norm": 0.14513346552848816,
      "learning_rate": 2.634830587503886e-06,
      "loss": 0.0117,
      "step": 18955
    },
    {
      "epoch": 1.4731115946534037,
      "grad_norm": 0.4464300870895386,
      "learning_rate": 2.634442026732981e-06,
      "loss": 0.138,
      "step": 18956
    },
    {
      "epoch": 1.4731893068075848,
      "grad_norm": 0.44486868381500244,
      "learning_rate": 2.6340534659620765e-06,
      "loss": 0.1252,
      "step": 18957
    },
    {
      "epoch": 1.4732670189617656,
      "grad_norm": 0.27017587423324585,
      "learning_rate": 2.6336649051911723e-06,
      "loss": 0.0372,
      "step": 18958
    },
    {
      "epoch": 1.4733447311159464,
      "grad_norm": 0.8984712362289429,
      "learning_rate": 2.6332763444202673e-06,
      "loss": 0.219,
      "step": 18959
    },
    {
      "epoch": 1.4734224432701275,
      "grad_norm": 0.3978567123413086,
      "learning_rate": 2.6328877836493626e-06,
      "loss": 0.0719,
      "step": 18960
    },
    {
      "epoch": 1.4735001554243083,
      "grad_norm": 0.22294335067272186,
      "learning_rate": 2.6324992228784584e-06,
      "loss": 0.1139,
      "step": 18961
    },
    {
      "epoch": 1.4735778675784892,
      "grad_norm": 0.6299404501914978,
      "learning_rate": 2.632110662107554e-06,
      "loss": 0.115,
      "step": 18962
    },
    {
      "epoch": 1.4736555797326703,
      "grad_norm": 0.8233144879341125,
      "learning_rate": 2.6317221013366496e-06,
      "loss": 0.459,
      "step": 18963
    },
    {
      "epoch": 1.473733291886851,
      "grad_norm": 0.20253852009773254,
      "learning_rate": 2.6313335405657446e-06,
      "loss": 0.1297,
      "step": 18964
    },
    {
      "epoch": 1.473811004041032,
      "grad_norm": 0.2576717138290405,
      "learning_rate": 2.63094497979484e-06,
      "loss": 0.1305,
      "step": 18965
    },
    {
      "epoch": 1.473888716195213,
      "grad_norm": 1.086082935333252,
      "learning_rate": 2.6305564190239357e-06,
      "loss": 0.5063,
      "step": 18966
    },
    {
      "epoch": 1.4739664283493938,
      "grad_norm": 0.31907981634140015,
      "learning_rate": 2.630167858253031e-06,
      "loss": 0.0742,
      "step": 18967
    },
    {
      "epoch": 1.4740441405035747,
      "grad_norm": 0.7510868906974792,
      "learning_rate": 2.629779297482126e-06,
      "loss": 0.6174,
      "step": 18968
    },
    {
      "epoch": 1.4741218526577557,
      "grad_norm": 0.3938708007335663,
      "learning_rate": 2.629390736711222e-06,
      "loss": 0.019,
      "step": 18969
    },
    {
      "epoch": 1.4741995648119366,
      "grad_norm": 0.40702569484710693,
      "learning_rate": 2.6290021759403172e-06,
      "loss": 0.1483,
      "step": 18970
    },
    {
      "epoch": 1.4742772769661174,
      "grad_norm": 0.2081758975982666,
      "learning_rate": 2.6286136151694126e-06,
      "loss": 0.0208,
      "step": 18971
    },
    {
      "epoch": 1.4743549891202985,
      "grad_norm": 0.0911107286810875,
      "learning_rate": 2.6282250543985084e-06,
      "loss": 0.0344,
      "step": 18972
    },
    {
      "epoch": 1.4744327012744793,
      "grad_norm": 0.45722076296806335,
      "learning_rate": 2.6278364936276033e-06,
      "loss": 0.0919,
      "step": 18973
    },
    {
      "epoch": 1.4745104134286602,
      "grad_norm": 0.24882647395133972,
      "learning_rate": 2.6274479328566987e-06,
      "loss": 0.1175,
      "step": 18974
    },
    {
      "epoch": 1.4745881255828412,
      "grad_norm": 0.40555208921432495,
      "learning_rate": 2.6270593720857945e-06,
      "loss": 0.0416,
      "step": 18975
    },
    {
      "epoch": 1.474665837737022,
      "grad_norm": 0.404771089553833,
      "learning_rate": 2.62667081131489e-06,
      "loss": 0.1144,
      "step": 18976
    },
    {
      "epoch": 1.474743549891203,
      "grad_norm": 0.8565313816070557,
      "learning_rate": 2.6262822505439857e-06,
      "loss": 0.056,
      "step": 18977
    },
    {
      "epoch": 1.474821262045384,
      "grad_norm": 0.4659671187400818,
      "learning_rate": 2.6258936897730806e-06,
      "loss": 0.1155,
      "step": 18978
    },
    {
      "epoch": 1.4748989741995648,
      "grad_norm": 1.1078428030014038,
      "learning_rate": 2.625505129002176e-06,
      "loss": 0.6029,
      "step": 18979
    },
    {
      "epoch": 1.4749766863537457,
      "grad_norm": 0.3808767795562744,
      "learning_rate": 2.625116568231272e-06,
      "loss": 0.1137,
      "step": 18980
    },
    {
      "epoch": 1.4750543985079267,
      "grad_norm": 0.2451847940683365,
      "learning_rate": 2.624728007460367e-06,
      "loss": 0.1099,
      "step": 18981
    },
    {
      "epoch": 1.4751321106621076,
      "grad_norm": 0.4905649423599243,
      "learning_rate": 2.624339446689462e-06,
      "loss": 0.5673,
      "step": 18982
    },
    {
      "epoch": 1.4752098228162884,
      "grad_norm": 0.8465728163719177,
      "learning_rate": 2.623950885918558e-06,
      "loss": 0.1707,
      "step": 18983
    },
    {
      "epoch": 1.4752875349704695,
      "grad_norm": 0.348431795835495,
      "learning_rate": 2.6235623251476533e-06,
      "loss": 0.0492,
      "step": 18984
    },
    {
      "epoch": 1.4753652471246503,
      "grad_norm": 0.33931756019592285,
      "learning_rate": 2.6231737643767487e-06,
      "loss": 0.0817,
      "step": 18985
    },
    {
      "epoch": 1.4754429592788312,
      "grad_norm": 0.3688574731349945,
      "learning_rate": 2.6227852036058445e-06,
      "loss": 0.0742,
      "step": 18986
    },
    {
      "epoch": 1.4755206714330122,
      "grad_norm": 0.5206271409988403,
      "learning_rate": 2.6223966428349394e-06,
      "loss": 0.1723,
      "step": 18987
    },
    {
      "epoch": 1.475598383587193,
      "grad_norm": 1.2111904621124268,
      "learning_rate": 2.6220080820640348e-06,
      "loss": 1.1376,
      "step": 18988
    },
    {
      "epoch": 1.475676095741374,
      "grad_norm": 0.7656288743019104,
      "learning_rate": 2.6216195212931306e-06,
      "loss": 0.576,
      "step": 18989
    },
    {
      "epoch": 1.475753807895555,
      "grad_norm": 1.2682955265045166,
      "learning_rate": 2.621230960522226e-06,
      "loss": 0.492,
      "step": 18990
    },
    {
      "epoch": 1.4758315200497358,
      "grad_norm": 0.23331408202648163,
      "learning_rate": 2.6208423997513217e-06,
      "loss": 0.0459,
      "step": 18991
    },
    {
      "epoch": 1.4759092322039167,
      "grad_norm": 0.7495126128196716,
      "learning_rate": 2.6204538389804167e-06,
      "loss": 0.2386,
      "step": 18992
    },
    {
      "epoch": 1.4759869443580977,
      "grad_norm": 0.6173396110534668,
      "learning_rate": 2.620065278209512e-06,
      "loss": 0.1108,
      "step": 18993
    },
    {
      "epoch": 1.4760646565122786,
      "grad_norm": 0.6160041689872742,
      "learning_rate": 2.619676717438608e-06,
      "loss": 0.1493,
      "step": 18994
    },
    {
      "epoch": 1.4761423686664594,
      "grad_norm": 0.4235648512840271,
      "learning_rate": 2.6192881566677032e-06,
      "loss": 0.1053,
      "step": 18995
    },
    {
      "epoch": 1.4762200808206403,
      "grad_norm": 0.10894637554883957,
      "learning_rate": 2.618899595896798e-06,
      "loss": 0.0172,
      "step": 18996
    },
    {
      "epoch": 1.4762977929748213,
      "grad_norm": 0.25335201621055603,
      "learning_rate": 2.618511035125894e-06,
      "loss": 0.0376,
      "step": 18997
    },
    {
      "epoch": 1.4763755051290022,
      "grad_norm": 0.7436980605125427,
      "learning_rate": 2.6181224743549894e-06,
      "loss": 0.274,
      "step": 18998
    },
    {
      "epoch": 1.476453217283183,
      "grad_norm": 0.21931695938110352,
      "learning_rate": 2.6177339135840847e-06,
      "loss": 0.0424,
      "step": 18999
    },
    {
      "epoch": 1.476530929437364,
      "grad_norm": 0.7905858755111694,
      "learning_rate": 2.6173453528131805e-06,
      "loss": 0.4972,
      "step": 19000
    },
    {
      "epoch": 1.476608641591545,
      "grad_norm": 0.20227833092212677,
      "learning_rate": 2.6169567920422755e-06,
      "loss": 0.0617,
      "step": 19001
    },
    {
      "epoch": 1.4766863537457258,
      "grad_norm": 0.4211520850658417,
      "learning_rate": 2.616568231271371e-06,
      "loss": 0.1678,
      "step": 19002
    },
    {
      "epoch": 1.4767640658999066,
      "grad_norm": 0.7263160943984985,
      "learning_rate": 2.6161796705004666e-06,
      "loss": 0.0775,
      "step": 19003
    },
    {
      "epoch": 1.4768417780540877,
      "grad_norm": 0.4938652217388153,
      "learning_rate": 2.615791109729562e-06,
      "loss": 0.1888,
      "step": 19004
    },
    {
      "epoch": 1.4769194902082685,
      "grad_norm": 0.8002867698669434,
      "learning_rate": 2.615402548958657e-06,
      "loss": 0.0903,
      "step": 19005
    },
    {
      "epoch": 1.4769972023624494,
      "grad_norm": 0.30667221546173096,
      "learning_rate": 2.6150139881877528e-06,
      "loss": 0.1644,
      "step": 19006
    },
    {
      "epoch": 1.4770749145166304,
      "grad_norm": 0.26274409890174866,
      "learning_rate": 2.614625427416848e-06,
      "loss": 0.0828,
      "step": 19007
    },
    {
      "epoch": 1.4771526266708113,
      "grad_norm": 0.2814693748950958,
      "learning_rate": 2.614236866645944e-06,
      "loss": 0.158,
      "step": 19008
    },
    {
      "epoch": 1.477230338824992,
      "grad_norm": 0.49600520730018616,
      "learning_rate": 2.6138483058750393e-06,
      "loss": 0.1263,
      "step": 19009
    },
    {
      "epoch": 1.4773080509791732,
      "grad_norm": 0.5162445902824402,
      "learning_rate": 2.6134597451041343e-06,
      "loss": 0.1165,
      "step": 19010
    },
    {
      "epoch": 1.477385763133354,
      "grad_norm": 0.4511311650276184,
      "learning_rate": 2.61307118433323e-06,
      "loss": 0.1699,
      "step": 19011
    },
    {
      "epoch": 1.4774634752875349,
      "grad_norm": 0.3273717164993286,
      "learning_rate": 2.6126826235623254e-06,
      "loss": 0.0753,
      "step": 19012
    },
    {
      "epoch": 1.477541187441716,
      "grad_norm": 0.38637885451316833,
      "learning_rate": 2.612294062791421e-06,
      "loss": 0.14,
      "step": 19013
    },
    {
      "epoch": 1.4776188995958968,
      "grad_norm": 0.3326494097709656,
      "learning_rate": 2.6119055020205166e-06,
      "loss": 0.3684,
      "step": 19014
    },
    {
      "epoch": 1.4776966117500776,
      "grad_norm": 0.3541552722454071,
      "learning_rate": 2.6115169412496116e-06,
      "loss": 0.081,
      "step": 19015
    },
    {
      "epoch": 1.4777743239042587,
      "grad_norm": 0.28885310888290405,
      "learning_rate": 2.611128380478707e-06,
      "loss": 0.115,
      "step": 19016
    },
    {
      "epoch": 1.4778520360584395,
      "grad_norm": 0.3949175179004669,
      "learning_rate": 2.6107398197078027e-06,
      "loss": 0.0895,
      "step": 19017
    },
    {
      "epoch": 1.4779297482126204,
      "grad_norm": 0.29403939843177795,
      "learning_rate": 2.610351258936898e-06,
      "loss": 0.1782,
      "step": 19018
    },
    {
      "epoch": 1.4780074603668014,
      "grad_norm": 2.2639644145965576,
      "learning_rate": 2.609962698165993e-06,
      "loss": 0.2829,
      "step": 19019
    },
    {
      "epoch": 1.4780851725209823,
      "grad_norm": 0.3107697665691376,
      "learning_rate": 2.609574137395089e-06,
      "loss": 0.205,
      "step": 19020
    },
    {
      "epoch": 1.478162884675163,
      "grad_norm": 0.6262239813804626,
      "learning_rate": 2.6091855766241842e-06,
      "loss": 0.1244,
      "step": 19021
    },
    {
      "epoch": 1.4782405968293442,
      "grad_norm": 0.6549776792526245,
      "learning_rate": 2.60879701585328e-06,
      "loss": 0.2463,
      "step": 19022
    },
    {
      "epoch": 1.478318308983525,
      "grad_norm": 0.7145407199859619,
      "learning_rate": 2.608408455082375e-06,
      "loss": 0.2666,
      "step": 19023
    },
    {
      "epoch": 1.4783960211377059,
      "grad_norm": 0.3058847188949585,
      "learning_rate": 2.6080198943114703e-06,
      "loss": 0.0989,
      "step": 19024
    },
    {
      "epoch": 1.478473733291887,
      "grad_norm": 0.6121804118156433,
      "learning_rate": 2.607631333540566e-06,
      "loss": 0.2249,
      "step": 19025
    },
    {
      "epoch": 1.4785514454460678,
      "grad_norm": 0.4234735369682312,
      "learning_rate": 2.6072427727696615e-06,
      "loss": 0.066,
      "step": 19026
    },
    {
      "epoch": 1.4786291576002486,
      "grad_norm": 0.6821692585945129,
      "learning_rate": 2.6068542119987565e-06,
      "loss": 0.3081,
      "step": 19027
    },
    {
      "epoch": 1.4787068697544297,
      "grad_norm": 0.513694703578949,
      "learning_rate": 2.6064656512278523e-06,
      "loss": 0.1997,
      "step": 19028
    },
    {
      "epoch": 1.4787845819086105,
      "grad_norm": 0.2787003517150879,
      "learning_rate": 2.6060770904569476e-06,
      "loss": 0.0233,
      "step": 19029
    },
    {
      "epoch": 1.4788622940627913,
      "grad_norm": 0.41048523783683777,
      "learning_rate": 2.605688529686043e-06,
      "loss": 0.1198,
      "step": 19030
    },
    {
      "epoch": 1.4789400062169724,
      "grad_norm": 0.24957305192947388,
      "learning_rate": 2.605299968915139e-06,
      "loss": 0.1174,
      "step": 19031
    },
    {
      "epoch": 1.4790177183711533,
      "grad_norm": 0.25371402502059937,
      "learning_rate": 2.6049114081442337e-06,
      "loss": 0.0645,
      "step": 19032
    },
    {
      "epoch": 1.479095430525334,
      "grad_norm": 1.1260011196136475,
      "learning_rate": 2.604522847373329e-06,
      "loss": 0.4475,
      "step": 19033
    },
    {
      "epoch": 1.4791731426795152,
      "grad_norm": 0.11809834092855453,
      "learning_rate": 2.604134286602425e-06,
      "loss": 0.1573,
      "step": 19034
    },
    {
      "epoch": 1.479250854833696,
      "grad_norm": 0.525823175907135,
      "learning_rate": 2.6037457258315203e-06,
      "loss": 0.2421,
      "step": 19035
    },
    {
      "epoch": 1.4793285669878768,
      "grad_norm": 1.2716686725616455,
      "learning_rate": 2.6033571650606152e-06,
      "loss": 0.1681,
      "step": 19036
    },
    {
      "epoch": 1.479406279142058,
      "grad_norm": 0.9535864591598511,
      "learning_rate": 2.602968604289711e-06,
      "loss": 0.1981,
      "step": 19037
    },
    {
      "epoch": 1.4794839912962388,
      "grad_norm": 0.901854395866394,
      "learning_rate": 2.6025800435188064e-06,
      "loss": 0.1818,
      "step": 19038
    },
    {
      "epoch": 1.4795617034504196,
      "grad_norm": 1.216322422027588,
      "learning_rate": 2.602191482747902e-06,
      "loss": 0.5963,
      "step": 19039
    },
    {
      "epoch": 1.4796394156046007,
      "grad_norm": 0.24265459179878235,
      "learning_rate": 2.6018029219769976e-06,
      "loss": 0.0441,
      "step": 19040
    },
    {
      "epoch": 1.4797171277587815,
      "grad_norm": 0.5628585815429688,
      "learning_rate": 2.6014143612060925e-06,
      "loss": 0.2535,
      "step": 19041
    },
    {
      "epoch": 1.4797948399129623,
      "grad_norm": 1.4731851816177368,
      "learning_rate": 2.6010258004351883e-06,
      "loss": 0.3742,
      "step": 19042
    },
    {
      "epoch": 1.4798725520671434,
      "grad_norm": 0.1531701236963272,
      "learning_rate": 2.6006372396642837e-06,
      "loss": 0.0359,
      "step": 19043
    },
    {
      "epoch": 1.4799502642213243,
      "grad_norm": 0.6352905631065369,
      "learning_rate": 2.600248678893379e-06,
      "loss": 0.3252,
      "step": 19044
    },
    {
      "epoch": 1.480027976375505,
      "grad_norm": 0.30618518590927124,
      "learning_rate": 2.599860118122475e-06,
      "loss": 0.0787,
      "step": 19045
    },
    {
      "epoch": 1.4801056885296862,
      "grad_norm": 0.21161989867687225,
      "learning_rate": 2.59947155735157e-06,
      "loss": 0.0687,
      "step": 19046
    },
    {
      "epoch": 1.480183400683867,
      "grad_norm": 0.14047570526599884,
      "learning_rate": 2.599082996580665e-06,
      "loss": 0.0169,
      "step": 19047
    },
    {
      "epoch": 1.4802611128380478,
      "grad_norm": 0.7456615567207336,
      "learning_rate": 2.598694435809761e-06,
      "loss": 0.2518,
      "step": 19048
    },
    {
      "epoch": 1.480338824992229,
      "grad_norm": 0.38720840215682983,
      "learning_rate": 2.5983058750388564e-06,
      "loss": 0.0861,
      "step": 19049
    },
    {
      "epoch": 1.4804165371464098,
      "grad_norm": 1.096622347831726,
      "learning_rate": 2.5979173142679513e-06,
      "loss": 0.3287,
      "step": 19050
    },
    {
      "epoch": 1.4804942493005906,
      "grad_norm": 0.2191404551267624,
      "learning_rate": 2.597528753497047e-06,
      "loss": 0.0851,
      "step": 19051
    },
    {
      "epoch": 1.4805719614547717,
      "grad_norm": 0.3118599057197571,
      "learning_rate": 2.5971401927261425e-06,
      "loss": 0.0492,
      "step": 19052
    },
    {
      "epoch": 1.4806496736089525,
      "grad_norm": 0.8923510313034058,
      "learning_rate": 2.5967516319552383e-06,
      "loss": 0.0927,
      "step": 19053
    },
    {
      "epoch": 1.4807273857631333,
      "grad_norm": 0.6578166484832764,
      "learning_rate": 2.5963630711843337e-06,
      "loss": 0.1589,
      "step": 19054
    },
    {
      "epoch": 1.4808050979173144,
      "grad_norm": 1.0398640632629395,
      "learning_rate": 2.5959745104134286e-06,
      "loss": 0.669,
      "step": 19055
    },
    {
      "epoch": 1.4808828100714952,
      "grad_norm": 0.16494230926036835,
      "learning_rate": 2.5955859496425244e-06,
      "loss": 0.0516,
      "step": 19056
    },
    {
      "epoch": 1.480960522225676,
      "grad_norm": 0.11415313184261322,
      "learning_rate": 2.5951973888716198e-06,
      "loss": 0.0139,
      "step": 19057
    },
    {
      "epoch": 1.481038234379857,
      "grad_norm": 0.4109225571155548,
      "learning_rate": 2.594808828100715e-06,
      "loss": 0.2017,
      "step": 19058
    },
    {
      "epoch": 1.481115946534038,
      "grad_norm": 0.309693843126297,
      "learning_rate": 2.594420267329811e-06,
      "loss": 0.1301,
      "step": 19059
    },
    {
      "epoch": 1.4811936586882188,
      "grad_norm": 0.3808775842189789,
      "learning_rate": 2.594031706558906e-06,
      "loss": 0.0899,
      "step": 19060
    },
    {
      "epoch": 1.4812713708423997,
      "grad_norm": 0.1496676504611969,
      "learning_rate": 2.5936431457880013e-06,
      "loss": 0.0729,
      "step": 19061
    },
    {
      "epoch": 1.4813490829965807,
      "grad_norm": 0.3365400433540344,
      "learning_rate": 2.593254585017097e-06,
      "loss": 0.0858,
      "step": 19062
    },
    {
      "epoch": 1.4814267951507616,
      "grad_norm": 0.4554365277290344,
      "learning_rate": 2.5928660242461924e-06,
      "loss": 0.3068,
      "step": 19063
    },
    {
      "epoch": 1.4815045073049424,
      "grad_norm": 1.1148184537887573,
      "learning_rate": 2.5924774634752874e-06,
      "loss": 0.2263,
      "step": 19064
    },
    {
      "epoch": 1.4815822194591233,
      "grad_norm": 1.3634179830551147,
      "learning_rate": 2.592088902704383e-06,
      "loss": 0.3057,
      "step": 19065
    },
    {
      "epoch": 1.4816599316133043,
      "grad_norm": 0.5152430534362793,
      "learning_rate": 2.5917003419334786e-06,
      "loss": 0.2595,
      "step": 19066
    },
    {
      "epoch": 1.4817376437674852,
      "grad_norm": 0.46188268065452576,
      "learning_rate": 2.5913117811625744e-06,
      "loss": 0.1459,
      "step": 19067
    },
    {
      "epoch": 1.481815355921666,
      "grad_norm": 0.4124925136566162,
      "learning_rate": 2.5909232203916697e-06,
      "loss": 0.0922,
      "step": 19068
    },
    {
      "epoch": 1.481893068075847,
      "grad_norm": 0.8189970850944519,
      "learning_rate": 2.5905346596207647e-06,
      "loss": 0.5408,
      "step": 19069
    },
    {
      "epoch": 1.481970780230028,
      "grad_norm": 1.0412639379501343,
      "learning_rate": 2.5901460988498605e-06,
      "loss": 0.4145,
      "step": 19070
    },
    {
      "epoch": 1.4820484923842088,
      "grad_norm": 0.8747370839118958,
      "learning_rate": 2.589757538078956e-06,
      "loss": 0.3427,
      "step": 19071
    },
    {
      "epoch": 1.4821262045383898,
      "grad_norm": 0.8858642578125,
      "learning_rate": 2.5893689773080512e-06,
      "loss": 0.3708,
      "step": 19072
    },
    {
      "epoch": 1.4822039166925707,
      "grad_norm": 1.0448983907699585,
      "learning_rate": 2.588980416537147e-06,
      "loss": 0.2439,
      "step": 19073
    },
    {
      "epoch": 1.4822816288467515,
      "grad_norm": 0.6502876281738281,
      "learning_rate": 2.588591855766242e-06,
      "loss": 0.6233,
      "step": 19074
    },
    {
      "epoch": 1.4823593410009326,
      "grad_norm": 0.7619447112083435,
      "learning_rate": 2.5882032949953373e-06,
      "loss": 0.2267,
      "step": 19075
    },
    {
      "epoch": 1.4824370531551134,
      "grad_norm": 0.20038317143917084,
      "learning_rate": 2.587814734224433e-06,
      "loss": 0.0357,
      "step": 19076
    },
    {
      "epoch": 1.4825147653092943,
      "grad_norm": 0.27823832631111145,
      "learning_rate": 2.5874261734535285e-06,
      "loss": 0.053,
      "step": 19077
    },
    {
      "epoch": 1.4825924774634753,
      "grad_norm": 0.3153553903102875,
      "learning_rate": 2.5870376126826235e-06,
      "loss": 0.1099,
      "step": 19078
    },
    {
      "epoch": 1.4826701896176562,
      "grad_norm": 0.439774751663208,
      "learning_rate": 2.5866490519117193e-06,
      "loss": 0.1893,
      "step": 19079
    },
    {
      "epoch": 1.482747901771837,
      "grad_norm": 0.3132784068584442,
      "learning_rate": 2.5862604911408146e-06,
      "loss": 0.037,
      "step": 19080
    },
    {
      "epoch": 1.482825613926018,
      "grad_norm": 0.7759340405464172,
      "learning_rate": 2.58587193036991e-06,
      "loss": 0.1214,
      "step": 19081
    },
    {
      "epoch": 1.482903326080199,
      "grad_norm": 0.29981955885887146,
      "learning_rate": 2.585483369599006e-06,
      "loss": 0.071,
      "step": 19082
    },
    {
      "epoch": 1.4829810382343798,
      "grad_norm": 1.5516592264175415,
      "learning_rate": 2.5850948088281007e-06,
      "loss": 0.6654,
      "step": 19083
    },
    {
      "epoch": 1.4830587503885608,
      "grad_norm": 0.4345325827598572,
      "learning_rate": 2.5847062480571965e-06,
      "loss": 0.2225,
      "step": 19084
    },
    {
      "epoch": 1.4831364625427417,
      "grad_norm": 1.1528855562210083,
      "learning_rate": 2.584317687286292e-06,
      "loss": 0.1716,
      "step": 19085
    },
    {
      "epoch": 1.4832141746969225,
      "grad_norm": 0.1838701069355011,
      "learning_rate": 2.583929126515387e-06,
      "loss": 0.0238,
      "step": 19086
    },
    {
      "epoch": 1.4832918868511036,
      "grad_norm": 0.24602650105953217,
      "learning_rate": 2.5835405657444827e-06,
      "loss": 0.0612,
      "step": 19087
    },
    {
      "epoch": 1.4833695990052844,
      "grad_norm": 0.5280799865722656,
      "learning_rate": 2.583152004973578e-06,
      "loss": 0.1319,
      "step": 19088
    },
    {
      "epoch": 1.4834473111594653,
      "grad_norm": 0.17299576103687286,
      "learning_rate": 2.5827634442026734e-06,
      "loss": 0.0519,
      "step": 19089
    },
    {
      "epoch": 1.4835250233136463,
      "grad_norm": 0.2778295874595642,
      "learning_rate": 2.582374883431769e-06,
      "loss": 0.043,
      "step": 19090
    },
    {
      "epoch": 1.4836027354678272,
      "grad_norm": 0.3655077815055847,
      "learning_rate": 2.581986322660864e-06,
      "loss": 0.0938,
      "step": 19091
    },
    {
      "epoch": 1.483680447622008,
      "grad_norm": 0.5386235117912292,
      "learning_rate": 2.5815977618899595e-06,
      "loss": 0.2324,
      "step": 19092
    },
    {
      "epoch": 1.483758159776189,
      "grad_norm": 0.4286016821861267,
      "learning_rate": 2.5812092011190553e-06,
      "loss": 0.0863,
      "step": 19093
    },
    {
      "epoch": 1.48383587193037,
      "grad_norm": 0.8034062385559082,
      "learning_rate": 2.5808206403481507e-06,
      "loss": 0.2963,
      "step": 19094
    },
    {
      "epoch": 1.4839135840845508,
      "grad_norm": 0.5895763635635376,
      "learning_rate": 2.5804320795772457e-06,
      "loss": 0.0815,
      "step": 19095
    },
    {
      "epoch": 1.4839912962387318,
      "grad_norm": 0.4108320474624634,
      "learning_rate": 2.5800435188063414e-06,
      "loss": 0.4562,
      "step": 19096
    },
    {
      "epoch": 1.4840690083929127,
      "grad_norm": 0.5204164981842041,
      "learning_rate": 2.579654958035437e-06,
      "loss": 0.1725,
      "step": 19097
    },
    {
      "epoch": 1.4841467205470935,
      "grad_norm": 0.10699109733104706,
      "learning_rate": 2.5792663972645326e-06,
      "loss": 0.0493,
      "step": 19098
    },
    {
      "epoch": 1.4842244327012746,
      "grad_norm": 0.3565107583999634,
      "learning_rate": 2.578877836493628e-06,
      "loss": 0.0654,
      "step": 19099
    },
    {
      "epoch": 1.4843021448554554,
      "grad_norm": 0.16637593507766724,
      "learning_rate": 2.578489275722723e-06,
      "loss": 0.0628,
      "step": 19100
    },
    {
      "epoch": 1.4843798570096363,
      "grad_norm": 0.3344324827194214,
      "learning_rate": 2.5781007149518187e-06,
      "loss": 0.0724,
      "step": 19101
    },
    {
      "epoch": 1.4844575691638173,
      "grad_norm": 0.5016431212425232,
      "learning_rate": 2.577712154180914e-06,
      "loss": 0.1771,
      "step": 19102
    },
    {
      "epoch": 1.4845352813179982,
      "grad_norm": 0.36621102690696716,
      "learning_rate": 2.5773235934100095e-06,
      "loss": 0.1371,
      "step": 19103
    },
    {
      "epoch": 1.484612993472179,
      "grad_norm": 0.6424856781959534,
      "learning_rate": 2.5769350326391053e-06,
      "loss": 0.1338,
      "step": 19104
    },
    {
      "epoch": 1.48469070562636,
      "grad_norm": 0.28301095962524414,
      "learning_rate": 2.5765464718682002e-06,
      "loss": 0.0811,
      "step": 19105
    },
    {
      "epoch": 1.484768417780541,
      "grad_norm": 0.5424898266792297,
      "learning_rate": 2.5761579110972956e-06,
      "loss": 0.165,
      "step": 19106
    },
    {
      "epoch": 1.4848461299347218,
      "grad_norm": 1.2632217407226562,
      "learning_rate": 2.5757693503263914e-06,
      "loss": 0.1072,
      "step": 19107
    },
    {
      "epoch": 1.4849238420889028,
      "grad_norm": 0.8322215676307678,
      "learning_rate": 2.5753807895554868e-06,
      "loss": 0.4386,
      "step": 19108
    },
    {
      "epoch": 1.4850015542430837,
      "grad_norm": 0.14851777255535126,
      "learning_rate": 2.5749922287845817e-06,
      "loss": 0.0388,
      "step": 19109
    },
    {
      "epoch": 1.4850792663972645,
      "grad_norm": 0.49373966455459595,
      "learning_rate": 2.5746036680136775e-06,
      "loss": 0.1113,
      "step": 19110
    },
    {
      "epoch": 1.4851569785514456,
      "grad_norm": 0.5635716915130615,
      "learning_rate": 2.574215107242773e-06,
      "loss": 0.1008,
      "step": 19111
    },
    {
      "epoch": 1.4852346907056264,
      "grad_norm": 0.7453036308288574,
      "learning_rate": 2.5738265464718683e-06,
      "loss": 0.1069,
      "step": 19112
    },
    {
      "epoch": 1.4853124028598073,
      "grad_norm": 0.7449941039085388,
      "learning_rate": 2.573437985700964e-06,
      "loss": 0.1658,
      "step": 19113
    },
    {
      "epoch": 1.4853901150139883,
      "grad_norm": 0.5479534268379211,
      "learning_rate": 2.573049424930059e-06,
      "loss": 0.2171,
      "step": 19114
    },
    {
      "epoch": 1.4854678271681692,
      "grad_norm": 0.1165720522403717,
      "learning_rate": 2.572660864159155e-06,
      "loss": 0.0466,
      "step": 19115
    },
    {
      "epoch": 1.48554553932235,
      "grad_norm": 0.4752391278743744,
      "learning_rate": 2.57227230338825e-06,
      "loss": 0.0637,
      "step": 19116
    },
    {
      "epoch": 1.4856232514765308,
      "grad_norm": 0.1403767168521881,
      "learning_rate": 2.5718837426173456e-06,
      "loss": 0.0319,
      "step": 19117
    },
    {
      "epoch": 1.485700963630712,
      "grad_norm": 0.21605433523654938,
      "learning_rate": 2.5714951818464414e-06,
      "loss": 0.0481,
      "step": 19118
    },
    {
      "epoch": 1.4857786757848928,
      "grad_norm": 0.8563247919082642,
      "learning_rate": 2.5711066210755363e-06,
      "loss": 0.3308,
      "step": 19119
    },
    {
      "epoch": 1.4858563879390736,
      "grad_norm": 0.9289021492004395,
      "learning_rate": 2.5707180603046317e-06,
      "loss": 0.3104,
      "step": 19120
    },
    {
      "epoch": 1.4859341000932547,
      "grad_norm": 1.0802209377288818,
      "learning_rate": 2.5703294995337275e-06,
      "loss": 0.6957,
      "step": 19121
    },
    {
      "epoch": 1.4860118122474355,
      "grad_norm": 0.1932942122220993,
      "learning_rate": 2.569940938762823e-06,
      "loss": 0.053,
      "step": 19122
    },
    {
      "epoch": 1.4860895244016163,
      "grad_norm": 0.19813571870326996,
      "learning_rate": 2.569552377991918e-06,
      "loss": 0.0606,
      "step": 19123
    },
    {
      "epoch": 1.4861672365557972,
      "grad_norm": 0.21551506221294403,
      "learning_rate": 2.5691638172210136e-06,
      "loss": 0.0903,
      "step": 19124
    },
    {
      "epoch": 1.4862449487099783,
      "grad_norm": 1.2186585664749146,
      "learning_rate": 2.568775256450109e-06,
      "loss": 0.3142,
      "step": 19125
    },
    {
      "epoch": 1.486322660864159,
      "grad_norm": 0.24522973597049713,
      "learning_rate": 2.5683866956792043e-06,
      "loss": 0.0298,
      "step": 19126
    },
    {
      "epoch": 1.48640037301834,
      "grad_norm": 0.4684351980686188,
      "learning_rate": 2.5679981349083e-06,
      "loss": 0.2013,
      "step": 19127
    },
    {
      "epoch": 1.486478085172521,
      "grad_norm": 1.3745331764221191,
      "learning_rate": 2.567609574137395e-06,
      "loss": 0.8209,
      "step": 19128
    },
    {
      "epoch": 1.4865557973267018,
      "grad_norm": 0.5978095531463623,
      "learning_rate": 2.567221013366491e-06,
      "loss": 0.4123,
      "step": 19129
    },
    {
      "epoch": 1.4866335094808827,
      "grad_norm": 0.45026895403862,
      "learning_rate": 2.5668324525955863e-06,
      "loss": 0.0977,
      "step": 19130
    },
    {
      "epoch": 1.4867112216350638,
      "grad_norm": 0.6038925051689148,
      "learning_rate": 2.5664438918246816e-06,
      "loss": 0.0924,
      "step": 19131
    },
    {
      "epoch": 1.4867889337892446,
      "grad_norm": 1.161483645439148,
      "learning_rate": 2.5660553310537774e-06,
      "loss": 0.9724,
      "step": 19132
    },
    {
      "epoch": 1.4868666459434254,
      "grad_norm": 0.5875877141952515,
      "learning_rate": 2.5656667702828724e-06,
      "loss": 0.2196,
      "step": 19133
    },
    {
      "epoch": 1.4869443580976065,
      "grad_norm": 0.7795827388763428,
      "learning_rate": 2.5652782095119678e-06,
      "loss": 0.2303,
      "step": 19134
    },
    {
      "epoch": 1.4870220702517873,
      "grad_norm": 0.2712160050868988,
      "learning_rate": 2.5648896487410635e-06,
      "loss": 0.1658,
      "step": 19135
    },
    {
      "epoch": 1.4870997824059682,
      "grad_norm": 0.9298396110534668,
      "learning_rate": 2.564501087970159e-06,
      "loss": 0.2708,
      "step": 19136
    },
    {
      "epoch": 1.4871774945601492,
      "grad_norm": 0.7116413116455078,
      "learning_rate": 2.564112527199254e-06,
      "loss": 0.146,
      "step": 19137
    },
    {
      "epoch": 1.48725520671433,
      "grad_norm": 0.6535938382148743,
      "learning_rate": 2.5637239664283497e-06,
      "loss": 0.2983,
      "step": 19138
    },
    {
      "epoch": 1.487332918868511,
      "grad_norm": 1.1818945407867432,
      "learning_rate": 2.563335405657445e-06,
      "loss": 0.8201,
      "step": 19139
    },
    {
      "epoch": 1.487410631022692,
      "grad_norm": 0.4841654598712921,
      "learning_rate": 2.5629468448865404e-06,
      "loss": 0.1858,
      "step": 19140
    },
    {
      "epoch": 1.4874883431768728,
      "grad_norm": 0.6706506013870239,
      "learning_rate": 2.562558284115636e-06,
      "loss": 0.2079,
      "step": 19141
    },
    {
      "epoch": 1.4875660553310537,
      "grad_norm": 0.35564324259757996,
      "learning_rate": 2.562169723344731e-06,
      "loss": 0.1824,
      "step": 19142
    },
    {
      "epoch": 1.4876437674852347,
      "grad_norm": 0.6475719213485718,
      "learning_rate": 2.561781162573827e-06,
      "loss": 0.0606,
      "step": 19143
    },
    {
      "epoch": 1.4877214796394156,
      "grad_norm": 0.6461330056190491,
      "learning_rate": 2.5613926018029223e-06,
      "loss": 0.3532,
      "step": 19144
    },
    {
      "epoch": 1.4877991917935964,
      "grad_norm": 0.5454832911491394,
      "learning_rate": 2.5610040410320177e-06,
      "loss": 0.0765,
      "step": 19145
    },
    {
      "epoch": 1.4878769039477775,
      "grad_norm": 0.18773646652698517,
      "learning_rate": 2.560615480261113e-06,
      "loss": 0.0363,
      "step": 19146
    },
    {
      "epoch": 1.4879546161019583,
      "grad_norm": 0.2104826122522354,
      "learning_rate": 2.5602269194902085e-06,
      "loss": 0.0227,
      "step": 19147
    },
    {
      "epoch": 1.4880323282561392,
      "grad_norm": 0.5125435590744019,
      "learning_rate": 2.559838358719304e-06,
      "loss": 0.0996,
      "step": 19148
    },
    {
      "epoch": 1.4881100404103202,
      "grad_norm": 0.5423226952552795,
      "learning_rate": 2.5594497979483996e-06,
      "loss": 0.1908,
      "step": 19149
    },
    {
      "epoch": 1.488187752564501,
      "grad_norm": 0.7039042711257935,
      "learning_rate": 2.5590612371774946e-06,
      "loss": 0.1897,
      "step": 19150
    },
    {
      "epoch": 1.488265464718682,
      "grad_norm": 0.8018133640289307,
      "learning_rate": 2.55867267640659e-06,
      "loss": 0.2211,
      "step": 19151
    },
    {
      "epoch": 1.488343176872863,
      "grad_norm": 0.7264998555183411,
      "learning_rate": 2.5582841156356857e-06,
      "loss": 0.4419,
      "step": 19152
    },
    {
      "epoch": 1.4884208890270438,
      "grad_norm": 0.6019410490989685,
      "learning_rate": 2.557895554864781e-06,
      "loss": 0.115,
      "step": 19153
    },
    {
      "epoch": 1.4884986011812247,
      "grad_norm": 0.4960807263851166,
      "learning_rate": 2.557506994093876e-06,
      "loss": 0.0943,
      "step": 19154
    },
    {
      "epoch": 1.4885763133354057,
      "grad_norm": 0.27784445881843567,
      "learning_rate": 2.557118433322972e-06,
      "loss": 0.0974,
      "step": 19155
    },
    {
      "epoch": 1.4886540254895866,
      "grad_norm": 0.44724300503730774,
      "learning_rate": 2.5567298725520672e-06,
      "loss": 0.5283,
      "step": 19156
    },
    {
      "epoch": 1.4887317376437674,
      "grad_norm": 0.17277614772319794,
      "learning_rate": 2.5563413117811626e-06,
      "loss": 0.0618,
      "step": 19157
    },
    {
      "epoch": 1.4888094497979485,
      "grad_norm": 0.1922520399093628,
      "learning_rate": 2.5559527510102584e-06,
      "loss": 0.0713,
      "step": 19158
    },
    {
      "epoch": 1.4888871619521293,
      "grad_norm": 0.49774470925331116,
      "learning_rate": 2.5555641902393534e-06,
      "loss": 0.1293,
      "step": 19159
    },
    {
      "epoch": 1.4889648741063102,
      "grad_norm": 0.7075380086898804,
      "learning_rate": 2.555175629468449e-06,
      "loss": 0.4021,
      "step": 19160
    },
    {
      "epoch": 1.4890425862604912,
      "grad_norm": 0.9348165392875671,
      "learning_rate": 2.5547870686975445e-06,
      "loss": 0.4031,
      "step": 19161
    },
    {
      "epoch": 1.489120298414672,
      "grad_norm": 0.3007022738456726,
      "learning_rate": 2.55439850792664e-06,
      "loss": 0.1743,
      "step": 19162
    },
    {
      "epoch": 1.489198010568853,
      "grad_norm": 0.7616564035415649,
      "learning_rate": 2.5540099471557357e-06,
      "loss": 0.5456,
      "step": 19163
    },
    {
      "epoch": 1.489275722723034,
      "grad_norm": 0.2646726071834564,
      "learning_rate": 2.5536213863848306e-06,
      "loss": 0.0465,
      "step": 19164
    },
    {
      "epoch": 1.4893534348772148,
      "grad_norm": 0.4681077301502228,
      "learning_rate": 2.553232825613926e-06,
      "loss": 0.2053,
      "step": 19165
    },
    {
      "epoch": 1.4894311470313957,
      "grad_norm": 0.5451260805130005,
      "learning_rate": 2.552844264843022e-06,
      "loss": 0.1477,
      "step": 19166
    },
    {
      "epoch": 1.4895088591855767,
      "grad_norm": 0.6725202798843384,
      "learning_rate": 2.552455704072117e-06,
      "loss": 0.2953,
      "step": 19167
    },
    {
      "epoch": 1.4895865713397576,
      "grad_norm": 0.5421139001846313,
      "learning_rate": 2.552067143301212e-06,
      "loss": 0.2676,
      "step": 19168
    },
    {
      "epoch": 1.4896642834939384,
      "grad_norm": 0.31171295046806335,
      "learning_rate": 2.551678582530308e-06,
      "loss": 0.1979,
      "step": 19169
    },
    {
      "epoch": 1.4897419956481195,
      "grad_norm": 0.6252862811088562,
      "learning_rate": 2.5512900217594033e-06,
      "loss": 0.2787,
      "step": 19170
    },
    {
      "epoch": 1.4898197078023003,
      "grad_norm": 0.5319650769233704,
      "learning_rate": 2.5509014609884987e-06,
      "loss": 0.2879,
      "step": 19171
    },
    {
      "epoch": 1.4898974199564812,
      "grad_norm": 0.13596121966838837,
      "learning_rate": 2.5505129002175945e-06,
      "loss": 0.0177,
      "step": 19172
    },
    {
      "epoch": 1.4899751321106622,
      "grad_norm": 0.24761979281902313,
      "learning_rate": 2.5501243394466894e-06,
      "loss": 0.0371,
      "step": 19173
    },
    {
      "epoch": 1.490052844264843,
      "grad_norm": 0.4523251950740814,
      "learning_rate": 2.5497357786757852e-06,
      "loss": 0.058,
      "step": 19174
    },
    {
      "epoch": 1.490130556419024,
      "grad_norm": 0.5031217336654663,
      "learning_rate": 2.5493472179048806e-06,
      "loss": 0.0637,
      "step": 19175
    },
    {
      "epoch": 1.490208268573205,
      "grad_norm": 0.592146635055542,
      "learning_rate": 2.548958657133976e-06,
      "loss": 0.2522,
      "step": 19176
    },
    {
      "epoch": 1.4902859807273858,
      "grad_norm": 0.717119574546814,
      "learning_rate": 2.5485700963630718e-06,
      "loss": 0.2128,
      "step": 19177
    },
    {
      "epoch": 1.4903636928815667,
      "grad_norm": 0.530871570110321,
      "learning_rate": 2.5481815355921667e-06,
      "loss": 0.1918,
      "step": 19178
    },
    {
      "epoch": 1.4904414050357475,
      "grad_norm": 0.2076016664505005,
      "learning_rate": 2.547792974821262e-06,
      "loss": 0.0631,
      "step": 19179
    },
    {
      "epoch": 1.4905191171899286,
      "grad_norm": 0.411404550075531,
      "learning_rate": 2.547404414050358e-06,
      "loss": 0.1066,
      "step": 19180
    },
    {
      "epoch": 1.4905968293441094,
      "grad_norm": 0.45599648356437683,
      "learning_rate": 2.5470158532794533e-06,
      "loss": 0.1536,
      "step": 19181
    },
    {
      "epoch": 1.4906745414982903,
      "grad_norm": 0.40583762526512146,
      "learning_rate": 2.546627292508548e-06,
      "loss": 0.2275,
      "step": 19182
    },
    {
      "epoch": 1.4907522536524713,
      "grad_norm": 0.07938461750745773,
      "learning_rate": 2.546238731737644e-06,
      "loss": 0.0091,
      "step": 19183
    },
    {
      "epoch": 1.4908299658066522,
      "grad_norm": 0.23461541533470154,
      "learning_rate": 2.5458501709667394e-06,
      "loss": 0.101,
      "step": 19184
    },
    {
      "epoch": 1.490907677960833,
      "grad_norm": 0.12536948919296265,
      "learning_rate": 2.5454616101958348e-06,
      "loss": 0.0087,
      "step": 19185
    },
    {
      "epoch": 1.4909853901150139,
      "grad_norm": 0.5160208344459534,
      "learning_rate": 2.5450730494249305e-06,
      "loss": 0.1869,
      "step": 19186
    },
    {
      "epoch": 1.491063102269195,
      "grad_norm": 0.2958970367908478,
      "learning_rate": 2.5446844886540255e-06,
      "loss": 0.0259,
      "step": 19187
    },
    {
      "epoch": 1.4911408144233758,
      "grad_norm": 0.47484317421913147,
      "learning_rate": 2.544295927883121e-06,
      "loss": 0.2165,
      "step": 19188
    },
    {
      "epoch": 1.4912185265775566,
      "grad_norm": 0.32204368710517883,
      "learning_rate": 2.5439073671122167e-06,
      "loss": 0.1024,
      "step": 19189
    },
    {
      "epoch": 1.4912962387317377,
      "grad_norm": 1.804055094718933,
      "learning_rate": 2.543518806341312e-06,
      "loss": 0.5671,
      "step": 19190
    },
    {
      "epoch": 1.4913739508859185,
      "grad_norm": 0.3996630907058716,
      "learning_rate": 2.543130245570408e-06,
      "loss": 0.0767,
      "step": 19191
    },
    {
      "epoch": 1.4914516630400994,
      "grad_norm": 0.9300591945648193,
      "learning_rate": 2.542741684799503e-06,
      "loss": 0.135,
      "step": 19192
    },
    {
      "epoch": 1.4915293751942804,
      "grad_norm": 0.5315893888473511,
      "learning_rate": 2.542353124028598e-06,
      "loss": 0.2788,
      "step": 19193
    },
    {
      "epoch": 1.4916070873484613,
      "grad_norm": 0.19642071425914764,
      "learning_rate": 2.541964563257694e-06,
      "loss": 0.084,
      "step": 19194
    },
    {
      "epoch": 1.491684799502642,
      "grad_norm": 0.44777122139930725,
      "learning_rate": 2.5415760024867893e-06,
      "loss": 0.1282,
      "step": 19195
    },
    {
      "epoch": 1.4917625116568232,
      "grad_norm": 0.4295825660228729,
      "learning_rate": 2.5411874417158843e-06,
      "loss": 0.2002,
      "step": 19196
    },
    {
      "epoch": 1.491840223811004,
      "grad_norm": 0.542106032371521,
      "learning_rate": 2.54079888094498e-06,
      "loss": 0.0568,
      "step": 19197
    },
    {
      "epoch": 1.4919179359651848,
      "grad_norm": 0.6510375142097473,
      "learning_rate": 2.5404103201740755e-06,
      "loss": 0.345,
      "step": 19198
    },
    {
      "epoch": 1.491995648119366,
      "grad_norm": 0.7208238840103149,
      "learning_rate": 2.540021759403171e-06,
      "loss": 0.4352,
      "step": 19199
    },
    {
      "epoch": 1.4920733602735468,
      "grad_norm": 0.6573659181594849,
      "learning_rate": 2.5396331986322666e-06,
      "loss": 0.6242,
      "step": 19200
    },
    {
      "epoch": 1.4921510724277276,
      "grad_norm": 0.3955175280570984,
      "learning_rate": 2.5392446378613616e-06,
      "loss": 0.1691,
      "step": 19201
    },
    {
      "epoch": 1.4922287845819087,
      "grad_norm": 1.084935188293457,
      "learning_rate": 2.538856077090457e-06,
      "loss": 0.4568,
      "step": 19202
    },
    {
      "epoch": 1.4923064967360895,
      "grad_norm": 0.541109025478363,
      "learning_rate": 2.5384675163195527e-06,
      "loss": 0.1176,
      "step": 19203
    },
    {
      "epoch": 1.4923842088902703,
      "grad_norm": 0.4033001959323883,
      "learning_rate": 2.538078955548648e-06,
      "loss": 0.0875,
      "step": 19204
    },
    {
      "epoch": 1.4924619210444514,
      "grad_norm": 0.11865796148777008,
      "learning_rate": 2.537690394777744e-06,
      "loss": 0.0213,
      "step": 19205
    },
    {
      "epoch": 1.4925396331986323,
      "grad_norm": 0.04597511142492294,
      "learning_rate": 2.537301834006839e-06,
      "loss": 0.0122,
      "step": 19206
    },
    {
      "epoch": 1.492617345352813,
      "grad_norm": 0.5279380679130554,
      "learning_rate": 2.5369132732359342e-06,
      "loss": 0.0896,
      "step": 19207
    },
    {
      "epoch": 1.4926950575069942,
      "grad_norm": 0.30638471245765686,
      "learning_rate": 2.53652471246503e-06,
      "loss": 0.0773,
      "step": 19208
    },
    {
      "epoch": 1.492772769661175,
      "grad_norm": 0.45460405945777893,
      "learning_rate": 2.536136151694125e-06,
      "loss": 0.2413,
      "step": 19209
    },
    {
      "epoch": 1.4928504818153558,
      "grad_norm": 0.04471106082201004,
      "learning_rate": 2.5357475909232204e-06,
      "loss": 0.0166,
      "step": 19210
    },
    {
      "epoch": 1.492928193969537,
      "grad_norm": 0.5066907405853271,
      "learning_rate": 2.535359030152316e-06,
      "loss": 0.0937,
      "step": 19211
    },
    {
      "epoch": 1.4930059061237178,
      "grad_norm": 0.45152217149734497,
      "learning_rate": 2.5349704693814115e-06,
      "loss": 0.1278,
      "step": 19212
    },
    {
      "epoch": 1.4930836182778986,
      "grad_norm": 0.3353462219238281,
      "learning_rate": 2.5345819086105065e-06,
      "loss": 0.0882,
      "step": 19213
    },
    {
      "epoch": 1.4931613304320797,
      "grad_norm": 0.24771811068058014,
      "learning_rate": 2.5341933478396023e-06,
      "loss": 0.0478,
      "step": 19214
    },
    {
      "epoch": 1.4932390425862605,
      "grad_norm": 1.4059487581253052,
      "learning_rate": 2.5338047870686976e-06,
      "loss": 0.5042,
      "step": 19215
    },
    {
      "epoch": 1.4933167547404413,
      "grad_norm": 0.44677412509918213,
      "learning_rate": 2.533416226297793e-06,
      "loss": 0.4718,
      "step": 19216
    },
    {
      "epoch": 1.4933944668946224,
      "grad_norm": 0.7305838465690613,
      "learning_rate": 2.533027665526889e-06,
      "loss": 0.2323,
      "step": 19217
    },
    {
      "epoch": 1.4934721790488033,
      "grad_norm": 0.16575336456298828,
      "learning_rate": 2.5326391047559838e-06,
      "loss": 0.0212,
      "step": 19218
    },
    {
      "epoch": 1.493549891202984,
      "grad_norm": 0.3939744830131531,
      "learning_rate": 2.5322505439850796e-06,
      "loss": 0.2467,
      "step": 19219
    },
    {
      "epoch": 1.4936276033571652,
      "grad_norm": 1.148073673248291,
      "learning_rate": 2.531861983214175e-06,
      "loss": 0.1956,
      "step": 19220
    },
    {
      "epoch": 1.493705315511346,
      "grad_norm": 0.20073547959327698,
      "learning_rate": 2.5314734224432703e-06,
      "loss": 0.0685,
      "step": 19221
    },
    {
      "epoch": 1.4937830276655268,
      "grad_norm": 0.27375829219818115,
      "learning_rate": 2.531084861672366e-06,
      "loss": 0.1291,
      "step": 19222
    },
    {
      "epoch": 1.493860739819708,
      "grad_norm": 1.3841552734375,
      "learning_rate": 2.530696300901461e-06,
      "loss": 0.2951,
      "step": 19223
    },
    {
      "epoch": 1.4939384519738887,
      "grad_norm": 0.25274860858917236,
      "learning_rate": 2.5303077401305564e-06,
      "loss": 0.2461,
      "step": 19224
    },
    {
      "epoch": 1.4940161641280696,
      "grad_norm": 0.2976815104484558,
      "learning_rate": 2.5299191793596522e-06,
      "loss": 0.1321,
      "step": 19225
    },
    {
      "epoch": 1.4940938762822507,
      "grad_norm": 0.3495713174343109,
      "learning_rate": 2.5295306185887476e-06,
      "loss": 0.1354,
      "step": 19226
    },
    {
      "epoch": 1.4941715884364315,
      "grad_norm": 0.42918503284454346,
      "learning_rate": 2.5291420578178425e-06,
      "loss": 0.0972,
      "step": 19227
    },
    {
      "epoch": 1.4942493005906123,
      "grad_norm": 0.4476305842399597,
      "learning_rate": 2.5287534970469383e-06,
      "loss": 0.1988,
      "step": 19228
    },
    {
      "epoch": 1.4943270127447934,
      "grad_norm": 0.2008230984210968,
      "learning_rate": 2.5283649362760337e-06,
      "loss": 0.0304,
      "step": 19229
    },
    {
      "epoch": 1.4944047248989742,
      "grad_norm": 0.24685990810394287,
      "learning_rate": 2.527976375505129e-06,
      "loss": 0.3038,
      "step": 19230
    },
    {
      "epoch": 1.494482437053155,
      "grad_norm": 0.33395370841026306,
      "learning_rate": 2.527587814734225e-06,
      "loss": 0.0385,
      "step": 19231
    },
    {
      "epoch": 1.4945601492073362,
      "grad_norm": 0.22406722605228424,
      "learning_rate": 2.52719925396332e-06,
      "loss": 0.0765,
      "step": 19232
    },
    {
      "epoch": 1.494637861361517,
      "grad_norm": 0.39655834436416626,
      "learning_rate": 2.5268106931924152e-06,
      "loss": 0.1461,
      "step": 19233
    },
    {
      "epoch": 1.4947155735156978,
      "grad_norm": 0.8015941977500916,
      "learning_rate": 2.526422132421511e-06,
      "loss": 0.4554,
      "step": 19234
    },
    {
      "epoch": 1.494793285669879,
      "grad_norm": 0.6376291513442993,
      "learning_rate": 2.5260335716506064e-06,
      "loss": 0.1216,
      "step": 19235
    },
    {
      "epoch": 1.4948709978240597,
      "grad_norm": 0.3223740756511688,
      "learning_rate": 2.525645010879702e-06,
      "loss": 0.1289,
      "step": 19236
    },
    {
      "epoch": 1.4949487099782406,
      "grad_norm": 0.34521788358688354,
      "learning_rate": 2.525256450108797e-06,
      "loss": 0.1008,
      "step": 19237
    },
    {
      "epoch": 1.4950264221324214,
      "grad_norm": 0.14000795781612396,
      "learning_rate": 2.5248678893378925e-06,
      "loss": 0.026,
      "step": 19238
    },
    {
      "epoch": 1.4951041342866025,
      "grad_norm": 0.5182393193244934,
      "learning_rate": 2.5244793285669883e-06,
      "loss": 0.1356,
      "step": 19239
    },
    {
      "epoch": 1.4951818464407833,
      "grad_norm": 0.3961760401725769,
      "learning_rate": 2.5240907677960837e-06,
      "loss": 0.2292,
      "step": 19240
    },
    {
      "epoch": 1.4952595585949642,
      "grad_norm": 0.5642988681793213,
      "learning_rate": 2.5237022070251786e-06,
      "loss": 0.0522,
      "step": 19241
    },
    {
      "epoch": 1.4953372707491452,
      "grad_norm": 0.2893548607826233,
      "learning_rate": 2.5233136462542744e-06,
      "loss": 0.0716,
      "step": 19242
    },
    {
      "epoch": 1.495414982903326,
      "grad_norm": 0.6304966807365417,
      "learning_rate": 2.52292508548337e-06,
      "loss": 0.3437,
      "step": 19243
    },
    {
      "epoch": 1.495492695057507,
      "grad_norm": 1.5300952196121216,
      "learning_rate": 2.522536524712465e-06,
      "loss": 0.5466,
      "step": 19244
    },
    {
      "epoch": 1.495570407211688,
      "grad_norm": 0.4249778985977173,
      "learning_rate": 2.522147963941561e-06,
      "loss": 0.0758,
      "step": 19245
    },
    {
      "epoch": 1.4956481193658688,
      "grad_norm": 0.19336707890033722,
      "learning_rate": 2.521759403170656e-06,
      "loss": 0.0495,
      "step": 19246
    },
    {
      "epoch": 1.4957258315200497,
      "grad_norm": 0.3907219469547272,
      "learning_rate": 2.5213708423997513e-06,
      "loss": 0.2155,
      "step": 19247
    },
    {
      "epoch": 1.4958035436742305,
      "grad_norm": 0.3735150396823883,
      "learning_rate": 2.520982281628847e-06,
      "loss": 0.0923,
      "step": 19248
    },
    {
      "epoch": 1.4958812558284116,
      "grad_norm": 0.695809006690979,
      "learning_rate": 2.5205937208579425e-06,
      "loss": 0.2628,
      "step": 19249
    },
    {
      "epoch": 1.4959589679825924,
      "grad_norm": 0.42263680696487427,
      "learning_rate": 2.5202051600870383e-06,
      "loss": 0.2008,
      "step": 19250
    },
    {
      "epoch": 1.4960366801367733,
      "grad_norm": 0.8446235656738281,
      "learning_rate": 2.519816599316133e-06,
      "loss": 0.3133,
      "step": 19251
    },
    {
      "epoch": 1.4961143922909543,
      "grad_norm": 0.6126356720924377,
      "learning_rate": 2.5194280385452286e-06,
      "loss": 0.1633,
      "step": 19252
    },
    {
      "epoch": 1.4961921044451352,
      "grad_norm": 0.6853980422019958,
      "learning_rate": 2.5190394777743244e-06,
      "loss": 0.3724,
      "step": 19253
    },
    {
      "epoch": 1.496269816599316,
      "grad_norm": 0.5870542526245117,
      "learning_rate": 2.5186509170034197e-06,
      "loss": 0.1417,
      "step": 19254
    },
    {
      "epoch": 1.496347528753497,
      "grad_norm": 0.20136334002017975,
      "learning_rate": 2.5182623562325147e-06,
      "loss": 0.0417,
      "step": 19255
    },
    {
      "epoch": 1.496425240907678,
      "grad_norm": 0.68709796667099,
      "learning_rate": 2.5178737954616105e-06,
      "loss": 0.3023,
      "step": 19256
    },
    {
      "epoch": 1.4965029530618588,
      "grad_norm": 0.9031326770782471,
      "learning_rate": 2.517485234690706e-06,
      "loss": 0.2687,
      "step": 19257
    },
    {
      "epoch": 1.4965806652160398,
      "grad_norm": 0.047652196139097214,
      "learning_rate": 2.5170966739198012e-06,
      "loss": 0.0138,
      "step": 19258
    },
    {
      "epoch": 1.4966583773702207,
      "grad_norm": 0.43296000361442566,
      "learning_rate": 2.516708113148897e-06,
      "loss": 0.0797,
      "step": 19259
    },
    {
      "epoch": 1.4967360895244015,
      "grad_norm": 0.21795396506786346,
      "learning_rate": 2.516319552377992e-06,
      "loss": 0.0511,
      "step": 19260
    },
    {
      "epoch": 1.4968138016785826,
      "grad_norm": 0.6474025249481201,
      "learning_rate": 2.5159309916070874e-06,
      "loss": 0.1131,
      "step": 19261
    },
    {
      "epoch": 1.4968915138327634,
      "grad_norm": 0.3731006979942322,
      "learning_rate": 2.515542430836183e-06,
      "loss": 0.062,
      "step": 19262
    },
    {
      "epoch": 1.4969692259869443,
      "grad_norm": 0.27728134393692017,
      "learning_rate": 2.5151538700652785e-06,
      "loss": 0.0991,
      "step": 19263
    },
    {
      "epoch": 1.4970469381411253,
      "grad_norm": 0.40411847829818726,
      "learning_rate": 2.5147653092943735e-06,
      "loss": 0.0413,
      "step": 19264
    },
    {
      "epoch": 1.4971246502953062,
      "grad_norm": 0.4740543067455292,
      "learning_rate": 2.5143767485234693e-06,
      "loss": 0.0138,
      "step": 19265
    },
    {
      "epoch": 1.497202362449487,
      "grad_norm": 0.5854663252830505,
      "learning_rate": 2.5139881877525646e-06,
      "loss": 0.1254,
      "step": 19266
    },
    {
      "epoch": 1.497280074603668,
      "grad_norm": 0.46917542815208435,
      "learning_rate": 2.5135996269816604e-06,
      "loss": 0.0715,
      "step": 19267
    },
    {
      "epoch": 1.497357786757849,
      "grad_norm": 1.1091152429580688,
      "learning_rate": 2.513211066210756e-06,
      "loss": 0.3579,
      "step": 19268
    },
    {
      "epoch": 1.4974354989120298,
      "grad_norm": 0.32894933223724365,
      "learning_rate": 2.5128225054398508e-06,
      "loss": 0.0642,
      "step": 19269
    },
    {
      "epoch": 1.4975132110662108,
      "grad_norm": 1.5566686391830444,
      "learning_rate": 2.5124339446689466e-06,
      "loss": 0.2869,
      "step": 19270
    },
    {
      "epoch": 1.4975909232203917,
      "grad_norm": 0.594308078289032,
      "learning_rate": 2.512045383898042e-06,
      "loss": 0.2729,
      "step": 19271
    },
    {
      "epoch": 1.4976686353745725,
      "grad_norm": 0.2635228633880615,
      "learning_rate": 2.5116568231271373e-06,
      "loss": 0.1326,
      "step": 19272
    },
    {
      "epoch": 1.4977463475287536,
      "grad_norm": 1.1291561126708984,
      "learning_rate": 2.5112682623562327e-06,
      "loss": 0.1011,
      "step": 19273
    },
    {
      "epoch": 1.4978240596829344,
      "grad_norm": 0.42049461603164673,
      "learning_rate": 2.510879701585328e-06,
      "loss": 0.0802,
      "step": 19274
    },
    {
      "epoch": 1.4979017718371153,
      "grad_norm": 0.25713545083999634,
      "learning_rate": 2.5104911408144234e-06,
      "loss": 0.0293,
      "step": 19275
    },
    {
      "epoch": 1.4979794839912963,
      "grad_norm": 0.29313623905181885,
      "learning_rate": 2.5101025800435192e-06,
      "loss": 0.1214,
      "step": 19276
    },
    {
      "epoch": 1.4980571961454772,
      "grad_norm": 0.5361855030059814,
      "learning_rate": 2.509714019272614e-06,
      "loss": 0.0911,
      "step": 19277
    },
    {
      "epoch": 1.498134908299658,
      "grad_norm": 0.1951400637626648,
      "learning_rate": 2.5093254585017096e-06,
      "loss": 0.1313,
      "step": 19278
    },
    {
      "epoch": 1.498212620453839,
      "grad_norm": 0.2062830775976181,
      "learning_rate": 2.5089368977308053e-06,
      "loss": 0.0485,
      "step": 19279
    },
    {
      "epoch": 1.49829033260802,
      "grad_norm": 0.16514019668102264,
      "learning_rate": 2.5085483369599007e-06,
      "loss": 0.0455,
      "step": 19280
    },
    {
      "epoch": 1.4983680447622008,
      "grad_norm": 0.7923297882080078,
      "learning_rate": 2.5081597761889965e-06,
      "loss": 0.3527,
      "step": 19281
    },
    {
      "epoch": 1.4984457569163818,
      "grad_norm": 0.5233863592147827,
      "learning_rate": 2.5077712154180915e-06,
      "loss": 0.2662,
      "step": 19282
    },
    {
      "epoch": 1.4985234690705627,
      "grad_norm": 0.16356410086154938,
      "learning_rate": 2.507382654647187e-06,
      "loss": 0.0218,
      "step": 19283
    },
    {
      "epoch": 1.4986011812247435,
      "grad_norm": 1.0403594970703125,
      "learning_rate": 2.5069940938762826e-06,
      "loss": 0.1279,
      "step": 19284
    },
    {
      "epoch": 1.4986788933789246,
      "grad_norm": 0.9572876691818237,
      "learning_rate": 2.506605533105378e-06,
      "loss": 0.3083,
      "step": 19285
    },
    {
      "epoch": 1.4987566055331054,
      "grad_norm": 0.9732732176780701,
      "learning_rate": 2.506216972334473e-06,
      "loss": 0.2392,
      "step": 19286
    },
    {
      "epoch": 1.4988343176872863,
      "grad_norm": 0.8272549510002136,
      "learning_rate": 2.5058284115635688e-06,
      "loss": 0.2041,
      "step": 19287
    },
    {
      "epoch": 1.4989120298414673,
      "grad_norm": 0.6218376159667969,
      "learning_rate": 2.505439850792664e-06,
      "loss": 0.2915,
      "step": 19288
    },
    {
      "epoch": 1.4989897419956482,
      "grad_norm": 0.5503054261207581,
      "learning_rate": 2.5050512900217595e-06,
      "loss": 0.4423,
      "step": 19289
    },
    {
      "epoch": 1.499067454149829,
      "grad_norm": 0.4682525098323822,
      "learning_rate": 2.5046627292508553e-06,
      "loss": 0.1517,
      "step": 19290
    },
    {
      "epoch": 1.49914516630401,
      "grad_norm": 0.3755398690700531,
      "learning_rate": 2.5042741684799503e-06,
      "loss": 0.0681,
      "step": 19291
    },
    {
      "epoch": 1.499222878458191,
      "grad_norm": 0.2807687222957611,
      "learning_rate": 2.5038856077090456e-06,
      "loss": 0.0302,
      "step": 19292
    },
    {
      "epoch": 1.4993005906123718,
      "grad_norm": 0.5196779370307922,
      "learning_rate": 2.5034970469381414e-06,
      "loss": 0.0255,
      "step": 19293
    },
    {
      "epoch": 1.4993783027665528,
      "grad_norm": 0.9102811217308044,
      "learning_rate": 2.503108486167237e-06,
      "loss": 0.1963,
      "step": 19294
    },
    {
      "epoch": 1.4994560149207337,
      "grad_norm": 0.3460869789123535,
      "learning_rate": 2.5027199253963326e-06,
      "loss": 0.1569,
      "step": 19295
    },
    {
      "epoch": 1.4995337270749145,
      "grad_norm": 0.372541606426239,
      "learning_rate": 2.5023313646254275e-06,
      "loss": 0.3035,
      "step": 19296
    },
    {
      "epoch": 1.4996114392290956,
      "grad_norm": 0.05156228318810463,
      "learning_rate": 2.501942803854523e-06,
      "loss": 0.007,
      "step": 19297
    },
    {
      "epoch": 1.4996891513832764,
      "grad_norm": 2.0499391555786133,
      "learning_rate": 2.5015542430836187e-06,
      "loss": 0.7206,
      "step": 19298
    },
    {
      "epoch": 1.4997668635374573,
      "grad_norm": 0.2629462480545044,
      "learning_rate": 2.501165682312714e-06,
      "loss": 0.0796,
      "step": 19299
    },
    {
      "epoch": 1.499844575691638,
      "grad_norm": 0.6335462331771851,
      "learning_rate": 2.500777121541809e-06,
      "loss": 0.7339,
      "step": 19300
    },
    {
      "epoch": 1.4999222878458192,
      "grad_norm": 0.49721357226371765,
      "learning_rate": 2.500388560770905e-06,
      "loss": 0.0579,
      "step": 19301
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.1658449023962021,
      "learning_rate": 2.5e-06,
      "loss": 0.016,
      "step": 19302
    },
    {
      "epoch": 1.500077712154181,
      "grad_norm": 0.0861910730600357,
      "learning_rate": 2.4996114392290956e-06,
      "loss": 0.0176,
      "step": 19303
    },
    {
      "epoch": 1.5001554243083617,
      "grad_norm": 0.5630373358726501,
      "learning_rate": 2.499222878458191e-06,
      "loss": 0.0296,
      "step": 19304
    },
    {
      "epoch": 1.5002331364625427,
      "grad_norm": 0.9017384052276611,
      "learning_rate": 2.4988343176872863e-06,
      "loss": 0.3285,
      "step": 19305
    },
    {
      "epoch": 1.5003108486167238,
      "grad_norm": 0.2671446204185486,
      "learning_rate": 2.498445756916382e-06,
      "loss": 0.0552,
      "step": 19306
    },
    {
      "epoch": 1.5003885607709044,
      "grad_norm": 0.1629791408777237,
      "learning_rate": 2.4980571961454775e-06,
      "loss": 0.0479,
      "step": 19307
    },
    {
      "epoch": 1.5004662729250855,
      "grad_norm": 0.6169320940971375,
      "learning_rate": 2.497668635374573e-06,
      "loss": 0.6894,
      "step": 19308
    },
    {
      "epoch": 1.5005439850792666,
      "grad_norm": 0.4817342758178711,
      "learning_rate": 2.4972800746036682e-06,
      "loss": 0.3525,
      "step": 19309
    },
    {
      "epoch": 1.5006216972334472,
      "grad_norm": 0.27348965406417847,
      "learning_rate": 2.4968915138327636e-06,
      "loss": 0.0731,
      "step": 19310
    },
    {
      "epoch": 1.5006994093876282,
      "grad_norm": 0.32851943373680115,
      "learning_rate": 2.496502953061859e-06,
      "loss": 0.074,
      "step": 19311
    },
    {
      "epoch": 1.500777121541809,
      "grad_norm": 0.25539806485176086,
      "learning_rate": 2.4961143922909544e-06,
      "loss": 0.0548,
      "step": 19312
    },
    {
      "epoch": 1.50085483369599,
      "grad_norm": 0.3318485915660858,
      "learning_rate": 2.49572583152005e-06,
      "loss": 0.0989,
      "step": 19313
    },
    {
      "epoch": 1.500932545850171,
      "grad_norm": 0.2094501107931137,
      "learning_rate": 2.4953372707491455e-06,
      "loss": 0.0759,
      "step": 19314
    },
    {
      "epoch": 1.5010102580043518,
      "grad_norm": 0.8951833844184875,
      "learning_rate": 2.494948709978241e-06,
      "loss": 0.2123,
      "step": 19315
    },
    {
      "epoch": 1.5010879701585327,
      "grad_norm": 0.23928755521774292,
      "learning_rate": 2.4945601492073363e-06,
      "loss": 0.0694,
      "step": 19316
    },
    {
      "epoch": 1.5011656823127137,
      "grad_norm": 0.6664947867393494,
      "learning_rate": 2.4941715884364317e-06,
      "loss": 0.154,
      "step": 19317
    },
    {
      "epoch": 1.5012433944668946,
      "grad_norm": 0.8099335432052612,
      "learning_rate": 2.493783027665527e-06,
      "loss": 0.2702,
      "step": 19318
    },
    {
      "epoch": 1.5013211066210754,
      "grad_norm": 0.9694662690162659,
      "learning_rate": 2.4933944668946224e-06,
      "loss": 0.2382,
      "step": 19319
    },
    {
      "epoch": 1.5013988187752565,
      "grad_norm": 0.28416499495506287,
      "learning_rate": 2.493005906123718e-06,
      "loss": 0.1163,
      "step": 19320
    },
    {
      "epoch": 1.5014765309294373,
      "grad_norm": 0.7231785655021667,
      "learning_rate": 2.4926173453528136e-06,
      "loss": 0.3492,
      "step": 19321
    },
    {
      "epoch": 1.5015542430836182,
      "grad_norm": 0.37126991152763367,
      "learning_rate": 2.492228784581909e-06,
      "loss": 0.3913,
      "step": 19322
    },
    {
      "epoch": 1.5016319552377992,
      "grad_norm": 0.10363554209470749,
      "learning_rate": 2.4918402238110043e-06,
      "loss": 0.021,
      "step": 19323
    },
    {
      "epoch": 1.50170966739198,
      "grad_norm": 0.8502519726753235,
      "learning_rate": 2.4914516630400997e-06,
      "loss": 0.3581,
      "step": 19324
    },
    {
      "epoch": 1.501787379546161,
      "grad_norm": 0.271340548992157,
      "learning_rate": 2.491063102269195e-06,
      "loss": 0.0902,
      "step": 19325
    },
    {
      "epoch": 1.501865091700342,
      "grad_norm": 0.4370686113834381,
      "learning_rate": 2.4906745414982904e-06,
      "loss": 0.1459,
      "step": 19326
    },
    {
      "epoch": 1.5019428038545228,
      "grad_norm": 1.629419207572937,
      "learning_rate": 2.4902859807273862e-06,
      "loss": 0.2793,
      "step": 19327
    },
    {
      "epoch": 1.5020205160087037,
      "grad_norm": 0.3150641620159149,
      "learning_rate": 2.489897419956481e-06,
      "loss": 0.1096,
      "step": 19328
    },
    {
      "epoch": 1.5020982281628847,
      "grad_norm": 0.34868940711021423,
      "learning_rate": 2.489508859185577e-06,
      "loss": 0.1527,
      "step": 19329
    },
    {
      "epoch": 1.5021759403170656,
      "grad_norm": 1.513146996498108,
      "learning_rate": 2.4891202984146724e-06,
      "loss": 0.3728,
      "step": 19330
    },
    {
      "epoch": 1.5022536524712464,
      "grad_norm": 0.546137273311615,
      "learning_rate": 2.4887317376437677e-06,
      "loss": 0.1503,
      "step": 19331
    },
    {
      "epoch": 1.5023313646254275,
      "grad_norm": 0.3699456453323364,
      "learning_rate": 2.488343176872863e-06,
      "loss": 0.0929,
      "step": 19332
    },
    {
      "epoch": 1.5024090767796083,
      "grad_norm": 0.4342639744281769,
      "learning_rate": 2.4879546161019585e-06,
      "loss": 0.1175,
      "step": 19333
    },
    {
      "epoch": 1.5024867889337892,
      "grad_norm": 0.1495586335659027,
      "learning_rate": 2.487566055331054e-06,
      "loss": 0.0463,
      "step": 19334
    },
    {
      "epoch": 1.5025645010879702,
      "grad_norm": 1.3193440437316895,
      "learning_rate": 2.4871774945601492e-06,
      "loss": 0.3504,
      "step": 19335
    },
    {
      "epoch": 1.502642213242151,
      "grad_norm": 0.8409640789031982,
      "learning_rate": 2.4867889337892446e-06,
      "loss": 0.4147,
      "step": 19336
    },
    {
      "epoch": 1.502719925396332,
      "grad_norm": 0.7680694460868835,
      "learning_rate": 2.4864003730183404e-06,
      "loss": 0.323,
      "step": 19337
    },
    {
      "epoch": 1.502797637550513,
      "grad_norm": 0.21168702840805054,
      "learning_rate": 2.4860118122474358e-06,
      "loss": 0.0178,
      "step": 19338
    },
    {
      "epoch": 1.5028753497046938,
      "grad_norm": 0.7154895663261414,
      "learning_rate": 2.485623251476531e-06,
      "loss": 0.1233,
      "step": 19339
    },
    {
      "epoch": 1.5029530618588747,
      "grad_norm": 0.42950356006622314,
      "learning_rate": 2.4852346907056265e-06,
      "loss": 0.2724,
      "step": 19340
    },
    {
      "epoch": 1.5030307740130557,
      "grad_norm": 0.2719475328922272,
      "learning_rate": 2.484846129934722e-06,
      "loss": 0.0396,
      "step": 19341
    },
    {
      "epoch": 1.5031084861672366,
      "grad_norm": 0.2678971588611603,
      "learning_rate": 2.4844575691638173e-06,
      "loss": 0.1069,
      "step": 19342
    },
    {
      "epoch": 1.5031861983214174,
      "grad_norm": 0.962972104549408,
      "learning_rate": 2.4840690083929126e-06,
      "loss": 0.3346,
      "step": 19343
    },
    {
      "epoch": 1.5032639104755985,
      "grad_norm": 0.3501851558685303,
      "learning_rate": 2.4836804476220084e-06,
      "loss": 0.149,
      "step": 19344
    },
    {
      "epoch": 1.5033416226297793,
      "grad_norm": 0.5853323936462402,
      "learning_rate": 2.483291886851104e-06,
      "loss": 0.2239,
      "step": 19345
    },
    {
      "epoch": 1.5034193347839602,
      "grad_norm": 0.7310065627098083,
      "learning_rate": 2.482903326080199e-06,
      "loss": 0.1488,
      "step": 19346
    },
    {
      "epoch": 1.5034970469381412,
      "grad_norm": 0.29795408248901367,
      "learning_rate": 2.4825147653092945e-06,
      "loss": 0.2239,
      "step": 19347
    },
    {
      "epoch": 1.503574759092322,
      "grad_norm": 0.4567503035068512,
      "learning_rate": 2.48212620453839e-06,
      "loss": 0.0997,
      "step": 19348
    },
    {
      "epoch": 1.503652471246503,
      "grad_norm": 0.755723237991333,
      "learning_rate": 2.4817376437674853e-06,
      "loss": 0.2116,
      "step": 19349
    },
    {
      "epoch": 1.503730183400684,
      "grad_norm": 0.9568938612937927,
      "learning_rate": 2.4813490829965807e-06,
      "loss": 0.0495,
      "step": 19350
    },
    {
      "epoch": 1.5038078955548648,
      "grad_norm": 0.17681968212127686,
      "learning_rate": 2.4809605222256765e-06,
      "loss": 0.0486,
      "step": 19351
    },
    {
      "epoch": 1.5038856077090457,
      "grad_norm": 0.3970794975757599,
      "learning_rate": 2.480571961454772e-06,
      "loss": 0.2497,
      "step": 19352
    },
    {
      "epoch": 1.5039633198632267,
      "grad_norm": 0.3733244240283966,
      "learning_rate": 2.480183400683867e-06,
      "loss": 0.0438,
      "step": 19353
    },
    {
      "epoch": 1.5040410320174076,
      "grad_norm": 0.23633742332458496,
      "learning_rate": 2.4797948399129626e-06,
      "loss": 0.4175,
      "step": 19354
    },
    {
      "epoch": 1.5041187441715884,
      "grad_norm": 0.5004397630691528,
      "learning_rate": 2.479406279142058e-06,
      "loss": 0.1032,
      "step": 19355
    },
    {
      "epoch": 1.5041964563257695,
      "grad_norm": 0.42096033692359924,
      "learning_rate": 2.4790177183711533e-06,
      "loss": 0.1226,
      "step": 19356
    },
    {
      "epoch": 1.50427416847995,
      "grad_norm": 0.22114229202270508,
      "learning_rate": 2.4786291576002487e-06,
      "loss": 0.0935,
      "step": 19357
    },
    {
      "epoch": 1.5043518806341312,
      "grad_norm": 0.07885495573282242,
      "learning_rate": 2.4782405968293445e-06,
      "loss": 0.1339,
      "step": 19358
    },
    {
      "epoch": 1.5044295927883122,
      "grad_norm": 0.2631274461746216,
      "learning_rate": 2.47785203605844e-06,
      "loss": 0.156,
      "step": 19359
    },
    {
      "epoch": 1.5045073049424929,
      "grad_norm": 0.36360567808151245,
      "learning_rate": 2.4774634752875352e-06,
      "loss": 0.0972,
      "step": 19360
    },
    {
      "epoch": 1.504585017096674,
      "grad_norm": 0.28526201844215393,
      "learning_rate": 2.4770749145166306e-06,
      "loss": 0.0662,
      "step": 19361
    },
    {
      "epoch": 1.504662729250855,
      "grad_norm": 0.30252963304519653,
      "learning_rate": 2.476686353745726e-06,
      "loss": 0.0228,
      "step": 19362
    },
    {
      "epoch": 1.5047404414050356,
      "grad_norm": 0.31216561794281006,
      "learning_rate": 2.4762977929748214e-06,
      "loss": 0.061,
      "step": 19363
    },
    {
      "epoch": 1.5048181535592167,
      "grad_norm": 0.09294458478689194,
      "learning_rate": 2.4759092322039167e-06,
      "loss": 0.0456,
      "step": 19364
    },
    {
      "epoch": 1.5048958657133977,
      "grad_norm": 0.24099640548229218,
      "learning_rate": 2.4755206714330125e-06,
      "loss": 0.053,
      "step": 19365
    },
    {
      "epoch": 1.5049735778675783,
      "grad_norm": 0.6641379594802856,
      "learning_rate": 2.4751321106621075e-06,
      "loss": 0.2906,
      "step": 19366
    },
    {
      "epoch": 1.5050512900217594,
      "grad_norm": 0.42647168040275574,
      "learning_rate": 2.4747435498912033e-06,
      "loss": 0.1334,
      "step": 19367
    },
    {
      "epoch": 1.5051290021759405,
      "grad_norm": 0.17158418893814087,
      "learning_rate": 2.4743549891202987e-06,
      "loss": 0.0076,
      "step": 19368
    },
    {
      "epoch": 1.505206714330121,
      "grad_norm": 0.5761409401893616,
      "learning_rate": 2.473966428349394e-06,
      "loss": 0.2639,
      "step": 19369
    },
    {
      "epoch": 1.5052844264843022,
      "grad_norm": 0.6510958075523376,
      "learning_rate": 2.4735778675784894e-06,
      "loss": 0.1334,
      "step": 19370
    },
    {
      "epoch": 1.505362138638483,
      "grad_norm": 0.2810612618923187,
      "learning_rate": 2.4731893068075848e-06,
      "loss": 0.1216,
      "step": 19371
    },
    {
      "epoch": 1.5054398507926638,
      "grad_norm": 0.14552448689937592,
      "learning_rate": 2.4728007460366806e-06,
      "loss": 0.04,
      "step": 19372
    },
    {
      "epoch": 1.505517562946845,
      "grad_norm": 0.28036555647850037,
      "learning_rate": 2.4724121852657755e-06,
      "loss": 0.0791,
      "step": 19373
    },
    {
      "epoch": 1.5055952751010258,
      "grad_norm": 0.10846425592899323,
      "learning_rate": 2.4720236244948713e-06,
      "loss": 0.0267,
      "step": 19374
    },
    {
      "epoch": 1.5056729872552066,
      "grad_norm": 0.6878613829612732,
      "learning_rate": 2.4716350637239667e-06,
      "loss": 0.3407,
      "step": 19375
    },
    {
      "epoch": 1.5057506994093877,
      "grad_norm": 0.811998188495636,
      "learning_rate": 2.471246502953062e-06,
      "loss": 0.2744,
      "step": 19376
    },
    {
      "epoch": 1.5058284115635685,
      "grad_norm": 1.1474848985671997,
      "learning_rate": 2.4708579421821574e-06,
      "loss": 0.9903,
      "step": 19377
    },
    {
      "epoch": 1.5059061237177493,
      "grad_norm": 0.10975535959005356,
      "learning_rate": 2.470469381411253e-06,
      "loss": 0.0111,
      "step": 19378
    },
    {
      "epoch": 1.5059838358719304,
      "grad_norm": 0.5471909046173096,
      "learning_rate": 2.4700808206403486e-06,
      "loss": 0.1216,
      "step": 19379
    },
    {
      "epoch": 1.5060615480261113,
      "grad_norm": 0.20575013756752014,
      "learning_rate": 2.4696922598694436e-06,
      "loss": 0.0874,
      "step": 19380
    },
    {
      "epoch": 1.506139260180292,
      "grad_norm": 0.360629677772522,
      "learning_rate": 2.4693036990985394e-06,
      "loss": 0.3438,
      "step": 19381
    },
    {
      "epoch": 1.5062169723344732,
      "grad_norm": 0.244670569896698,
      "learning_rate": 2.4689151383276347e-06,
      "loss": 0.0406,
      "step": 19382
    },
    {
      "epoch": 1.506294684488654,
      "grad_norm": 0.5575066208839417,
      "learning_rate": 2.46852657755673e-06,
      "loss": 0.1439,
      "step": 19383
    },
    {
      "epoch": 1.5063723966428348,
      "grad_norm": 0.16016845405101776,
      "learning_rate": 2.4681380167858255e-06,
      "loss": 0.0385,
      "step": 19384
    },
    {
      "epoch": 1.506450108797016,
      "grad_norm": 0.6181371808052063,
      "learning_rate": 2.467749456014921e-06,
      "loss": 0.3741,
      "step": 19385
    },
    {
      "epoch": 1.5065278209511967,
      "grad_norm": 0.49901264905929565,
      "learning_rate": 2.4673608952440166e-06,
      "loss": 0.2483,
      "step": 19386
    },
    {
      "epoch": 1.5066055331053776,
      "grad_norm": 1.1592299938201904,
      "learning_rate": 2.4669723344731116e-06,
      "loss": 0.342,
      "step": 19387
    },
    {
      "epoch": 1.5066832452595587,
      "grad_norm": 0.6320430636405945,
      "learning_rate": 2.4665837737022074e-06,
      "loss": 0.1725,
      "step": 19388
    },
    {
      "epoch": 1.5067609574137395,
      "grad_norm": 1.3154572248458862,
      "learning_rate": 2.4661952129313028e-06,
      "loss": 0.3766,
      "step": 19389
    },
    {
      "epoch": 1.5068386695679203,
      "grad_norm": 0.4148654639720917,
      "learning_rate": 2.465806652160398e-06,
      "loss": 0.046,
      "step": 19390
    },
    {
      "epoch": 1.5069163817221014,
      "grad_norm": 0.6840657591819763,
      "learning_rate": 2.4654180913894935e-06,
      "loss": 0.1584,
      "step": 19391
    },
    {
      "epoch": 1.5069940938762822,
      "grad_norm": 0.3933471739292145,
      "learning_rate": 2.465029530618589e-06,
      "loss": 0.1024,
      "step": 19392
    },
    {
      "epoch": 1.507071806030463,
      "grad_norm": 0.8093073964118958,
      "learning_rate": 2.4646409698476847e-06,
      "loss": 0.2419,
      "step": 19393
    },
    {
      "epoch": 1.5071495181846442,
      "grad_norm": 0.44927850365638733,
      "learning_rate": 2.4642524090767796e-06,
      "loss": 0.161,
      "step": 19394
    },
    {
      "epoch": 1.507227230338825,
      "grad_norm": 0.521206259727478,
      "learning_rate": 2.4638638483058754e-06,
      "loss": 0.2356,
      "step": 19395
    },
    {
      "epoch": 1.5073049424930058,
      "grad_norm": 0.9976145625114441,
      "learning_rate": 2.463475287534971e-06,
      "loss": 0.3813,
      "step": 19396
    },
    {
      "epoch": 1.507382654647187,
      "grad_norm": 0.5017703771591187,
      "learning_rate": 2.463086726764066e-06,
      "loss": 0.2127,
      "step": 19397
    },
    {
      "epoch": 1.5074603668013677,
      "grad_norm": 0.9583123922348022,
      "learning_rate": 2.4626981659931615e-06,
      "loss": 0.4566,
      "step": 19398
    },
    {
      "epoch": 1.5075380789555486,
      "grad_norm": 0.6349803805351257,
      "learning_rate": 2.462309605222257e-06,
      "loss": 0.6503,
      "step": 19399
    },
    {
      "epoch": 1.5076157911097297,
      "grad_norm": 1.21131432056427,
      "learning_rate": 2.4619210444513523e-06,
      "loss": 0.8394,
      "step": 19400
    },
    {
      "epoch": 1.5076935032639105,
      "grad_norm": 0.44732731580734253,
      "learning_rate": 2.4615324836804477e-06,
      "loss": 0.7363,
      "step": 19401
    },
    {
      "epoch": 1.5077712154180913,
      "grad_norm": 0.6598772406578064,
      "learning_rate": 2.461143922909543e-06,
      "loss": 0.1341,
      "step": 19402
    },
    {
      "epoch": 1.5078489275722724,
      "grad_norm": 0.5867462754249573,
      "learning_rate": 2.460755362138639e-06,
      "loss": 0.3906,
      "step": 19403
    },
    {
      "epoch": 1.5079266397264532,
      "grad_norm": 0.33723488450050354,
      "learning_rate": 2.4603668013677338e-06,
      "loss": 0.0557,
      "step": 19404
    },
    {
      "epoch": 1.508004351880634,
      "grad_norm": 0.24484527111053467,
      "learning_rate": 2.4599782405968296e-06,
      "loss": 0.1401,
      "step": 19405
    },
    {
      "epoch": 1.5080820640348152,
      "grad_norm": 0.23116016387939453,
      "learning_rate": 2.459589679825925e-06,
      "loss": 0.061,
      "step": 19406
    },
    {
      "epoch": 1.508159776188996,
      "grad_norm": 0.576707124710083,
      "learning_rate": 2.4592011190550203e-06,
      "loss": 0.1982,
      "step": 19407
    },
    {
      "epoch": 1.5082374883431768,
      "grad_norm": 0.3223447799682617,
      "learning_rate": 2.4588125582841157e-06,
      "loss": 0.0799,
      "step": 19408
    },
    {
      "epoch": 1.508315200497358,
      "grad_norm": 0.9825740456581116,
      "learning_rate": 2.458423997513211e-06,
      "loss": 0.3943,
      "step": 19409
    },
    {
      "epoch": 1.5083929126515387,
      "grad_norm": 0.9718059301376343,
      "learning_rate": 2.458035436742307e-06,
      "loss": 0.5063,
      "step": 19410
    },
    {
      "epoch": 1.5084706248057196,
      "grad_norm": 0.37102004885673523,
      "learning_rate": 2.457646875971402e-06,
      "loss": 0.4033,
      "step": 19411
    },
    {
      "epoch": 1.5085483369599006,
      "grad_norm": 0.23080691695213318,
      "learning_rate": 2.4572583152004976e-06,
      "loss": 0.0284,
      "step": 19412
    },
    {
      "epoch": 1.5086260491140815,
      "grad_norm": 0.2693835198879242,
      "learning_rate": 2.456869754429593e-06,
      "loss": 0.0798,
      "step": 19413
    },
    {
      "epoch": 1.5087037612682623,
      "grad_norm": 0.6964181065559387,
      "learning_rate": 2.4564811936586884e-06,
      "loss": 0.3755,
      "step": 19414
    },
    {
      "epoch": 1.5087814734224434,
      "grad_norm": 0.6348477602005005,
      "learning_rate": 2.4560926328877837e-06,
      "loss": 0.2834,
      "step": 19415
    },
    {
      "epoch": 1.508859185576624,
      "grad_norm": 1.9625062942504883,
      "learning_rate": 2.455704072116879e-06,
      "loss": 0.1538,
      "step": 19416
    },
    {
      "epoch": 1.508936897730805,
      "grad_norm": 0.4457205533981323,
      "learning_rate": 2.455315511345975e-06,
      "loss": 0.2392,
      "step": 19417
    },
    {
      "epoch": 1.5090146098849861,
      "grad_norm": 0.3338460922241211,
      "learning_rate": 2.45492695057507e-06,
      "loss": 0.0603,
      "step": 19418
    },
    {
      "epoch": 1.5090923220391668,
      "grad_norm": 0.5934374928474426,
      "learning_rate": 2.4545383898041657e-06,
      "loss": 0.1246,
      "step": 19419
    },
    {
      "epoch": 1.5091700341933478,
      "grad_norm": 0.22927126288414001,
      "learning_rate": 2.454149829033261e-06,
      "loss": 0.0876,
      "step": 19420
    },
    {
      "epoch": 1.509247746347529,
      "grad_norm": 0.37183883786201477,
      "learning_rate": 2.4537612682623564e-06,
      "loss": 0.0998,
      "step": 19421
    },
    {
      "epoch": 1.5093254585017095,
      "grad_norm": 0.35023313760757446,
      "learning_rate": 2.4533727074914518e-06,
      "loss": 0.0455,
      "step": 19422
    },
    {
      "epoch": 1.5094031706558906,
      "grad_norm": 0.7005370259284973,
      "learning_rate": 2.452984146720547e-06,
      "loss": 0.3177,
      "step": 19423
    },
    {
      "epoch": 1.5094808828100716,
      "grad_norm": 0.08933413773775101,
      "learning_rate": 2.452595585949643e-06,
      "loss": 0.0227,
      "step": 19424
    },
    {
      "epoch": 1.5095585949642523,
      "grad_norm": 0.23161518573760986,
      "learning_rate": 2.452207025178738e-06,
      "loss": 0.0971,
      "step": 19425
    },
    {
      "epoch": 1.5096363071184333,
      "grad_norm": 0.7171271443367004,
      "learning_rate": 2.4518184644078337e-06,
      "loss": 0.1959,
      "step": 19426
    },
    {
      "epoch": 1.5097140192726144,
      "grad_norm": 0.44800499081611633,
      "learning_rate": 2.451429903636929e-06,
      "loss": 0.0862,
      "step": 19427
    },
    {
      "epoch": 1.509791731426795,
      "grad_norm": 0.4355720579624176,
      "learning_rate": 2.4510413428660244e-06,
      "loss": 0.0855,
      "step": 19428
    },
    {
      "epoch": 1.509869443580976,
      "grad_norm": 0.36515653133392334,
      "learning_rate": 2.45065278209512e-06,
      "loss": 0.1056,
      "step": 19429
    },
    {
      "epoch": 1.5099471557351571,
      "grad_norm": 0.2609846293926239,
      "learning_rate": 2.450264221324215e-06,
      "loss": 0.0894,
      "step": 19430
    },
    {
      "epoch": 1.5100248678893378,
      "grad_norm": 0.34131842851638794,
      "learning_rate": 2.449875660553311e-06,
      "loss": 0.1525,
      "step": 19431
    },
    {
      "epoch": 1.5101025800435188,
      "grad_norm": 1.1780304908752441,
      "learning_rate": 2.449487099782406e-06,
      "loss": 0.8464,
      "step": 19432
    },
    {
      "epoch": 1.5101802921976997,
      "grad_norm": 0.3573262095451355,
      "learning_rate": 2.4490985390115017e-06,
      "loss": 0.0636,
      "step": 19433
    },
    {
      "epoch": 1.5102580043518805,
      "grad_norm": 0.6626883149147034,
      "learning_rate": 2.448709978240597e-06,
      "loss": 0.2561,
      "step": 19434
    },
    {
      "epoch": 1.5103357165060616,
      "grad_norm": 0.4077156186103821,
      "learning_rate": 2.4483214174696925e-06,
      "loss": 0.2291,
      "step": 19435
    },
    {
      "epoch": 1.5104134286602424,
      "grad_norm": 0.22092141211032867,
      "learning_rate": 2.447932856698788e-06,
      "loss": 0.0226,
      "step": 19436
    },
    {
      "epoch": 1.5104911408144233,
      "grad_norm": 2.7960081100463867,
      "learning_rate": 2.4475442959278832e-06,
      "loss": 0.5766,
      "step": 19437
    },
    {
      "epoch": 1.5105688529686043,
      "grad_norm": 0.566962718963623,
      "learning_rate": 2.447155735156979e-06,
      "loss": 0.083,
      "step": 19438
    },
    {
      "epoch": 1.5106465651227852,
      "grad_norm": 1.1462782621383667,
      "learning_rate": 2.446767174386074e-06,
      "loss": 0.2367,
      "step": 19439
    },
    {
      "epoch": 1.510724277276966,
      "grad_norm": 0.9695904850959778,
      "learning_rate": 2.4463786136151698e-06,
      "loss": 0.1695,
      "step": 19440
    },
    {
      "epoch": 1.510801989431147,
      "grad_norm": 0.5927949547767639,
      "learning_rate": 2.445990052844265e-06,
      "loss": 0.0529,
      "step": 19441
    },
    {
      "epoch": 1.510879701585328,
      "grad_norm": 0.675041675567627,
      "learning_rate": 2.4456014920733605e-06,
      "loss": 0.7494,
      "step": 19442
    },
    {
      "epoch": 1.5109574137395088,
      "grad_norm": 0.9395257234573364,
      "learning_rate": 2.445212931302456e-06,
      "loss": 0.8385,
      "step": 19443
    },
    {
      "epoch": 1.5110351258936898,
      "grad_norm": 0.5499054789543152,
      "learning_rate": 2.4448243705315513e-06,
      "loss": 0.3809,
      "step": 19444
    },
    {
      "epoch": 1.5111128380478707,
      "grad_norm": 0.48612555861473083,
      "learning_rate": 2.444435809760647e-06,
      "loss": 0.3138,
      "step": 19445
    },
    {
      "epoch": 1.5111905502020515,
      "grad_norm": 1.10993230342865,
      "learning_rate": 2.444047248989742e-06,
      "loss": 0.5182,
      "step": 19446
    },
    {
      "epoch": 1.5112682623562326,
      "grad_norm": 0.0766843631863594,
      "learning_rate": 2.443658688218838e-06,
      "loss": 0.0083,
      "step": 19447
    },
    {
      "epoch": 1.5113459745104134,
      "grad_norm": 0.6706644892692566,
      "learning_rate": 2.443270127447933e-06,
      "loss": 0.6403,
      "step": 19448
    },
    {
      "epoch": 1.5114236866645943,
      "grad_norm": 0.3293423354625702,
      "learning_rate": 2.4428815666770285e-06,
      "loss": 0.1311,
      "step": 19449
    },
    {
      "epoch": 1.5115013988187753,
      "grad_norm": 0.36155039072036743,
      "learning_rate": 2.442493005906124e-06,
      "loss": 0.318,
      "step": 19450
    },
    {
      "epoch": 1.5115791109729562,
      "grad_norm": 0.33689969778060913,
      "learning_rate": 2.4421044451352193e-06,
      "loss": 0.157,
      "step": 19451
    },
    {
      "epoch": 1.511656823127137,
      "grad_norm": 0.3197142779827118,
      "learning_rate": 2.441715884364315e-06,
      "loss": 0.1276,
      "step": 19452
    },
    {
      "epoch": 1.511734535281318,
      "grad_norm": 0.4753773510456085,
      "learning_rate": 2.44132732359341e-06,
      "loss": 0.1309,
      "step": 19453
    },
    {
      "epoch": 1.511812247435499,
      "grad_norm": 0.32707980275154114,
      "learning_rate": 2.440938762822506e-06,
      "loss": 0.1137,
      "step": 19454
    },
    {
      "epoch": 1.5118899595896798,
      "grad_norm": 0.23223796486854553,
      "learning_rate": 2.4405502020516012e-06,
      "loss": 0.0259,
      "step": 19455
    },
    {
      "epoch": 1.5119676717438608,
      "grad_norm": 0.7753445506095886,
      "learning_rate": 2.4401616412806966e-06,
      "loss": 0.4063,
      "step": 19456
    },
    {
      "epoch": 1.5120453838980417,
      "grad_norm": 0.5197187662124634,
      "learning_rate": 2.439773080509792e-06,
      "loss": 0.1084,
      "step": 19457
    },
    {
      "epoch": 1.5121230960522225,
      "grad_norm": 1.2479358911514282,
      "learning_rate": 2.4393845197388873e-06,
      "loss": 0.1728,
      "step": 19458
    },
    {
      "epoch": 1.5122008082064036,
      "grad_norm": 0.7654941082000732,
      "learning_rate": 2.4389959589679827e-06,
      "loss": 0.1111,
      "step": 19459
    },
    {
      "epoch": 1.5122785203605844,
      "grad_norm": 0.41303086280822754,
      "learning_rate": 2.438607398197078e-06,
      "loss": 0.1348,
      "step": 19460
    },
    {
      "epoch": 1.5123562325147653,
      "grad_norm": 0.1332557499408722,
      "learning_rate": 2.4382188374261735e-06,
      "loss": 0.0405,
      "step": 19461
    },
    {
      "epoch": 1.5124339446689463,
      "grad_norm": 0.23766976594924927,
      "learning_rate": 2.4378302766552692e-06,
      "loss": 0.0434,
      "step": 19462
    },
    {
      "epoch": 1.5125116568231272,
      "grad_norm": 0.520573079586029,
      "learning_rate": 2.437441715884364e-06,
      "loss": 0.0822,
      "step": 19463
    },
    {
      "epoch": 1.512589368977308,
      "grad_norm": 0.2914945185184479,
      "learning_rate": 2.43705315511346e-06,
      "loss": 0.0412,
      "step": 19464
    },
    {
      "epoch": 1.512667081131489,
      "grad_norm": 1.075170874595642,
      "learning_rate": 2.4366645943425554e-06,
      "loss": 0.3964,
      "step": 19465
    },
    {
      "epoch": 1.51274479328567,
      "grad_norm": 0.44362232089042664,
      "learning_rate": 2.4362760335716507e-06,
      "loss": 0.2402,
      "step": 19466
    },
    {
      "epoch": 1.5128225054398508,
      "grad_norm": 0.6790436506271362,
      "learning_rate": 2.435887472800746e-06,
      "loss": 0.2677,
      "step": 19467
    },
    {
      "epoch": 1.5129002175940318,
      "grad_norm": 0.8702875971794128,
      "learning_rate": 2.4354989120298415e-06,
      "loss": 0.2497,
      "step": 19468
    },
    {
      "epoch": 1.5129779297482127,
      "grad_norm": 0.34512367844581604,
      "learning_rate": 2.4351103512589373e-06,
      "loss": 0.205,
      "step": 19469
    },
    {
      "epoch": 1.5130556419023935,
      "grad_norm": 0.12351763248443604,
      "learning_rate": 2.4347217904880322e-06,
      "loss": 0.0178,
      "step": 19470
    },
    {
      "epoch": 1.5131333540565746,
      "grad_norm": 0.1753484457731247,
      "learning_rate": 2.434333229717128e-06,
      "loss": 0.0237,
      "step": 19471
    },
    {
      "epoch": 1.5132110662107554,
      "grad_norm": 1.348487138748169,
      "learning_rate": 2.4339446689462234e-06,
      "loss": 0.2452,
      "step": 19472
    },
    {
      "epoch": 1.5132887783649362,
      "grad_norm": 0.7697131633758545,
      "learning_rate": 2.4335561081753188e-06,
      "loss": 0.3428,
      "step": 19473
    },
    {
      "epoch": 1.5133664905191173,
      "grad_norm": 0.210658460855484,
      "learning_rate": 2.433167547404414e-06,
      "loss": 0.0504,
      "step": 19474
    },
    {
      "epoch": 1.5134442026732982,
      "grad_norm": 0.906273603439331,
      "learning_rate": 2.4327789866335095e-06,
      "loss": 0.342,
      "step": 19475
    },
    {
      "epoch": 1.513521914827479,
      "grad_norm": 0.2524639368057251,
      "learning_rate": 2.4323904258626053e-06,
      "loss": 0.0706,
      "step": 19476
    },
    {
      "epoch": 1.51359962698166,
      "grad_norm": 0.20823608338832855,
      "learning_rate": 2.4320018650917003e-06,
      "loss": 0.0197,
      "step": 19477
    },
    {
      "epoch": 1.5136773391358407,
      "grad_norm": 0.3233517110347748,
      "learning_rate": 2.431613304320796e-06,
      "loss": 0.1935,
      "step": 19478
    },
    {
      "epoch": 1.5137550512900217,
      "grad_norm": 0.7043930292129517,
      "learning_rate": 2.4312247435498914e-06,
      "loss": 0.3221,
      "step": 19479
    },
    {
      "epoch": 1.5138327634442028,
      "grad_norm": 0.7429845333099365,
      "learning_rate": 2.430836182778987e-06,
      "loss": 0.4583,
      "step": 19480
    },
    {
      "epoch": 1.5139104755983834,
      "grad_norm": 0.6536173224449158,
      "learning_rate": 2.430447622008082e-06,
      "loss": 0.437,
      "step": 19481
    },
    {
      "epoch": 1.5139881877525645,
      "grad_norm": 0.5003596544265747,
      "learning_rate": 2.4300590612371776e-06,
      "loss": 0.1562,
      "step": 19482
    },
    {
      "epoch": 1.5140658999067456,
      "grad_norm": 0.4392845332622528,
      "learning_rate": 2.4296705004662734e-06,
      "loss": 0.1399,
      "step": 19483
    },
    {
      "epoch": 1.5141436120609262,
      "grad_norm": 0.7676462531089783,
      "learning_rate": 2.4292819396953683e-06,
      "loss": 0.5711,
      "step": 19484
    },
    {
      "epoch": 1.5142213242151072,
      "grad_norm": 0.2554173469543457,
      "learning_rate": 2.428893378924464e-06,
      "loss": 0.0234,
      "step": 19485
    },
    {
      "epoch": 1.5142990363692883,
      "grad_norm": 0.4415035545825958,
      "learning_rate": 2.4285048181535595e-06,
      "loss": 0.1639,
      "step": 19486
    },
    {
      "epoch": 1.514376748523469,
      "grad_norm": 0.3386669456958771,
      "learning_rate": 2.428116257382655e-06,
      "loss": 0.0593,
      "step": 19487
    },
    {
      "epoch": 1.51445446067765,
      "grad_norm": 0.4140137732028961,
      "learning_rate": 2.4277276966117502e-06,
      "loss": 0.2312,
      "step": 19488
    },
    {
      "epoch": 1.514532172831831,
      "grad_norm": 0.16527606546878815,
      "learning_rate": 2.4273391358408456e-06,
      "loss": 0.0194,
      "step": 19489
    },
    {
      "epoch": 1.5146098849860117,
      "grad_norm": 0.4005035161972046,
      "learning_rate": 2.4269505750699414e-06,
      "loss": 0.2423,
      "step": 19490
    },
    {
      "epoch": 1.5146875971401927,
      "grad_norm": 0.15992717444896698,
      "learning_rate": 2.4265620142990363e-06,
      "loss": 0.0314,
      "step": 19491
    },
    {
      "epoch": 1.5147653092943736,
      "grad_norm": 0.7733818292617798,
      "learning_rate": 2.426173453528132e-06,
      "loss": 0.3802,
      "step": 19492
    },
    {
      "epoch": 1.5148430214485544,
      "grad_norm": 0.6092764139175415,
      "learning_rate": 2.4257848927572275e-06,
      "loss": 0.3799,
      "step": 19493
    },
    {
      "epoch": 1.5149207336027355,
      "grad_norm": 0.5903357863426208,
      "learning_rate": 2.425396331986323e-06,
      "loss": 0.0987,
      "step": 19494
    },
    {
      "epoch": 1.5149984457569163,
      "grad_norm": 1.2539973258972168,
      "learning_rate": 2.4250077712154183e-06,
      "loss": 0.3981,
      "step": 19495
    },
    {
      "epoch": 1.5150761579110972,
      "grad_norm": 0.24458323419094086,
      "learning_rate": 2.4246192104445136e-06,
      "loss": 0.0626,
      "step": 19496
    },
    {
      "epoch": 1.5151538700652782,
      "grad_norm": 0.27356573939323425,
      "learning_rate": 2.4242306496736094e-06,
      "loss": 0.1169,
      "step": 19497
    },
    {
      "epoch": 1.515231582219459,
      "grad_norm": 0.06482583284378052,
      "learning_rate": 2.4238420889027044e-06,
      "loss": 0.008,
      "step": 19498
    },
    {
      "epoch": 1.51530929437364,
      "grad_norm": 0.15984176099300385,
      "learning_rate": 2.4234535281318e-06,
      "loss": 0.0178,
      "step": 19499
    },
    {
      "epoch": 1.515387006527821,
      "grad_norm": 0.7003746032714844,
      "learning_rate": 2.4230649673608956e-06,
      "loss": 0.2543,
      "step": 19500
    },
    {
      "epoch": 1.5154647186820018,
      "grad_norm": 0.25772833824157715,
      "learning_rate": 2.422676406589991e-06,
      "loss": 0.0674,
      "step": 19501
    },
    {
      "epoch": 1.5155424308361827,
      "grad_norm": 0.41952773928642273,
      "learning_rate": 2.4222878458190863e-06,
      "loss": 0.0846,
      "step": 19502
    },
    {
      "epoch": 1.5156201429903637,
      "grad_norm": 0.39257365465164185,
      "learning_rate": 2.4218992850481817e-06,
      "loss": 0.1675,
      "step": 19503
    },
    {
      "epoch": 1.5156978551445446,
      "grad_norm": 0.4186997711658478,
      "learning_rate": 2.4215107242772775e-06,
      "loss": 0.2426,
      "step": 19504
    },
    {
      "epoch": 1.5157755672987254,
      "grad_norm": 0.4548254609107971,
      "learning_rate": 2.4211221635063724e-06,
      "loss": 0.14,
      "step": 19505
    },
    {
      "epoch": 1.5158532794529065,
      "grad_norm": 0.40013444423675537,
      "learning_rate": 2.4207336027354682e-06,
      "loss": 0.1399,
      "step": 19506
    },
    {
      "epoch": 1.5159309916070873,
      "grad_norm": 0.11070459336042404,
      "learning_rate": 2.4203450419645636e-06,
      "loss": 0.0152,
      "step": 19507
    },
    {
      "epoch": 1.5160087037612682,
      "grad_norm": 0.30038151144981384,
      "learning_rate": 2.419956481193659e-06,
      "loss": 0.0656,
      "step": 19508
    },
    {
      "epoch": 1.5160864159154492,
      "grad_norm": 0.19883258640766144,
      "learning_rate": 2.4195679204227543e-06,
      "loss": 0.0209,
      "step": 19509
    },
    {
      "epoch": 1.51616412806963,
      "grad_norm": 1.00308096408844,
      "learning_rate": 2.4191793596518497e-06,
      "loss": 0.4046,
      "step": 19510
    },
    {
      "epoch": 1.516241840223811,
      "grad_norm": 0.47797632217407227,
      "learning_rate": 2.4187907988809455e-06,
      "loss": 0.0878,
      "step": 19511
    },
    {
      "epoch": 1.516319552377992,
      "grad_norm": 0.4597815275192261,
      "learning_rate": 2.4184022381100405e-06,
      "loss": 0.1023,
      "step": 19512
    },
    {
      "epoch": 1.5163972645321728,
      "grad_norm": 0.4116937816143036,
      "learning_rate": 2.4180136773391363e-06,
      "loss": 0.3695,
      "step": 19513
    },
    {
      "epoch": 1.5164749766863537,
      "grad_norm": 0.2904305160045624,
      "learning_rate": 2.4176251165682316e-06,
      "loss": 0.0679,
      "step": 19514
    },
    {
      "epoch": 1.5165526888405347,
      "grad_norm": 0.6882792115211487,
      "learning_rate": 2.417236555797327e-06,
      "loss": 0.7266,
      "step": 19515
    },
    {
      "epoch": 1.5166304009947156,
      "grad_norm": 0.3871074318885803,
      "learning_rate": 2.4168479950264224e-06,
      "loss": 0.0904,
      "step": 19516
    },
    {
      "epoch": 1.5167081131488964,
      "grad_norm": 0.9584846496582031,
      "learning_rate": 2.4164594342555177e-06,
      "loss": 0.2108,
      "step": 19517
    },
    {
      "epoch": 1.5167858253030775,
      "grad_norm": 0.608244776725769,
      "learning_rate": 2.416070873484613e-06,
      "loss": 0.4899,
      "step": 19518
    },
    {
      "epoch": 1.5168635374572583,
      "grad_norm": 0.11881644278764725,
      "learning_rate": 2.4156823127137085e-06,
      "loss": 0.0654,
      "step": 19519
    },
    {
      "epoch": 1.5169412496114392,
      "grad_norm": 0.9107065200805664,
      "learning_rate": 2.4152937519428043e-06,
      "loss": 0.3024,
      "step": 19520
    },
    {
      "epoch": 1.5170189617656202,
      "grad_norm": 0.49368178844451904,
      "learning_rate": 2.4149051911718997e-06,
      "loss": 0.0654,
      "step": 19521
    },
    {
      "epoch": 1.517096673919801,
      "grad_norm": 1.1695177555084229,
      "learning_rate": 2.4145166304009946e-06,
      "loss": 0.2929,
      "step": 19522
    },
    {
      "epoch": 1.517174386073982,
      "grad_norm": 0.17031054198741913,
      "learning_rate": 2.4141280696300904e-06,
      "loss": 0.0172,
      "step": 19523
    },
    {
      "epoch": 1.517252098228163,
      "grad_norm": 0.4418525695800781,
      "learning_rate": 2.4137395088591858e-06,
      "loss": 0.1361,
      "step": 19524
    },
    {
      "epoch": 1.5173298103823438,
      "grad_norm": 0.4422362446784973,
      "learning_rate": 2.413350948088281e-06,
      "loss": 0.4866,
      "step": 19525
    },
    {
      "epoch": 1.5174075225365247,
      "grad_norm": 0.7890295386314392,
      "learning_rate": 2.4129623873173765e-06,
      "loss": 0.3301,
      "step": 19526
    },
    {
      "epoch": 1.5174852346907057,
      "grad_norm": 0.3275277614593506,
      "learning_rate": 2.412573826546472e-06,
      "loss": 0.0352,
      "step": 19527
    },
    {
      "epoch": 1.5175629468448866,
      "grad_norm": 0.20958060026168823,
      "learning_rate": 2.4121852657755677e-06,
      "loss": 0.1196,
      "step": 19528
    },
    {
      "epoch": 1.5176406589990674,
      "grad_norm": 0.5553884506225586,
      "learning_rate": 2.4117967050046626e-06,
      "loss": 0.1195,
      "step": 19529
    },
    {
      "epoch": 1.5177183711532485,
      "grad_norm": 0.42364344000816345,
      "learning_rate": 2.4114081442337584e-06,
      "loss": 0.1625,
      "step": 19530
    },
    {
      "epoch": 1.5177960833074293,
      "grad_norm": 0.5086524486541748,
      "learning_rate": 2.411019583462854e-06,
      "loss": 0.1478,
      "step": 19531
    },
    {
      "epoch": 1.5178737954616102,
      "grad_norm": 0.5977526307106018,
      "learning_rate": 2.410631022691949e-06,
      "loss": 0.316,
      "step": 19532
    },
    {
      "epoch": 1.5179515076157912,
      "grad_norm": 1.5069012641906738,
      "learning_rate": 2.4102424619210446e-06,
      "loss": 2.4569,
      "step": 19533
    },
    {
      "epoch": 1.518029219769972,
      "grad_norm": 0.6707335710525513,
      "learning_rate": 2.40985390115014e-06,
      "loss": 0.1766,
      "step": 19534
    },
    {
      "epoch": 1.518106931924153,
      "grad_norm": 0.4740940034389496,
      "learning_rate": 2.4094653403792357e-06,
      "loss": 0.1251,
      "step": 19535
    },
    {
      "epoch": 1.518184644078334,
      "grad_norm": 0.5531156063079834,
      "learning_rate": 2.4090767796083307e-06,
      "loss": 0.585,
      "step": 19536
    },
    {
      "epoch": 1.5182623562325148,
      "grad_norm": 0.3669154644012451,
      "learning_rate": 2.4086882188374265e-06,
      "loss": 0.0501,
      "step": 19537
    },
    {
      "epoch": 1.5183400683866957,
      "grad_norm": 0.24626408517360687,
      "learning_rate": 2.408299658066522e-06,
      "loss": 0.1905,
      "step": 19538
    },
    {
      "epoch": 1.5184177805408767,
      "grad_norm": 0.536248505115509,
      "learning_rate": 2.4079110972956172e-06,
      "loss": 0.1651,
      "step": 19539
    },
    {
      "epoch": 1.5184954926950573,
      "grad_norm": 0.820824146270752,
      "learning_rate": 2.4075225365247126e-06,
      "loss": 0.2833,
      "step": 19540
    },
    {
      "epoch": 1.5185732048492384,
      "grad_norm": 0.5167214274406433,
      "learning_rate": 2.407133975753808e-06,
      "loss": 0.2452,
      "step": 19541
    },
    {
      "epoch": 1.5186509170034195,
      "grad_norm": 0.9252161383628845,
      "learning_rate": 2.4067454149829038e-06,
      "loss": 0.2752,
      "step": 19542
    },
    {
      "epoch": 1.5187286291576,
      "grad_norm": 0.38410627841949463,
      "learning_rate": 2.4063568542119987e-06,
      "loss": 0.106,
      "step": 19543
    },
    {
      "epoch": 1.5188063413117812,
      "grad_norm": 0.615746796131134,
      "learning_rate": 2.4059682934410945e-06,
      "loss": 0.1929,
      "step": 19544
    },
    {
      "epoch": 1.5188840534659622,
      "grad_norm": 0.7800959348678589,
      "learning_rate": 2.40557973267019e-06,
      "loss": 0.2329,
      "step": 19545
    },
    {
      "epoch": 1.5189617656201428,
      "grad_norm": 0.2879193127155304,
      "learning_rate": 2.4051911718992853e-06,
      "loss": 0.0982,
      "step": 19546
    },
    {
      "epoch": 1.519039477774324,
      "grad_norm": 0.6541634202003479,
      "learning_rate": 2.4048026111283806e-06,
      "loss": 0.4182,
      "step": 19547
    },
    {
      "epoch": 1.519117189928505,
      "grad_norm": 0.23202474415302277,
      "learning_rate": 2.404414050357476e-06,
      "loss": 0.0875,
      "step": 19548
    },
    {
      "epoch": 1.5191949020826856,
      "grad_norm": 2.3391237258911133,
      "learning_rate": 2.404025489586572e-06,
      "loss": 0.3437,
      "step": 19549
    },
    {
      "epoch": 1.5192726142368667,
      "grad_norm": 0.6797552704811096,
      "learning_rate": 2.4036369288156668e-06,
      "loss": 0.7089,
      "step": 19550
    },
    {
      "epoch": 1.5193503263910477,
      "grad_norm": 0.47817307710647583,
      "learning_rate": 2.4032483680447626e-06,
      "loss": 0.3319,
      "step": 19551
    },
    {
      "epoch": 1.5194280385452283,
      "grad_norm": 0.5734532475471497,
      "learning_rate": 2.402859807273858e-06,
      "loss": 0.0661,
      "step": 19552
    },
    {
      "epoch": 1.5195057506994094,
      "grad_norm": 0.6667922735214233,
      "learning_rate": 2.4024712465029533e-06,
      "loss": 0.1355,
      "step": 19553
    },
    {
      "epoch": 1.5195834628535902,
      "grad_norm": 0.5084778070449829,
      "learning_rate": 2.4020826857320487e-06,
      "loss": 0.268,
      "step": 19554
    },
    {
      "epoch": 1.519661175007771,
      "grad_norm": 0.4317638576030731,
      "learning_rate": 2.401694124961144e-06,
      "loss": 0.158,
      "step": 19555
    },
    {
      "epoch": 1.5197388871619522,
      "grad_norm": 0.3457833230495453,
      "learning_rate": 2.4013055641902394e-06,
      "loss": 0.1946,
      "step": 19556
    },
    {
      "epoch": 1.519816599316133,
      "grad_norm": 0.2451796531677246,
      "learning_rate": 2.400917003419335e-06,
      "loss": 0.0647,
      "step": 19557
    },
    {
      "epoch": 1.5198943114703138,
      "grad_norm": 0.30028095841407776,
      "learning_rate": 2.4005284426484306e-06,
      "loss": 0.0754,
      "step": 19558
    },
    {
      "epoch": 1.519972023624495,
      "grad_norm": 0.6163983941078186,
      "learning_rate": 2.400139881877526e-06,
      "loss": 0.1809,
      "step": 19559
    },
    {
      "epoch": 1.5200497357786757,
      "grad_norm": 0.166102334856987,
      "learning_rate": 2.3997513211066213e-06,
      "loss": 0.0262,
      "step": 19560
    },
    {
      "epoch": 1.5201274479328566,
      "grad_norm": 0.25551658868789673,
      "learning_rate": 2.3993627603357167e-06,
      "loss": 0.1428,
      "step": 19561
    },
    {
      "epoch": 1.5202051600870377,
      "grad_norm": 0.07247188687324524,
      "learning_rate": 2.398974199564812e-06,
      "loss": 0.0112,
      "step": 19562
    },
    {
      "epoch": 1.5202828722412185,
      "grad_norm": 0.4484157860279083,
      "learning_rate": 2.3985856387939075e-06,
      "loss": 0.2265,
      "step": 19563
    },
    {
      "epoch": 1.5203605843953993,
      "grad_norm": 0.1414247453212738,
      "learning_rate": 2.398197078023003e-06,
      "loss": 0.015,
      "step": 19564
    },
    {
      "epoch": 1.5204382965495804,
      "grad_norm": 0.17615807056427002,
      "learning_rate": 2.3978085172520986e-06,
      "loss": 0.0362,
      "step": 19565
    },
    {
      "epoch": 1.5205160087037612,
      "grad_norm": 0.406357079744339,
      "learning_rate": 2.397419956481194e-06,
      "loss": 0.2958,
      "step": 19566
    },
    {
      "epoch": 1.520593720857942,
      "grad_norm": 0.11279526352882385,
      "learning_rate": 2.3970313957102894e-06,
      "loss": 0.0163,
      "step": 19567
    },
    {
      "epoch": 1.5206714330121232,
      "grad_norm": 0.32311874628067017,
      "learning_rate": 2.3966428349393847e-06,
      "loss": 0.1202,
      "step": 19568
    },
    {
      "epoch": 1.520749145166304,
      "grad_norm": 0.2464790940284729,
      "learning_rate": 2.39625427416848e-06,
      "loss": 0.1056,
      "step": 19569
    },
    {
      "epoch": 1.5208268573204848,
      "grad_norm": 0.48210614919662476,
      "learning_rate": 2.3958657133975755e-06,
      "loss": 0.126,
      "step": 19570
    },
    {
      "epoch": 1.520904569474666,
      "grad_norm": 0.3032662868499756,
      "learning_rate": 2.395477152626671e-06,
      "loss": 0.0839,
      "step": 19571
    },
    {
      "epoch": 1.5209822816288467,
      "grad_norm": 0.36369118094444275,
      "learning_rate": 2.3950885918557667e-06,
      "loss": 0.0364,
      "step": 19572
    },
    {
      "epoch": 1.5210599937830276,
      "grad_norm": 0.3468281328678131,
      "learning_rate": 2.394700031084862e-06,
      "loss": 0.0827,
      "step": 19573
    },
    {
      "epoch": 1.5211377059372087,
      "grad_norm": 0.14013175666332245,
      "learning_rate": 2.3943114703139574e-06,
      "loss": 0.0516,
      "step": 19574
    },
    {
      "epoch": 1.5212154180913895,
      "grad_norm": 0.5195751786231995,
      "learning_rate": 2.3939229095430528e-06,
      "loss": 0.1393,
      "step": 19575
    },
    {
      "epoch": 1.5212931302455703,
      "grad_norm": 0.4919317364692688,
      "learning_rate": 2.393534348772148e-06,
      "loss": 0.1713,
      "step": 19576
    },
    {
      "epoch": 1.5213708423997514,
      "grad_norm": 0.9743139147758484,
      "learning_rate": 2.3931457880012435e-06,
      "loss": 0.0749,
      "step": 19577
    },
    {
      "epoch": 1.5214485545539322,
      "grad_norm": 0.5316953063011169,
      "learning_rate": 2.392757227230339e-06,
      "loss": 0.3745,
      "step": 19578
    },
    {
      "epoch": 1.521526266708113,
      "grad_norm": 0.5676146745681763,
      "learning_rate": 2.3923686664594347e-06,
      "loss": 0.1906,
      "step": 19579
    },
    {
      "epoch": 1.5216039788622941,
      "grad_norm": 0.6437011361122131,
      "learning_rate": 2.39198010568853e-06,
      "loss": 0.2304,
      "step": 19580
    },
    {
      "epoch": 1.521681691016475,
      "grad_norm": 0.1857984960079193,
      "learning_rate": 2.3915915449176254e-06,
      "loss": 0.0138,
      "step": 19581
    },
    {
      "epoch": 1.5217594031706558,
      "grad_norm": 0.19771845638751984,
      "learning_rate": 2.391202984146721e-06,
      "loss": 0.0467,
      "step": 19582
    },
    {
      "epoch": 1.521837115324837,
      "grad_norm": 0.9185181856155396,
      "learning_rate": 2.390814423375816e-06,
      "loss": 0.399,
      "step": 19583
    },
    {
      "epoch": 1.5219148274790177,
      "grad_norm": 0.4209367632865906,
      "learning_rate": 2.3904258626049116e-06,
      "loss": 0.0974,
      "step": 19584
    },
    {
      "epoch": 1.5219925396331986,
      "grad_norm": 0.21232011914253235,
      "learning_rate": 2.390037301834007e-06,
      "loss": 0.12,
      "step": 19585
    },
    {
      "epoch": 1.5220702517873796,
      "grad_norm": 0.3648766279220581,
      "learning_rate": 2.3896487410631023e-06,
      "loss": 0.0646,
      "step": 19586
    },
    {
      "epoch": 1.5221479639415605,
      "grad_norm": 0.21351316571235657,
      "learning_rate": 2.389260180292198e-06,
      "loss": 0.1313,
      "step": 19587
    },
    {
      "epoch": 1.5222256760957413,
      "grad_norm": 0.13137862086296082,
      "learning_rate": 2.388871619521293e-06,
      "loss": 0.0089,
      "step": 19588
    },
    {
      "epoch": 1.5223033882499224,
      "grad_norm": 0.8578115701675415,
      "learning_rate": 2.388483058750389e-06,
      "loss": 0.2968,
      "step": 19589
    },
    {
      "epoch": 1.5223811004041032,
      "grad_norm": 0.5600213408470154,
      "learning_rate": 2.3880944979794842e-06,
      "loss": 0.4023,
      "step": 19590
    },
    {
      "epoch": 1.522458812558284,
      "grad_norm": 0.5297733545303345,
      "learning_rate": 2.3877059372085796e-06,
      "loss": 0.1389,
      "step": 19591
    },
    {
      "epoch": 1.5225365247124651,
      "grad_norm": 0.4609866738319397,
      "learning_rate": 2.387317376437675e-06,
      "loss": 0.1263,
      "step": 19592
    },
    {
      "epoch": 1.522614236866646,
      "grad_norm": 1.1178247928619385,
      "learning_rate": 2.3869288156667703e-06,
      "loss": 0.2857,
      "step": 19593
    },
    {
      "epoch": 1.5226919490208268,
      "grad_norm": 0.4291822612285614,
      "learning_rate": 2.3865402548958657e-06,
      "loss": 0.1435,
      "step": 19594
    },
    {
      "epoch": 1.522769661175008,
      "grad_norm": 0.1908084750175476,
      "learning_rate": 2.386151694124961e-06,
      "loss": 0.0447,
      "step": 19595
    },
    {
      "epoch": 1.5228473733291887,
      "grad_norm": 0.6104937195777893,
      "learning_rate": 2.385763133354057e-06,
      "loss": 0.1705,
      "step": 19596
    },
    {
      "epoch": 1.5229250854833696,
      "grad_norm": 0.45510348677635193,
      "learning_rate": 2.3853745725831523e-06,
      "loss": 0.2312,
      "step": 19597
    },
    {
      "epoch": 1.5230027976375506,
      "grad_norm": 1.0901466608047485,
      "learning_rate": 2.3849860118122476e-06,
      "loss": 0.3658,
      "step": 19598
    },
    {
      "epoch": 1.5230805097917313,
      "grad_norm": 0.18272265791893005,
      "learning_rate": 2.384597451041343e-06,
      "loss": 0.0532,
      "step": 19599
    },
    {
      "epoch": 1.5231582219459123,
      "grad_norm": 0.8130441308021545,
      "learning_rate": 2.3842088902704384e-06,
      "loss": 0.1667,
      "step": 19600
    },
    {
      "epoch": 1.5232359341000934,
      "grad_norm": 0.4241456687450409,
      "learning_rate": 2.3838203294995338e-06,
      "loss": 0.0485,
      "step": 19601
    },
    {
      "epoch": 1.523313646254274,
      "grad_norm": 0.6175270080566406,
      "learning_rate": 2.383431768728629e-06,
      "loss": 0.4699,
      "step": 19602
    },
    {
      "epoch": 1.523391358408455,
      "grad_norm": 0.16779203712940216,
      "learning_rate": 2.383043207957725e-06,
      "loss": 0.0964,
      "step": 19603
    },
    {
      "epoch": 1.5234690705626361,
      "grad_norm": 0.8803285956382751,
      "learning_rate": 2.3826546471868203e-06,
      "loss": 0.7616,
      "step": 19604
    },
    {
      "epoch": 1.5235467827168168,
      "grad_norm": 0.3243336081504822,
      "learning_rate": 2.3822660864159157e-06,
      "loss": 0.143,
      "step": 19605
    },
    {
      "epoch": 1.5236244948709978,
      "grad_norm": 0.12643131613731384,
      "learning_rate": 2.381877525645011e-06,
      "loss": 0.0475,
      "step": 19606
    },
    {
      "epoch": 1.523702207025179,
      "grad_norm": 1.121951699256897,
      "learning_rate": 2.3814889648741064e-06,
      "loss": 0.0758,
      "step": 19607
    },
    {
      "epoch": 1.5237799191793595,
      "grad_norm": 0.5865764021873474,
      "learning_rate": 2.381100404103202e-06,
      "loss": 0.4142,
      "step": 19608
    },
    {
      "epoch": 1.5238576313335406,
      "grad_norm": 0.6374124884605408,
      "learning_rate": 2.380711843332297e-06,
      "loss": 0.1182,
      "step": 19609
    },
    {
      "epoch": 1.5239353434877216,
      "grad_norm": 1.8932504653930664,
      "learning_rate": 2.380323282561393e-06,
      "loss": 0.5788,
      "step": 19610
    },
    {
      "epoch": 1.5240130556419023,
      "grad_norm": 0.11938650161027908,
      "learning_rate": 2.3799347217904883e-06,
      "loss": 0.0363,
      "step": 19611
    },
    {
      "epoch": 1.5240907677960833,
      "grad_norm": 1.301007866859436,
      "learning_rate": 2.3795461610195837e-06,
      "loss": 0.3342,
      "step": 19612
    },
    {
      "epoch": 1.5241684799502644,
      "grad_norm": 0.38904061913490295,
      "learning_rate": 2.379157600248679e-06,
      "loss": 0.1438,
      "step": 19613
    },
    {
      "epoch": 1.524246192104445,
      "grad_norm": 0.5333186388015747,
      "learning_rate": 2.3787690394777745e-06,
      "loss": 0.2506,
      "step": 19614
    },
    {
      "epoch": 1.524323904258626,
      "grad_norm": 0.572501540184021,
      "learning_rate": 2.37838047870687e-06,
      "loss": 0.2459,
      "step": 19615
    },
    {
      "epoch": 1.524401616412807,
      "grad_norm": 0.3638336658477783,
      "learning_rate": 2.377991917935965e-06,
      "loss": 0.2222,
      "step": 19616
    },
    {
      "epoch": 1.5244793285669878,
      "grad_norm": 0.3888658583164215,
      "learning_rate": 2.377603357165061e-06,
      "loss": 0.1089,
      "step": 19617
    },
    {
      "epoch": 1.5245570407211688,
      "grad_norm": 0.9305881261825562,
      "learning_rate": 2.3772147963941564e-06,
      "loss": 1.0642,
      "step": 19618
    },
    {
      "epoch": 1.5246347528753497,
      "grad_norm": 0.4172883927822113,
      "learning_rate": 2.3768262356232517e-06,
      "loss": 0.3004,
      "step": 19619
    },
    {
      "epoch": 1.5247124650295305,
      "grad_norm": 0.5580959320068359,
      "learning_rate": 2.376437674852347e-06,
      "loss": 0.383,
      "step": 19620
    },
    {
      "epoch": 1.5247901771837116,
      "grad_norm": 1.1131552457809448,
      "learning_rate": 2.3760491140814425e-06,
      "loss": 0.6118,
      "step": 19621
    },
    {
      "epoch": 1.5248678893378924,
      "grad_norm": 0.2390705645084381,
      "learning_rate": 2.375660553310538e-06,
      "loss": 0.0633,
      "step": 19622
    },
    {
      "epoch": 1.5249456014920733,
      "grad_norm": 1.035054087638855,
      "learning_rate": 2.3752719925396332e-06,
      "loss": 0.5231,
      "step": 19623
    },
    {
      "epoch": 1.5250233136462543,
      "grad_norm": 0.12568946182727814,
      "learning_rate": 2.374883431768729e-06,
      "loss": 0.0458,
      "step": 19624
    },
    {
      "epoch": 1.5251010258004352,
      "grad_norm": 0.37561020255088806,
      "learning_rate": 2.3744948709978244e-06,
      "loss": 0.0711,
      "step": 19625
    },
    {
      "epoch": 1.525178737954616,
      "grad_norm": 0.8080278038978577,
      "learning_rate": 2.3741063102269198e-06,
      "loss": 0.5358,
      "step": 19626
    },
    {
      "epoch": 1.525256450108797,
      "grad_norm": 0.7116038203239441,
      "learning_rate": 2.373717749456015e-06,
      "loss": 0.0481,
      "step": 19627
    },
    {
      "epoch": 1.525334162262978,
      "grad_norm": 0.7379889488220215,
      "learning_rate": 2.3733291886851105e-06,
      "loss": 0.1061,
      "step": 19628
    },
    {
      "epoch": 1.5254118744171588,
      "grad_norm": 0.03732527419924736,
      "learning_rate": 2.372940627914206e-06,
      "loss": 0.0062,
      "step": 19629
    },
    {
      "epoch": 1.5254895865713398,
      "grad_norm": 0.49196964502334595,
      "learning_rate": 2.3725520671433013e-06,
      "loss": 0.2815,
      "step": 19630
    },
    {
      "epoch": 1.5255672987255207,
      "grad_norm": 0.5840500593185425,
      "learning_rate": 2.372163506372397e-06,
      "loss": 0.2078,
      "step": 19631
    },
    {
      "epoch": 1.5256450108797015,
      "grad_norm": 0.17640303075313568,
      "learning_rate": 2.371774945601492e-06,
      "loss": 0.0631,
      "step": 19632
    },
    {
      "epoch": 1.5257227230338826,
      "grad_norm": 0.8978849053382874,
      "learning_rate": 2.371386384830588e-06,
      "loss": 0.248,
      "step": 19633
    },
    {
      "epoch": 1.5258004351880634,
      "grad_norm": 0.24865053594112396,
      "learning_rate": 2.370997824059683e-06,
      "loss": 0.0864,
      "step": 19634
    },
    {
      "epoch": 1.5258781473422443,
      "grad_norm": 0.7003007531166077,
      "learning_rate": 2.3706092632887786e-06,
      "loss": 0.0938,
      "step": 19635
    },
    {
      "epoch": 1.5259558594964253,
      "grad_norm": 0.47067737579345703,
      "learning_rate": 2.370220702517874e-06,
      "loss": 0.2028,
      "step": 19636
    },
    {
      "epoch": 1.5260335716506062,
      "grad_norm": 0.3016207218170166,
      "learning_rate": 2.3698321417469693e-06,
      "loss": 0.0582,
      "step": 19637
    },
    {
      "epoch": 1.526111283804787,
      "grad_norm": 1.1236120462417603,
      "learning_rate": 2.369443580976065e-06,
      "loss": 0.0421,
      "step": 19638
    },
    {
      "epoch": 1.526188995958968,
      "grad_norm": 0.37169474363327026,
      "learning_rate": 2.36905502020516e-06,
      "loss": 0.1313,
      "step": 19639
    },
    {
      "epoch": 1.526266708113149,
      "grad_norm": 0.119899220764637,
      "learning_rate": 2.368666459434256e-06,
      "loss": 0.0074,
      "step": 19640
    },
    {
      "epoch": 1.5263444202673297,
      "grad_norm": 0.4229073226451874,
      "learning_rate": 2.3682778986633512e-06,
      "loss": 0.0949,
      "step": 19641
    },
    {
      "epoch": 1.5264221324215108,
      "grad_norm": 0.5979284048080444,
      "learning_rate": 2.3678893378924466e-06,
      "loss": 0.3588,
      "step": 19642
    },
    {
      "epoch": 1.5264998445756917,
      "grad_norm": 0.48930248618125916,
      "learning_rate": 2.367500777121542e-06,
      "loss": 0.2162,
      "step": 19643
    },
    {
      "epoch": 1.5265775567298725,
      "grad_norm": 0.38392430543899536,
      "learning_rate": 2.3671122163506374e-06,
      "loss": 0.5165,
      "step": 19644
    },
    {
      "epoch": 1.5266552688840536,
      "grad_norm": 0.3417709469795227,
      "learning_rate": 2.366723655579733e-06,
      "loss": 0.0833,
      "step": 19645
    },
    {
      "epoch": 1.5267329810382344,
      "grad_norm": 2.283369779586792,
      "learning_rate": 2.366335094808828e-06,
      "loss": 0.3667,
      "step": 19646
    },
    {
      "epoch": 1.5268106931924152,
      "grad_norm": 0.975658655166626,
      "learning_rate": 2.3659465340379235e-06,
      "loss": 0.6189,
      "step": 19647
    },
    {
      "epoch": 1.5268884053465963,
      "grad_norm": 0.3912203013896942,
      "learning_rate": 2.3655579732670193e-06,
      "loss": 0.1059,
      "step": 19648
    },
    {
      "epoch": 1.5269661175007772,
      "grad_norm": 0.13476158678531647,
      "learning_rate": 2.3651694124961146e-06,
      "loss": 0.0164,
      "step": 19649
    },
    {
      "epoch": 1.527043829654958,
      "grad_norm": 0.9048714637756348,
      "learning_rate": 2.36478085172521e-06,
      "loss": 0.7558,
      "step": 19650
    },
    {
      "epoch": 1.527121541809139,
      "grad_norm": 0.6011289358139038,
      "learning_rate": 2.3643922909543054e-06,
      "loss": 0.212,
      "step": 19651
    },
    {
      "epoch": 1.52719925396332,
      "grad_norm": 0.49822062253952026,
      "learning_rate": 2.3640037301834008e-06,
      "loss": 0.2787,
      "step": 19652
    },
    {
      "epoch": 1.5272769661175007,
      "grad_norm": 0.17454925179481506,
      "learning_rate": 2.363615169412496e-06,
      "loss": 0.0098,
      "step": 19653
    },
    {
      "epoch": 1.5273546782716818,
      "grad_norm": 0.3964492976665497,
      "learning_rate": 2.3632266086415915e-06,
      "loss": 0.0216,
      "step": 19654
    },
    {
      "epoch": 1.5274323904258627,
      "grad_norm": 0.44369935989379883,
      "learning_rate": 2.3628380478706873e-06,
      "loss": 0.1423,
      "step": 19655
    },
    {
      "epoch": 1.5275101025800435,
      "grad_norm": 0.5337161421775818,
      "learning_rate": 2.3624494870997827e-06,
      "loss": 0.4629,
      "step": 19656
    },
    {
      "epoch": 1.5275878147342246,
      "grad_norm": 0.0580424927175045,
      "learning_rate": 2.362060926328878e-06,
      "loss": 0.0059,
      "step": 19657
    },
    {
      "epoch": 1.5276655268884054,
      "grad_norm": 0.5119566321372986,
      "learning_rate": 2.3616723655579734e-06,
      "loss": 0.1344,
      "step": 19658
    },
    {
      "epoch": 1.5277432390425862,
      "grad_norm": 0.33577287197113037,
      "learning_rate": 2.361283804787069e-06,
      "loss": 0.1173,
      "step": 19659
    },
    {
      "epoch": 1.5278209511967673,
      "grad_norm": 0.1813737452030182,
      "learning_rate": 2.360895244016164e-06,
      "loss": 0.0403,
      "step": 19660
    },
    {
      "epoch": 1.527898663350948,
      "grad_norm": 0.6027436852455139,
      "learning_rate": 2.3605066832452595e-06,
      "loss": 0.119,
      "step": 19661
    },
    {
      "epoch": 1.527976375505129,
      "grad_norm": 0.22457697987556458,
      "learning_rate": 2.3601181224743553e-06,
      "loss": 0.1352,
      "step": 19662
    },
    {
      "epoch": 1.52805408765931,
      "grad_norm": 0.7854897975921631,
      "learning_rate": 2.3597295617034507e-06,
      "loss": 0.6303,
      "step": 19663
    },
    {
      "epoch": 1.5281317998134907,
      "grad_norm": 0.20415569841861725,
      "learning_rate": 2.359341000932546e-06,
      "loss": 0.0427,
      "step": 19664
    },
    {
      "epoch": 1.5282095119676717,
      "grad_norm": 0.6457417011260986,
      "learning_rate": 2.3589524401616415e-06,
      "loss": 0.2129,
      "step": 19665
    },
    {
      "epoch": 1.5282872241218528,
      "grad_norm": 0.6354557275772095,
      "learning_rate": 2.358563879390737e-06,
      "loss": 0.3588,
      "step": 19666
    },
    {
      "epoch": 1.5283649362760334,
      "grad_norm": 0.32369014620780945,
      "learning_rate": 2.358175318619832e-06,
      "loss": 0.143,
      "step": 19667
    },
    {
      "epoch": 1.5284426484302145,
      "grad_norm": 0.818841278553009,
      "learning_rate": 2.3577867578489276e-06,
      "loss": 0.3518,
      "step": 19668
    },
    {
      "epoch": 1.5285203605843956,
      "grad_norm": 0.5270594954490662,
      "learning_rate": 2.3573981970780234e-06,
      "loss": 0.1283,
      "step": 19669
    },
    {
      "epoch": 1.5285980727385762,
      "grad_norm": 0.7069209218025208,
      "learning_rate": 2.3570096363071188e-06,
      "loss": 0.3091,
      "step": 19670
    },
    {
      "epoch": 1.5286757848927572,
      "grad_norm": 0.7943659424781799,
      "learning_rate": 2.356621075536214e-06,
      "loss": 0.1601,
      "step": 19671
    },
    {
      "epoch": 1.5287534970469383,
      "grad_norm": 0.5075967907905579,
      "learning_rate": 2.3562325147653095e-06,
      "loss": 0.3067,
      "step": 19672
    },
    {
      "epoch": 1.528831209201119,
      "grad_norm": 0.4048222303390503,
      "learning_rate": 2.355843953994405e-06,
      "loss": 0.1536,
      "step": 19673
    },
    {
      "epoch": 1.5289089213553,
      "grad_norm": 0.1892920285463333,
      "learning_rate": 2.3554553932235002e-06,
      "loss": 0.0474,
      "step": 19674
    },
    {
      "epoch": 1.5289866335094808,
      "grad_norm": 0.3842077851295471,
      "learning_rate": 2.3550668324525956e-06,
      "loss": 0.1123,
      "step": 19675
    },
    {
      "epoch": 1.5290643456636617,
      "grad_norm": 0.5705938339233398,
      "learning_rate": 2.3546782716816914e-06,
      "loss": 0.3376,
      "step": 19676
    },
    {
      "epoch": 1.5291420578178427,
      "grad_norm": 0.806483268737793,
      "learning_rate": 2.3542897109107864e-06,
      "loss": 0.5332,
      "step": 19677
    },
    {
      "epoch": 1.5292197699720236,
      "grad_norm": 0.34023603796958923,
      "learning_rate": 2.353901150139882e-06,
      "loss": 0.7985,
      "step": 19678
    },
    {
      "epoch": 1.5292974821262044,
      "grad_norm": 0.302005410194397,
      "learning_rate": 2.3535125893689775e-06,
      "loss": 0.083,
      "step": 19679
    },
    {
      "epoch": 1.5293751942803855,
      "grad_norm": 0.23392190039157867,
      "learning_rate": 2.353124028598073e-06,
      "loss": 0.0807,
      "step": 19680
    },
    {
      "epoch": 1.5294529064345663,
      "grad_norm": 0.16439363360404968,
      "learning_rate": 2.3527354678271683e-06,
      "loss": 0.0466,
      "step": 19681
    },
    {
      "epoch": 1.5295306185887472,
      "grad_norm": 0.65421062707901,
      "learning_rate": 2.3523469070562637e-06,
      "loss": 0.1204,
      "step": 19682
    },
    {
      "epoch": 1.5296083307429282,
      "grad_norm": 0.41816386580467224,
      "learning_rate": 2.3519583462853595e-06,
      "loss": 0.1376,
      "step": 19683
    },
    {
      "epoch": 1.529686042897109,
      "grad_norm": 0.8610756397247314,
      "learning_rate": 2.3515697855144544e-06,
      "loss": 0.0619,
      "step": 19684
    },
    {
      "epoch": 1.52976375505129,
      "grad_norm": 0.5051403641700745,
      "learning_rate": 2.35118122474355e-06,
      "loss": 0.321,
      "step": 19685
    },
    {
      "epoch": 1.529841467205471,
      "grad_norm": 0.5625126361846924,
      "learning_rate": 2.3507926639726456e-06,
      "loss": 0.159,
      "step": 19686
    },
    {
      "epoch": 1.5299191793596518,
      "grad_norm": 0.3269282579421997,
      "learning_rate": 2.350404103201741e-06,
      "loss": 0.033,
      "step": 19687
    },
    {
      "epoch": 1.5299968915138327,
      "grad_norm": 0.2567210793495178,
      "learning_rate": 2.3500155424308363e-06,
      "loss": 0.0411,
      "step": 19688
    },
    {
      "epoch": 1.5300746036680137,
      "grad_norm": 0.7261013984680176,
      "learning_rate": 2.3496269816599317e-06,
      "loss": 0.2507,
      "step": 19689
    },
    {
      "epoch": 1.5301523158221946,
      "grad_norm": 0.6766753196716309,
      "learning_rate": 2.3492384208890275e-06,
      "loss": 0.1211,
      "step": 19690
    },
    {
      "epoch": 1.5302300279763754,
      "grad_norm": 0.12164240330457687,
      "learning_rate": 2.3488498601181224e-06,
      "loss": 0.0225,
      "step": 19691
    },
    {
      "epoch": 1.5303077401305565,
      "grad_norm": 0.5653929114341736,
      "learning_rate": 2.3484612993472182e-06,
      "loss": 0.0571,
      "step": 19692
    },
    {
      "epoch": 1.5303854522847373,
      "grad_norm": 0.4281505346298218,
      "learning_rate": 2.3480727385763136e-06,
      "loss": 0.4066,
      "step": 19693
    },
    {
      "epoch": 1.5304631644389182,
      "grad_norm": 0.27150997519493103,
      "learning_rate": 2.347684177805409e-06,
      "loss": 0.0672,
      "step": 19694
    },
    {
      "epoch": 1.5305408765930992,
      "grad_norm": 0.533045768737793,
      "learning_rate": 2.3472956170345044e-06,
      "loss": 0.1245,
      "step": 19695
    },
    {
      "epoch": 1.53061858874728,
      "grad_norm": 0.33659523725509644,
      "learning_rate": 2.3469070562635997e-06,
      "loss": 0.1629,
      "step": 19696
    },
    {
      "epoch": 1.530696300901461,
      "grad_norm": 0.5612421035766602,
      "learning_rate": 2.3465184954926955e-06,
      "loss": 0.5908,
      "step": 19697
    },
    {
      "epoch": 1.530774013055642,
      "grad_norm": 0.22182637453079224,
      "learning_rate": 2.3461299347217905e-06,
      "loss": 0.0612,
      "step": 19698
    },
    {
      "epoch": 1.5308517252098228,
      "grad_norm": 0.6704880595207214,
      "learning_rate": 2.3457413739508863e-06,
      "loss": 0.0862,
      "step": 19699
    },
    {
      "epoch": 1.5309294373640037,
      "grad_norm": 0.3905521035194397,
      "learning_rate": 2.3453528131799816e-06,
      "loss": 0.108,
      "step": 19700
    },
    {
      "epoch": 1.5310071495181847,
      "grad_norm": 0.16074249148368835,
      "learning_rate": 2.344964252409077e-06,
      "loss": 0.0471,
      "step": 19701
    },
    {
      "epoch": 1.5310848616723656,
      "grad_norm": 1.1191341876983643,
      "learning_rate": 2.3445756916381724e-06,
      "loss": 0.2738,
      "step": 19702
    },
    {
      "epoch": 1.5311625738265464,
      "grad_norm": 0.4478442370891571,
      "learning_rate": 2.3441871308672678e-06,
      "loss": 0.1863,
      "step": 19703
    },
    {
      "epoch": 1.5312402859807275,
      "grad_norm": 0.3149818480014801,
      "learning_rate": 2.3437985700963636e-06,
      "loss": 0.1207,
      "step": 19704
    },
    {
      "epoch": 1.5313179981349083,
      "grad_norm": 0.38996511697769165,
      "learning_rate": 2.3434100093254585e-06,
      "loss": 0.0677,
      "step": 19705
    },
    {
      "epoch": 1.5313957102890892,
      "grad_norm": 0.251426637172699,
      "learning_rate": 2.3430214485545543e-06,
      "loss": 0.0472,
      "step": 19706
    },
    {
      "epoch": 1.5314734224432702,
      "grad_norm": 0.1601676046848297,
      "learning_rate": 2.3426328877836497e-06,
      "loss": 0.0349,
      "step": 19707
    },
    {
      "epoch": 1.531551134597451,
      "grad_norm": 0.19484843313694,
      "learning_rate": 2.342244327012745e-06,
      "loss": 0.0711,
      "step": 19708
    },
    {
      "epoch": 1.531628846751632,
      "grad_norm": 0.44508135318756104,
      "learning_rate": 2.3418557662418404e-06,
      "loss": 0.0684,
      "step": 19709
    },
    {
      "epoch": 1.531706558905813,
      "grad_norm": 0.8865081667900085,
      "learning_rate": 2.341467205470936e-06,
      "loss": 0.0926,
      "step": 19710
    },
    {
      "epoch": 1.5317842710599938,
      "grad_norm": 0.48090511560440063,
      "learning_rate": 2.341078644700031e-06,
      "loss": 0.2395,
      "step": 19711
    },
    {
      "epoch": 1.5318619832141747,
      "grad_norm": 0.5637813806533813,
      "learning_rate": 2.3406900839291265e-06,
      "loss": 0.1365,
      "step": 19712
    },
    {
      "epoch": 1.5319396953683557,
      "grad_norm": 0.38275331258773804,
      "learning_rate": 2.340301523158222e-06,
      "loss": 0.0436,
      "step": 19713
    },
    {
      "epoch": 1.5320174075225366,
      "grad_norm": 1.16427481174469,
      "learning_rate": 2.3399129623873177e-06,
      "loss": 0.4181,
      "step": 19714
    },
    {
      "epoch": 1.5320951196767174,
      "grad_norm": 0.4911842346191406,
      "learning_rate": 2.3395244016164127e-06,
      "loss": 0.2392,
      "step": 19715
    },
    {
      "epoch": 1.5321728318308985,
      "grad_norm": 0.6801103353500366,
      "learning_rate": 2.3391358408455085e-06,
      "loss": 0.7612,
      "step": 19716
    },
    {
      "epoch": 1.5322505439850793,
      "grad_norm": 0.9509997963905334,
      "learning_rate": 2.338747280074604e-06,
      "loss": 0.208,
      "step": 19717
    },
    {
      "epoch": 1.5323282561392602,
      "grad_norm": 0.4711790680885315,
      "learning_rate": 2.338358719303699e-06,
      "loss": 0.1538,
      "step": 19718
    },
    {
      "epoch": 1.5324059682934412,
      "grad_norm": 0.28784334659576416,
      "learning_rate": 2.3379701585327946e-06,
      "loss": 0.0823,
      "step": 19719
    },
    {
      "epoch": 1.5324836804476218,
      "grad_norm": 0.30284056067466736,
      "learning_rate": 2.33758159776189e-06,
      "loss": 0.0357,
      "step": 19720
    },
    {
      "epoch": 1.532561392601803,
      "grad_norm": 0.9136818051338196,
      "learning_rate": 2.3371930369909858e-06,
      "loss": 0.3276,
      "step": 19721
    },
    {
      "epoch": 1.532639104755984,
      "grad_norm": 0.876413881778717,
      "learning_rate": 2.3368044762200807e-06,
      "loss": 0.2905,
      "step": 19722
    },
    {
      "epoch": 1.5327168169101646,
      "grad_norm": 0.6747716069221497,
      "learning_rate": 2.3364159154491765e-06,
      "loss": 0.2669,
      "step": 19723
    },
    {
      "epoch": 1.5327945290643457,
      "grad_norm": 0.3972893953323364,
      "learning_rate": 2.336027354678272e-06,
      "loss": 0.039,
      "step": 19724
    },
    {
      "epoch": 1.5328722412185267,
      "grad_norm": 0.25762543082237244,
      "learning_rate": 2.3356387939073672e-06,
      "loss": 0.232,
      "step": 19725
    },
    {
      "epoch": 1.5329499533727073,
      "grad_norm": 0.4390588104724884,
      "learning_rate": 2.3352502331364626e-06,
      "loss": 0.1587,
      "step": 19726
    },
    {
      "epoch": 1.5330276655268884,
      "grad_norm": 0.2541027069091797,
      "learning_rate": 2.334861672365558e-06,
      "loss": 0.049,
      "step": 19727
    },
    {
      "epoch": 1.5331053776810695,
      "grad_norm": 0.7048792243003845,
      "learning_rate": 2.334473111594654e-06,
      "loss": 0.1928,
      "step": 19728
    },
    {
      "epoch": 1.53318308983525,
      "grad_norm": 0.9845209717750549,
      "learning_rate": 2.3340845508237487e-06,
      "loss": 1.1491,
      "step": 19729
    },
    {
      "epoch": 1.5332608019894312,
      "grad_norm": 0.23297971487045288,
      "learning_rate": 2.3336959900528445e-06,
      "loss": 0.1355,
      "step": 19730
    },
    {
      "epoch": 1.5333385141436122,
      "grad_norm": 0.35387468338012695,
      "learning_rate": 2.33330742928194e-06,
      "loss": 0.1673,
      "step": 19731
    },
    {
      "epoch": 1.5334162262977928,
      "grad_norm": 0.494012713432312,
      "learning_rate": 2.3329188685110353e-06,
      "loss": 0.1535,
      "step": 19732
    },
    {
      "epoch": 1.533493938451974,
      "grad_norm": 0.21370536088943481,
      "learning_rate": 2.3325303077401307e-06,
      "loss": 0.0588,
      "step": 19733
    },
    {
      "epoch": 1.533571650606155,
      "grad_norm": 0.4156012535095215,
      "learning_rate": 2.332141746969226e-06,
      "loss": 0.1621,
      "step": 19734
    },
    {
      "epoch": 1.5336493627603356,
      "grad_norm": 0.3080516457557678,
      "learning_rate": 2.331753186198322e-06,
      "loss": 0.0871,
      "step": 19735
    },
    {
      "epoch": 1.5337270749145167,
      "grad_norm": 0.8137436509132385,
      "learning_rate": 2.3313646254274168e-06,
      "loss": 0.1329,
      "step": 19736
    },
    {
      "epoch": 1.5338047870686975,
      "grad_norm": 0.5815054178237915,
      "learning_rate": 2.3309760646565126e-06,
      "loss": 0.131,
      "step": 19737
    },
    {
      "epoch": 1.5338824992228783,
      "grad_norm": 0.6399092674255371,
      "learning_rate": 2.330587503885608e-06,
      "loss": 0.1976,
      "step": 19738
    },
    {
      "epoch": 1.5339602113770594,
      "grad_norm": 0.284715861082077,
      "learning_rate": 2.3301989431147033e-06,
      "loss": 0.0664,
      "step": 19739
    },
    {
      "epoch": 1.5340379235312402,
      "grad_norm": 1.2509407997131348,
      "learning_rate": 2.3298103823437987e-06,
      "loss": 0.3127,
      "step": 19740
    },
    {
      "epoch": 1.534115635685421,
      "grad_norm": 0.28443342447280884,
      "learning_rate": 2.329421821572894e-06,
      "loss": 0.0175,
      "step": 19741
    },
    {
      "epoch": 1.5341933478396022,
      "grad_norm": 0.8845750689506531,
      "learning_rate": 2.32903326080199e-06,
      "loss": 0.1396,
      "step": 19742
    },
    {
      "epoch": 1.534271059993783,
      "grad_norm": 0.7334068417549133,
      "learning_rate": 2.328644700031085e-06,
      "loss": 0.5803,
      "step": 19743
    },
    {
      "epoch": 1.5343487721479638,
      "grad_norm": 0.2653063237667084,
      "learning_rate": 2.3282561392601806e-06,
      "loss": 0.0261,
      "step": 19744
    },
    {
      "epoch": 1.534426484302145,
      "grad_norm": 0.5205836296081543,
      "learning_rate": 2.327867578489276e-06,
      "loss": 0.1487,
      "step": 19745
    },
    {
      "epoch": 1.5345041964563257,
      "grad_norm": 0.5120943784713745,
      "learning_rate": 2.3274790177183714e-06,
      "loss": 0.1206,
      "step": 19746
    },
    {
      "epoch": 1.5345819086105066,
      "grad_norm": 0.3671017587184906,
      "learning_rate": 2.3270904569474667e-06,
      "loss": 0.0573,
      "step": 19747
    },
    {
      "epoch": 1.5346596207646876,
      "grad_norm": 0.546785831451416,
      "learning_rate": 2.326701896176562e-06,
      "loss": 0.0234,
      "step": 19748
    },
    {
      "epoch": 1.5347373329188685,
      "grad_norm": 0.6776275634765625,
      "learning_rate": 2.326313335405658e-06,
      "loss": 0.1724,
      "step": 19749
    },
    {
      "epoch": 1.5348150450730493,
      "grad_norm": 0.30841097235679626,
      "learning_rate": 2.325924774634753e-06,
      "loss": 0.1597,
      "step": 19750
    },
    {
      "epoch": 1.5348927572272304,
      "grad_norm": 0.15558023750782013,
      "learning_rate": 2.3255362138638486e-06,
      "loss": 0.0247,
      "step": 19751
    },
    {
      "epoch": 1.5349704693814112,
      "grad_norm": 0.4979369044303894,
      "learning_rate": 2.325147653092944e-06,
      "loss": 0.1184,
      "step": 19752
    },
    {
      "epoch": 1.535048181535592,
      "grad_norm": 0.1553662270307541,
      "learning_rate": 2.3247590923220394e-06,
      "loss": 0.019,
      "step": 19753
    },
    {
      "epoch": 1.5351258936897731,
      "grad_norm": 0.24454788863658905,
      "learning_rate": 2.3243705315511348e-06,
      "loss": 0.0518,
      "step": 19754
    },
    {
      "epoch": 1.535203605843954,
      "grad_norm": 0.37178075313568115,
      "learning_rate": 2.32398197078023e-06,
      "loss": 0.1589,
      "step": 19755
    },
    {
      "epoch": 1.5352813179981348,
      "grad_norm": 0.5737897157669067,
      "learning_rate": 2.323593410009326e-06,
      "loss": 0.101,
      "step": 19756
    },
    {
      "epoch": 1.535359030152316,
      "grad_norm": 0.18553169071674347,
      "learning_rate": 2.323204849238421e-06,
      "loss": 0.0701,
      "step": 19757
    },
    {
      "epoch": 1.5354367423064967,
      "grad_norm": 0.20873574912548065,
      "learning_rate": 2.3228162884675167e-06,
      "loss": 0.064,
      "step": 19758
    },
    {
      "epoch": 1.5355144544606776,
      "grad_norm": 0.41548952460289,
      "learning_rate": 2.322427727696612e-06,
      "loss": 0.1457,
      "step": 19759
    },
    {
      "epoch": 1.5355921666148586,
      "grad_norm": 0.3353055417537689,
      "learning_rate": 2.3220391669257074e-06,
      "loss": 0.0603,
      "step": 19760
    },
    {
      "epoch": 1.5356698787690395,
      "grad_norm": 0.1763755977153778,
      "learning_rate": 2.321650606154803e-06,
      "loss": 0.0367,
      "step": 19761
    },
    {
      "epoch": 1.5357475909232203,
      "grad_norm": 0.5382372140884399,
      "learning_rate": 2.321262045383898e-06,
      "loss": 0.1099,
      "step": 19762
    },
    {
      "epoch": 1.5358253030774014,
      "grad_norm": 0.2153375744819641,
      "learning_rate": 2.320873484612994e-06,
      "loss": 0.0189,
      "step": 19763
    },
    {
      "epoch": 1.5359030152315822,
      "grad_norm": 0.5889331102371216,
      "learning_rate": 2.320484923842089e-06,
      "loss": 0.4714,
      "step": 19764
    },
    {
      "epoch": 1.535980727385763,
      "grad_norm": 0.6383481025695801,
      "learning_rate": 2.3200963630711847e-06,
      "loss": 0.1248,
      "step": 19765
    },
    {
      "epoch": 1.5360584395399441,
      "grad_norm": 1.6226258277893066,
      "learning_rate": 2.31970780230028e-06,
      "loss": 0.1482,
      "step": 19766
    },
    {
      "epoch": 1.536136151694125,
      "grad_norm": 0.20530398190021515,
      "learning_rate": 2.3193192415293755e-06,
      "loss": 0.0329,
      "step": 19767
    },
    {
      "epoch": 1.5362138638483058,
      "grad_norm": 0.6136600971221924,
      "learning_rate": 2.318930680758471e-06,
      "loss": 0.1781,
      "step": 19768
    },
    {
      "epoch": 1.536291576002487,
      "grad_norm": 0.2982913851737976,
      "learning_rate": 2.3185421199875662e-06,
      "loss": 0.0938,
      "step": 19769
    },
    {
      "epoch": 1.5363692881566677,
      "grad_norm": 0.7064736485481262,
      "learning_rate": 2.3181535592166616e-06,
      "loss": 0.2579,
      "step": 19770
    },
    {
      "epoch": 1.5364470003108486,
      "grad_norm": 0.2399510145187378,
      "learning_rate": 2.317764998445757e-06,
      "loss": 0.0745,
      "step": 19771
    },
    {
      "epoch": 1.5365247124650296,
      "grad_norm": 0.5998902320861816,
      "learning_rate": 2.3173764376748523e-06,
      "loss": 0.055,
      "step": 19772
    },
    {
      "epoch": 1.5366024246192105,
      "grad_norm": 0.23784101009368896,
      "learning_rate": 2.316987876903948e-06,
      "loss": 0.1125,
      "step": 19773
    },
    {
      "epoch": 1.5366801367733913,
      "grad_norm": 0.4632115066051483,
      "learning_rate": 2.316599316133043e-06,
      "loss": 0.1399,
      "step": 19774
    },
    {
      "epoch": 1.5367578489275724,
      "grad_norm": 0.25074493885040283,
      "learning_rate": 2.316210755362139e-06,
      "loss": 0.0942,
      "step": 19775
    },
    {
      "epoch": 1.5368355610817532,
      "grad_norm": 0.9999271035194397,
      "learning_rate": 2.3158221945912342e-06,
      "loss": 0.7356,
      "step": 19776
    },
    {
      "epoch": 1.536913273235934,
      "grad_norm": 0.627587616443634,
      "learning_rate": 2.3154336338203296e-06,
      "loss": 0.1443,
      "step": 19777
    },
    {
      "epoch": 1.5369909853901151,
      "grad_norm": 1.003515601158142,
      "learning_rate": 2.315045073049425e-06,
      "loss": 0.3831,
      "step": 19778
    },
    {
      "epoch": 1.537068697544296,
      "grad_norm": 0.15748442709445953,
      "learning_rate": 2.3146565122785204e-06,
      "loss": 0.0434,
      "step": 19779
    },
    {
      "epoch": 1.5371464096984768,
      "grad_norm": 0.28832757472991943,
      "learning_rate": 2.314267951507616e-06,
      "loss": 0.0436,
      "step": 19780
    },
    {
      "epoch": 1.5372241218526579,
      "grad_norm": 0.30087026953697205,
      "learning_rate": 2.313879390736711e-06,
      "loss": 0.1152,
      "step": 19781
    },
    {
      "epoch": 1.5373018340068385,
      "grad_norm": 0.6119608879089355,
      "learning_rate": 2.313490829965807e-06,
      "loss": 0.2082,
      "step": 19782
    },
    {
      "epoch": 1.5373795461610196,
      "grad_norm": 0.11435481160879135,
      "learning_rate": 2.3131022691949023e-06,
      "loss": 0.0301,
      "step": 19783
    },
    {
      "epoch": 1.5374572583152006,
      "grad_norm": 0.2887049615383148,
      "learning_rate": 2.3127137084239977e-06,
      "loss": 0.1762,
      "step": 19784
    },
    {
      "epoch": 1.5375349704693813,
      "grad_norm": 0.6788983345031738,
      "learning_rate": 2.312325147653093e-06,
      "loss": 0.2698,
      "step": 19785
    },
    {
      "epoch": 1.5376126826235623,
      "grad_norm": 0.621270477771759,
      "learning_rate": 2.3119365868821884e-06,
      "loss": 0.3282,
      "step": 19786
    },
    {
      "epoch": 1.5376903947777434,
      "grad_norm": 0.71165931224823,
      "learning_rate": 2.311548026111284e-06,
      "loss": 0.3792,
      "step": 19787
    },
    {
      "epoch": 1.537768106931924,
      "grad_norm": 0.6377962231636047,
      "learning_rate": 2.311159465340379e-06,
      "loss": 0.3561,
      "step": 19788
    },
    {
      "epoch": 1.537845819086105,
      "grad_norm": 0.8379926085472107,
      "learning_rate": 2.310770904569475e-06,
      "loss": 0.2193,
      "step": 19789
    },
    {
      "epoch": 1.5379235312402861,
      "grad_norm": 0.9344748854637146,
      "learning_rate": 2.3103823437985703e-06,
      "loss": 0.2255,
      "step": 19790
    },
    {
      "epoch": 1.5380012433944668,
      "grad_norm": 2.6967313289642334,
      "learning_rate": 2.3099937830276657e-06,
      "loss": 0.2053,
      "step": 19791
    },
    {
      "epoch": 1.5380789555486478,
      "grad_norm": 0.10977237671613693,
      "learning_rate": 2.309605222256761e-06,
      "loss": 0.0414,
      "step": 19792
    },
    {
      "epoch": 1.5381566677028289,
      "grad_norm": 0.2869512736797333,
      "learning_rate": 2.3092166614858564e-06,
      "loss": 0.073,
      "step": 19793
    },
    {
      "epoch": 1.5382343798570095,
      "grad_norm": 0.3331150710582733,
      "learning_rate": 2.3088281007149522e-06,
      "loss": 0.0802,
      "step": 19794
    },
    {
      "epoch": 1.5383120920111906,
      "grad_norm": 0.13995379209518433,
      "learning_rate": 2.308439539944047e-06,
      "loss": 0.0369,
      "step": 19795
    },
    {
      "epoch": 1.5383898041653714,
      "grad_norm": 0.6360018253326416,
      "learning_rate": 2.308050979173143e-06,
      "loss": 0.2658,
      "step": 19796
    },
    {
      "epoch": 1.5384675163195523,
      "grad_norm": 0.6327923536300659,
      "learning_rate": 2.3076624184022384e-06,
      "loss": 0.243,
      "step": 19797
    },
    {
      "epoch": 1.5385452284737333,
      "grad_norm": 0.4464564025402069,
      "learning_rate": 2.3072738576313337e-06,
      "loss": 0.0808,
      "step": 19798
    },
    {
      "epoch": 1.5386229406279142,
      "grad_norm": 0.022255586460232735,
      "learning_rate": 2.306885296860429e-06,
      "loss": 0.0025,
      "step": 19799
    },
    {
      "epoch": 1.538700652782095,
      "grad_norm": 0.6908143758773804,
      "learning_rate": 2.3064967360895245e-06,
      "loss": 0.2541,
      "step": 19800
    },
    {
      "epoch": 1.538778364936276,
      "grad_norm": 0.4427531361579895,
      "learning_rate": 2.3061081753186203e-06,
      "loss": 0.2331,
      "step": 19801
    },
    {
      "epoch": 1.538856077090457,
      "grad_norm": 0.2531103789806366,
      "learning_rate": 2.3057196145477152e-06,
      "loss": 0.1999,
      "step": 19802
    },
    {
      "epoch": 1.5389337892446378,
      "grad_norm": 0.3799939453601837,
      "learning_rate": 2.305331053776811e-06,
      "loss": 0.1319,
      "step": 19803
    },
    {
      "epoch": 1.5390115013988188,
      "grad_norm": 0.24633875489234924,
      "learning_rate": 2.3049424930059064e-06,
      "loss": 0.0498,
      "step": 19804
    },
    {
      "epoch": 1.5390892135529997,
      "grad_norm": 0.6279594898223877,
      "learning_rate": 2.3045539322350018e-06,
      "loss": 0.2519,
      "step": 19805
    },
    {
      "epoch": 1.5391669257071805,
      "grad_norm": 0.18772071599960327,
      "learning_rate": 2.304165371464097e-06,
      "loss": 0.08,
      "step": 19806
    },
    {
      "epoch": 1.5392446378613616,
      "grad_norm": 0.36915984749794006,
      "learning_rate": 2.3037768106931925e-06,
      "loss": 0.1381,
      "step": 19807
    },
    {
      "epoch": 1.5393223500155424,
      "grad_norm": 0.4421943426132202,
      "learning_rate": 2.3033882499222883e-06,
      "loss": 0.1507,
      "step": 19808
    },
    {
      "epoch": 1.5394000621697232,
      "grad_norm": 0.12567028403282166,
      "learning_rate": 2.3029996891513833e-06,
      "loss": 0.0354,
      "step": 19809
    },
    {
      "epoch": 1.5394777743239043,
      "grad_norm": 0.23899738490581512,
      "learning_rate": 2.302611128380479e-06,
      "loss": 0.1495,
      "step": 19810
    },
    {
      "epoch": 1.5395554864780852,
      "grad_norm": 0.7554526925086975,
      "learning_rate": 2.3022225676095744e-06,
      "loss": 0.2804,
      "step": 19811
    },
    {
      "epoch": 1.539633198632266,
      "grad_norm": 0.8451603055000305,
      "learning_rate": 2.30183400683867e-06,
      "loss": 0.0931,
      "step": 19812
    },
    {
      "epoch": 1.539710910786447,
      "grad_norm": 0.2414221316576004,
      "learning_rate": 2.301445446067765e-06,
      "loss": 0.0499,
      "step": 19813
    },
    {
      "epoch": 1.539788622940628,
      "grad_norm": 0.23846358060836792,
      "learning_rate": 2.3010568852968606e-06,
      "loss": 0.0193,
      "step": 19814
    },
    {
      "epoch": 1.5398663350948087,
      "grad_norm": 0.15994231402873993,
      "learning_rate": 2.3006683245259563e-06,
      "loss": 0.0241,
      "step": 19815
    },
    {
      "epoch": 1.5399440472489898,
      "grad_norm": 0.17975689470767975,
      "learning_rate": 2.3002797637550513e-06,
      "loss": 0.0804,
      "step": 19816
    },
    {
      "epoch": 1.5400217594031707,
      "grad_norm": 1.1461273431777954,
      "learning_rate": 2.299891202984147e-06,
      "loss": 0.1124,
      "step": 19817
    },
    {
      "epoch": 1.5400994715573515,
      "grad_norm": 0.4775000512599945,
      "learning_rate": 2.2995026422132425e-06,
      "loss": 0.1346,
      "step": 19818
    },
    {
      "epoch": 1.5401771837115326,
      "grad_norm": 0.8291133046150208,
      "learning_rate": 2.299114081442338e-06,
      "loss": 0.3134,
      "step": 19819
    },
    {
      "epoch": 1.5402548958657134,
      "grad_norm": 0.09633314609527588,
      "learning_rate": 2.2987255206714332e-06,
      "loss": 0.0381,
      "step": 19820
    },
    {
      "epoch": 1.5403326080198942,
      "grad_norm": 0.5726679563522339,
      "learning_rate": 2.2983369599005286e-06,
      "loss": 0.1786,
      "step": 19821
    },
    {
      "epoch": 1.5404103201740753,
      "grad_norm": 0.1658729761838913,
      "learning_rate": 2.2979483991296244e-06,
      "loss": 0.0268,
      "step": 19822
    },
    {
      "epoch": 1.5404880323282562,
      "grad_norm": 0.1374840885400772,
      "learning_rate": 2.2975598383587193e-06,
      "loss": 0.042,
      "step": 19823
    },
    {
      "epoch": 1.540565744482437,
      "grad_norm": 0.8829901218414307,
      "learning_rate": 2.297171277587815e-06,
      "loss": 0.5799,
      "step": 19824
    },
    {
      "epoch": 1.540643456636618,
      "grad_norm": 0.4135395288467407,
      "learning_rate": 2.2967827168169105e-06,
      "loss": 0.1858,
      "step": 19825
    },
    {
      "epoch": 1.540721168790799,
      "grad_norm": 0.1967572420835495,
      "learning_rate": 2.296394156046006e-06,
      "loss": 0.0709,
      "step": 19826
    },
    {
      "epoch": 1.5407988809449797,
      "grad_norm": 0.5889120101928711,
      "learning_rate": 2.2960055952751013e-06,
      "loss": 0.1787,
      "step": 19827
    },
    {
      "epoch": 1.5408765930991608,
      "grad_norm": 0.1542072892189026,
      "learning_rate": 2.2956170345041966e-06,
      "loss": 0.0608,
      "step": 19828
    },
    {
      "epoch": 1.5409543052533416,
      "grad_norm": 0.18642818927764893,
      "learning_rate": 2.295228473733292e-06,
      "loss": 0.0967,
      "step": 19829
    },
    {
      "epoch": 1.5410320174075225,
      "grad_norm": 0.5326619744300842,
      "learning_rate": 2.2948399129623874e-06,
      "loss": 0.2238,
      "step": 19830
    },
    {
      "epoch": 1.5411097295617036,
      "grad_norm": 0.2790883183479309,
      "learning_rate": 2.294451352191483e-06,
      "loss": 0.0541,
      "step": 19831
    },
    {
      "epoch": 1.5411874417158844,
      "grad_norm": 1.1486116647720337,
      "learning_rate": 2.2940627914205785e-06,
      "loss": 0.3144,
      "step": 19832
    },
    {
      "epoch": 1.5412651538700652,
      "grad_norm": 0.7283200025558472,
      "learning_rate": 2.293674230649674e-06,
      "loss": 0.3979,
      "step": 19833
    },
    {
      "epoch": 1.5413428660242463,
      "grad_norm": 1.233763337135315,
      "learning_rate": 2.2932856698787693e-06,
      "loss": 0.6425,
      "step": 19834
    },
    {
      "epoch": 1.5414205781784271,
      "grad_norm": 0.20904237031936646,
      "learning_rate": 2.2928971091078647e-06,
      "loss": 0.3301,
      "step": 19835
    },
    {
      "epoch": 1.541498290332608,
      "grad_norm": 0.8475521206855774,
      "learning_rate": 2.29250854833696e-06,
      "loss": 0.2526,
      "step": 19836
    },
    {
      "epoch": 1.541576002486789,
      "grad_norm": 0.7872204780578613,
      "learning_rate": 2.2921199875660554e-06,
      "loss": 0.4634,
      "step": 19837
    },
    {
      "epoch": 1.54165371464097,
      "grad_norm": 0.17357377707958221,
      "learning_rate": 2.2917314267951508e-06,
      "loss": 0.0785,
      "step": 19838
    },
    {
      "epoch": 1.5417314267951507,
      "grad_norm": 0.15962433815002441,
      "learning_rate": 2.2913428660242466e-06,
      "loss": 0.2481,
      "step": 19839
    },
    {
      "epoch": 1.5418091389493318,
      "grad_norm": 0.30138716101646423,
      "learning_rate": 2.2909543052533415e-06,
      "loss": 0.0566,
      "step": 19840
    },
    {
      "epoch": 1.5418868511035124,
      "grad_norm": 0.43216368556022644,
      "learning_rate": 2.2905657444824373e-06,
      "loss": 0.0816,
      "step": 19841
    },
    {
      "epoch": 1.5419645632576935,
      "grad_norm": 0.31798505783081055,
      "learning_rate": 2.2901771837115327e-06,
      "loss": 0.1034,
      "step": 19842
    },
    {
      "epoch": 1.5420422754118746,
      "grad_norm": 0.23898616433143616,
      "learning_rate": 2.289788622940628e-06,
      "loss": 0.0535,
      "step": 19843
    },
    {
      "epoch": 1.5421199875660552,
      "grad_norm": 0.5786537528038025,
      "learning_rate": 2.2894000621697234e-06,
      "loss": 0.09,
      "step": 19844
    },
    {
      "epoch": 1.5421976997202362,
      "grad_norm": 0.389223575592041,
      "learning_rate": 2.289011501398819e-06,
      "loss": 0.0419,
      "step": 19845
    },
    {
      "epoch": 1.5422754118744173,
      "grad_norm": 0.2771700322628021,
      "learning_rate": 2.2886229406279146e-06,
      "loss": 0.1392,
      "step": 19846
    },
    {
      "epoch": 1.542353124028598,
      "grad_norm": 0.07937667518854141,
      "learning_rate": 2.2882343798570096e-06,
      "loss": 0.023,
      "step": 19847
    },
    {
      "epoch": 1.542430836182779,
      "grad_norm": 0.7189505100250244,
      "learning_rate": 2.2878458190861054e-06,
      "loss": 0.1951,
      "step": 19848
    },
    {
      "epoch": 1.54250854833696,
      "grad_norm": 0.29383063316345215,
      "learning_rate": 2.2874572583152007e-06,
      "loss": 0.0262,
      "step": 19849
    },
    {
      "epoch": 1.5425862604911407,
      "grad_norm": 0.5519198179244995,
      "learning_rate": 2.287068697544296e-06,
      "loss": 0.2217,
      "step": 19850
    },
    {
      "epoch": 1.5426639726453217,
      "grad_norm": 0.30952736735343933,
      "learning_rate": 2.2866801367733915e-06,
      "loss": 0.1923,
      "step": 19851
    },
    {
      "epoch": 1.5427416847995028,
      "grad_norm": 0.3971101939678192,
      "learning_rate": 2.286291576002487e-06,
      "loss": 0.2729,
      "step": 19852
    },
    {
      "epoch": 1.5428193969536834,
      "grad_norm": 0.22580644488334656,
      "learning_rate": 2.2859030152315827e-06,
      "loss": 0.0367,
      "step": 19853
    },
    {
      "epoch": 1.5428971091078645,
      "grad_norm": 0.1756555587053299,
      "learning_rate": 2.2855144544606776e-06,
      "loss": 0.0327,
      "step": 19854
    },
    {
      "epoch": 1.5429748212620455,
      "grad_norm": 0.35133081674575806,
      "learning_rate": 2.2851258936897734e-06,
      "loss": 0.1344,
      "step": 19855
    },
    {
      "epoch": 1.5430525334162262,
      "grad_norm": 0.20495446026325226,
      "learning_rate": 2.2847373329188688e-06,
      "loss": 0.0309,
      "step": 19856
    },
    {
      "epoch": 1.5431302455704072,
      "grad_norm": 0.7423151731491089,
      "learning_rate": 2.284348772147964e-06,
      "loss": 0.2377,
      "step": 19857
    },
    {
      "epoch": 1.543207957724588,
      "grad_norm": 0.8891181945800781,
      "learning_rate": 2.2839602113770595e-06,
      "loss": 0.1961,
      "step": 19858
    },
    {
      "epoch": 1.543285669878769,
      "grad_norm": 0.3170013427734375,
      "learning_rate": 2.283571650606155e-06,
      "loss": 0.0568,
      "step": 19859
    },
    {
      "epoch": 1.54336338203295,
      "grad_norm": 0.12449949979782104,
      "learning_rate": 2.2831830898352507e-06,
      "loss": 0.0184,
      "step": 19860
    },
    {
      "epoch": 1.5434410941871308,
      "grad_norm": 0.6293622851371765,
      "learning_rate": 2.2827945290643456e-06,
      "loss": 0.2602,
      "step": 19861
    },
    {
      "epoch": 1.5435188063413117,
      "grad_norm": 0.2159631848335266,
      "learning_rate": 2.2824059682934414e-06,
      "loss": 0.0693,
      "step": 19862
    },
    {
      "epoch": 1.5435965184954927,
      "grad_norm": 0.8079153299331665,
      "learning_rate": 2.282017407522537e-06,
      "loss": 0.548,
      "step": 19863
    },
    {
      "epoch": 1.5436742306496736,
      "grad_norm": 0.1729552000761032,
      "learning_rate": 2.281628846751632e-06,
      "loss": 0.0337,
      "step": 19864
    },
    {
      "epoch": 1.5437519428038544,
      "grad_norm": 0.2512570917606354,
      "learning_rate": 2.2812402859807276e-06,
      "loss": 0.0201,
      "step": 19865
    },
    {
      "epoch": 1.5438296549580355,
      "grad_norm": 0.45318466424942017,
      "learning_rate": 2.280851725209823e-06,
      "loss": 0.1969,
      "step": 19866
    },
    {
      "epoch": 1.5439073671122163,
      "grad_norm": 0.6031985878944397,
      "learning_rate": 2.2804631644389183e-06,
      "loss": 0.0629,
      "step": 19867
    },
    {
      "epoch": 1.5439850792663972,
      "grad_norm": 1.2793971300125122,
      "learning_rate": 2.2800746036680137e-06,
      "loss": 0.1908,
      "step": 19868
    },
    {
      "epoch": 1.5440627914205782,
      "grad_norm": 0.48649290204048157,
      "learning_rate": 2.2796860428971095e-06,
      "loss": 0.3005,
      "step": 19869
    },
    {
      "epoch": 1.544140503574759,
      "grad_norm": 0.7136761546134949,
      "learning_rate": 2.279297482126205e-06,
      "loss": 0.4531,
      "step": 19870
    },
    {
      "epoch": 1.54421821572894,
      "grad_norm": 0.7359161376953125,
      "learning_rate": 2.2789089213553002e-06,
      "loss": 0.1101,
      "step": 19871
    },
    {
      "epoch": 1.544295927883121,
      "grad_norm": 0.3713890314102173,
      "learning_rate": 2.2785203605843956e-06,
      "loss": 0.2065,
      "step": 19872
    },
    {
      "epoch": 1.5443736400373018,
      "grad_norm": 0.4305039048194885,
      "learning_rate": 2.278131799813491e-06,
      "loss": 0.1794,
      "step": 19873
    },
    {
      "epoch": 1.5444513521914827,
      "grad_norm": 0.23635749518871307,
      "learning_rate": 2.2777432390425863e-06,
      "loss": 0.0508,
      "step": 19874
    },
    {
      "epoch": 1.5445290643456637,
      "grad_norm": 0.4232604503631592,
      "learning_rate": 2.2773546782716817e-06,
      "loss": 0.3515,
      "step": 19875
    },
    {
      "epoch": 1.5446067764998446,
      "grad_norm": 0.46431660652160645,
      "learning_rate": 2.2769661175007775e-06,
      "loss": 0.2733,
      "step": 19876
    },
    {
      "epoch": 1.5446844886540254,
      "grad_norm": 0.2663661241531372,
      "learning_rate": 2.276577556729873e-06,
      "loss": 0.0604,
      "step": 19877
    },
    {
      "epoch": 1.5447622008082065,
      "grad_norm": 0.5757644176483154,
      "learning_rate": 2.2761889959589683e-06,
      "loss": 0.3599,
      "step": 19878
    },
    {
      "epoch": 1.5448399129623873,
      "grad_norm": 0.27841395139694214,
      "learning_rate": 2.2758004351880636e-06,
      "loss": 0.1102,
      "step": 19879
    },
    {
      "epoch": 1.5449176251165682,
      "grad_norm": 0.35947924852371216,
      "learning_rate": 2.275411874417159e-06,
      "loss": 0.102,
      "step": 19880
    },
    {
      "epoch": 1.5449953372707492,
      "grad_norm": 0.14279158413410187,
      "learning_rate": 2.2750233136462544e-06,
      "loss": 0.0361,
      "step": 19881
    },
    {
      "epoch": 1.54507304942493,
      "grad_norm": 0.8241584300994873,
      "learning_rate": 2.2746347528753497e-06,
      "loss": 0.1937,
      "step": 19882
    },
    {
      "epoch": 1.545150761579111,
      "grad_norm": 0.6992254257202148,
      "learning_rate": 2.2742461921044455e-06,
      "loss": 0.4697,
      "step": 19883
    },
    {
      "epoch": 1.545228473733292,
      "grad_norm": 0.23140408098697662,
      "learning_rate": 2.273857631333541e-06,
      "loss": 0.0225,
      "step": 19884
    },
    {
      "epoch": 1.5453061858874728,
      "grad_norm": 0.48336756229400635,
      "learning_rate": 2.2734690705626363e-06,
      "loss": 0.1285,
      "step": 19885
    },
    {
      "epoch": 1.5453838980416537,
      "grad_norm": 2.4606993198394775,
      "learning_rate": 2.2730805097917317e-06,
      "loss": 0.3779,
      "step": 19886
    },
    {
      "epoch": 1.5454616101958347,
      "grad_norm": 0.44076448678970337,
      "learning_rate": 2.272691949020827e-06,
      "loss": 0.0507,
      "step": 19887
    },
    {
      "epoch": 1.5455393223500156,
      "grad_norm": 0.15188716351985931,
      "learning_rate": 2.2723033882499224e-06,
      "loss": 0.0693,
      "step": 19888
    },
    {
      "epoch": 1.5456170345041964,
      "grad_norm": 1.3269761800765991,
      "learning_rate": 2.2719148274790178e-06,
      "loss": 0.3781,
      "step": 19889
    },
    {
      "epoch": 1.5456947466583775,
      "grad_norm": 0.4733330309391022,
      "learning_rate": 2.2715262667081136e-06,
      "loss": 0.1467,
      "step": 19890
    },
    {
      "epoch": 1.5457724588125583,
      "grad_norm": 0.6707049608230591,
      "learning_rate": 2.271137705937209e-06,
      "loss": 0.4381,
      "step": 19891
    },
    {
      "epoch": 1.5458501709667392,
      "grad_norm": 0.3161921501159668,
      "learning_rate": 2.2707491451663043e-06,
      "loss": 0.0459,
      "step": 19892
    },
    {
      "epoch": 1.5459278831209202,
      "grad_norm": 0.39214402437210083,
      "learning_rate": 2.2703605843953997e-06,
      "loss": 0.0365,
      "step": 19893
    },
    {
      "epoch": 1.546005595275101,
      "grad_norm": 0.31048908829689026,
      "learning_rate": 2.269972023624495e-06,
      "loss": 0.0297,
      "step": 19894
    },
    {
      "epoch": 1.546083307429282,
      "grad_norm": 0.42613622546195984,
      "learning_rate": 2.2695834628535904e-06,
      "loss": 0.0869,
      "step": 19895
    },
    {
      "epoch": 1.546161019583463,
      "grad_norm": 0.5614931583404541,
      "learning_rate": 2.269194902082686e-06,
      "loss": 0.2752,
      "step": 19896
    },
    {
      "epoch": 1.5462387317376438,
      "grad_norm": 0.38232964277267456,
      "learning_rate": 2.268806341311781e-06,
      "loss": 0.0735,
      "step": 19897
    },
    {
      "epoch": 1.5463164438918247,
      "grad_norm": 0.8967347145080566,
      "learning_rate": 2.268417780540877e-06,
      "loss": 0.7603,
      "step": 19898
    },
    {
      "epoch": 1.5463941560460057,
      "grad_norm": 0.17860576510429382,
      "learning_rate": 2.268029219769972e-06,
      "loss": 0.0107,
      "step": 19899
    },
    {
      "epoch": 1.5464718682001866,
      "grad_norm": 0.3306649625301361,
      "learning_rate": 2.2676406589990677e-06,
      "loss": 0.1229,
      "step": 19900
    },
    {
      "epoch": 1.5465495803543674,
      "grad_norm": 0.6115620136260986,
      "learning_rate": 2.267252098228163e-06,
      "loss": 0.2096,
      "step": 19901
    },
    {
      "epoch": 1.5466272925085485,
      "grad_norm": 0.6784763932228088,
      "learning_rate": 2.2668635374572585e-06,
      "loss": 0.078,
      "step": 19902
    },
    {
      "epoch": 1.546705004662729,
      "grad_norm": 0.40513065457344055,
      "learning_rate": 2.266474976686354e-06,
      "loss": 0.1887,
      "step": 19903
    },
    {
      "epoch": 1.5467827168169102,
      "grad_norm": 0.40885958075523376,
      "learning_rate": 2.2660864159154492e-06,
      "loss": 0.2191,
      "step": 19904
    },
    {
      "epoch": 1.5468604289710912,
      "grad_norm": 0.4474285840988159,
      "learning_rate": 2.2656978551445446e-06,
      "loss": 0.0806,
      "step": 19905
    },
    {
      "epoch": 1.5469381411252718,
      "grad_norm": 0.4639628827571869,
      "learning_rate": 2.26530929437364e-06,
      "loss": 0.1215,
      "step": 19906
    },
    {
      "epoch": 1.547015853279453,
      "grad_norm": 0.5795641541481018,
      "learning_rate": 2.2649207336027358e-06,
      "loss": 0.2177,
      "step": 19907
    },
    {
      "epoch": 1.547093565433634,
      "grad_norm": 0.18090099096298218,
      "learning_rate": 2.264532172831831e-06,
      "loss": 0.0391,
      "step": 19908
    },
    {
      "epoch": 1.5471712775878146,
      "grad_norm": 0.33698686957359314,
      "learning_rate": 2.2641436120609265e-06,
      "loss": 0.0326,
      "step": 19909
    },
    {
      "epoch": 1.5472489897419957,
      "grad_norm": 0.7536136507987976,
      "learning_rate": 2.263755051290022e-06,
      "loss": 0.266,
      "step": 19910
    },
    {
      "epoch": 1.5473267018961767,
      "grad_norm": 1.068040370941162,
      "learning_rate": 2.2633664905191173e-06,
      "loss": 0.2539,
      "step": 19911
    },
    {
      "epoch": 1.5474044140503573,
      "grad_norm": 0.42302602529525757,
      "learning_rate": 2.2629779297482126e-06,
      "loss": 0.062,
      "step": 19912
    },
    {
      "epoch": 1.5474821262045384,
      "grad_norm": 0.11340875178575516,
      "learning_rate": 2.262589368977308e-06,
      "loss": 0.0139,
      "step": 19913
    },
    {
      "epoch": 1.5475598383587195,
      "grad_norm": 0.11701178550720215,
      "learning_rate": 2.262200808206404e-06,
      "loss": 0.0295,
      "step": 19914
    },
    {
      "epoch": 1.5476375505129,
      "grad_norm": 0.4634947180747986,
      "learning_rate": 2.261812247435499e-06,
      "loss": 0.0756,
      "step": 19915
    },
    {
      "epoch": 1.5477152626670811,
      "grad_norm": 0.5130210518836975,
      "learning_rate": 2.2614236866645946e-06,
      "loss": 0.1439,
      "step": 19916
    },
    {
      "epoch": 1.547792974821262,
      "grad_norm": 0.6981960535049438,
      "learning_rate": 2.26103512589369e-06,
      "loss": 0.3095,
      "step": 19917
    },
    {
      "epoch": 1.5478706869754428,
      "grad_norm": 0.7059916257858276,
      "learning_rate": 2.2606465651227853e-06,
      "loss": 0.2639,
      "step": 19918
    },
    {
      "epoch": 1.547948399129624,
      "grad_norm": 0.5018666386604309,
      "learning_rate": 2.2602580043518807e-06,
      "loss": 0.1174,
      "step": 19919
    },
    {
      "epoch": 1.5480261112838047,
      "grad_norm": 0.22832733392715454,
      "learning_rate": 2.259869443580976e-06,
      "loss": 0.0583,
      "step": 19920
    },
    {
      "epoch": 1.5481038234379856,
      "grad_norm": 0.29964274168014526,
      "learning_rate": 2.259480882810072e-06,
      "loss": 0.1689,
      "step": 19921
    },
    {
      "epoch": 1.5481815355921666,
      "grad_norm": 0.2733839154243469,
      "learning_rate": 2.2590923220391672e-06,
      "loss": 0.0812,
      "step": 19922
    },
    {
      "epoch": 1.5482592477463475,
      "grad_norm": 0.3740828335285187,
      "learning_rate": 2.2587037612682626e-06,
      "loss": 0.098,
      "step": 19923
    },
    {
      "epoch": 1.5483369599005283,
      "grad_norm": 0.5307596921920776,
      "learning_rate": 2.258315200497358e-06,
      "loss": 0.1839,
      "step": 19924
    },
    {
      "epoch": 1.5484146720547094,
      "grad_norm": 0.11697894334793091,
      "learning_rate": 2.2579266397264533e-06,
      "loss": 0.0298,
      "step": 19925
    },
    {
      "epoch": 1.5484923842088902,
      "grad_norm": 0.5073776841163635,
      "learning_rate": 2.2575380789555487e-06,
      "loss": 0.1775,
      "step": 19926
    },
    {
      "epoch": 1.548570096363071,
      "grad_norm": 1.0711408853530884,
      "learning_rate": 2.257149518184644e-06,
      "loss": 0.4022,
      "step": 19927
    },
    {
      "epoch": 1.5486478085172521,
      "grad_norm": 0.46667322516441345,
      "learning_rate": 2.25676095741374e-06,
      "loss": 0.1013,
      "step": 19928
    },
    {
      "epoch": 1.548725520671433,
      "grad_norm": 0.48178166151046753,
      "learning_rate": 2.2563723966428353e-06,
      "loss": 0.2077,
      "step": 19929
    },
    {
      "epoch": 1.5488032328256138,
      "grad_norm": 0.2653804123401642,
      "learning_rate": 2.2559838358719306e-06,
      "loss": 0.0404,
      "step": 19930
    },
    {
      "epoch": 1.548880944979795,
      "grad_norm": 0.4333966374397278,
      "learning_rate": 2.255595275101026e-06,
      "loss": 0.4456,
      "step": 19931
    },
    {
      "epoch": 1.5489586571339757,
      "grad_norm": 0.37103384733200073,
      "learning_rate": 2.2552067143301214e-06,
      "loss": 0.1526,
      "step": 19932
    },
    {
      "epoch": 1.5490363692881566,
      "grad_norm": 0.14119158685207367,
      "learning_rate": 2.2548181535592168e-06,
      "loss": 0.0062,
      "step": 19933
    },
    {
      "epoch": 1.5491140814423376,
      "grad_norm": 0.27664655447006226,
      "learning_rate": 2.254429592788312e-06,
      "loss": 0.0561,
      "step": 19934
    },
    {
      "epoch": 1.5491917935965185,
      "grad_norm": 0.2376503050327301,
      "learning_rate": 2.254041032017408e-06,
      "loss": 0.0498,
      "step": 19935
    },
    {
      "epoch": 1.5492695057506993,
      "grad_norm": 0.7276737093925476,
      "learning_rate": 2.2536524712465033e-06,
      "loss": 0.3444,
      "step": 19936
    },
    {
      "epoch": 1.5493472179048804,
      "grad_norm": 0.45708218216896057,
      "learning_rate": 2.2532639104755987e-06,
      "loss": 0.2546,
      "step": 19937
    },
    {
      "epoch": 1.5494249300590612,
      "grad_norm": 0.23135197162628174,
      "learning_rate": 2.252875349704694e-06,
      "loss": 0.0328,
      "step": 19938
    },
    {
      "epoch": 1.549502642213242,
      "grad_norm": 0.6217837929725647,
      "learning_rate": 2.2524867889337894e-06,
      "loss": 0.189,
      "step": 19939
    },
    {
      "epoch": 1.5495803543674231,
      "grad_norm": 0.016443025320768356,
      "learning_rate": 2.2520982281628848e-06,
      "loss": 0.0013,
      "step": 19940
    },
    {
      "epoch": 1.549658066521604,
      "grad_norm": 0.3540151119232178,
      "learning_rate": 2.25170966739198e-06,
      "loss": 0.1119,
      "step": 19941
    },
    {
      "epoch": 1.5497357786757848,
      "grad_norm": 0.7543725371360779,
      "learning_rate": 2.251321106621076e-06,
      "loss": 0.1039,
      "step": 19942
    },
    {
      "epoch": 1.549813490829966,
      "grad_norm": 0.8195369243621826,
      "learning_rate": 2.250932545850171e-06,
      "loss": 0.696,
      "step": 19943
    },
    {
      "epoch": 1.5498912029841467,
      "grad_norm": 0.4434337615966797,
      "learning_rate": 2.2505439850792667e-06,
      "loss": 0.0708,
      "step": 19944
    },
    {
      "epoch": 1.5499689151383276,
      "grad_norm": 0.28396978974342346,
      "learning_rate": 2.250155424308362e-06,
      "loss": 0.0624,
      "step": 19945
    },
    {
      "epoch": 1.5500466272925086,
      "grad_norm": 0.5931298136711121,
      "learning_rate": 2.2497668635374575e-06,
      "loss": 0.2582,
      "step": 19946
    },
    {
      "epoch": 1.5501243394466895,
      "grad_norm": 1.3126691579818726,
      "learning_rate": 2.249378302766553e-06,
      "loss": 0.2432,
      "step": 19947
    },
    {
      "epoch": 1.5502020516008703,
      "grad_norm": 0.508324146270752,
      "learning_rate": 2.248989741995648e-06,
      "loss": 0.1411,
      "step": 19948
    },
    {
      "epoch": 1.5502797637550514,
      "grad_norm": 0.25607815384864807,
      "learning_rate": 2.248601181224744e-06,
      "loss": 0.0692,
      "step": 19949
    },
    {
      "epoch": 1.5503574759092322,
      "grad_norm": 1.7719550132751465,
      "learning_rate": 2.248212620453839e-06,
      "loss": 0.4326,
      "step": 19950
    },
    {
      "epoch": 1.550435188063413,
      "grad_norm": 0.4185026288032532,
      "learning_rate": 2.2478240596829347e-06,
      "loss": 0.1128,
      "step": 19951
    },
    {
      "epoch": 1.5505129002175941,
      "grad_norm": 0.5577641725540161,
      "learning_rate": 2.24743549891203e-06,
      "loss": 0.2033,
      "step": 19952
    },
    {
      "epoch": 1.550590612371775,
      "grad_norm": 0.4665848910808563,
      "learning_rate": 2.2470469381411255e-06,
      "loss": 0.1515,
      "step": 19953
    },
    {
      "epoch": 1.5506683245259558,
      "grad_norm": 0.4623645842075348,
      "learning_rate": 2.246658377370221e-06,
      "loss": 0.0833,
      "step": 19954
    },
    {
      "epoch": 1.5507460366801369,
      "grad_norm": 0.19803932309150696,
      "learning_rate": 2.2462698165993162e-06,
      "loss": 0.0621,
      "step": 19955
    },
    {
      "epoch": 1.5508237488343177,
      "grad_norm": 0.5091260075569153,
      "learning_rate": 2.245881255828412e-06,
      "loss": 0.4164,
      "step": 19956
    },
    {
      "epoch": 1.5509014609884986,
      "grad_norm": 0.21414494514465332,
      "learning_rate": 2.245492695057507e-06,
      "loss": 0.084,
      "step": 19957
    },
    {
      "epoch": 1.5509791731426796,
      "grad_norm": 0.3148752748966217,
      "learning_rate": 2.2451041342866028e-06,
      "loss": 0.1623,
      "step": 19958
    },
    {
      "epoch": 1.5510568852968605,
      "grad_norm": 0.4791836738586426,
      "learning_rate": 2.244715573515698e-06,
      "loss": 0.1734,
      "step": 19959
    },
    {
      "epoch": 1.5511345974510413,
      "grad_norm": 0.17792253196239471,
      "learning_rate": 2.2443270127447935e-06,
      "loss": 0.0315,
      "step": 19960
    },
    {
      "epoch": 1.5512123096052224,
      "grad_norm": 0.7968356013298035,
      "learning_rate": 2.243938451973889e-06,
      "loss": 0.9818,
      "step": 19961
    },
    {
      "epoch": 1.5512900217594032,
      "grad_norm": 0.9007046222686768,
      "learning_rate": 2.2435498912029843e-06,
      "loss": 0.4962,
      "step": 19962
    },
    {
      "epoch": 1.551367733913584,
      "grad_norm": 0.13434873521327972,
      "learning_rate": 2.2431613304320796e-06,
      "loss": 0.035,
      "step": 19963
    },
    {
      "epoch": 1.5514454460677651,
      "grad_norm": 0.47182372212409973,
      "learning_rate": 2.242772769661175e-06,
      "loss": 0.1988,
      "step": 19964
    },
    {
      "epoch": 1.5515231582219458,
      "grad_norm": 0.6190450191497803,
      "learning_rate": 2.2423842088902704e-06,
      "loss": 0.3976,
      "step": 19965
    },
    {
      "epoch": 1.5516008703761268,
      "grad_norm": 0.4342450201511383,
      "learning_rate": 2.241995648119366e-06,
      "loss": 0.0953,
      "step": 19966
    },
    {
      "epoch": 1.5516785825303079,
      "grad_norm": 0.21789434552192688,
      "learning_rate": 2.2416070873484616e-06,
      "loss": 0.0444,
      "step": 19967
    },
    {
      "epoch": 1.5517562946844885,
      "grad_norm": 0.42561647295951843,
      "learning_rate": 2.241218526577557e-06,
      "loss": 0.0853,
      "step": 19968
    },
    {
      "epoch": 1.5518340068386696,
      "grad_norm": 0.4267587959766388,
      "learning_rate": 2.2408299658066523e-06,
      "loss": 0.165,
      "step": 19969
    },
    {
      "epoch": 1.5519117189928506,
      "grad_norm": 0.6483349800109863,
      "learning_rate": 2.2404414050357477e-06,
      "loss": 0.2163,
      "step": 19970
    },
    {
      "epoch": 1.5519894311470313,
      "grad_norm": 0.3747568428516388,
      "learning_rate": 2.240052844264843e-06,
      "loss": 0.0699,
      "step": 19971
    },
    {
      "epoch": 1.5520671433012123,
      "grad_norm": 0.3694857954978943,
      "learning_rate": 2.2396642834939384e-06,
      "loss": 0.1236,
      "step": 19972
    },
    {
      "epoch": 1.5521448554553934,
      "grad_norm": 0.8671170473098755,
      "learning_rate": 2.2392757227230342e-06,
      "loss": 0.1092,
      "step": 19973
    },
    {
      "epoch": 1.552222567609574,
      "grad_norm": 0.40709981322288513,
      "learning_rate": 2.2388871619521296e-06,
      "loss": 0.1895,
      "step": 19974
    },
    {
      "epoch": 1.552300279763755,
      "grad_norm": 0.040605682879686356,
      "learning_rate": 2.238498601181225e-06,
      "loss": 0.005,
      "step": 19975
    },
    {
      "epoch": 1.5523779919179361,
      "grad_norm": 0.32870954275131226,
      "learning_rate": 2.2381100404103203e-06,
      "loss": 0.1029,
      "step": 19976
    },
    {
      "epoch": 1.5524557040721167,
      "grad_norm": 0.44329872727394104,
      "learning_rate": 2.2377214796394157e-06,
      "loss": 0.1204,
      "step": 19977
    },
    {
      "epoch": 1.5525334162262978,
      "grad_norm": 0.5351241230964661,
      "learning_rate": 2.237332918868511e-06,
      "loss": 0.1639,
      "step": 19978
    },
    {
      "epoch": 1.5526111283804787,
      "grad_norm": 1.2219336032867432,
      "learning_rate": 2.2369443580976065e-06,
      "loss": 0.3085,
      "step": 19979
    },
    {
      "epoch": 1.5526888405346595,
      "grad_norm": 0.4575195014476776,
      "learning_rate": 2.2365557973267023e-06,
      "loss": 0.2942,
      "step": 19980
    },
    {
      "epoch": 1.5527665526888406,
      "grad_norm": 0.43420007824897766,
      "learning_rate": 2.236167236555797e-06,
      "loss": 0.0842,
      "step": 19981
    },
    {
      "epoch": 1.5528442648430214,
      "grad_norm": 0.08781400322914124,
      "learning_rate": 2.235778675784893e-06,
      "loss": 0.0175,
      "step": 19982
    },
    {
      "epoch": 1.5529219769972022,
      "grad_norm": 0.4718320965766907,
      "learning_rate": 2.2353901150139884e-06,
      "loss": 0.0983,
      "step": 19983
    },
    {
      "epoch": 1.5529996891513833,
      "grad_norm": 2.9106855392456055,
      "learning_rate": 2.2350015542430838e-06,
      "loss": 0.5332,
      "step": 19984
    },
    {
      "epoch": 1.5530774013055642,
      "grad_norm": 0.33154383301734924,
      "learning_rate": 2.234612993472179e-06,
      "loss": 0.0543,
      "step": 19985
    },
    {
      "epoch": 1.553155113459745,
      "grad_norm": 0.24780650436878204,
      "learning_rate": 2.2342244327012745e-06,
      "loss": 0.0744,
      "step": 19986
    },
    {
      "epoch": 1.553232825613926,
      "grad_norm": 1.0946241617202759,
      "learning_rate": 2.2338358719303703e-06,
      "loss": 0.2093,
      "step": 19987
    },
    {
      "epoch": 1.553310537768107,
      "grad_norm": 0.6292157769203186,
      "learning_rate": 2.2334473111594652e-06,
      "loss": 0.4549,
      "step": 19988
    },
    {
      "epoch": 1.5533882499222877,
      "grad_norm": 0.314823180437088,
      "learning_rate": 2.233058750388561e-06,
      "loss": 0.0372,
      "step": 19989
    },
    {
      "epoch": 1.5534659620764688,
      "grad_norm": 0.230060875415802,
      "learning_rate": 2.2326701896176564e-06,
      "loss": 0.1547,
      "step": 19990
    },
    {
      "epoch": 1.5535436742306497,
      "grad_norm": 0.9346175193786621,
      "learning_rate": 2.232281628846752e-06,
      "loss": 0.2978,
      "step": 19991
    },
    {
      "epoch": 1.5536213863848305,
      "grad_norm": 0.29350554943084717,
      "learning_rate": 2.231893068075847e-06,
      "loss": 0.1393,
      "step": 19992
    },
    {
      "epoch": 1.5536990985390116,
      "grad_norm": 0.17947600781917572,
      "learning_rate": 2.2315045073049425e-06,
      "loss": 0.0472,
      "step": 19993
    },
    {
      "epoch": 1.5537768106931924,
      "grad_norm": 0.22725962102413177,
      "learning_rate": 2.2311159465340383e-06,
      "loss": 0.2701,
      "step": 19994
    },
    {
      "epoch": 1.5538545228473732,
      "grad_norm": 0.6438267230987549,
      "learning_rate": 2.2307273857631333e-06,
      "loss": 0.1027,
      "step": 19995
    },
    {
      "epoch": 1.5539322350015543,
      "grad_norm": 0.5654988884925842,
      "learning_rate": 2.230338824992229e-06,
      "loss": 0.1697,
      "step": 19996
    },
    {
      "epoch": 1.5540099471557351,
      "grad_norm": 0.384050190448761,
      "learning_rate": 2.2299502642213245e-06,
      "loss": 0.1203,
      "step": 19997
    },
    {
      "epoch": 1.554087659309916,
      "grad_norm": 0.20012447237968445,
      "learning_rate": 2.22956170345042e-06,
      "loss": 0.0264,
      "step": 19998
    },
    {
      "epoch": 1.554165371464097,
      "grad_norm": 0.99531489610672,
      "learning_rate": 2.229173142679515e-06,
      "loss": 0.4076,
      "step": 19999
    },
    {
      "epoch": 1.554243083618278,
      "grad_norm": 0.4288058876991272,
      "learning_rate": 2.2287845819086106e-06,
      "loss": 0.0444,
      "step": 20000
    }
  ],
  "logging_steps": 1,
  "max_steps": 25736,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 10000,
  "total_flos": 2.814163819454331e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
